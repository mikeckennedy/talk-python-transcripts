WEBVTT

00:00:00.001 --> 00:00:04.320
If you're a data scientist, how do you deliver your analysis and your models to the people who need them?

00:00:04.320 --> 00:00:07.960
A really good option is to serve them over Flask as an API.

00:00:07.960 --> 00:00:12.000
But there are some special considerations you might want to keep in mind.

00:00:12.000 --> 00:00:13.700
How should you structure this API?

00:00:13.700 --> 00:00:18.040
What type of project structures work best for data science and web apps together?

00:00:18.040 --> 00:00:22.560
That and much more on this episode of Talk Python to Me with guest AJ Pryor.

00:00:22.560 --> 00:00:26.520
It's episode 226, recorded August 5th, 2019.

00:00:26.520 --> 00:00:46.020
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:00:46.020 --> 00:00:47.960
This is your host, Michael Kennedy.

00:00:47.960 --> 00:00:50.080
Follow me on Twitter where I'm @mkennedy.

00:00:50.080 --> 00:00:53.840
Keep up with the show and listen to past episodes at talkpython.fm.

00:00:53.840 --> 00:00:56.280
And follow the show on Twitter via at Talk Python.

00:00:56.960 --> 00:00:59.260
This episode is brought to you by Linode and Rollbar.

00:00:59.260 --> 00:01:01.280
Please check out what they're offering during their segments.

00:01:01.280 --> 00:01:02.620
It really helps support the show.

00:01:02.620 --> 00:01:04.780
Hey, Jay, welcome to Talk Python to Me.

00:01:04.780 --> 00:01:05.760
Hi, Michael. How are you doing?

00:01:05.760 --> 00:01:07.700
I'm doing super well. Thanks for being on the show.

00:01:07.700 --> 00:01:09.340
Yeah, absolutely. I'm super excited.

00:01:09.340 --> 00:01:10.760
Yeah, it's going to be a lot of fun.

00:01:10.760 --> 00:01:18.240
We get to talk about some things that are really popular in Python, web development, and data science.

00:01:18.240 --> 00:01:22.380
And then we're going to intersect them together, which I don't know is going to make them mega popular.

00:01:22.380 --> 00:01:35.260
Because if you look at the Python space, all the surveys and sort of where people are working, it seems like it's mostly web development or data science, and then just like a whole bunch of others, right?

00:01:35.300 --> 00:01:36.720
So we're hitting both of those today.

00:01:36.720 --> 00:01:40.720
Yeah, I mean, you've got on one hand sort of most of the code that's written is for the web.

00:01:40.720 --> 00:01:43.700
And then you've got this meteoric rise of Python coming beside it.

00:01:43.700 --> 00:01:45.220
So I figure why not just do both?

00:01:45.220 --> 00:01:46.920
And then you're pretty much positioned at the top.

00:01:47.600 --> 00:01:49.760
Yeah, it's definitely a good place to be, I would say.

00:01:49.760 --> 00:01:51.160
One way to look at it, at least, right?

00:01:51.160 --> 00:01:52.660
Yeah, it's a positive way for sure.

00:01:52.660 --> 00:01:55.680
So before we get into that, though, let's go ahead and start with your story.

00:01:55.680 --> 00:01:57.000
How do you get into programming in Python?

00:01:57.000 --> 00:01:57.520
Sure.

00:01:57.520 --> 00:02:00.840
Actually, I didn't grow up around programming at all.

00:02:00.840 --> 00:02:02.960
I grew up in the middle of nowhere, Georgia.

00:02:02.960 --> 00:02:04.420
I played sports as a kid.

00:02:04.420 --> 00:02:07.300
You know, I was always into math and science, but never programming.

00:02:07.860 --> 00:02:10.440
And I went to college undergrad at Georgia Tech.

00:02:10.440 --> 00:02:16.200
And my first semester there was declared as an engineering major and took a MATLAB course.

00:02:16.200 --> 00:02:18.920
And immediately, just everything about it clicked.

00:02:18.920 --> 00:02:19.880
I was hooked.

00:02:19.880 --> 00:02:21.980
And of course, you know, MATLAB is MATLAB.

00:02:21.980 --> 00:02:26.000
And so I changed my major immediately to computer science.

00:02:26.000 --> 00:02:33.340
And then I got about one semester further and started taking some of the sort of pure CS classes.

00:02:33.340 --> 00:02:37.560
You know, it's very theoretical and that's fine and all, but I didn't feel as hands-on with it.

00:02:38.040 --> 00:02:43.340
And simultaneous to that, I started taking some physics classes, which had an application of Python.

00:02:43.340 --> 00:02:46.780
So we were kind of modeling gravitational systems and whatnot.

00:02:46.780 --> 00:02:51.480
And that really resonated with me because it had both the math side of things that I gravitated towards,

00:02:51.480 --> 00:02:55.140
but I was also building things using code, which was new.

00:02:55.140 --> 00:02:56.720
And I got really excited about that.

00:02:56.720 --> 00:03:02.580
So I remember we had this lab where we built like an orbital system of the moon and a rocket and earth.

00:03:02.580 --> 00:03:06.500
And, you know, before I know it, I had this little couple of dots on a screen moving around.

00:03:06.600 --> 00:03:08.780
And I'm convinced that I'm like landing Apollo 11.

00:03:08.780 --> 00:03:10.440
And I just, it was really gratifying.

00:03:10.440 --> 00:03:11.540
And so I've been hooked ever since.

00:03:11.540 --> 00:03:12.500
And the rest is history.

00:03:12.500 --> 00:03:13.120
Yeah, that's cool.

00:03:13.120 --> 00:03:18.040
It's really interesting how some of these early wins, like this three-body problem you're simulating

00:03:18.040 --> 00:03:20.620
in physics or whatever, like it's not a big deal, right?

00:03:20.620 --> 00:03:25.500
Like the little simulation is probably pretty limited, but at the same time, it feels like

00:03:25.500 --> 00:03:26.800
so gratifying, right?

00:03:26.800 --> 00:03:27.580
Yeah, absolutely.

00:03:27.580 --> 00:03:30.800
And then, you know, of course that starts off as sort of the baby problem.

00:03:30.800 --> 00:03:35.540
And then as I went on to grad school and my PhD, and this was all physics, the coding got

00:03:35.540 --> 00:03:36.140
more complicated.

00:03:36.140 --> 00:03:39.780
The algorithms got more complicated, but at the core, it was still, it was still the same

00:03:39.780 --> 00:03:40.380
problem, right?

00:03:40.380 --> 00:03:44.300
You're solving some kind of computational problem through coding.

00:03:44.300 --> 00:03:47.900
And although that wasn't always Python these days, it's pretty much moved from that.

00:03:47.900 --> 00:03:53.020
You know, I kind of diverted along the way and did some C++ and did CUDA and GPU programming,

00:03:53.020 --> 00:03:55.960
but Python is a lot of what I do day to day now.

00:03:55.960 --> 00:03:56.820
Yeah, cool, cool.

00:03:56.820 --> 00:03:59.380
You know, I followed a bit of a similar path.

00:03:59.380 --> 00:04:04.900
Like I was working my PhD in math and doing a lot of math stuff, but then also analyzing

00:04:04.900 --> 00:04:05.680
and programming.

00:04:05.680 --> 00:04:11.920
And I guess I should have known that I was not really intended to finish my degree, my PhD

00:04:11.920 --> 00:04:18.320
anyway, and go into math because I would find when I'm working on these projects, like I was

00:04:18.320 --> 00:04:20.660
really excited, especially about the programming.

00:04:20.660 --> 00:04:24.340
And it was so cool, kind of like you described this, like how awesome it felt to have this

00:04:24.340 --> 00:04:25.160
simulation running.

00:04:25.160 --> 00:04:30.840
And then I'd always kind of get like a little bit less excited and like, oh, here comes the

00:04:30.840 --> 00:04:35.280
drudgery work part of it when I got to the math and then you go back to the program and

00:04:35.280 --> 00:04:36.140
I get really excited again.

00:04:36.140 --> 00:04:38.580
I'm like, I should have been a sign that I could have.

00:04:38.580 --> 00:04:39.000
That's what you know.

00:04:39.000 --> 00:04:39.460
Yeah.

00:04:39.460 --> 00:04:39.840
Yeah.

00:04:39.840 --> 00:04:40.700
But no, it was all good.

00:04:40.700 --> 00:04:42.700
So for you, what are you doing these days?

00:04:42.700 --> 00:04:45.520
So I work for a company called American Tire Distributors.

00:04:45.520 --> 00:04:49.300
It's the largest distributor of replacement tires in the world.

00:04:49.300 --> 00:04:54.060
So the tire industry is very interesting because tires are something that pretty much everybody

00:04:54.060 --> 00:04:54.820
has to buy.

00:04:54.820 --> 00:04:56.020
You don't buy frequently.

00:04:56.020 --> 00:04:59.440
And it's an overwhelmingly miserable experience for most people.

00:04:59.440 --> 00:04:59.720
Yeah.

00:04:59.720 --> 00:05:01.280
And it's an antiquated industry.

00:05:01.280 --> 00:05:06.520
So it turns out that they have a ton of data, but technologically speaking, it's not particularly

00:05:06.520 --> 00:05:07.700
modern.

00:05:08.220 --> 00:05:13.500
And so my company has spun up a pretty new analytics team that's data scientists, engineers,

00:05:13.500 --> 00:05:19.180
and developers to kind of build out applications to try to revolutionize that industry and bring

00:05:19.180 --> 00:05:23.880
it up to the modern world in terms of analytics, increasing supply chain efficiency and all of

00:05:23.880 --> 00:05:24.020
this.

00:05:24.120 --> 00:05:28.600
And so as a data scientist, particularly one who is interested in web development and app

00:05:28.600 --> 00:05:33.160
development, like I am, it's kind of like being a kid in a candy store because there's tons of data,

00:05:33.160 --> 00:05:35.460
both historical and streaming every day.

00:05:35.600 --> 00:05:41.420
And basically no solutions other than the traditional sort of BI descriptive backward

00:05:41.420 --> 00:05:43.220
looking stuff, which is good.

00:05:43.220 --> 00:05:43.840
And you need that.

00:05:43.840 --> 00:05:48.180
But we're also looking to build more predictive analytics and doing forecasting and finding

00:05:48.180 --> 00:05:52.360
other optimization techniques to kind of squeeze efficiency because as a distributor, you're a

00:05:52.360 --> 00:05:54.260
middleman and efficiency is the name of the game.

00:05:54.260 --> 00:05:58.900
So I find myself sort of stuck between I build backends in Python.

00:05:58.900 --> 00:06:01.180
I write a lot of SQL, interact with databases.

00:06:01.180 --> 00:06:04.760
Sometimes that means building new databases on our cloud resources.

00:06:04.760 --> 00:06:10.560
And then I spend a lot of time building front ends to actually expose those applications in a way

00:06:10.560 --> 00:06:11.340
that's consumable.

00:06:11.340 --> 00:06:14.840
And that's actually a very important part of this whole process because at the end of the day,

00:06:14.840 --> 00:06:19.620
if you're building an app for somebody, it doesn't matter how fancy your mathematics is.

00:06:19.620 --> 00:06:24.360
If the consumer who's actually making an actionable decision on that can't do anything useful,

00:06:24.360 --> 00:06:25.740
it's not worth your time.

00:06:25.740 --> 00:06:28.940
So that's where I find myself spending my time.

00:06:28.940 --> 00:06:30.920
I write a lot of code and talk to a lot of people.

00:06:30.920 --> 00:06:31.600
Yeah, yeah.

00:06:31.600 --> 00:06:32.440
That sounds so fun.

00:06:32.440 --> 00:06:39.240
I mean, almost any industry that has like tons of data and yet no one is doing anything with it.

00:06:39.240 --> 00:06:40.060
Not really.

00:06:40.060 --> 00:06:41.400
It just sounds really fun.

00:06:41.400 --> 00:06:43.540
You can come and go, all right, let's see what we can do here.

00:06:43.540 --> 00:06:45.660
We can bring in a little TensorFlow to do this.

00:06:45.660 --> 00:06:48.600
We can bring in some APIs to modernize that.

00:06:48.600 --> 00:06:51.880
Like, why are you seriously emailing me an Excel spreadsheet?

00:06:51.880 --> 00:06:53.560
Is that really what's happening?

00:06:53.960 --> 00:06:56.000
Oh, that's the story of my life.

00:06:56.000 --> 00:06:56.920
Do you guys use SharePoint?

00:06:56.920 --> 00:06:57.620
You're hitting home.

00:06:57.620 --> 00:07:01.440
Do you like share Excel docs through SharePoint?

00:07:01.440 --> 00:07:02.020
Yeah.

00:07:02.020 --> 00:07:05.020
I mean, we use a bit of everything, which is part of the problem.

00:07:05.020 --> 00:07:08.920
There's historical reasons that it's an Excel spreadsheet or it's emailed.

00:07:08.920 --> 00:07:10.560
And, you know, consolidating, that's a lot of work.

00:07:10.560 --> 00:07:13.180
And that's something that we've got people working diligently on.

00:07:13.260 --> 00:07:14.660
But it keeps things interesting.

00:07:14.660 --> 00:07:18.780
You know, you learn about tech from the lens of like your big tech companies.

00:07:18.780 --> 00:07:23.520
And the reality is there's an awful lot of business out there that are not nearly that refined.

00:07:23.520 --> 00:07:25.680
And so it's a different problem.

00:07:25.680 --> 00:07:26.500
It's fun, though.

00:07:26.500 --> 00:07:27.460
I really love my job.

00:07:27.460 --> 00:07:28.840
Yeah, it's definitely a different problem.

00:07:28.840 --> 00:07:32.080
I mean, if you're working at Netflix as a data scientist, it would be very different.

00:07:32.080 --> 00:07:34.040
Or, you know, somewhere like that, right?

00:07:34.040 --> 00:07:35.040
Just as an analogy.

00:07:35.600 --> 00:07:42.260
But I do think it sounds really fun to come in and have kind of this blank slate and say, okay, it's 2019.

00:07:42.260 --> 00:07:44.740
These are the tools we're using.

00:07:44.740 --> 00:07:46.700
We could easily apply them here.

00:07:46.700 --> 00:07:54.140
Because it happens to be open source, you don't even have to get budget approved to like buy the $2,000 license for this or that.

00:07:54.140 --> 00:07:57.080
Like you just say, okay, you know, let me go after it.

00:07:57.080 --> 00:07:57.540
I'll do it.

00:07:57.540 --> 00:07:57.920
Yeah.

00:07:57.920 --> 00:08:03.100
I mean, our analytics team functions basically like a startup inside of a very sizable company.

00:08:03.220 --> 00:08:06.020
So we have freedom to pick the tech we want to use.

00:08:06.020 --> 00:08:08.840
A lot of those decisions get to be made sort of last minute on the fly.

00:08:08.840 --> 00:08:11.600
We get to use whatever the latest and greatest tech is.

00:08:11.600 --> 00:08:12.580
So it's a lot of fun.

00:08:12.580 --> 00:08:20.440
Yeah, that's actually, you know, I find those types of environments are really, really good for actually learning a whole lot of technology and techniques.

00:08:20.440 --> 00:08:25.260
Because you're not dropped into like, well, we already have an enterprise architect.

00:08:25.260 --> 00:08:27.000
And they say we use this technology.

00:08:27.000 --> 00:08:29.200
And then we use it in this way and not in that way.

00:08:29.200 --> 00:08:31.500
Now you go work on a small sliver, right?

00:08:31.580 --> 00:08:33.180
Like you're there to just explore.

00:08:33.180 --> 00:08:36.320
And I don't know what it's like for you.

00:08:36.320 --> 00:08:43.080
But the times I've been in those situations, like people don't really care what technology you're using or how you're using it.

00:08:43.080 --> 00:08:46.780
If you're showing results and you're like, I've tried these things and look what we're doing.

00:08:46.780 --> 00:08:48.640
Like last week we couldn't do this.

00:08:48.640 --> 00:08:49.460
This week we can.

00:08:49.460 --> 00:08:51.220
That's all they really care about.

00:08:51.220 --> 00:08:51.860
And they're super happy.

00:08:51.860 --> 00:08:52.960
Is that kind of the experience?

00:08:52.960 --> 00:09:05.700
Yeah, I mean, more or less, like you were saying earlier, if you worked at a company like a Netflix or an Uber, you can have a whole data science team, you know, whatever, 10, 20, 100 people dedicated to making tiny incremental improvements to an algorithm.

00:09:05.700 --> 00:09:11.380
And that might be worthwhile because it's a half percentage point across an enormous profit base, right?

00:09:11.380 --> 00:09:12.840
And so that might justify it.

00:09:12.840 --> 00:09:22.620
But in a smaller team, you might have more of the kind of 80, 20 approach where you're trying to get most of the benefit with the least amount of work so that you can touch a lot of different points.

00:09:22.620 --> 00:09:27.600
Because the surface area of your problem space is just huge compared to how many people you have.

00:09:27.600 --> 00:09:30.460
As a company grows over time, that dynamic shifts.

00:09:30.460 --> 00:09:30.860
Yeah.

00:09:30.860 --> 00:09:32.140
There's like seasons.

00:09:32.140 --> 00:09:34.820
It's also brings up some sort of team structure issues.

00:09:34.820 --> 00:09:35.600
Yeah, for sure.

00:09:35.600 --> 00:09:36.220
Yeah, exactly.

00:09:36.220 --> 00:09:39.460
Like seasons, it kind of changes as the evolution of the company progresses.

00:09:39.460 --> 00:09:39.900
Yeah.

00:09:39.900 --> 00:09:41.160
Cool, cool.

00:09:41.160 --> 00:09:47.740
So one of the things that we're going to talk about, and I would like to start off the conversation with, you touched on it before.

00:09:47.740 --> 00:09:54.160
It's really cool to have these libraries and these predictions and all of this tooling in place.

00:09:54.160 --> 00:10:02.140
But if you can't share it and expose it over, say, like a web service or something like that, then it's not super valuable, is it?

00:10:02.140 --> 00:10:02.860
No, not at all.

00:10:02.860 --> 00:10:08.880
So let's talk about your work that you're doing with Flask and data science, right?

00:10:08.880 --> 00:10:12.480
This is the web dev side of the intersection that I was talking about.

00:10:12.480 --> 00:10:12.820
Right.

00:10:13.120 --> 00:10:19.120
Basically, you know, what is a data science application and how is that different from a traditional, quote, web app?

00:10:19.120 --> 00:10:28.800
The biggest difference is that a data science application is going to have some kind of computational predictive machine learning element embedded into the actual API results.

00:10:28.800 --> 00:10:41.420
So if I'm purely a front end developer and I'm used to a workflow of building an app, hitting an endpoint, receiving data and displaying it, there's basically no difference between a traditional app and something that's driven by data science.

00:10:41.420 --> 00:10:45.300
Other than maybe you're cooking up more graphs and visualizations, depending on the context.

00:10:45.300 --> 00:10:51.520
But from the back end perspective, you're going to be generating these API results, calling some kind of prediction method.

00:10:51.520 --> 00:11:07.720
And so one of the great things about Python with machine learning, which is, in my opinion, one of the reasons it's become so popular, is that it has scikit-learn, which is a very understandable interface to sort of churn out predictions repeatedly across many different models, many different parameters.

00:11:07.720 --> 00:11:14.140
And so it makes the kind of plug and play nature of how the data science industry needs to work very friendly.

00:11:14.140 --> 00:11:18.460
And that means that we can have multiple data scientists trying to solve the same problem.

00:11:18.460 --> 00:11:19.980
Each have their own models.

00:11:19.980 --> 00:11:20.900
They can be tuning it.

00:11:20.900 --> 00:11:21.960
We might combine them.

00:11:21.960 --> 00:11:28.780
But at the end of the day, we can have some kind of predict method that generates data and that that data can be JSONified.

00:11:28.780 --> 00:11:30.820
It can be sent back through an API.

00:11:30.820 --> 00:11:37.820
And so it's really in the nature of the meaning of the data and where it comes from and what problems it's trying to solve.

00:11:37.820 --> 00:11:39.620
It's really the only main difference.

00:11:39.620 --> 00:11:40.220
Yeah, for sure.

00:11:40.220 --> 00:11:49.120
When you're talking about APIs, I suspect consuming them looks very similar to working with the GitHub API or the Stripe API or whatever, right?

00:11:49.120 --> 00:11:49.660
Yeah, exactly.

00:11:49.660 --> 00:11:50.500
You've got some authentication.

00:11:50.500 --> 00:11:52.120
You call some methods.

00:11:52.120 --> 00:11:59.540
You get a JSON answer back and you say, they recommend this tire or they recommend it's time to buy or not time to buy or whatever, right?

00:11:59.540 --> 00:12:00.800
Like whatever it is you're trying to predict.

00:12:00.800 --> 00:12:01.120
Yeah, exactly.

00:12:01.120 --> 00:12:08.880
When it comes to web applications, though, I suspect that also means bringing in other interesting elements.

00:12:08.880 --> 00:12:19.000
Like, for example, there's probably more charting and graphing and interactive data display on something that is data science backed than something that's not.

00:12:19.000 --> 00:12:22.560
You know, like my site that does like training, right?

00:12:22.560 --> 00:12:25.260
It shows you videos, but I don't think there's a graph on the site.

00:12:25.260 --> 00:12:27.600
Like there's no graphs, nothing like that, really.

00:12:27.600 --> 00:12:28.340
Right, exactly.

00:12:28.480 --> 00:12:30.900
Maybe on some of your like admin dashboards or whatever.

00:12:30.900 --> 00:12:31.520
Possibly, yeah.

00:12:31.520 --> 00:12:32.640
It depends on the context.

00:12:32.640 --> 00:12:36.480
So, for example, we might be making a pricing tool, right?

00:12:36.480 --> 00:12:42.100
So, let's say you want to do some machine learning analytics to figure out how should I adjust my pricing on different products?

00:12:42.100 --> 00:12:50.240
Well, the way somebody in the tire industry or the shoe industry are going to handle those problems are very different because they have different problems.

00:12:50.740 --> 00:12:55.900
So, to pull from tires, there's an enormous number of different kinds of things.

00:12:55.900 --> 00:12:59.940
And so, it's tens of thousands of things that you might be making a decision about pricing.

00:13:00.160 --> 00:13:01.160
A human can't understand that.

00:13:01.160 --> 00:13:01.740
A human can't understand that.

00:13:01.740 --> 00:13:15.980
But if you make an application that makes it very easy to slice and dice that ecosystem and bubbles to the top the things that are maybe the most egregiously mispriced one way or the other, you allow a human to then make decisions about the important parts of that.

00:13:16.400 --> 00:13:26.520
But that kind of interaction might not be so meaningful if you're in a product space where there's not so many things and, you know, it's not as hard for a human to make a decision, but you have other problems.

00:13:26.520 --> 00:13:31.520
So, it's kind of a dynamic business because it very much depends on the context.

00:13:31.520 --> 00:13:41.220
And that's why the user, their use case matters so much in how you design an app because it's one thing to just solve the same pricing problem twice, but the user experience might be vastly different.

00:13:41.220 --> 00:13:43.860
And that completely changes the front end that makes it a good product.

00:13:44.040 --> 00:13:54.980
Sure. And maybe whether or not it should be just a server-side Flask type of application, or maybe you need to bring in some funky JavaScript for interactivity once you pull down the data or something like that.

00:13:54.980 --> 00:14:05.500
One thing I did want to ask you about is how does hosting and deployment look relative to, like, for a data science web app rather than a standard web app?

00:14:05.500 --> 00:14:08.560
Like, I know in data science, there's lots of computation.

00:14:09.200 --> 00:14:15.160
There's often leveraging GPUs, but is that more done in the preparation phase?

00:14:15.160 --> 00:14:16.960
Like, do you train a model up or something?

00:14:16.960 --> 00:14:22.160
But then the actual execution of it, it doesn't need any special hardware in the deployment stage?

00:14:22.160 --> 00:14:22.980
Or what does that look like?

00:14:22.980 --> 00:14:24.100
Great question. It depends.

00:14:24.100 --> 00:14:30.220
So, in some cases, you have a problem where the computational load can be done in advance.

00:14:30.400 --> 00:14:32.420
Great example is image classification.

00:14:32.420 --> 00:14:46.600
So, Google has trained a number of models that they open source for image classification, like the Inception series of models that you can go download and use them to classify things that they already out of the box know how to do, cats and dogs and things like this.

00:14:46.800 --> 00:14:58.160
And to get there, Google threw a whole bunch of compute at that, you know, tons of nodes, many GPUs, and it takes a long time to get that model weighted the way it is, get it trained to where it is.

00:14:58.160 --> 00:15:05.160
But from that point, another data scientist could pick that up where it left off and basically finish out the rest of a model to repurpose it.

00:15:05.400 --> 00:15:11.600
So, in that case, the data scientist workload is mitigated because Google did some front-end work.

00:15:11.600 --> 00:15:24.680
But at the same time, you might take that final trained model that data scientist adds their specific use case to, and once that's trained, you might be able to just throw that into a Docker container and then make predictions with it very quickly, trivially quickly.

00:15:24.680 --> 00:15:26.640
It was the training that was the hard part.

00:15:26.640 --> 00:15:30.760
So, in this case, you would just Dockerize it and you can deploy the application as is.

00:15:31.140 --> 00:15:38.420
However, there are other cases where the actual computation you need to do in the web server is where the complexity is.

00:15:38.420 --> 00:15:48.860
So, for example, I have some apps I've built where they're built around optimizations where you have lots of free variables and the problem that you're solving is completely dependent on the state of the app.

00:15:48.860 --> 00:15:50.560
You have to do that on the fly.

00:15:50.560 --> 00:16:04.540
And so, your Python server, your Flask app is now either doing that computation directly or offloading it to some other server via something like a task manager with Celery or some other serverless hook that you've put together, microservice architecture, whatever you're using.

00:16:04.540 --> 00:16:06.060
There's many different ways to do it.

00:16:06.060 --> 00:16:06.520
Yeah, yeah.

00:16:06.520 --> 00:16:07.780
That definitely makes a lot of sense.

00:16:07.780 --> 00:16:10.120
So, I guess depends is the answer, right?

00:16:10.120 --> 00:16:10.480
Yeah.

00:16:10.480 --> 00:16:11.300
It depends.

00:16:11.300 --> 00:16:12.240
Very interesting.

00:16:12.240 --> 00:16:15.580
How does serverless fit into the world here?

00:16:16.000 --> 00:16:18.420
I know serverless is good for async stuff, right?

00:16:18.420 --> 00:16:19.280
Like, I want to send an email.

00:16:19.280 --> 00:16:20.940
Like, nobody needs to wait in that.

00:16:20.940 --> 00:16:24.700
I can shoot off something to say AWS Lambda or Azure Functions and just have it go.

00:16:24.700 --> 00:16:26.880
How does that work in your world?

00:16:26.880 --> 00:16:29.760
Personally, serverless doesn't affect me too much.

00:16:29.760 --> 00:16:33.860
First off, the name serverless, I don't really understand because there's always a server there.

00:16:33.860 --> 00:16:38.800
It just means serverless in the sense that you don't have to manage partitioning and setting that up.

00:16:39.320 --> 00:16:44.380
And so, it's a valuable thing, especially if you're more of building like a front-end only type app.

00:16:44.380 --> 00:16:47.540
You know, if you want to use a Firebase or something, that kind of model.

00:16:47.540 --> 00:16:51.700
In my case, I came from more of a back-end development side first.

00:16:51.700 --> 00:16:55.080
And so, I've never had an issue with creating those endpoints myself.

00:16:55.080 --> 00:16:58.260
And so, I tend to have not needed the serverless model.

00:16:58.260 --> 00:17:00.140
It's not to say it's not good and useful.

00:17:00.140 --> 00:17:01.900
It just hasn't affected me very much ever.

00:17:01.900 --> 00:17:02.840
Yeah, it's interesting.

00:17:02.840 --> 00:17:05.120
The way I kind of see it the same way as well.

00:17:05.120 --> 00:17:08.500
And I think it's because I came from the back-end development side first, possibly.

00:17:08.800 --> 00:17:12.540
So, to me, I think there's a lot of value in serverless.

00:17:12.540 --> 00:17:14.720
It makes a lot of sense some of the time.

00:17:14.720 --> 00:17:26.120
But my perception, speaking only for me, if I'm going to build something for me, is I am trading code complexity, an application that has multiple things, all of it going on.

00:17:26.120 --> 00:17:26.940
It's got to keep running.

00:17:27.500 --> 00:17:32.280
I'm trading that code complexity for infrastructure complexity, right?

00:17:32.340 --> 00:17:39.520
I might now have 30 Lambda functions that all have to be versioned and migrated and kept in sync.

00:17:39.600 --> 00:17:41.560
But they're all separate things up in the cloud.

00:17:41.560 --> 00:17:43.340
And I have to deal with that somehow.

00:17:43.340 --> 00:17:45.000
And how do I keep them all running?

00:17:45.000 --> 00:17:49.040
And so, I always feel like I'm trading code complexity for infrastructure complexity.

00:17:49.040 --> 00:17:51.720
And I feel like I'm better at code than I am at infrastructure.

00:17:51.720 --> 00:17:54.500
So, I lean towards not going that way.

00:17:54.500 --> 00:17:56.200
Same thing with microservices, right?

00:17:56.200 --> 00:18:01.940
I just feel like I'm better at managing code complexity than DevOps-y infrastructure complexity.

00:18:01.940 --> 00:18:03.700
So, let me play to that, you know?

00:18:05.820 --> 00:18:08.820
This portion of Talk Python to me is brought to you by Linode.

00:18:08.820 --> 00:18:12.540
Are you looking for hosting that's fast, simple, and incredibly affordable?

00:18:12.540 --> 00:18:17.660
Well, look past that bookstore and check out Linode at talkpython.fm/Linode.

00:18:17.660 --> 00:18:19.540
That's L-I-N-O-D-E.

00:18:19.540 --> 00:18:23.960
Plans start at just $5 a month for a dedicated server with a gig of RAM.

00:18:23.960 --> 00:18:26.180
They have 10 data centers across the globe.

00:18:26.180 --> 00:18:30.000
So, no matter where you are or where your users are, there's a data center for you.

00:18:30.000 --> 00:18:34.500
Whether you want to run a Python web app, host a private Git server, or just a file server,

00:18:34.720 --> 00:18:40.840
you'll get native SSDs on all the machines, a newly upgraded 200 gigabit network, 24-7

00:18:40.840 --> 00:18:44.420
friendly support, even on holidays, and a seven-day money-back guarantee.

00:18:44.420 --> 00:18:46.040
Need a little help with your infrastructure?

00:18:46.040 --> 00:18:50.780
They even offer professional services to help you with architecture, migrations, and more.

00:18:50.780 --> 00:18:53.720
Do you want a dedicated server for free for the next four months?

00:18:53.720 --> 00:18:56.800
Just visit talkpython.fm/Linode.

00:18:56.800 --> 00:18:59.660
Totally get it.

00:18:59.660 --> 00:19:03.080
I think Docker is really the game changer there because nowadays,

00:19:03.080 --> 00:19:07.840
if you can throw it into a Docker container, there are services like Google App Engine

00:19:07.840 --> 00:19:12.040
or AWS Elastic Beanstalk where it can sort of transparently scale up and down.

00:19:12.040 --> 00:19:15.660
And yes, of course, there's differences between Lambda and those services.

00:19:15.660 --> 00:19:21.140
But at least as far as I have found, you can get pretty far just by having Docker

00:19:21.140 --> 00:19:24.740
and using whatever managed service on top of that to handle your kind of auto scaling.

00:19:24.740 --> 00:19:25.260
Yeah, that's cool.

00:19:25.260 --> 00:19:28.880
Docker is nice because you can do basically anything that Linux can do.

00:19:28.880 --> 00:19:29.460
Right.

00:19:29.560 --> 00:19:31.180
You don't have the restrictions like...

00:19:31.180 --> 00:19:31.880
Yes, which makes me happy.

00:19:31.880 --> 00:19:36.740
Yes, it has to run within 30 seconds or 10 seconds or whatever it does for service.

00:19:36.740 --> 00:19:39.700
And you can only do work with these dependent...

00:19:39.700 --> 00:19:40.960
Like you can do whatever you want, right?

00:19:40.960 --> 00:19:43.040
You need to install some like C library.

00:19:43.040 --> 00:19:43.800
It doesn't matter.

00:19:43.800 --> 00:19:44.380
Absolutely.

00:19:44.380 --> 00:19:46.300
Do you use Docker much for your work?

00:19:46.300 --> 00:19:46.660
Yes.

00:19:46.660 --> 00:19:47.140
Oh, yeah.

00:19:47.140 --> 00:19:51.240
Both myself and my team, we Dockerize anything that we can Dockerize pretty much.

00:19:51.240 --> 00:19:52.600
It just makes life so much easier.

00:19:52.600 --> 00:19:54.260
It's easier deployments.

00:19:54.380 --> 00:19:59.100
It's easier going from a VM to something like App Engine if you're on Google Cloud or whatever

00:19:59.100 --> 00:19:59.960
your service is.

00:19:59.960 --> 00:20:03.940
The installations, especially with some of the data science libraries that we're using,

00:20:03.940 --> 00:20:10.120
for example, CVXPy is an optimization framework, and it has some potential gotchas with compiling

00:20:10.120 --> 00:20:10.340
it.

00:20:10.340 --> 00:20:12.380
Putting that in a Docker container solves that problem.

00:20:12.380 --> 00:20:16.800
I don't have to worry about some obscure GCC version on the Linux box I'm deploying to

00:20:16.800 --> 00:20:19.480
or my Jenkins server if I just have it in Docker.

00:20:19.480 --> 00:20:20.480
So I'm a huge fan.

00:20:20.480 --> 00:20:23.680
Yeah, you get it working once and then you just never have to touch it again.

00:20:24.000 --> 00:20:26.360
You containerize it and you just say, I depend on that.

00:20:26.360 --> 00:20:27.180
That works.

00:20:27.180 --> 00:20:29.660
And your team can have one guy who's good at it.

00:20:29.660 --> 00:20:33.140
You know, everybody doesn't have to learn it because it's a super copy-pastable kind of

00:20:33.140 --> 00:20:33.400
thing.

00:20:33.400 --> 00:20:34.200
Yeah, yeah, absolutely.

00:20:34.200 --> 00:20:39.500
What I found interesting about Docker was as I learned to create the Docker files and

00:20:39.500 --> 00:20:44.560
build the images and containers and whatnot, it's like, well, what you really need to know

00:20:44.560 --> 00:20:46.080
is Linux, right?

00:20:46.080 --> 00:20:49.000
Here's a bunch of commands that you're issuing to configure Linux.

00:20:49.000 --> 00:20:55.220
It just happens to be you issue them in a Docker file format rather than on the terminal

00:20:55.220 --> 00:20:56.180
association.

00:20:56.180 --> 00:20:59.420
But it's basically like the complexity is not Docker.

00:20:59.420 --> 00:21:01.360
The complexity is Linux.

00:21:01.360 --> 00:21:04.860
And if you're comfortable with that, then Docker is actually a small step.

00:21:04.860 --> 00:21:05.560
Yeah, exactly.

00:21:05.780 --> 00:21:10.940
So do you use something like Swarm or Docker Compose or Kubernetes on top of that?

00:21:10.940 --> 00:21:15.300
Yeah, so generally for those kinds of things, we're either going to be using Kubernetes,

00:21:15.300 --> 00:21:20.220
but a lot of times we'll just operate within App Engine just because it's so simple.

00:21:20.220 --> 00:21:25.160
If you get your Flask app, whether it's a single application or whether you've got a front and

00:21:25.160 --> 00:21:29.740
back end separately, you Dockerize it, you can push it to App Engine, and then it will deal

00:21:29.740 --> 00:21:32.740
with scaling it up, down, making sure it stays up.

00:21:32.740 --> 00:21:37.100
And then you can also add rules on top of it, like for static files that they'll map to some

00:21:37.100 --> 00:21:39.600
internal Nginx configuration you never have to deal with.

00:21:39.980 --> 00:21:40.740
That works pretty well.

00:21:40.740 --> 00:21:44.900
But Kubernetes, if it needs to be a full cluster or integrated microservices, for sure.

00:21:44.900 --> 00:21:45.200
Yeah, yeah.

00:21:45.200 --> 00:21:46.600
Like they've got to talk to each other.

00:21:46.600 --> 00:21:48.740
That's where it gets complex with Docker.

00:21:48.740 --> 00:21:49.360
All right.

00:21:49.360 --> 00:21:50.100
Thanks for the diversion.

00:21:50.100 --> 00:21:50.340
Yes.

00:21:50.340 --> 00:21:50.860
That was interesting.

00:21:50.860 --> 00:21:56.340
So if I'm building a data science web app, I would say, you know, if you went out to the

00:21:56.340 --> 00:22:00.280
street and just started interviewing random people where all these people were knowledgeable

00:22:00.280 --> 00:22:03.080
about data science, they would probably say like, well...

00:22:03.080 --> 00:22:03.680
I want to live there.

00:22:03.680 --> 00:22:05.560
Yeah, for sure.

00:22:05.560 --> 00:22:09.940
So probably the first thought or the most popular answer of like, how do I take my

00:22:09.940 --> 00:22:11.700
data science stuff and present it on the web?

00:22:11.700 --> 00:22:12.740
It would be Jupyter Notebooks.

00:22:12.740 --> 00:22:13.580
What do you think?

00:22:13.580 --> 00:22:13.860
Yes.

00:22:13.860 --> 00:22:16.160
I have such a love-hate relationship with Jupyter.

00:22:16.160 --> 00:22:20.860
And I think other data scientists and my team would hate me for saying this, but Jupyter

00:22:20.860 --> 00:22:22.720
Notebooks just cause a lot of problems.

00:22:22.720 --> 00:22:29.040
They are super great for interactive data science, exploratory analysis, initial data cleansing

00:22:29.040 --> 00:22:29.420
and whatnot.

00:22:29.420 --> 00:22:30.100
They're great.

00:22:30.100 --> 00:22:36.500
But for anything you need to pipeline, productionalize or make repeatable, the native Jupyter Notebook

00:22:36.500 --> 00:22:38.640
space just doesn't really work very well.

00:22:38.640 --> 00:22:39.880
I mean, how many...

00:22:39.880 --> 00:22:43.740
I guarantee you, if you're listening to this and you have shared a Jupyter Notebook with

00:22:43.740 --> 00:22:47.920
a team before, you've gotten one back at some point that you ran and it immediately errors

00:22:47.920 --> 00:22:49.940
out because you don't have some file or whatever.

00:22:49.940 --> 00:22:53.000
Just make sure your Jupyter Notebook runs start to finish.

00:22:53.000 --> 00:22:55.240
So yeah, you're right, Michael.

00:22:55.240 --> 00:22:57.840
Jupyter Notebooks and apps are very different.

00:22:57.840 --> 00:23:02.040
And how you kind of connect those thoughts to production is not trivial.

00:23:02.340 --> 00:23:08.000
Yeah, it took me a while to appreciate Jupyter Notebooks and just the whole notebook style

00:23:08.000 --> 00:23:08.580
of programming.

00:23:08.580 --> 00:23:15.820
Because to me, coming from a more app building type of software development, like I was all

00:23:15.820 --> 00:23:21.340
about having different files for the different purposes and like factoring an app.

00:23:21.340 --> 00:23:25.420
So like the data access stuff is over here and then I can test this part and I put them

00:23:25.420 --> 00:23:27.280
together and then here's the app.

00:23:27.540 --> 00:23:30.300
And when I looked at Jupyter, I'm like, all that stuff is missing.

00:23:30.300 --> 00:23:33.480
I mean, even to some degree, like a lot of times, even functions are missing.

00:23:33.480 --> 00:23:38.000
And that like kind of made me a little, gave me the willies a little bit.

00:23:38.000 --> 00:23:39.280
But then, you know, I saw people...

00:23:39.280 --> 00:23:40.400
Yeah, how do I modularize?

00:23:40.400 --> 00:23:41.380
Exactly, right?

00:23:41.380 --> 00:23:43.360
Like how do I, how is this maintainable, right?

00:23:43.360 --> 00:23:44.380
So...

00:23:44.380 --> 00:23:45.240
Unit test it, yeah.

00:23:45.240 --> 00:23:45.860
Yeah, exactly.

00:23:45.860 --> 00:23:49.440
So, but then I saw people working with it and I'm like, they're just working differently.

00:23:49.440 --> 00:23:53.000
They're solving different problems than the problem I'm trying to solve.

00:23:53.840 --> 00:23:57.160
And the notebook space makes more sense for them.

00:23:57.160 --> 00:24:02.180
But to be able to push it actually into full production, I don't know, it's, it doesn't

00:24:02.180 --> 00:24:04.440
seem like really necessarily the right answer.

00:24:04.440 --> 00:24:12.400
There are some projects trying to leverage notebooks for production that are pretty interesting.

00:24:12.400 --> 00:24:16.840
I want to ask you if you had any experience with them, not saying that I would recommend

00:24:16.840 --> 00:24:18.980
like ditching flasks to use them, but they are interesting.

00:24:18.980 --> 00:24:20.980
Things like Paper Mill, have you seen that?

00:24:20.980 --> 00:24:25.960
Yes, I think Paper Mill is exactly the kind of solution to the problems because it kind

00:24:25.960 --> 00:24:27.180
of hammered on Jupyter Notebooks.

00:24:27.180 --> 00:24:28.480
I'm actually a big fan of them.

00:24:28.480 --> 00:24:30.160
It's just that it can be misused.

00:24:30.160 --> 00:24:35.620
And what Paper Mill does is it provides you a way to parameterize your notebook and then

00:24:35.620 --> 00:24:38.040
execute them in a more programmatic way.

00:24:38.040 --> 00:24:43.000
And if nothing else, this forces the developer of the Jupyter Notebook to kind of think about

00:24:43.000 --> 00:24:45.900
abstracting parameters out where it makes sense.

00:24:45.900 --> 00:24:46.200
Right.

00:24:46.200 --> 00:24:47.020
What are the inputs?

00:24:47.020 --> 00:24:47.720
What are the outputs?

00:24:47.720 --> 00:24:51.500
And it makes it a lot easier to productionalize these things.

00:24:51.500 --> 00:24:51.920
Yeah.

00:24:51.920 --> 00:24:57.100
There's an interesting article I'll link to from Netflix, how they're using Paper Mill to

00:24:57.100 --> 00:25:03.220
sort of productionalize their Jupyter stuff and do a lot of data science still with the notebooks.

00:25:03.220 --> 00:25:07.280
But yeah, I would say like, if you really want to put something online and really make it

00:25:07.280 --> 00:25:08.540
accessible, right?

00:25:08.540 --> 00:25:14.480
You need an API or at least a website is probably the final end game.

00:25:14.480 --> 00:25:15.180
What do you think?

00:25:15.180 --> 00:25:15.480
Yeah.

00:25:15.480 --> 00:25:20.600
But I think that, I mean, whether or not it's Paper Mill, I think some kind of integrated tooling

00:25:20.600 --> 00:25:21.760
is going to be the solution.

00:25:21.760 --> 00:25:26.540
Whether it's something that makes it easy to go back and forth between notebooks and Python

00:25:26.540 --> 00:25:28.980
files or whether it's a Paper Mill or something like that.

00:25:29.280 --> 00:25:34.940
I think that where that will take you is a place where it's simpler to move from the data science

00:25:34.940 --> 00:25:38.580
that you're doing in the notebook to production, because we also can't just say, oh, well,

00:25:38.580 --> 00:25:42.940
you do your exploratory analysis in a Jupyter notebook and then we productionalize it,

00:25:42.940 --> 00:25:44.280
which is a whole scratch rewrite.

00:25:44.280 --> 00:25:45.880
Like that's a huge waste of time.

00:25:45.880 --> 00:25:52.120
And so you have to sort of trade off how painful is it to refactor this versus how easy is it to

00:25:52.120 --> 00:25:55.240
just kind of build a tool that can make those dots connected for you.

00:25:55.400 --> 00:25:59.440
I think eventually we'll land on something that's kind of an integrated workflow and that's

00:25:59.440 --> 00:26:02.980
going to get picked up very quickly because of how beneficial that time save is.

00:26:02.980 --> 00:26:03.200
Yeah.

00:26:03.200 --> 00:26:04.480
It's going to be pretty interesting.

00:26:04.480 --> 00:26:11.020
Now, I do think one of the challenges that people run into in the data science space is

00:26:11.020 --> 00:26:15.540
incredible growth of Python really does have a lot to do with data science.

00:26:15.540 --> 00:26:22.140
And I think that's because Python itself appeals a lot to people who are not necessarily programmers

00:26:22.140 --> 00:26:26.280
first, but they use programming to do something else amazing, right?

00:26:26.280 --> 00:26:29.960
Like a biologist or a physicist or a statistician or something.

00:26:29.960 --> 00:26:38.860
But it also means like a lot of folks come without necessarily a rigorous software engineering

00:26:38.860 --> 00:26:39.440
background.

00:26:39.440 --> 00:26:41.640
That's not a dig against them or anything negative.

00:26:41.640 --> 00:26:44.020
It just happens to be like we all come from different perspectives.

00:26:44.020 --> 00:26:48.480
But I do feel like there's probably a lot of teams and folks I talk to, it seems like

00:26:48.480 --> 00:26:57.580
they could use a little bit of help or some pointers on taking things like testing and maintainability

00:26:57.580 --> 00:26:58.260
and factoring.

00:26:58.260 --> 00:27:03.640
And you talked about continuous integration and whatnot and all that into their workflow.

00:27:03.640 --> 00:27:08.140
What are some of the software engineering techniques you think data scientists should pay attention

00:27:08.140 --> 00:27:08.400
to?

00:27:08.480 --> 00:27:09.860
Number one is testing.

00:27:09.860 --> 00:27:12.660
Why do we care about unit testing?

00:27:12.660 --> 00:27:19.180
And I like to tell people that testing is actually important mostly for refactoring purposes.

00:27:19.180 --> 00:27:23.880
It's actually a side effect of writing tests that you verify that your code works.

00:27:23.880 --> 00:27:28.620
So what I mean is that, you know, if I have my test built and I've got good coverage and I've

00:27:28.620 --> 00:27:33.400
got the little auto reloader over and every time I change something, hit control S to save it

00:27:33.400 --> 00:27:37.960
and I get those little dots, I can be extremely aggressive with coming in and just gutting

00:27:37.960 --> 00:27:42.300
whole parts of the app and changing them around because I know I'm backed by those tests.

00:27:42.300 --> 00:27:47.860
And I can't tell you how many times I have done a refactor that would either have taken a long

00:27:47.860 --> 00:27:52.320
time to piece by piece change it and make sure nothing broke or simply would have just not done

00:27:52.320 --> 00:27:55.340
because it was like, oh, I don't want to touch that because it's going to be super painful.

00:27:55.340 --> 00:27:56.980
So testing is one.

00:27:57.540 --> 00:28:01.560
And along with that comes sort of how you write code, because if you're writing code

00:28:01.560 --> 00:28:08.400
for tests, you will do things like lift variables up or abstract things out to be either a dependency

00:28:08.400 --> 00:28:09.680
injection type flow.

00:28:09.680 --> 00:28:10.020
Yeah.

00:28:10.020 --> 00:28:14.840
You'll think about small functions versus large functions because large ones are super hard

00:28:14.840 --> 00:28:15.400
to test.

00:28:15.400 --> 00:28:19.460
What you'll see, and this is not a knock on people who are not quote software engineers,

00:28:19.460 --> 00:28:23.520
but you get these big long functions and then somewhere embedded in the middle is like a

00:28:23.520 --> 00:28:27.360
hard coded call to some API and the endpoint and credentials are buried in there.

00:28:27.360 --> 00:28:28.520
And maybe in source control.

00:28:28.520 --> 00:28:32.620
And it just becomes very difficult when you want to come in and change something, which

00:28:32.620 --> 00:28:35.120
inevitably, you know, your client wants you to do.

00:28:35.120 --> 00:28:37.580
And you come in there and you're like, oh man, this is such a mess.

00:28:37.580 --> 00:28:39.400
It's going to take me a while to dig myself out.

00:28:39.400 --> 00:28:43.000
Whereas if you take a little bit more time to set yourself up from the beginning, it just

00:28:43.000 --> 00:28:44.240
flows way faster.

00:28:44.240 --> 00:28:45.040
Yeah, for sure.

00:28:45.040 --> 00:28:49.900
So if I had to pick one or two, it's those, but I could go on and on about design patterns

00:28:49.900 --> 00:28:51.380
and whatnot, but I'll cut it there.

00:28:51.380 --> 00:28:53.060
Yeah, no, that's good advice.

00:28:53.060 --> 00:28:56.860
The one I see also often missing is like proper source control.

00:28:57.180 --> 00:28:58.800
Maybe, I don't know.

00:28:58.800 --> 00:29:00.700
It depends on the team, right?

00:29:00.700 --> 00:29:05.060
But if they're like mostly scientists who are started, you know, like leaving MATLAB and

00:29:05.060 --> 00:29:08.840
going into say Jupyter and Python, like source control.

00:29:08.840 --> 00:29:10.040
That's actually a good point.

00:29:10.040 --> 00:29:16.060
And I almost feel like source control gets overlooked as being just assumed that you know it, but

00:29:16.060 --> 00:29:16.600
very interesting.

00:29:16.600 --> 00:29:20.640
Most people coming fresh out of school, you know, they've only seen a limited amount of

00:29:20.640 --> 00:29:22.960
exposure to it, but you're completely right.

00:29:23.060 --> 00:29:24.220
It's a huge part of it.

00:29:24.220 --> 00:29:27.320
I actually am extremely interested in Git as a separate aside.

00:29:27.320 --> 00:29:30.460
You know, I kind of, our Slack channel, we have run a Git tip of the day.

00:29:30.460 --> 00:29:32.540
So you can look at some of the blogs that we'll link.

00:29:32.540 --> 00:29:35.900
We've actually published a couple of those just to kind of as a way of keeping everybody's

00:29:35.900 --> 00:29:37.420
brains fresh on source control.

00:29:37.420 --> 00:29:40.100
Or how do I revert this branch in a particular way?

00:29:40.100 --> 00:29:41.800
Or what is Git ref log?

00:29:41.800 --> 00:29:43.220
And so I completely agree.

00:29:43.220 --> 00:29:46.120
If you're fluid in source control, it's also a big time saver.

00:29:46.300 --> 00:29:46.380
Yeah.

00:29:46.380 --> 00:29:50.180
Well, I mean, all these things go, like everything we're touching on goes really well together.

00:29:50.180 --> 00:29:56.040
Testing so that I can change my code, writing code that is testable and easy to maintain

00:29:56.040 --> 00:29:57.660
so I can have these tests.

00:29:57.660 --> 00:30:02.100
And then having source control so that I can, you know, like commit it and tag it and then

00:30:02.100 --> 00:30:03.240
go crazy and go, you know what?

00:30:03.240 --> 00:30:04.640
It was a horrible idea.

00:30:04.640 --> 00:30:09.240
We're either dropping this branch or we're rolling it back and we're going to skip over

00:30:09.240 --> 00:30:10.700
this bit or whatever, right?

00:30:10.700 --> 00:30:15.060
Like even if you forgot to branch, you can still go back to your last commit or a couple

00:30:15.060 --> 00:30:15.720
commits back.

00:30:15.720 --> 00:30:16.260
Yeah.

00:30:16.260 --> 00:30:19.280
They all kind of hit at the same core essence.

00:30:19.280 --> 00:30:19.640
Yeah.

00:30:19.640 --> 00:30:21.900
And then you add your CICD on top of that.

00:30:21.900 --> 00:30:22.680
And now you've got it.

00:30:22.680 --> 00:30:27.840
So when every time I push changes or whatever circle or Travis or Jenkins grabs it, builds

00:30:27.840 --> 00:30:28.660
it, pushes it out.

00:30:28.660 --> 00:30:31.960
And I can be deploying five, 10 times, a hundred times a day.

00:30:31.960 --> 00:30:33.240
Model works extremely well.

00:30:33.240 --> 00:30:35.760
You catch bugs more quickly and you're not afraid to change stuff.

00:30:35.760 --> 00:30:36.480
Yeah, for sure.

00:30:36.480 --> 00:30:37.060
Cool.

00:30:37.060 --> 00:30:37.980
That's good advice.

00:30:38.520 --> 00:30:42.880
So when we're building these apps, I have a pretty good sense for when it makes sense

00:30:42.880 --> 00:30:48.400
to have, say, one of these JavaScript rich web apps.

00:30:48.400 --> 00:30:56.640
I'm thinking of AngularJS, React, VueJS, something where like a lot of the application logic is actually

00:30:56.640 --> 00:30:57.380
written in JavaScript.

00:30:57.380 --> 00:31:02.880
And then there's a bunch of services probably written in Python that you're talking to behind

00:31:02.880 --> 00:31:04.920
the scenes, like we were talking about with Flask.

00:31:05.120 --> 00:31:11.620
I have a good sense for when that maybe makes sense versus when a more server-side backed

00:31:11.620 --> 00:31:14.820
framework, Flask, Pyramid, Django, something like that.

00:31:14.820 --> 00:31:18.800
You can just stick with that and not add that extra complexity.

00:31:18.800 --> 00:31:23.820
I always feel like there's a little bit of glitchiness in the front-end apps somewhere and

00:31:23.820 --> 00:31:25.640
some setup with some plugin or whatever.

00:31:26.300 --> 00:31:31.700
But I do feel like there's actually a tendency for people to assume they need more JavaScript

00:31:31.700 --> 00:31:32.780
than they actually need.

00:31:32.780 --> 00:31:35.700
And they need these front-end frameworks more than they actually need.

00:31:35.700 --> 00:31:38.920
Like you can go a long way with the server-side framework, but there are times.

00:31:38.920 --> 00:31:43.300
So maybe what are your thoughts in the data science web space around that?

00:31:43.300 --> 00:31:44.160
It's a good question.

00:31:44.160 --> 00:31:45.360
We do both.

00:31:45.360 --> 00:31:49.300
There's a time and a place for both kind of the single Flask app that does both the front

00:31:49.300 --> 00:31:49.900
and the back end.

00:31:49.980 --> 00:31:53.700
And then when you need to bring JavaScript in, the biggest thing that JavaScript gives

00:31:53.700 --> 00:31:57.160
you, and it's the whole magic of the web really, is the interactivity.

00:31:57.160 --> 00:32:03.040
So if you've got, from a data science perspective, some kind of application that's maybe kind of

00:32:03.040 --> 00:32:06.760
like a dashboard where you've got a number of visualization widgets and maybe you change

00:32:06.760 --> 00:32:10.120
something and it re-aggregates data and it's responsive.

00:32:10.360 --> 00:32:16.060
That kind of thing really sings as a JavaScript app, whether it's React, Angular, whatever you,

00:32:16.060 --> 00:32:17.460
jQuery, whatever you use.

00:32:17.460 --> 00:32:23.600
When it's more of sort of static content, you know, a blog or a report or some kind of anything

00:32:23.600 --> 00:32:25.780
even that could be served with just a SQL query.

00:32:25.780 --> 00:32:26.060
Right.

00:32:26.060 --> 00:32:28.940
Even if it's data-driven, it's like not static per se.

00:32:28.940 --> 00:32:34.300
But once it hits the page, you don't need it to be interactively changing unless you like

00:32:34.300 --> 00:32:35.440
open another page, right?

00:32:35.440 --> 00:32:38.960
Like here's a list of things and I click on the book and I have the book details, right?

00:32:38.960 --> 00:32:40.920
Like all that doesn't need any JavaScript, probably.

00:32:40.920 --> 00:32:41.160
Yeah.

00:32:41.160 --> 00:32:46.280
And since sometimes those lines get blurred because what happens if that SQL query is either

00:32:46.280 --> 00:32:51.300
really complicated or it returns a huge number of rows, I still kind of want to interact with

00:32:51.300 --> 00:32:51.920
on the front end.

00:32:51.920 --> 00:32:53.480
Maybe I want to paginate it.

00:32:53.480 --> 00:32:53.720
Right.

00:32:53.720 --> 00:32:54.060
Filter it or something.

00:32:54.060 --> 00:32:54.260
Yeah.

00:32:54.260 --> 00:32:56.840
Going back to the server, I'd have to run that huge heavy query.

00:32:56.840 --> 00:32:57.920
Well, that's not great.

00:32:57.920 --> 00:33:01.340
But if I also have to fit a bunch of data into the browser, that might not work.

00:33:01.340 --> 00:33:04.280
So where do I put that pagination is now not always trivial.

00:33:04.280 --> 00:33:08.880
And so those kinds of things tip the decision, whether you want to go JS or pure Python.

00:33:08.880 --> 00:33:11.840
Well, yeah, probably also heavily depends on your team, right?

00:33:11.840 --> 00:33:15.420
If you have a bunch of people and they just love Python and they don't want to touch JavaScript,

00:33:15.420 --> 00:33:20.200
like saying, you know, it's probably better if we do this in JavaScript and we just force

00:33:20.200 --> 00:33:21.600
everyone to now do JavaScript.

00:33:21.600 --> 00:33:26.100
Like that might not actually be better given the people working on it, right?

00:33:26.100 --> 00:33:30.840
Like it's, I think the team's desires and capabilities also should be considered, right?

00:33:31.000 --> 00:33:31.160
Yeah.

00:33:31.160 --> 00:33:34.900
Because data scientists typically don't know JavaScript, right?

00:33:34.900 --> 00:33:39.720
They know Python and depending on their background, they might have some exposure to HTML, CSS,

00:33:39.720 --> 00:33:41.740
but you can't really depend on it.

00:33:41.740 --> 00:33:44.380
You can depend on Python or R and hopefully SQL.

00:33:44.380 --> 00:33:48.560
So sometimes it's just the nature of who's going to be working on this project.

00:33:48.560 --> 00:33:50.400
They might choose the technology that fits.

00:33:50.400 --> 00:33:52.720
So it might be, this is Python only because I'm really good with Jinja.

00:33:52.720 --> 00:33:54.040
So I'm going to use those.

00:33:54.080 --> 00:33:57.560
And it might be that we've got dedicated front end engineers who are really good with JS and

00:33:57.560 --> 00:34:00.880
we put them on those heavier interactivity type projects.

00:34:00.880 --> 00:34:04.300
And so it's, it's, it's also very much about sort of where your team's at.

00:34:04.300 --> 00:34:05.620
We're, we're a small team.

00:34:05.620 --> 00:34:07.420
And so you kind of play to your strengths.

00:34:07.420 --> 00:34:08.880
Yeah, that's definitely a good idea.

00:34:08.880 --> 00:34:15.780
One of the ways you can add interaction to these apps and not go and write all that stuff

00:34:15.780 --> 00:34:23.440
in D3 or HTML5 Canvas and JavaScript, God forbid, is to use something like Bokeh or Plotly

00:34:23.440 --> 00:34:25.340
or some of these other interactive stuff.

00:34:25.340 --> 00:34:30.840
There's like things you can add to your site as well that may get you close enough for this

00:34:30.840 --> 00:34:31.400
exploration.

00:34:31.400 --> 00:34:32.280
What do you think?

00:34:32.280 --> 00:34:37.220
This stuff is magical because it unlocks that interactivity that I was saying is so good about

00:34:37.220 --> 00:34:39.360
the web to people who don't know JavaScript.

00:34:39.360 --> 00:34:41.120
So Bokeh is a great example.

00:34:41.120 --> 00:34:43.940
Plotly is also a one that I'm a big fan of.

00:34:43.940 --> 00:34:48.980
Plotly is nice because the charts that you create in Python are serializable to JSON.

00:34:48.980 --> 00:34:51.940
That's actually how it renders it into JavaScript eventually.

00:34:52.400 --> 00:34:57.120
But if you interact with Plotly within JavaScript itself, it's the same data structure.

00:34:57.120 --> 00:35:01.980
And so it plays very nicely when we have pure web devs and pure data scientists that they

00:35:01.980 --> 00:35:03.640
can both interact with the same objects.

00:35:03.640 --> 00:35:05.200
So I'm a big fan of Plotly.

00:35:05.200 --> 00:35:07.360
There's also a cool project called Dash.

00:35:07.360 --> 00:35:09.520
That's part of the Plotly umbrella.

00:35:09.520 --> 00:35:10.740
I don't know how you'd call it that.

00:35:10.740 --> 00:35:16.520
That is a declarative way to create dashboards and visualizations that actually renders into

00:35:16.520 --> 00:35:17.240
a React app.

00:35:17.240 --> 00:35:19.220
So the internals are pretty cool.

00:35:19.300 --> 00:35:23.200
You create this layout, serializes it, and there's a React app that generates that into

00:35:23.200 --> 00:35:23.540
charts.

00:35:23.540 --> 00:35:26.220
So that's another cool way to unlock sort of interactivity.

00:35:26.220 --> 00:35:27.740
You can hook up widgets and whatnot.

00:35:27.740 --> 00:35:31.660
So those kind of ecosystems and tools, I see more and more of that.

00:35:31.660 --> 00:35:35.340
I think it's a great place to go again because it just enables people.

00:35:35.340 --> 00:35:36.060
Yeah, for sure.

00:35:36.060 --> 00:35:39.860
I think that's one of the things that you learn as you progress in software development

00:35:39.860 --> 00:35:44.620
is we probably all had the experience of, I had this problem.

00:35:44.620 --> 00:35:46.460
I wrote all this code to solve it.

00:35:46.460 --> 00:35:49.780
And then I realized there was a library that would solve it in two lines.

00:35:49.780 --> 00:35:51.220
And it took me a week to solve it.

00:35:51.220 --> 00:35:53.860
Like there's all these things you can find and add in.

00:35:53.860 --> 00:35:59.980
I guess the challenge there is knowing when adding in something like that will get you 80%

00:35:59.980 --> 00:36:02.800
of the way there and there'd be a complete pain trying to finish it.

00:36:02.980 --> 00:36:05.100
Or is it going to be good enough and you'll be happy with it?

00:36:05.100 --> 00:36:07.200
You know, like that's a real challenge, I think.

00:36:07.200 --> 00:36:12.800
But a lot of these data science visualization tools you can drop into your website do seem

00:36:12.800 --> 00:36:13.300
really nice.

00:36:13.300 --> 00:36:18.840
Yeah, that's honestly one of the biggest things I think that makes experience matter is knowing

00:36:18.840 --> 00:36:20.720
when do I look for another tool?

00:36:20.720 --> 00:36:22.480
When should I pay for something?

00:36:22.480 --> 00:36:24.360
When do I roll my own?

00:36:24.360 --> 00:36:25.820
Or when do we go with the 80-20?

00:36:25.820 --> 00:36:29.960
And you can over-architect things to the point where nothing gets done.

00:36:30.120 --> 00:36:33.860
And then on the flip side, you can create this spaghetti monster mess that's completely

00:36:33.860 --> 00:36:34.580
unmaintainable.

00:36:34.580 --> 00:36:38.740
And I think being pragmatic is the biggest thing you hope to get with experience.

00:36:38.740 --> 00:36:39.080
Yeah.

00:36:39.080 --> 00:36:43.820
And coming back to what you were touching on before, if it's testable, maintainable, and

00:36:43.820 --> 00:36:49.060
you can evolve it quickly, you can make one choice and then change your mind, right?

00:36:49.060 --> 00:36:50.620
Because it's easy to change.

00:36:50.620 --> 00:36:53.780
Because you have the test that'll tell you, no, it's not actually broken yet.

00:36:53.780 --> 00:36:54.720
And things like that, right?

00:36:54.720 --> 00:36:56.720
There's also that aspect of it, I think.

00:36:56.820 --> 00:36:59.080
Yeah, you're paying for technical debt, basically.

00:36:59.080 --> 00:37:02.060
And if you write unit tests and all these other things, you're getting rid of that.

00:37:02.060 --> 00:37:02.920
You catch up later.

00:37:05.080 --> 00:37:08.060
This portion of Talk Python to Me is brought to you by Rollbar.

00:37:08.060 --> 00:37:09.460
Got a question for you.

00:37:09.460 --> 00:37:12.180
Have you been outsourcing your bug discovery to your users?

00:37:12.180 --> 00:37:14.820
Have you been making them send you bug reports?

00:37:14.820 --> 00:37:16.520
You know there's two problems with that.

00:37:16.520 --> 00:37:18.480
You can't discover all the bugs this way.

00:37:18.480 --> 00:37:21.040
And some users don't bother reporting bugs at all.

00:37:21.040 --> 00:37:22.960
They just leave, sometimes forever.

00:37:22.960 --> 00:37:26.740
The best software teams practice proactive error monitoring.

00:37:27.040 --> 00:37:35.160
They detect all the errors in their production apps and services in real time and debug important errors in minutes or hours, sometimes before users even notice.

00:37:35.160 --> 00:37:40.240
Teams from companies like Twilio, Instacart, and CircleCI use Rollbar to do this.

00:37:40.240 --> 00:37:46.320
With Rollbar, you get a real-time feed of all the errors so you know exactly what's broken in production.

00:37:46.480 --> 00:37:53.520
And Rollbar automatically collects all the relevant data and metadata you need to debug the errors so you don't have to sift through logs.

00:37:53.520 --> 00:37:57.480
If you aren't using Rollbar yet, they have a special offer for you, and it's really awesome.

00:37:57.480 --> 00:38:01.980
Sign up and install Rollbar at talkpython.fm/Rollbar.

00:38:01.980 --> 00:38:06.540
And Rollbar will send you a $100 gift card to use at the Open Collective,

00:38:06.540 --> 00:38:14.000
where you can donate to any of the 900-plus projects listed under the Open Source Collective or to the Women Who Code organization.

00:38:14.120 --> 00:38:17.680
Get notified of errors in real time and make a difference in open source.

00:38:17.680 --> 00:38:20.560
Visit talkpython.fm/Rollbar today.

00:38:20.560 --> 00:38:29.580
You recently wrote an article called Flask Best Practices, Patterns for Building Testable, Scalable, and Maintainable APIs,

00:38:29.580 --> 00:38:37.000
really from the perspective that we're coming from here, from the data science side of things, but also the web developer side.

00:38:37.000 --> 00:38:38.640
So maybe we could touch on that a little bit.

00:38:38.640 --> 00:38:39.040
Sure.

00:38:39.440 --> 00:38:47.440
So the idea with that blog post was for structuring these kind of applications, you know, Flask is very unopinionated, which is great.

00:38:47.440 --> 00:38:54.760
You know, it's kind of like in the front end world, you have this sort of React versus Angular, and there's also Vue, but a lot of discussion between those two.

00:38:54.900 --> 00:39:00.060
And one of the biggest differences, React is very unopinionated and kind of call it plugin-based.

00:39:00.060 --> 00:39:06.060
And then Angular is full weight and sort of opinionated, but kind of has all the bells and whistles included.

00:39:06.520 --> 00:39:18.520
And in the Python world, Flask kind of fits that sort of plug-and-play type thing, where you have the freedom to make all of these decisions and do things the way you want, but you also have the burden to make all these decisions and do things the way you want.

00:39:18.520 --> 00:39:20.520
And so it can cut both ways.

00:39:20.520 --> 00:39:28.360
One of the things that's always bugged me about Flask is I felt like it was presented artificially simplistic.

00:39:28.360 --> 00:39:32.680
And what I mean by that is like, they always, Django is super complicated.

00:39:32.680 --> 00:39:35.320
And look at all the stuff you do for Pyramid with this cookie cutter thing.

00:39:35.320 --> 00:39:42.960
But what you get, you just, for Flask, you just create one file, app.py, you create the app, you put app.route, one function, boom, we're done.

00:39:43.160 --> 00:39:47.580
And that's true, it does say hello world on the screen, but like, that's not maintainable.

00:39:47.580 --> 00:39:48.800
That's not how real apps work.

00:39:48.800 --> 00:39:49.960
They get big and complicated.

00:39:49.960 --> 00:39:57.480
And like you were saying, there's just an absence of any guidance on the next step, right?

00:39:57.480 --> 00:40:00.560
How does that not become a 4,000 line app.py?

00:40:00.560 --> 00:40:01.700
Well, that's what happens.

00:40:01.700 --> 00:40:04.180
I mean, Armin Roneher is very humble.

00:40:04.180 --> 00:40:08.940
So he tends to give talks and basically downplay Flask and say, look how simple it is.

00:40:08.940 --> 00:40:11.220
But you can build big systems with it.

00:40:11.360 --> 00:40:13.880
You just have to make the right decisions.

00:40:13.880 --> 00:40:23.000
And because there's not a whole lot of direction out there, you do end up with these multi-thousand line monstrosities that, you know, you end up having to control F for whatever endpoint you're hitting.

00:40:23.000 --> 00:40:24.900
And it's very difficult to sort of grok.

00:40:24.900 --> 00:40:34.740
And yeah, so this blog post is basically, after having tried a lot of different things and having some sort of core philosophies like testing that I needed out of the end product.

00:40:34.860 --> 00:40:39.100
It was a pattern that I landed on that we tried for several months.

00:40:39.100 --> 00:40:40.620
And it really sung.

00:40:40.620 --> 00:40:41.600
I'm very happy with it.

00:40:41.600 --> 00:40:51.540
And so this blog post is basically kind of just sharing that experience because it was working within a team on a code base that was a mixture of Python, TypeScript, JS, all this kind of things.

00:40:51.580 --> 00:41:02.480
Yeah, so you basically talk about a set of tools, a way of organizing all the files that you actually have on real actual Flask apps, like data access layers and models and whatever, right?

00:41:02.480 --> 00:41:04.120
Test files and whatnot.

00:41:04.120 --> 00:41:05.740
The structure is really interesting.

00:41:05.740 --> 00:41:08.000
I think it's especially good for APIs.

00:41:08.420 --> 00:41:15.380
It's not the structure that I use for my website, but I do have a very structured way that like kind of has similar goals to what you have.

00:41:15.380 --> 00:41:19.820
So maybe we could just start first talking about this with some of the packages.

00:41:19.820 --> 00:41:21.760
So you have Flask, obviously.

00:41:21.760 --> 00:41:25.040
pytest is pretty de facto these days.

00:41:25.040 --> 00:41:29.920
SQLAlchemy, I think, is probably the most common ORM if you're going to talk to a relational database.

00:41:29.920 --> 00:41:30.880
What? There's another one?

00:41:30.880 --> 00:41:32.740
There are.

00:41:32.740 --> 00:41:36.180
You know, we got PeeWee ORM and some other interesting little ones.

00:41:36.180 --> 00:41:37.160
Oh, yeah, yeah, yeah.

00:41:37.160 --> 00:41:37.440
I know.

00:41:37.700 --> 00:41:38.120
Yeah, I know.

00:41:38.120 --> 00:41:40.120
But yeah, you have to choose, though, right?

00:41:40.120 --> 00:41:43.000
With Flask, you've got to go look them all up and decide, right?

00:41:43.000 --> 00:41:44.840
Django is just Django ORM or whatever.

00:41:44.840 --> 00:41:50.560
But then some other interesting ones, you have Flask REST+, which is interesting.

00:41:50.560 --> 00:41:53.660
You have Flask Accept and also Marshmallow.

00:41:53.660 --> 00:41:59.260
So maybe touch on some of the other ones like Marshmallow, Flask REST+, and so on.

00:41:59.260 --> 00:42:02.780
Well, specifically, I wanted to integrate these things.

00:42:02.780 --> 00:42:06.100
So Marshmallow is not really outside of Flask.

00:42:06.260 --> 00:42:08.900
It's a serialization and deserialization library.

00:42:08.900 --> 00:42:14.760
And so it has a really rich way of declaring that there are these fields and they have a

00:42:14.760 --> 00:42:15.340
certain type.

00:42:15.340 --> 00:42:17.980
And some things might be required, some not.

00:42:17.980 --> 00:42:19.620
Some might have defaults, some might not.

00:42:19.620 --> 00:42:22.100
And furthermore, it gives you all these hooks for it.

00:42:22.100 --> 00:42:22.240
Yeah.

00:42:22.240 --> 00:42:26.060
So I give you like a Python dictionary, which may be originated from a JSON file.

00:42:26.060 --> 00:42:30.680
And then Marshmallow will answer the question like, is this valid data?

00:42:30.680 --> 00:42:31.680
Something like that?

00:42:31.760 --> 00:42:32.160
Exactly.

00:42:32.160 --> 00:42:35.240
And if it's not, it will give you good error messages.

00:42:35.240 --> 00:42:37.500
So let's say you give me a JSON file.

00:42:37.500 --> 00:42:41.320
You post it to my server and I've declared that I want to make a widget.

00:42:41.320 --> 00:42:44.480
And a widget has these fields that I declare with the Marshmallow schema.

00:42:44.480 --> 00:42:50.260
I call it the load method and it will take the input data and create either a dictionary or you

00:42:50.260 --> 00:42:52.860
can give it a hook to create some kind of actual Python class.

00:42:53.260 --> 00:42:57.580
And if one of those input fails validation, it gives you a really nice error message that,

00:42:57.580 --> 00:42:58.940
oh, this is not a valid int.

00:42:58.940 --> 00:43:03.180
And so on the front end, the front end devs, it really helps them out because they say, oh,

00:43:03.180 --> 00:43:08.460
okay, AJ's schema has kicked back an error because I'm passing a float instead of an int or whatever

00:43:08.460 --> 00:43:08.840
it is.

00:43:08.840 --> 00:43:10.160
So there's Marshmallow.

00:43:10.160 --> 00:43:12.840
And then it also does the serialization on the way out.

00:43:13.180 --> 00:43:17.240
So for example, you have a user model that has a password.

00:43:17.240 --> 00:43:21.500
You probably don't want to send the password back to the front end.

00:43:21.500 --> 00:43:26.500
So you can set certain fields that are, you know, read or write only to solve that kind of problem.

00:43:26.500 --> 00:43:27.440
So it's very flexible.

00:43:27.440 --> 00:43:29.160
It's on the flip side.

00:43:29.160 --> 00:43:36.740
There is Flask REST plus, which I was very excited about, which basically just makes it easier to write

00:43:36.740 --> 00:43:41.360
endpoints where you're going through the full, you know, get post put delete flow,

00:43:41.500 --> 00:43:44.000
because otherwise you're writing a raw Flask endpoint.

00:43:44.000 --> 00:43:48.380
You have to sort of declare the methods it takes and effectively do a switch case on that.

00:43:48.380 --> 00:43:53.680
But with Flask REST plus, you create these resources that are class-based and you put the methods that

00:43:53.680 --> 00:43:56.500
they need for each of the different type of HTTP protocols.

00:43:56.500 --> 00:43:58.920
And it just makes it less code.

00:43:58.920 --> 00:44:06.200
And so combining these two though was not trivial because on one hand, Flask REST plus has its own

00:44:06.200 --> 00:44:11.020
validation scheme that although they declare is going to be deprecated,

00:44:11.020 --> 00:44:12.840
it doesn't seem like that's ever actually going to happen.

00:44:12.840 --> 00:44:17.680
They even referenced that we're deprecating this because we would like to switch to Marshmallow.

00:44:17.680 --> 00:44:22.240
But if you look through the Git history, there's years of conversation where they're like,

00:44:22.240 --> 00:44:24.380
eh, well, it's kind of hard and we've got this and that problem.

00:44:24.380 --> 00:44:24.660
Sure.

00:44:24.660 --> 00:44:29.160
And so I'm sort of at this frustration point where I want to use both of these cool technologies.

00:44:29.940 --> 00:44:32.480
And so Flask accepts is a library.

00:44:32.480 --> 00:44:37.360
It's just a couple of decorators really that allows me to unify REST plus and Marshmallow.

00:44:37.360 --> 00:44:41.680
Because what REST plus gives you in addition to those resources is Swagger docs.

00:44:41.860 --> 00:44:50.480
And the Swagger docs allow it to turn your API into a webpage that I can go to and it shows me all the endpoints and I can interactively hit them.

00:44:50.480 --> 00:45:03.040
Basically, it's like almost imagine if you had some kind of export config that would let you load into Postman and it just pre-populated every one of your endpoints with a click and it would just hit them with the right parameters and whatnot.

00:45:03.860 --> 00:45:09.340
And so in order to get both of those, this Flask accepts library allows you to sort of mix the two.

00:45:09.340 --> 00:45:11.060
So you would just have an endpoint.

00:45:11.060 --> 00:45:14.200
You put this accepts decorator, give it a Marshmallow schema.

00:45:14.200 --> 00:45:20.680
It will apply that validation on the way in, attach something to the Flask request object that you can then go on your merry way and use.

00:45:20.680 --> 00:45:22.880
And it also supports those Swagger docs.

00:45:22.880 --> 00:45:23.920
Yeah, it looks really nice.

00:45:23.920 --> 00:45:30.340
And this Flask accepts is something that you wrote because of your work with Marshmallow and Flask REST plus.

00:45:30.340 --> 00:45:32.540
And you're like, these need to live better together, right?

00:45:32.540 --> 00:45:34.640
Yeah, it was purely a personal pain point.

00:45:34.640 --> 00:45:38.420
And I wrote it over like a weekend to solve a problem I had at work.

00:45:38.420 --> 00:45:42.260
And naturally then since it's 2019, you open source things.

00:45:42.260 --> 00:45:43.360
Yeah, it's cool.

00:45:43.360 --> 00:45:45.000
I don't know if people will find it useful or not.

00:45:45.000 --> 00:45:47.100
There's other things, but it solves my problem.

00:45:47.100 --> 00:45:47.580
Yeah, super.

00:45:47.580 --> 00:45:49.360
So those are all really good.

00:45:49.360 --> 00:45:50.480
And you talk about those in there.

00:45:50.480 --> 00:45:57.560
One other thing I want to throw out there is people are just thinking about their Flask, like a new Flask project potentially is secure.py.

00:45:59.300 --> 00:46:05.860
So there's a lot of recommendations from OWASP and other web security companies and organizations saying, you know what?

00:46:05.900 --> 00:46:12.000
You should really add the header XSS protection and turn it on and set the mode to block.

00:46:12.000 --> 00:46:19.380
Or the iframe option should by default be set to same origin so nobody can embed you into their sites and make it look different or whatever.

00:46:20.060 --> 00:46:27.480
So like with one line of middleware for Flask, Pyramid Django and a whole bunch of others, you can just add this thing and it'll automatically add all those headers.

00:46:27.480 --> 00:46:28.820
So that's pretty cool.

00:46:28.820 --> 00:46:31.500
So if you're security conscious, that might be worth checking out.

00:46:31.500 --> 00:46:41.040
Yeah, I think especially with security, it's really smart to delegate that to third parties and allow them to be the experts because it's a full-time career to keep up with that.

00:46:41.040 --> 00:46:45.020
And every day there's some new hack people come out with and just delegate that stuff.

00:46:45.020 --> 00:46:46.420
Yeah, and you'll sleep slightly better.

00:46:46.420 --> 00:46:47.640
Yeah, slightly better.

00:46:47.640 --> 00:46:48.120
Slightly.

00:46:48.120 --> 00:46:51.040
Like it's no fantasy, but it's better than not.

00:46:51.040 --> 00:46:53.040
You wake up for other problems.

00:46:53.040 --> 00:46:53.720
Exactly.

00:46:53.720 --> 00:47:01.460
So we don't have a whole ton of time to spend on this, but I do want to talk just a little bit about this and then touch on some high-performance computing bits as well.

00:47:01.540 --> 00:47:13.980
But maybe give us a quick overflow of how you're structuring your Flask app because I think it's, like I said, it's different than what I'm doing and it's a little bit unique and people can think about whether it makes sense, but I think it's definitely worth considering.

00:47:13.980 --> 00:47:15.160
What are you doing there?

00:47:15.160 --> 00:47:18.580
And you were right that this is kind of more thought about from an API perspective.

00:47:18.580 --> 00:47:22.280
So if you're doing a lot of view rendering, this is not directly the same approach.

00:47:22.340 --> 00:47:33.020
But in essence, the philosophy is you want to be able to break up each of your, call them entities, it's a thing you're going to interact with from the server, into separate directories.

00:47:33.020 --> 00:47:38.820
Like this is the core tenet of your idea of organizing your code and your files and whatnot.

00:47:38.820 --> 00:47:46.740
And the reason I think this makes more sense for APIs than it does for apps is APIs are often centered around these entities, right?

00:47:46.740 --> 00:47:50.220
Like I want to go talk about the users or talk about these, right?

00:47:50.220 --> 00:47:53.320
Like this is like the essence of what APIs do often.

00:47:53.320 --> 00:48:08.320
Yeah, but I mean, even if I were to go set up a site that was more view-based, I would still think about it this way in the sense of if I had some kind of module that was like my users, I'm still going to change each of the pages maybe within the users module to be their own single folders.

00:48:08.320 --> 00:48:09.080
Yeah, I agree.

00:48:09.080 --> 00:48:11.440
So go ahead and tell us about this.

00:48:11.440 --> 00:48:17.740
Yeah, so the idea that you have a model, which is basically probably your SQLAlchemy layer, you know, your persistent storage.

00:48:17.740 --> 00:48:21.520
You have some kind of interface that we called it an interface.

00:48:21.520 --> 00:48:23.920
It's because it is basically what a TypeScript interface is.

00:48:23.920 --> 00:48:28.400
So it defines the type, what are the attributes that need to make this object?

00:48:28.400 --> 00:48:33.140
And there's a whole discussion there around why typing is super beneficial.

00:48:33.580 --> 00:48:44.200
So there's great tools out there like mypy and static analysis tools, and they save you an enormous amount of bug finding by highlighting errors where you've typoed something or missed a parameter.

00:48:44.200 --> 00:48:50.200
And so that gives you a layer to sort of make sure that your functions are behaving the way at least you're using them the way you've defined them.

00:48:50.200 --> 00:48:54.740
There's the schema, which is the marshmallow schema that I referred to.

00:48:54.800 --> 00:48:59.480
And so that handles the serialization layer on the way in and out of the application.

00:48:59.480 --> 00:49:05.740
That's where you can do last minute transforms, change names, export things, pick fields off, whatever.

00:49:05.740 --> 00:49:08.480
There is the controller.

00:49:08.480 --> 00:49:10.480
The controller is what's response.

00:49:10.480 --> 00:49:11.500
It's actually is the route.

00:49:11.500 --> 00:49:16.660
The controller, the way I think about it is it takes all these other pieces, and it kind of is the glue.

00:49:16.660 --> 00:49:23.800
It gets the parameters, calls the service, which I'll discuss in a second, gets the data, wrangles it, and outputs it.

00:49:23.800 --> 00:49:29.140
And then lastly, you have the service, which is what's responsible for actually manipulating the entity.

00:49:29.140 --> 00:49:36.700
Now, whether the entity is like a user you're storing your database or whether it is the result of some optimization calculation, it doesn't really matter.

00:49:36.700 --> 00:49:39.020
It's just a way for you to organize all this code.

00:49:39.020 --> 00:49:44.380
And then internally, you can use Pandas or NumPy or C++ or whatever, just how you think about it.

00:49:44.600 --> 00:49:52.900
Because the last place that those database queries or those Panda calculations should be is like in the route view method.

00:49:52.900 --> 00:49:54.060
Under your route, yeah.

00:49:54.060 --> 00:49:55.420
It shouldn't be crammed in there.

00:49:55.420 --> 00:49:56.180
It should be separate.

00:49:56.180 --> 00:49:57.820
The route should be pretty simple, right?

00:49:57.820 --> 00:49:58.220
Yes, exactly.

00:49:58.220 --> 00:49:58.960
You know, five, ten lines.

00:49:58.960 --> 00:50:00.680
It should be orchestration.

00:50:00.680 --> 00:50:01.060
Get the data call service.

00:50:01.060 --> 00:50:01.360
Exactly.

00:50:01.360 --> 00:50:04.360
It should be orchestration between all these other pieces is the way I see it.

00:50:04.360 --> 00:50:04.520
Yeah.

00:50:04.520 --> 00:50:06.220
Cool.

00:50:06.220 --> 00:50:08.120
And then tests go alongside with that.

00:50:08.120 --> 00:50:08.300
Yeah.

00:50:08.360 --> 00:50:16.700
So your main philosophy here is that instead of having a services section and a controller section and a data section and whatnot,

00:50:16.700 --> 00:50:25.740
is to have like a user section with a service controller model kind of in its own self-contained area, right?

00:50:25.980 --> 00:50:26.200
Yes.

00:50:26.200 --> 00:50:30.260
So how long would it take you to delete everything related to users?

00:50:30.260 --> 00:50:32.480
There's basically your sanity check.

00:50:32.480 --> 00:50:39.700
If you've got to go through and dig eight trees down into every other directory and find it, you're not compliant with what I am proposing.

00:50:39.700 --> 00:50:40.160
Okay.

00:50:40.160 --> 00:50:40.400
Yeah.

00:50:40.440 --> 00:50:43.720
It's an interesting article and people can check it out for sure.

00:50:43.720 --> 00:50:44.600
The gory details.

00:50:44.600 --> 00:50:44.780
Yeah.

00:50:44.780 --> 00:50:45.560
Yeah, exactly.

00:50:45.560 --> 00:50:54.000
But I definitely think, you know, if nothing else, like FlashRest Plus, Marshmallow, all these things are pretty interesting.

00:50:54.000 --> 00:50:56.560
And it's cool to see how you're putting them to use there.

00:50:56.560 --> 00:50:57.360
Great.

00:50:57.360 --> 00:50:59.100
So let's talk a little bit about computation.

00:50:59.100 --> 00:51:03.920
You know, I touched on this at the beginning when I said, like, what is the deployment story, right?

00:51:03.920 --> 00:51:10.480
Do I need to like deploy to a cluster that has GPUs because I got to have GPUs in production or something like this, right?

00:51:10.480 --> 00:51:12.140
Let's talk a little bit about that.

00:51:12.140 --> 00:51:17.180
I mean, I think one of the things that's interesting to just touch on first is Python performance.

00:51:17.180 --> 00:51:21.540
Like people will tell me sometimes, usually they're not Python people.

00:51:21.540 --> 00:51:23.560
They'll tell me Python is slow.

00:51:23.560 --> 00:51:26.880
So I can't use Python for X, right?

00:51:26.880 --> 00:51:32.080
The performance story of Python is actually complicated and it depends, right?

00:51:32.080 --> 00:51:37.700
Like, yes, maybe this part of Python, if I wrote it in pure Python is slower than, say, Java.

00:51:37.700 --> 00:51:42.100
But if I were to write it in C, it would actually be faster than Java.

00:51:42.100 --> 00:51:53.080
And so I could actually do something like a Cython version of this code, which then, you know, maps over to C++ or C and then compiles down to native instructions.

00:51:53.080 --> 00:51:55.140
So is it fast or is it slow?

00:51:55.140 --> 00:51:55.620
I don't know.

00:51:55.620 --> 00:51:57.200
Like it's like this blend.

00:51:57.200 --> 00:51:59.980
And so you can do a lot of tricks to make it fast where it matters.

00:51:59.980 --> 00:52:01.440
Use things like NumPy and whatnot.

00:52:01.620 --> 00:52:05.800
But maybe like, like, how do you see that world from somebody who does way more computation than I do?

00:52:05.800 --> 00:52:06.140
Right.

00:52:06.140 --> 00:52:10.780
This whole topic of HPC, high performance computing is something I'm super passionate about.

00:52:10.780 --> 00:52:12.460
It was my whole grad experience.

00:52:12.460 --> 00:52:17.480
As far as Python's performance, you should compute from Python, but not with Python.

00:52:17.480 --> 00:52:19.680
So Python is slow.

00:52:19.680 --> 00:52:29.780
If you're talking about doing numeric computation in Python, you should invoke Python libraries that push that computation down to C.

00:52:29.960 --> 00:52:32.320
So, I mean, I write loops all the time.

00:52:32.320 --> 00:52:45.540
But anytime you're writing a loop to accomplish something that has a lot of IJs and Ks in it, you should at least kind of get the heebie-jeebies and think maybe there's a NumPy or Pandas method that's going to push this down to a C or C++ layer that's super fast.

00:52:45.540 --> 00:52:45.820
Right.

00:52:45.880 --> 00:52:51.700
And if there's not, could you make that one function a Cython function and really change it, right?

00:52:51.700 --> 00:52:52.140
Right.

00:52:52.140 --> 00:52:52.440
Yeah.

00:52:52.440 --> 00:52:59.080
So Cython's the way to go if you have a custom operation that you want to do that you can't do out of the box with NumPy.

00:52:59.600 --> 00:53:11.920
Because basically all you do is you provide a set of annotations to create the Cython file and then you run a transpiler that converts that into valid C, C++, and then brings that back into Python.

00:53:11.920 --> 00:53:14.500
Because Python, if you don't know, is ultimately written in C.

00:53:14.820 --> 00:53:19.260
So this kind of gives you a way to write Python and compile it and then bring it back in.

00:53:19.260 --> 00:53:22.720
Or you could also just write directly in C++.

00:53:22.720 --> 00:53:27.820
And that's kind of what you have to do if you want to do custom computing with GPUs.

00:53:27.820 --> 00:53:39.000
You're almost, and again, unless you're using a library that enables GPU routines, if you're doing custom stuff, you're going to have to go to the C++ level and bring in like a shared library or something like that.

00:53:39.000 --> 00:53:40.560
At that point, it's pretty much unavoidable.

00:53:40.560 --> 00:53:40.860
Yeah.

00:53:40.860 --> 00:53:41.900
It's interesting.

00:53:41.900 --> 00:53:44.540
I have yet to need to go to C++.

00:53:44.540 --> 00:53:55.480
But I'm happy when the libraries that I use have C extensions or parts of them are somehow using C speedups to make them much faster.

00:53:55.480 --> 00:53:57.020
And I don't have to worry about it.

00:53:57.020 --> 00:53:57.220
Yeah.

00:53:57.220 --> 00:54:02.420
So I find writing in raw C++ is helpful if you need to deal with a lot of multi-threaded stuff.

00:54:02.420 --> 00:54:06.340
Multi-threaded in the C++ context, not in the GIL context.

00:54:06.340 --> 00:54:15.200
So if you have an algorithm that you want to manually deal with pushing out threads and multi-procking something and bringing them back, I find it's easier to do in C++.

00:54:15.200 --> 00:54:18.360
But to be honest, I don't have to do that very much day to day.

00:54:18.360 --> 00:54:19.820
I did that in the past life.

00:54:19.940 --> 00:54:23.120
But in industrial data science, I don't need to do that.

00:54:23.120 --> 00:54:26.860
Pretty much NumPy, SciPy, Pandas gives me everything I need more or less.

00:54:26.860 --> 00:54:28.200
It takes a lot of time, right?

00:54:28.200 --> 00:54:30.380
It's developer time versus compute time at the end of the day.

00:54:30.380 --> 00:54:30.640
Yeah.

00:54:30.640 --> 00:54:30.960
Yeah.

00:54:30.960 --> 00:54:32.740
It's another one of those define fast, right?

00:54:32.800 --> 00:54:46.300
Like if it takes you two days to write the C++ code that then runs in five minutes, or it took you half an hour to write the Python code and it runs in 20 minutes, who solved that problem first, right?

00:54:46.300 --> 00:54:48.260
Like it depends how many times you're running it.

00:54:48.260 --> 00:54:50.400
Like there's a lot of considerations there.

00:54:50.400 --> 00:55:01.180
But if you're working for a hedge fund where a tiny increment of performance is whatever, put a bunch of zeros after a dollar sign, then maybe it matters and it makes sense to spend weeks on this tiny micro optimization.

00:55:01.180 --> 00:55:02.520
It's all about context.

00:55:02.620 --> 00:55:05.140
The whole hedge fund algorithmic trading space is crazy.

00:55:05.140 --> 00:55:14.160
Like when you consider like server co-location and stuff so that you can like drop a few milliseconds of latency because that changes your profit margins.

00:55:14.160 --> 00:55:15.860
Like that's a bizarre industry.

00:55:15.860 --> 00:55:16.480
Yes.

00:55:16.480 --> 00:55:17.880
But that's how it is, right?

00:55:17.880 --> 00:55:18.820
Cool.

00:55:18.820 --> 00:55:19.020
All right.

00:55:19.020 --> 00:55:20.420
So you talked about GPUs.

00:55:20.420 --> 00:55:24.620
Like what are, I mean, what are some of the things that we compute with GPUs?

00:55:24.620 --> 00:55:31.020
You know, the real simple ones are like, I'm doing machine learning training, like a training machine learning model.

00:55:31.260 --> 00:55:33.660
And I'm going to do that, say with GPUs or something like that.

00:55:33.660 --> 00:55:39.440
But what are some of the more, what are some of the other things I might go and write GPU code with for rather?

00:55:39.440 --> 00:55:41.100
Well, in practice, you might not need to.

00:55:41.100 --> 00:55:46.480
You probably don't need to until you have a problem that you don't have a better solution for.

00:55:46.740 --> 00:55:54.580
So I don't necessarily think it's sort of the general audience, but for the people that it's the right solution for, it's probably the only good solution.

00:55:54.580 --> 00:55:59.460
So GPUs are very good at doing enormous computations in parallel.

00:56:00.260 --> 00:56:02.860
So interestingly, I mean, they started out as graphics cards, right?

00:56:02.860 --> 00:56:07.980
And I think people here make the connection between like my video game engine and how am I doing science?

00:56:07.980 --> 00:56:16.100
Well, what actually happened was scientists realized that they could use these native graphics card APIs for like text or vertex shading.

00:56:16.660 --> 00:56:24.400
And they wrote problems like whatever, an earthquake simulation or something using these vertex APIs because along the way it did the math they needed.

00:56:24.400 --> 00:56:24.680
Yeah.

00:56:24.680 --> 00:56:26.660
And that was sort of where CUDA came out.

00:56:26.660 --> 00:56:31.000
So the kinds of problems they solve are things that you can do heavily in parallel.

00:56:31.060 --> 00:56:34.760
So for example, matrix math, GPUs are very good at.

00:56:34.760 --> 00:56:37.080
Aggregations, GPUs are very good at.

00:56:37.080 --> 00:56:45.360
Sorting, not very good at because sorting is sort of inherently in general interdependent on the state of the rest of the algorithm.

00:56:45.360 --> 00:56:50.540
And although there's GPU sorting algorithms at a high level, those are the kinds of problems.

00:56:50.540 --> 00:56:52.300
So it's the right tool for the right job.

00:56:52.300 --> 00:56:52.960
Yeah, cool.

00:56:53.460 --> 00:57:01.380
You know, I didn't appreciate how much computation GPUs could do until I started working in 3D graphics, which I did a long time ago.

00:57:01.380 --> 00:57:03.900
But you think I'm loading up all these models.

00:57:03.900 --> 00:57:15.180
I'm applying all these, like every time you want to rotate or move any item that is on the screen, it's a matrix multiplication on all the vertices of it to make that happen.

00:57:15.180 --> 00:57:16.600
And there's usually multiple ones.

00:57:16.720 --> 00:57:29.340
And then just if you start to think about like a modern graphical simulation, a game or some other 3D environment, and then the amount of matrix multiplications per second at 120 frames a second.

00:57:29.340 --> 00:57:30.280
It's mind boggling.

00:57:30.280 --> 00:57:34.600
Like the human mind cannot grasp how much math is happening per second.

00:57:34.600 --> 00:57:35.680
It's just unbelievable.

00:57:35.680 --> 00:57:36.120
Yes.

00:57:36.120 --> 00:57:40.940
I mean, the physics engines in games these days do, you know, ricochets and everything on the fly.

00:57:40.940 --> 00:57:42.800
And then there's also the memory management.

00:57:43.060 --> 00:57:47.040
You've got memory on the host and the GPU, and it's constantly going back and forth.

00:57:47.040 --> 00:57:48.820
I mean, all of this, it's extremely complex.

00:57:48.820 --> 00:57:50.960
So, yeah, it's really amazing technology.

00:57:50.960 --> 00:57:57.560
Yeah, if you can turn that computational engine on to like more direct problems like you're talking about, it's pretty interesting.

00:57:57.560 --> 00:58:01.420
So, some other options, you know, like there's grid computing.

00:58:01.420 --> 00:58:08.000
We could set up like 50 computers in AWS or GPC or GCP, something like that.

00:58:08.000 --> 00:58:09.820
Like what's a good story for that, right?

00:58:09.860 --> 00:58:17.480
Like maybe you don't need all these clusters, or if you do have them, maybe you can use something like Dask, and you don't actually have to program against it.

00:58:17.480 --> 00:58:19.700
It just magic happens if you set them up right.

00:58:19.700 --> 00:58:24.520
Yeah, Dask is a great project because it's basically solving these kinds of problems for you.

00:58:24.520 --> 00:58:26.680
You know, as the user, you just say, I have a thing.

00:58:26.680 --> 00:58:28.340
I need it to run fast.

00:58:28.340 --> 00:58:34.480
I don't want to know about how you have your nodes networked together for running an MPI job.

00:58:34.860 --> 00:58:36.720
But originally, that was what you had to do.

00:58:36.720 --> 00:58:45.400
So, I think the more projects like Dask evolve, and you kind of write what feels like maybe pandas, and it can just scale outwards, it's going to be really good for the community.

00:58:45.400 --> 00:58:46.020
Yeah, that's cool.

00:58:46.020 --> 00:58:53.580
You know, I always thought Dask was something that would make no sense for me because I don't really have these large cluster type computations that I ever have to do.

00:58:53.580 --> 00:59:06.260
But when I was talking to Matthew Rocklin, I realized, he pointed out to me, that you can run Dask on a single CPU, or a single machine, and it'll actually do the multiprocessing and parallelism and all that.

00:59:06.260 --> 00:59:09.960
And so, it's just another interesting use case where you might not think of it.

00:59:09.960 --> 00:59:10.160
Yeah.

00:59:10.160 --> 00:59:11.900
I mean, all that comes with overhead, too, though.

00:59:11.900 --> 00:59:13.420
So, it's always the right tool for the right job.

00:59:13.420 --> 00:59:17.680
You wouldn't take an airplane across the street, even though it's faster than a car, right?

00:59:18.000 --> 00:59:21.060
Because by the time you went through all of that, it doesn't make any sense.

00:59:21.060 --> 00:59:22.040
The overhead's too high.

00:59:22.040 --> 00:59:24.360
But at some point, it catches up, right?

00:59:24.360 --> 00:59:25.000
Yeah, for sure.

00:59:25.000 --> 00:59:26.320
Super interesting.

00:59:26.320 --> 00:59:29.220
Okay, well, I guess let's leave it at this.

00:59:29.220 --> 00:59:34.200
You have a few other libraries to leverage HPC without too much expertise.

00:59:34.200 --> 00:59:37.200
You want to take us through those really quick, and then we'll close it out?

00:59:37.200 --> 00:59:45.960
Yeah, so it's just the idea is if you're not somebody who knows CUDA and is obsessed with all these little micro-optimizations, like I've been for a long time,

00:59:46.040 --> 00:59:54.720
which is the vast majority of the normal work encoding population, how do you get the advantage of these is to just use those tools like Dask.

00:59:54.720 --> 00:59:55.460
That's one option.

00:59:55.460 --> 00:59:57.460
There's libraries that are inherently parallel.

00:59:57.460 --> 01:00:00.460
NumPy has some multi-core support and whatnot.

01:00:00.460 --> 01:00:12.720
There's also a lot of analytics, sort of more managed services, like Google BigQuery is basically a SQL-like engine that just scales out transparently to you to lots of nodes.

01:00:12.720 --> 01:00:14.160
It comes back very quickly.

01:00:14.600 --> 01:00:19.640
There's another one called CitusDB that Microsoft, I think, recently acquired, and it's very good for that kind of thing.

01:00:19.640 --> 01:00:27.560
So there's technologies that you can leverage, and I think, by and large, that's the most straightforward way to get into that without getting a PhD in the subject.

01:00:27.560 --> 01:00:28.740
Yeah, start there.

01:00:28.740 --> 01:00:30.560
Then go custom if you got to, right?

01:00:30.560 --> 01:00:31.060
Exactly.

01:00:31.060 --> 01:00:31.780
All right, cool.

01:00:31.780 --> 01:00:33.820
Well, this has been really fun to talk about all these things.

01:00:33.820 --> 01:00:38.560
Now, before we wrap it up, I've got to ask you the two final questions, of course.

01:00:39.060 --> 01:00:41.800
If you're writing some Python code, what editor do you use?

01:00:41.800 --> 01:00:43.100
VS Code these days.

01:00:43.100 --> 01:00:46.620
I used to be diehard Vim because I knew the shortcuts.

01:00:46.620 --> 01:00:48.020
I could get around faster.

01:00:48.020 --> 01:00:53.500
And something about VS Code, I found myself outpacing my productivity.

01:00:53.500 --> 01:00:55.420
And then at that point, I was sold.

01:00:55.420 --> 01:00:57.900
I mean, I still use Vim when I'm in a remote terminal.

01:00:57.900 --> 01:01:00.640
But I'm a big VS Code fan, yeah.

01:01:00.640 --> 01:01:01.020
That's cool.

01:01:01.020 --> 01:01:02.800
Yeah, it's definitely got the momentum these days.

01:01:02.800 --> 01:01:05.340
And there's a lot of effort to make it better.

01:01:05.340 --> 01:01:06.860
So I think it's only going to get better.

01:01:06.860 --> 01:01:08.100
It's great for TypeScript.

01:01:08.100 --> 01:01:10.860
If you're writing Angular, it's very good for TypeScript.

01:01:10.860 --> 01:01:12.360
I mean, Microsoft makes both products.

01:01:12.360 --> 01:01:12.860
Go figure it out.

01:01:12.860 --> 01:01:17.860
Yeah, and it's literally even the Python extension is written in TypeScript.

01:01:17.860 --> 01:01:21.140
So it's no surprise that it's good at writing in TypeScript, right?

01:01:21.140 --> 01:01:22.440
Yeah, Electron apps.

01:01:22.440 --> 01:01:23.500
Yeah, I mean, they use TypeScript for that.

01:01:23.500 --> 01:01:24.080
Yeah, absolutely.

01:01:24.080 --> 01:01:24.940
Cool.

01:01:24.940 --> 01:01:26.600
And then notable PyPI packages?

01:01:26.600 --> 01:01:29.120
So there's one called pytest Watch.

01:01:29.120 --> 01:01:31.480
I mentioned, I mean, I like pytest.

01:01:31.480 --> 01:01:32.620
This one's super simple.

01:01:32.620 --> 01:01:34.540
It just gives you a terminal watcher.

01:01:34.540 --> 01:01:36.420
So you pip install pytest Watch.

01:01:36.420 --> 01:01:41.120
And there's like a PTW command that just on reload will run your test again.

01:01:41.120 --> 01:01:43.000
Super simple, but I use it all the time.

01:01:43.000 --> 01:01:43.660
That's really cool.

01:01:43.660 --> 01:01:46.100
So if you just hit save, like your test run, basically.

01:01:46.100 --> 01:01:46.960
Yep, yep.

01:01:46.960 --> 01:01:51.260
And so I just leave that running pretty much 24-7 and just sit there, change code,

01:01:51.260 --> 01:01:54.520
control S, and just glance over and make sure my tests are good all day long.

01:01:54.520 --> 01:01:55.440
That's pretty solid.

01:01:55.440 --> 01:01:55.620
Very helpful.

01:01:55.620 --> 01:01:56.700
Cool.

01:01:56.700 --> 01:01:59.120
Another is, I mentioned mypy.

01:01:59.120 --> 01:02:03.800
And then specifically, there's a flake 8 mypy extension for VS Code.

01:02:03.800 --> 01:02:06.020
The mypy is a static type analysis.

01:02:06.020 --> 01:02:10.820
So it will do things like, if I write a function in Python, and I say, this takes a parameter

01:02:10.820 --> 01:02:12.160
that is a string.

01:02:12.160 --> 01:02:15.580
And then I later call that function with a parameter that's an int.

01:02:15.640 --> 01:02:18.840
I get a little red squiggle, and it says, you know, error, you've called this function

01:02:18.840 --> 01:02:19.320
incorrectly.

01:02:19.320 --> 01:02:24.420
And it catches a whole class of bugs that you might not find until runtime because, well,

01:02:24.420 --> 01:02:25.440
it's a dynamic language.

01:02:25.440 --> 01:02:29.060
So this is a newer thing for me.

01:02:29.060 --> 01:02:34.540
It's mostly born out of using TypeScript for a while and moving from JavaScript to TypeScript

01:02:34.540 --> 01:02:37.340
and realizing, like, wow, this is a huge productivity boost.

01:02:37.380 --> 01:02:42.240
And so now that Python seems to be moving towards more of this type annotation stuff, I'm just

01:02:42.240 --> 01:02:43.980
completely jumping on the bandwagon.

01:02:43.980 --> 01:02:44.480
That's cool.

01:02:44.480 --> 01:02:44.700
Yeah.

01:02:44.700 --> 01:02:46.480
I'm a fan of type annotations as well.

01:02:46.480 --> 01:02:47.000
Yeah.

01:02:47.000 --> 01:02:48.060
I really think they add a lot.

01:02:48.060 --> 01:02:53.700
And then if you're interested in performance, there's mypyC, which compiles that code, the

01:02:53.700 --> 01:02:56.140
type annotated Python 2C code as well.

01:02:56.140 --> 01:02:59.200
So those people looking for performance, that's another option.

01:02:59.200 --> 01:03:00.400
Is that a Facebook thing?

01:03:00.400 --> 01:03:01.420
It is.

01:03:01.420 --> 01:03:02.540
Where is it?

01:03:02.540 --> 01:03:05.460
It's under its own organization.

01:03:05.460 --> 01:03:06.940
I don't remember.

01:03:06.940 --> 01:03:11.520
There was one like that, I think, from Facebook and one like that from Dropbox.

01:03:11.520 --> 01:03:12.380
And I don't know which.

01:03:12.380 --> 01:03:15.080
Now there's somebody listening to it and just cursing my name for that.

01:03:15.080 --> 01:03:15.760
So apologies.

01:03:15.760 --> 01:03:17.940
It's under its own organization.

01:03:17.940 --> 01:03:20.680
It's not like under a different organization.

01:03:20.680 --> 01:03:21.260
Yeah.

01:03:21.260 --> 01:03:21.780
So I'm not sure.

01:03:21.780 --> 01:03:22.840
That's a great idea, though.

01:03:22.840 --> 01:03:27.280
The idea that you annotate this and now it's almost like Cython, you know, it knows more about

01:03:27.280 --> 01:03:30.900
what you meant and now it could potentially convert that into better code.

01:03:30.900 --> 01:03:31.620
See it going there.

01:03:31.620 --> 01:03:31.840
Yeah.

01:03:31.840 --> 01:03:35.140
I don't think it's generally useful yet, but it's getting close.

01:03:35.140 --> 01:03:36.240
So it's pretty cool.

01:03:36.240 --> 01:03:36.500
Yeah.

01:03:36.500 --> 01:03:37.980
You need critical mass.

01:03:37.980 --> 01:03:38.340
Yeah.

01:03:38.340 --> 01:03:40.080
I think they use it to build my pie itself.

01:03:40.080 --> 01:03:41.000
At a certain point, there's enough adoption.

01:03:41.000 --> 01:03:41.700
Yeah, exactly.

01:03:41.700 --> 01:03:42.040
Yeah.

01:03:42.040 --> 01:03:42.440
Super cool.

01:03:42.440 --> 01:03:44.380
And then you have one more you want to throw out there before we hit that.

01:03:44.380 --> 01:03:45.360
I have one more.

01:03:45.360 --> 01:03:46.580
It's called RxPy.

01:03:46.580 --> 01:03:51.360
So reactive extensions, you should go to reactivex.io.

01:03:51.360 --> 01:03:56.240
It's a whole pattern of programming that's been around for a while, but it's based on the

01:03:56.240 --> 01:03:58.020
idea of observable streams.

01:03:58.180 --> 01:04:03.460
So rather than imperatively saying, I want my program to do X and Y, you say, I want to

01:04:03.460 --> 01:04:07.120
sort of declare what my program should do in response to data changes.

01:04:07.120 --> 01:04:12.060
And it makes certain types of problems tremendously easier to reason about and program.

01:04:12.060 --> 01:04:16.720
And there's a JavaScript counterpart, RxJS, that's super popular in Angular.

01:04:16.960 --> 01:04:18.520
And this is the Python implementation.

01:04:18.520 --> 01:04:23.940
It's not nearly as mainstream, even though that repo has a lot of stars, but it's something

01:04:23.940 --> 01:04:28.220
I'm experimenting a lot with just because I've seen some of the problems it solves in front

01:04:28.220 --> 01:04:33.020
end development and found a couple of interesting cases where it can be used in Python.

01:04:33.020 --> 01:04:34.160
Yeah, it looks interesting.

01:04:34.160 --> 01:04:40.900
I haven't used that before, but the whole observable data notification stuff is kind of cool.

01:04:40.900 --> 01:04:42.000
Nice.

01:04:42.000 --> 01:04:42.860
Good recommendation.

01:04:42.860 --> 01:04:43.640
So, all right.

01:04:43.640 --> 01:04:45.240
So people are out there.

01:04:45.240 --> 01:04:46.640
Maybe they're doing some data science.

01:04:46.640 --> 01:04:47.860
They want to get it on the web.

01:04:47.860 --> 01:04:49.460
What's the final call to action?

01:04:49.460 --> 01:04:50.300
Where do they start?

01:04:50.300 --> 01:04:55.080
So, well, one place you could start is there's another project that sort of was born out of

01:04:55.080 --> 01:04:59.720
a weekend thing that would be very, it's sort of in its infancy called Flaskerize.

01:04:59.720 --> 01:05:05.280
And the idea there was we have front end apps and back end apps that you traditionally deploy

01:05:05.280 --> 01:05:08.000
separately, or you make a Python only app.

01:05:08.000 --> 01:05:13.440
But in principle, you could serve your React front end from the same Flask API.

01:05:13.440 --> 01:05:16.560
And if you have a single app, it makes deployment a lot easier.

01:05:16.580 --> 01:05:17.720
It makes scaling a lot easier.

01:05:17.720 --> 01:05:22.020
And so we sort of had this idea, like, why don't I just make a command line tool that could

01:05:22.020 --> 01:05:26.900
take a static site that you built with whatever, whether it's a JavaScript thing like React or

01:05:26.900 --> 01:05:30.780
Angular, or whether it's a Jekyll or Gatsby or whatever.

01:05:30.780 --> 01:05:35.640
And you want to basically embed that in your existing API and potentially Dockerize it with

01:05:35.640 --> 01:05:36.220
like one command.

01:05:36.220 --> 01:05:42.700
And so that's what this Flaskerize project is about is sort of making a code generation and

01:05:42.700 --> 01:05:47.240
templating and DevTool sort of Flask command line interface.

01:05:47.240 --> 01:05:53.280
And at this point, I've sort of played around with it a bit and I'm using some of it as its

01:05:53.280 --> 01:05:55.000
DevTool form in production.

01:05:55.000 --> 01:05:59.320
I think there's a lot that could be done with this, but I don't necessarily always have the

01:05:59.320 --> 01:05:59.540
time.

01:05:59.600 --> 01:06:01.420
So I have a lot of ideas around that.

01:06:01.420 --> 01:06:06.080
So it'd be interesting for people to check that out or potentially contribute.

01:06:06.080 --> 01:06:12.060
You know, there's a rich CLI in some of the front end communities that doesn't exist in

01:06:12.060 --> 01:06:12.320
Python.

01:06:12.320 --> 01:06:15.700
I think that could be a real productivity boost in Python.

01:06:15.700 --> 01:06:18.440
We don't really have a good like templated generator.

01:06:19.200 --> 01:06:21.080
It's not that I've found particularly useful.

01:06:21.080 --> 01:06:21.760
That's pretty interesting.

01:06:21.760 --> 01:06:24.000
Take your stuff and basically convert it to Flask.

01:06:24.000 --> 01:06:24.500
That's cool.

01:06:24.500 --> 01:06:25.740
All right.

01:06:25.740 --> 01:06:26.340
Yeah, nice.

01:06:26.340 --> 01:06:30.920
And then I'm going to have a bunch of links from various articles and libraries that you've

01:06:30.920 --> 01:06:31.680
talked about here.

01:06:31.680 --> 01:06:33.360
So throw those all in the show notes.

01:06:33.360 --> 01:06:34.940
People can just click on them in there and their player.

01:06:34.940 --> 01:06:35.380
Yeah.

01:06:35.380 --> 01:06:37.780
And then I'm speaking at a conference at the end of the month.

01:06:37.780 --> 01:06:42.200
If you want to hear me ramble on more about this type of stuff, if you're near the Charlotte

01:06:42.200 --> 01:06:45.120
area, there's the Data Science North Carolina 2019.

01:06:45.120 --> 01:06:48.460
I guess we'll put a link in the show notes below for that as well.

01:06:48.620 --> 01:06:48.720
Yeah.

01:06:48.720 --> 01:06:50.880
Do you know if they record those videos and put them online?

01:06:50.880 --> 01:06:51.500
They do.

01:06:51.500 --> 01:06:54.520
I'll make a reminder to myself once that's out to put that up.

01:06:54.520 --> 01:06:56.120
The conference is at the end of August.

01:06:56.120 --> 01:06:59.420
So it'll be around shortly after this airs.

01:06:59.420 --> 01:07:00.660
The closest time this comes out.

01:07:00.660 --> 01:07:00.980
Yeah, for sure.

01:07:00.980 --> 01:07:05.500
Through the magic of time travel, we can put that link retro back in.

01:07:05.500 --> 01:07:06.460
Yeah, that sounds good.

01:07:06.460 --> 01:07:08.200
And then credit where credit's due.

01:07:08.200 --> 01:07:10.280
mypyC is developed by Dropbox.

01:07:10.280 --> 01:07:11.940
Thank you for preventing me from getting sued.

01:07:11.940 --> 01:07:12.680
Appreciate that.

01:07:12.680 --> 01:07:14.520
Yeah, no problem.

01:07:14.520 --> 01:07:14.800
All right.

01:07:14.800 --> 01:07:18.500
Well, AJ, it's been really fun to talk about this intersection of data science.

01:07:18.500 --> 01:07:19.460
And web development.

01:07:19.460 --> 01:07:20.940
And thanks for sharing with everyone.

01:07:20.940 --> 01:07:21.500
Yes, sir.

01:07:21.500 --> 01:07:22.260
Thank you for having me.

01:07:23.380 --> 01:07:26.040
This has been another episode of Talk Python to Me.

01:07:26.040 --> 01:07:28.920
Our guest on this episode was AJ Pryor.

01:07:28.920 --> 01:07:31.380
And it's been brought to you by Linode and Rollbar.

01:07:31.380 --> 01:07:35.760
Linode is your go-to hosting for whatever you're building with Python.

01:07:35.760 --> 01:07:39.300
Get four months free at talkpython.fm/Linode.

01:07:39.300 --> 01:07:41.200
That's L-I-N-O-D-E.

01:07:41.200 --> 01:07:44.100
Rollbar takes the pain out of errors.

01:07:44.500 --> 01:07:49.400
They give you the context and insight you need to quickly locate and fix errors that might have gone unnoticed.

01:07:49.400 --> 01:07:51.400
Until users complain, of course.

01:07:51.400 --> 01:07:57.840
Track a ridiculous number of errors for free as Talk Python to Me listeners at talkpython.fm/rollbar.

01:07:57.840 --> 01:08:00.100
Want to level up your Python?

01:08:00.100 --> 01:08:04.880
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

01:08:04.880 --> 01:08:13.040
Or if you're looking for something more advanced, check out our new async course that digs into all the different types of async programming you can do in Python.

01:08:13.040 --> 01:08:17.700
And of course, if you're interested in more than one of these, be sure to check out our Everything Bundle.

01:08:17.700 --> 01:08:19.600
It's like a subscription that never expires.

01:08:19.600 --> 01:08:21.880
Be sure to subscribe to the show.

01:08:21.880 --> 01:08:24.300
Open your favorite podcatcher and search for Python.

01:08:24.300 --> 01:08:25.520
We should be right at the top.

01:08:25.520 --> 01:08:34.500
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

01:08:34.500 --> 01:08:36.600
This is your host, Michael Kennedy.

01:08:36.600 --> 01:08:38.100
Thanks so much for listening.

01:08:38.100 --> 01:08:39.160
I really appreciate it.

01:08:39.160 --> 01:08:40.940
Now get out there and write some Python code.

01:08:40.940 --> 01:09:01.400
I really appreciate it.

