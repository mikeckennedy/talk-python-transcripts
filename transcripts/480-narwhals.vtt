WEBVTT

00:00:00.001 --> 00:00:03.420
If you work in data science, you definitely know about data frame libraries.

00:00:03.420 --> 00:00:09.880
Handis is certainly the most popular, but there are others such as QDF, Moden, Polars,

00:00:09.880 --> 00:00:10.640
Dask, and more.

00:00:10.640 --> 00:00:15.060
They're all similar, but definitely not the same APIs, and Polars is quite different.

00:00:15.060 --> 00:00:16.260
But here's the problem.

00:00:16.260 --> 00:00:20.880
If you want to write a library that is for users of more than one of these data frame

00:00:20.880 --> 00:00:22.640
frameworks, how do you do that?

00:00:22.640 --> 00:00:27.000
Or if you want to leave open the possibility of changing yours after the app is built,

00:00:27.000 --> 00:00:28.280
you've got the same problem.

00:00:28.280 --> 00:00:30.500
Well, that's what narwhals solves.

00:00:30.500 --> 00:00:34.880
We have Marco Garelli on the show to tell us all about narwhals.

00:00:34.880 --> 00:00:40.460
This is Talk Python to Me, episode 480, recorded September 10th, 2024.

00:00:40.460 --> 00:00:43.160
Are you ready for your host, please?

00:00:43.160 --> 00:00:46.840
You're listening to Michael Kennedy on Talk Python to Me.

00:00:46.840 --> 00:00:50.500
Live from Portland, Oregon, and this segment was made with Python.

00:00:50.500 --> 00:00:56.600
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:56.600 --> 00:00:58.840
This is your host, Michael Kennedy.

00:00:58.840 --> 00:01:04.060
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using at Talk Python,

00:01:04.060 --> 00:01:07.180
both accounts over at fosstodon.org.

00:01:07.180 --> 00:01:12.080
And keep up with the show and listen to over nine years of episodes at talkpython.fm.

00:01:12.620 --> 00:01:16.660
If you want to be part of our live episodes, you can find the live streams over on YouTube.

00:01:16.660 --> 00:01:22.880
Subscribe to our YouTube channel over at talkpython.fm/youtube and get notified about upcoming shows.

00:01:23.420 --> 00:01:25.640
This episode is brought to you by WorkOS.

00:01:25.640 --> 00:01:32.800
If you're building a B2B SaaS app, at some point your customers will start asking for enterprise features like SAML authentication,

00:01:32.800 --> 00:01:36.740
skim provisioning, audit logs, and fine-grained authorization.

00:01:36.740 --> 00:01:42.680
WorkOS helps ship enterprise features on day one without slowing down your core product development.

00:01:42.680 --> 00:01:46.560
Find out more at talkpython.fm/workos.

00:01:46.560 --> 00:01:49.080
Marco, welcome to Talk Python to Me.

00:01:49.080 --> 00:01:50.400
Hey, thanks for having me.

00:01:50.600 --> 00:01:51.960
Hey, it's fantastic to have you here.

00:01:51.960 --> 00:01:59.300
We talked a little bit on the socials and other places, but, you know, nice to talk to you in person and about some of your projects.

00:01:59.300 --> 00:02:00.820
Yeah, nice to finally do it.

00:02:00.820 --> 00:02:04.320
Been listening to your shows for years, so it's a pleasure to be here.

00:02:04.320 --> 00:02:05.760
Yeah, that's really cool.

00:02:05.760 --> 00:02:09.640
It's awesome when people who are listeners for a long time get to come on the show.

00:02:09.640 --> 00:02:10.680
I love it.

00:02:10.680 --> 00:02:20.340
So we're going to talk about narwhals and data science, data frame, libraries, and basically coming up with a way to write,

00:02:20.340 --> 00:02:27.000
consistent code against all these different libraries, which I think is an awesome goal, which is why I'm having you on the show, of course.

00:02:27.000 --> 00:02:30.160
Before we get to all that, as you know, let's hear a little bit about yourself.

00:02:30.160 --> 00:02:30.700
Sure.

00:02:30.700 --> 00:02:32.160
So, yeah, my name is Marco.

00:02:32.580 --> 00:02:41.560
I work at a company called Quantsite Labs, which supports several open source projects and also offers some training and consulting services.

00:02:41.560 --> 00:02:47.880
I live in Cardiff in Wales and been at Quantsite for about two years now.

00:02:47.880 --> 00:02:55.520
Originally hired as a Pandas maintainer, but then shifted considerably towards some other projects such as Polars.

00:02:55.520 --> 00:03:01.380
And then in February of this year, I tried releasing this narwhals library as a bit of an experiment.

00:03:01.840 --> 00:03:04.020
It's growing a bit faster than expected.

00:03:04.020 --> 00:03:07.440
Yeah, it's a really interesting project.

00:03:07.440 --> 00:03:09.880
Quantsite is quite the place.

00:03:09.880 --> 00:03:14.800
You know, I didn't really know about y'all before having people on the show from there.

00:03:14.800 --> 00:03:16.060
But here's my experience.

00:03:16.180 --> 00:03:19.560
I've had I reach out to say some of the Jupyter folks, whatever.

00:03:19.560 --> 00:03:21.540
Let's have let's have some of the Jupyter people on.

00:03:21.540 --> 00:03:23.880
There's three or four people from Quantsite show up.

00:03:23.880 --> 00:03:26.240
And then, oh, let's talk about this other project.

00:03:26.240 --> 00:03:28.920
Another person from Quantsite two weeks later.

00:03:28.920 --> 00:03:30.240
And then you're from Quantsite.

00:03:30.240 --> 00:03:34.200
And none of those connections were like, let me try to find people from Quantsite.

00:03:34.200 --> 00:03:37.300
I think you all are having a pretty big impact in the data science space.

00:03:37.300 --> 00:03:37.760
That's cool.

00:03:37.760 --> 00:03:41.020
Yeah, it is a bit amusing in the internal Slack channel.

00:03:41.020 --> 00:03:43.980
If you ask a question, does anyone know how to do this?

00:03:44.360 --> 00:03:48.020
Someone will reply, oh, yeah, let me ping this person who's a maintainer of that library.

00:03:48.020 --> 00:03:49.040
And you're like, okay, well.

00:03:49.040 --> 00:03:49.300
Exactly.

00:03:49.300 --> 00:03:51.640
I think we know how it works.

00:03:51.640 --> 00:03:52.580
Let's ask them.

00:03:52.580 --> 00:03:53.640
Yeah, exactly.

00:03:53.640 --> 00:03:57.720
Yeah, it's a big world, but also a small world in interesting ways.

00:03:57.720 --> 00:03:58.300
Yeah.

00:03:58.300 --> 00:04:00.520
How did you get into programming in the first place?

00:04:00.520 --> 00:04:04.560
I think the first experience with programming I had was at university.

00:04:04.560 --> 00:04:05.640
So I studied maths.

00:04:05.640 --> 00:04:07.400
I think like you as well.

00:04:07.400 --> 00:04:08.040
Yeah, yeah, yeah.

00:04:08.040 --> 00:04:08.900
That sounds really.

00:04:08.900 --> 00:04:09.700
Yeah, keep going.

00:04:09.700 --> 00:04:10.800
So far, you're telling my story.

00:04:10.800 --> 00:04:12.100
Yeah, sure.

00:04:12.600 --> 00:04:16.360
Although my initial encounter with it, I didn't, I'm not quite particularly enjoyed it.

00:04:16.360 --> 00:04:19.280
It was just having to solve some problems in MATLAB.

00:04:19.280 --> 00:04:24.600
I did find it kind of satisfying that if you gave it instructions, it did exactly that.

00:04:24.600 --> 00:04:29.040
But I wouldn't say that I felt like naturally talented or anything.

00:04:29.040 --> 00:04:36.560
I then really took to programming, though, after I started a maths PhD and dropped out because it wasn't really going anywhere.

00:04:36.560 --> 00:04:42.540
And once I went deeper into programming, then I realized, okay, actually, I do have some affinity for this topic.

00:04:42.540 --> 00:04:43.840
I do quite enjoy it.

00:04:43.840 --> 00:04:44.340
Yeah.

00:04:44.340 --> 00:04:45.320
I think that's often the case.

00:04:45.500 --> 00:04:47.460
What was your PhD focus before you dropped out?

00:04:47.460 --> 00:04:52.760
It was meant to be, well, some applied mathematics, like stochastic partial differential equations.

00:04:52.760 --> 00:04:55.560
But, you know, in academia, you publish or perish.

00:04:55.560 --> 00:04:59.360
And I wasn't publishing and didn't really see that changing.

00:04:59.360 --> 00:05:02.040
So I had to make a bit of a pivot.

00:05:02.040 --> 00:05:04.860
I imagine you made a pretty good choice, just guessing.

00:05:05.020 --> 00:05:10.040
I mean, I love math, but the options are just so much broader outside of academia.

00:05:10.040 --> 00:05:17.760
In hindsight, yeah, I kind of wish that somebody at the time had told me that I could have still had a really interesting and rewarding career outside of academia.

00:05:17.760 --> 00:05:26.060
And I shouldn't have stressed myself out so much about trying to find a PhD or about having to complete it when I had already started it.

00:05:26.060 --> 00:05:31.280
The secret, I think, about being a good programmer is it's kind of like grad school anyway.

00:05:31.280 --> 00:05:33.940
You're constantly studying and learning.

00:05:34.080 --> 00:05:35.920
You feel like you've figured something out.

00:05:35.920 --> 00:05:36.860
It's like, well, that's changed.

00:05:36.860 --> 00:05:37.780
Now on to the next thing.

00:05:37.780 --> 00:05:39.440
You're kind of like, well, we figured out pandas.

00:05:39.440 --> 00:05:40.200
Now we got polars.

00:05:40.200 --> 00:05:42.560
Okay, well, we're going to start over and figure out how to use that one.

00:05:42.560 --> 00:05:42.880
All right.

00:05:42.880 --> 00:05:44.780
So that is true.

00:05:44.780 --> 00:05:48.400
You need to do a lot of learning, a lot of self-directed learning in particular.

00:05:48.400 --> 00:05:50.880
It's really stimulating, I must say.

00:05:50.880 --> 00:05:51.420
It is.

00:05:51.420 --> 00:05:52.780
It's great if you want that.

00:05:52.780 --> 00:05:55.580
If you want to just nine to five, you don't need to stress about.

00:05:55.580 --> 00:05:58.140
Look, I think there's actually options there.

00:05:58.140 --> 00:05:59.620
We'll get to narwhals in a second.

00:05:59.620 --> 00:06:00.780
But I think there are options there.

00:06:00.880 --> 00:06:10.160
I think if you want to do COBOL, FORTRAN, some of these older programming languages where so much of the world depends on them, but nobody wants to do them.

00:06:10.660 --> 00:06:15.400
You could totally own that space and make really good money if you didn't want to learn anything.

00:06:15.400 --> 00:06:17.080
But where's the fun in that, right?

00:06:17.080 --> 00:06:18.880
Yeah.

00:06:18.880 --> 00:06:21.720
It would be nice if we could all get rid of our legacy systems.

00:06:21.720 --> 00:06:24.160
But, you know, this stuff does power the world.

00:06:24.160 --> 00:06:26.200
They're there for a reason, right?

00:06:26.200 --> 00:06:27.400
That works.

00:06:27.400 --> 00:06:29.280
I would really like it if you don't touch it, please.

00:06:29.280 --> 00:06:32.900
But that's not the way it is with narwhals.

00:06:32.900 --> 00:06:38.360
Let's start with an overview of what narwhals is and why you created it.

00:06:38.360 --> 00:06:42.480
And then I want to talk a bit about some of the data science libraries before we get too much deeper.

00:06:42.480 --> 00:06:43.380
What is narwhals?

00:06:43.380 --> 00:06:46.040
A narwhal is a cool whale as far as I know.

00:06:46.040 --> 00:06:48.960
It's like the unicorn of the sea, basically.

00:06:48.960 --> 00:06:50.740
What is this library?

00:06:51.920 --> 00:06:56.420
So it's intended as a compatibility layer between different data frame libraries.

00:06:56.420 --> 00:07:00.200
So narwhals does not do any computation itself.

00:07:00.200 --> 00:07:04.080
It's more of just a wrapper around different data frame APIs.

00:07:04.080 --> 00:07:09.860
And I like the Polar's API, so I figured that I should keep it fairly close to the Polar's API,

00:07:09.860 --> 00:07:12.300
and in particular, to Polar's expressions.

00:07:12.300 --> 00:07:18.580
As to why narwhals, so I was just getting frustrated with the fact that there's,

00:07:19.000 --> 00:07:23.200
let's say about a year ago, there were relatively few libraries that supported Polar's.

00:07:23.200 --> 00:07:30.320
And if libraries did support Polar's, it was often just done by converting to pandas or converting to pyarrow.

00:07:30.320 --> 00:07:34.740
Yet a lot of these libraries, they weren't doing anything that complicated with data frames.

00:07:34.740 --> 00:07:38.620
A lot of data frame consuming libraries, they don't really want to do that much.

00:07:38.620 --> 00:07:40.300
They want to select columns.

00:07:40.300 --> 00:07:42.060
They want to select rows.

00:07:42.060 --> 00:07:43.820
Maybe they want to do some aggregations.

00:07:43.820 --> 00:07:46.800
Like they're not doing stuff that's completely wild.

00:07:46.800 --> 00:07:57.920
And so trying to design some minimal compatibility layer, I think, is a lot easier than trying to make a full-blown data frame API that end users are meant to use.

00:07:57.920 --> 00:08:00.840
So the idea with narwhals is this is a tool for tool builders.

00:08:01.360 --> 00:08:12.520
If library maintainers want to support different data frame libraries as inputs with minimal overhead and with minimal maintenance required on their side, this is the problem we're trying to solve.

00:08:12.520 --> 00:08:20.920
It's a great problem to solve because maybe you want to have a library that works with an abstract concept of a data frame.

00:08:20.920 --> 00:08:25.920
But usually I would imagine you have to start out and say, are we going to go and support Polar's?

00:08:25.920 --> 00:08:27.420
Are we going to support pandas?

00:08:27.420 --> 00:08:28.660
And the APIs are different.

00:08:28.660 --> 00:08:31.620
Not just the APIs, but the behaviors.

00:08:31.620 --> 00:08:37.320
For example, the lazy execution of Polar's versus the eager execution of pandas.

00:08:37.320 --> 00:08:42.580
And so being able to just write your library so it takes you there is probably a big hassle, right?

00:08:42.580 --> 00:08:46.600
Because it's just kind of have to have almost two versions each step, right?

00:08:46.600 --> 00:08:47.560
Yeah, exactly.

00:08:47.560 --> 00:08:56.400
Well, I actually heard from a maintainer recently who was saying that he was interested in using narwhals even just to have pandas as a dependency.

00:08:56.400 --> 00:09:00.740
Because pandas, the API changes a bit between versions.

00:09:00.740 --> 00:09:05.040
And he was getting a bit tired of pandas' API changes.

00:09:05.040 --> 00:09:16.440
And was like, okay, well, if we can just defer all of the version checks and API differences to an abstraction there that might even simplify our life, even if we're just interested in supporting pandas.

00:09:16.440 --> 00:09:17.520
Yeah, that's cool.

00:09:17.520 --> 00:09:20.180
Yeah, actually, that's an interesting idea.

00:09:20.180 --> 00:09:22.960
It's just like, we'll have a compatibility later, just in case.

00:09:22.960 --> 00:09:30.780
And pandas went from one to two on major version recently, which is a big deal, and switched to PyArrow and all that, right?

00:09:30.780 --> 00:09:36.060
Yeah, so version two, it was sometime last year, I think, 2023.

00:09:36.060 --> 00:09:40.800
So yeah, the PyArrow, I think there were some misconceptions around that.

00:09:40.800 --> 00:09:46.020
So as we're live on air, let's take the chance to address some PyArrow misconceptions.

00:09:46.840 --> 00:09:52.380
PyArrow in pandas currently is optional, and it'll probably stay optional for quite a while.

00:09:52.380 --> 00:09:59.860
So there is some talk about in version three using PyArrow strings instead of the classical NumPy object strings.

00:09:59.860 --> 00:10:04.540
By default, if people have PyArrow installed, it's not totally decided.

00:10:04.540 --> 00:10:07.980
It's not totally set in stone whether PyArrow will be a required dependency.

00:10:08.500 --> 00:10:14.240
And maybe pandas version four will have it as a required dependency, and it'll be the default everywhere.

00:10:14.240 --> 00:10:16.520
But that's a few years away.

00:10:16.520 --> 00:10:17.180
Yeah, maybe.

00:10:17.180 --> 00:10:19.400
Maybe we'll get Python four as well.

00:10:19.400 --> 00:10:20.000
You never know.

00:10:20.720 --> 00:10:22.080
You know, it's interesting.

00:10:22.080 --> 00:10:29.520
I think the data science space, more than many other areas, has this ability to run Python in more places, right?

00:10:29.520 --> 00:10:33.040
For example, there's Pyodide, there's Jupyter Lite.

00:10:33.040 --> 00:10:37.060
There's a lot of more constrained environments that it might go in.

00:10:37.060 --> 00:10:41.360
And I don't know what the story of PyArrow and WASM and all these different things.

00:10:41.360 --> 00:10:43.560
You tell me you still get benefits there.

00:10:43.560 --> 00:10:44.900
But there's a lot to consider.

00:10:44.900 --> 00:10:45.720
Yeah, totally.

00:10:45.720 --> 00:10:52.680
And I think that's one reason why some library maintainers are really drawn to a lightweight compatibility layer like narwhals.

00:10:52.680 --> 00:10:55.640
With narwhals, you say you don't need any dependencies.

00:10:55.640 --> 00:10:58.560
You need narwhals, but that's just a bunch of Python files.

00:10:58.560 --> 00:11:01.200
Like if you wanted to, you could even just vendor narwhals.

00:11:01.200 --> 00:11:05.860
Like it's not that big of a deal, but there's no extra dependencies required.

00:11:05.860 --> 00:11:10.520
Like pandas users don't need polas installed, and polas users don't need pandas installed.

00:11:10.520 --> 00:11:26.000
So if you're trying to deploy to a constrained environment where package size is limited, like if a library has narwhals as a required dependency, as opposed to any big data frame library, and then the user can just bring their own data frame.

00:11:26.000 --> 00:11:32.180
Then like this, we're really minimizing the number of installation and dependency hell issues that people might run into.

00:11:32.180 --> 00:11:35.760
I think you've covered dependency hell on the show a few times before.

00:11:35.760 --> 00:11:44.140
Yeah, indeed. I think one thing that's interesting for people out there listening, we'll talk about the different libraries that it works with right now.

00:11:44.140 --> 00:11:56.320
But if you have a library out there and you're listening, there's not too much work to integrate it into or make it narwhal compatible, narwhalification of a library to let it do this interchange, right?

00:11:56.600 --> 00:12:00.180
So I think I can interpret your question in a couple of ways.

00:12:00.180 --> 00:12:02.020
So I'll just play them back and let's just see.

00:12:02.020 --> 00:12:03.460
Let's do it.

00:12:03.460 --> 00:12:06.140
One is if you're a library that consumes data frames.

00:12:06.140 --> 00:12:10.540
So yeah, there's some examples there on the readme of who's adopted narwhals.

00:12:10.540 --> 00:12:14.360
So like Altair is the most recent, probably the most famous one.

00:12:14.360 --> 00:12:21.400
I think that's where I heard of it was when I was, some news about Altair and narwhals together is actually how I heard of narwhals.

00:12:21.400 --> 00:12:30.660
Okay, yeah. So yeah. And how complicated that is really depends on how complicated the data frame operations this library is doing.

00:12:30.660 --> 00:12:34.020
In the case of Altair, they weren't doing anything that was that crazy.

00:12:34.020 --> 00:12:44.520
They needed to inspect the data types, select some columns, convert date times to strings, get the unique categories out of categoricals.

00:12:44.520 --> 00:12:51.940
It wasn't that bad. So I think within a few weeks we were able to do it. Same story with Psychic Lego.

00:12:51.940 --> 00:12:57.860
There's some other libraries that have reached out that have shown interest where it's going to be a bit of a heavier lift,

00:12:57.860 --> 00:13:03.500
but it's generally not as bad as I thought it was going to be when I started the project.

00:13:03.500 --> 00:13:11.740
The other way that I think I might have interpreted your question is how difficult is it for a new data frame library to become narwhals compatible?

00:13:11.740 --> 00:13:12.580
Yes.

00:13:12.580 --> 00:13:14.420
And there's a couple of ways that they can go about doing that.

00:13:14.420 --> 00:13:21.780
The preferred way is if they either write to us or open a pull request, adding their library as a backend in narwhals.

00:13:21.780 --> 00:13:26.420
However, we love open source, but I don't consider myself an open source absolutist.

00:13:26.420 --> 00:13:29.400
I understand that not everything can be open sourced.

00:13:29.500 --> 00:13:38.220
So if somebody has a closed source solution, we do have an extensibility mechanism within narwhals such that somebody just needs to implement some dunder methods.

00:13:38.220 --> 00:13:45.520
And then if they pass the data frame into a library that's been narwhalified, then narwhals will know how to glue things together.

00:13:45.520 --> 00:13:50.880
And they'll be able to still support this closed source solution without it needing to go out into the open.

00:13:51.020 --> 00:13:57.640
Right. It's kind of something like inheriting from a class and implementing some functions and then it knows, right?

00:13:57.640 --> 00:13:58.300
Yeah, exactly.

00:13:58.300 --> 00:13:59.580
Yeah. Yeah. Cool.

00:13:59.860 --> 00:14:07.760
So right now it has full API support for CUDAF, C-U-D-F. I'm guessing that's CUDA data frame library?

00:14:07.760 --> 00:14:11.300
Yeah, I'm not totally sure how we're supposed to pronounce it. I call it CUDAF.

00:14:11.300 --> 00:14:17.280
Yeah, that came out of the Rapids team at NVIDIA. It's like an accelerated version of Pandas on GPU.

00:14:17.280 --> 00:14:18.980
Yeah, that's been quite a fun one.

00:14:18.980 --> 00:14:21.560
Nice. Yeah, I bet. That's pretty wild.

00:14:22.820 --> 00:14:27.960
The API is quite similar to Pandas, but it's not exactly the same. So we have to do a bit of working around.

00:14:27.960 --> 00:14:34.000
Right, right. Because graphics cards are not just regular memory and regular programs. They're weird, right?

00:14:34.000 --> 00:14:39.420
Yeah, that's part of it. So there's some parts of the Pandas API which they intentionally don't support.

00:14:39.420 --> 00:14:46.360
And there's another part of it is just that the Pandas API is so extensive that it's just a question of resources.

00:14:46.700 --> 00:14:57.180
It's pretty difficult to reimplement 100% of the Pandas API. But Moden does attempt to do that. Moden does tell itself as a drop-in replacement for Pandas.

00:14:57.180 --> 00:15:05.440
In practice, I think they do have a section in their docs where they do mention some gotchas, some slight differences.

00:15:05.900 --> 00:15:17.040
But that's the idea. They've kind of got their own intermediate representation, and they've got their algebra, which they've published a paper about, which they then map onto the Pandas API.

00:15:17.040 --> 00:15:23.340
A pretty interesting project that was a lot easier to support. The way they mimic the Pandas API is a lot closer.

00:15:23.340 --> 00:15:33.000
But it's been interesting. Like with novels, we did find a couple of minor bugs in Moden just by running our test suite through the different libraries, which we then reported to them and they fixed very quickly.

00:15:33.000 --> 00:15:34.960
That's pretty awesome. Yeah, yeah. That's super awesome.

00:15:34.960 --> 00:15:40.800
So Moden lets you use Ray, Dask, or Unidisk. Unidisk.

00:15:40.800 --> 00:15:45.260
Two of, one of which I know. One of which I've heard of. Two of which I've heard of.

00:15:45.260 --> 00:15:52.620
So I was going to ask about things like Dask and others, which are sort of themselves extensions of InDesk.

00:15:52.620 --> 00:15:57.460
But if you support Moden, you're kind of through one more layer supporting Dask.

00:15:57.680 --> 00:16:04.600
Oh, but it's better. We don't have this on the readme yet, but we do have a level of support for Dask.

00:16:04.600 --> 00:16:10.760
We've not quite put it on the readme yet because we're still kind of defining exactly where the boundaries are.

00:16:10.760 --> 00:16:17.140
But it's going to be some kind of partial, lazy-only layer of support.

00:16:17.600 --> 00:16:19.800
And it's actually quite a nice way to run Dask.

00:16:19.800 --> 00:16:23.380
Like when you're running Dask, there are some things which do trigger compute for you.

00:16:23.380 --> 00:16:27.160
There are some things which may trigger index repartitioning.

00:16:27.160 --> 00:16:28.220
I think that's what it's called.

00:16:28.220 --> 00:16:33.060
And in NowWals, we've just been extremely careful that if you're able to stick to the NowWals API,

00:16:33.060 --> 00:16:36.120
then what you're doing is going to be performant.

00:16:36.820 --> 00:16:38.180
Awesome. Yeah, that's super cool.

00:16:38.180 --> 00:16:44.260
So one thing I think worth maybe pointing out here is you talked about Pandas, Pandas 1, Pandas 2,

00:16:44.260 --> 00:16:46.140
and it being an extensive API.

00:16:46.140 --> 00:16:49.480
I mentioned the eager versus lazy computation.

00:16:49.480 --> 00:16:54.420
But these two libraries are maybe some of the most popular ones,

00:16:54.420 --> 00:16:56.720
but they're pretty different in their philosophy.

00:16:56.720 --> 00:17:01.200
So maybe just could you just quick compare and contrast Polars versus Pandas?

00:17:01.200 --> 00:17:02.600
Yeah, sure.

00:17:02.600 --> 00:17:11.960
So Pandas started a lot earlier, I think, in 2008, maybe first released in 2009,

00:17:11.960 --> 00:17:16.580
and originally really written heavily around NumPy.

00:17:16.580 --> 00:17:20.960
And you can see this in the classical Pandas NumPy data types.

00:17:20.960 --> 00:17:25.460
So the support for missing values is fairly inconsistent across types.

00:17:25.460 --> 00:17:27.540
So you brought up PyArrow before.

00:17:27.540 --> 00:17:32.220
So with the PyArrow data types, then we do get consistent missing value handling in Pandas.

00:17:32.500 --> 00:17:34.420
But for the classical NumPy ones, we don't.

00:17:34.420 --> 00:17:36.160
Polars started a lot later.

00:17:36.160 --> 00:17:42.880
It didn't have a lot of backwards compatibility concerns to have to worry about.

00:17:42.880 --> 00:17:44.940
So it could make a lot of good decisions up front.

00:17:44.940 --> 00:17:47.240
It's generally a lot stricter than Pandas.

00:17:47.240 --> 00:17:55.180
And in particular, there's a lot of strictness and the kinds of ways it lets you interact with its subjects.

00:17:55.180 --> 00:18:02.880
So in Pandas, the way we interact with data frames is we typically extract a series as one-dimensional objects.

00:18:02.880 --> 00:18:04.580
We then manipulate those series.

00:18:04.580 --> 00:18:07.160
Maybe we put them back into the original data frame.

00:18:07.160 --> 00:18:09.000
But we're doing everything one step at a time.

00:18:09.300 --> 00:18:16.160
In Polars, the primary way that we interact with data frames is with what you've got there on the screen.

00:18:16.160 --> 00:18:17.840
PL.col, AB.

00:18:17.840 --> 00:18:19.160
These are called expressions.

00:18:19.160 --> 00:18:22.320
And that expression, my mental model for it is just a function.

00:18:22.320 --> 00:18:24.680
It's a function from a data frame to a series.

00:18:24.680 --> 00:18:25.660
And being a function...

00:18:25.660 --> 00:18:27.060
It's like a generator or something, huh?

00:18:27.060 --> 00:18:27.760
Yeah, kind of.

00:18:27.760 --> 00:18:27.920
Yeah.

00:18:27.920 --> 00:18:33.680
So although I think when you say generator, like in Python, a generator, it's at some point you can consume it.

00:18:33.680 --> 00:18:36.400
Like you can type next on the generator and it produces a value.

00:18:36.400 --> 00:18:38.500
But an expression doesn't produce a value.

00:18:38.500 --> 00:18:41.340
It's like if you've got lambda x, x times two.

00:18:41.340 --> 00:18:41.620
Yeah.

00:18:41.620 --> 00:18:44.100
It doesn't produce a value until you give it an input.

00:18:44.100 --> 00:18:47.700
And similarly, an expression like PL.col, A, B.

00:18:47.700 --> 00:18:49.380
By itself, it doesn't do anything.

00:18:49.380 --> 00:18:54.340
The interpretation is given some data frame DF, I'll return you the columns A and B.

00:18:54.580 --> 00:18:57.920
So it only produces those columns once you give it some input data frame.

00:18:57.920 --> 00:19:02.960
And functions, just by their very definition, are lazy, kind of.

00:19:02.960 --> 00:19:05.100
Like you don't need to evaluate them straight away.

00:19:05.100 --> 00:19:07.720
And so Polers can take a look at all of the things you want to do.

00:19:07.720 --> 00:19:10.640
It can recognize some optimization patterns.

00:19:10.640 --> 00:19:15.680
It can recognize that maybe between some of your expressions, there are some parts that are repeated.

00:19:15.680 --> 00:19:18.940
And so instead of having to recompute the same thing multiple times,

00:19:18.940 --> 00:19:22.700
it can just compute it once and then reuse that between the different expressions.

00:19:23.480 --> 00:19:32.340
Yeah, that's one of the big features of big capabilities of Polers is that it has kind of a query engine optimizer in there.

00:19:32.340 --> 00:19:36.240
Whereas Pandas, because it's not lazy, it just does one thing, then the next, the next.

00:19:36.240 --> 00:19:41.840
But maybe if you switch the order, like first filter and then compute versus compute and then filter,

00:19:41.840 --> 00:19:44.060
you might get a way better outcome, right?

00:19:44.280 --> 00:19:45.460
That's a massive one, yeah.

00:19:45.460 --> 00:19:49.540
So when I was doing some benchmarking, we brought up QDF earlier.

00:19:49.540 --> 00:19:51.960
So that's the GPU accelerated version of Pandas.

00:19:51.960 --> 00:19:57.020
And that is super fast if you're just doing single operations one at a time in a given order.

00:19:57.020 --> 00:20:02.980
However, there are some benchmarks where maybe you're having to join together multiple data frames,

00:20:02.980 --> 00:20:07.060
and then you're only selecting certain rows.

00:20:07.200 --> 00:20:12.620
At that point, it's actually faster to just do it on a CPU using a lazy library like Polers,

00:20:12.620 --> 00:20:14.820
because Polers can do the query optimization.

00:20:14.820 --> 00:20:20.760
It can figure out that it needs to do the filter and only keep certain rows before doing five gigantic joins.

00:20:20.760 --> 00:20:25.420
Whereas QDF, it's super fast on GPU, but it is all eagerly executed.

00:20:25.420 --> 00:20:28.760
It did way more work, but it did it really fast, so it was about the same in the end.

00:20:29.240 --> 00:20:33.020
Yeah, but now in Polers, there's going to be GPU support.

00:20:33.020 --> 00:20:37.060
And it's going to be query optimized GPU support.

00:20:37.060 --> 00:20:39.160
I don't know if the world is ready for this level of speed.

00:20:39.160 --> 00:20:41.680
Yeah, that's going to be interesting.

00:20:41.680 --> 00:20:46.560
This portion of Talk Python is brought to you by WorkOS.

00:20:46.560 --> 00:20:49.340
If you're building a B2B SaaS app, at some point,

00:20:49.340 --> 00:20:53.500
your customers will start asking for enterprise features like SAML authentication,

00:20:53.500 --> 00:20:57.260
SKIM provisioning, autologs, and fine-grained authorization.

00:20:57.860 --> 00:21:02.560
That's where WorkOS comes in, with easy-to-use APIs that'll help you ship enterprise features

00:21:02.560 --> 00:21:06.400
on day one without slowing down your core product development.

00:21:06.400 --> 00:21:10.860
Today, some of the fastest-growing startups in the world are powered by WorkOS,

00:21:10.860 --> 00:21:14.760
including ones you probably know, like Perplexity, Vercel, and Webflow.

00:21:14.760 --> 00:21:21.080
WorkOS also provides a generous free tier of up to 1 million monthly active users for AuthKit,

00:21:21.080 --> 00:21:24.460
making it the perfect authentication layer for growing companies.

00:21:24.540 --> 00:21:29.880
It comes standard with useful features like RBAC, MFA, and bot protection.

00:21:29.880 --> 00:21:34.020
If you're currently looking to build SSO for your first enterprise customer,

00:21:34.020 --> 00:21:35.880
you should consider using WorkOS.

00:21:35.880 --> 00:21:40.080
Integrate in minutes and start shipping enterprise plans today.

00:21:40.080 --> 00:21:43.360
Just visit talkpython.fm/workos.

00:21:43.360 --> 00:21:45.340
The link is in your podcast player's show notes.

00:21:45.340 --> 00:21:47.580
Thank you to WorkOS for supporting the show.

00:21:48.080 --> 00:21:53.060
I guess another difference, it's not a massive, you know, in some ways it matters,

00:21:53.060 --> 00:21:58.040
some ways it doesn't, is Pandas is based on C extensions, right?

00:21:58.040 --> 00:21:59.940
I'm guessing, if I remember right.

00:21:59.940 --> 00:22:05.880
And then Poolers is Rust, and they even took the .rs extension for their domain,

00:22:05.880 --> 00:22:07.880
which is really embracing it.

00:22:08.120 --> 00:22:14.280
Not that it really matters, you know, what your native layer is, if you're not working in that, right?

00:22:14.280 --> 00:22:17.940
Like, most Python people don't work in C or Rust, but it's still interesting.

00:22:17.940 --> 00:22:23.600
Well, I think it, yeah, it is interesting, but also it can be useful for users to know this,

00:22:23.600 --> 00:22:26.160
because Poolers has a really nice plugin system.

00:22:26.160 --> 00:22:31.120
So you can extend Poolers with your own little expressions, which you can write in Rust.

00:22:31.560 --> 00:22:34.880
And the amount of Rust that you need to do this is really quite minimal.

00:22:34.880 --> 00:22:38.680
Like, if you try to write these Poolers plugins as if you were writing Python,

00:22:38.680 --> 00:22:42.000
and then just use some LLM or something to guide you,

00:22:42.000 --> 00:22:48.160
I think, realistically, most data scientists can solve 98% of their inefficient data frame usage

00:22:48.160 --> 00:22:49.420
by using Poolers plugins.

00:22:49.420 --> 00:22:54.080
So having a nice, safe language that you can do this, it really makes a difference.

00:22:54.080 --> 00:22:58.420
I'm going to write it in Python, and then I'm going to ask some LLM.

00:22:58.420 --> 00:23:01.840
Right now I'm using LLM Studio and I think Llama 3.

00:23:01.840 --> 00:23:06.100
Anyway, ask it, say, okay, write this in Rust for me.

00:23:06.100 --> 00:23:07.380
Write it as a Polers plugin.

00:23:07.380 --> 00:23:08.060
Here we go.

00:23:08.060 --> 00:23:08.480
All right.

00:23:08.480 --> 00:23:09.580
Yeah, exactly.

00:23:09.580 --> 00:23:11.200
It's crazy.

00:23:11.200 --> 00:23:12.540
It's this new world we live in.

00:23:12.540 --> 00:23:13.240
Yeah, yeah, totally.

00:23:13.240 --> 00:23:18.460
I mean, like, the amount of Rust knowledge you need to take care of some of the complicated

00:23:18.460 --> 00:23:20.360
parts in Polers is really advanced.

00:23:20.360 --> 00:23:23.400
Really need to study for that, and LLM isn't going to solve it for you.

00:23:23.400 --> 00:23:29.820
But the amount of Rust that you need to just make a plugin to solve some inefficient function,

00:23:29.820 --> 00:23:30.920
I think that's doable.

00:23:30.920 --> 00:23:31.520
Right.

00:23:31.520 --> 00:23:32.140
Yeah, exactly.

00:23:32.140 --> 00:23:35.460
It's very different to say, we're going to just do this loop in this function call here

00:23:35.460 --> 00:23:39.920
versus there, rather than I'm going to write a whole library in Rust or C or whatever.

00:23:39.920 --> 00:23:40.900
Exactly.

00:23:41.280 --> 00:23:45.020
Yeah, so there's a pretty different API between these.

00:23:45.020 --> 00:23:50.000
And in Narwhals, it looks like you've adopted the Rust API, right?

00:23:50.000 --> 00:23:51.300
A subset of it.

00:23:51.300 --> 00:23:51.860
Is that right?

00:23:51.860 --> 00:23:53.700
The Polers one, yes, exactly.

00:23:53.700 --> 00:23:55.780
So I kind of figured we've got a few choices.

00:23:55.780 --> 00:23:56.540
That's what I mean.

00:23:56.540 --> 00:23:57.780
Yeah, the Polers one.

00:23:57.780 --> 00:23:58.620
Yeah, yeah.

00:23:58.620 --> 00:24:00.700
We can either, like, just choose the Pandas API.

00:24:00.700 --> 00:24:06.200
But to be honest, I found that trying to translate the Pandas API to Polers was fairly painful.

00:24:06.200 --> 00:24:12.440
Like, Pandas has a bunch of extra things, like the index, multi-index, and it does index alignment on all the operations.

00:24:12.440 --> 00:24:18.000
I just found it not a particularly pleasant experience to try to map this onto Pandas.

00:24:18.000 --> 00:24:22.100
However, when I tried to do the reverse of translating the Polers API to Pandas,

00:24:22.100 --> 00:24:25.100
it kind of just worked without that much effort.

00:24:25.100 --> 00:24:26.520
And I was like, oh, wow, this is magic.

00:24:26.520 --> 00:24:29.600
Okay, let's just take this a bit further, publish it on GitHub.

00:24:29.600 --> 00:24:31.900
Maybe somebody would find a use case for it.

00:24:31.900 --> 00:24:32.500
I don't know.

00:24:32.500 --> 00:24:33.360
Yeah, that's great.

00:24:33.360 --> 00:24:34.180
Out of the audience.

00:24:34.660 --> 00:24:38.540
ZigZackJack asks, how is Narwhals different from IBIS?

00:24:38.540 --> 00:24:39.260
All right.

00:24:39.260 --> 00:24:41.440
The number one most common question.

00:24:41.440 --> 00:24:41.960
Love this.

00:24:41.960 --> 00:24:42.700
Is it?

00:24:42.700 --> 00:24:43.280
Okay, great.

00:24:43.280 --> 00:24:43.800
Yeah.

00:24:43.800 --> 00:24:47.960
Maybe we should provide a bit of context for the listeners on what is IBIS.

00:24:47.960 --> 00:24:52.200
So IBIS, yes, you can see there on the screen, they describe themselves as the portable data frame library.

00:24:52.200 --> 00:24:57.780
So IBIS is really aiming to be a data frame library, just like Pandas, just like Polers.

00:24:57.780 --> 00:25:02.280
But it's got this API, which can then dispatch to different backends.

00:25:02.280 --> 00:25:08.100
The default one is DuckDB, which is a really powerful embedded analytics database.

00:25:08.100 --> 00:25:09.660
I think you covered it on the show.

00:25:09.660 --> 00:25:12.920
In fact, I think I might have first heard about DuckDB on Python Bytes.

00:25:12.920 --> 00:25:17.400
So listeners, if you want to stay up to date, subscribe to Python Bytes.

00:25:17.400 --> 00:25:18.500
Thank you.

00:25:18.780 --> 00:25:18.940
Yeah.

00:25:18.940 --> 00:25:20.700
One of the shows I almost never miss.

00:25:20.700 --> 00:25:26.620
So yeah, I think the primary difference between Narwhals and IBIS is the target audience.

00:25:26.620 --> 00:25:32.400
So with IBIS, they're really trying to be this full-blown data frame that people can use to do their analyses.

00:25:33.060 --> 00:25:42.820
Whereas with Narwhals, I'm openly saying to end users, like if you're an end user, if you're a data scientist, if you're an ML engineer, if you're a data analyst, don't use Narwhals.

00:25:43.820 --> 00:25:55.520
It's a tool for tool builders, like learn Polers, learn DuckDB, learn whatever the best tool is for your particular task and learn it well and master that and do your analyses.

00:25:55.520 --> 00:26:03.100
On the other hand, if you're a tool builder and you just need to do some simple operations with data frames and you want to empower your...

00:26:03.100 --> 00:26:11.660
If you want to enable your users to use your tool, regardless of which library they're starting with, then Narwhals can provide a nice bridge between them.

00:26:11.660 --> 00:26:12.200
Interesting.

00:26:12.200 --> 00:26:16.380
Is there any interoperability between IBIS and Narwhals?

00:26:16.380 --> 00:26:18.840
We do have some level of support for IBIS.

00:26:18.840 --> 00:26:29.760
And at the moment, this is just interchange level support in the sense that if you pass a IBIS data frame, then you can inspect the schema, not do much else.

00:26:30.140 --> 00:26:33.360
But for the Altair use case, that's all they needed.

00:26:33.360 --> 00:26:39.160
Like they just wanted to inspect the schema, make some decisions on how to encode some different columns.

00:26:39.160 --> 00:26:49.140
And then depending on how long your data frame is, they might convert to PyArrow and dispatch to a different library called Vega Fusion, or they might just do everything within Altair.

00:26:49.380 --> 00:27:04.200
But we found that even just having this relatively minimal level of support for IBIS, Vax, DuckDB, and anything else, anything that implements the data frame interchange protocol was enough to already solve some problems for users of these libraries.

00:27:04.200 --> 00:27:04.760
Yeah.

00:27:04.760 --> 00:27:05.640
Okay.

00:27:05.640 --> 00:27:06.680
Very interesting.

00:27:06.680 --> 00:27:07.920
Let's see.

00:27:07.920 --> 00:27:10.660
We'll hit a few more of the highlights here.

00:27:10.660 --> 00:27:12.500
100% test coverage.

00:27:12.500 --> 00:27:15.600
You already mentioned that you found some bugs in...

00:27:15.600 --> 00:27:16.720
I think it's...

00:27:16.720 --> 00:27:17.120
Which library was it?

00:27:17.120 --> 00:27:17.620
Modian.

00:27:17.620 --> 00:27:18.360
Yeah, yeah, that's right.

00:27:18.360 --> 00:27:19.620
I think all of them.

00:27:19.620 --> 00:27:25.960
I think it's helpful to uncover some rough edge cases in all of the libraries that we have some support for.

00:27:25.960 --> 00:27:29.380
You write a library and you're going to say, I'm going to try to behave like you do.

00:27:29.380 --> 00:27:30.820
And I'll write some tests around that.

00:27:30.820 --> 00:27:34.040
And then when you find the differences, you're like, wait a minute, right?

00:27:34.040 --> 00:27:35.200
Yeah, exactly.

00:27:35.380 --> 00:27:39.980
Also really love to see the let your IDE help you thanks to static typing.

00:27:39.980 --> 00:27:42.840
We'll definitely have to dive into that in a bit as well.

00:27:42.840 --> 00:27:43.920
That looks awesome.

00:27:43.920 --> 00:27:44.380
Cheers.

00:27:44.380 --> 00:27:45.800
Yeah, a huge fan of static typing.

00:27:45.800 --> 00:27:48.540
You know, it's a bit of a controversial topic in some Python circles.

00:27:48.540 --> 00:27:53.840
Some people say that it's not really what Python is meant for and that it doesn't help you prevent bugs and all of that.

00:27:53.840 --> 00:27:55.760
And I can see where these people are coming from.

00:27:55.760 --> 00:28:06.360
But when I've got a statically typed library and my IDE is just always popping up with helpful suggestions and doc strings and all of that, then that's when I really appreciate it.

00:28:06.360 --> 00:28:06.960
Exactly.

00:28:06.960 --> 00:28:08.160
Like, forget the bugs.

00:28:08.160 --> 00:28:15.260
If I don't have to go to the documentation because I hit dot and it's immediately obvious what I'm supposed to do, that's already a win, right?

00:28:15.260 --> 00:28:16.620
And that's typing gives you that.

00:28:16.620 --> 00:28:17.640
Plus it gives you checking.

00:28:17.640 --> 00:28:19.340
Plus it gives you lots of other things.

00:28:19.340 --> 00:28:20.260
I think it's great.

00:28:20.260 --> 00:28:25.180
And especially with your focus on tool builders, tool builders can build tools which have typing.

00:28:25.560 --> 00:28:29.560
They can build better tools using your typing, but they don't because it's optional.

00:28:29.560 --> 00:28:32.560
It's not really forced upon any of the users.

00:28:32.560 --> 00:28:43.960
The only libraries that I can think of that really force typing on their users is Pydantic and FastAPI and a couple of these that like Typer that have behavior driven on the types you put.

00:28:43.960 --> 00:28:49.180
But if you're using that library, you're choosing that as a feature, not a bug, right?

00:28:49.180 --> 00:28:50.100
Yeah, exactly.

00:28:50.100 --> 00:28:50.660
Yeah.

00:28:50.660 --> 00:28:51.400
So awesome.

00:28:51.400 --> 00:28:57.280
And then finally, sticking with the focus on tool builders, perfect backwards compatibility policy.

00:28:57.280 --> 00:28:57.840
What does this mean?

00:28:57.840 --> 00:28:59.980
This is a bit of an ambitious thing.

00:29:00.700 --> 00:29:04.120
So when I was learning Rust, I read about Rust editions.

00:29:04.120 --> 00:29:11.420
So the idea is that when you start a Rust project, you specify the edition of Rust that you want to use.

00:29:11.860 --> 00:29:20.740
And even as Rust gets updated, if you write some project using the 2015 edition of Rust, then it should keep working essentially forever.

00:29:20.740 --> 00:29:22.380
So they keep this edition around.

00:29:22.380 --> 00:29:28.540
And if they have to make backwards incompatible changes, there's new editions like 2018, 2021 editions.

00:29:29.060 --> 00:29:30.600
So this is kind of what we're trying to do.

00:29:30.600 --> 00:29:34.220
Like the idea, the idea was, well, we're kind of mimicking the Polar's API.

00:29:34.220 --> 00:29:40.020
I think there was a bracket I opened earlier, which I might not have finished, which was that the third choice we had was to make an entirely new API.

00:29:40.020 --> 00:29:44.480
But I thought, well, better to give to do something that people are somewhat familiar with.

00:29:44.480 --> 00:29:46.180
Yeah, I think that's a great choice.

00:29:46.180 --> 00:29:46.400
Yeah.

00:29:46.440 --> 00:29:50.680
Because when you go and write the code, half of the people will already know Polar's.

00:29:50.680 --> 00:29:51.880
And so they just keep doing that.

00:29:51.880 --> 00:29:54.600
You don't have to go, well, here's a third thing you have to learn, right?

00:29:54.600 --> 00:29:55.160
Yeah.

00:29:55.160 --> 00:29:59.600
I'd like to think that now half people know Polar's.

00:29:59.600 --> 00:30:03.260
Unfortunately, I think we might not quite be there yet, but it is growing.

00:30:03.260 --> 00:30:03.660
No, I think so too.

00:30:03.660 --> 00:30:04.280
Yeah.

00:30:04.280 --> 00:30:04.840
Yeah, yeah.

00:30:04.840 --> 00:30:05.680
I think we'll get there.

00:30:05.680 --> 00:30:07.720
So yeah, it's okay.

00:30:07.720 --> 00:30:13.100
We're kind of mimicking a subset of the Polar's API and we're just sticking into fundamentals.

00:30:13.100 --> 00:30:15.760
So that part should be relatively stable.

00:30:16.080 --> 00:30:19.800
But at some point, presumably Polar's is going to make a backwards incompatible change.

00:30:19.800 --> 00:30:21.960
And at that point, what do we do in Narwhals?

00:30:21.960 --> 00:30:24.480
What do we do about the top level Narwhals API?

00:30:24.480 --> 00:30:30.560
And coordinating changes between different libraries, it's going to get tricky.

00:30:30.560 --> 00:30:35.500
And the last thing that I want to do is see people put upper bound constraints on the Narwhals library.

00:30:35.500 --> 00:30:40.160
I think upper bound constraints on something like this should never really be necessary.

00:30:40.160 --> 00:30:44.140
So we've tried to replicate what Rust does with its additions.

00:30:44.540 --> 00:30:47.600
The idea is that we've got a stable V1 API.

00:30:47.600 --> 00:30:52.440
We will have a stable V2 API at some point if we need to make backwards incompatible changes.

00:30:52.440 --> 00:31:09.480
But if you write your code using the V1 stable Narwhals API, then even as new Narwhals versions come out, even as the main Narwhals namespace changes, even as we might introduce V2, then your code should, in theory, keep working.

00:31:09.480 --> 00:31:12.220
Like V1 should stay supported indefinitely.

00:31:12.560 --> 00:31:13.400
This is the intention.

00:31:13.400 --> 00:31:14.220
Yeah.

00:31:14.220 --> 00:31:17.560
And you said see the stable API for how to opt in.

00:31:17.560 --> 00:31:21.240
So how do you, I'm just curious what the mechanism is.

00:31:21.240 --> 00:31:26.680
So for example, import Narwhals.stable.v1 as NW, which is the standard Narwhals.

00:31:26.680 --> 00:31:27.000
Yeah, exactly.

00:31:27.000 --> 00:31:28.120
So instead of.

00:31:28.120 --> 00:31:29.000
I got you.

00:31:29.000 --> 00:31:29.480
That's cool.

00:31:29.820 --> 00:31:34.580
Yeah, instead of import Narwhals as NW, you'll do import Narwhals.stable.v1 as NW.

00:31:34.580 --> 00:31:40.740
And yeah, I encourage people when they're just trying it out, prototyping, use import Narwhals as NW.

00:31:40.740 --> 00:31:47.440
If you want to make a release and future-proof yourself, then switch over to the stable.v1.

00:31:47.440 --> 00:32:01.240
This is a little similar to the API.talkpython.fm/v1 slash whatever versus, you know, where people encode a different version in their API endpoints, basically.

00:32:01.240 --> 00:32:02.000
Yeah, yeah.

00:32:02.000 --> 00:32:02.980
In import statements.

00:32:02.980 --> 00:32:03.440
I like it.

00:32:03.440 --> 00:32:03.920
I like it a lot.

00:32:03.920 --> 00:32:04.320
It's great.

00:32:04.320 --> 00:32:05.880
Yeah, let's see how this goes.

00:32:05.880 --> 00:32:06.840
Yeah, exactly.

00:32:06.840 --> 00:32:07.480
Now it's good.

00:32:07.740 --> 00:32:09.880
So just back to typing real quick.

00:32:09.880 --> 00:32:18.680
Pamphil Roy out there says, a lot of open source maintainers complain about typing because if you want to make it really correct, it's painful to add.

00:32:18.680 --> 00:32:19.800
That can be true.

00:32:19.800 --> 00:32:24.160
And so, you know, the last 1% is some insane statement.

00:32:24.160 --> 00:32:26.260
But it's so helpful for end users.

00:32:26.260 --> 00:32:27.420
True, yeah.

00:32:27.420 --> 00:32:29.840
You mentioned earlier that everyone seems to be at QuantSight.

00:32:29.840 --> 00:32:31.500
Do you know where I met Pamphil?

00:32:31.500 --> 00:32:32.520
QuantSight?

00:32:32.520 --> 00:32:34.820
He was an ex-colleague of mine at QuantSight, yes.

00:32:34.820 --> 00:32:35.540
Amazing.

00:32:36.920 --> 00:32:38.260
See, it continues to happen.

00:32:38.260 --> 00:32:38.940
Yeah, exactly.

00:32:38.940 --> 00:32:43.020
But yeah, I think that totally sums it up for me as well.

00:32:43.020 --> 00:32:46.820
You know, it's really great to be using libraries that give you those options.

00:32:46.820 --> 00:32:56.660
You know, we do have the PYI files and we have TypeShed and all of that where people can kind of put typing on things from the outside that didn't want to support it.

00:32:56.660 --> 00:33:00.420
But if it's built in and part of the project, it's just better, you know?

00:33:00.420 --> 00:33:00.880
Yeah.

00:33:00.880 --> 00:33:02.840
If you have it from day one, it works well.

00:33:02.840 --> 00:33:08.840
I mean, trying to add types to a library that started without types like Pandas, it's fairly painful to be honest.

00:33:08.840 --> 00:33:09.640
I bet it is.

00:33:09.640 --> 00:33:10.520
I bet it is.

00:33:10.520 --> 00:33:11.440
Yeah, really cool.

00:33:11.440 --> 00:33:11.700
All right.

00:33:11.900 --> 00:33:16.280
Let's go and talk through, I guess, a quick shout out.

00:33:16.280 --> 00:33:21.840
Just last year, I had Richie Vink, who's the creator of Polars on Talk Python.

00:33:21.840 --> 00:33:26.100
If people want to check that out, they can certainly have a listen to that.

00:33:26.100 --> 00:33:30.660
And I also just recently had Wes McKinney, creator of Pandas, on.

00:33:30.660 --> 00:33:33.040
And I'll link to those shows if people want to, like, dive into those.

00:33:33.180 --> 00:33:35.280
But let's talk a little bit through your documentation.

00:33:35.280 --> 00:33:37.260
It tells a really good story.

00:33:37.260 --> 00:33:43.020
I like what you put down here as, you know, it's not just here's your API and stuff, but it walks you through.

00:33:43.020 --> 00:33:46.700
So we talked about why, obviously, install, pip install.

00:33:46.700 --> 00:33:49.680
It's pure Python with a pure Python wheel, right?

00:33:49.680 --> 00:33:50.560
Yeah, exactly.

00:33:50.560 --> 00:33:52.560
Shouldn't be any issues with installation.

00:33:52.560 --> 00:33:54.520
Is it WASM compatible?

00:33:54.520 --> 00:33:55.060
Do you know?

00:33:55.060 --> 00:33:57.160
Could I use it on PyScript, Pyodide?

00:33:57.160 --> 00:33:58.660
I don't know.

00:33:58.660 --> 00:34:01.380
Are there any restrictions that they need?

00:34:01.380 --> 00:34:03.500
There's some restrictions.

00:34:03.500 --> 00:34:05.700
For example, I don't think you can do threading.

00:34:05.700 --> 00:34:10.000
I don't think you can use some of the common, which you don't have any dependencies, but some

00:34:10.000 --> 00:34:14.740
of the common third-party HTTP clients because it has to go through the browser's AJAX layer.

00:34:14.740 --> 00:34:16.960
There's some, but not terribly many restrictions.

00:34:16.960 --> 00:34:21.540
I'd imagine then that we would only be limited by whichever data frame people are passing in.

00:34:21.540 --> 00:34:22.300
Yeah, yeah.

00:34:22.300 --> 00:34:22.560
Awesome.

00:34:22.560 --> 00:34:23.080
Okay.

00:34:23.080 --> 00:34:24.960
That's super nice.

00:34:24.960 --> 00:34:30.400
And maybe let's just talk through a quick example here, keeping in mind that most people

00:34:30.400 --> 00:34:35.180
can't see any of the code, but let's just give them a sense still of what does it look

00:34:35.180 --> 00:34:40.860
like to write code that is interoperable with both or all these different libraries or these

00:34:40.860 --> 00:34:42.920
data frame libraries using narwhals.

00:34:42.920 --> 00:34:44.620
So maybe give us just an example.

00:34:44.620 --> 00:34:45.720
Sure.

00:34:45.720 --> 00:34:51.740
So the idea is what we can see on the screen is just a very simple example of a data frame

00:34:51.740 --> 00:34:52.640
agnostic function.

00:34:52.640 --> 00:34:54.840
We've got a function called my function.

00:34:54.840 --> 00:34:57.780
And this is something that users could maybe just use.

00:34:57.780 --> 00:35:02.080
Maybe it's something your library exposes, but the user doesn't need to know about narwhals.

00:35:02.080 --> 00:35:05.580
The narwhals only happens once you get inside the function.

00:35:05.580 --> 00:35:07.800
So the user passes in some data frame.

00:35:07.800 --> 00:35:12.280
We then call narwhals.fromNative on that data frame object.

00:35:12.280 --> 00:35:16.360
We do some operation and then we return some native object back to the user.

00:35:16.360 --> 00:35:19.660
Now the narwhals.fromNative, it's a practically free operation.

00:35:19.860 --> 00:35:21.420
It's not doing any data conversion.

00:35:21.420 --> 00:35:26.840
It's just instantiating some narwhals class that's backed by your original data frame.

00:35:26.840 --> 00:35:27.360
Right.

00:35:27.360 --> 00:35:27.820
Right.

00:35:27.820 --> 00:35:33.420
And I imagine if it's Polar's data frame that gets passed in, it's probably a more direct

00:35:33.420 --> 00:35:38.600
pass through to the API than if you're doing operations on a pandas data frame.

00:35:38.600 --> 00:35:38.820
Right.

00:35:38.940 --> 00:35:41.940
Is there a difference of sort of runtime depending on the backend?

00:35:41.940 --> 00:35:45.600
The overhead is really low even for the pandas case.

00:35:45.600 --> 00:35:50.480
In fact, sometimes things do get a little bit faster because of how careful we've been about

00:35:50.480 --> 00:35:55.200
avoiding index operations and unnecessary copies.

00:35:55.200 --> 00:36:00.900
To be honest, some of this will be alleviated in pandas version three when copy on write becomes

00:36:00.900 --> 00:36:01.380
the default.

00:36:02.200 --> 00:36:03.100
Oh, that's interesting.

00:36:03.100 --> 00:36:03.360
Yeah.

00:36:03.360 --> 00:36:03.800
Yeah.

00:36:03.800 --> 00:36:07.780
In terms of the mapping on the implementation side, it's a bit easier to do the Polar's

00:36:07.780 --> 00:36:08.420
backend.

00:36:08.420 --> 00:36:10.580
But even then, we do need to do some version checks.

00:36:10.580 --> 00:36:17.000
Like in 0.20.4, they renamed with row count to with row index, I think.

00:36:17.000 --> 00:36:20.740
And so, yeah, even there, we do need some if-then statements.

00:36:20.740 --> 00:36:25.480
But like the end of the day, what the library does is there's a few extra function calls,

00:36:25.480 --> 00:36:27.460
a few checks on versions.

00:36:28.460 --> 00:36:29.880
It's not really doing that much.

00:36:29.880 --> 00:36:30.320
Yeah.

00:36:30.320 --> 00:36:34.900
Like you might experience an extra millisecond compared to running something natively at most.

00:36:34.900 --> 00:36:40.320
And usually you're using a data frame because you have some amount of data, even hundreds

00:36:40.320 --> 00:36:40.840
of rows.

00:36:40.840 --> 00:36:45.540
It's still most of the computation is going to end up there rather than if it's first in this,

00:36:45.540 --> 00:36:46.900
call that, otherwise call this.

00:36:46.900 --> 00:36:47.140
Right.

00:36:47.140 --> 00:36:49.620
That's not a lot of overhead, relatively speaking.

00:36:49.620 --> 00:36:50.360
I agree.

00:36:50.360 --> 00:36:50.640
Yeah.

00:36:50.640 --> 00:36:55.560
So, yeah, we see an example here of a data frame agnostic function, which just calculates

00:36:55.560 --> 00:36:58.280
some descriptive statistics from an input data frame.

00:36:58.280 --> 00:37:01.900
Using the expressions API, which we talked about earlier.

00:37:01.900 --> 00:37:02.360
Yeah.

00:37:02.360 --> 00:37:04.660
And here's something that I quite like about mkdocs.

00:37:04.660 --> 00:37:06.820
So you see where it says, let's try it out.

00:37:06.820 --> 00:37:13.140
We've got these different tabs and you can click on like polars, pandas, polars lazy.

00:37:13.140 --> 00:37:17.480
And then you can see in each case what it looks like from the user's point of view.

00:37:17.480 --> 00:37:20.000
And you can see, you can compare the outputs.

00:37:20.000 --> 00:37:23.800
So from the user's point of view, they're just passing their object to funk.

00:37:24.140 --> 00:37:27.960
What they're not seeing is that under the hood, funk is using narwhals.

00:37:27.960 --> 00:37:31.240
But from their perspective, they put pandas in, they get pandas out.

00:37:31.240 --> 00:37:33.220
They put polars in, they get polars out.

00:37:33.220 --> 00:37:34.360
That's awesome.

00:37:34.360 --> 00:37:36.840
So we talked about the typing.

00:37:36.840 --> 00:37:40.900
And in this one, we have a DF typed as a frame T.

00:37:41.260 --> 00:37:43.280
Is that some sort of generic?

00:37:43.280 --> 00:37:45.480
And does it have restrictions on it?

00:37:45.480 --> 00:37:46.360
What is this frame T?

00:37:46.360 --> 00:37:49.100
I didn't dive into the source and check it out before.

00:37:49.100 --> 00:37:49.680
Sure.

00:37:49.680 --> 00:37:49.820
Yeah.

00:37:49.820 --> 00:37:50.480
It's a type fur.

00:37:50.480 --> 00:37:56.100
So it's just the idea that you start with a data frame of some kind and you get back some

00:37:56.100 --> 00:37:57.200
data frame of the same kind.

00:37:57.200 --> 00:38:01.960
Start with polars, get back polars, start with pandas, get back pandas, and so on.

00:38:01.960 --> 00:38:07.400
And yeah, this version of the function is using the decorator nw.narwhalify.

00:38:07.400 --> 00:38:08.640
Narwhalify.

00:38:08.640 --> 00:38:09.940
It's a fantastic verb.

00:38:10.440 --> 00:38:10.800
Yeah.

00:38:10.800 --> 00:38:17.060
So there's two ways in which you can implement your function.

00:38:17.060 --> 00:38:23.280
You can do it the explicit way where that's in the quick start in the docs where you write

00:38:23.280 --> 00:38:30.520
your function that takes some native frame and then you convert that to this narwhals one.

00:38:30.520 --> 00:38:32.280
You say from native, then you do your work.

00:38:32.280 --> 00:38:37.420
And then depending on, you could convert it back or in this case, it returns a list of strings

00:38:37.420 --> 00:38:38.000
in that example.

00:38:38.240 --> 00:38:42.900
Or you can skip the first and the last step and just put this decorator on it and it'll

00:38:42.900 --> 00:38:46.860
convert it to or wait, convert it from and then convert it to on the way in and out, right?

00:38:46.860 --> 00:38:47.700
Yeah, exactly.

00:38:47.700 --> 00:38:54.120
So if you're really strict about type annotations, then using from native and to native gives you

00:38:54.120 --> 00:38:55.440
a little bit of extra information.

00:38:56.020 --> 00:38:59.120
But I think narwhalify looks a little bit neater.

00:38:59.120 --> 00:39:00.040
Yeah, that's true.

00:39:00.040 --> 00:39:06.480
So for example, in the first one, you could say that this is actually a pandas data frame because

00:39:06.480 --> 00:39:09.000
you're writing the code or something like that.

00:39:09.000 --> 00:39:09.340
I don't know.

00:39:09.340 --> 00:39:10.700
What is this into frame?

00:39:10.700 --> 00:39:12.980
This is the type on this first example.

00:39:12.980 --> 00:39:13.480
Yeah.

00:39:13.480 --> 00:39:19.800
By into frame, we mean something that can be converted into a narwhals data frame or lazy frame.

00:39:19.800 --> 00:39:21.620
How do you implement that in the type system?

00:39:21.620 --> 00:39:24.120
Is it a protocol or what is this?

00:39:24.120 --> 00:39:27.100
It's, yeah, we've got a protocol.

00:39:27.100 --> 00:39:30.800
So I just found some methods that these libraries have in common.

00:39:30.800 --> 00:39:31.620
Exactly.

00:39:31.620 --> 00:39:32.440
Which wasn't too much.

00:39:32.440 --> 00:39:32.820
You can find that.

00:39:33.720 --> 00:39:34.740
That's what I was thinking.

00:39:34.740 --> 00:39:35.060
Yeah.

00:39:35.060 --> 00:39:35.780
Okay.

00:39:35.780 --> 00:39:36.340
Yeah.

00:39:36.340 --> 00:39:41.820
But if it has enough of the functions of pandas or pollers, you're like, all right, this is

00:39:41.820 --> 00:39:42.320
probably good.

00:39:42.320 --> 00:39:42.720
All right.

00:39:42.720 --> 00:39:43.960
And you can say it's one of these.

00:39:43.960 --> 00:39:45.000
That's pretty cool.

00:39:45.000 --> 00:39:45.860
Yeah, exactly.

00:39:45.860 --> 00:39:49.920
I mean, if any of this is confusing to listeners, we do have a page there in the documentation

00:39:49.920 --> 00:39:51.120
that's all about typing.

00:39:51.120 --> 00:39:53.820
So people can read through that at their own leisure.

00:39:53.820 --> 00:39:55.100
Yeah, for sure.

00:39:55.100 --> 00:39:55.640
All right.

00:39:55.640 --> 00:39:56.380
Let's see.

00:39:56.380 --> 00:40:00.100
I do like the MKDocs where you can have these different examples.

00:40:00.520 --> 00:40:06.600
One thing I noticed is you've got the pollers eager evaluation and you've got the pollers

00:40:06.600 --> 00:40:08.020
lazy evaluation.

00:40:08.020 --> 00:40:14.420
And when you have the pollers lazy, this function decorated with the decorator, the Narwhalify

00:40:14.420 --> 00:40:19.460
decorator, it itself returns something that is lazy and you've got to call collect on, right?

00:40:19.460 --> 00:40:21.800
So it kind of preserves the laziness, I guess.

00:40:21.800 --> 00:40:22.220
Is that right?

00:40:22.220 --> 00:40:23.260
Yes, exactly.

00:40:23.260 --> 00:40:28.380
This was something that was quite important to me, like not be something that only works

00:40:28.380 --> 00:40:29.880
well with eager execution.

00:40:30.260 --> 00:40:36.160
I want to have some level of support such that lazy in can mean lazy out.

00:40:36.160 --> 00:40:36.640
Yeah.

00:40:36.640 --> 00:40:37.820
Eager in, eager out.

00:40:37.820 --> 00:40:38.860
Lazy in, lazy out.

00:40:38.860 --> 00:40:39.100
Okay.

00:40:39.100 --> 00:40:39.760
Exactly.

00:40:39.760 --> 00:40:40.300
Yeah.

00:40:40.300 --> 00:40:45.240
So the way you do that in pollers is you create a lazy frame versus data frame, right?

00:40:45.240 --> 00:40:50.480
But then you've got to call collect on it, kind of like awaiting it if it were async, which

00:40:50.480 --> 00:40:50.820
is cool.

00:40:50.820 --> 00:40:51.180
Yeah.

00:40:51.180 --> 00:40:55.540
Or don't call collect or just wait until you really need to call collect.

00:40:55.540 --> 00:40:56.260
Right.

00:40:56.260 --> 00:40:58.560
Or pass it on to the next one and on to the next.

00:40:58.560 --> 00:40:59.400
Yeah, exactly.

00:40:59.840 --> 00:41:00.160
Exactly.

00:41:00.160 --> 00:41:06.440
So one of the things that you talk about here is the pandas index, which is one of the

00:41:06.440 --> 00:41:08.620
key differences between pollers and pandas.

00:41:08.620 --> 00:41:12.540
And you've classified pandas people into two categories.

00:41:12.540 --> 00:41:17.200
Those who love the index and those who try to get rid of it and ignore it.

00:41:17.400 --> 00:41:17.920
Yeah, exactly.

00:41:17.920 --> 00:41:22.580
So if James Powell is listening, I think we can put him in the first category.

00:41:22.580 --> 00:41:28.880
I think most realistically, most pandas users that I've seen call .reset index drop equals

00:41:28.880 --> 00:41:30.400
true every other line of code.

00:41:30.500 --> 00:41:34.580
They just find that the index gets in the way more than helps them most of the time.

00:41:34.580 --> 00:41:37.940
And with novels, we're trying to accommodate both.

00:41:37.940 --> 00:41:41.020
So we don't do automated index alignment.

00:41:41.280 --> 00:41:43.320
So this isn't something that you have to worry about.

00:41:43.320 --> 00:41:50.000
But if you are really bothered about index alignment, say, due to backwards compatibility concerns,

00:41:50.000 --> 00:41:55.940
then we do have some functions which allow you to do that, which would be no operations for other libraries.

00:41:56.300 --> 00:42:00.360
There's an example in scikit-lego of where they were relying on pandas index alignment.

00:42:00.360 --> 00:42:01.960
So we've got a function here.

00:42:01.960 --> 00:42:04.300
Narwhals may be a line index.

00:42:04.300 --> 00:42:08.100
So for pandas-like, it'll do, the index will do its thing.

00:42:08.100 --> 00:42:11.440
And for other libraries, the data will just be passed through.

00:42:11.440 --> 00:42:12.100
Right.

00:42:12.100 --> 00:42:15.000
So you said they're pandas-like.

00:42:15.000 --> 00:42:17.860
And pandas-like is actually a type in your type system, right?

00:42:17.860 --> 00:42:18.760
Did I see that?

00:42:18.760 --> 00:42:20.040
Yeah, yeah.

00:42:20.040 --> 00:42:24.000
So we've got is pandas-like data frame function to tell.

00:42:24.000 --> 00:42:28.180
So by pandas-like, we mean pandas-qdf-modin.

00:42:28.180 --> 00:42:32.100
So the libraries that have an index and follow those kinds of rules.

00:42:32.100 --> 00:42:33.580
Yeah, yeah, that's really cool.

00:42:33.580 --> 00:42:37.640
Yeah, because at the end of the day, like the idea of writing completely data frame agnostic code

00:42:37.640 --> 00:42:42.540
is a lot easier for new libraries than for existing libraries that have backwards compatibility concerns.

00:42:42.540 --> 00:42:46.880
And we recognize that it might not be completely achievable.

00:42:46.880 --> 00:42:49.940
I think in all of the use cases where we've seen Narwhals adopted,

00:42:49.940 --> 00:42:52.480
they're doing most of it in a data frame agnostic way,

00:42:52.740 --> 00:42:55.160
but they do have some parts of it where they're saying,

00:42:55.160 --> 00:42:58.620
okay, if this is a pandas data frame, we've got some pandas-specific logic.

00:42:58.620 --> 00:43:01.820
And otherwise, let's go down the data frame agnostic route.

00:43:01.820 --> 00:43:05.660
Yeah, you also have here levels of support.

00:43:05.660 --> 00:43:06.840
You have full and interchange.

00:43:06.840 --> 00:43:08.440
I think we talked about that a little bit.

00:43:08.440 --> 00:43:10.360
So maybe just point people here.

00:43:10.500 --> 00:43:15.720
If you want to be QDF or modin, you can fully integrate.

00:43:15.720 --> 00:43:21.780
Or if you just want to have enough of an implementation that they can kind of work together, right?

00:43:21.780 --> 00:43:24.100
You can do this data frame interchange protocol.

00:43:24.100 --> 00:43:24.960
Yeah, exactly.

00:43:24.960 --> 00:43:31.360
Or just write to us and we'd be happy to accommodate you without you having to go through the data frame interchange protocol.

00:43:31.620 --> 00:43:32.420
Oh yeah, very nice.

00:43:32.420 --> 00:43:32.900
Okay.

00:43:32.900 --> 00:43:35.300
You mentioned the overhead before, but you do have a picture.

00:43:35.300 --> 00:43:36.560
Picture's always fun.

00:43:36.560 --> 00:43:42.340
And in the picture, you've got little different operations, different times for each of the operations.

00:43:42.340 --> 00:43:46.780
And there's a quite small overhead for pandas versus pandas with Narwhals.

00:43:47.120 --> 00:43:47.780
Yeah, exactly.

00:43:47.780 --> 00:43:51.100
Like in some of them, you can see it becoming a little bit faster.

00:43:51.100 --> 00:43:53.260
In some of them, you can see it becoming a little bit slower.

00:43:53.260 --> 00:43:58.940
And these are queries that I think are the size that you can expect most data scientists to be working with a lot of the time.

00:43:58.940 --> 00:44:02.820
You've got queries that take between a couple of seconds to 30 seconds.

00:44:02.820 --> 00:44:08.320
And there, it's pretty hard to distinguish reliably between like the blue and red dots.

00:44:08.320 --> 00:44:11.760
Sometimes one's higher, sometimes the other one's higher.

00:44:11.760 --> 00:44:15.820
There's a bit of statistical variance just between running the same benchmark multiple times.

00:44:16.240 --> 00:44:18.840
But overall, yeah, we were pretty happy with these results.

00:44:18.840 --> 00:44:20.320
Yeah, that's great.

00:44:20.320 --> 00:44:23.700
So how well have we covered how it works?

00:44:23.700 --> 00:44:29.580
We talked about the API, but I know we've talked about the implementation of how you actually,

00:44:29.580 --> 00:44:33.180
why is it basically almost the same speed?

00:44:33.180 --> 00:44:34.980
Are you not doing, why is it not going to work?

00:44:34.980 --> 00:44:35.840
Yeah, well maybe.

00:44:35.840 --> 00:44:37.420
Are you using underwater unicorn magic?

00:44:37.420 --> 00:44:38.660
Is that what it is?

00:44:38.660 --> 00:44:40.180
That's the secret, yes.

00:44:40.180 --> 00:44:41.340
Underwater unicorn magic.

00:44:41.340 --> 00:44:45.300
Well, perhaps first I should just say why we wrote this, how it works.

00:44:45.440 --> 00:44:48.820
And it's because really I want this to be a community driven project.

00:44:48.820 --> 00:44:54.080
And this is one of those cases where open source is more of a social game than a technical one.

00:44:54.080 --> 00:44:55.600
I'm not saying that's always the case.

00:44:55.600 --> 00:44:57.720
There are many problems that are purely technical.

00:44:57.720 --> 00:44:59.920
Now else is a social game in the end.

00:44:59.920 --> 00:45:01.800
Like what we're doing isn't that complicated.

00:45:01.800 --> 00:45:06.380
But if we want it to work, then it needs to be accessible to the community.

00:45:06.380 --> 00:45:08.320
People do need to be able to trust us.

00:45:08.680 --> 00:45:11.800
And that typically does not happen if it's a one person project.

00:45:11.800 --> 00:45:19.060
So it was really important to me that different people would be able to contribute to it, that it all be as simple and clear as possible.

00:45:19.400 --> 00:45:21.860
So we made this page trying to explain how it works.

00:45:21.860 --> 00:45:25.360
It's not quite as clear and quite as extensive as it'd like to be.

00:45:25.360 --> 00:45:28.240
But a few contributors did say that it really helped them.

00:45:28.240 --> 00:45:31.080
So in terms of how do we get this slow overhead?

00:45:31.080 --> 00:45:36.120
So we're just defining an expression as being a function from a data frame, your sequence of series.

00:45:36.120 --> 00:45:39.480
And then we're just repeatedly and strictly applying that definition.

00:45:39.480 --> 00:45:41.860
So there's nothing too fancy going on.

00:45:41.860 --> 00:45:48.260
That's like in the end, just evaluating Lambda functions in Python, going down the stack trace.

00:45:48.260 --> 00:45:49.440
Like it's pretty fast.

00:45:49.840 --> 00:45:50.520
Yeah, that's really cool.

00:45:50.520 --> 00:45:51.940
Yeah, so people can check this out.

00:45:51.940 --> 00:45:52.580
They want to know.

00:45:52.580 --> 00:45:55.480
I think this might be where I saw the pandas-like expression.

00:45:55.480 --> 00:45:56.320
Ah, right, yeah.

00:45:56.320 --> 00:45:56.720
Pandas-like.

00:45:56.720 --> 00:46:00.740
Yeah, pandas-like is this class that encompasses pandas mode in QDF.

00:46:00.740 --> 00:46:02.940
The ones that kind of follow the pandas API.

00:46:02.940 --> 00:46:05.720
Yeah, close enough for what you need to do.

00:46:05.720 --> 00:46:06.500
Yeah, exactly.

00:46:06.500 --> 00:46:07.140
All right.

00:46:07.140 --> 00:46:14.720
Well, I saw a question out there in the audience somewhere from Francesco, which was basically asking about the roadmap.

00:46:14.720 --> 00:46:15.760
Like, where are you?

00:46:15.760 --> 00:46:16.560
Where are you going?

00:46:16.560 --> 00:46:18.300
Yeah, I should probably introduce Francesco.

00:46:18.380 --> 00:46:22.300
He's one of the most active contributors to the project.

00:46:22.300 --> 00:46:26.540
So thanks, Francesco, for helping to make it a success.

00:46:26.540 --> 00:46:31.200
He was actually also the first person to adopt Narwhals in one of his libraries.

00:46:31.200 --> 00:46:33.840
Yeah, I spoke to him about it at a conference.

00:46:33.840 --> 00:46:37.580
And he was like, I've got this tiny little time-based CV library.

00:46:37.580 --> 00:46:39.560
Let's try Narwhalifying it as an experiment.

00:46:39.560 --> 00:46:40.900
Sure, we did that.

00:46:40.900 --> 00:46:42.440
Then scikit-learn.

00:46:42.440 --> 00:46:43.820
Not scikit-learn, sorry.

00:46:43.820 --> 00:46:45.660
Not scikit-lego.

00:46:45.960 --> 00:46:50.340
It was this kind of experimental building blocks for scikit-learn pipelines that he maintains.

00:46:50.340 --> 00:46:52.620
And then we've just been taking it from there.

00:46:52.620 --> 00:47:00.220
So in terms of roadmap, my top priority is helping out libraries that have shown interest in Narwhals.

00:47:00.220 --> 00:47:05.980
So at the moment, Formulaic, that opened a draft pull request in which they were trying out Narwhals.

00:47:06.120 --> 00:47:08.580
And they tagged me just about some things they were missing.

00:47:08.580 --> 00:47:11.780
So I'd like to see if I can take that to completion.

00:47:11.780 --> 00:47:16.660
I've got, I think I've got most of it working, but just been a bit busy with conferences recently.

00:47:16.660 --> 00:47:21.760
So maybe next month I'll be able to get something ready for review and show that to them.

00:47:21.760 --> 00:47:23.180
That would be pretty cool.

00:47:23.600 --> 00:47:25.400
It's summer is passing.

00:47:25.400 --> 00:47:26.740
The conferences are ending.

00:47:26.740 --> 00:47:28.180
It's going to get dark and cold.

00:47:28.180 --> 00:47:29.320
Perfect time to program.

00:47:29.320 --> 00:47:36.500
Yeah, we'll get back to the situation that I was in when I started Narwhals, which was that it was a rainy Friday.

00:47:36.500 --> 00:47:37.720
Not Friday, sorry.

00:47:37.720 --> 00:47:40.600
It was a rainy February weekend in Wales.

00:47:40.600 --> 00:47:42.240
The rainiest part of the UK.

00:47:42.700 --> 00:47:45.480
Yeah, that's exactly the same in Oregon here.

00:47:45.480 --> 00:47:47.380
So it's a good time to get stuff done.

00:47:47.380 --> 00:47:48.560
Yeah, exactly.

00:47:48.560 --> 00:47:48.980
So yeah.

00:47:48.980 --> 00:47:55.420
And then I've been speaking to people from Shiny and Plotly about potentially looking into Narwhals.

00:47:55.420 --> 00:47:59.080
There's no contract set in stone or anything.

00:47:59.080 --> 00:48:02.160
These people may well change their mind if it doesn't work for them.

00:48:02.160 --> 00:48:04.480
But my idea is, okay, they've shown interest.

00:48:04.480 --> 00:48:10.040
Let's go headfirst into seeing whether we can help them and whether they'd be able to use Narwhals.

00:48:10.040 --> 00:48:15.360
If it doesn't work out, we'll just have strengthened the Narwhals API and learn some new things.

00:48:15.360 --> 00:48:17.680
If it does work, then great, exciting.

00:48:17.680 --> 00:48:20.340
So that's my top priority.

00:48:20.340 --> 00:48:25.220
And it's been really pleasing to see the contributor to community develop around Narwhals.

00:48:25.220 --> 00:48:28.020
I really thought it would be a one-person project for a long time.

00:48:28.020 --> 00:48:31.500
But so many people have been contributing really high-quality pull requests.

00:48:31.500 --> 00:48:33.700
It's really been, yeah, AC42.

00:48:33.700 --> 00:48:35.440
Okay, one of them is this.

00:48:35.440 --> 00:48:38.220
Okay, maybe a couple of them here are like GitHub bots.

00:48:39.080 --> 00:48:40.360
This pre-commit CI bot.

00:48:40.360 --> 00:48:41.620
Yeah.

00:48:41.620 --> 00:48:44.600
Maybe 40, 30, but still, that's a lot.

00:48:44.600 --> 00:48:49.740
While we're talking numbers on the homepage, I also want to point out 10 million downloads a month is a lot of downloads.

00:48:49.740 --> 00:48:50.380
That's awesome.

00:48:50.380 --> 00:48:57.940
Yeah, that's maybe slightly misleading because they pretty much just come from the fact that it's now a required dependency of Altair.

00:48:57.940 --> 00:49:00.380
And Altair gets millions of downloads.

00:49:00.380 --> 00:49:01.380
Yeah, yeah, yeah, exactly.

00:49:01.380 --> 00:49:04.520
But that's how, that's the place of some libraries.

00:49:04.520 --> 00:49:09.640
Like Berksoig, I don't think many people go, oh, let me go get this HTTP library or it's dangerous.

00:49:09.640 --> 00:49:11.100
They just go, I'm going to use Flask.

00:49:11.100 --> 00:49:11.560
Right?

00:49:11.780 --> 00:49:19.360
But it's still a really important building block of the community, even if people don't seek it out as a top-level thing they use, right?

00:49:19.360 --> 00:49:20.040
Sure, cheers.

00:49:20.040 --> 00:49:20.520
Thanks, yeah.

00:49:20.520 --> 00:49:25.480
In fact, if we do our job well, then most people should never know about novels.

00:49:25.480 --> 00:49:26.240
Exactly.

00:49:26.240 --> 00:49:28.060
They just use, just work.

00:49:28.060 --> 00:49:29.220
Yeah, exactly.

00:49:29.220 --> 00:49:34.160
They just look in their pip list like, what is this whale thing in here?

00:49:34.160 --> 00:49:35.900
Yeah, exactly.

00:49:35.900 --> 00:49:36.900
Yeah.

00:49:36.900 --> 00:49:42.480
So, yeah, it's been really encouraging, really pleasing to see this contributor community emerge around the project.

00:49:42.480 --> 00:49:51.080
And I think a lot of the contributors are really interested in adding extra methods and adding extra backends and things.

00:49:51.080 --> 00:49:55.340
So I'm trying to leave a lot of that to the community.

00:49:55.800 --> 00:49:59.700
So, like with Dask, I just got the rough building blocks together.

00:49:59.700 --> 00:50:07.400
And then it was just so nice, like so many really high-quality contributions coming up that brought the Dask support pretty much complete.

00:50:07.400 --> 00:50:11.400
We should see now if we're able to execute all of the TPC-H queries with the Dask backend.

00:50:11.400 --> 00:50:15.480
We might actually be there or be pretty close to getting there.

00:50:15.480 --> 00:50:15.920
Nice.

00:50:15.920 --> 00:50:19.420
What does TPC-H stand for?

00:50:19.420 --> 00:50:24.220
I don't remember what it stands for, but it's a set of database queries.

00:50:24.220 --> 00:50:25.280
I see.

00:50:25.360 --> 00:50:28.760
They were originally written for testing out different databases.

00:50:28.760 --> 00:50:31.100
So it's a bunch of SQL queries.

00:50:31.100 --> 00:50:48.820
But I'm not sure if it was Kaggle that popularized the idea of translating these SQL queries to data frame-like APIs and then running different data frames on them to see who wins the speed test.

00:50:48.820 --> 00:50:57.900
But we just figured they do a bunch of things like joins, concatenations, filtering comparisons with dates, string operations.

00:50:57.900 --> 00:51:04.200
And we're like, okay, if the Nowels API is able to do all of this, then maybe it's extensive enough to be useful.

00:51:04.640 --> 00:51:04.980
Yeah, yeah, yeah.

00:51:04.980 --> 00:51:06.300
That's super cool.

00:51:06.300 --> 00:51:10.920
It sounds a little bit like the TOB index plus other stuff maybe, but for databases.

00:51:11.580 --> 00:51:13.140
I'm not familiar with that.

00:51:13.140 --> 00:51:15.680
It's like a language ranking type of thing.

00:51:15.680 --> 00:51:18.600
And, you know, one aspect is maybe ranking the databases.

00:51:18.600 --> 00:51:20.360
But yeah, no, this is very cool.

00:51:20.360 --> 00:51:20.660
Okay.

00:51:20.660 --> 00:51:21.280
Got it.

00:51:21.280 --> 00:51:29.620
In the end, we're not trying to be fast as Nowels, but we just want to make sure that there's no extra overhead compared to running things natively.

00:51:29.620 --> 00:51:34.680
As long as you're not much slower than the stuff that you're operating with, like, that's all you should ask for.

00:51:34.680 --> 00:51:37.040
You can't make it go faster in the extreme.

00:51:37.040 --> 00:51:40.940
Like, you did talk about some optimizations, but you can't fundamentally change what's happening.

00:51:40.940 --> 00:51:43.520
Yeah, we could do some optimizations on the Nowels side.

00:51:43.520 --> 00:51:45.420
But to be honest, I'm not sure I want to.

00:51:45.420 --> 00:51:49.620
And part of the reason is because I want this to be a pretty simple project that's easy to maintain.

00:51:49.620 --> 00:51:50.300
Yeah, sure.

00:51:50.300 --> 00:51:52.340
And that's really just low overhead.

00:51:52.340 --> 00:51:54.720
Add extra docs and tutorials coming.

00:51:54.720 --> 00:51:55.540
That's fun.

00:51:55.540 --> 00:51:56.000
Yeah.

00:51:56.100 --> 00:51:59.480
Are you looking for contributors and maybe want to write some tutorials or docs?

00:51:59.480 --> 00:52:00.740
I would love this, yeah.

00:52:00.740 --> 00:52:08.220
I mean, it drives me crazy when I see so many projects where people have put so much effort into making a really good product, but then the documentation is really scant.

00:52:08.220 --> 00:52:13.820
Like, if you don't prioritize writing good docs, nobody's going to use your product.

00:52:13.820 --> 00:52:17.180
So I was really grateful to my company.

00:52:17.180 --> 00:52:22.720
They had four interns come on who really helped out with making the docs look amazing.

00:52:22.720 --> 00:52:23.460
Oh, that's cool.

00:52:23.500 --> 00:52:31.340
Like, if you look at the API reference, I think every single function now has got a, like a doc string with an example.

00:52:31.340 --> 00:52:33.580
At the bottom, I think there's API reference.

00:52:33.580 --> 00:52:41.600
Yeah, if you search for any function in here, yeah, in the search box at the top, some, I don't know, series dot something.

00:52:41.600 --> 00:52:49.100
Yeah, see, for any of these, we've got like an example of, okay, here's how you could write a data frame agnostic function, which uses this method.

00:52:49.100 --> 00:52:53.080
And let's show that if you pass pandas or polars, you get the same result.

00:52:53.080 --> 00:53:00.760
And if there's some slight differences that we just cannot get around, like in the way that they handle missing values, then we've got a very clear note about in the docs.

00:53:00.760 --> 00:53:01.640
Yeah, that's great.

00:53:01.640 --> 00:53:03.800
Maybe someday support for DuckDB?

00:53:03.800 --> 00:53:06.040
I would like that.

00:53:06.040 --> 00:53:09.900
I don't think we have much of a choice about whether or not we support DuckDB.

00:53:09.900 --> 00:53:12.260
Like DuckDB is really on fire now.

00:53:13.260 --> 00:53:14.100
It really is.

00:53:14.100 --> 00:53:25.440
Yeah, I think it might be a question of either we have some level of support for DuckDB, or somebody else is going to make something like novels that supports DuckDB, and then we become extinct.

00:53:25.440 --> 00:53:31.440
But besides, to be honest, DuckDB is amazing.

00:53:31.680 --> 00:53:34.940
I just find it a bit painful to write SQL strings.

00:53:34.940 --> 00:53:41.540
And so if I could use DuckDB, but with the Polar's API that I prefer and I'm more familiar with, then...

00:53:41.540 --> 00:53:44.340
Yeah, I 100% agree.

00:53:44.340 --> 00:53:45.480
It looks super nice.

00:53:45.480 --> 00:53:50.620
But if you look, it has a SQL example, and then the Python example is just SQL, quote, quote, quote.

00:53:50.620 --> 00:53:51.320
Yeah, exactly.

00:53:51.580 --> 00:53:53.760
Here's the SQL embedded in Python, you know what I mean?

00:53:53.760 --> 00:53:56.440
So you're kind of writing SQL no matter what.

00:53:56.440 --> 00:54:01.240
Yeah, and then the error messages that you get sometimes are like, oh, there's a pass error near this keyword.

00:54:01.240 --> 00:54:03.080
And you're like, what on earth is going on?

00:54:03.080 --> 00:54:05.640
And then you're like, oh, yeah, I forgot.

00:54:05.640 --> 00:54:08.460
I've got an extra comma at the end of my select or something.

00:54:08.460 --> 00:54:08.820
I don't know.

00:54:08.820 --> 00:54:09.080
Yeah.

00:54:09.080 --> 00:54:16.480
So DuckDB is a little bit like SQLite, but for analytics rather than relational, maybe.

00:54:16.480 --> 00:54:17.660
I'm not sure if that's...

00:54:17.660 --> 00:54:24.880
I think it's primarily aimed at analysts, yeah, analytical kinds of things, yeah, data scientists and people.

00:54:24.880 --> 00:54:32.500
What we are going to struggle with is that in DuckDB, there's no guarantees about row order or operations.

00:54:32.500 --> 00:54:40.800
But on the plus side, when I look at what Altair are doing with data frames, when I look at some of the other libraries that I've shown interest in now,

00:54:40.800 --> 00:54:43.220
they're often just doing very simple things.

00:54:43.220 --> 00:54:45.340
They're not doing things that depend on row order.

00:54:45.340 --> 00:54:51.080
So if we could just initially just support DuckDB for the operations that don't require row order.

00:54:51.080 --> 00:54:56.380
So for something like a cumulative sum, maybe initially we just don't support that for DuckDB.

00:54:56.380 --> 00:55:01.420
Like in the end, if you want to do advanced SQL, just use DuckDB directly.

00:55:01.420 --> 00:55:06.220
Like, as I said earlier, I don't recommend that end users use novels directly.

00:55:06.400 --> 00:55:16.820
But even just having some common operations, ones that aren't row order dependent, I'd like to think that this is already enough to solve some real problems for real people.

00:55:16.820 --> 00:55:19.400
Yeah, I know you said it's mostly for library builders.

00:55:19.400 --> 00:55:28.220
But if you were building an app and you were not committed to your data frame library, or you really wanted to leave open the possibility of choosing a different data frame library,

00:55:28.580 --> 00:55:32.680
using narwhals to isolate that a little bit might be nice, right?

00:55:32.680 --> 00:55:33.120
Yeah.

00:55:33.120 --> 00:55:34.860
So yeah.

00:55:34.860 --> 00:55:35.740
Yeah.

00:55:35.740 --> 00:55:38.640
If anyone tries to do this, and I'd love to hear your story.

00:55:38.640 --> 00:55:42.080
I did hear from somebody in our community call.

00:55:42.080 --> 00:55:46.260
We've got a community call every two weeks, by the way, if anyone wants to come and chat with us.

00:55:46.320 --> 00:55:53.780
I did hear from somebody that, like, at work has got some teams that are primarily using pandas, some teams that are primarily using polars,

00:55:53.780 --> 00:55:57.760
and he just wanted to build some common logic that both teams could use.

00:55:57.760 --> 00:55:59.740
And he was using narwhals for that.

00:55:59.740 --> 00:56:03.640
So I think there are some use cases beyond just library maintainers.

00:56:03.640 --> 00:56:04.480
Yeah, absolutely.

00:56:04.480 --> 00:56:09.680
Maybe you're building just an internal library, and it needs to work with some code you've written in pandas,

00:56:09.680 --> 00:56:13.940
but you maybe want to try your new project in polars, but you want to still use that library, right?

00:56:13.940 --> 00:56:15.760
That would be a cool use case as well.

00:56:16.080 --> 00:56:16.580
Yeah, yeah.

00:56:16.580 --> 00:56:17.200
To not lock yourself in.

00:56:17.200 --> 00:56:23.220
Yeah, I'm pretty sure you've brought up on the show before that XKCD about, like, the spacebar overheating.

00:56:23.220 --> 00:56:27.640
I don't remember which number that one is, but in the end, with a lot of open source projects,

00:56:27.640 --> 00:56:31.100
you put it out with some intention of how it's meant to be used.

00:56:31.100 --> 00:56:31.560
Yes.

00:56:31.560 --> 00:56:33.420
But then people find their own way of using it.

00:56:33.420 --> 00:56:35.600
I believe it was spacebar heating.

00:56:35.600 --> 00:56:37.120
Workflow, this is it.

00:56:37.120 --> 00:56:37.660
Yes.

00:56:37.660 --> 00:56:38.220
Love this one.

00:56:38.220 --> 00:56:43.800
Yeah, it looks like something out of a changelog with feedback or something that says,

00:56:44.100 --> 00:56:46.200
changes in version 10.7.

00:56:46.200 --> 00:56:49.020
The CPU no longer overheats when you hold down the spacebar.

00:56:49.020 --> 00:56:49.580
Comments.

00:56:49.580 --> 00:56:53.300
Longtime user 4 writes, this update broke my workflow.

00:56:53.300 --> 00:56:56.320
My control key is hard to reach, so I hold the spacebar instead.

00:56:56.320 --> 00:57:00.220
And I configured Emacs to interpret a rapid temperature rise as control.

00:57:00.220 --> 00:57:00.920
That's horrifying.

00:57:00.920 --> 00:57:02.580
Look, my setup works for me.

00:57:02.580 --> 00:57:05.280
Just add an option to re-enable spacebar heating.

00:57:06.860 --> 00:57:09.660
I've seen it so many times, but it still makes me laugh each time.

00:57:09.660 --> 00:57:10.300
It's incredible.

00:57:10.300 --> 00:57:11.040
It's incredible.

00:57:11.040 --> 00:57:11.800
All right, Marco.

00:57:11.800 --> 00:57:13.240
Well, congrats on the cool library.

00:57:13.240 --> 00:57:14.180
Congrats on the traction.

00:57:14.180 --> 00:57:15.460
Final call to action.

00:57:15.460 --> 00:57:17.040
Maybe people want to start using narwhals.

00:57:17.040 --> 00:57:17.560
What do you tell them?

00:57:17.560 --> 00:57:18.860
Yeah, give it a go.

00:57:18.860 --> 00:57:22.340
And please join our Discord and or our community calls.

00:57:22.340 --> 00:57:24.060
We're very friendly and open.

00:57:24.060 --> 00:57:30.060
And we'd love to hear from you and see what we can do to address whatever limitations you

00:57:30.060 --> 00:57:31.580
might come up against.

00:57:31.580 --> 00:57:35.900
This has been another episode of Talk Python to Me.

00:57:35.900 --> 00:57:37.720
Thank you to our sponsors.

00:57:37.720 --> 00:57:39.320
Be sure to check out what they're offering.

00:57:39.320 --> 00:57:40.740
It really helps support the show.

00:57:40.740 --> 00:57:43.900
This episode is brought to you by WorkOS.

00:57:43.900 --> 00:57:49.240
If you're building a B2B SaaS app, at some point, your customers will start asking for enterprise

00:57:49.240 --> 00:57:55.000
features like SAML authentication, SKIM provisioning, audit logs, and fine-grained authorization.

00:57:55.000 --> 00:58:00.000
WorkOS helps ship enterprise features on day one without slowing down your

00:58:00.000 --> 00:58:00.940
core product development.

00:58:00.940 --> 00:58:04.820
Find out more at talkpython.fm/workOS.

00:58:04.820 --> 00:58:06.300
Want to level up your Python?

00:58:06.300 --> 00:58:10.340
We have one of the largest catalogs of Python video courses over at Talk Python.

00:58:10.340 --> 00:58:15.520
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:58:15.520 --> 00:58:18.180
And best of all, there's not a subscription in sight.

00:58:18.180 --> 00:58:21.080
Check it out for yourself at training.talkpython.fm.

00:58:21.080 --> 00:58:23.200
Be sure to subscribe to the show.

00:58:23.200 --> 00:58:26.060
Open your favorite podcast app and search for Python.

00:58:26.060 --> 00:58:27.300
We should be right at the top.

00:58:27.780 --> 00:58:32.460
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:58:32.460 --> 00:58:36.660
and the direct RSS feed at /rss on talkpython.fm.

00:58:36.660 --> 00:58:39.620
We're live streaming most of our recordings these days.

00:58:39.620 --> 00:58:43.740
If you want to be part of the show and have your comments featured on the air, be sure to

00:58:43.740 --> 00:58:47.460
subscribe to our YouTube channel at talkpython.fm/youtube.

00:58:48.120 --> 00:58:49.500
This is your host, Michael Kennedy.

00:58:49.500 --> 00:58:50.800
Thanks so much for listening.

00:58:50.800 --> 00:58:51.960
I really appreciate it.

00:58:51.960 --> 00:58:53.860
Now get out there and write some Python code.

00:58:53.860 --> 00:58:54.860
Bye.

00:58:54.860 --> 00:58:55.300
Bye.

00:58:55.300 --> 00:58:55.360
Bye.

00:58:55.360 --> 00:58:55.880
Bye.

00:58:55.880 --> 00:58:56.000
Bye.

00:58:56.000 --> 00:58:56.240
Bye.

00:58:56.240 --> 00:58:56.880
Bye.

00:58:56.880 --> 00:58:56.880
Bye.

00:58:56.880 --> 00:58:56.880
Bye.

00:58:56.880 --> 00:58:57.520
Bye.

00:58:57.520 --> 00:58:57.520
Bye.

00:58:57.520 --> 00:58:57.520
Bye.

00:58:57.520 --> 00:58:57.520
Bye.

00:58:57.520 --> 00:58:58.160
Bye.

00:58:58.160 --> 00:58:58.160
Bye.

00:58:58.160 --> 00:58:58.160
Bye.

00:58:58.160 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:58.800
Bye.

00:58:58.800 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:58:59.440
Bye.

00:58:59.440 --> 00:59:00.080
Bye.

00:59:00.080 --> 00:59:00.080
Bye.

00:59:00.080 --> 00:59:00.080
Bye.

00:59:00.080 --> 00:59:00.080
Bye.

00:59:00.080 --> 00:59:00.080
Bye.

00:59:00.080 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:00.720
Bye.

00:59:00.720 --> 00:59:01.360
Bye.

00:59:01.360 --> 00:59:01.360
Bye.

00:59:01.360 --> 00:59:01.360
Bye.

00:59:01.360 --> 00:59:01.360
Bye.

00:59:01.360 --> 00:59:01.360
Bye.

00:59:01.360 --> 00:59:02.000
Bye.

00:59:02.000 --> 00:59:02.000
Bye.

00:59:02.000 --> 00:59:02.000
Bye.

00:59:02.000 --> 00:59:02.000
Bye.

00:59:02.000 --> 00:59:02.640
Bye.

00:59:02.640 --> 00:59:02.640
Bye.

00:59:02.640 --> 00:59:02.640
Bye.

00:59:02.640 --> 00:59:02.640
Bye.

00:59:02.640 --> 00:59:02.640
Bye.

00:59:02.640 --> 00:59:03.280
Bye.

00:59:03.280 --> 00:59:03.280
Bye.

00:59:03.280 --> 00:59:03.280
Bye.

00:59:03.280 --> 00:59:03.920
Bye.

00:59:03.920 --> 00:59:03.920
Bye.

00:59:03.920 --> 00:59:03.920
Bye.

00:59:03.920 --> 00:59:04.560
Bye.

00:59:04.560 --> 00:59:04.560
Bye.

00:59:04.560 --> 00:59:04.560
Bye.

00:59:04.560 --> 00:59:04.560
Bye.

00:59:04.560 --> 00:59:04.560
Bye.

00:59:04.560 --> 00:59:05.200
Bye.

00:59:05.200 --> 00:59:05.200
Bye.

00:59:05.200 --> 00:59:05.200
Bye.

00:59:05.200 --> 00:59:05.840
Bye.

00:59:05.840 --> 00:59:05.840
Bye.

00:59:05.840 --> 00:59:05.840
Bye.

00:59:05.840 --> 00:59:05.840
Bye.

00:59:05.840 --> 00:59:06.480
Bye.

00:59:06.480 --> 00:59:06.480
Bye.

00:59:06.480 --> 00:59:06.480
Bye.

00:59:06.480 --> 00:59:07.120
Bye.

00:59:07.120 --> 00:59:07.120
Bye.

00:59:07.120 --> 00:59:07.120
Bye.

00:59:07.120 --> 00:59:07.120
Bye.

00:59:07.120 --> 00:59:07.760
Bye.

00:59:07.760 --> 00:59:07.760
Bye.

00:59:07.760 --> 00:59:07.760
Bye.

00:59:07.760 --> 00:59:07.760
Bye.

00:59:07.760 --> 00:59:08.400
Bye.

00:59:08.400 --> 00:59:08.400
Bye.

00:59:08.400 --> 00:59:08.400
Bye.

00:59:08.400 --> 00:59:09.040
Bye.

00:59:09.040 --> 00:59:09.040
Bye.

00:59:09.040 --> 00:59:09.040
Bye.

00:59:09.040 --> 00:59:09.680
Bye.

00:59:09.680 --> 00:59:09.680
Bye.

00:59:09.680 --> 00:59:09.680
Bye.

00:59:09.680 --> 00:59:09.680
Bye.

00:59:09.680 --> 00:59:10.320
Bye.

00:59:10.320 --> 00:59:10.320
Bye.

00:59:10.320 --> 00:59:10.320
Bye.

00:59:10.320 --> 00:59:10.960
Bye.

00:59:10.960 --> 00:59:10.960
Bye.

00:59:10.960 --> 00:59:10.960
Bye.

00:59:10.960 --> 00:59:11.460
you

00:59:11.460 --> 00:59:11.960
you

00:59:11.960 --> 00:59:12.460
you

00:59:12.460 --> 00:59:14.460
Thank you.

00:59:14.460 --> 00:59:44.440
Thank you.

