WEBVTT

00:00:00.001 --> 00:00:04.520
On the last episode, we explored Pyodide, a project whose goal is to bring the CPython

00:00:04.520 --> 00:00:09.800
scientific stack to the browser via WebAssembly. This time, I meet up with Brett Cannon,

00:00:09.800 --> 00:00:14.300
one of the more well-known and prolific core developers, to explore what role WebAssembly

00:00:14.300 --> 00:00:19.700
has for CPython in general and what opportunities might exist for Python and WebAssembly at the

00:00:19.700 --> 00:00:26.960
moment. This is Talk Python To Me, episode 213, recorded on-site at PyCon on May 3rd, 2019.

00:00:26.960 --> 00:00:45.040
Welcome to Talk Python To Me, a weekly podcast on Python, the language, the libraries, the

00:00:45.040 --> 00:00:49.620
ecosystem, and the personalities. This is your host, Michael Kennedy. Follow me on Twitter,

00:00:49.620 --> 00:00:54.320
where I'm @mkennedy. Keep up with the show and listen to past episodes at talkpython.fm,

00:00:54.320 --> 00:00:58.880
and follow the show on Twitter via at Talk Python. This episode is brought to you by

00:00:58.880 --> 00:01:02.200
Microsoft. Be sure to check out what they're offering during their segments.

00:01:02.200 --> 00:01:06.400
It really helps support the show. Hey, folks. Thanks for listening in today.

00:01:06.400 --> 00:01:11.820
Just a quick heads up on the audio on this one. We recorded it live on the Expo floor hall at PyCon

00:01:11.820 --> 00:01:16.880
in Cleveland this year. I think the audio is actually amazing and came out great, but you will hear our

00:01:16.880 --> 00:01:21.980
voices straining a bit to talk over the crowd, and my voice in particular has a little road wear from

00:01:21.980 --> 00:01:26.940
all that conferencing. So sorry for my fading voice, but you'll enjoy the conversation with

00:01:26.940 --> 00:01:30.400
Brett for sure. Brett, welcome back to Talk Python.

00:01:30.400 --> 00:01:31.920
Thank you, Michael. Glad to be here.

00:01:31.920 --> 00:01:35.740
It's great to have you here. It's been too long. I mean, what has it been like? Three episodes?

00:01:35.740 --> 00:01:38.560
Has it even been that many? I don't know if it's even gone that far.

00:01:38.560 --> 00:01:44.300
I know. I don't think it has. But we're back together because we had a great show talking about

00:01:44.300 --> 00:01:49.760
the steering council, the future of Python governance, and all that kind of stuff. And then we hung up.

00:01:49.760 --> 00:01:54.740
Well, we stopped the recording. And I just threw this offhand comment about, oh, and what do you

00:01:54.740 --> 00:01:59.460
think about WebAssembly? Yeah. I mean, this happens every time I come on your show. We end up chatting

00:01:59.460 --> 00:02:03.280
after the hangup. And then it comes up, oh, we should have brought that up while we actually had

00:02:03.280 --> 00:02:08.400
the microphones recording. Yeah. And so we're going to be here at PyCon. We're recording live from the

00:02:08.400 --> 00:02:14.320
PyCon Expo Hall Center here. And that's what the background noise is everyone hears. So we're

00:02:14.320 --> 00:02:19.320
going to talk a little bit about WebAssembly. And I guess maybe we should start with what is this

00:02:19.320 --> 00:02:25.920
WebAssembly? Why is it interesting? To me, it seems like WebAssembly is starting to gain some traction.

00:02:25.920 --> 00:02:32.460
Yeah. So I'm going to preface all of this as I'm a fan and keep up on this out of interest. I actually

00:02:32.460 --> 00:02:38.220
almost made something similar to this, my PhD thesis, except my PhD supervisor, Eric Wellstetter,

00:02:38.220 --> 00:02:44.500
was smart enough to say, no, that's a bit ambitious for one PhD because that's going to take three or

00:02:44.500 --> 00:02:48.920
four other PhD students. And he didn't want to dedicate that much time of his life to the topic.

00:02:48.920 --> 00:02:51.120
I'll be your advisor, but come on, not for life.

00:02:51.120 --> 00:02:55.460
Exactly. So I'm just going to fully admit, I could quite possibly say something wrong about this.

00:02:55.460 --> 00:03:00.920
But basically to explain what WebAssembly is, is the browser vendors all got together realizing that

00:03:00.920 --> 00:03:05.580
while JavaScript is nice, it's not the end of the world and the best answer necessary for everyone.

00:03:05.580 --> 00:03:11.960
and they want a more lower level kind of target for languages in browser. And so they basically

00:03:11.960 --> 00:03:18.860
designed an assembly language specifically for the web. And the key thing here is you can think of it as

00:03:18.860 --> 00:03:25.680
basically like x86 or ARM or RISC or any of those other chips that have the low level assembly commands

00:03:25.680 --> 00:03:31.160
that the CPU actually executes. But the key thing here is it was designed to be performant,

00:03:31.360 --> 00:03:36.120
but also verifiable to be safe because as we know on the web, you can't trust everything that

00:03:36.120 --> 00:03:39.760
could send to your browser. So they very much made sure it was fast and verifiable, which is

00:03:39.760 --> 00:03:41.880
and cross-platform, which is also very cool.

00:03:41.880 --> 00:03:47.120
Yeah, I think that's the first danger when you think, all right, we have this binary thing and

00:03:47.120 --> 00:03:52.320
we're going to download it and execute it in your browser. They're like, oh my God, is this ActiveX?

00:03:52.420 --> 00:03:56.180
Is this calm? Is this the thing that's going to hack all the machines?

00:03:56.180 --> 00:04:03.760
We all know you do not download a random binary off the internet and run it and expect not to get

00:04:03.760 --> 00:04:07.980
some nasty malware installed on your machine. And the same goes for WebAssembly. You don't want

00:04:07.980 --> 00:04:13.300
a buffer overflow in your browser, right? That's hard enough just for the browser vendors to do with

00:04:13.300 --> 00:04:16.840
the render. The last thing you want is the JavaScript or anything else you download to just make

00:04:16.840 --> 00:04:22.200
a button flash to actually cause a buffer overflow and suddenly take over your machine.

00:04:22.200 --> 00:04:29.320
Right. So WebAssembly is kind of this assembly language. It's faster, it's binary, but it's run

00:04:29.320 --> 00:04:31.420
within the same sandbox as JavaScript.

00:04:31.420 --> 00:04:32.800
Yes, from my understanding.

00:04:32.800 --> 00:04:33.360
More or less.

00:04:33.360 --> 00:04:33.580
Yeah.

00:04:33.580 --> 00:04:38.300
But there's some really interesting things. A lot of things that compile to see can be made to compile

00:04:38.300 --> 00:04:39.140
to WebAssembly.

00:04:39.140 --> 00:04:43.800
Yeah. And that was actually the original way they tested this idea was there was a project called

00:04:43.800 --> 00:04:50.000
asim.js and they created a tool for LLVM called mscripten. And what they did was they just came

00:04:50.000 --> 00:04:55.260
up with a subset of JavaScript that you could actually compile C down to. And it was basically

00:04:55.260 --> 00:05:02.020
typed arrays to simulate a stack in memory and a bunch of other stuff. And they basically made it

00:05:02.020 --> 00:05:07.740
work. And they were able to show that if you added certain markers to tell the JavaScript's

00:05:07.740 --> 00:05:11.180
execution engines that, hey, you know what? This is actually asim.js, not normal JavaScript.

00:05:11.480 --> 00:05:14.760
They could actually get really good performance out of it. And that was enough of a motivation

00:05:14.760 --> 00:05:18.700
for them to go like, okay, let's make this a real thing. Let's not do kind of a weird little

00:05:18.700 --> 00:05:22.820
subset of JavaScript. Let's like do a proper assembly language that will still get us the

00:05:22.820 --> 00:05:27.200
exact same compile target and safety with even better performance.

00:05:27.200 --> 00:05:31.820
Right. Let's not try to treat JavaScript truly as assembly language, but make something that

00:05:31.820 --> 00:05:33.440
executes like binary bits, right?

00:05:33.440 --> 00:05:37.820
Exactly. Everyone's already compiled to JavaScript and knows it's possible, but let's actually take

00:05:37.820 --> 00:05:40.960
it to the next level and actually compile to a reasonable target.

00:05:40.960 --> 00:05:45.440
That's awesome. Did you happen to catch the birth and death of JavaScript by Gary Barnhart?

00:05:45.440 --> 00:05:46.300
No, I didn't.

00:05:46.300 --> 00:05:50.680
Oh my gosh. So this is such an insightful thing. So people out there listening, they're interested.

00:05:50.680 --> 00:05:52.940
They should definitely Google that. Maybe I'll put it in the show notes.

00:05:53.240 --> 00:06:01.440
It's a talk he did at PyCon, I think 2015. And it imagines a future where JavaScript takes over the

00:06:01.440 --> 00:06:07.660
world, talks about the future, like 2030, going down this Asm.js world and things being compiled

00:06:07.660 --> 00:06:11.940
deeper and deeper and deeper in the world, just being all JavaScript. And it's both super insightful

00:06:11.940 --> 00:06:17.500
because it talks about these things and predicts stuff. He's got examples of like having Quake,

00:06:17.660 --> 00:06:23.040
which is written in C run in Chrome, but then recompile Chrome to run in Firefox. So like

00:06:23.040 --> 00:06:28.680
Firefox is running Chrome, Chrome is running Quake, all like nested together in this, like it's

00:06:28.680 --> 00:06:30.280
turtles all the way down with JavaScript.

00:06:30.280 --> 00:06:34.960
Well, actually, I don't know if you caught Dan Callahan's keynote at PyCon US in 2018,

00:06:34.960 --> 00:06:41.080
but he did something similar where he showed a VR of a computer in a basement running similar

00:06:41.080 --> 00:06:46.580
Windows 3.1 running a browser in it. So you can go very deep with this stuff.

00:06:46.580 --> 00:06:51.120
Right. And so many of those were these sort of these proof of concepts into some JavaScript

00:06:51.120 --> 00:06:54.300
world. But WebAssembly is like, well, that's cool. Let's make that official.

00:06:54.300 --> 00:06:54.600
Yes.

00:06:54.600 --> 00:07:01.900
That's the stage for what the heck is WebAssembly. Now the big question is, CPython, right in its name,

00:07:01.900 --> 00:07:08.900
we know it's written in C. What are the possibilities for it being interacting with,

00:07:08.900 --> 00:07:10.960
doing interesting things with WebAssembly?

00:07:10.960 --> 00:07:15.620
There's basically two current projects that I'm aware of. So one is Pyodide,

00:07:15.620 --> 00:07:18.800
which I believe you'll have an episode out on this, if not already.

00:07:18.800 --> 00:07:23.100
Due to time shifting. It's not out yet, but it's out before this. So people will have heard of that.

00:07:23.100 --> 00:07:27.840
So go back and listen to that episode. But basically, someone at Mozilla has taken CPython

00:07:27.840 --> 00:07:32.740
and the scientific Python stack, so SciPy, NumPy, Pandas, all those.

00:07:32.740 --> 00:07:34.680
Which are heavily C underneath, right?

00:07:34.680 --> 00:07:37.700
Oh, and more, right? Because this also includes Fortran stuff.

00:07:37.860 --> 00:07:39.640
Like, this is deep level stuff, right?

00:07:39.640 --> 00:07:41.580
SciPy is crazy to compile.

00:07:41.580 --> 00:07:46.680
But what they did was, is they actually compiled that whole stack down to WebAssembly.

00:07:46.680 --> 00:07:47.960
And they got it running.

00:07:47.960 --> 00:07:54.300
And if I remember correctly from the blog post, they said it was three or four to 12 times slower,

00:07:54.300 --> 00:07:56.420
which is not great.

00:07:56.420 --> 00:08:01.840
I mean, compared to some things, but it was still actually fairly performant to the point that they actually,

00:08:01.840 --> 00:08:09.880
Mozilla has a demo, I believe, of Jupyter Notebook style workflow for data science exploration that actually works reasonably well.

00:08:09.880 --> 00:08:10.240
Yeah.

00:08:10.420 --> 00:08:14.400
And what's cool about that project is they've actually compiled the libraries that you need.

00:08:14.640 --> 00:08:19.440
So you can import NumPy, you can import Pandas in the browser.

00:08:19.440 --> 00:08:24.400
It'll go get the WebAssembly equivalent, suck that down on demand, by the way, which is cool.

00:08:24.400 --> 00:08:26.240
It doesn't even suck it all down in front.

00:08:26.240 --> 00:08:28.060
It's like, wait till you hit the import statement.

00:08:28.640 --> 00:08:30.140
And it sucks it down and it runs.

00:08:30.140 --> 00:08:31.240
So that's pretty cool.

00:08:31.240 --> 00:08:34.980
But to me, what that feels like, and not to take anything away from it, it's super cool,

00:08:34.980 --> 00:08:40.340
is that feels like, let's take the compilers we have and point them at the version we have

00:08:40.340 --> 00:08:43.700
and make them run in this place best we can.

00:08:43.700 --> 00:08:51.700
But it's not saying, what if we imagined what a CPython-developed for WebAssembly could be?

00:08:51.700 --> 00:08:52.260
Yes.

00:08:52.260 --> 00:08:56.500
It's very much a, let's take what we have already and see if we can make it work.

00:08:56.500 --> 00:08:59.500
Not a, let's make this a target of something.

00:08:59.500 --> 00:09:01.140
And what does that look like?

00:09:01.140 --> 00:09:02.000
That's a good question.

00:09:02.000 --> 00:09:03.100
That is a good question.

00:09:03.100 --> 00:09:04.920
So I think it's, I mean, it's super noble.

00:09:04.920 --> 00:09:06.200
It's awesome that they've done it.

00:09:06.200 --> 00:09:09.060
And like having Quake run in the browser, it proves it could be done.

00:09:09.060 --> 00:09:09.400
Yes.

00:09:09.400 --> 00:09:12.340
But size, size matters sometimes on the web.

00:09:12.340 --> 00:09:12.780
Right.

00:09:12.780 --> 00:09:17.240
And they fully admit in the PyoDiode project, I believe the download for the interpreter is

00:09:17.240 --> 00:09:19.180
40 megs, roughly.

00:09:19.180 --> 00:09:21.660
So it's not small.

00:09:21.660 --> 00:09:26.460
We might all be living with one multi-meg pages now, unfortunately.

00:09:26.940 --> 00:09:28.340
But they're not 40 megs.

00:09:28.340 --> 00:09:29.240
No one's that crazy.

00:09:29.240 --> 00:09:31.000
So there's definitely issues.

00:09:31.000 --> 00:09:36.000
Now, I'm also going to say that not all use cases for WebAssembly necessarily require a

00:09:36.000 --> 00:09:36.740
smaller download size.

00:09:36.740 --> 00:09:39.180
So for instance, if we were doing an Electron app.

00:09:39.180 --> 00:09:40.360
Like Visual Studio Code.

00:09:40.360 --> 00:09:41.420
Visual Studio Code.

00:09:41.420 --> 00:09:42.600
Or something else.

00:09:42.800 --> 00:09:47.840
Slack or any other Electron app I can see out on the shore floor from someone sponsoring PyCon.

00:09:47.840 --> 00:09:50.380
They don't have that download size restriction.

00:09:50.380 --> 00:09:53.760
They could totally just embed a 40 meg version and be done with it.

00:09:53.760 --> 00:09:53.940
Right.

00:09:53.940 --> 00:09:59.240
The Electron JS apps, for people who don't know, already embed the binaries of Chrome plus the

00:09:59.240 --> 00:10:00.060
binaries of Node.

00:10:00.060 --> 00:10:03.040
So throw in a few more megabytes of WebAssembly.

00:10:03.040 --> 00:10:03.760
Who cares, right?

00:10:03.760 --> 00:10:04.340
Whatever.

00:10:04.340 --> 00:10:10.560
But obviously, if we wanted this to be on the web or in more size restricted situations,

00:10:10.560 --> 00:10:16.820
like we're talking more embedded space or you're embedding it in a smaller, more native desktop

00:10:16.820 --> 00:10:18.920
app, like think Blender or something.

00:10:19.420 --> 00:10:20.900
That's where you start to care about the size.

00:10:20.900 --> 00:10:22.900
So directly compiling and see Python.

00:10:22.900 --> 00:10:29.040
While great is a great solution for today, it might not be if we want to potentially expand

00:10:29.040 --> 00:10:30.760
the possibilities in the future.

00:10:30.760 --> 00:10:31.080
Right.

00:10:31.080 --> 00:10:32.460
And Python is doing awesome.

00:10:32.460 --> 00:10:36.700
I mean, we've seen the stack overflow, the incredible growth of Python article.

00:10:36.700 --> 00:10:37.040
Yep.

00:10:37.040 --> 00:10:39.420
I mean, look around PyCon this year.

00:10:39.420 --> 00:10:43.260
Like to me, when I walked in here, I felt like, wow, Python's grown up a little bit.

00:10:43.260 --> 00:10:46.240
Like these booths are a little more corporate, a little more pro.

00:10:46.240 --> 00:10:46.880
They're like taller.

00:10:46.880 --> 00:10:49.220
I don't know what that means, but they're like twice as tall as last year.

00:10:49.220 --> 00:10:49.580
Yeah.

00:10:49.580 --> 00:10:53.540
I mean, I was kind of shocked when I came in here and I saw stuff hanging from the ceiling.

00:10:53.540 --> 00:10:59.580
I saw people with walls put up and these aren't just like custom for the booth walls.

00:10:59.580 --> 00:11:02.160
I mean, this is really slick stuff coming in here.

00:11:02.160 --> 00:11:05.400
So yeah, Python's definitely come a long way since I started using it.

00:11:05.400 --> 00:11:05.720
Yeah.

00:11:05.720 --> 00:11:07.560
And so my point is, that's amazing.

00:11:07.560 --> 00:11:14.720
But how far would it go if it could be in mobile, if it could be on the front end of web,

00:11:14.720 --> 00:11:17.300
if it could be the foundation of these Electron JSA?

00:11:17.300 --> 00:11:18.880
I mean, there's like lots of growth.

00:11:19.020 --> 00:11:20.940
There's headroom here for more.

00:11:20.940 --> 00:11:21.420
Yeah.

00:11:21.420 --> 00:11:28.100
And if you get a chance, watch Russell Keith McGee's keynote from PyCon US 2019.

00:11:28.100 --> 00:11:29.220
It was on Friday.

00:11:29.220 --> 00:11:36.340
He did a really good job of outlining why this is a potentially great growth opportunity for Python.

00:11:36.340 --> 00:11:38.360
We're in a lot of spaces, right?

00:11:38.360 --> 00:11:39.640
As I said, we're embedded.

00:11:39.640 --> 00:11:41.520
We do scripting.

00:11:41.620 --> 00:11:43.620
We do some desktop apps.

00:11:43.620 --> 00:11:44.960
We do web.

00:11:44.960 --> 00:11:46.280
We do data science.

00:11:46.280 --> 00:11:51.740
But for instance, we haven't really tapped into the mobile space or the web space front end.

00:11:51.740 --> 00:11:53.020
Obviously, we got backhand covered.

00:11:53.440 --> 00:11:57.860
So there's definitely opportunity for us to grow the community and help bring more people in.

00:11:57.860 --> 00:12:00.440
Because I've been told we have one of the best communities in the world.

00:12:00.440 --> 00:12:07.020
So I'd like to honestly do this just so we can get more people actually in and participating and off of communities that they might not be happy with.

00:12:07.140 --> 00:12:07.260
Yeah.

00:12:07.260 --> 00:12:12.860
And to me, it feels like WebAssembly kind of holds the key to unlocking some of those possibilities.

00:12:12.860 --> 00:12:13.360
Yeah.

00:12:13.360 --> 00:12:15.360
I think it's a definite possibility.

00:12:15.360 --> 00:12:20.480
I don't think we can necessarily claim it's definitely a panacea or that it's an obvious black swan event.

00:12:20.480 --> 00:12:21.700
Another reference to Russell's keynote.

00:12:22.260 --> 00:12:27.740
But I think there's definitely enough there to make it a very interesting possibility worth looking into.

00:12:27.740 --> 00:12:28.060
Okay.

00:12:28.060 --> 00:12:32.560
So I guess let's think about you are on the core dev team.

00:12:32.560 --> 00:12:34.000
You are also on the steering council.

00:12:34.000 --> 00:12:38.320
You obviously don't make all the decisions, but you're in a place to have some internal insights.

00:12:38.320 --> 00:12:39.860
What would need to happen?

00:12:39.860 --> 00:12:46.660
Or is there any possibility of CPython having an official WebAssembly story?

00:12:46.660 --> 00:12:48.060
I don't know.

00:12:48.400 --> 00:12:52.560
So in any official capacity, I have to say, I don't know.

00:12:52.560 --> 00:12:54.580
Personally, I would love to see it.

00:12:54.580 --> 00:13:05.140
One thing I can say is we've had some very initial discussions on the steering council about kind of coming up with a vision document of what would it take to make Python two times faster?

00:13:05.140 --> 00:13:05.480
Right.

00:13:05.480 --> 00:13:09.280
And kind of like outlining like what do we view as necessary?

00:13:09.280 --> 00:13:10.380
What do we view as acceptable?

00:13:10.380 --> 00:13:13.440
What do we view as total fertile ground?

00:13:13.440 --> 00:13:15.040
And we don't care what you do.

00:13:15.040 --> 00:13:17.840
And we've just started talking about this.

00:13:17.920 --> 00:13:19.260
So there's nothing specific there.

00:13:19.260 --> 00:13:24.460
But I mean, you could theoretically think of some company going like, oh, okay, I've read this document.

00:13:24.460 --> 00:13:25.740
I see kind of where you're going.

00:13:25.740 --> 00:13:29.240
We're going to take a stab at it and we're going to try to make a WebAssembly Python.

00:13:29.240 --> 00:13:31.640
Now, who knows what that means?

00:13:31.640 --> 00:13:39.640
That could either mean let's see what happens if we didn't do see Python to WebAssembly, but we still had an interpreter that was more restricted to make the size smaller.

00:13:39.800 --> 00:13:43.420
Or someone could even do a straight Python to WebAssembly compilation target.

00:13:43.420 --> 00:13:45.580
Now, I don't know what we'd have to give up for that.

00:13:45.580 --> 00:13:55.100
For instance, for my reading of the spec, WebAssembly doesn't provide a way to directly execute on the fly compiled WebAssembly like actual assembly does.

00:13:55.100 --> 00:13:55.300
Right.

00:13:55.360 --> 00:13:56.400
That's how JITs work.

00:13:56.400 --> 00:14:02.560
They actually write to a memory point and you basically treat it like a function pointer in C and that just magically gets executed.

00:14:02.560 --> 00:14:04.860
There is no equivalent from what I can tell in WebAssembly.

00:14:05.040 --> 00:14:11.460
So that would potentially make eval and exec a problem if we were trying to compile Python straight to WebAssembly.

00:14:11.460 --> 00:14:26.080
But I think there's opportunity there to explore all this stuff and see where it goes because there's general excitement from what I've been seeing and hearing from people about this idea, not just for Python, but the overall tech community as a really clear, cool opportunity.

00:14:26.080 --> 00:14:32.900
I mean, Cloudflare is doing JavaScript on the edge computing, but it's JavaScript, but you can compile the WebAssembly.

00:14:32.900 --> 00:14:36.840
And then recently Fastly came out and just said, we're doing straight WebAssembly.

00:14:36.840 --> 00:14:38.480
That's all we're doing for their edge computing.

00:14:38.480 --> 00:14:44.040
There just seems to be a real kind of conglomeration of people, at least in the web space around this as a thing.

00:14:44.040 --> 00:14:47.500
And obviously, we all know the web's got a lot of money and a lot of push.

00:14:47.500 --> 00:14:50.180
So I think it's worth at least considering and taking a look.

00:14:50.180 --> 00:14:51.560
Yeah, that's a super interesting point.

00:14:51.560 --> 00:14:54.840
There's definitely a huge, huge number of users there.

00:14:54.840 --> 00:14:58.780
I mean, Flask, we consider Flask to be like one of the more popular things, right?

00:14:58.780 --> 00:15:00.500
It's got 41,000 GitHub stars.

00:15:00.840 --> 00:15:04.080
Just Vue.js has 140,000.

00:15:04.080 --> 00:15:06.180
I mean, like the scale is massive, right?

00:15:06.180 --> 00:15:08.360
So the days are early, I think.

00:15:08.360 --> 00:15:17.580
So if we could tap into the whole WebAssembly space at the early days, you know, how much could we make Python a first class citizen there?

00:15:17.840 --> 00:15:24.460
Yeah, I mean, and that's really what I would love someone who has the time and resources to actually look into, right?

00:15:24.460 --> 00:15:27.780
Like really doing the research, finding out how possible it is.

00:15:27.780 --> 00:15:28.800
What would we gain?

00:15:28.800 --> 00:15:34.400
What could we make it as fast to see Python if it is slower or faster by how much?

00:15:34.400 --> 00:15:39.200
It's something I would just love for someone to just go out and try.

00:15:39.360 --> 00:15:40.080
Yeah, it's super interesting.

00:15:40.080 --> 00:15:42.420
I mean, we talked about Pyodide, and that's really great.

00:15:42.420 --> 00:15:47.060
But that's super focused on getting the scientific stack on the client side in the browser.

00:15:47.060 --> 00:15:50.420
Yeah, and I believe Mozilla even admits that it's fully a proof of concept.

00:15:50.420 --> 00:15:52.360
It's to show that this is possible.

00:15:52.360 --> 00:15:54.240
I don't know how far they plan to take it.

00:15:54.240 --> 00:15:56.740
So I don't know where they could even push it.

00:15:56.740 --> 00:15:57.980
But I mean, it'd be great to see.

00:15:57.980 --> 00:16:05.740
Yeah, another one that's really interesting that's not anything to do with Python but comes from your home base in the Microsoft world is Blazor.

00:16:05.740 --> 00:16:06.700
Are you familiar with Blazor?

00:16:06.700 --> 00:16:07.380
A little bit.

00:16:07.380 --> 00:16:18.400
Yeah, so Blazor is take the .NET CLR, which is also JIT-based, and take C# and turn that into a front-end single-page app framework through WebAssembly.

00:16:18.400 --> 00:16:29.080
So if they were able to get the CLR and all the UI bits down, it seems like the CLR and CPython are sort of comparable in size and complexity, ignoring the libraries.

00:16:29.080 --> 00:16:43.260
I think it definitely shows that with the resourcing, it's definitely possible to use WebAssembly as a target, even as it is, which the WebAssembly team and the website and everything are very clear that this is very much a minimum viable product.

00:16:43.260 --> 00:16:45.460
And they are still very much working towards it.

00:16:45.460 --> 00:16:50.360
Like, they just announced something called WASI, W-A-S-I, which adds a system interface.

00:16:50.360 --> 00:16:58.700
That's what the S-I stands for, to WebAssembly, because they realize that with a portable target, you can now actually start using this for more desktop application and execution, right?

00:16:58.700 --> 00:17:06.540
So basically, if you start to treat WebAssembly as kind of the world's common interpreter layer, and you start targeting that, it starts to really open up.

00:17:06.540 --> 00:17:11.680
And in order to make that work, you really have to have that layer of basically POSIX on Unix would cover.

00:17:11.680 --> 00:17:14.080
And so they're very much working towards that.

00:17:14.200 --> 00:17:17.700
It's still early days, but once again, there's definite possibility there.

00:17:17.700 --> 00:17:18.020
Absolutely.

00:17:18.020 --> 00:17:19.660
So let's bring it back to your original statement.

00:17:19.660 --> 00:17:24.060
What if you could make CPython two times, well, Python two times faster?

00:17:24.060 --> 00:17:25.980
What are some of the ideas you have there?

00:17:25.980 --> 00:17:28.880
For Python, it's in general or specifically for WebAssembly?

00:17:28.880 --> 00:17:29.960
Let's start with in general.

00:17:29.960 --> 00:17:37.880
I think the key thing there is going to be really outline exactly what is like things we just cannot give up, right?

00:17:37.880 --> 00:17:41.160
Like compatibility, at what level?

00:17:41.160 --> 00:17:42.700
Where would we go?

00:17:42.700 --> 00:17:47.220
Like, okay, if we gave this up, the community would just never even contemplate it.

00:17:47.220 --> 00:17:48.840
It just would break way too much code, whatever.

00:17:48.840 --> 00:17:49.640
It just wouldn't work.

00:17:49.640 --> 00:17:49.840
Right.

00:17:49.880 --> 00:17:52.480
If C extensions went away, that's probably a bridge too far.

00:17:52.480 --> 00:17:52.920
Exactly.

00:17:52.920 --> 00:17:53.620
Right.

00:17:53.740 --> 00:17:57.620
Like, what would we be okay with transitioning, right?

00:17:57.620 --> 00:18:01.940
Like we've done two to three and we know how difficult that was, but we also know why that was difficult.

00:18:01.940 --> 00:18:08.280
If we had ways to automate bridging and such so that that pain wasn't there, that's a possibility.

00:18:08.280 --> 00:18:11.640
I think it's PEP554 that is multiple sub-interpreters.

00:18:11.640 --> 00:18:11.940
Yeah.

00:18:11.940 --> 00:18:12.600
Eric Snow's PEP.

00:18:12.600 --> 00:18:12.920
Yep.

00:18:12.920 --> 00:18:17.400
Would it be possible to maybe use that as a compatibility layer these days?

00:18:17.400 --> 00:18:18.160
Right?

00:18:18.160 --> 00:18:20.420
Like you take the stuff that runs over here and you got to do an eval.

00:18:20.420 --> 00:18:22.000
So we're going to do the eval and another.

00:18:22.000 --> 00:18:23.120
That's an interesting idea.

00:18:23.120 --> 00:18:24.500
I honestly have not thought about it.

00:18:24.500 --> 00:18:25.140
That's all I know.

00:18:25.140 --> 00:18:26.380
I haven't really thought much about it either.

00:18:26.380 --> 00:18:33.140
But it seems like you might be able to have like a compatible older CPython that handles the cases that's not as fast.

00:18:33.140 --> 00:18:36.180
And then like a proper, maybe like a jitting.

00:18:36.180 --> 00:18:39.500
That comes tricky because all that's running in the same process.

00:18:39.500 --> 00:18:49.520
So suddenly you're getting a multiprocessing scenario and that always has its own kind of worms that if you're not really aware of how it's working and what the edge cases are, it can really show my problem.

00:18:49.520 --> 00:18:50.520
So I don't know.

00:18:50.520 --> 00:18:51.400
Maybe it's not worth pursuing.

00:18:51.400 --> 00:18:52.480
Yeah, probably not.

00:18:52.480 --> 00:18:52.940
Yeah.

00:18:52.940 --> 00:18:58.120
I know a lot of people want that idea of when we're doing the two to three bridging and no one ever really got to work properly.

00:18:58.120 --> 00:19:00.900
So I'm going to assume in any other scenario, it just ain't going to work.

00:19:00.900 --> 00:19:01.920
It just wasn't worth the trouble.

00:19:01.920 --> 00:19:02.520
Okay.

00:19:02.520 --> 00:19:03.180
Interesting.

00:19:03.180 --> 00:19:04.320
I honestly don't know.

00:19:04.320 --> 00:19:06.720
Like I know there's Rust Python and people are working on that.

00:19:06.720 --> 00:19:10.420
I've always been curious to see what Rust could give us in terms of safety and performance.

00:19:10.420 --> 00:19:18.220
I also know though, some people don't want to go that route because at least in CPython's case, Rust is not available on every platform where there's a C compiler.

00:19:18.220 --> 00:19:25.520
And so there and the embedding story is there, but it's not necessarily quite as straightforward if you don't put in the work to do that.

00:19:25.520 --> 00:19:30.360
I mean, you can give FFIs through C through Rust, but that's an extra layer of work.

00:19:30.360 --> 00:19:30.680
Right.

00:19:30.680 --> 00:19:32.440
Maybe slower too with another layer.

00:19:32.440 --> 00:19:36.520
So I think the key thing here is also don't focus too much on CPython itself.

00:19:36.520 --> 00:19:40.200
I mean, if we're talking website, we're talking basically a whole new thing.

00:19:40.200 --> 00:19:43.420
So I totally up and just even first proof of concept for whatever.

00:19:43.420 --> 00:19:48.580
I would want people to try anything and don't tie yourself to CPython as necessarily the starting point.

00:19:48.580 --> 00:19:51.740
Tie yourself to CPython as kind of the way to test your compatibility.

00:19:52.040 --> 00:19:58.540
Although I would still say, don't tie yourself to every edge case and every little potential bug.

00:19:58.540 --> 00:20:10.620
Because Guido has even said before he retired that really small edge casey parts of the language that no one really uses would be up for consideration from being deprecated and removed from language if it made a massive performance difference.

00:20:11.180 --> 00:20:13.280
So people have also never done that exploration.

00:20:13.280 --> 00:20:17.740
So we even have that potential, regardless of WebAssembly, of ways to potentially speed up Python.

00:20:20.000 --> 00:20:23.280
This portion of Talk Python To Me is brought to you by Microsoft.

00:20:23.280 --> 00:20:28.560
For ultimate developer productivity in the cloud, use Azure extensions for Visual Studio Code.

00:20:28.560 --> 00:20:32.740
You can deploy and debug your serverless Python apps directly from your editor.

00:20:32.740 --> 00:20:44.340
On Azure, you can run your Python apps as serverless code on Linux web apps and functions or on top of managed Kubernetes and easily connect data from database services, including Postgres and MySQL.

00:20:44.480 --> 00:20:52.740
You can also use Azure DevOps to create cross-platform builds of your Python packages with hosted macOS, Linux, and Windows build machines.

00:20:52.740 --> 00:20:56.460
And publish them to Azure Artifacts for your own hosted PyPI feed.

00:20:56.460 --> 00:21:00.460
Azure DevOps is free for open source projects and many are using it already.

00:21:00.460 --> 00:21:04.300
Get started for free at talkpython.fm/Microsoft.

00:21:04.300 --> 00:21:07.780
We've had a lot of progress, right?

00:21:07.780 --> 00:21:08.400
Yes.

00:21:08.400 --> 00:21:11.880
From 3.5, maybe 3.4, let's say 3.4 to 3.7.

00:21:11.880 --> 00:21:12.280
Yes.

00:21:12.280 --> 00:21:18.080
The stuff that Victor Stenner was doing and other people, you would hear, oh, dictionaries got this much faster.

00:21:18.080 --> 00:21:21.760
Function calls got 20% faster, bound methods or whatever, right?

00:21:21.760 --> 00:21:24.280
Year over year, that stuff's compounding as well, right?

00:21:24.280 --> 00:21:30.820
And I don't think we've even necessarily hit all the low-hanging fruit, but I do believe that we're reaching a point where I think on the team,

00:21:30.820 --> 00:21:40.420
we're realizing that our goal from years back of keeping the interpreter simple, specifically to make it easier to contribute to,

00:21:40.420 --> 00:21:42.620
by making it easier to comprehend how it works.

00:21:42.620 --> 00:21:45.420
Basically, Python's so big, we can't really do that anymore.

00:21:45.420 --> 00:21:52.260
I think we've hit the point now where we don't worry about whether a single individual can fully comprehend how the entire interpreter works,

00:21:52.320 --> 00:21:54.520
because we realize that so many people rely on it.

00:21:54.520 --> 00:21:59.520
We need to keep it maintainable, obviously, but we don't need to keep it simple.

00:21:59.520 --> 00:22:01.460
And that's a very key distinction.

00:22:01.460 --> 00:22:06.800
And so I think there's opportunity there, once again, if someone had the time and resources to really dig into that

00:22:06.800 --> 00:22:12.860
and see what would be possible to actually speed up CPython itself and obviously whatever crazy thing someone might do.

00:22:13.120 --> 00:22:18.320
What's the possibility, likelihood of some kind of JIT making it a point?

00:22:18.320 --> 00:22:19.360
I know you worked on Pigeon.

00:22:19.360 --> 00:22:19.740
Yep.

00:22:19.740 --> 00:22:24.160
Which maybe, I lived in a different country when we last spoke about Pigeon.

00:22:24.160 --> 00:22:25.800
Maybe tell people quickly about what that is.

00:22:25.800 --> 00:22:29.300
Pigeon, for those of you who don't know, and it's spelled P-Y-J-I-O-N,

00:22:29.300 --> 00:22:38.120
was a project with Dino Veland, who was a co-worker at the time, now at Facebook, and myself worked on back in 2016, I believe?

00:22:38.120 --> 00:22:39.040
Yeah, I think it was 2016, yeah.

00:22:39.120 --> 00:22:46.460
Where we looked at what it would take to jet CPython executable bytecode using .NET.

00:22:46.460 --> 00:22:55.480
And we got the project to the point where we developed a PEP for adding a hook into CPython to allow you to override the eval loop,

00:22:55.480 --> 00:22:58.500
the actual function that you pass commands through.

00:22:58.500 --> 00:23:00.860
Which is like 3,000 lines switch.

00:23:00.860 --> 00:23:01.980
It's an impressive thing.

00:23:01.980 --> 00:23:03.260
It's a very large thing.

00:23:03.260 --> 00:23:04.380
Eval.c, yeah, that's it.

00:23:04.380 --> 00:23:06.880
Eval.c has got a, it's quite the impressive function.

00:23:07.340 --> 00:23:14.420
But basically, we tried a way to hook into it such that if we took some Python bytecode and compiled it down into .NET IR,

00:23:14.420 --> 00:23:19.920
which is stack-based as well, which made the translation, I'm not going to say straightforward, but at least possible,

00:23:19.920 --> 00:23:24.640
we did it and we managed to hit the Python benchmark suite pretty much even.

00:23:24.640 --> 00:23:30.900
Unfortunately, once, after we did our PyCon talk, work got in the way and we just weren't able to pursue it any farther.

00:23:31.060 --> 00:23:33.160
Yeah, I remember you said it got even and that's pretty good.

00:23:33.160 --> 00:23:35.740
How much more do you think it could have gotten better?

00:23:35.740 --> 00:23:36.360
A lot?

00:23:36.360 --> 00:23:37.640
Or is it kind of like...

00:23:37.640 --> 00:23:40.320
That's one of those things where with JITs, you just never know.

00:23:40.320 --> 00:23:46.640
Like if you talk to the PyPy folks, they'll fully admit, I'm sure, that PyPy is excellent and can go really fast if it works for you.

00:23:46.640 --> 00:23:51.640
But for some people, they need very deterministic performance because JITs always work on hot code and such.

00:23:51.640 --> 00:23:53.880
And it can be very variant based on the current workload.

00:23:53.880 --> 00:23:53.940
Right.

00:23:53.940 --> 00:23:56.540
With the reference counting in CPython, it's pretty predictable.

00:23:57.020 --> 00:24:06.400
Yeah, exactly. So I don't know what PyJint could have been had we put more time into it because JITs, by definition, are very load dependent.

00:24:06.400 --> 00:24:08.860
And so there's just no way to even speculate.

00:24:08.860 --> 00:24:14.320
How much does a GC and generational garbage collectors are required around JITs?

00:24:14.320 --> 00:24:20.760
I mean, most of that unpredictability has more to do with the garbage collection side of things than they do with the JIT.

00:24:20.760 --> 00:24:23.920
Because you could pre-JIT stuff and things like that if you had to.

00:24:24.100 --> 00:24:26.640
I don't think it necessarily really ties into it specifically.

00:24:26.640 --> 00:24:35.980
So for those of you who don't know, CPython uses reference counting to do its memory management, which basically means we keep track of the number of places an object is referred to in your Python code.

00:24:35.980 --> 00:24:38.920
So every time you do an assignment, the count goes up by one.

00:24:38.920 --> 00:24:42.140
And every time a variable goes away, goes down by one.

00:24:42.140 --> 00:24:44.560
And basically when an object hits zero, we garbage collect it.

00:24:44.560 --> 00:24:44.760
Yeah.

00:24:44.760 --> 00:24:45.660
It's very straightforward.

00:24:45.660 --> 00:24:49.060
But the nice thing about it is it's very deterministic, right?

00:24:49.060 --> 00:24:56.300
So if you define your dunder del on an object, you can actually see that execute fairly quickly after you actually delete the object.

00:24:56.300 --> 00:24:57.820
With garbage collection, you don't get that.

00:24:57.820 --> 00:25:00.840
So really the bigger problem with that has always been the C API.

00:25:00.840 --> 00:25:06.940
Because it's very directly exposed for C extensions to be able to properly manage the memory that they need for any objects they create.

00:25:07.320 --> 00:25:15.040
And that has always been a stumbling block for things like the GIL because in order to control that kind of stuff, there's overhead.

00:25:15.040 --> 00:25:27.580
And the real key thing is the global interpreter lock exists specifically for reference counting because that's how we make sure you don't accidentally stomp on each other when like two threads try to both increment or decrement.

00:25:27.840 --> 00:25:32.420
And you don't want to lose all of those because if you get the count wrong, that's a memory and that's not a good time.

00:25:32.420 --> 00:25:35.220
It's either a crash or it's a memory like depending on which way the race condition runs.

00:25:35.220 --> 00:25:37.720
Yeah, whichever badness you want, choose one.

00:25:37.720 --> 00:25:38.420
Yeah, okay.

00:25:38.420 --> 00:25:41.140
You just don't get to choose though because one of the threads will choose for you, which is the problem.

00:25:41.140 --> 00:25:48.220
So I honestly don't know from a JIT perspective if it really specifically matters depending on how you decide to handle it.

00:25:48.220 --> 00:25:53.920
But getting off of a rust kind of opens things up because it gets rid of that single point of contention with the GIL.

00:25:53.920 --> 00:25:54.460
Right, okay.

00:25:54.460 --> 00:25:55.900
That's interesting.

00:25:56.040 --> 00:25:59.900
I think the GIL gets more negativity than it deserves, honestly.

00:25:59.900 --> 00:26:02.820
It's one of those things where if you're IO bound, it doesn't matter.

00:26:02.820 --> 00:26:08.100
And if you're CPU bound, it can, but only if your load is that high that this is really a critical thing.

00:26:08.100 --> 00:26:08.400
Right.

00:26:08.400 --> 00:26:12.540
So there may be some C library that's already doing parallelism for you or...

00:26:12.540 --> 00:26:12.800
Yeah.

00:26:12.800 --> 00:26:23.600
And if you look at Eric Snow's work with subinterpreters, there's the potential there that if Eric can get it all working to have per interpreter gills,

00:26:23.600 --> 00:26:34.860
which would then give you per thread interpreters, which would then let you have GIL release because basically each interpreter in its own thread running on our gill, which should still have its contention.

00:26:34.860 --> 00:26:40.040
But it's equivalent to basically running completely free threads, which would help a lot.

00:26:40.240 --> 00:26:43.220
And it doesn't require us to completely rewrite every extension.

00:26:43.220 --> 00:26:47.600
And we don't have to try to detangle all this world.

00:26:47.600 --> 00:26:50.540
And we get to keep the very straightforward and determinist reference counting.

00:26:50.540 --> 00:26:51.420
That's all really interesting.

00:26:51.420 --> 00:26:52.920
And I guess sort of a roundabout.

00:26:53.040 --> 00:27:08.280
The reason I was asking about a lot of these things is if your goal is to make Python run twice as fast, there's all these options, but there's all these limitations because of the history of the implementation of C for Python and the C, you know, Val.c and all that.

00:27:08.280 --> 00:27:12.380
What if it was written in something like Rust or something else?

00:27:12.380 --> 00:27:17.220
I guess let me also preface that with like Rust is all about compiling to WebAssembly.

00:27:17.220 --> 00:27:22.840
So could you get your one benefit and then unlock this other WebAssembly world at the same time?

00:27:22.840 --> 00:27:25.240
I think it's definitely possible from my understanding.

00:27:25.240 --> 00:27:30.560
I don't know what kind of restrictions your Rust code has to be placed on it in order to compile down to WebAssembly.

00:27:31.120 --> 00:27:32.660
But I think it's definitely there.

00:27:32.660 --> 00:27:36.180
For some people, CPython is just a Python interpreter.

00:27:36.180 --> 00:27:42.440
And it's not a critical aspect that it has this extensive C API that allows you to do these C extensions.

00:27:42.440 --> 00:27:43.700
And for others, it is.

00:27:43.700 --> 00:27:49.440
And that also varies based on people who embed CPython and a C or C++ application and those who don't.

00:27:49.440 --> 00:27:52.860
Like design apps that have an automation or whatever.

00:27:52.860 --> 00:27:54.360
Yeah, like Blender is a perfect example.

00:27:54.360 --> 00:28:03.620
Blur Maya, a lot of the 3D, the special effects tooling in movies often embed CPython specifically because they want Python embedded as a scripting tool.

00:28:03.620 --> 00:28:10.760
So for those people, that would matter if the hypothetical Rust implementation didn't provide those kind of hooks.

00:28:10.760 --> 00:28:12.540
But for others, it wouldn't.

00:28:12.540 --> 00:28:20.820
This is one of those things where for me personally, I've always viewed it as Python the language as implemented by CPython the interpreter.

00:28:21.000 --> 00:28:24.440
And so I view the key component as the language.

00:28:24.440 --> 00:28:31.040
And we just happen to have this CPython implementation, which, by the way, is really great for embedding as a thing.

00:28:31.040 --> 00:28:42.720
But I don't think that necessarily means that CPython, in my personal view, as like special or in some way untouchable or unreplaceable in terms of at least having other options.

00:28:42.720 --> 00:28:45.140
I mean, PyPy exists and it does have users, right?

00:28:45.140 --> 00:28:46.340
There's a reason it's there.

00:28:46.340 --> 00:28:47.400
It doesn't work for everybody.

00:28:47.400 --> 00:28:48.280
And that's fine.

00:28:48.400 --> 00:29:06.480
The key question is, is does the community and do other people who have the time and resources to put in the work to look at making Python faster, whether it's through WebAssembly or through Rust or through helping make CPython go faster, do they have the stomach and the, honestly, gumption to take some of these paths and try to make it happen?

00:29:06.480 --> 00:29:07.360
That I don't know.

00:29:07.360 --> 00:29:13.480
And honestly, I can't answer that until the community as a whole kind of comes forward and says, we're going to give this a shot and we see what happens.

00:29:13.740 --> 00:29:15.300
Yeah, I mean, that's a really big question.

00:29:15.300 --> 00:29:20.400
We just kind of put to bed this whole Python 2, Python 3 saga.

00:29:20.400 --> 00:29:26.120
And I know it's a totally different story, but it's kind of just churn and fatigue for some folks.

00:29:26.120 --> 00:29:30.060
And so, you know, how much do you want to like rattle that cage?

00:29:30.060 --> 00:29:32.020
Maybe just let things settle for a while.

00:29:32.020 --> 00:29:32.720
I don't know.

00:29:32.720 --> 00:29:48.320
I know for a long time, a lot of people have hoped that once Python 2 was laid to rest, that the mental, honestly, the cumulative mental capacity of the community would suddenly be freed up because suddenly all this Python 2 stuff would kind of just go away.

00:29:48.320 --> 00:29:49.380
The weight is off us.

00:29:49.460 --> 00:30:00.520
Yeah, the bite of our collective brain that had to still deal with Python 2 would now be free to just try to make Python 3, which then honestly is just going to be Python, just make Python faster and better.

00:30:00.520 --> 00:30:04.480
And I would like to think and hope that that's going to happen, but I honestly don't know.

00:30:04.480 --> 00:30:08.220
Once again, that's going to come down to the community coming forward and saying, you know what?

00:30:08.240 --> 00:30:13.980
We want to help make this happen and we're going to work with everyone as necessary to make that a thing.

00:30:13.980 --> 00:30:16.940
Yeah, well, maybe we're entering a period of where lots of flowers will bloom.

00:30:16.940 --> 00:30:18.480
Some of them will wither.

00:30:18.480 --> 00:30:20.440
Some of them will grow into trees or whatever.

00:30:20.440 --> 00:30:36.580
But, you know, for example, taking CPython itself and just compiling it to WebAssembly and getting it to run, say, in like an Electron JS app, like that would be a huge win for deployment, I think, because all you deploy is this little WebAssembly binary and it just loads up in the Chrome.

00:30:36.740 --> 00:30:38.840
And maybe that unlocks one area of growth.

00:30:38.840 --> 00:30:43.680
Maybe Pyodide does something for the data science and there's a bunch of different areas.

00:30:43.680 --> 00:30:47.120
And eventually we find what's working, find ways to adapt them.

00:30:47.120 --> 00:30:47.440
I don't know.

00:30:47.440 --> 00:30:47.880
What do you think?

00:30:47.880 --> 00:30:55.780
I'm honestly, one thing I'm curious about with WebAssembly is whether the phone OSs are going to start potentially adopting it as a target as well, right?

00:30:55.780 --> 00:31:06.100
Like I could imagine a world where Android and iOS suddenly started allowing WebAssembly as a compiled target versus specifically Swift and the raw C stuff on iOS.

00:31:06.180 --> 00:31:09.980
Or the equivalent on Android or its art on JIT.

00:31:09.980 --> 00:31:13.360
And I don't know if WebAssembly will catch that much.

00:31:13.360 --> 00:31:19.800
But if it does, that really opens it even to an even greater extent in terms of the usefulness and potential importance of WebAssembly.

00:31:19.800 --> 00:31:23.400
Because if you get that, then suddenly you have the web and you have mobile.

00:31:23.400 --> 00:31:24.780
And with Wazoo, you get desktop.

00:31:25.280 --> 00:31:31.660
That's a crazy amount of the user base in terms of just flat out computer users.

00:31:31.660 --> 00:31:32.460
It's just crazy.

00:31:32.460 --> 00:31:32.700
Yeah.

00:31:32.700 --> 00:31:38.360
I mean, the three places I see missing the huge growth opportunities are desktop, mobile, and front end and web browsers.

00:31:38.360 --> 00:31:38.740
Yeah.

00:31:38.740 --> 00:31:39.680
That kind of hits them all.

00:31:39.680 --> 00:31:39.840
Yeah.

00:31:39.960 --> 00:31:40.200
Yeah.

00:31:40.200 --> 00:31:43.300
And once again, I'm just going to keep harping on this.

00:31:43.300 --> 00:31:45.220
It's really going to come down to the community coming forward.

00:31:45.220 --> 00:31:51.760
And I do want to say I personally really hope that whatever the community does do, we're able to work together as a community.

00:31:52.140 --> 00:31:58.760
Like, I don't want to see fragmentation of, oh, I've done this thing, this version of Python that's slightly different.

00:31:58.760 --> 00:32:01.680
And, oh, this person over here has done a version of Python that's slightly different.

00:32:01.680 --> 00:32:03.940
And we haven't talked as a community about what we care about.

00:32:03.940 --> 00:32:09.520
And try to also pull everyone together to kind of work towards a common goal versus, oh, I think we should do it this way.

00:32:09.520 --> 00:32:10.620
No, I think we should do it that way.

00:32:10.620 --> 00:32:10.920
Okay.

00:32:10.920 --> 00:32:13.840
Well, I'll re-implement Python with a garbage collector over here.

00:32:13.840 --> 00:32:14.640
And, oh, here.

00:32:14.640 --> 00:32:16.300
And I'll do it a different way over here.

00:32:16.300 --> 00:32:18.060
And there's no way for them to work together.

00:32:18.060 --> 00:32:26.660
I understand experimenting with different ways, but I would still want them to hopefully end up in the same spot together such that we're just not wasting time and energy.

00:32:26.660 --> 00:32:30.860
Because as you commented earlier, we already did that with the Python 2 to 3 transition.

00:32:30.860 --> 00:32:32.880
It was somewhat painful, but we got through it.

00:32:32.880 --> 00:32:33.860
And there was reasons for it.

00:32:33.860 --> 00:32:34.780
And I don't regret it.

00:32:34.780 --> 00:32:40.300
But I also don't want to ever purposely do that again if we can avoid it.

00:32:40.300 --> 00:32:46.000
And so my big hope is we can get the community to come together as a group to try to decide how we want to make this happen.

00:32:46.000 --> 00:32:47.360
Yeah, I definitely second that.

00:32:47.360 --> 00:32:49.520
I don't want to dictate much is my key point.

00:32:49.520 --> 00:32:54.300
And I can't speak for my other steering council members, but I don't think they want to either.

00:32:54.300 --> 00:33:05.860
I think our key goal in anything, if anything does come out, is how can we help shepherd the community towards a single point and try to give guidance to help make sure that everyone is able to work together as a community.

00:33:05.860 --> 00:33:06.840
I think that sounds great.

00:33:06.840 --> 00:33:11.880
One of the things that might be cool, you talked about maybe eval not working, for example.

00:33:11.880 --> 00:33:13.300
And is that a problem?

00:33:13.300 --> 00:33:16.040
I don't even know how much of a problem that would be.

00:33:16.040 --> 00:33:16.860
I don't know.

00:33:16.860 --> 00:33:19.840
I mean, for instance, for a long time, named tuples required it.

00:33:19.840 --> 00:33:20.620
Yes, I remember.

00:33:20.620 --> 00:33:20.920
Yeah.

00:33:20.920 --> 00:33:21.180
Yeah.

00:33:21.180 --> 00:33:22.040
And a lot of people didn't know that.

00:33:22.040 --> 00:33:27.280
And then that just got changed, I believe, in 3.6, perhaps?

00:33:27.280 --> 00:33:28.000
Maybe 3.7?

00:33:28.000 --> 00:33:28.320
Yeah.

00:33:28.320 --> 00:33:29.100
Versus blur for me.

00:33:29.180 --> 00:33:29.660
Yeah.

00:33:29.660 --> 00:33:33.900
So yes, for the longest time component that a lot of people use in the starting library would not have worked.

00:33:34.540 --> 00:33:38.140
So it really, it's one of those things, as I said, I don't know.

00:33:38.140 --> 00:33:39.380
Edge case stuff.

00:33:39.380 --> 00:33:46.080
I think the team would be open to ditching things that really can be shown as like, yeah, not a lot of people use this.

00:33:46.080 --> 00:33:47.520
And boy, is it a pain to implement.

00:33:47.520 --> 00:33:52.360
Let's really consider getting rid of it because it's just not important enough to keep around for that performance boost.

00:33:52.360 --> 00:34:05.360
One of the thoughts I was having is, what if there's like a, something like a subset standard Python language, like, okay, maybe we can't have meta classes, or we can't have eval, or something that's kind of edge.

00:34:05.360 --> 00:34:06.580
Or maybe, I don't know.

00:34:06.620 --> 00:34:15.340
But if you target like this subset, it's guaranteed to run in some WebAssembly world, in CPython, maybe in PyPy, maybe like we're a...

00:34:15.340 --> 00:34:16.740
Well, so have you heard about mypyC?

00:34:16.740 --> 00:34:17.640
I've heard of it, yeah.

00:34:17.640 --> 00:34:17.980
Yeah.

00:34:17.980 --> 00:34:35.140
So for those of you who don't know, the mypy team has implemented a tool called mypyC, where basically they can take a subset of Python that's fully typed, run it through mypy, and they use mypy as actually a compiler front end to drive it to a Python C extension backend,

00:34:35.400 --> 00:34:38.960
and actually emit a Python extension for your Python code.

00:34:38.960 --> 00:34:43.680
And it was originally written for mypy, I assume because Dropbox wanted mypy to run faster.

00:34:43.680 --> 00:34:48.460
But they've actually gotten mypy to run four times faster than what Guido's told me.

00:34:48.460 --> 00:34:48.780
Wow.

00:34:48.780 --> 00:34:50.440
At Dropbox by doing this.

00:34:50.440 --> 00:34:52.600
Now, they fully admit it.

00:34:52.600 --> 00:34:55.760
It was fully written for mypy, and it's got a very specific subset, and it's very targeted.

00:34:55.760 --> 00:35:05.240
But that does tie into your whole, like, what happens if we make it so that, if you care, just type Python end to end for your code, and then pass it through something like mypyC.

00:35:05.240 --> 00:35:06.340
And hit that target.

00:35:06.340 --> 00:35:09.520
I mean, some people have done that with Cython, but Cython is very much...

00:35:09.520 --> 00:35:10.980
It's kind of got its own little bit of syntax.

00:35:10.980 --> 00:35:11.860
It's got its own syntax.

00:35:11.860 --> 00:35:12.060
It's got its own syntax.

00:35:12.060 --> 00:35:14.260
You've got to, like, do its style, you know.

00:35:14.260 --> 00:35:17.100
Well, they've actually added type hint support for it.

00:35:17.100 --> 00:35:17.800
Which is awesome, yeah.

00:35:17.800 --> 00:35:18.220
Which is great.

00:35:18.580 --> 00:35:24.380
But Cython is also typically targeted much lower constructs like C-level ints, right?

00:35:24.380 --> 00:35:27.000
And void stars and structs and that kind of thing.

00:35:27.000 --> 00:35:32.900
While mypyC is targeting a higher level, not such a C-level bridge like Cython, but very much specific.

00:35:32.900 --> 00:35:34.400
This is just normal Python.

00:35:34.400 --> 00:35:35.820
We just want Python faster.

00:35:35.820 --> 00:35:36.380
Yeah.

00:35:36.420 --> 00:35:39.760
So it's a slightly different opportunity from what Cython's been targeting all these years.

00:35:39.760 --> 00:35:41.120
And done a good job at them.

00:35:41.120 --> 00:35:42.920
Cython definitely deserves credit for what they've done.

00:35:42.920 --> 00:35:43.300
Absolutely.

00:35:43.300 --> 00:35:44.580
So there's a lot of possibilities.

00:35:44.580 --> 00:35:48.080
I don't know if WebAssembly has to be here or not, but it seems like it could be.

00:35:48.080 --> 00:35:49.740
I think it's definitely worth a consideration.

00:35:49.740 --> 00:35:51.520
I think, as you...

00:35:51.520 --> 00:35:53.940
Hopefully people can tell through the excitement in our voices.

00:35:53.940 --> 00:35:58.080
I think both Michael and I obviously think it's a great thing.

00:35:58.080 --> 00:36:00.020
And I think it's a very cool piece of tech.

00:36:00.020 --> 00:36:01.560
And I like the motivation behind it.

00:36:01.560 --> 00:36:04.580
And I think they seem to be driving it for the right reasons.

00:36:04.580 --> 00:36:06.960
And I think it's definitely worth looking at.

00:36:06.960 --> 00:36:10.820
I think it's just a question of what benefits will Python get as a community?

00:36:10.820 --> 00:36:12.260
And will that be enough to cover...

00:36:12.260 --> 00:36:15.320
Tick five boxes or tick two boxes?

00:36:15.320 --> 00:36:16.100
Right, right, right.

00:36:16.100 --> 00:36:17.780
Or 10 boxes even because we just don't know.

00:36:17.780 --> 00:36:21.560
It's enticing enough that I really do hope someone gives it a solid go.

00:36:21.560 --> 00:36:22.340
Yeah, I concur.

00:36:22.340 --> 00:36:28.480
And one of my bits of excitement is around how it seems to let languages interoperate.

00:36:28.480 --> 00:36:34.620
If you can get something to get down to WebAssembly, you can get it to play with other things that it might not, right?

00:36:34.620 --> 00:36:42.540
If I can compile CPython to WebAssembly, I can now get it to do JavaScript-y things with JavaScript and work with other stuff and Rust.

00:36:42.540 --> 00:36:44.640
If I can get it there, I can get it in the space as well.

00:36:44.640 --> 00:36:47.640
There seems like it could be a cool integration layer.

00:36:47.640 --> 00:36:48.480
Oh, most definitely.

00:36:48.480 --> 00:36:51.700
If you look at the WebAssembly spec, what it actually specs out in the MVP,

00:36:51.700 --> 00:37:01.740
is basically unassigned and assigned ints, both 32 and 64, floats and functions, plus imports at the module level.

00:37:01.740 --> 00:37:04.820
But the key point is because they're specifying at the function level,

00:37:04.820 --> 00:37:09.600
if you wrote something in JavaScript and had it compiled down to a WebAssembly function...

00:37:09.600 --> 00:37:10.900
If you could export that function.

00:37:10.900 --> 00:37:11.500
Exactly.

00:37:11.500 --> 00:37:13.380
So now at the WebAssembly level, it's available.

00:37:13.380 --> 00:37:18.620
So as long as your code, as long as Python knows how to work with WebAssembly code, it can do that.

00:37:18.720 --> 00:37:24.800
And actually, there is a WebAssembly implementation called Wasmr, which I believe you talked about on Python Bytes.

00:37:24.800 --> 00:37:26.280
Yes, we did talk about it on Python Bytes.

00:37:26.280 --> 00:37:27.920
And Wasmr is super exciting.

00:37:27.920 --> 00:37:28.740
Tell people about that.

00:37:28.740 --> 00:37:29.020
Yeah.

00:37:29.020 --> 00:37:31.020
It's like the reverse of what we're talking about in a sense.

00:37:31.020 --> 00:37:31.820
Yeah, yeah, exactly.

00:37:31.820 --> 00:37:33.420
So it's a WebAssembly implementation.

00:37:33.420 --> 00:37:37.780
But one of the interesting things they've done is they've defined their own basic kind of C API.

00:37:37.780 --> 00:37:45.820
And so what they're letting other languages that can do C API work is they allow you to actually use it like an extension.

00:37:45.820 --> 00:37:52.160
So what Wasmr has is they actually have a C extension for Python that will actually let you load WebAssembly code into Wasmr.

00:37:52.160 --> 00:37:57.580
And then make calls through Python into Wasmr itself to do execution on your behalf and then come back.

00:37:57.580 --> 00:38:02.880
Kind of like what your idea was earlier, Michael, about could we somehow use a sub-interpreter to do backwards compatibility?

00:38:03.220 --> 00:38:11.780
This is actually using kind of like almost a multiprocessing kind of like out through an extension call to have some WebAssembly get executed on your behalf and then come back into Python.

00:38:11.780 --> 00:38:13.100
Yeah, it's really cool.

00:38:13.100 --> 00:38:16.180
To me, when I saw it, I felt like it's a little bit like what Node.js did.

00:38:16.180 --> 00:38:19.880
So JavaScript was stuck in the browser and it lived in the browser and it's a web thing.

00:38:19.880 --> 00:38:20.980
But then Node.js came along.

00:38:20.980 --> 00:38:26.100
All of a sudden, we could take this stuff and bring it to run on the desktop or on a server.

00:38:26.100 --> 00:38:26.740
And it brought it.

00:38:26.740 --> 00:38:33.020
So this lets us take anything that would run in WebAssembly and now bring it into your Python application on the server side.

00:38:33.020 --> 00:38:33.860
And run it.

00:38:33.860 --> 00:38:37.720
And that's just that's a pretty exciting, different take on this angle here.

00:38:37.720 --> 00:38:47.120
Yeah, I mean, I think it's a very clever way to try to start that bridging of showing people the benefits of WebAssembly, but also just making it useful today.

00:38:47.120 --> 00:38:47.680
Right.

00:38:47.680 --> 00:38:54.040
Because like there's plenty of great stuff being written in JavaScript or any other language that can target WebAssembly, Rust.

00:38:54.360 --> 00:38:57.840
And there's no reason why you can't reach for it through that mechanism.

00:38:57.840 --> 00:39:03.080
So I think, once again, it acts even just at some levels of proof of concept to show what the possibilities are.

00:39:03.080 --> 00:39:16.380
If as a technical community, all up, what would happen if all languages and tooling and all that started to actually start to tackle the WebAssembly as a target and try to actually work towards that as a common goal?

00:39:16.580 --> 00:39:18.860
It's early days, but it's exciting to imagine what might happen.

00:39:18.860 --> 00:39:22.460
It feels very utopian, amazing if we could have it.

00:39:22.460 --> 00:39:27.420
And it's kind of cool and exciting because it seems not totally bonkers to actually aim for it.

00:39:27.420 --> 00:39:28.080
So, yeah.

00:39:28.080 --> 00:39:33.800
People have always said that JavaScript is the assembly language of the Web, but maybe WebAssembly actually is going to be what we get to.

00:39:33.920 --> 00:39:40.860
This portion of Talk Python is sponsored by Microsoft and Visual Studio Code.

00:39:40.860 --> 00:39:48.140
Visual Studio Code is a free, open-source, and lightweight code editor that runs on Mac, Linux, and Windows with rich Python support.

00:39:48.140 --> 00:39:56.240
Download Visual Studio Code and install the Python extension to get coding with support for tools you love like Jupyter, Black Formatting, Pilot, pytest, and more.

00:39:56.240 --> 00:40:03.480
And just announced this month, you can now work with remote Python code bases using the new Visual Studio Code remote extensions.

00:40:04.080 --> 00:40:10.640
Use the full power of Visual Studio Code when coding in containers, in Windows subsystem for Linux, and over SSH connections.

00:40:10.640 --> 00:40:11.660
Yep, that's right.

00:40:11.660 --> 00:40:15.640
Auto completions, debugging, the terminal, source control, your favorite extensions.

00:40:15.640 --> 00:40:18.460
Everything works just right in the remote environment.

00:40:18.460 --> 00:40:23.120
Get started with Visual Studio Code now at talkpython.fm/Microsoft.

00:40:23.120 --> 00:40:27.420
I think that pretty much covers it for WebAssembly.

00:40:27.420 --> 00:40:30.780
I do like these two projects that are out there, and I want to see more.

00:40:30.860 --> 00:40:35.120
I guess maybe we should throw a little love to Rust Python as well, which is a cool project.

00:40:35.120 --> 00:40:40.220
And you mentioned it earlier, but its goal is to, let's see if we can rewrite CPython in Rust.

00:40:40.220 --> 00:40:41.560
And there's a lot of options.

00:40:41.560 --> 00:40:47.180
Like, what if we reimagined what CPython was supposed to do with some compatibility in mind?

00:40:47.180 --> 00:40:50.440
Or, I don't know, something like, but for WebAssembly, right?

00:40:50.440 --> 00:40:51.380
There's some options.

00:40:51.380 --> 00:40:56.960
Yeah, and the only clarification I make is I don't think it's a target from CPython to Rust.

00:40:56.960 --> 00:41:00.680
I think they're doing a full Python itself, re-implementation, right?

00:41:00.680 --> 00:41:07.500
So it's not like they're taking CPython and slowly implementing bits of Rust, kind of like what Mozilla is doing with Firefox.

00:41:07.500 --> 00:41:11.680
And it's kind of like an inside-out kind of growth of Rust.

00:41:11.680 --> 00:41:13.500
They're doing it fully Rust from scratch.

00:41:13.500 --> 00:41:13.760
Yeah.

00:41:13.880 --> 00:41:19.720
I mean, with the amount of tooling and work that Rust is pulling into the WebAssembly world as something they very specifically care about,

00:41:19.720 --> 00:41:29.540
it does potentially open that implementation if they manage to reach a level of compatibility that people are happy with to get us Python in WebAssembly, potentially.

00:41:29.540 --> 00:41:30.720
Yeah, it's very exciting.

00:41:30.720 --> 00:41:31.060
Awesome.

00:41:31.060 --> 00:41:36.040
All right, well, let's talk about just a couple of other things while I got you stuck here on the Expo floor hall.

00:41:36.040 --> 00:41:36.340
Sure.

00:41:36.440 --> 00:41:37.960
We talked about the 2 to 3 thing.

00:41:37.960 --> 00:41:38.340
Yep.

00:41:38.340 --> 00:41:42.440
Let's just talk a little bit about sunsetting the whole Python 2 thing next.

00:41:42.440 --> 00:41:43.040
Yes.

00:41:43.040 --> 00:41:44.380
Where are we right now?

00:41:44.380 --> 00:41:45.000
It is May.

00:41:45.000 --> 00:41:48.900
Seven months from now, we're going to be officially at the sunset.

00:41:48.900 --> 00:41:50.100
Like, what's the plan?

00:41:50.100 --> 00:41:52.200
Is that just going to happen?

00:41:52.200 --> 00:41:55.220
Is there something happening to, like, shepherd that?

00:41:55.460 --> 00:42:03.800
The steering council is just starting to get ourselves out from the pile of open peps that we started off dealing with when we first got elected.

00:42:03.800 --> 00:42:13.820
And so we're just starting to have conversations among ourselves of, okay, what do we think we can do if we can somehow help direct some energy in the world and such?

00:42:13.820 --> 00:42:26.020
And so we've just started just, like, very much, I mean just, started having conversations with the PSF about seeing if we could potentially get some funding for, like, a PM to help us with the sunsetting of Python 2.7.

00:42:26.020 --> 00:42:30.140
Because, like, if you go to the python.org website, it says Python 2, Python 3 everywhere.

00:42:30.140 --> 00:42:30.740
But you know what?

00:42:30.740 --> 00:42:33.940
Come January 1st, 2020, it just should say Python.

00:42:33.940 --> 00:42:41.140
All the little, oh, two here, three there, all that should just go away because now it's just Python 3, which will just be Python.

00:42:41.140 --> 00:42:52.880
Well, the biggest one is if I go search for a function that's in the standard library and I click on the result in Google, there's a high probability that says 2.7 or pull down the dropdown to get to the 3.7 or whatever.

00:42:52.880 --> 00:42:54.400
Yeah, and how do we handle that, right?

00:42:54.400 --> 00:42:55.440
Do we do it with redirects?

00:42:55.440 --> 00:42:56.940
Do we just totally get rid of it?

00:42:56.940 --> 00:42:58.140
What are our options?

00:42:58.140 --> 00:42:59.120
I don't know.

00:42:59.120 --> 00:43:01.240
But it's definitely something we should look into.

00:43:01.240 --> 00:43:04.640
And I think we're hoping we can get some, basically, professional help to get that done.

00:43:04.700 --> 00:43:15.640
Because, obviously, that's going to be potentially a slight slog and asking a bunch of volunteer core developers to go through the website and all our documentation and just remove every mention of 2.7.

00:43:15.640 --> 00:43:17.100
I don't think that's going to go well.

00:43:17.100 --> 00:43:18.180
Command F.

00:43:18.180 --> 00:43:18.800
Yeah.

00:43:18.800 --> 00:43:19.600
Put 2.7.

00:43:19.600 --> 00:43:20.880
Type 3.7.

00:43:20.880 --> 00:43:24.140
Let's really test VS Code's global search and replace.

00:43:24.520 --> 00:43:28.140
The other thing, though, is there's going to be some decisions that have to be made.

00:43:28.140 --> 00:43:29.660
And someone's going to have to stay on top of this, right?

00:43:29.660 --> 00:43:34.260
This is very much going to be a detail-oriented thing to keep a massive to-do list of things to get done.

00:43:34.260 --> 00:43:39.420
And once again, asking a single volunteer to try to act as the contact point coordinator for that is probably going to be way too much.

00:43:39.420 --> 00:43:47.700
So I'm hoping this initial conversation will go somewhere and we're going to hopefully be able to get a PM or something to help us kind of make this happen.

00:43:47.700 --> 00:43:49.020
Yeah, it sounds like a great plan.

00:43:49.160 --> 00:43:54.800
And also, honestly, I guess it's kind of a nice first step to see what it's like for there to potentially be hired help to help Python Dev.

00:43:54.800 --> 00:43:56.160
And who knows where that can lead.

00:43:56.160 --> 00:43:57.540
That can lead to a lot of good places.

00:43:57.540 --> 00:44:03.500
I mean, we saw the whole PyPI.org relaunch because there was a little funding brought in there.

00:44:03.500 --> 00:44:06.540
And that had been kind of been chipped at for a long, long time.

00:44:06.540 --> 00:44:08.020
And then, you know, six months later.

00:44:08.020 --> 00:44:13.200
I've personally said that I think there's possibility, but we've not had those conversations yet.

00:44:13.200 --> 00:44:17.980
Among even the steering council, let alone Python Dev all up, what that potentially could look like or mean.

00:44:18.440 --> 00:44:20.760
But I think there's some potential opportunity there.

00:44:20.760 --> 00:44:20.980
Yeah.

00:44:20.980 --> 00:44:22.980
If this works out, everyone's amenable.

00:44:22.980 --> 00:44:25.120
And honestly, once again, we can get the funding.

00:44:25.120 --> 00:44:25.400
Yeah.

00:44:25.400 --> 00:44:26.420
Minor thing, funding.

00:44:26.420 --> 00:44:26.700
Yeah.

00:44:26.700 --> 00:44:27.000
Money.

00:44:27.000 --> 00:44:28.280
It's just a thing.

00:44:28.280 --> 00:44:28.800
Just paper.

00:44:28.800 --> 00:44:29.120
Come on.

00:44:29.120 --> 00:44:29.400
Yeah.

00:44:29.400 --> 00:44:29.780
All right.

00:44:29.780 --> 00:44:33.680
And then you're on the VS Code team, specifically the Python side.

00:44:33.680 --> 00:44:36.620
You guys probably made some announcements or have something going on here.

00:44:36.620 --> 00:44:37.500
Anything you want to share?

00:44:37.500 --> 00:44:38.720
Actually, it was kind of cool.

00:44:38.720 --> 00:44:44.240
We've been working with the VS Code team for a while now to land some support for remote editing.

00:44:44.240 --> 00:44:46.460
Actually, it was mainly driven by the VS Code team.

00:44:46.620 --> 00:44:49.940
They basically talked to us about some of our needs to make sure they got addressed.

00:44:49.940 --> 00:44:53.660
We helped test it for them because the Python extension is the number one extension of VS Code.

00:44:53.660 --> 00:44:55.500
That doesn't come with it out of the box.

00:44:55.500 --> 00:44:55.860
Yeah.

00:44:55.860 --> 00:45:04.440
One of the things that drives me crazy, people say, I'm going to use some really subpar editor because I need something that's always available to me no matter what.

00:45:04.800 --> 00:45:06.440
Even if I'm going to use SSH in over terminal.

00:45:06.440 --> 00:45:11.840
So I'm going to choose a least common denominator option rather than maybe among all the tooling.

00:45:11.840 --> 00:45:19.060
So what's really great is VS Code has developed a system, but it leaves them in the insiders build right now while they work out any kinks from the public announcement.

00:45:19.060 --> 00:45:28.180
But basically, they've launched three extensions that let you use Windows 10's WSL support, Docker, both remote and local, and SSH.

00:45:28.680 --> 00:45:42.520
And so basically what it does is it runs more or less a headless VS Code on the remote location of where your code is to get proper IntelliSense, paths, all that stuff that's normally really hairy to do on the translation side.

00:45:42.520 --> 00:45:49.320
If your development platform is different from the development position of your code, they just basically run VS Code on that point.

00:45:49.320 --> 00:45:55.420
And then you basically get a GUI front end on your actual desktop, which it's a really slick solution.

00:45:55.420 --> 00:46:00.200
And I'm honestly really appreciative of the VS Code team for letting us actually announce that here at PyCon.

00:46:00.200 --> 00:46:02.600
It was not a thing that they announced anywhere else.

00:46:02.600 --> 00:46:08.520
We actually got to announce it here because VS Code team itself has been very supportive of us and the work we've done on the extension.

00:46:08.520 --> 00:46:09.600
So thanks to them for that.

00:46:09.600 --> 00:46:09.780
Yeah.

00:46:09.780 --> 00:46:11.140
Well, that sounds pretty awesome.

00:46:11.140 --> 00:46:14.800
I mean, that's part of the Electron.js suite aspect, right?

00:46:14.800 --> 00:46:16.660
It's kind of already like two tier.

00:46:16.660 --> 00:46:18.540
It's just now the tier is far, far away.

00:46:18.540 --> 00:46:19.160
Yeah, exactly.

00:46:19.160 --> 00:46:27.540
I mean, the analogy I use, and I think it's kind of, it feels a little like it cheapens it a little too much for the amount of work in the VS Code teams.

00:46:27.540 --> 00:46:29.200
But it's almost like running an X11, right?

00:46:29.200 --> 00:46:33.400
We've got the headless version running on the remote machine and you just get it on the other end.

00:46:33.400 --> 00:46:34.120
Yeah, pretty cool.

00:46:34.120 --> 00:46:35.000
So yeah, it's awesome.

00:46:35.000 --> 00:46:40.100
I'm extremely happy, if for any other reason, that it closed out our top two feature requests on our issue tracker

00:46:40.100 --> 00:46:45.380
that have been there since they joined the team and the extension moved over under Microsoft.

00:46:45.380 --> 00:46:45.820
Yeah.

00:46:45.820 --> 00:46:46.980
Now you can stop talking about it.

00:46:46.980 --> 00:46:47.320
Yeah.

00:46:47.320 --> 00:46:51.220
Now we just got to start with the next new number one and number two feature request.

00:46:51.220 --> 00:46:52.640
Can you make it write my code for me?

00:46:52.640 --> 00:46:52.920
Yeah.

00:46:52.920 --> 00:46:53.160
No.

00:46:53.160 --> 00:46:53.900
No, we don't.

00:46:53.900 --> 00:46:54.740
I don't know if we want that.

00:46:54.740 --> 00:46:55.540
No, probably not.

00:46:55.540 --> 00:46:55.940
Probably not.

00:46:56.000 --> 00:46:57.300
But people keep saying it's going to happen.

00:46:57.300 --> 00:46:57.900
I don't know.

00:46:57.900 --> 00:46:58.360
We'll see.

00:46:58.360 --> 00:46:58.680
Yeah.

00:46:58.680 --> 00:47:03.700
I actually had a prof in my master's program at CalPots, San Luis Obispo, who said, oh, yeah,

00:47:03.700 --> 00:47:05.560
like in 10 years, code will be running itself.

00:47:05.560 --> 00:47:08.020
And I hate to break it to you, Dr. Fisher.

00:47:08.020 --> 00:47:09.080
It's 10 years now.

00:47:09.080 --> 00:47:10.000
It didn't quite happen.

00:47:10.000 --> 00:47:15.060
And yeah, I'm quickly approaching 20 and it still doesn't quite look like it's going to happen.

00:47:15.200 --> 00:47:18.380
Yeah, there's a lot happening here at PyCon and a lot of people typing a lot of keyboards

00:47:18.380 --> 00:47:19.040
doing cool stuff.

00:47:19.040 --> 00:47:19.280
Yeah.

00:47:19.280 --> 00:47:19.800
All right, Brett.

00:47:19.800 --> 00:47:22.680
Well, thanks for coming back and following up this discussion because it was a lot of

00:47:22.680 --> 00:47:22.900
fun.

00:47:22.900 --> 00:47:26.940
And I think WebAssembly and Rust have some pretty amazing possibilities.

00:47:26.940 --> 00:47:28.020
We'll see where it goes.

00:47:28.020 --> 00:47:31.820
I think the future is bright if the community decides to make it so.

00:47:31.820 --> 00:47:34.760
And so I'm optimistic and hopeful that it will.

00:47:34.760 --> 00:47:37.820
And I'm really excited to see where things potentially end up.

00:47:37.820 --> 00:47:38.180
All right, cool.

00:47:38.180 --> 00:47:40.160
Well, thanks for being on the show and enjoy the conference.

00:47:40.160 --> 00:47:40.600
Thanks, Michael.

00:47:40.600 --> 00:47:40.900
You too.

00:47:40.900 --> 00:47:41.160
Bye.

00:47:41.160 --> 00:47:41.360
Bye.

00:47:41.360 --> 00:47:44.760
This has been another episode of Talk Python To Me.

00:47:45.440 --> 00:47:49.440
Our guest on this episode was Brett Cannon, and it's been brought to you by Microsoft.

00:47:49.440 --> 00:47:53.020
If you're a Python developer, Microsoft has you covered.

00:47:53.020 --> 00:47:58.100
From VS Code and their modern editor plugins to Azure Pipelines for continuous integration

00:47:58.100 --> 00:48:00.880
and serverless Python functions on Azure.

00:48:00.880 --> 00:48:04.540
Check them out at talkpython.fm/Microsoft.

00:48:04.540 --> 00:48:06.800
Want to level up your Python?

00:48:06.800 --> 00:48:11.660
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

00:48:11.920 --> 00:48:16.760
Or if you're looking for something more advanced, check out our new async course that digs into

00:48:16.760 --> 00:48:19.820
all the different types of async programming you can do in Python.

00:48:19.820 --> 00:48:23.780
And of course, if you're interested in more than one of these, be sure to check out our

00:48:23.780 --> 00:48:24.480
Everything Bundle.

00:48:24.480 --> 00:48:26.360
It's like a subscription that never expires.

00:48:26.360 --> 00:48:28.680
Be sure to subscribe to the show.

00:48:28.680 --> 00:48:31.160
Open your favorite podcatcher and search for Python.

00:48:31.160 --> 00:48:32.300
We should be right at the top.

00:48:32.720 --> 00:48:37.140
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:48:37.140 --> 00:48:41.300
and the direct RSS feed at /rss on talkpython.fm.

00:48:41.300 --> 00:48:43.380
This is your host, Michael Kennedy.

00:48:43.380 --> 00:48:44.880
Thanks so much for listening.

00:48:44.880 --> 00:48:45.960
I really appreciate it.

00:48:45.960 --> 00:48:47.700
Now get out there and write some Python code.

00:48:47.700 --> 00:49:08.220
I really appreciate it.

