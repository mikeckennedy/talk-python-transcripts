00:00:00 What is the status of serverless computing and Python in 2024?

00:00:04 What are some of the new tools and best practices?

00:00:06 Well, we're lucky to have Tony Sherman, who has a lot of practical experience

00:00:11 with serverless programming on the show.

00:00:14 This is "Talk Python to Me," episode 458, recorded January 25th, 2024.

00:00:20 (upbeat music)

00:00:25 Welcome to "Talk Python to Me," a weekly podcast on Python.

00:00:38 This is your host, Michael Kennedy.

00:00:39 Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:00:44 both on fosstodon.org.

00:00:47 Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:52 We've started streaming most of our episodes live on YouTube.

00:00:56 Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows

00:01:02 and be part of that episode.

00:01:04 This episode is brought to you by Sentry.

00:01:06 Don't let those errors go unnoticed.

00:01:07 Use Sentry like we do here at Talk Python.

00:01:09 Sign up at talkpython.fm/sentry.

00:01:13 And it's brought to you by MailTrap, an email delivery platform that developers love.

00:01:18 Try for free at mailtrap.io.

00:01:22 Tony, welcome to Talk Python to me.

00:01:24 - Thank you.

00:01:25 Thanks for having me.

00:01:26 - Fantastic to have you here.

00:01:27 Gonna be really fun to talk about serverless.

00:01:30 You know, the joke with the cloud is, well, I know you call it the cloud,

00:01:34 but it's really just somebody else's computer.

00:01:36 But we're not even talking about computers, we're just talking about functions.

00:01:39 Maybe it's someone else's function.

00:01:40 I don't know, we're gonna find out.

00:01:41 - Yeah, I actually, I saw a recent article about server-free.

00:01:45 Recently, somebody trying to, yeah, move completely.

00:01:48 Yes, yeah, because as you might know, serverless doesn't mean actually no servers.

00:01:53 - Of course, of course.

00:01:55 Server-free, all right.

00:01:56 So we could just get the thing to run on the BitTorrent network.

00:02:01 Got it, okay.

00:02:01 - Yeah.

00:02:02 - I don't know, I don't know, we'll figure it out.

00:02:05 But it's gonna be super fun.

00:02:06 We're gonna talk about your experience working with serverless.

00:02:10 We'll talk about some of the choices people have out there and also some of the tools that we can use

00:02:15 to do things like observe and test our serverless code.

00:02:19 Before that though, tell us a bit about yourself.

00:02:22 - Sure, so I'm actually a career changer.

00:02:26 So I worked in the cable industry for about 10 years and doing a lot of different things

00:02:34 from installing, knock at the door cable guy to working on more of the outside plant.

00:02:40 But it just, at some point, I was seeing limits of career path there.

00:02:46 And so my brother-in-law is a software engineer and I had already started going back to school,

00:02:54 finishing my degree and I was like, okay, well maybe I should look into this.

00:02:57 And so I took an intro to programming class.

00:03:00 It was in Python and that just led me down this path.

00:03:05 So now for the past four years or so, been working professionally in the software world,

00:03:10 started out in a QA role at an IOT company.

00:03:14 And now, yeah, doing a lot of serverless programming in Python these days.

00:03:20 Second company now, but that does some school bus safety products.

00:03:24 - Interesting, very cool.

00:03:26 - Yeah, yep.

00:03:27 But a lot of Python and a lot of serverless.

00:03:29 - Well, serverless and IOT, feel like they go pretty hand in hand.

00:03:34 - Yes, yep.

00:03:36 Yeah, another thing is with serverless is when you have very like spiky traffic,

00:03:42 like if you think about school buses that you have a lot coming on twice a day.

00:03:47 - Exactly, like the 8 a.m. shift and then the 2.30 to 3.00 shift.

00:03:52 - So yeah, that's a really good use case for serverless is something like that.

00:03:57 - Okay, are you enjoying doing the programming stuff?

00:04:01 So the cable stuff?

00:04:02 - Absolutely.

00:04:03 Sometimes I live in Michigan, so I look outside and look at the snow coming down

00:04:08 or these storms and yeah, I just, yeah, I really, some people are like, you don't miss being outside?

00:04:14 I'm like, maybe every once in a while, but I can go walk outside on a nice day.

00:04:19 - You can choose to go outside.

00:04:21 You're not ready to go outside in the sleet or rain.

00:04:24 - Yeah.

00:04:25 - Yeah, absolutely.

00:04:26 We just had a mega storm here and just the huge tall trees here in Oregon

00:04:31 just fell left and right.

00:04:33 And there's in every direction that I look, there's a large tree on top of one of the houses

00:04:39 of my neighbors, maybe a house or two over.

00:04:42 But it just took out all the, everything that was a cable in the air was taken out.

00:04:46 So it's just been a swarm of people who are out in 13 degree Fahrenheit,

00:04:50 negative nine Celsius weather.

00:04:52 And I'm thinking, not really choosing to be out there today probably.

00:04:56 Excellent.

00:04:57 Well, thanks for that introduction.

00:04:59 I guess maybe we could, a lot of people probably know what serverless is,

00:05:02 but I'm sure there's a lot who are not even really aware of what serverless programming is, right?

00:05:08 - Yes.

00:05:09 - Let's talk about what's the idea, what's the zen of this?

00:05:13 - Yeah.

00:05:14 So yeah, I kind of made the joke that serverless doesn't mean there are no servers,

00:05:18 but, and there's, hopefully I don't butcher it too much, but it's more like functions as a service.

00:05:25 There's other things that can be serverless too.

00:05:28 Like there's serverless databases or a lot of different services that can be serverless,

00:05:35 meaning you don't have to think about like how to operate them, how to think about scaling them up.

00:05:40 You don't have to spin up VMs or Kubernetes clusters or anything.

00:05:46 You don't have to think about that part.

00:05:48 It's just your code that goes into it.

00:05:51 And so yeah, serverless functions are probably what people are most familiar with.

00:05:55 And that's, I'm sure what we'll talk about most today.

00:05:58 But yeah, that's really the idea.

00:06:01 You don't have to manage the server.

00:06:05 - Sure.

00:06:06 And that's a huge barrier.

00:06:07 I remember when I first started getting into web apps and programming and then another level

00:06:14 when I got into Python, because I had not done that much Linux work, getting stuff up running, it was really tricky.

00:06:21 And then having the concern of, is it secure?

00:06:24 How do I patch it?

00:06:25 How do I back it up?

00:06:26 How do I keep it going?

00:06:28 All of those things, they're non-trivial, right?

00:06:31 - Right.

00:06:32 Yeah, yeah.

00:06:32 There's a lot to think about.

00:06:33 And if you like work at an organization, it's probably different everywhere you go too,

00:06:39 that how they manage their servers and things.

00:06:42 So putting in some stuff in the cloud kind of brings some commonality to it too.

00:06:46 Like you can learn how the Azure cloud or Google cloud or AWS, how those things work

00:06:53 and kind of have some common ground too.

00:06:55 - Yeah, for sure.

00:06:58 Like having, also feels more accessible to the developers in a larger group,

00:07:04 in the sense that it's not a DevOps team that kind of takes care of the servers

00:07:08 or a production engineers where you hand them your code.

00:07:11 It's a little closer to just, I have a function and then I get it up there

00:07:15 and it continues to be the function, you know?

00:07:17 - Yeah, and that is a different mindset too.

00:07:19 You kind of see it all the way through from writing your code to deploying it.

00:07:24 Yeah, without maybe an entire DevOps team that you just kind of say, here you go, go deploy this.

00:07:32 - Yeah.

00:07:33 In my world, I mostly have virtual machines.

00:07:37 I've moved over to kind of a Docker cluster.

00:07:40 I think I've got 17 different things running in the Docker cluster at the moment,

00:07:45 but both of those are really different than serverless, right?

00:07:48 - Yeah.

00:07:49 - Yeah, so it's been working well for me, but when I think about serverless,

00:07:53 let me know if this is true.

00:07:55 It feels like you don't need to have as much of a Linux or server or sort of an ops experience

00:08:03 to create these things.

00:08:05 - Yeah, I would say like you could probably get away with like almost none, right?

00:08:09 Like at the simplest form, like with like AWS, for instance, their Lambda functions,

00:08:16 you can, and that's the one I'm most familiar with.

00:08:19 So forgive me for using them as an example for everything.

00:08:22 There's a lot of different serverless options, but you could go into the AWS console

00:08:29 and you could actually write your Python code right in the console, deploy that.

00:08:36 They have function URLs now.

00:08:38 So you could actually have like, I mean, within a matter of minutes, you can have a serverless function set up.

00:08:44 And so, yeah.

00:08:45 - AWS Lambda, right?

00:08:47 That's the one. - Yes, yep.

00:08:48 - Lambda being, I guess, a simple function, right?

00:08:50 We have Lambdas in Python.

00:08:51 They can only be one line.

00:08:53 I'm sure you can have more than one line in the AWS Lambda.

00:08:56 - Yeah, there are limitations though with Lambda that are definitely some pain points

00:09:02 that I ran into, so.

00:09:04 - Oh, really?

00:09:04 Okay, what are some of the limitations?

00:09:05 - Yeah, so package size is one.

00:09:09 So if you start thinking about all these like amazing packages on PyPI, you do have to start thinking about

00:09:17 how many you're gonna bring in.

00:09:19 So, and I don't know the exact limits off the top of my head, but it's, yeah, pretty quick Google search

00:09:26 on their package size.

00:09:28 It might be like 50 megabytes zipped, but 250 when you decompress it to do a zip base,

00:09:35 then they do have containerized Lambda functions that go up to like a 10 gig limit.

00:09:41 So that helps, but.

00:09:42 - Interesting, okay.

00:09:43 - Yeah, yeah, those ones used to be less performant, but they're kind of catching up to where they're,

00:09:49 that was really on something called cold starts, but they're getting, I think, pretty close to it,

00:09:56 not being a very big difference whether you dockerize or zip these functions,

00:10:02 but yeah, so when you start just like pip install and everything, you've got to think about

00:10:07 how to get that code into your function and how much it's gonna bring in.

00:10:13 So yeah, that definitely was a limitation that I had to quickly learn.

00:10:19 - Yeah, I guess it's probably trying to do pip install -r effectively.

00:10:24 - Yeah.

00:10:25 - And it's like, you can't go overboard with this, right?

00:10:28 - Right, yeah, yeah.

00:10:29 When you start bringing in packages, like maybe like some of the scientific packages,

00:10:35 you're definitely gonna be hitting some size limits.

00:10:38 - Okay, and with the containerized ones, basically you probably give it a Docker file

00:10:42 and a command to run in it, and it can build those images before and then just execute and just do a Docker run.

00:10:49 - Yeah, I think how those ones work is you store an image on like their container registry,

00:10:55 Amazon's, is it ECR, I think.

00:10:58 And so then you kind of point it at that and yeah, it'll execute your like handler function

00:11:06 when the Lambda gets called, so.

00:11:08 - This portion of Talk Python to Me is brought to you by Multi-Platform Error Monitoring at Sentry.

00:11:15 Code breaks, it's a fact of life.

00:11:17 With Sentry, you can fix it faster.

00:11:20 Does your team or company work on multiple platforms that collaborate?

00:11:24 Chances are extremely high that they do.

00:11:27 It might be a React or Vue front-end JavaScript app that talks to your FastAPI backend services.

00:11:32 Could be a Go microservice talking to your Python microservice, or even native mobile apps

00:11:38 talking to your Python backend APIs.

00:11:41 Now let me ask you a question.

00:11:43 Whatever combination of these that applies to you, how tightly do these teams work together?

00:11:47 Especially if there are errors originating at one layer, but becoming visible at the other.

00:11:53 It can be super hard to track these errors across platforms and devices,

00:11:57 but Sentry has you covered.

00:11:58 They support many JavaScript front-end frameworks, obviously Python backend, such as FastAPI and Django,

00:12:04 and they even support native mobile apps.

00:12:07 For example, at Talk Python, we have Sentry integrated into our mobile apps

00:12:11 for our courses.

00:12:12 Those apps are built and compiled in native code with Flutter.

00:12:15 With Sentry, it's literally a few lines of code to start tracking those errors.

00:12:19 Don't fly blind.

00:12:20 Fix code faster with Sentry.

00:12:22 Create your Sentry account at talkpython.fm/sentry.

00:12:25 And if you sign up with the code TALKPYTHON, one word, all caps, it's good for two free months of Sentry's business plan,

00:12:32 which will give you up to 20 times as many monthly events, as well as some other cool features.

00:12:36 My thanks to Sentry for supporting Talk Python to me.

00:12:39 - Yeah, so out in the audience, Kim says, "AWS does make a few packages available directly

00:12:47 just by default in Lambda." That's kind of nice.

00:12:49 - Yeah, yep.

00:12:50 So yeah, Bodo, which if you're dealing with AWS and Python, you're using the Bodo package.

00:12:57 And yeah, that's included for you.

00:12:59 So that's definitely helpful in any of their, transitive dependencies would be there.

00:13:04 I think Bodo used to even include like requests, but then I think they eventually dropped that

00:13:11 with some like SSL stuff.

00:13:12 But yeah, you definitely, you can't just like pip install anything and not think of it,

00:13:19 unless depending on how you package these up.

00:13:21 So. - Sure.

00:13:22 Sure, that makes sense.

00:13:23 Of course they would include their own Python libraries.

00:13:25 Right?

00:13:26 - Yeah, and it's not a, yeah, it's not exactly small.

00:13:29 I think like Bodo core used to be like 60 megabytes, but I think they've done some work to really get that down.

00:13:37 So.

00:13:37 - Yeah, yeah, that's, yeah, that's not too bad.

00:13:40 I feel like Bodo core, Bodo three, those are constantly changing, like constantly.

00:13:45 - Yeah, yeah, well, as fast as AWS ad services, that they'll probably keep changing quickly.

00:13:52 - Yeah, I feel like those are auto-generated maybe, just from looking at the way the API looks at it,

00:13:58 you know, the way they look written.

00:14:00 And so. - Yeah, yeah.

00:14:01 That's probably the case, yeah.

00:14:04 I know they do that with like their, their infrastructure is code CDK, it's all like TypeScript originally,

00:14:11 and then you have your Python bindings for it and so.

00:14:14 - Right, right, right, right.

00:14:15 I mean, it makes sense, but at the same time, when you see a change, it doesn't necessarily mean,

00:14:19 oh, there's a new important aspect added, it's probably just, I don't know,

00:14:23 people have actually pulled up the console for AWS, but just the amount of services that are there.

00:14:30 And then each one of those has its own full API, like a little bit of the one of those.

00:14:34 So we regenerated it, but it might be for some part that you never, never call, right?

00:14:38 Like you might only work with S3 and it's only changed, I don't know, EC2 stuff, right?

00:14:44 - Right, yep, exactly.

00:14:46 - Yeah, indeed.

00:14:47 All right, well, let's talk real quickly about some of the places where we could do serverless, right?

00:14:53 You've mentioned AWS Lambda.

00:14:55 - Yep.

00:14:56 - And I also maybe touch on just 1 million requests free per month.

00:15:00 That's pretty cool. - Yeah, yeah.

00:15:02 So yeah, getting like jumping into AWS sometimes sounds scary, but they have a pretty generous free tier.

00:15:08 Definitely do your research on some of the security of this, but yeah, you can, a million requests free per month.

00:15:16 You probably have to look into that a little bit because it's, you have your memory configurations too.

00:15:22 So there's probably, I don't know exactly how that works within their free tier, but you're charged like,

00:15:28 with Lambda at least it's your like invocation time and memory and also amount of requests.

00:15:34 So yeah.

00:15:37 - I'm always confused when I look at that and go, okay, with all of those variables,

00:15:41 is that a lot or a little, I know it's a lot, but it's hard for me to conceptualize like,

00:15:45 well, I use a little more memory than I thought.

00:15:47 So it costs like, wait a minute, how do I know how much memory I use?

00:15:50 You know, like. - Yeah.

00:15:51 - What does this mean in practice?

00:15:52 - And it's actually, yeah, it's built by how you configure it too.

00:15:55 So if you say I need a Lambda with 10 gigs of memory, you're being built at that like 10 gigabyte price threshold.

00:16:04 So there is a really, a really cool tool called PowerTooth or AWS Lambda PowerTuner.

00:16:13 So yeah, what that'll do is you can, it creates a state machine in AWS.

00:16:19 Yeah, I think I did send you a link to that one.

00:16:21 So the PowerTuner will create a state machine that invocates your Lambda

00:16:29 with several different memory configurations.

00:16:31 And you can say, I want either the best cost optimized version or the best performance optimized version.

00:16:37 So, and that'll tell you, like, it'll say, okay, yeah, you're best with a Lambda configured at,

00:16:44 you know, 256 megabytes, you know, for memory.

00:16:48 So, sorry, yeah, for the link, it's, this is PowerTools.

00:16:54 This is a different amazing package.

00:16:56 Maybe I didn't send you the PowerTuner.

00:16:58 I should, okay, sorry.

00:16:59 - It's news to me.

00:17:01 I'll look and see. - Okay, sorry, yeah.

00:17:03 And they have similar names.

00:17:04 - Yeah, there's only so many ways to describe stuff.

00:17:07 - Right, yeah, okay.

00:17:08 They have it right in their AW, yep.

00:17:10 - And it is an open source package.

00:17:11 So there's probably a GitHub link in there, but yeah.

00:17:14 And this will tell you like the best way to optimize your Lambda function,

00:17:19 at least as far as memory is concerned.

00:17:22 So, yeah, really good tool.

00:17:24 It gives you a visualization, gives you a graph that will say like, okay, here's kind of where cost and performance meet.

00:17:31 And so, yeah, it's really excellent for figuring that out.

00:17:36 Yeah, at least in AWS land.

00:17:39 I don't know if some of the other cloud providers have something similar to this,

00:17:43 but yeah, it's definitely a really helpful tool.

00:17:48 - Sure, yeah.

00:17:49 Like I said, I'm confused and I've been doing cloud stuff for a long time

00:17:52 when I look at it.

00:17:53 - Yeah, so, well, there's some interesting things here.

00:17:55 So like you can actually have a Lambda invocation that costs less with a higher memory configuration

00:18:04 because it'll run faster.

00:18:05 So you're, I think Lambda bills like by the millisecond now.

00:18:09 So you can actually, because it runs faster, it can be cheaper to run.

00:18:14 So. - Well, that explains all the rust that's been getting written.

00:18:17 - Yeah, yeah.

00:18:18 - There's a real number behind this.

00:18:21 I mean, we need to go faster, right?

00:18:24 Okay, so, I think maybe AWS Lambda is one of the very first ones as well

00:18:29 to come on with this concept of serverless.

00:18:32 - Yeah, I don't know for sure, but it probably is.

00:18:36 And then, yeah, your other big cloud providers have them.

00:18:38 And now you're actually even seeing them come up with a lot of like Vercell has some type

00:18:46 of serverless function.

00:18:47 I don't know what they're using behind it, but it's almost like they just put a nicer UI

00:18:53 around AWS Lambda or whichever cloud provider that's potentially backing this up.

00:18:58 But yeah.

00:18:59 - They're just reselling their flavor of somebody else's cloud, yeah.

00:19:04 - Yeah, it could be because, yeah, Vercel obviously they have a really nice suite

00:19:09 of products with a good UI, very usable.

00:19:12 So, yeah.

00:19:13 - Okay, so Vercel, some of them people can try.

00:19:16 And then we've got the two other hyperscale clouds, I guess you call them.

00:19:20 Google Cloud has serverless, right?

00:19:22 - Yep.

00:19:23 - Okay, so.

00:19:24 - I'm not sure which ones, they might just be called Cloud Functions.

00:19:27 And yeah, Azure also has.

00:19:31 - They got Cloud Run and Cloud Functions.

00:19:33 I have no idea what the difference is though.

00:19:35 - Yep, and yeah, Azure also has a serverless product.

00:19:39 And I'd imagine there's probably like even more that we're not aware of, but yeah,

00:19:45 it's kind of nice to not think about setting up servers for something, so.

00:19:52 - I think maybe, is it FaaS?

00:19:53 Yeah, Function as a Service, let's see.

00:19:55 - Yeah.

00:19:56 - But if we search for FaaS instead of PaaS or IaaS, right?

00:20:01 There's, oh, we've got Almeda, Intel.

00:20:04 I saw that IBM had some.

00:20:06 Oh, there's also, we've got Digital Ocean.

00:20:10 I'm a big fan of Digital Ocean because I feel like their pricing is really fair

00:20:14 and they've got good documentation and stuff.

00:20:16 So they've got functionless, sorry, serverless functions that you can, I don't use these.

00:20:24 - Yeah, I haven't used these either, but yeah.

00:20:27 And yeah, as far as costs, especially for small personal projects and things

00:20:32 where you don't need to have a server on all the time, they're, yeah, pretty nice if you have a website

00:20:39 that you need something server side where you gotta have some Python, but you don't need a server going all the time.

00:20:44 Yeah, it's-

00:20:45 - Okay, like maybe I have a static site, but then I want this one thing to happen

00:20:49 if somebody clicks a button, something like that.

00:20:51 - Yeah, yeah, absolutely.

00:20:53 Yep, you could be completely static, but have something that is, yeah, yeah, that one function call that you do need, yeah.

00:21:00 - Exactly.

00:21:01 And then you also pointed out that Cloudflare has some form of serverless.

00:21:05 - Yeah, and I haven't used these either, but yeah, I do know that they have some type of,

00:21:11 functions as a service as well, so.

00:21:15 - I don't know what frameworks for languages, they let you write them in there.

00:21:19 I use bunny.net for my CDN, just absolutely awesome platform.

00:21:25 I really, really love it.

00:21:26 And one of the things that they've started offering, I can get this stupid, completely useless cookie banner

00:21:30 to go away, is they've offered what they call edge compute.

00:21:35 - Oh, yeah, okay.

00:21:37 - What you would do, I don't know where to find it, somewhere maybe, but basically the CDN has 115,

00:21:44 120 points of presence all over the world where, this one's close to Brazil,

00:21:49 this one's close to Australia, whatever.

00:21:52 But you can actually run serverless functions on those things, like, so you deploy them,

00:21:57 so the code actually executes in 115 locations.

00:22:01 - Yes, yeah.

00:22:02 - Probably Cloudflare or something like that as well, but I don't know.

00:22:05 - Yeah, AWS has, they have like Lambda at edge, at the edge, so that's kind of goes hand in hand

00:22:13 with their like CDN CloudFront, I believe, yeah.

00:22:17 So they have something similar like that, where you have a Lambda that's gonna be,

00:22:22 perform it because it's distributed across their CDN.

00:22:26 - Yeah, CDNs, that's a whole nother world.

00:22:28 They're getting really advanced.

00:22:30 - Yeah, yeah.

00:22:31 - Yeah, so we won't, maybe that's a different show, it's not a show today, but it's just the idea of like,

00:22:38 you distribute the compute on the CDN, it's pretty nice.

00:22:42 The drawback is it's just JavaScript, which is okay, but it's not the same as--

00:22:47 - Right, yes, yeah.

00:22:49 - Wonder if you could do HighScript.

00:22:51 - Oh, yeah, that's an interesting thought, yeah.

00:22:54 - Yeah, we're getting closer and closer to Python in the browser, so.

00:22:57 - Yeah, my JavaScript includes this little bit of WebAssembly, and I don't like semicolons, but go ahead and run it anyway.

00:23:04 - Yeah.

00:23:05 - Out in the audience, it looks like CloudFlare probably does support Python, which is awesome.

00:23:10 - Yeah, yeah, there's so many options out there for serverless functions that are, yeah,

00:23:16 especially if you're already in, if you're maybe deploying some static stuff

00:23:21 over CloudFlare or Brazil, yeah, it's sometimes nice just to be all in on one service.

00:23:29 - Yeah, yeah, it really is.

00:23:30 Let's talk about choosing serverless over other things, right, you've actually laid out two really good examples,

00:23:37 or maybe three even with the static site example, but I've got bursts of activity.

00:23:43 - Yeah, that's definitely--

00:23:44 - Right, and really, really low, incredibly, incredibly low usage other times, right?

00:23:51 - Yeah, yeah, you think of like, yeah, your Black Friday traffic, right?

00:23:54 Like you, to not have to think of like how many servers to be provisioned

00:24:00 for something like that, or if you don't know, I think there's probably some like,

00:24:06 well, I actually know there's been like some pretty popular articles about people

00:24:09 like leaving the cloud, and yeah, like if you know your scale and you know,

00:24:16 you know exactly what you need, yeah, you probably can save money by just having

00:24:22 your own infrastructure set up, or, but yeah, if you don't know, or it's very like spiky, you don't need to have a server

00:24:31 that's consuming a lot of power running, you know, 24 hours a day, you can just invoke a function as you need, so.

00:24:39 - This portion of Talk Python to Me is brought to you by MailTrap, an email delivery platform that developers love.

00:24:48 An email sending solution with industry best analytics, SMTP and email API SDKs for major programming languages

00:24:56 and 24/7 human support.

00:24:59 Try for free at mailtrap.io.

00:25:02 - Yeah, there's a super interesting series by David Heinemeyer Hansen of Ruby on Rails fame

00:25:09 and from Basecamp about how Basecamp has left the cloud and how they're saving $7 million

00:25:16 and getting better performance over five years.

00:25:18 - Yeah, yeah.

00:25:19 - But that's a big investment, right?

00:25:21 They bought, they paid $600,000 for hardware, right?

00:25:26 - Yeah, yeah.

00:25:27 - Only so many people can do that.

00:25:28 - Right, and you know, you gotta have that running somewhere that, you know, with backup power and, yeah.

00:25:36 - Yeah, so what they ended up doing for this one is they went with some service called Geft,

00:25:42 cloud hosting, which is like white glove, white, so white labeled is the word I'm looking for,

00:25:49 where it just looks like it's your hardware, but they put it into a mega data center.

00:25:54 And there's, you know, they'll have the hardware shipped to them and somebody will just come out

00:25:58 and install it into racks and go, here's your IP.

00:26:00 - Right, yeah.

00:26:01 - Like a virtual VM or a VM in a cloud, but it takes three weeks to boot.

00:26:09 - Right, yeah, yeah.

00:26:12 - Which is kind of the opposite, it's almost, I'm kind of diving into it because it's almost

00:26:16 the exact opposite of the serverless benefits, right?

00:26:20 This is insane stability.

00:26:22 I have this thing for five years.

00:26:25 We have 4,000 CPUs we've installed and we're using them for the next five years

00:26:30 rather than how many milliseconds am I gonna run this code for?

00:26:33 - Right, exactly, yeah, yeah, yeah.

00:26:35 It's definitely the far opposite.

00:26:37 And so, yeah, you kind of, you know, maybe serverless isn't for every use case,

00:26:42 but it's definitely a nice like tool to have in the toolbox and yeah, you definitely,

00:26:47 even working in serverless, like if you're, yeah, eventually you're gonna need like maybe

00:26:52 to interact with the database that's gotta be on all the time, you know, it's, yeah, there's a lot of,

00:26:57 it's a good tool, but it's definitely not the one size fits all solution, so.

00:27:02 - Yeah, let's talk databases in a second, but for, you know, when does it make sense to say,

00:27:07 we're gonna put this, like if let's suppose I have an API, right, that's a pretty,

00:27:11 an API is a real similar equivalent to what a serverless thing is, like,

00:27:16 I'm gonna call this API, things gonna happen, I'm gonna call this function, the thing's gonna happen.

00:27:19 Let's suppose I have an API and it has eight endpoints, it's written in FastAPI or whatever it is.

00:27:24 It might make sense to have that as serverless, right?

00:27:27 You don't wanna run a server and all that kind of thing.

00:27:29 But what if I have an API with 200 endpoints?

00:27:32 Like, where is the point where like, there are so many little serverless things,

00:27:35 I don't even know where to look, they're everywhere, which version is this one?

00:27:38 You know what I mean?

00:27:38 Like, where's that trade off and how do, you know, you and the people you work with

00:27:42 think about that?

00:27:43 - Yeah, I guess that's a good question.

00:27:47 I mean, as you start like, you know, getting into these like micro services,

00:27:52 how small do you wanna break these up?

00:27:54 And so there is some different thoughts on that.

00:27:58 Even like a Lambda function, for instance, if you put this behind an API,

00:28:03 you can use a single Lambda function for your entire REST API, even if it is,

00:28:12 you know, 200 endpoints.

00:28:13 So- - Okay.

00:28:15 - Yeah. - So you put the whole app there and then when a request comes in,

00:28:18 it routes to whatever part of your app?

00:28:20 - Theoretically, yeah.

00:28:21 Yeah, so there's a package called Power Tools for AWS Power Tools.

00:28:28 AWS Lambda Power Tools for Python.

00:28:30 Yeah, I know, yes.

00:28:31 Yeah, I know the similar name.

00:28:32 Yeah, so they have a really good like event resolver.

00:28:36 So you can actually, it almost looks like, you know, Flask or some of the other Python web frameworks.

00:28:44 And so you can have this resolver, whether it's, you know, API gateway and in AWS

00:28:49 or different, they have a few different options for the API itself.

00:28:54 But yeah, in theory, you could have your entire API behind a single Lambda function,

00:29:02 but then that's probably not optimal, right?

00:29:04 So you're, that's where you have to figure out how to break that up.

00:29:09 And so, yeah, they do like that same, the decorators, you know, app.post or, yeah.

00:29:17 Yeah, and your endpoints and you can do the, with the, have them have variables in there

00:29:23 where maybe you have like ID as your lookup and it can, you know, slash user slash ID

00:29:29 is going to find your, find, you know, a single user.

00:29:33 So, and their documentation, they actually address this a little bit.

00:29:37 Like, do you want to do, they call it either like a micro function pattern

00:29:43 where maybe every single endpoint has its own Lambda function.

00:29:48 But yeah, that's a lot of overhead to maintain.

00:29:50 If you had, like you said, 200 endpoints, you have 200 Lambdas.

00:29:54 - You gotta upgrade them all at the same time so they have the right data models and all that.

00:30:00 Yeah, that's really.

00:30:01 - So yeah, so there's definitely some, even conflicting views on this.

00:30:07 How micro do you want to go?

00:30:09 And so I was able to go to AWS reInvent in November and they actually kind of pitched this hybrid.

00:30:19 Maybe like if you take your like CRUD operations, right?

00:30:21 And maybe you have your create, update and delete all on one Lambda that's with its configuration for those,

00:30:30 but your read is on another Lambda.

00:30:33 So maybe your CRUD operations, they all interact with a relational database,

00:30:37 but your reader just does like reads from a Dynamo database where you kind of sync that data up.

00:30:45 And so you could have your permissions kind of separated for each of those Lambda functions.

00:30:50 And people reading from an API don't always need the same permissions as updating, deleting.

00:30:57 And so, yeah, there's a lot of different ways to break that up and how micro do you go with this?

00:31:04 - Definitely. - How micro can you go?

00:31:05 - Yeah. - Yeah, 'cause it sounds to me like if you had many, many of them,

00:31:09 then all of a sudden you're back to like, wait, I did this because I didn't want to be in DevOps

00:31:14 and now I'm different kind of DevOps.

00:31:17 - Yeah, yeah.

00:31:18 So yeah, that Python, that package, the Power Tools is, does a lot of like heavy lifting for you.

00:31:27 At PyCon, there was a talk on serverless that the way they described the Power Tools package

00:31:34 was it, they said it like codified your serverless best practices.

00:31:39 And it's really true.

00:31:40 They give a lot, there's like so many different tools in there.

00:31:43 There's a logger, like a structured logger that works really well with Lambda.

00:31:48 And you don't even have to use like the AWS login services.

00:31:53 If you want to use like, you know, Datadog or Splunk or something else, it's just a structured logger and how you aggregate them

00:32:01 is like up to you and you can even customize how you format them.

00:32:04 But it's, works really well with Lambda.

00:32:08 - Yeah, you probably could actually capture exceptions and stuff with something like Sentry even, right?

00:32:14 - Oh yeah.

00:32:14 - Python code, there's no reason you couldn't.

00:32:16 - Right, exactly.

00:32:17 Yeah.

00:32:18 Yeah, some of that comes into, you know, packaging up those libraries for that.

00:32:23 You do have to think of some of that stuff, but like Datadog. - Log this log.

00:32:27 - Yeah.

00:32:28 Yeah, Datadog, for instance, they provide something called like a Lambda layer

00:32:32 or a Lambda extension, which is another way to package code up that just makes it a little bit easier.

00:32:38 So yeah, there's a lot of different ways to attack some of these problems.

00:32:43 - A lot of that stuff, even though they have nice libraries for them, it's really just calling a HTTP endpoint

00:32:48 and you could go, okay, we need something really light.

00:32:51 I don't know if requests is already included, or, but there's some gotta be some kind of HTTP thing

00:32:54 already included.

00:32:55 We're just gonna directly call it, not.

00:32:57 - Sure.

00:32:58 - And then we'll just do all these packages.

00:32:59 Yeah.

00:33:00 - Yep.

00:33:00 - Yeah.

00:33:01 - Yeah.

00:33:02 This code looks nice.

00:33:03 This Power Tools code, it looks like well-written Python code.

00:33:07 - They do some really amazing stuff and they bring in a Pydantic too.

00:33:13 So yeah, like being mostly in serverless, I've never really gotten to use like FastAPI, right?

00:33:20 And leverage Pydantic as much, but with Power Tools, you really can.

00:33:24 So they'll package up Pydantic for you.

00:33:28 And so you can actually, yeah, you can have Pydantic models for validation on these.

00:33:36 It's like a Lambda function, for instance, it always receives an event.

00:33:41 There's always like two arguments to the handler function, it's event and context.

00:33:45 And like event is always a, it's a dictionary in Python.

00:33:50 And so they can always look different.

00:33:53 And so, yeah.

00:33:56 So, 'cause the event, yeah.

00:33:58 So if you look in the Power Tools, GitHub, their tests, they have like, okay, here's what an event from-

00:34:07 - API gateway proxy event.json or whatever, right?

00:34:11 - Yes, yeah.

00:34:12 So they have, yeah, examples.

00:34:14 Yes, yeah.

00:34:15 So like, you don't wanna parse that out by yourself.

00:34:19 - No.

00:34:20 - So they have Pydantic models or they might actually just be Python data classes,

00:34:26 but that you can say like, okay, yeah, this function is going to be for, yeah,

00:34:32 an API gateway proxy event, or it's going to be an S3 event or whatever it is.

00:34:37 You know, there's so many different ways to receive events from different AWS services.

00:34:42 So, yeah, Power Tools kind of gives you some nice validation.

00:34:47 And yeah, you might just say like, okay, yeah, the body of this event, even though I don't care about all this other stuff

00:34:53 that they include, the path headers, queer string parameters, but I just need like the body of this.

00:35:00 So you just say, okay, event.body, and you can even use, you can validate that further.

00:35:06 The event body is going to be a Pydantic model that you created, so.

00:35:10 - Yeah, there's a lot of different pieces in here.

00:35:12 If I was working on this and it didn't already have Pydantic models, I would take this and go to JSON Pydantic.

00:35:19 - Oh, I didn't even know this existed.

00:35:21 That's weird, okay.

00:35:22 - Boom, put that right in there and boom, there you go.

00:35:25 It parses it onto a nested tree, object tree of the model.

00:35:30 - Very nice, yeah.

00:35:31 - But if they already give it to you, they already give it to you, then just take what they give you, but.

00:35:34 - Yeah, those specific events might be data classes instead of Pydantic, just because you don't,

00:35:40 that way you don't have to package Pydantic up in your Lambda.

00:35:43 But yeah, if you're already figuring out a way to package Power Tools, you're close enough that you probably

00:35:49 just include Pydantic too, but.

00:35:51 - Yeah.

00:35:52 - Yeah, and they also, I think they just added this feature where it'll actually generate OpenAPI schema for you.

00:36:02 I think, yeah, FastAPI does that as well, right?

00:36:04 So, yeah, so that's something you can leverage Power Tools to do now as well.

00:36:10 - So, excellent, and then you can actually take the OpenAPI schema and generate a Python.

00:36:14 - Client board on top of that, I think.

00:36:16 - Yeah, yeah.

00:36:17 - So you just, it's robots all the way down.

00:36:19 - Right, yeah.

00:36:20 - All the way down.

00:36:21 - Yeah, yeah, yeah.

00:36:24 Yeah, I haven't used those OpenAPI generated clients very much.

00:36:30 I was always skeptical of them, but yeah, in theory.

00:36:34 - I just feel heartless, or soulless, I guess, is the word, like, boring.

00:36:37 It's just like, okay, here's another star org, star star KW orgs thing, where it's like,

00:36:42 couldn't you just write, make some reasonable defaults and give me some keyword argument, you know,

00:36:46 just like, it's all top field.

00:36:47 But if it's better than nothing, you know, it's better than nothing.

00:36:50 - Right, yeah, yeah.

00:36:51 So, but yeah, you can see like Power Tools, they took a lot of influence from FastAPI and--

00:36:58 - It does seem like it, yeah, for sure.

00:36:59 - Yeah, yeah.

00:37:00 So it's definitely really powerful and you get some of those same benefits.

00:37:05 - Yeah, this is new to me, it looks quite nice.

00:37:07 So another comment by Kim is, tended to use serverless functions for either things

00:37:12 that run briefly, like once a month on a schedule, or the code that processes stuff coming in on an AWS SQS,

00:37:19 simple queuing service, queue of unknown schedule.

00:37:23 So maybe that's an interesting segue into how do you call your serverless code?

00:37:28 - Yeah, yeah.

00:37:29 So as we kind of touched on, there's a lot of different ways from like, you know,

00:37:34 AWS, for instance, to do it.

00:37:36 So yeah, like AWS Lambda has like Lambda function URLs, but I haven't used those as much.

00:37:43 But if you just look at like the different options and like power tools, for instance,

00:37:47 you can have a load balancer that's gonna, where you set the endpoint to invoke a Lambda,

00:37:54 you can have API gateway, which is another service they have.

00:37:59 So there's a lot of different ways, yeah, SQS.

00:38:03 So that's kind of almost getting into like a way of like streaming or an asynchronous way of processing data.

00:38:11 So yeah, maybe in AWS, you're using a queue, right?

00:38:16 That's filling up and you say like, okay, yeah, every time this queue is at this size or this timeframe,

00:38:23 invoke this Lambda and process all these messages.

00:38:27 So there's a lot of different ways to invoke a Lambda function.

00:38:33 So if it's, I mean, really as simple as you can invoke them like from the AWS CLI or,

00:38:41 but yeah, most people are probably have some kind of API around it.

00:38:44 - Yeah, yeah, almost make them look like just HTTP endpoints.

00:38:47 - Right, yeah.

00:38:48 - Yeah, Mark out there says, not heard talk of ECS, I don't think, but I've been running web services

00:38:55 using Fargate serverless tasks on ECS for years now.

00:38:59 Are you familiar with this?

00:39:00 I haven't done it.

00:39:02 - Yeah, I'm like vaguely familiar with it, but yeah, this is like a serverless,

00:39:08 yeah, serverless compute for containers.

00:39:10 So I haven't used this personally, but yeah, very like similar concept where it kind of scales up for you.

00:39:19 And yeah, you don't have to have things running all the time, but yeah, it can be Dockerized applications.

00:39:25 Now, in fact, the company I work for now, they do this with their Ruby on Rails applications.

00:39:29 They Dockerize them and run with Fargate.

00:39:34 So.

00:39:35 - Creating Docker containers of these things, the less familiar you are with running that tech stack,

00:39:42 the better it is in Docker, you know what I mean?

00:39:44 - Yeah, yeah.

00:39:45 - Like I could run straight Python, but if it's Ruby on Rails or PHP, maybe it's going into a container.

00:39:51 That would make me feel a little bit better about it.

00:39:53 - Yeah, especially if you're in that workflow of like handing something over to a DevOps team, right?

00:39:57 Like you can say like, here's an image or a container or a Docker file that will work for you.

00:40:04 That's maybe a little bit easier than trying to explain how to set up an environment or something, so.

00:40:11 - Yeah.

00:40:11 - Yeah, Fargate's a really good serverless option too.

00:40:15 - Excellent.

00:40:16 What about performance?

00:40:17 You know, you talked about having like a whole API apps, like FastAPI, Flask or whatever.

00:40:23 - Yeah.

00:40:24 - The startup of those apps can be somewhat, can be non-trivial basically.

00:40:27 And so then on the other side, we've got databases and stuff.

00:40:31 And one of the bits of magic of databases is the connection pooling that happens, right?

00:40:36 So the first connection might take 500 milliseconds, but the next one takes one.

00:40:40 As it's already open effectively, right?

00:40:42 - Yeah, yeah.

00:40:43 That's definitely something you really have to take into consideration is like how much you can do.

00:40:48 That's where some of that like observability, some of like the tracing that you can do

00:40:53 and profiling is really powerful.

00:40:55 Yeah, AWS Lambda, for instance, they have something called cold starts.

00:41:03 So like, yeah.

00:41:05 So the first time like a Lambda gets invoked or maybe you have 10 Lambdas that get called

00:41:12 at the same time, that's gonna, you know, invoke 10 separate Lambda functions.

00:41:17 So that's like great for the scale, right?

00:41:19 That's really nice.

00:41:22 But on a cold start, it's usually a little bit slower invocation because it has to initialize.

00:41:27 Like I think what's happening, you know, behind the scenes is they're like,

00:41:32 they're moving your code over that's gonna get executed.

00:41:35 And anything that happens like outside of your handler function, so importing libraries,

00:41:43 sometimes you're establishing a database connection.

00:41:46 Maybe you're, you know, loading some environment variables or some, you know, secrets.

00:41:52 And so, yeah, there's definitely, performance is something to consider.

00:41:57 Yeah, that's probably, you mentioned Rust.

00:42:01 Yeah, there's probably some more performant, like runtimes for some of these serverless functions.

00:42:06 So I've even heard some people say, okay, for like client facing things,

00:42:13 we're not gonna use serverless.

00:42:15 Like we just want that performance.

00:42:17 So that cold start definitely can, that can have an impact on you.

00:42:21 - Yeah, on both ends that I've pointed out.

00:42:25 The app start, but also the service, the database stuff with like the connection.

00:42:29 - Right, yeah, so yeah, relational databases too.

00:42:32 That's an interesting thing.

00:42:34 - Yeah, what do you guys do?

00:42:35 You mentioned Dynamo already.

00:42:36 - Yeah, so Dynamo really performant for a lot of connections, right?

00:42:41 But a, so Dynamo is a, you know, serverless database that can scale, you can query it over and over

00:42:48 and that's not going to, it doesn't reuse a connection in the same way that like a SQL database would.

00:42:55 So that's an excellent option, but if you do have to connect to a relational database

00:43:02 and you have a lot of invocations, you can use a, like a proxy, if you're all in on AWS.

00:43:11 And so again, sorry for this is really AWS heavy, but if you're using their like

00:43:15 relational database service, RDS, you can use RDS proxy, which will use like a pool of connections

00:43:22 for your Lambda function.

00:43:24 - Oh, interesting.

00:43:24 - So that can, yeah, that can give you a lot of performance or at least you won't be, you know,

00:43:32 running out of connections to your database.

00:43:34 So another thing too, is just how you structure that connection.

00:43:39 So I mentioned cold Lambdas, you obviously have warm Lambdas too.

00:43:43 So a Lambda has its handler function.

00:43:47 And so anything outside of the handler function can get reused on a warm Lambda.

00:43:52 So you can establish the connection to a database and it'll get reused on every invocation that it can.

00:43:58 - That's cool.

00:43:59 Do you have to do anything explicit to make it do that?

00:44:01 Or is that just a...

00:44:03 - It just has to be outside of that handler function.

00:44:06 So, you know, kind of at your top level of your file.

00:44:10 So, yeah.

00:44:11 - Excellent, yeah.

00:44:12 It makes me think almost one thing you would consider is like profiling the import statement almost, right?

00:44:18 - Yeah.

00:44:19 - That's what we normally do, but there's a library called import profiler

00:44:24 that actually lets you time how long different things take to import.

00:44:27 It could take a while, especially if you come from, not from a native Python way of thinking

00:44:33 in like C# or C++ or something.

00:44:36 You say hash include or using such and such, like that's a compiler type thing that really has no cost.

00:44:44 - Yeah.

00:44:45 - But there's code execution when you import something in Python and some of these can take a while, right?

00:44:49 - Yes, yeah.

00:44:50 So there's a lot of tools for that.

00:44:52 There's some, I think even maybe specific for Lambda.

00:44:55 I know like Datadog has a profiler that gives you like this, I forget what the graphic is called.

00:45:02 Like a flame graph. - Flame graph?

00:45:03 - A flame graph, yeah.

00:45:04 That'll give you like a flame graph and show like, okay, yeah, it took this long

00:45:07 to make your database connection, this long to import Pydantic.

00:45:12 And it took this long to make a call to DynamoDB, you know, so you can actually kind of like break that up.

00:45:21 AWS has X-Ray, I think, which does something similar too.

00:45:24 So yeah, it's definitely something to consider.

00:45:28 Another, just what you're packaging is definitely something to watch for.

00:45:34 And so I mentioned, yeah, I mentioned using Pants to package Lambdas and they do, hopefully I don't butcher

00:45:45 how this works behind the scenes, but they're using Rust and they'll actually kind of like infer

00:45:51 your dependencies for you.

00:45:52 And so they have an integration with AWS Lambda.

00:45:57 They also have it for Google Cloud Functions.

00:46:00 So yeah, it'll go through, you say, here's like my AWS Lambda function.

00:46:05 This is the file for it and the function that needs to be called.

00:46:09 And it's gonna create a zip file for you that has your Lambda code in it.

00:46:15 And it's gonna find all those dependencies you need.

00:46:17 So it'll actually, by default, it's gonna include like Bodo that you need.

00:46:23 If you're using Bodo, if you're gonna use, PyMySQL or whatever library, it's gonna pull all those in and zip that up for you.

00:46:34 And so if you just like open up that zip and you see, especially if you're sharing code across your code base,

00:46:41 maybe you have a shared function to make some of these database connections or calls.

00:46:46 Like you see everything that's gonna go in there.

00:46:50 And so, yeah.

00:46:52 And so how like Pants does it is it's file-based.

00:46:55 So sometimes just for like ease of imports, you might throw a lot of stuff in like your init.py file

00:47:02 and say like, okay, yeah, from, you know, you add all, kind of bubble up all your things

00:47:07 that you want to import in there.

00:47:09 Well, if one of those imports is also using OpenCV, and you don't need that,

00:47:18 then Pants is gonna say like, oh, he's importing this.

00:47:21 And because it's file-based, now this Lambda needs OpenCV, which is a massive package that's going to,

00:47:29 it's going to impact your performance, especially in those cold starts.

00:47:33 'Cause that code has to be moved over.

00:47:36 So. - Yeah.

00:47:37 That's pretty interesting.

00:47:38 So kind of an alternative to saying, here's my requirements or my pyproject.toml.

00:47:44 - A lock file or whatever. - Yeah.

00:47:46 - That just lists everything the entire program might use.

00:47:48 This could say, you're gonna import this function.

00:47:51 And to do that, it imports these things, which import those things.

00:47:53 And then it just says, okay, that means here's what you need, right?

00:47:57 - Right, yeah.

00:47:58 Yeah, it's definitely one of like the best ways that I've found to package up Lambda functions.

00:48:04 I think some of the other tooling might do some of this too, but yeah, a lot of times it would require

00:48:10 like requirements.txt.

00:48:12 But if you have like a large code base too, where maybe you do have this shared module for that,

00:48:19 maybe you have 30 different Lambda functions that are all going to use some kind of helper function.

00:48:24 It's just gonna go and like grab that.

00:48:26 And it doesn't have to be like pip installable.

00:48:28 Pants is smart enough to just be like, okay, it needs this code.

00:48:31 And so, but yeah, you just have to be careful.

00:48:34 Yeah, yeah.

00:48:35 And there's so many other cool things that Pants is doing that they have some really nice stuff for testing

00:48:41 and linting and formatting.

00:48:43 And it's, yeah, there's a lot of really good stuff that they're doing.

00:48:48 - Yeah, I had Benji on the show to talk about Pants.

00:48:51 That was fun.

00:48:52 - Yeah.

00:48:53 - So let me go back to this picture.

00:48:55 Is this the picture?

00:48:56 I have a lot of things open on my screen now.

00:48:59 There.

00:49:00 So on my server setup that I described, which is a bunch of Docker containers

00:49:04 running on one big machine, I can go in there and I can say, tail this log and see all the traffic

00:49:10 to all the different containers.

00:49:11 I can tail another log and just see like the logging, log book, log guru, whatever output of that,

00:49:17 or just web traffic.

00:49:18 Like there's different ways to just go.

00:49:20 I'm just gonna sit back and look at it for a minute.

00:49:22 Make sure it's chilling, right?

00:49:24 If everything's so transient, not so easy in the same way.

00:49:28 So what do you do?

00:49:29 - Yeah.

00:49:30 So yeah, Power Tools does, they have their structured logger that helps a lot.

00:49:36 But yeah, you have to kind of like aggregate these logs somewhere, right?

00:49:39 Because yeah, you can't, you know, a Lambda function you can't like SSH into, right?

00:49:44 So yeah.

00:49:45 - You can't, it's gonna take too long.

00:49:47 - Yeah, yeah.

00:49:48 So yeah, you need to have some way to aggregate these.

00:49:53 So like AWS has CloudWatch where that will like by default kind of log all of your standard out.

00:50:00 So even like a print statement would go to CloudWatch just by default.

00:50:07 But you probably wanna like structure these better with most likely and, you know, JSON format,

00:50:13 just most tooling around those is going to help you.

00:50:16 So yeah, the Power Tools structured logger is really good.

00:50:20 And you can even like, you can have like a single log statement, but you can append different keys to it.

00:50:27 And it's pretty powerful, especially 'cause you don't wanna like, I think like, so if you just like printed something

00:50:36 in a Lambda function, for instance, that's gonna be like a different row on each of your,

00:50:41 like by like the default CloudWatch, like it'll be, how it breaks it up is really odd

00:50:48 unless you have some kind of structure to them.

00:50:50 - Okay. - And so, yeah.

00:50:52 So definitely something to consider.

00:50:55 Something else you can do is, yeah, there's metrics you can do.

00:51:00 So like how it works with like CloudWatch, they have a specific format.

00:51:04 And if you use that format, you can, it'll automatically pull that in as a metric.

00:51:11 And like Datadog has something similar where you can actually kind of like go in there.

00:51:15 You can look at your logs and say like, find a value and be like, I want this to be a metric now.

00:51:20 And so that's really powerful.

00:51:23 - Oh, the metric sounds cool.

00:51:24 So I see logging and tracing.

00:51:27 What's the difference between those things?

00:51:29 Like to me, tracing is a level, just a high level of logging.

00:51:33 - Yeah, tracing, and hopefully I do the justice differentiated too.

00:51:41 I feel like tracing does have a lot more to do with your performance or maybe even closer to like tracking

00:51:48 some of these metrics, right?

00:51:49 I've used the Datadog tracer a lot and I've used the AWS like X-ray, their tracing utility a little bit too.

00:52:01 And so like those will show you.

00:52:04 So like maybe you are reaching out to a database, writing to S3. - Almost like a APM

00:52:08 application performance monitoring where it says you spent this much time in a SQL query

00:52:14 and this much time in identic serialization.

00:52:18 Whereas the logging would say, a user has been sent a message.

00:52:22 - Right, exactly.

00:52:23 Yeah, yeah.

00:52:24 Tracing definitely is probably more around your performance and yeah, things like that.

00:52:29 - It's kind of insane that they can do that.

00:52:31 You see it in the Django debug tool or in the pyramid debug tool, but they'll be like, here's your code

00:52:37 and here's all your SQL queries and here's how long they took.

00:52:39 And you're just like, wow, that thing is reaching deep down in there.

00:52:42 - The Datadog one is very interesting because like it just knows like that this is a SQL connection

00:52:49 and it tells you like, oh, okay, this SQL connection took this long.

00:52:52 And it was like, I didn't tell it to even trace that.

00:52:55 Like it just like, it knows really well.

00:52:58 Yeah, so like the expectation.

00:52:59 - It's one thing to know a SQL connection is open, it's another to say, and here's what it sent over SSL by the way.

00:53:04 Like how'd you get in there?

00:53:05 - Yeah, yeah.

00:53:06 So especially.

00:53:07 - It's in process so it can do a lot.

00:53:10 It is impressive to see those things that work.

00:53:12 All right, so that's probably what the tracing is about, right?

00:53:14 - Yes, yeah, yeah.

00:53:15 Definitely probably more around performance.

00:53:17 You can put some different things in tracing too.

00:53:20 Like I've used it to say like, we talked about those like database connections to say like,

00:53:25 oh yeah, this is reusing a connection here.

00:53:29 'Cause I was trying to like debug some stuff on, am I creating a connection too many times

00:53:33 so I don't wanna be?

00:53:34 So yeah, you can put some other useful things in tracing as well.

00:53:38 - Yeah, and Pat out in the audience.

00:53:40 Oops, I'm moving around.

00:53:41 When using many microservices, like single execution involves many services basically,

00:53:46 it's hard to follow the logs between the services and tracing helps tie that together.

00:53:51 - Yeah, yeah, that's for sure.

00:53:53 - All right, let's close this out, Tony, with one more thing that I'm not sure

00:53:57 how constructive it can be.

00:53:59 There probably is some ways, but testing, right?

00:54:02 - Yeah, yeah, that's definitely.

00:54:05 - If you could set up your own Lambda cluster, you might just run that for yourself, right?

00:54:10 So how are you gonna do this, right?

00:54:12 - Yeah, to some extent you can, right?

00:54:14 Like there's a Lambda Docker image that you could run locally and you can do that.

00:54:19 But if your Lambda is reaching out to DynamoDB, I guess there's technically a DynamoDB container as well.

00:54:27 Like you could, it's a lot of overhead to set this up, but rather than just doing like, you know, flask start

00:54:35 or, you know, whatever the command is to like spin up a flask server. - I pressed the go button

00:54:38 in my IDE and now it's.

00:54:41 - Yeah, so that's definitely, and there's more and more tooling coming out,

00:54:46 you know, that's coming out for this kind of stuff.

00:54:49 But if you can like unit test, there's no reason you can't just like, you know,

00:54:55 run unit tests locally.

00:54:58 But when you start getting into the integration test, you're probably getting to the point where

00:55:03 maybe you just deploy to actual services.

00:55:07 And, you know, it's always trade-offs, right?

00:55:11 Like there's costs associated with it.

00:55:13 There's the overhead of like, okay, how can I deploy to an isolated environment?

00:55:18 But maybe it interacts with another microservice.

00:55:20 So yeah, so there's definitely trade-offs, but testing is. - I can see that you might

00:55:26 come up with like a QA environment, almost like a mirror image that doesn't share any data.

00:55:33 - Yeah. - But it's sufficiently close, but then you're running, I mean, that's a pretty big commitment 'cause you're running

00:55:38 a whole replica of whatever you have.

00:55:41 - Right, yeah.

00:55:42 And so yeah, QA environments are great, but you might even want lower than QA.

00:55:48 You might want to have a dev or like a, one place I worked at, we would spin up an entire environment for every PR.

00:55:58 So you could actually, yeah, like when you created a PR, that environment got spun up

00:56:05 and it ran your integration tests and system tests against that environment, which, you know,

00:56:10 simulated your prod environment a little bit better than running locally on your machine.

00:56:15 So certainly a challenge to test this.

00:56:19 - Yeah, I can imagine that it is.

00:56:21 - Yeah, and there's always these like one-off things too, right, like you can't really simulate

00:56:27 like that memory limitation of a Lambda locally, you know, as much as when you deploy it

00:56:32 and things like that, so.

00:56:33 - Yeah, yeah.

00:56:34 That would be much, much harder.

00:56:37 Maybe you could run a Docker container and put a memory limit on it, you know, that might work.

00:56:41 - Yeah, yeah, maybe.

00:56:43 - You're back into like more and more DevOps to avoid DevOps.

00:56:46 - Right, yeah, yeah.

00:56:48 - So there it goes, but interesting.

00:56:50 All right, well, anything else you wanna add to this conversation before we wrap it up?

00:56:54 About out of time here.

00:56:55 - Yeah, I guess, I don't know if I have it, hopefully we covered enough.

00:57:00 There's just a lot of like good, yeah, there's a lot of good resources.

00:57:03 The tooling that I've mentioned, like Power Tools and Pants, just amazing communities.

00:57:09 Like Power Tools has a Discord, and you can go on there and ask for help,

00:57:12 and they're super helpful.

00:57:14 Pants has a Slack channel, you can join their Slack and ask, you know, about things.

00:57:19 And so those two communities have been really good and really helpful in this.

00:57:24 A lot of good talks that are available on YouTube too.

00:57:27 So just, yeah, there's definitely resources out there and a lot of people have, you know,

00:57:31 fought this for a while, so.

00:57:33 - Yeah, excellent.

00:57:34 And you don't have to start from just create a function and start typing.

00:57:38 - Yeah, yeah.

00:57:39 - Cool, all right, well, before you get out of here though, let's get your recommendation for a PyPI package.

00:57:45 Something notable, something fun.

00:57:48 - I probably, you know, we've talked a lot about it, but Power Tools is definitely one

00:57:54 that is like everyday getting used for me.

00:57:56 So the, yeah, Power Tools for Lambda and Python, they actually support other languages too.

00:58:03 So they have like the same functionality for like, you know, Node.js, you know, for like TypeScript and .NET.

00:58:08 And so, yeah, but this one definitely leveraging Power Tools and Pydantic together,

00:58:17 just really made like a serverless, a lot of fun to write.

00:58:21 So yeah, definitely doing great things there.

00:58:25 - Excellent, well, I'll put all those things in the show notes and it's been great to talk to you.

00:58:29 Thanks for sharing your journey down the serverless path.

00:58:34 - Yep, thanks for having me.

00:58:35 - You bet.

00:58:36 - Yeah, enjoy chatting.

00:58:37 - Same, bye.

00:58:38 This has been another episode of Talk Python to Me.

00:58:42 Thank you to our sponsors.

00:58:44 Be sure to check out what they're offering.

00:58:45 It really helps support the show.

00:58:47 Take some stress out of your life.

00:58:49 Get notified immediately about errors and performance issues in your web or mobile applications with Sentry.

00:58:55 Just visit talkpython.fm/sentry and get started for free.

00:59:00 And be sure to use the promo code, Talk Python, all one word.

00:59:03 MailTrap, an email delivery platform that developers love.

00:59:07 Try for free at mailtrap.io.

00:59:11 Want to level up your Python?

00:59:12 We have one of the largest catalogs of Python video courses over at Talk Python.

00:59:17 Our content ranges from true beginners to deeply advanced topics like memory and async.

00:59:22 And best of all, there's not a subscription in sight.

00:59:24 Check it out for yourself at training.talkpython.fm.

00:59:28 Be sure to subscribe to the show.

00:59:29 Open your favorite podcast app and search for Python.

00:59:32 We should be right at the top.

00:59:34 You can also find the iTunes feed at /iTunes, the Google Play feed at /play,

00:59:39 and the direct RSS feed at /rss on talkpython.fm.

00:59:43 We're live streaming most of our recordings these days.

00:59:46 If you want to be part of the show and have your comments featured on the air,

00:59:49 be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

00:59:54 This is your host, Michael Kennedy.

00:59:56 Thanks so much for listening.

00:59:57 I really appreciate it.

00:59:58 Now get out there and write some Python code.

01:00:01 (upbeat music)

01:00:19 Thank you for watching.
