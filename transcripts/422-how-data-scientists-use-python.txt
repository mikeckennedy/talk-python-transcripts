00:00:00 Regardless of which side of Python you sit on, software developer or data scientist,

00:00:04 you surely know that data scientists and software devs seem to have different styles and priorities.

00:00:09 Why is that? And what are the benefits as well as the pitfalls of this separation?

00:00:14 That's the topic of this conversation with our guest, Dr. Jody Birchall,

00:00:19 data science developer advocate at JetBrains.

00:00:21 This is Talk Python in Me, episode 422, recorded May 31st, 2023.

00:00:27 Welcome to Talk Python in Me, a weekly podcast on Python.

00:00:43 This is your host, Michael Kennedy.

00:00:45 Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython, both on fosstodon.org.

00:00:52 Be careful with impersonating accounts on other instances, there are many.

00:00:56 Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:01:01 We've started streaming most of our episodes live on YouTube.

00:01:05 Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.

00:01:12 This episode is brought to you by JetBrains, who encourage you to get work done with PyCharm.

00:01:19 Download your free trial of PyCharm Professional at talkpython.fm/done-with-PyCharm.

00:01:26 And it's brought to you by Prodigy from Explosion AI.

00:01:29 Spend better time with your data and build better ML-based applications with Prodigy, a radically

00:01:35 efficient data annotation tool.

00:01:37 Get it at talkpython.fm/Prodigy and use our code TALKPYTHON, all caps, to save 25%

00:01:43 off a personal license.

00:01:44 Jodi, welcome to Talk Python in Me.

00:01:48 Thank you.

00:01:48 I am so thrilled to be on the show.

00:01:50 I'm so thrilled to have you on the show.

00:01:52 I've been a fan of your work for a while and we got a chance to get to know each other at

00:01:56 this year's PyCon.

00:01:57 And so here you are on the podcast as well.

00:02:00 Thank you.

00:02:00 We had some very nice Mexican food, actually, or maybe Utah Mexican.

00:02:05 I don't know quite how I would interpret it.

00:02:07 It was very good, though.

00:02:08 It was very good.

00:02:10 Yeah, the food was excellent.

00:02:11 I thought the parties were great at the conference and people who are maybe still holding out on

00:02:18 going.

00:02:18 Personally, I really enjoyed being there.

00:02:20 I think it's probably the best conference that I go to yearly.

00:02:24 And it's like the vibe is so nice.

00:02:26 On this show, we're going to talk about how data scientists use Python, which is somewhat

00:02:33 different than maybe a software developer we have, which I guess I'll put myself solidly

00:02:38 into that camp.

00:02:39 I do a bunch of web development, make APIs, I build apps and ship them.

00:02:43 That's quite a different story.

00:02:45 And I think we're going to have a really great time talking about those things.

00:02:48 But before we do, let's get a little bit.

00:02:51 How did you get into programming, Python, data science?

00:02:54 Yeah.

00:02:54 So I'm probably going hand in hand with maybe not being a developer.

00:02:59 My story is perhaps a little unconventional.

00:03:01 So my background is academic, like a lot of data scientists.

00:03:05 And unsurprisingly, the first language that I learned was R because I was doing psychology

00:03:10 and health sciences and a lot of statistics.

00:03:13 And I was procrastinating once during my PhD.

00:03:17 You will find any excuse to not work on your thesis.

00:03:20 And I think I was reading, oh, you know, people who are into statistics, you should really learn

00:03:25 Python.

00:03:25 It's the future.

00:03:26 And I was like, I should learn Python.

00:03:28 So I sat down and...

00:03:29 Because I really don't want to write that next chapter.

00:03:32 I just don't.

00:03:32 Exactly.

00:03:32 Exactly.

00:03:33 So I remember it.

00:03:34 Like I actually had this long weekend and I worked my way through, I think it was Zed Shaw's

00:03:40 Learn Python the Hard Way.

00:03:41 This is showing my age, I think.

00:03:43 I loved it.

00:03:44 Like I completed the course in three days and then I didn't know what to do with Python

00:03:49 because the stats libraries weren't as developed back then.

00:03:51 So I just put it aside for a couple of years and ended up picking it up again when I started

00:03:57 working in industry because obviously I've left academia.

00:04:00 And you sort of fairly quickly, once you start in data science, move away from more sort of

00:04:05 statistical stuff to machine learning.

00:04:07 And Python really has libraries for that.

00:04:09 So that's my journey.

00:04:11 It's a little bit bibs and bobs and stops and starts.

00:04:15 But once I kind of picked up Python, it really was love at first sight.

00:04:18 Oh, that's excellent.

00:04:19 What's your PhD in?

00:04:20 It's actually...

00:04:21 Computer science, of course, right?

00:04:22 Of course, of course.

00:04:24 You know, it's so funny.

00:04:25 You are the third person to ask me in two weeks and no one has asked me this question for like

00:04:29 two years.

00:04:30 My PhD was in hurt feelings.

00:04:32 Hurt feelings?

00:04:33 Yeah.

00:04:33 Okay.

00:04:34 I say this a little bit blithely.

00:04:35 So my PhD being in psychology, I was really interested in emotions research and

00:04:41 relationships research.

00:04:42 So I kind of wanted to see what happens to people emotionally when close relationships

00:04:47 go bad.

00:04:48 And it's hurt feelings like things like, you know, infidelities, rejections, all of that.

00:04:55 It's hurt.

00:04:55 So I was just studying what generates like and regulates the intensity of hurt and studied

00:05:01 that for four and a half years.

00:05:03 Sounds interesting.

00:05:05 I'm sure there was a lot of data to process.

00:05:07 There was a lot of data to process and a lot of very interesting statistics.

00:05:12 That was sort of how I got into data science.

00:05:15 I fell in love with stats in undergrad and just kept going down that path.

00:05:18 I think a lot of people are drawn to data science, not with the intent of waking up one

00:05:25 day and saying, I'm going to be a data scientist, but they're excited or inspired about something

00:05:29 tangential.

00:05:30 And they're like, well, I really need to get something better than Excel to work on

00:05:34 this.

00:05:35 Absolutely.

00:05:36 Yeah.

00:05:36 Yeah.

00:05:37 And we'll probably talk about this a little bit later about why data scientists use programming.

00:05:42 And it kind of is like in some ways that need to jump from something way more powerful and

00:05:48 reproducible than Excel.

00:05:49 Yeah.

00:05:49 Yeah.

00:05:50 For sure.

00:05:50 So how about now?

00:05:51 You said you've left academics.

00:05:53 And what are you doing these days?

00:05:56 Yeah.

00:05:56 So that leap from academia was a long time ago now.

00:05:59 I think that was like seven years again, showing my age.

00:06:02 So for six of those years, I was a data scientist.

00:06:06 So day to day was, you know, pretty varied, but the job I have now is very different.

00:06:13 So I currently work as a developer advocate at JetBrains.

00:06:16 And the way I would describe my job is I'm a liaison between data scientists and JetBrains.

00:06:23 So I try and advocate for our tools to be as good as they can be.

00:06:27 And I try to recommend ways that people can use our tools if I think it's useful.

00:06:31 But I'm definitely not marketing or sales.

00:06:33 It's more if I think this is the right fit for you, I'll do it.

00:06:36 So it's like the way I achieve that is really up to me.

00:06:41 For me, I really kind of, I like to do a mixture of what I call internal and external

00:06:46 activities.

00:06:47 So external activities are actually kind of only tangentially related to the products.

00:06:52 So this would be an example of an external activity.

00:06:54 It's just getting out there and educating people about data science or educating data scientists

00:06:58 about technical topics, things like conference talks or webinars, you know, all this sort of

00:07:05 stuff.

00:07:05 And then internal stuff is more focused on maybe things a bit more related to the product.

00:07:10 So if I think there's a feature that people would be really interested in, I might make a

00:07:13 video about it or create, you know, a blog post.

00:07:17 So yeah, it's a real hodgepodge.

00:07:19 So this week, for example, I've been working on actually a materials for a free workshop that

00:07:26 they're organizing at Europython.

00:07:27 So I'm going to be volunteering to help out that.

00:07:29 It's completely unrelated to anything I'm doing at JetBrains.

00:07:32 It's just a volunteer activity.

00:07:33 But last week, I was at a conference, week before that.

00:07:36 So you can see the job's pretty varied.

00:07:38 Think developer evangelist.

00:07:40 It seems like such a fun job.

00:07:42 You know, I had your colleague, Paul Everett on and we actually talked, it's quite a while

00:07:46 ago, a couple of years ago, three, four.

00:07:48 And we had a whole episode on like a panel on what is the developer advocate, developer

00:07:54 relations job.

00:07:56 But it's, it just seems like such a great mix of you still get to travel a little bit,

00:08:01 see people, but you also get to write code and work on, on influencing technology and products

00:08:08 and stuff.

00:08:08 Yeah.

00:08:08 And I think the thing that I started to appreciate about the job a few months in is you have a

00:08:13 platform with this job and that means you can choose to promote the message that you want.

00:08:18 And a message that no surprise is very meaningful for me is data science is for everyone.

00:08:24 Like I hate the gatekeeping that can happen in tech communities.

00:08:28 I think it's quite bad in terms of like people being intimidated by math in data science.

00:08:33 And like, I'm here to say to you, if you want it, it's for you.

00:08:37 It is a very cool field and yeah, it doesn't matter what background you come from.

00:08:41 I absolutely agree.

00:08:42 And I was kind of hinting at that saying like a lot of people who don't see themselves as

00:08:46 developers or programmers, like still find really great places, really great fits in data

00:08:51 science and in programming as well.

00:08:53 And I also want to second that I don't think you really need that much math.

00:08:57 Maybe if you're trying to build the next machine learning model platform, then yes.

00:09:03 Okay.

00:09:03 But that's not what most people do.

00:09:05 They take the data, they clean it up.

00:09:07 They do interesting visualizations and maybe put it into some framework for production.

00:09:11 Right?

00:09:11 Yeah.

00:09:12 And the nice thing is the field is in such a point where you have so many frameworks or

00:09:17 tools that will handle a lot of this stuff for you.

00:09:20 Like I'm not saying you don't need any understanding of what's going on under the hood, but you can

00:09:24 learn it incrementally.

00:09:26 A lot of it is like with software development where you develop that smell or that instinct

00:09:30 for when something is not right.

00:09:32 That will benefit you more than, you know, knowing how backpropagation works from a calculus

00:09:38 perspective.

00:09:39 Like that stuff is maybe a bit too much.

00:09:41 You don't necessarily need it.

00:09:42 Yeah.

00:09:43 Let's get into the main topic and talk a little bit about how does programming and Python differ

00:09:48 on the data science side than say me as somebody who builds web apps.

00:09:52 Yeah.

00:09:53 And maybe we can start by doing an orientation to like, what does a data scientist do?

00:09:57 Because I think this confuses a lot of people.

00:09:59 Yeah.

00:09:59 Yeah.

00:10:00 So basically the role of a data scientist is to sort of like, like the reason you would

00:10:06 hire a data scientist is you have a bunch of data and you have an instinct that you can

00:10:11 use that data to either improve your internal processes or sell some sort of IP.

00:10:17 So the reason, you know, we differ from BI analysts is BI analysts are doing analysis, but it's

00:10:24 more about business as usual, which is really important.

00:10:27 You absolutely need BI analysts.

00:10:29 How are sales going?

00:10:30 How much have we made versus last year?

00:10:32 Like those kinds of charts, right?

00:10:34 Like absolutely fundamental questions.

00:10:36 So you need to be a analyst before you need a data scientist, but your data scientists are

00:10:40 more there to push the envelope in a data driven way.

00:10:44 So we have two main outputs.

00:10:47 I would say you can either create an analysis and do a report, or you can build some sort of

00:10:53 model that will go into production.

00:10:54 So an example might be as a business, I have an instinct that I can get my customers to buy

00:11:01 more things based on people like them also buying those things.

00:11:05 So in that case, your data scientists might be able to build you a recommendation engine

00:11:10 and this, you know, will have a business outcome.

00:11:13 Developers obviously, on the other hand, have a very different goal.

00:11:16 Their goal is to create robust software systems.

00:11:20 So the concerns that they have are things like latency, server load, downtime, things like that.

00:11:27 And it's very interesting.

00:11:29 And we'll talk about it a bit more when we talk about code, if we kind of get into that

00:11:32 topic, but basically data scientists are not really interested in creating code for the

00:11:38 long term.

00:11:38 Whereas the code becomes the product that software developers write often.

00:11:43 And you have to think about things like legacy systems, because eventually every Greenfield

00:11:48 project becomes a legacy system if it lasts for long enough.

00:11:51 Yeah.

00:11:51 If you're lucky, right?

00:11:52 Because the alternative is it never really got used or it didn't add that much value and

00:11:56 got discarded, shut down.

00:11:58 All right.

00:11:59 So even though people talk about how much they don't want legacy code or how they kind

00:12:03 of, you know, don't necessarily want to work on it because they want to work on something

00:12:07 new and shiny.

00:12:08 That's kind of the success side of software development, right?

00:12:12 Yeah, exactly.

00:12:13 I do think it's super interesting to different life cycle of code on the data science side,

00:12:20 because you might be just looking to explore a concept or understand an idea better and not

00:12:26 necessarily ever intend to put it into production in the traditional software sense, right?

00:12:32 So I've seen some pretty interesting code written that people would look at and go, oh my goodness,

00:12:40 what is there's not even a function here?

00:12:43 How is this possible?

00:12:44 You know, it's like copy and paste, reuse almost.

00:12:46 And yet it really does go from having no idea to pictures and understanding and then maybe

00:12:54 handing that off potentially to be written more robustly or better.

00:12:58 Exactly.

00:12:59 And it's really interesting.

00:13:01 Like they're kind of two very different processes.

00:13:04 And that point actually where engineering and research meets is a very, very interesting one.

00:13:11 And I've seen it work in multiple different ways in multiple different workplaces.

00:13:14 So for example, I've worked in places where the data scientists were completely sequestered

00:13:20 away from the engineers.

00:13:21 And there really wouldn't be that much discussion between the engineers and the data scientists

00:13:25 during the research phase, which I do not advise.

00:13:29 So what that means is the data scientists will come at the end and hand over this chunk of

00:13:33 perhaps very difficult to read code to an engineer and be like, hey, so we need to implement

00:13:39 this.

00:13:40 And the engineer is like, what is this?

00:13:41 Okay.

00:13:42 I will schedule that for the next six months.

00:13:44 And then I've seen, you know, or I've been a data scientist embedded within a software

00:13:50 development team.

00:13:51 And in that case, your project is marching in lockstep with what the engineers are doing.

00:13:56 And from the very start, you know, you've been discussing important things like you need

00:14:00 to build a model that has latency constraints.

00:14:02 You need to think about this as the data scientist in terms of like the model that you run,

00:14:07 but also how it's implemented.

00:14:09 Right.

00:14:09 How much memory does it use?

00:14:10 Because if you run it on your own machine by yourself, then, well, it's kind of the limit

00:14:14 of your computer sort of sometimes.

00:14:15 But if you're running a thousand of them concurrently because people are interacting at the website,

00:14:20 all of a sudden that might make a difference.

00:14:22 Exactly.

00:14:23 Or like one of the most interesting problems I think I ever solved in my career was basically

00:14:28 I was working at a job board.

00:14:29 We're trying to improve the search using natural language processing.

00:14:34 So we had this idea that we could build a model that found out the probabilistic relations between

00:14:40 skills and job titles.

00:14:41 So if someone typed a skill into the search, we could expand it with job titles and then

00:14:46 find all of the jobs that we indexed with that at search time and vice versa with job titles

00:14:51 and skills.

00:14:51 The thing is we need to find those relations at search time.

00:14:55 Like that is a very low latency system.

00:14:57 And it was super interesting because we had to think about how we could search that vector

00:15:02 space in really, really like quickly.

00:15:05 Like instead of having to calculate the distance between that and every single vector, we had

00:15:10 to work out how to do that more efficiently.

00:15:12 That sort of stuff I really like because it's so applied and it's so like it's this really

00:15:17 nice intersection between computer science and data science.

00:15:20 I think it's super cool.

00:15:21 That is neat.

00:15:22 One of the things I really like about working with programming broadly is how concrete it is,

00:15:28 right?

00:15:28 You came from academics.

00:15:30 You know, I was in grad school for a while as well.

00:15:33 And it's, you could debate on and on about a certain idea or concept.

00:15:37 And it's like, well, you might be right.

00:15:39 Or I'm here and you push a button and you get the answer or it runs or like, there's a really

00:15:44 nice feedback of like, I built this thing and it's look, it's really connecting these people.

00:15:49 And, you know, then it comes down to, can you do it in real time and other things like

00:15:54 that.

00:15:54 But that's a really cool aspect of programming.

00:15:57 This portion of Talk Python to Me is brought to you by JetBrains and PyCharm.

00:16:04 Are you a data scientist or a web developer looking to take your projects to the next level?

00:16:09 Well, I have the perfect tool for you, PyCharm.

00:16:11 PyCharm is a powerful integrated development environment that empowers developers and data

00:16:17 scientists like us to write clean and efficient code with ease.

00:16:21 Whether you're analyzing complex data sets or building dynamic web applications, PyCharm has

00:16:26 got you covered.

00:16:27 With its intuitive interface and robust features, you can boost your productivity and bring your

00:16:32 ideas to life faster than ever before.

00:16:34 For data scientists, PyCharm offers seamless integration with popular libraries like NumPy,

00:16:39 Pandas, and Matplotlib.

00:16:40 You can explore, visualize, and manipulate data effortlessly, unlocking valuable insights with

00:16:46 just a few lines of code.

00:16:48 And for us web developers, PyCharm provides a rich set of tools to streamline your workflow.

00:16:52 From intelligent code completion to advanced debugging capabilities, PyCharm helps you write clean, scalable

00:16:58 code that powers stunning web applications.

00:17:01 Plus, PyCharm's support for popular frameworks like Django, FastAPI, and React make it a breeze to build and deploy your web projects.

00:17:10 It's time to say goodbye to tedious configuration and hello to rapid development.

00:17:14 But wait, there's more.

00:17:16 With PyCharm, you get even more advanced features like remote development, database integration, and version control, ensuring your projects stay organized and secure.

00:17:25 So whether you're diving into data science or shaping the future of the web, PyCharm is your go-to tool.

00:17:30 Join me and try PyCharm today.

00:17:32 Just visit talkpython.fm/done-with-pycharm, links in your show notes, and experience the power of PyCharm firsthand for three months free.

00:17:43 PyCharm.

00:17:44 It's how I get work done.

00:17:49 I think it's kind of a shame that a lot of places do set up their engineering and data science teams so separately.

00:17:56 Sure, we have quite different roles and we have quite different backgrounds sometimes.

00:18:01 But I really think that having the two teams at least planning things together, you can really actually learn a lot from each other about how to approach problems.

00:18:10 When you were describing either having those groups really separated or working really closely together, maybe an analogous relationship that people could relate with is maybe front-end developers and people building the APIs and the back-end, right?

00:18:25 Like the people doing React or Angular or Vue or whatever it is, you know, and the web design.

00:18:32 Having those completely separated as well is also, you know, it's terrible.

00:18:36 Not a good idea.

00:18:36 It doesn't make any sense.

00:18:38 And like, I can totally understand it from the point of view of like team composition, because it is, I think, better to have all your data scientists together because they can learn from each other.

00:18:47 But then I think having, I don't want to use the squad term because I know it's become a little bit unpopular to use it.

00:18:52 But, you know, this idea of project-oriented teams, I think are quite important.

00:18:56 Let's dive a little bit more into the research side of things that I want to ask you about.

00:19:00 Why Python?

00:19:02 Let's talk about how the research process works and maybe why that results in different priorities and styles of code and styles of engineering.

00:19:10 It starts at a similar point to all software projects, which is business comes to you and they have some sort of goal.

00:19:17 Sometimes it's very vague and you need to interpret that and turn it into an executable project.

00:19:23 But where the sort of uncertainty starts and like where it sort of becomes a research project rather than a project.

00:19:31 And I don't know if I described that very well, but where it becomes research versus something you're building concretely is even know at the start of a research project, whether it's even possible to answer the question that you're being asked or build the internal product that you're being asked for.

00:19:46 You might not understand the domain entirely, right?

00:19:48 You're trying to gain understanding even.

00:19:50 In the very worst cases, you won't even know if you have the data because maybe your company has so much data and it's so poorly organized.

00:19:56 Again, something I've seen that you don't even know if the data exists to answer this question.

00:20:01 So first is going and getting your data.

00:20:04 And you spend quite a lot of time with the data because the data will be the one that tells you the story.

00:20:09 It'll tell you whether what you even want is possible.

00:20:12 And you probably like heard data scientists hammering on about, you know, garbage in, garbage out.

00:20:18 Like you can build the most beautiful, sophisticated model you want.

00:20:21 But if you have crap data where there's no signal, you're not going to get anything because it's just not there.

00:20:27 Like the relationship you're looking for is not there.

00:20:30 Yeah.

00:20:30 The side of that I've heard is 80% of the work is actually the data cleanup, data wrinkling, data gathering before you just magically hit it with a plot or something, right?

00:20:41 Absolutely.

00:20:42 And it's interesting because that data cleaning, data wrangling step also doesn't happen in one go, especially if you're building a model.

00:20:48 So what will happen is you'll try something out and you'll be like, okay, it didn't quite work.

00:20:52 Maybe I need to manipulate the data in a different way or I need to create this new variable.

00:20:56 And then you'll go again.

00:20:58 And it's this super iterative process where you have this tightly coupled relationship between both the models and the data.

00:21:06 So it really is sort of, you know, how I was talking about the instinct.

00:21:09 This is sort of where that comes in because you're going to spend like 80% of your time honing your skills.

00:21:14 But it's the most, I think, valuable part of the process.

00:21:17 And if the signal's there, you can usually get away with using really dumb and simple models.

00:21:23 You know, things that are unfashionable now like decision trees or linear regression.

00:21:28 You can get away with them because you've just got such good data that just go with a simpler model.

00:21:33 It's got all the advantages.

00:21:35 This is sort of, I think, what makes it different that you're sort of moving towards a goal, but you don't know what that goal is.

00:21:42 Estimation's always hard, right?

00:21:44 What I found is best is really just time boxing each step, seeing if you are up to where you thought you'd be up to by a certain point.

00:21:51 And if not, you need to just keep having those discussions with the business stakeholders because otherwise they're going to not be very happy if you've spent six months just looking at something and you have nothing.

00:22:02 Or what have you built?

00:22:03 Well, I have some notebooks I could show you.

00:22:06 I have 40,000 notebooks and they're all terrible.

00:22:09 Yeah.

00:22:11 Speaking of the data, Diego out in the audience has an interesting question.

00:22:15 How big are the data sets businesses will bring to you typically?

00:22:17 Enough that you don't need to go out and find more data.

00:22:20 This is a good question.

00:22:21 So I hate to be, it depends, you know.

00:22:25 I get to say that though because, you know, I was a lead data scientist, so I earned that rank.

00:22:31 It really does depend on the problem you need to solve.

00:22:33 So typically business will have enough data to cover at least some of the use cases.

00:22:40 So to give you a really concrete example, this job board that I was talking about that I worked at, we actually had like a bunch of different job boards across Europe.

00:22:49 So we had some that were a lot bigger like Germany or the UK.

00:22:53 And we had some that were really small like Poland or Spain.

00:22:56 And we wanted to build these multi-language models or models maybe for different languages.

00:23:02 We played around with both.

00:23:03 And I don't think we really had enough data to support the models in these smaller languages.

00:23:09 So the models were just not as good quality because we didn't have enough data.

00:23:12 But for the bigger languages, we did.

00:23:14 And then it sort of becomes a case of, okay, well, we have more data for these particular websites because they're the ones that are bringing the most revenue.

00:23:22 So then it sort of became like, well, okay, maybe it's good enough that we improve the search on the most important ones.

00:23:27 And for the smaller ones, we just wait until we accumulate more data.

00:23:31 So yeah, most of the time I found that there's a way to make it work for at least part of the solution.

00:23:37 And then sometimes, like in the case of my last job, we had something like 170 billion auctions per day.

00:23:44 So we had so much data.

00:23:48 We even had problems like processing it.

00:23:50 So sometimes, you know.

00:23:52 That's the other side of the story is when you've got too much and then how do you throw it away, right?

00:23:56 I mean, you've got this auction story, like another one that comes to mind is the Large Hadron Collider.

00:24:02 Oh, yes, yes.

00:24:04 They've got layers and layers of like chips on hardware and then chips or machines right next to the collectors and then on it, where it's all about how do we throw away, you know, terabytes of data down to get it to megabytes per second, right?

00:24:18 Yeah, and it's interesting because what you can end up in this within those situations is even then you can have underrepresented groups.

00:24:26 So, for example, we had, we're working with advertisers and apps, you know, basically trading ads.

00:24:31 And we ended up with some apps that were just so small that you were like, even with all this data, I really don't have enough to represent this particular combination in this country.

00:24:42 Interesting.

00:24:43 Very interesting.

00:24:44 So, why Python?

00:24:46 You know, you started out in R and, of course, any distraction from writing a PhD is a good distraction.

00:24:53 But I do think there's been a really interesting sort of graph.

00:24:57 Like, if people go and look at, what is it, Stack Overflow Insights.

00:25:02 If you go look at Stack Overflow Insights, they had a really great graph that shows you the popularity of Python over time.

00:25:12 And there's just this huge inflection point around 2012.

00:25:15 And I feel like that's when a lot of the data science libraries really came around and took off.

00:25:21 It seems like there was a big inflection at one point, but, you know, why?

00:25:25 To be honest, I can talk about why I like Python from my background.

00:25:31 I couldn't really tell you exactly what caused that takeoff.

00:25:34 But, you know, apart from, you know, this idea that the libraries were maturing enough.

00:25:38 But the thing is, looking even at current surveys, around 60% of data scientists do not have a software development or a software engineering background.

00:25:47 So, for people like us, we don't really understand, like, it sounds terrible.

00:25:52 We don't really understand basic constructs in how a programming language works.

00:25:56 And that can actually mean that going to some sort of compiled language even can be quite a steep learning curve.

00:26:03 Sure.

00:26:03 Pointers to pointers, for example.

00:26:05 Like, oh, no things.

00:26:07 Yeah.

00:26:08 Or having to deal with the fact that in Java, everything is a class.

00:26:12 You're just like, what is this?

00:26:15 But of course, you understand why if you have that background.

00:26:18 But if you're trying to learn it yourself, you then have a lot of background you need to cover.

00:26:22 But in Python and in R as well, you don't need to cover those things.

00:26:26 It's super easy to prototype.

00:26:28 It's super easy to script.

00:26:29 The flexibility of Python is what makes it, I think, the perfect prototyping language.

00:26:34 And that's essentially what you're doing.

00:26:36 You're prototyping.

00:26:36 So, we talked a little bit earlier about, like, why not just Excel?

00:26:41 We didn't quite say that.

00:26:42 But this was sort of what we were maybe getting at.

00:26:45 And, yeah, we could do some of our work in Excel.

00:26:48 I've tried this.

00:26:49 And first, I can tell you Excel really starts to struggle when you have too many calculations going on under the hood.

00:26:56 It gets very, very slow.

00:26:58 But to be honest, it's sort of just cleaner to code this sort of logic.

00:27:02 It's much more reproducible when you need to do this iterative sort of stuff.

00:27:06 And it also means that you can use much more powerful tools.

00:27:10 So, you can, say, use APIs that developers have made to process your data.

00:27:16 You can use powerful data.

00:27:18 Right?

00:27:18 Like, I need live currency conversion data.

00:27:21 Right?

00:27:22 So much easier than in Excel.

00:27:24 Yes, yes, yes, exactly.

00:27:25 Like, you can, like, scrape data.

00:27:27 Or you can, yeah, pull data in off an API.

00:27:30 Or you can use powerful tools like Spark to process 170 billion auctions per day in order to reduce it down to something manageable.

00:27:41 So, yeah, it just gives you a lot more power.

00:27:42 But at the same time, why we use programming languages is just such a different focus.

00:27:50 It's a bit overkill to use something like Java.

00:27:52 I know some people do do natural language processing in Java.

00:27:54 But that's more on the engineering side to build maintainable systems.

00:27:58 One of the things I like to say when thinking about how people who are coming from a tangential interest like biology or whatever is you can be really effective with Python.

00:28:08 And I suspect R as well with a really partial understanding of what Python is and what it does.

00:28:14 Right?

00:28:14 Like you pointed out, you don't even have to know what a class is or even really how to create a function.

00:28:19 You just, I can put these six magical incantations in a file and then I can do way more than I otherwise could.

00:28:26 Right?

00:28:27 Then you learn one more.

00:28:28 You make it better and better as you kind of gain experience.

00:28:30 Pretty much.

00:28:31 And this is where I started.

00:28:31 Like, obviously, I learned what functions and classes were when I first started programming.

00:28:36 But in the end, you will just, maybe it's not the best thing.

00:28:40 And we can sort of maybe get into this.

00:28:42 I suppose part of the confusion or not confusion, but internal debate I've had over the years is how good does data science code really need to be?

00:28:50 Like, how much would data scientists benefit from knowing more about computer science topics?

00:28:56 Or software engineering topics maybe more to the point?

00:28:59 And, you know, because like the thing is, every field has so much to learn.

00:29:03 Don't even get started on what's happening with large language models at the moment.

00:29:06 Like, it's just overwhelming.

00:29:07 Should we take some of our precious time and learn software engineering concepts?

00:29:12 I'm not sure.

00:29:12 Like, I'm not sure if I have the answer to that.

00:29:16 This portion of Talk Python Army is brought to you by Prodigy, a data annotation tool from Explosion AI.

00:29:22 Prodigy is created by Ines Montani and her team at Explosion.

00:29:26 And she's been doing machine learning and NLP for a long time.

00:29:30 Ines is a friend and frequent guest on the show.

00:29:32 And if you've listened to any of her episodes, you know that she knows her ML tools.

00:29:37 So what is Prodigy?

00:29:38 It's a modern, scriptable annotation tool for machine learning developers made by the team behind the popular NLP library, Spacey.

00:29:46 You can easily and visually annotate and develop data for named entity recognition, text classification, span, categorization, computer vision, audio, video, and more,

00:29:57 and put your model in the loop for even faster results.

00:30:00 After collecting data, you can quickly train and export a custom Spacey model or download annotations to use it with any other library or framework.

00:30:09 Prodigy is entirely scriptable in Python, of course, the language we all love.

00:30:13 And it seamlessly integrates with your favorite libraries and tools.

00:30:16 Plus, the new alpha version they just released also introduces a built-in support for large language models,

00:30:23 such as OpenAI's GPT models, and new tools for dividing up your data between multiple annotators.

00:30:29 Talk Python listeners get a massive discount on a lifetime license.

00:30:33 You'll get 25% off using the discount code Talk Python, but don't wait too long.

00:30:38 This offer does expire.

00:30:40 Get Prodigy at talkpython.fm/Prodigy and use our code Talk Python, all caps, to save 25% off a personal license.

00:30:49 This link is in your podcast player show notes.

00:30:52 Thank you to Explosion AI for sponsoring the show.

00:30:55 I think it really depends on what kind of data scientist you are.

00:31:02 If what you are is someone doing research, as you described before, and you're like, is there a trend between the type of device that they use to buy their thing at our store

00:31:13 and how much they're buying on the second, you know, how much are likely to come back?

00:31:17 Like, if they're using an iPhone, do they tend to spend more than if they're using an Android?

00:31:22 And is that a thing that we should consider?

00:31:24 Or, you know, is there any, like that kind of exploration, which you can judge whether or not you should make that exploration.

00:31:31 But just put that aside for a minute.

00:31:33 That kind of stuff, like once you know that answer, maybe you don't need to run that code again.

00:31:38 Maybe you don't care.

00:31:38 You just want to kind of discover if there is a trend.

00:31:41 And there, maybe you need to know software engineering techniques, but should you be writing unit tests for that?

00:31:46 I'd say maybe not, honestly.

00:31:48 On the other hand, if your job is to create a model that's going to go into production, that's going to run behind a Flask or FastAPI endpoint,

00:31:56 then you're kind of in the realm of continuously running for many people over a long time.

00:32:02 And I think that really is a different situation.

00:32:04 I think this is where you actually move from data science to machine learning engineering.

00:32:08 This term has a lot of different definitions.

00:32:11 For me, I base my definition of ML engineers on the two people that I've worked with,

00:32:15 who were like true full stack kind of people who could go from research and prototyping to deployment.

00:32:23 And they were data scientists who really cared enough to actually learn how to do proper engineering,

00:32:30 and they could actually deploy their own things.

00:32:32 But then this leads to another one of my very favorite topics, which is who is responsible for apps in production?

00:32:39 And here's the thing.

00:32:41 So I think as good as your data scientist is going to be, or your ML engineer, let's say an ML engineer,

00:32:47 let's say that they can actually deploy their own code.

00:32:49 If they're then responsible for that code in production, that then eats up the time that they can be prototyping

00:32:56 and researching new things for you.

00:32:58 So the conclusion I've come to over time, and again, this is a matter of a debate.

00:33:02 This is just my opinion.

00:33:04 Basically, I think if your company is above any sort of level of size or complexity,

00:33:09 in terms of the data products it has, I think you really do need dedicated data science and engineering teams.

00:33:16 Because in the end, no matter how good your data scientist code is going to be,

00:33:20 it needs to be implemented by the person who's going to maintain it.

00:33:23 And maybe they're not the ones writing the code from scratch.

00:33:26 Maybe they can adapt the data scientist code if it's good enough.

00:33:29 But in the end, they need to be comfortable and familiar enough with that code to be like,

00:33:33 yeah, if I get pinged at three in the morning, I'm okay knowing what to do with this code.

00:33:38 Yeah, that's a good point.

00:33:40 Yeah.

00:33:40 So I think it's just easier to scale these teams in parallel rather than trying to hire this like

00:33:45 wall in one person who can do everything.

00:33:47 They're impossible to hire.

00:33:48 Like I've only ever met two over the course of my career.

00:33:51 And quickly, they become overwhelmed by having to maintain projects.

00:33:55 Right.

00:33:55 Is that the best use of their time?

00:33:57 Yeah.

00:33:57 And like, it's maybe it's not necessarily even if it's the best use of their time.

00:34:01 It's more like, then who's going to do your research?

00:34:05 Because now you've used up that resource on maintaining two or three projects.

00:34:09 Right.

00:34:10 Absolutely.

00:34:10 Chris May has got an interesting question out here in the audience.

00:34:13 This kind of turns us on its head a little bit.

00:34:15 It says, development teams tend to work better when they focus on writing and refactoring code

00:34:19 to make it testable and understandable.

00:34:21 And we've talked a little bit about maybe stuff that data scientists shouldn't care about

00:34:26 or whatever.

00:34:27 So he has other ideas that are like good practices for data scientists and teams of them.

00:34:33 This is actually a really great question.

00:34:35 So basically, it's an interesting thing with data scientists that unlike software developers,

00:34:40 we often tend to work alone on projects or maybe in very, very small teams, like maybe two

00:34:47 or three people.

00:34:48 And I think it's probably a hangover from the fact a lot of us are ex-academics.

00:34:53 We're just used to having like, it's not great, but it's...

00:34:57 A whiteboard, an office in the corner, and no one knows what you're doing.

00:35:01 Exactly.

00:35:02 And no one cares.

00:35:03 That paper that three people read took me three years.

00:35:07 So what I think has been neglected, you know, aside from learning software engineering best

00:35:13 practices is more fundamental things, which is like writing maintainable code.

00:35:18 And I don't mean maintainable in the sense of it's a system that needs to be able to run

00:35:23 regularly.

00:35:23 It's more like this is a piece of code that I can come back to in six months and understand

00:35:29 what I was doing.

00:35:30 Because, you know, research projects can be shelved forever, but maybe they need to

00:35:34 be revisited and, you know, built upon.

00:35:37 So this was actually a topic I got really interested when I first moved to industry, like this idea

00:35:43 of reproducibility with data science projects.

00:35:45 It's about the code, but it's also about things like dependency management, which is notoriously...

00:35:50 Oh, yes.

00:35:51 ...difficult in Python to get reproducible environments later.

00:35:56 And even the operating system, if Linux is really dramatically changed over time, then

00:36:01 maybe your old dependency, you want to keep that one, but it won't run on the new operating

00:36:07 system or there's a whole spectrum of challenges there.

00:36:09 Exactly.

00:36:10 Exactly.

00:36:11 And it's sort of something that can be solved with using poetry, which is a little bit more

00:36:16 robust.

00:36:17 But even then, you've still got it.

00:36:19 Like it runs on my machine effect where your machine will not be the same machine.

00:36:24 Recently, there's actually a move towards doing more sort of cloud-based stuff for data

00:36:28 science, which solves a few of these problems.

00:36:31 And it also solves the additional problem where data scientists often need to do remote development

00:36:35 for various reasons.

00:36:36 Like you need access to GPUs in order to train models.

00:36:39 So, you know, obviously if you have a server, you have a Docker container, which has, you know,

00:36:45 environment specifications, you can power up that exact same environment.

00:36:48 And that actually helps with that reproducibility a lot.

00:36:51 And then another point, which I think is really important for data scientists and can be neglected

00:36:57 is literate programming.

00:36:58 So this is an idea from Donald Knuth.

00:37:00 And it's this idea that, you know, you should write your code in such a way that it's actually

00:37:06 understandable later.

00:37:07 With data science work, it's also that you really need to document a lot of the implicit kind of

00:37:14 assumptions that you make or decisions that you make as part of the research process.

00:37:18 And this is one of the reasons, probably a good segue, why Jupyter is so important.

00:37:23 Yeah.

00:37:23 Jupyter notebooks are designed to be research documents.

00:37:26 So this is why you have the markdown cells if you've seen a Jupyter notebook, because it's

00:37:31 this idea that you really, really need to like document along with the code, the decisions

00:37:36 that you made.

00:37:36 Like, why did you choose this sample?

00:37:38 Why did you decide to create the inputs to your models the way that you did it?

00:37:43 You need to document all this stuff.

00:37:44 So yeah, reproducibility is a super interesting topic.

00:37:47 And I think it's, yeah, something that really needs to be thought about carefully, even if

00:37:53 you're not collaborating with anyone else, because otherwise your piece of research is going to

00:37:57 be worthless in three months because you're not going to remember what you did.

00:37:59 I think notebooks are quite interesting.

00:38:01 They go a long ways to solving that.

00:38:02 When used in the right way, you can just jam a bunch of non-understandable stuff in there.

00:38:07 And it's just, well, now it's not understandable, but it's in a web page instead of in an editor.

00:38:11 But I think as in, you know, not just programmers, but tech in general, we're just bad at thinking

00:38:18 about the long-term life cycle of information and compute.

00:38:24 For example, I got a new heat pump to replace the furnace at my house.

00:38:29 The manual for it came on a CD drive.

00:38:31 And I'm like, I don't think I have a CD.

00:38:33 Where did I put that?

00:38:34 I went to go dig through closet full of electronics.

00:38:37 I'm not sure I can read that, right?

00:38:39 And, you know, CD seems so ubiquitous for so long, right?

00:38:43 And just simple little mismatches like that just get worse over time.

00:38:48 It's going to be tough to keep some of this older research and reproducibility around.

00:38:53 Yeah.

00:38:54 Like it's super interesting that there are packages I used to use, you know, back when I first

00:38:59 started in natural language processing.

00:39:01 Some of them haven't been updated from Python 2.

00:39:03 So I can't use them anymore because they were just some, probably like a PhD project and

00:39:08 no one really had the time or energy to maintain it after that person graduated.

00:39:12 And the person graduated, got a job and doesn't really care that much anymore, potentially.

00:39:16 Exactly.

00:39:16 Not enough to keep it going.

00:39:17 Yeah.

00:39:18 It's not even necessarily their fault.

00:39:19 It's just life.

00:39:20 Yeah.

00:39:21 Let's talk about some of the libraries and tools.

00:39:24 You mentioned Jupyter.

00:39:25 I think Jupyter is one of the absolute cornerstones, right?

00:39:29 So Jupyter or JupyterLab, what are your thoughts here?

00:39:33 It's funny, actually, for years, I was just working in Jupyter, playing Jupyter on my computer.

00:39:38 Maybe give people a quick summary of the differences so who don't know.

00:39:42 Very good idea.

00:39:43 So basically, Jupyter is, I suppose you could call it an editor.

00:39:46 It's basically an interactive document, which you run against a Python kernel, or you can

00:39:52 run it against different language kernels.

00:39:53 There are R, there are Julia, there are Kotlin notebooks.

00:39:56 Should I give my little advertisement for JetBrains?

00:39:58 Basically, what you can do is you can run code in cell blocks.

00:40:02 Then you can also create markdown cells in between them.

00:40:05 And this allows you to basically have, you know, markdown chunks and then cell chunks.

00:40:10 JupyterLab is hosted remotely.

00:40:13 So you have basically a bunch of other functionality built in.

00:40:16 So you can open terminals, you can create scripts, things like that.

00:40:20 But basically, it's like a little Jupyter ecosystem, which is designed to be remotely hosted.

00:40:25 And it can be accessed simultaneously by several people.

00:40:28 So I would say Jupyter is good if you are just starting out and you're dealing with small

00:40:35 data sets.

00:40:36 Maybe you're even retrieving things from databases, but you're not saving anything too heavy locally.

00:40:42 You're not using a huge amount of memory, like maybe unless you got one of those new M2 Macs

00:40:46 and server in your office.

00:40:48 So go for it.

00:40:49 Exactly.

00:40:49 Yeah.

00:40:50 JupyterLab, I think, is good if basically you need to access different types of machines.

00:40:56 So maybe you need to be able to access GPU machines easily.

00:40:59 You kind of want that remote first experience where you don't have to then connect to a remote

00:41:03 machine.

00:41:04 And I have found JupyterLab helpful in the past for sharing.

00:41:07 But the thing you can't do with JupyterLab is real-time collaboration.

00:41:10 And that's a bit of a pain in the butt.

00:41:12 Obviously, since I started at JetBrains, I've kind of, you know, like I'm using our tools

00:41:17 and I like them a lot.

00:41:18 Obviously, I wouldn't advocate them.

00:41:20 Yeah.

00:41:20 I was going to ask, is this PyCharm, Dataspel, like when you actually do that, are you using

00:41:25 some of those type of tools?

00:41:26 I am.

00:41:27 So I won't turn this into too much of an advertisement for our tools because it's not

00:41:31 really the point of me being here.

00:41:32 But we've kind of tried or my teams have tried to solve some of these problems that you might

00:41:39 have with just using plain Jupyter Notebooks or even working with JupyterLab, maybe a bit

00:41:43 more like robustly.

00:41:46 So we have actually three data science projects, products.

00:41:49 We have PyCharm and Dataspel, which you've mentioned.

00:41:52 They're desktop IDEs with the ability to connect to remote machines, but they're not really

00:41:57 collaborative, but they do give you like really like nice experience with using Jupyter, debugging

00:42:02 and co-completion and all those sort of things.

00:42:05 We have another one, which is DataLaw.

00:42:07 And this falls into those managed notebooks that I was talking about.

00:42:10 It's cloud hosted.

00:42:11 And the nice thing about DataLaw actually is you can do real-time collaboration.

00:42:16 So it sort of helps overcome-

00:42:18 Google Docs style, sort of.

00:42:18 Yes, it's the same technology actually.

00:42:20 So yeah, so it's kind of a very interesting thing because there will be times where, you

00:42:27 know, maybe you're not working on a project with a data scientist, but you need them to

00:42:31 have a look at your work.

00:42:32 And when I was working with JupyterLab, what we would do is we would clone the notebook to

00:42:37 our own folder and then we were in the same environment.

00:42:40 So it was okay.

00:42:41 But then you would rerun the whole thing again.

00:42:43 And sometimes it would be pretty time consuming.

00:42:46 DataLaw is an alternative to that.

00:42:47 It may or may not be kind of your style, but it's pretty cool because you can actually

00:42:53 just invite someone to the same notebook instance that you're in and you're basically hosting

00:42:58 them and they have access to everything that you've already run.

00:43:01 So it's like true kind of real time.

00:43:04 Yeah, that's nice.

00:43:04 Because sometimes a cell has to run for 30 minutes, but then it has this nice little answer

00:43:09 and you can work with that afterwards, right?

00:43:11 Exactly.

00:43:11 Or you want a model to be available and maybe you haven't saved it or something like this

00:43:17 is just a way around some of these friction points.

00:43:19 I want to circle back just really quickly for a sort of testimonial, I guess, out in the

00:43:23 audience.

00:43:24 Michael says, I started teaching basic Git, Docker and Python packaging to bioinformatics

00:43:29 students at UCLA.

00:43:31 And it's made a huge difference in the handoff.

00:43:33 But I think for actual projects, you know, I just think as we were talking about what should

00:43:38 people learn as data science and what they shouldn't.

00:43:40 Yeah.

00:43:40 A little bit of the fluency with some of these tools is really helpful.

00:43:44 I absolutely agree.

00:43:45 Like I know it can be really overwhelming, especially Git initially for students.

00:43:50 Git is overwhelming.

00:43:51 Yeah.

00:43:52 At first.

00:43:52 I would say I'm because I tend to work on things by myself.

00:43:57 Yeah, yeah.

00:43:57 This sort of falls into the reproducibility stuff that I was talking about earlier.

00:44:02 And it's super, super important.

00:44:04 Like and once you get comfortable with like just basic use of these tools, you can get really

00:44:08 far.

00:44:09 Okay.

00:44:09 Back to some of the tools, Jupyter, JupyterLab.

00:44:12 What about JupyterLite?

00:44:14 Have you played with JupyterLite any?

00:44:16 Only a teeny tiny bit because of this workshop that I'm going to be helping out with at Europython.

00:44:21 So they're going to be running the whole thing in JupyterLite, hopefully.

00:44:24 A couple of bugs to solve, but I think they're overcomable.

00:44:27 But yeah, it's a really interesting alternative to Google Colab, actually.

00:44:33 Yeah.

00:44:33 JupyterLite, take Pyodide, which is CPython running a WebAssembly, and then build a bunch

00:44:40 of the data science libraries like Matplotlib and stuff in web WebAssembly.

00:44:44 And then the benefit is you don't need a complex server to handle the compute and run arbitrary

00:44:50 Python code, which is a little sketchy.

00:44:52 You just run it on the front end in WebAssembly, which is pretty cool.

00:44:55 I interviewed the folks at PySport a little while ago.

00:44:58 And it's just the ability to just take code and run all these different pieces on your front end without worrying about a server, I think is super cool.

00:45:08 If I get that right or not.

00:45:09 But anyway, just I think running it on top of people using it on top of the browsers like you do JavaScript is it's an interesting thing to throw into the mix for notebooks.

00:45:20 Actually, a lot of these projects coming out using Pyodide are really interesting.

00:45:24 Obviously, PyScript is the big one from last year.

00:45:26 Yeah, I think PyScript actually has really lots of interesting possibilities beyond just the data science side, right?

00:45:33 Whereas Pyodide is a little more focused on just, I think, really providing the data science tools on the client side.

00:45:39 We'll see where PyScript goes.

00:45:41 If they can make an equivalent of Vue.js or something like that, where people can start building legitimate front end interactive web apps like Airbnb or Google Maps or something.

00:45:52 But with Python, that's going to unlock something that has been locked away for a really long time.

00:45:57 With Pyodide, that's like a nine or 10 meg download.

00:46:01 That's too much for the front end, just for like a public facing site generally at the start of time.

00:46:06 But they're moving it to MicroPython as an option.

00:46:09 And that's a couple hundred K, which is like these other front end frameworks.

00:46:12 So it's very exciting.

00:46:13 I think that's going to be that's definitely the most exciting thing in that area.

00:46:17 But all right, back to data science.

00:46:18 Let's see.

00:46:19 Where do you want to go next?

00:46:20 You want to talk Pandas maybe?

00:46:21 Yeah, let's jump into Pandas, which is the other biggie when you're talking about data science.

00:46:26 So what Pandas is really important for is it's basically the entry point of you working with your data.

00:46:32 So it's a library, which basically allows you to work with data frames.

00:46:37 Data frames are basically tables.

00:46:39 And from there, you can do data manipulation.

00:46:41 You can explore your data and visualize it.

00:46:44 And it also is an entry point to passing your data into models.

00:46:49 Sometimes it'll need additional transformations.

00:46:51 But say scikit-learn, which we can talk about in a sec, you can basically pass Pandas data frames directly into scikit-learn models.

00:46:59 Pandas also, because of its popularity, has kind of opened up this easy access to like grid computing and other types of processing database stuff that you don't really need to learn those tools, but you get to take advantage of.

00:47:14 And so two things that come to mind for me are Dask.

00:47:16 Yes.

00:47:16 It's kind of like a Pandas code, but instead you can actually run this across this cluster of machines or larger than memory or stuff on my personal computer or even just take advantage of all 10 cores on my M2 instead of the one.

00:47:34 Yes.

00:47:35 Have you done anything with Dask?

00:47:36 Are you a fan of it?

00:47:37 I was kind of there when Dask was new and let's just say they find out a lot of the bugs.

00:47:42 Yeah.

00:47:43 So what ended up happening was I ended up learning PySpark instead.

00:47:46 So I went down a different kind of route, but I think, you know, they solve very similar problems.

00:47:52 It's just Dask is much more similar to Pandas.

00:47:55 And so you don't really need to deal with learning.

00:47:57 It's similar, but it's a new API.

00:48:00 Yeah.

00:48:00 Another one that I was thinking of, I just had these guys on the show sort of is Ponder.

00:48:05 Oh, I have not heard of this.

00:48:07 So Ponder, they were at startup row at PyCon and they basically built on top of Moden, which is important, Moden.pandas as PD.

00:48:16 And what it does is it, instead of pulling all the data back and executing the commands on your machine in memory, which maybe that data transfer is huge.

00:48:23 It actually runs it inside of Postgres and other data.

00:48:26 And I think PySpark as well.

00:48:28 Like it translates all these Pandas commands to SQL commands to run inside the database where the data is, which is also a pretty interesting thing.

00:48:37 That is amazing.

00:48:38 So, yeah, it's just interpreting the code in a completely different way.

00:48:41 You can do like query planning and optimize the code.

00:48:44 Yeah, exactly.

00:48:44 They said that df.describe is like 300 lines of SQL.

00:48:50 It's really, really tough.

00:48:51 But once this thing writes it, then it's good to go.

00:48:53 And I think the reason I bring this up is like you don't have to write that code.

00:48:56 You just have to know Pandas.

00:48:58 And then all of a sudden there's these libraries that will do either grid computing or really complex SQL queries that you don't care about.

00:49:04 Yes.

00:49:05 You don't care to write or so on.

00:49:06 So I think it's Pandas is interesting on its own, but it's almost like a gateway to the broader data science community.

00:49:12 Agreed.

00:49:12 Agreed.

00:49:13 And it's such a de facto, I think, for data analysis now or data manipulation transformation.

00:49:20 Yeah, like I don't see it going away anytime soon.

00:49:23 And actually, Pandas 2.0 just came out.

00:49:26 And instead of being, yeah, instead of Pandas is NumPy under the hood, which is fast, but it's not really equipped to deal with certain kinds of structures like strings.

00:49:38 Because, you know, it's not really what NumPy is about.

00:49:41 And also missing values.

00:49:42 The way that it handles it is pretty janky.

00:49:45 So, yeah, it's been rewritten with PyArrow under the hood.

00:49:48 Right.

00:49:48 Yeah.

00:49:48 Apparently, the performance is so much better.

00:49:51 Something I need to sit down and actually try.

00:49:54 It's been out for like a month and I'm feeling a bit bad.

00:49:57 But, yeah.

00:49:57 Yeah, that's cool.

00:49:58 It probably has support for some of the serialization formats for the back of the term, like, is it Parquet?

00:50:04 And some of those types of things.

00:50:06 I think that comes straight out of PyArrow.

00:50:08 Yeah.

00:50:09 Yeah.

00:50:09 Excellent.

00:50:09 So that kind of brings me to a trade-off I wanted to talk to you about before we get off of Pandas.

00:50:14 Although it sounds like Pandas 2.0, it makes this less important.

00:50:18 But, you know, another sort of competitor that came out is Polars, which is a data frame library for Python written in Rust.

00:50:26 Many of the things are written in Rust these days when they care about performance.

00:50:30 It's like a big trend.

00:50:31 It's the new C extensions of Python.

00:50:33 But this one is supposed to also be way faster than Pandas 1.

00:50:37 And I think it's also based on PyArrow, amongst other things.

00:50:41 The details are not super important.

00:50:43 But more what I wanted to ask you is like, well, here's another way.

00:50:45 This is a totally different API.

00:50:47 It doesn't try to be compatible.

00:50:48 So you've got to learn it.

00:50:49 So the question is, as a data scientist, as a data science team leader, how should you think about, you know, do we keep chasing the shiny new thing?

00:50:59 Or do we stick with stuff that one, people know like Pandas, but two, also extends into this broader space as a gateway, as we described?

00:51:07 Like, what are your thoughts here?

00:51:08 This is a super interesting question.

00:51:10 So data scientists in some ways have the luxury of being able to maybe use newer packages faster.

00:51:18 Because we build these small kind of atomic projects that we can just update to the next library that we feel like using in the next project.

00:51:27 And maybe we're the only ones who ever look at that code.

00:51:29 So it's cool.

00:51:29 The problem is, though, of course, is if someone else needs to look at your code, they are going to need to be able to read it, which is not maybe the biggest problem.

00:51:39 The biggest problem, of course, is any new library.

00:51:43 You have less documentation and you have less entries on Stack Overflow.

00:51:47 So I would say you need to make a tradeoff between the time you're not only going to spend learning it, but also debugging it because it's going to be slower.

00:51:54 But your ChatGPT doesn't know much about Polis.

00:51:57 Basically, you're essentially going to need to trade that off against, are you going to see a benefit from that?

00:52:03 So do you actually have problems with processing your data fast enough?

00:52:09 If you're working on small data sets, probably not.

00:52:10 If you're not, then maybe try something pandas or pandas adjacent.

00:52:14 Yeah, that sort of community support side is important.

00:52:18 And I'm pretty sure there are a lot of data scientists out there who are the one data scientist at their organization.

00:52:25 And so it's not like, oh, we'll go ask the other expert down the hall because if it's not you, there's no answer, right?

00:52:31 Exactly.

00:52:31 I do think, though, like it's good to be curious.

00:52:34 It's good to try out new things as well.

00:52:37 And again, part of being a data scientist is you can experiment a bit more.

00:52:41 So, you know, 2017, 18, sort of the peak Python 2 versus 3 tension, I guess, maybe one year before then.

00:52:51 I noticed that the data scientists were like, I don't know what y'all are arguing about.

00:52:55 We're done with this.

00:52:56 What we're arguing about is when can we take the Python 2 code out to absolutely 100% drop support for it, not when are we moving over?

00:53:04 Whereas people running, you know, that Django site that's been around for eight years that's still on Python 2, they're starting to get nervous because they don't want to rewrite it because it works.

00:53:13 But they know they're going to have to.

00:53:14 And I feel like, you know, we talked about the legacy code is sort of the success story that is dreaded of software on the computer science side.

00:53:23 Because that is less of a thing in data science, it's easier to go, well, this next project that we're starting in a couple of months, we can start with newer tools.

00:53:31 Yep. And I actually remember the point where I decided, okay, this is the last project I'm doing into.

00:53:36 Because the thing that was keeping me into was actually one of those libraries that I mentioned, which built by a university.

00:53:45 And I was like, you know what, I'm just going to go find some alternative tool.

00:53:48 I think at that time, Spacey, which is a very well-known NLP library, actually, based here in Berlin, the company.

00:53:56 Yeah, exactly. Basically a neighbor of yours.

00:53:58 That's right. But I think Spacey was really getting off its feet in that time.

00:54:03 So I was like, you know, I'm just going to switch over to this new library and try that.

00:54:06 And it's excellent. So I didn't look back.

00:54:09 Yeah. Spacey's cool. Ines Montani is doing really great work.

00:54:13 And everyone over at Explosion AI.

00:54:14 And that's the thing. Sometimes it seems like a hassle, right?

00:54:18 But if it forces you out of your comfort zone to pick stuff that's being actively developed, maybe it's worth it, right?

00:54:23 Exactly.

00:54:24 All right. We're getting short on time. So you want to give us a lightning round and the other important libraries you think data scientists should pay attention to?

00:54:31 Yeah. So let's just quickly go through the visualization side of things.

00:54:35 So visualization is massive.

00:54:37 So matplotlib is really the biggie.

00:54:40 And it's what a lot of libraries are actually built on top of in Python.

00:54:44 So the syntax is not that friendly. So there's a lot of alternatives.

00:54:48 So Seaborn is a very popular one.

00:54:51 We actually have an internal one called Let's Plot, which is a port of ggplot2.

00:54:56 And there's another one called Plot9. And I think there actually may even be one called ggplot.

00:54:59 Plotlib.

00:55:00 Some of the fancy new ones that people hear about, they're actually internally just controlling matplotlib and a cleaner API, right?

00:55:06 Pretty much. And let me tell you, matplotlib needs a clean API. It's a bit, let's say, okay.

00:55:13 Although give it some props for its XKCD graph style.

00:55:17 I mean, that is pretty cool that you can get it to do that.

00:55:21 I actually have done, I've done XKCD graphs in Python as well.

00:55:27 It's a goal that you aim for to do like elite visualizations.

00:55:31 It's fun. And XKCD is amazing in a lot of ways.

00:55:35 However, I think it also can serve an important role when you're presenting to like leaders of an organization, non-technical people.

00:55:44 Because if they look and see a beautiful, pristine production ready, sort of like, we're done.

00:55:50 Like, no, no, no, this is a product. No, we're done. Look, you already got it.

00:55:53 But if it comes out in sort of cartoony, kind of like wireframing for UI design, you're like, oh, there are no expectations it's done.

00:56:01 It's XKCD. We're going to get you the real graphs later, right?

00:56:03 Yeah, yeah.

00:56:04 There may be some value there.

00:56:05 Like a psychological effect where you make it look like a hand-drawn prototype.

00:56:10 Exactly. It looks just hand-drawn. It's barely done.

00:56:12 That's right.

00:56:13 It's really just theme equals.

00:56:14 It didn't take me two days.

00:56:15 scikit-learn, you mentioned that before.

00:56:19 Yes. So there are a whole bunch of libraries for doing machine learning.

00:56:24 scikit-learn is kind of your all-in-one for classic machine learning.

00:56:27 But then, you know, you have this whole other branch of data science, which is around neural nets or deep learning.

00:56:33 So you have Keras, TensorFlow, you have PyTorch.

00:56:39 And then you have a package for working with a lot of like these generative AI models or large language models called Transformers from a company called Hugging Face.

00:56:50 So all of these are actually super accessible.

00:56:53 I wouldn't say TensorFlow and PyTorch can be tricky, but Keras is like a friendly front end for them.

00:56:57 Actually, if anyone is interested in getting into this side of things, there's a book called Deep Learning in Python by an AI researcher at Google called Francois Cholet.

00:57:08 It is actually, I think, the most popular book ever on Manning.

00:57:13 So it's an amazing book.

00:57:15 I can only recommend it.

00:57:17 And it's very gentle for beginners who have no background in the area.

00:57:20 Okay. Yeah, cool.

00:57:22 I'll put that in the show notes.

00:57:23 Awesome.

00:57:23 Yeah.

00:57:24 All right.

00:57:25 Well, there are many other things we can talk about.

00:57:28 Maybe just let's close this out with a quick shout out to your PyCon talk.

00:57:34 Eventually, someday, I'm sure that the talks for PyCon will be on YouTube.

00:57:40 They were last year, but I looked back and I was so excited near the end of the conference.

00:57:45 I'm like, look, the talks are up.

00:57:46 And I was talking to someone like, look, here's your talk.

00:57:49 They're like, no, that's my talk from last year.

00:57:50 I'm like, oh.

00:57:51 Yeah.

00:57:52 So it was maybe three or four months delayed until it actually came out.

00:57:56 So maybe this midsummer or the video Virginia talk will be out.

00:58:00 But maybe just give people a quick elevator pitch of your talk here.

00:58:03 Yeah.

00:58:04 So I decided to give this talk because I kind of had to learn things the hard way in terms

00:58:10 of performance with Python.

00:58:11 So basically, I used to do everything with loops.

00:58:15 And then I had to start working with larger amounts of data.

00:58:18 And it just doesn't scale.

00:58:19 So over time, as I got better with Python, I learned more about NumPy, which is another

00:58:25 important data science library.

00:58:26 And it basically allows you to do what's called vectorized operations.

00:58:30 So in this talk, I basically talk about the math behind why vectorized operations work.

00:58:36 You don't need any math background to understand.

00:58:38 It's very gentle.

00:58:39 And then just show why some of these operations work in NumPy and how you can implement it yourself

00:58:46 to get really massive gains in performance speed.

00:58:50 Yeah, that's incredible.

00:58:51 Move a lot of that stuff down into like a C or a Rust layer and just let it do its magic

00:58:56 instead of looping in Python.

00:58:58 Yeah.

00:58:58 Exactly.

00:58:59 Yeah.

00:59:00 Very cool.

00:59:00 So I don't know when, but eventually this will be out as a video.

00:59:03 People can check out for me now.

00:59:06 They know to go look for it.

00:59:07 Yeah, I think the poor team is still recovering so much work.

00:59:10 I know.

00:59:11 All right.

00:59:12 Well, Jodi, it's been great to have you on the show.

00:59:15 Before you get out of here, final two questions.

00:59:17 If you're going to write some Python code, what editor are you using these days?

00:59:20 So I'm actually using all three that I talked about.

00:59:23 I use PyCharm if I need to do something like a bit more on the engineering side, which is

00:59:29 not that often for me.

00:59:30 DataSpell if I'm doing sort of very local development and doing more of the research side.

00:59:35 And then if I need some GPUs, I'm using DataLaw.

00:59:39 So a bit boring, but using all of our tools.

00:59:42 And I really like them.

00:59:43 Yeah, they are good.

00:59:45 All right.

00:59:45 And then notable PyPI package, something you want to give a shout out to, or if you prefer

00:59:51 a Conda package, there's a lot of intersection there.

00:59:54 I think my favorite package at the moment is Transformers.

00:59:56 It is amazing.

00:59:58 And the documentation that Hugging Face have put together is so good.

01:00:01 And just the work they're doing in open data science is so, so important.

01:00:05 So like big props to Hugging Face.

01:00:08 We should really support the work that they're doing.

01:00:10 Excellent.

01:00:10 All right.

01:00:11 Well, thanks for being on the show and sharing your experience.

01:00:15 Thank you so much for having me.

01:00:16 I had an absolute blast.

01:00:17 Yeah, same.

01:00:18 Bye.

01:00:18 Bye.

01:00:19 This has been another episode of Talk Python to Me.

01:00:22 Thank you to our sponsors.

01:00:24 Be sure to check out what they're offering.

01:00:26 It really helps support the show.

01:00:27 The folks over at JetBrains encourage you to get work done with PyCharm.

01:00:32 PyCharm Professional understands complex projects across multiple languages and technologies,

01:00:38 so you can stay productive while you're writing Python code and other code like HTML or SQL.

01:00:43 Download your free trial at talkpython.fm/done with PyCharm.

01:00:48 Spend better time with your data and build better ML-based applications.

01:00:53 Use Prodigy from Explosion AI, a radically efficient data annotation tool.

01:00:57 Get it at talkpython.fm/prodigy and use our code TALKPYTHON, all caps, to save 25% off a personal license.

01:01:06 Want to level up your Python?

01:01:07 We have one of the largest catalogs of Python video courses over at Talk Python.

01:01:11 Our content ranges from true beginners to deeply advanced topics like memory and async.

01:01:16 And best of all, there's not a subscription in sight.

01:01:19 Check it out for yourself at training.talkpython.fm.

01:01:22 Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:01:26 We should be right at the top.

01:01:28 You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

01:01:37 We're live streaming most of our recordings these days.

01:01:40 If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:01:48 This is your host, Michael Kennedy.

01:01:50 Thanks so much for listening.

01:01:51 I really appreciate it.

01:01:53 Now get out there and write some Python code.

01:01:54 I'll see you next time.

