WEBVTT

00:00:00.001 --> 00:00:04.820
In this episode, we cover how Python is being used to understand the electrical markets and grid in

00:00:04.820 --> 00:00:09.920
Australia. Our guest, Jack Simpson, has used Python to uncover a bunch of interesting developments

00:00:09.920 --> 00:00:15.160
as the country has adopted more and more solar energy. We round out the episode looking at some

00:00:15.160 --> 00:00:19.980
of the best practices for high-performance, large data processing in pandas and beyond.

00:00:19.980 --> 00:00:24.940
In addition to that, we also spend some time on how Jack used Python and OpenCV,

00:00:24.940 --> 00:00:30.200
computer vision, to automate the study of massive bee colonies and behaviors. Spoiler alert,

00:00:30.200 --> 00:00:35.160
that involved gluing wingding fonts on the backs of bees. This is Talk Python to Me,

00:00:35.160 --> 00:00:39.160
episode 320, recorded June 6th, 2021.

00:00:52.320 --> 00:00:57.440
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the ecosystem,

00:00:57.440 --> 00:01:02.400
and the personalities. This is your host, Michael Kennedy. Follow me on Twitter where I'm @mkennedy,

00:01:02.400 --> 00:01:06.120
and keep up with the show and listen to past episodes at talkpython.fm,

00:01:06.120 --> 00:01:12.600
and follow the show on Twitter via at Talk Python. This episode is brought to you by Square and Linode,

00:01:12.600 --> 00:01:17.840
and the transcripts are provided by Assembly AI. Please check out what all three of them are offering.

00:01:17.840 --> 00:01:21.520
It really helps support the show. Jack, welcome to Talk Python to Me.

00:01:21.640 --> 00:01:24.800
Thank you, Michael. It's great to meet you after hearing your voice for so many years.

00:01:24.800 --> 00:01:29.460
It's so great to have you on the show. It's always fun to have people who are listeners,

00:01:29.460 --> 00:01:33.920
but have interesting stories to tell. Come on the show, and you definitely have some

00:01:33.920 --> 00:01:40.740
interesting stories about the energy grid and doing data science around really important stuff like

00:01:40.740 --> 00:01:42.680
keeping the lights on in Australia.

00:01:42.680 --> 00:01:43.260
Absolutely.

00:01:43.260 --> 00:01:46.580
Yeah, I'm definitely looking forward to diving into that stuff. It's going to be a lot of fun,

00:01:46.580 --> 00:01:46.900
I think.

00:01:46.900 --> 00:01:47.380
Absolutely.

00:01:47.620 --> 00:01:50.120
Before we get to it, though, let's start with your story. How did you get into programming,

00:01:50.120 --> 00:01:51.340
and what brought you to Python?

00:01:51.340 --> 00:01:56.640
Yeah. Well, I guess I have a very strange background. I actually started off at university

00:01:56.640 --> 00:02:02.520
enrolling in journalism and politics right at the start of the GFC. I had never programmed before,

00:02:02.520 --> 00:02:07.900
and I didn't even realize I was interested in it. And my lecturers kept telling me how many

00:02:07.900 --> 00:02:14.080
journalists were losing their jobs during the financial crisis. And so I actually dropped out,

00:02:14.280 --> 00:02:20.720
and I was trying to consider what I wanted to do. And I'd always had a passion for biology and science.

00:02:20.720 --> 00:02:27.080
And my hobby was I was actually a beekeeper. I had six of my own hives at home. I really love that.

00:02:27.080 --> 00:02:30.560
Amazing. Are these like honeybee type of bees or what kind of bees?

00:02:30.560 --> 00:02:38.620
Honeybees. Yes, absolutely. The ones that stink. I actually also had a couple of Australian native bees,

00:02:38.800 --> 00:02:43.700
tetragongula carbonaria, which I'm not sure if you've heard of them before, but they're actually,

00:02:43.700 --> 00:02:49.700
they almost look like tiny little flies. They're stingless bees. And they will actually make their

00:02:49.700 --> 00:02:55.660
hives out of the resin of trees. And they will build their brood in this beautiful kind of spiral

00:02:55.660 --> 00:03:00.800
pattern going up through the hive. And so I was just really interested in, I guess, all things bee and

00:03:00.800 --> 00:03:07.540
insects related at the time. And so I actually started blogging about bees and beekeeping. And

00:03:07.540 --> 00:03:12.860
that was actually my introduction to code because I had, I think I had a website on blogger. And one

00:03:12.860 --> 00:03:18.120
day I suddenly thought, well, I'd love to actually be able to make my own website. How do I do that?

00:03:18.120 --> 00:03:24.500
And so I started learning HTML and JavaScript. And it was literally just so I could talk about my bees.

00:03:24.820 --> 00:03:29.500
I had no interest in programming. Amazing. Well, I think so many people get into programming that way

00:03:29.500 --> 00:03:35.000
who don't necessarily feel like my goal is to go be a programmer, but they just really have something

00:03:35.000 --> 00:03:39.440
they're into. And programming is almost in the way, right? It's just like something you've got to figure

00:03:39.440 --> 00:03:43.720
out so that you can actually get to the thing that you actually like. But then a lot of people find out,

00:03:43.720 --> 00:03:47.000
well, hey, this is actually kind of cool. And what else can I do now that I know this, right?

00:03:47.180 --> 00:03:51.660
Absolutely. That was really what made me change my degree. So initially I was going to do

00:03:51.660 --> 00:03:57.960
a pure biology degree. And so I decided I would do biology and web development. And as I kind of went

00:03:57.960 --> 00:04:04.180
along with the degree, I suddenly started realizing that the programming skills I was picking up during

00:04:04.180 --> 00:04:10.720
my degree. So I learned, you know, PHP, Perl and Python. Suddenly I realized that these skills could

00:04:10.720 --> 00:04:16.820
actually help me with working with scientific data. We kind of hit this point where there's just so much

00:04:16.820 --> 00:04:21.600
genomic data. Really, most people at the time I was doing undergrad, but one of the things I've

00:04:21.600 --> 00:04:27.540
really noticed is most people these days that enroll in a biology PhD, you join the lab and it's

00:04:27.540 --> 00:04:32.240
almost like, right, you're learning Python or you're learning R. There's no other way you're working

00:04:32.240 --> 00:04:38.140
with this data. And so suddenly I kind of hit this point where I was like, wow, these kind of technical

00:04:38.140 --> 00:04:43.960
skills were letting me do things and be useful in ways that I never thought. And it let me answer

00:04:43.960 --> 00:04:49.640
research questions that I was really fascinated by. And that was my motivation to actually, I guess,

00:04:49.640 --> 00:04:53.860
go into and do a PhD and then try and take those skills further.

00:04:53.860 --> 00:04:55.020
What was your PhD in?

00:04:55.020 --> 00:05:01.340
So it was in computational biology. It was trying to develop software to automate the analysis of

00:05:01.340 --> 00:05:08.280
honeybee behavior in the hive. So the thing that was interesting was it was both a physical setup and

00:05:08.280 --> 00:05:16.020
the code as well. So the physical side was actually, how do we set up a beehive in a building with a kind

00:05:16.020 --> 00:05:21.360
of like a glass window in so that I can film them with an infrared camera in the dark? And how do I

00:05:21.360 --> 00:05:27.720
put little tags with patterns on them on the backs of the bees that I can then use Python and machine

00:05:27.720 --> 00:05:35.080
learning to identify and track over the course of several weeks? And that kind of process ended up being

00:05:35.080 --> 00:05:39.500
much harder than I had anticipated. Because when I started out, I read a couple of papers

00:05:39.500 --> 00:05:45.240
by some computer scientists who mentioned that they'd printed out some card tags. And they said

00:05:45.240 --> 00:05:49.240
that they filmed the bees for a couple of hours, got the data and did an analysis. And I thought,

00:05:49.240 --> 00:05:54.180
great, I'm going to do that. Problem solved. It was only until later that I realized the reason that

00:05:54.180 --> 00:05:58.980
they only filmed them for a couple of hours was because that was how long it took the bees to chew the

00:05:58.980 --> 00:06:01.640
cardboard off each other in the hive.

00:06:01.640 --> 00:06:05.760
I know. Oh, did they help each other? Like, hey, I've got this thing on my back, get it off me?

00:06:05.760 --> 00:06:10.000
Yes. Yes, they actually did. They actually, and that was the thing I came, I would actually find time

00:06:10.000 --> 00:06:13.900
and time again, I would come up with a material and I would try and stick it on the back of the bees.

00:06:13.900 --> 00:06:19.260
And you would see their friends effectively come over and start trying to pry it off them in the hive.

00:06:19.380 --> 00:06:25.220
And so it was actually a process to find something that didn't, I guess, trigger them, so to speak.

00:06:25.220 --> 00:06:30.420
And one of the things, a really immensely frustrating experience I had when I was doing these experiments

00:06:30.420 --> 00:06:36.280
was I thought I had found the perfect fabric and the perfect glue to put them on the bees.

00:06:36.740 --> 00:06:43.260
And I'd spent hours tagging hundreds of them. I put them into the hive. And then I came back,

00:06:43.260 --> 00:06:48.620
I would come back a few hours later and all my tags had disappeared. And I couldn't understand why. And I kept doing it.

00:06:48.620 --> 00:06:53.840
And then at one point I thought, you know what, I'm going to put a bucket outside the hive entrance just to see what happens.

00:06:53.840 --> 00:06:59.400
And I'm going to watch in the dark. And what actually happened was the bees didn't like the smell of the glue.

00:06:59.580 --> 00:07:06.980
So they were actually physically grabbing bees that I'd tagged, dragging them to the entrance and flinging them out of the hive.

00:07:06.980 --> 00:07:14.740
And because the hive, because these bees were juvenile bees, they were too young to fly yet.

00:07:14.740 --> 00:07:19.840
The ants were actually dragging them away. So I thought my tags were dropping off or being pulled off.

00:07:19.840 --> 00:07:24.320
But actually, my poor bees were getting eaten by the ants because they couldn't fly away.

00:07:24.320 --> 00:07:25.080
Oh my goodness.

00:07:25.080 --> 00:07:30.020
And so I guess it's another example as well. You know, when you've got missing data, understand the process.

00:07:30.020 --> 00:07:34.300
Sometimes the process that made that data missing is significant in a way.

00:07:34.300 --> 00:07:37.440
I would have never guessed. That's really pretty insane, actually.

00:07:37.440 --> 00:07:44.340
And so the solution for dealing with this was I would actually go through the process of tagging the bees.

00:07:44.340 --> 00:07:52.940
Then I would put them in this heated incubator on a frame of honey for several hours until all of the smell had kind of faded away.

00:07:53.060 --> 00:07:56.160
And then I could introduce them to the hive and they would be accepted.

00:07:56.160 --> 00:07:59.780
Oh, I see. Okay. Wait, basically wait till they dried and it was really on them.

00:07:59.780 --> 00:08:04.660
Yeah. Yeah. Well, wait until all the fumes were gone and then they would be accepted and then it would work.

00:08:04.660 --> 00:08:13.140
Because I think this was the real challenge of my project was we weren't interested in tracking, showing that we could write software that could track the bees.

00:08:13.400 --> 00:08:19.720
We had a specific application was to look at the social development over several weeks of these bees.

00:08:19.720 --> 00:08:27.260
So we needed a kind of experimental setup and the code to support it that would let us look at these extended periods of behavior.

00:08:27.260 --> 00:08:34.840
Did they have different markings based on like their age or their role in the colony or something?

00:08:35.000 --> 00:08:40.160
Like were they all tagged the same and you just said, well, they kind of move around like this or were they're like, did you group them or something?

00:08:40.160 --> 00:08:46.540
What I would often do is I had use a laser engraver to burn patterns in the fabric that I would put on them.

00:08:46.540 --> 00:08:50.100
And so each bee had a unique pattern that I could use to identify it.

00:08:50.100 --> 00:08:51.480
Like a QR code on the bee?

00:08:51.860 --> 00:08:53.300
Kind of like that, but not.

00:08:53.300 --> 00:08:56.920
In fact, I think if you scroll through the website to the bottom of the page.

00:08:56.920 --> 00:08:58.800
Yeah, there's some right there.

00:08:58.800 --> 00:08:59.720
There's some little patterns.

00:08:59.720 --> 00:09:01.760
This was some initial prototypes for the bottom.

00:09:01.760 --> 00:09:04.440
Just if you scroll up a little bit more, the last image.

00:09:04.440 --> 00:09:05.240
Yep, that one.

00:09:05.240 --> 00:09:10.100
I was literally using a wingdings pod to try out different patterns.

00:09:10.100 --> 00:09:11.040
Wingdings.

00:09:11.040 --> 00:09:11.520
Okay.

00:09:11.520 --> 00:09:12.420
On the bees.

00:09:12.420 --> 00:09:19.440
Because I just had the idea was to have a relatively inexpensive 4K camera that could pick up the different patterns.

00:09:19.560 --> 00:09:25.940
Of course, if you had a really expensive high resolution camera, then you could do more with QR codes, for instance.

00:09:25.940 --> 00:09:31.840
And what I would do is I would do these experiments where I would, half of the bees would be that I would introduce.

00:09:31.840 --> 00:09:37.200
They would all be juvenile, except I would also mark the queen so I could know how they were interacting with the queen.

00:09:37.200 --> 00:09:44.460
But half the juvenile bees I would introduce into the hive would receive a label that I could reference later on.

00:09:44.460 --> 00:09:48.720
And half would receive a different label that I knew about.

00:09:49.160 --> 00:09:54.780
And the reason I did this was so I could actually do these, have these control and treatment groups in my experiment.

00:09:54.780 --> 00:10:04.500
Because I would do these experiments where I would treat the bees with caffeine to see how it would actually affect their social development in the hive.

00:10:04.500 --> 00:10:10.220
I guess to give a little bit more context to that, diving a little bit into the way that bees develop.

00:10:10.660 --> 00:10:14.280
You could almost think of a worker bee in the hive like the pictures I have on my site.

00:10:14.280 --> 00:10:19.600
The jobs that a bee does over its lifetime are influenced by how old it is.

00:10:19.600 --> 00:10:23.380
So these juvenile bees I was first introducing to the colony.

00:10:23.380 --> 00:10:25.880
They really would just have quite menial colonies.

00:10:25.880 --> 00:10:28.220
They would do little cleaning tasks around the hive.

00:10:28.220 --> 00:10:29.120
They wouldn't do much.

00:10:29.420 --> 00:10:33.100
Then when they're a little bit older, they would start nursing other juvenile bees.

00:10:33.100 --> 00:10:40.460
And then the eldest bees are the ones that you actually see out and about flying and collecting nectar and pollen.

00:10:40.460 --> 00:10:44.280
So those are actually the eldest of the bees in the colony, typically.

00:10:44.280 --> 00:10:52.900
And so I wanted to see how this caffeine would affect that kind of behavioral process in the juvenile bees.

00:10:53.620 --> 00:10:54.020
How interesting.

00:10:54.020 --> 00:10:56.720
Short, briefly, what did you find that caffeine does to bees?

00:10:56.720 --> 00:11:06.540
One of the things I found was it effectively meant that bees sped up how quickly they adjusted to the rhythms of the colony.

00:11:06.540 --> 00:11:19.120
So for a bit of context, if you're a juvenile bee in the hive, you don't really care about circadian rhythms, day-night cycles, because you're in a hive, it's completely dark all the time.

00:11:19.520 --> 00:11:34.020
And so what we found was that we hadn't seen before was these juvenile bees, even though they weren't exposed to the light on the outside, they would actually pick up these circadian rhythms by interacting with the older bees that were coming back.

00:11:34.020 --> 00:11:37.240
It was effectively like a socially acquired circadian rhythm.

00:11:37.240 --> 00:11:49.240
And so what we found was that bees that were treated with caffeine effectively picked up this rhythm more quickly than bees that weren't and kind of progressed in their roles in the colony more quickly.

00:11:49.240 --> 00:11:50.240
So there was that.

00:11:50.240 --> 00:11:50.240
Okay.

00:11:50.240 --> 00:11:51.240
Yeah.

00:11:51.240 --> 00:11:52.240
So there was that.

00:11:52.240 --> 00:12:01.240
And I had a few other areas, but yeah, to be honest, a lot of the work was really just making the software and the bees all play nice together.

00:12:01.240 --> 00:12:02.240
Yeah.

00:12:02.240 --> 00:12:03.240
Yeah.

00:12:03.240 --> 00:12:04.240
Absolutely.

00:12:04.240 --> 00:12:14.240
It was probably one of the most immensely, I will say one of the things that is quite nice about the energy sector is I don't have to deal with, I guess I can deal with machines, which are a little bit less frustrating at times.

00:12:14.240 --> 00:12:17.300
More reliable, more predictable and certain, that's for sure.

00:12:17.300 --> 00:12:22.400
This portion of Talk Python to Me is brought to you by Square.

00:12:22.400 --> 00:12:27.420
Payment acceptance can be one of the most painful parts of building a web app for a business.

00:12:27.420 --> 00:12:32.420
When implementing checkout, you want it to be simple to build, secure, and slick to use.

00:12:32.420 --> 00:12:38.000
Square's new web payment SDK raises the bar in the payment acceptance developer experience

00:12:38.000 --> 00:12:41.740
and provides a best-in-class interface for merchants and buyers.

00:12:41.740 --> 00:12:47.280
With it, you can build a customized, branded payment experience and never miss a sale.

00:12:47.920 --> 00:12:52.060
Deliver a highly responsive payments flow across web and mobile that integrates with

00:12:52.060 --> 00:12:55.840
credit cards and debit cards, digital wallets like Apple Pay and Google,

00:12:55.840 --> 00:12:58.400
ACH bank payments, and even gift cards.

00:12:58.400 --> 00:13:03.200
For more complex transactions, follow-up actions by the customer can include

00:13:03.200 --> 00:13:07.680
completing a payment authentication step, filling in a credit line application form,

00:13:07.680 --> 00:13:10.520
or doing background risk checks on the buyer's device.

00:13:10.520 --> 00:13:14.340
And developers don't even need to know if the payment method requires validation.

00:13:15.000 --> 00:13:19.340
Square hides the complexity from the seller and guides the buyer through the necessary steps.

00:13:19.340 --> 00:13:22.060
Getting started with a new web payment SDK is easy.

00:13:22.060 --> 00:13:24.860
Simply include the web payment SDK JavaScript,

00:13:24.860 --> 00:13:27.940
flag an element on the page where you want the payment form to appear,

00:13:27.940 --> 00:13:30.260
and then attach hooks for your custom behavior.

00:13:30.260 --> 00:13:36.540
Learn more about integrating with Square's web payments SDK at talkpython.fm/square,

00:13:36.540 --> 00:13:39.100
or just click the link in your podcast player's show notes.

00:13:39.100 --> 00:13:48.800
Before we move on to the energy sectors, just give us a quick overview of the software that you use.

00:13:48.800 --> 00:13:50.960
Was Python part of this role here?

00:13:50.960 --> 00:13:51.860
Yes, absolutely.

00:13:52.080 --> 00:13:58.460
So I used a mix of Python and OpenCV for a lot of the image processing.

00:13:58.540 --> 00:14:07.160
And of course, TensorFlow and Keras for training my neural network to identify the different tags.

00:14:07.160 --> 00:14:10.880
And that actually ended up being quite an interesting process,

00:14:10.880 --> 00:14:13.460
building up that data set and improving it over time.

00:14:13.460 --> 00:14:18.720
Because one of the things I found when I started trying to train that data set was I thought,

00:14:19.100 --> 00:14:24.360
okay, I can take my patterns, film them, add a little bit of noise and rotation,

00:14:24.360 --> 00:14:27.960
and then that's my kind of starter, you know, machine learning model.

00:14:27.960 --> 00:14:31.760
The problem was that when you put the tag on the bee,

00:14:31.760 --> 00:14:34.980
the way that they kind of walk around the hive,

00:14:34.980 --> 00:14:38.320
you'll see different kind of angles of,

00:14:38.320 --> 00:14:41.100
they kind of have this bit of wobble walk as they go around.

00:14:41.100 --> 00:14:44.940
So it kind of introduces this level of distortion to the tag.

00:14:45.480 --> 00:14:49.480
And then other, and so then also you could have other situations where

00:14:49.480 --> 00:14:53.960
bees would walk over each other, the block occluded tags as well.

00:14:53.960 --> 00:14:59.080
So one of the things I ended up having to do was I had to introduce a class to my,

00:14:59.080 --> 00:15:02.440
a predictive class to my model that was literally just like the,

00:15:02.440 --> 00:15:04.640
I don't know what this is class.

00:15:04.640 --> 00:15:09.360
And effectively, the idea was, I'm going to see this bee,

00:15:09.360 --> 00:15:12.880
I'm going to have multiple attempts to classify this bee as it's walking around.

00:15:13.240 --> 00:15:17.420
So I want to only attempt a classification when I'm seeing enough of the tag

00:15:17.420 --> 00:15:20.100
and I'm confident enough in that to attempt it.

00:15:20.100 --> 00:15:21.920
And so that was one of the,

00:15:21.920 --> 00:15:24.580
one of the techniques I found that helped improve the classification.

00:15:24.580 --> 00:15:30.320
And really it ended up just becoming a process where I would,

00:15:30.320 --> 00:15:32.820
I had a bit of a pipeline that would go through,

00:15:32.820 --> 00:15:34.100
it would extract tags,

00:15:34.100 --> 00:15:37.520
it would use the model at the current iteration to label them.

00:15:37.520 --> 00:15:41.980
I would then go in and manually review it and then figure out where it had stuffed up,

00:15:41.980 --> 00:15:43.060
where it was doing well,

00:15:43.060 --> 00:15:48.340
and then use that corrected data set to retrain the model and then improve and see how well that

00:15:48.340 --> 00:15:48.940
iteration did.

00:15:48.940 --> 00:15:50.060
And it became kind of like a,

00:15:50.060 --> 00:15:54.760
almost like a semi-supervised problem to an extent when I was building it out.

00:15:54.760 --> 00:15:55.920
And at a certain point,

00:15:55.920 --> 00:16:00.140
it became just as good as me at doing these classifications.

00:16:00.580 --> 00:16:03.540
And then it was fully automated as well.

00:16:03.540 --> 00:16:09.580
But I think I ended up labeling about seven or 800,000 images as part of doing this.

00:16:09.580 --> 00:16:09.820
And my,

00:16:09.820 --> 00:16:10.740
my wife was actually,

00:16:10.740 --> 00:16:14.900
she was a PhD student in working in genetics at the time.

00:16:14.900 --> 00:16:16.500
She was helping me in her spare time.

00:16:16.920 --> 00:16:20.600
So she does not look favorably upon that,

00:16:20.600 --> 00:16:22.200
on that project.

00:16:22.200 --> 00:16:25.860
She probably doesn't love wingding fonts.

00:16:25.860 --> 00:16:27.000
Maybe in a bit of a surprise,

00:16:27.000 --> 00:16:27.340
she's like,

00:16:27.340 --> 00:16:27.460
oh,

00:16:27.460 --> 00:16:28.180
not you again.

00:16:28.180 --> 00:16:29.360
Yeah,

00:16:29.360 --> 00:16:30.020
absolutely.

00:16:30.020 --> 00:16:31.040
But I'd say,

00:16:31.040 --> 00:16:31.220
yeah,

00:16:31.220 --> 00:16:33.700
so Python and OpenCV were big ones.

00:16:33.700 --> 00:16:38.180
And then the other tool I was using a lot of was Python Cython library,

00:16:38.180 --> 00:16:39.500
where I would,

00:16:39.500 --> 00:16:42.140
for certain parts that I wanted to run really efficiently,

00:16:42.140 --> 00:16:48.620
I wrote those in C++ and then used Cython to expose some of those methods to it.

00:16:48.620 --> 00:16:50.760
And that worked amazingly well.

00:16:50.760 --> 00:16:53.240
It was so impressive how you could call,

00:16:53.240 --> 00:16:54.320
pass a list,

00:16:54.320 --> 00:16:56.100
a Python list to my,

00:16:56.100 --> 00:16:58.080
my C++ class,

00:16:58.080 --> 00:16:59.440
and it would interpret that as a vector.

00:16:59.440 --> 00:17:02.480
And then it would pass back the information as well.

00:17:02.480 --> 00:17:06.640
I think this is the reason I'm such a fan of Python is just how well it lets me

00:17:06.640 --> 00:17:09.220
do so many different things that I'm working on.

00:17:09.220 --> 00:17:10.360
That's a really interesting point.

00:17:10.360 --> 00:17:10.600
you know,

00:17:10.600 --> 00:17:11.860
a lot of people talk about,

00:17:11.860 --> 00:17:12.160
well,

00:17:12.160 --> 00:17:14.220
Python is slow for this or it's slow for that.

00:17:14.220 --> 00:17:19.240
And yet here's all these really intensive computational things that Python seems to be

00:17:19.240 --> 00:17:20.320
the preferred language for.

00:17:20.320 --> 00:17:25.080
And I think this is one of the hidden secrets that's not apparent as people come into the

00:17:25.080 --> 00:17:25.520
ecosystem,

00:17:25.520 --> 00:17:25.820
right?

00:17:25.820 --> 00:17:27.740
Obviously people have been here for a long time and they,

00:17:27.740 --> 00:17:29.020
they kind of know that story,

00:17:29.020 --> 00:17:29.840
but you know,

00:17:29.840 --> 00:17:31.140
as people come in,

00:17:31.140 --> 00:17:31.720
because there's,

00:17:31.720 --> 00:17:36.040
there's all sorts of people coming into the Python world drawn in a little bit like

00:17:36.040 --> 00:17:36.220
you,

00:17:36.220 --> 00:17:39.160
you talked about how you started out in biology,

00:17:39.160 --> 00:17:42.300
not necessarily to be in software development specifically,

00:17:42.300 --> 00:17:44.240
but then you kind of got sucked into it.

00:17:44.240 --> 00:17:44.460
Right?

00:17:44.460 --> 00:17:45.020
Absolutely.

00:17:45.020 --> 00:17:45.360
Yeah.

00:17:45.420 --> 00:17:49.520
I think all of the conversations around the performance of Python is super interesting.

00:17:49.520 --> 00:17:49.880
It's like,

00:17:49.880 --> 00:17:50.140
oh,

00:17:50.140 --> 00:17:50.420
it's,

00:17:50.420 --> 00:17:51.460
it's really slow,

00:17:51.460 --> 00:17:53.640
except for in this time where it's like as fast as C++.

00:17:53.640 --> 00:17:54.900
Wait a minute.

00:17:54.900 --> 00:17:55.280
Is it,

00:17:55.280 --> 00:17:55.840
is it slower?

00:17:55.840 --> 00:17:56.780
Is it fast as C++?

00:17:56.780 --> 00:17:57.160
Well,

00:17:57.160 --> 00:17:57.660
it's both,

00:17:57.660 --> 00:17:57.920
right?

00:17:57.920 --> 00:17:58.860
it varies,

00:17:58.860 --> 00:18:02.100
but you can bring in these extra like turbo boosts,

00:18:02.100 --> 00:18:02.220
right?

00:18:02.220 --> 00:18:03.340
Like Cython and,

00:18:03.340 --> 00:18:06.360
or do your work in NumPy rather than in,

00:18:06.360 --> 00:18:08.540
in straight lists and stuff like that.

00:18:08.540 --> 00:18:09.000
Absolutely.

00:18:09.000 --> 00:18:10.260
And like one of the,

00:18:10.260 --> 00:18:12.880
initially when I started off my PhD,

00:18:12.880 --> 00:18:19.180
I actually wrote an initial prototype version of it all in C++ using open CV,

00:18:19.180 --> 00:18:21.980
open C++ library and a machine learning,

00:18:21.980 --> 00:18:23.660
a deep learning library called cafe,

00:18:23.660 --> 00:18:25.720
which was a bit of a thing back in the day.

00:18:26.220 --> 00:18:31.500
And the pro that process for dealing with data and even just converting data

00:18:31.500 --> 00:18:32.080
between like,

00:18:32.080 --> 00:18:36.480
I think the best thing about Python is the fact that NumPy arrays is just

00:18:36.480 --> 00:18:38.780
understood by all the scientific libraries,

00:18:38.780 --> 00:18:40.560
whereas sometimes with other languages,

00:18:40.560 --> 00:18:44.800
it can be painful moving data between different libraries and tools.

00:18:44.800 --> 00:18:45.040
Oh,

00:18:45.040 --> 00:18:45.460
interesting.

00:18:45.460 --> 00:18:45.720
Yeah,

00:18:45.720 --> 00:18:46.620
you're right about that.

00:18:46.620 --> 00:18:47.000
Yeah.

00:18:47.000 --> 00:18:47.500
And so like,

00:18:47.500 --> 00:18:47.740
I,

00:18:47.740 --> 00:18:50.180
I remembered at one point during my PhD with,

00:18:50.180 --> 00:18:51.600
with that initial C++ version,

00:18:51.600 --> 00:18:56.200
I had like a page of code to convert between an open C,

00:18:56.200 --> 00:18:57.820
the matrix and a cafe,

00:18:57.820 --> 00:18:58.560
I think blob.

00:18:58.560 --> 00:19:03.640
And it was a page of code that I was terrified of breaking because I didn't understand how it

00:19:03.640 --> 00:19:04.000
worked.

00:19:04.000 --> 00:19:04.920
Whereas Python,

00:19:04.920 --> 00:19:07.460
it was like everything I can move between,

00:19:07.460 --> 00:19:07.700
you know,

00:19:07.700 --> 00:19:08.420
scikit-learn,

00:19:08.420 --> 00:19:09.080
pandas,

00:19:09.080 --> 00:19:11.400
and all these other libraries.

00:19:11.400 --> 00:19:14.580
And it's all kind of got that common foundation that makes me really efficient.

00:19:14.580 --> 00:19:14.960
Yeah.

00:19:14.960 --> 00:19:16.320
And that I understand really well.

00:19:16.440 --> 00:19:21.120
That's a really interesting insight that there's this sort of common data structure across the

00:19:21.120 --> 00:19:21.460
libraries,

00:19:21.460 --> 00:19:22.180
because you're right.

00:19:22.180 --> 00:19:25.840
I remember in C++ and other languages like C# and whatnot,

00:19:25.840 --> 00:19:31.540
this one will take something like this and you've got to reorder the data and reformat it to pass it over.

00:19:31.640 --> 00:19:33.060
And if you have to do that back and forth,

00:19:33.060 --> 00:19:35.260
it would completely slow things down.

00:19:35.260 --> 00:19:36.360
All sorts of stuff.

00:19:36.360 --> 00:19:36.600
Yeah.

00:19:36.600 --> 00:19:37.320
Very interesting.

00:19:37.320 --> 00:19:38.080
In a way as well.

00:19:38.080 --> 00:19:47.260
I really loved that the Python stack has let me do things in during my PhD and then post PhD as well.

00:19:47.320 --> 00:19:50.260
In just the skills that I developed in analytics here,

00:19:50.260 --> 00:19:53.460
I've gone on to be able to use that in so many different places.

00:19:53.460 --> 00:19:54.300
For instance,

00:19:54.300 --> 00:19:57.060
one of the pieces of analysis I did was look,

00:19:57.060 --> 00:20:03.460
I used Python's network X library to look at the social interactions between the queen and worker bees.

00:20:03.460 --> 00:20:14.140
And I would build out these network graphs that would explore the number of interactions and the length of time of those interactions between the queen and the worker bee.

00:20:14.140 --> 00:20:23.080
And this actually recording independent interactions actually became important because sometimes the queen would literally fall asleep behind another worker.

00:20:23.080 --> 00:20:25.240
And it would look like she loves that worker,

00:20:25.240 --> 00:20:28.500
but she just was resting for like over an hour or two.

00:20:28.500 --> 00:20:32.840
What I've actually found is that those skills for working with data and with network analysis,

00:20:32.840 --> 00:20:34.220
when I was working consulting,

00:20:34.220 --> 00:20:41.020
I would use network X to analyze the corporate structure of organizations that we're doing an org review for.

00:20:41.020 --> 00:20:44.300
And then more recently I have done work in the energy sector,

00:20:44.300 --> 00:20:47.620
looking at building out networks of power stations as well.

00:20:47.620 --> 00:20:48.440
And so it's,

00:20:48.440 --> 00:20:49.040
I think that's,

00:20:49.040 --> 00:20:58.460
that's one of the things I love about this area is that you have this kind of transferable skill set that you're more limited by what you can think of,

00:20:58.460 --> 00:21:01.140
but using it by rather than what you can actually do with it,

00:21:01.140 --> 00:21:02.200
with it itself.

00:21:02.200 --> 00:21:02.560
Yeah,

00:21:02.560 --> 00:21:03.020
absolutely.

00:21:03.460 --> 00:21:05.120
And I think for a lot of people,

00:21:05.120 --> 00:21:06.800
if they're out there listening and they're doing,

00:21:06.800 --> 00:21:07.340
you know,

00:21:07.340 --> 00:21:11.420
academic type stuff or working in one area,

00:21:11.420 --> 00:21:14.040
but maybe that's not the area they necessarily want to stay in.

00:21:14.040 --> 00:21:16.560
A lot of these skills are super transferable.

00:21:16.560 --> 00:21:22.040
One of the things that's blown my mind as I've spent more and more time in the software industry was,

00:21:22.180 --> 00:21:30.520
I remember I was doing professional training and I spent one week at a stock brokerage in New York City teaching programming.

00:21:30.520 --> 00:21:32.560
And then I spent two weeks later,

00:21:32.560 --> 00:21:36.520
I was like at an air force base working with some of the engineers there.

00:21:36.580 --> 00:21:38.360
The stuff that those two groups need to know,

00:21:38.360 --> 00:21:40.520
it sounds like it's entirely different worlds,

00:21:40.520 --> 00:21:40.760
right?

00:21:40.760 --> 00:21:43.740
It's like 90% identically the same.

00:21:43.740 --> 00:21:46.500
It's just a little bit of what do you do with that once you know it?

00:21:46.500 --> 00:21:49.020
Like what's the secret sauce on top of it that puts it together?

00:21:49.020 --> 00:21:49.500
But yeah.

00:21:49.500 --> 00:21:52.820
And it sounds like you kind of got that skill in your research.

00:21:52.820 --> 00:21:53.300
Absolutely.

00:21:53.300 --> 00:22:00.740
And I think this is one of the things I've noticed is that some PhDs can struggle to transition into industry.

00:22:00.960 --> 00:22:08.600
And often it's because there's people on the industry side that don't really understand how those skills can help them.

00:22:08.600 --> 00:22:09.540
But at the same time,

00:22:09.540 --> 00:22:15.620
I think it's actually a skill to be able to explain how you can link what you already know,

00:22:15.620 --> 00:22:18.420
what you're capable of and solve their kind of business problem.

00:22:18.420 --> 00:22:19.220
And in fact,

00:22:19.220 --> 00:22:23.420
I think when I went into management consulting and I would do some work for some of the partners,

00:22:23.420 --> 00:22:28.600
eventually it took me a little while to figure out that they weren't that interested in,

00:22:28.600 --> 00:22:28.920
you know,

00:22:28.920 --> 00:22:31.440
the code I was doing or even some of the raw data.

00:22:31.440 --> 00:22:35.640
But if I could figure out a way to link that to the business problem they were trying to solve,

00:22:35.640 --> 00:22:36.580
then they were interested.

00:22:36.580 --> 00:22:37.180
Yeah, absolutely.

00:22:37.180 --> 00:22:43.340
Being able to kind of communicate and act as like a bridge between those was something I didn't realize was a skill,

00:22:43.340 --> 00:22:46.620
but it is hugely valuable in organizations.

00:22:46.620 --> 00:22:47.500
I've really noticed.

00:22:47.500 --> 00:22:48.380
Yeah, absolutely.

00:22:48.380 --> 00:22:49.080
All right.

00:22:49.080 --> 00:22:52.880
One final question about your research before we get into the energy sector.

00:22:52.880 --> 00:22:54.660
That what year did you do that?

00:22:54.660 --> 00:22:55.340
Oh,

00:22:55.340 --> 00:22:57.460
so 2014 to 2017.

00:22:57.460 --> 00:22:57.940
Yeah.

00:22:57.940 --> 00:22:59.720
And that's not that long ago.

00:22:59.720 --> 00:23:06.760
And yet the machine learning story has probably progressed really quite a bit with deep learning,

00:23:06.760 --> 00:23:07.700
transfer learning,

00:23:07.700 --> 00:23:09.300
all sorts of stuff going on,

00:23:09.300 --> 00:23:13.180
the different use of GPUs and tensor compute units and whatnot.

00:23:13.180 --> 00:23:16.560
What would it look like now if you're doing it versus then?

00:23:16.560 --> 00:23:17.460
What would be different?

00:23:17.620 --> 00:23:25.500
I think now one of the big differences was really that TensorFlow only came out towards the second half of my PhD.

00:23:25.500 --> 00:23:27.860
So I think a lot of the,

00:23:27.860 --> 00:23:29.920
so I think that was a difference.

00:23:29.920 --> 00:23:34.520
Having more accessible machine learning libraries and tools really made a big difference.

00:23:34.520 --> 00:23:35.900
The other one was,

00:23:35.900 --> 00:23:37.920
I think when I started my project,

00:23:37.920 --> 00:23:40.520
I actually spent a lot of time playing around with,

00:23:40.520 --> 00:23:41.160
you know,

00:23:41.160 --> 00:23:42.240
now if you started your PhD,

00:23:42.240 --> 00:23:44.320
you would go image analysis,

00:23:44.320 --> 00:23:45.640
it's going to be deep learning.

00:23:45.640 --> 00:23:47.420
Whereas when I started,

00:23:47.420 --> 00:23:50.200
I was actually pointed in the direction of,

00:23:50.580 --> 00:23:50.660
oh,

00:23:50.660 --> 00:23:51.340
go check out,

00:23:51.340 --> 00:23:51.560
you know,

00:23:51.560 --> 00:23:52.720
support vector machines,

00:23:52.720 --> 00:23:54.500
try out a random forest,

00:23:54.500 --> 00:23:58.740
try out a whole bunch of different feature engineering and machine learning techniques.

00:23:58.740 --> 00:24:03.040
And so I spent a lot of time kind of moving around between those before I literally had a,

00:24:03.040 --> 00:24:09.200
I got in touch with a researcher in the computer science department because I was in the biology department doing this work.

00:24:09.200 --> 00:24:10.620
And he literally,

00:24:10.620 --> 00:24:14.000
I had a chat with him and he literally looked at what I was doing and he said,

00:24:14.000 --> 00:24:15.020
use deep learning.

00:24:15.020 --> 00:24:15.960
And he said,

00:24:15.960 --> 00:24:17.000
go check out,

00:24:17.000 --> 00:24:18.060
check out these libraries,

00:24:18.060 --> 00:24:19.440
but this is what you need to do it.

00:24:19.760 --> 00:24:20.820
And I think,

00:24:20.820 --> 00:24:21.320
yeah,

00:24:21.320 --> 00:24:23.120
in a way like that type of,

00:24:23.120 --> 00:24:26.640
the libraries and the understanding about how you would solve this problem now is,

00:24:26.640 --> 00:24:33.380
is a lot further along and probably would have shortcut a lot of my initial frustration compared to previous.

00:24:33.380 --> 00:24:33.460
Yeah,

00:24:33.460 --> 00:24:33.860
probably.

00:24:33.860 --> 00:24:37.860
But think of all the lessons you've learned with those late nights of it not working and,

00:24:37.860 --> 00:24:38.560
and whatnot.

00:24:38.560 --> 00:24:39.000
Right.

00:24:39.000 --> 00:24:43.940
One other thing really quickly is I love to look at this graph here,

00:24:43.940 --> 00:24:44.400
this,

00:24:44.400 --> 00:24:46.060
the stack overflow trends,

00:24:46.060 --> 00:24:47.880
and I'll link to this in the show notes.

00:24:47.880 --> 00:24:49.000
There was,

00:24:49.160 --> 00:24:52.020
back in 2017 article by stack overflow,

00:24:52.020 --> 00:24:55.800
their data science team set called the incredible growth of Python.

00:24:55.800 --> 00:24:56.820
And they predicted,

00:24:56.820 --> 00:24:57.440
Oh,

00:24:57.440 --> 00:24:59.220
Python's going to overtake some of these languages.

00:24:59.220 --> 00:25:00.960
And you're not going to believe it.

00:25:00.960 --> 00:25:02.580
It's going to be more popular than JavaScript,

00:25:02.580 --> 00:25:04.560
more popular than Java.

00:25:04.560 --> 00:25:04.980
And people are like,

00:25:05.040 --> 00:25:05.540
no way.

00:25:05.540 --> 00:25:07.420
This has got to be something wrong with the data.

00:25:07.420 --> 00:25:08.360
And obviously,

00:25:08.360 --> 00:25:09.160
here we are,

00:25:09.160 --> 00:25:10.040
you know,

00:25:10.040 --> 00:25:11.260
in 2021,

00:25:11.260 --> 00:25:13.340
where I think they underestimated.

00:25:13.340 --> 00:25:13.680
Honestly,

00:25:13.680 --> 00:25:16.100
I don't want to have the exact picture in my mind,

00:25:16.100 --> 00:25:19.240
but I'm pretty sure they underestimated the last couple of years,

00:25:19.240 --> 00:25:20.200
which is pretty interesting.

00:25:20.200 --> 00:25:21.460
But that's not what I want to talk about.

00:25:21.760 --> 00:25:23.840
What I want to talk about is that 2012,

00:25:23.840 --> 00:25:24.740
you know,

00:25:24.740 --> 00:25:27.100
Python had been around for at that time,

00:25:27.100 --> 00:25:28.460
25 years or something.

00:25:28.460 --> 00:25:29.680
It was well known.

00:25:29.680 --> 00:25:31.360
It was a fairly popular language,

00:25:31.360 --> 00:25:33.060
but it was kind of just steady state.

00:25:33.060 --> 00:25:37.520
And then it's like somebody just lit the afterburner on that language.

00:25:37.520 --> 00:25:38.200
And it just,

00:25:38.200 --> 00:25:38.880
you know,

00:25:38.880 --> 00:25:41.580
it just started going up and up right around that time.

00:25:41.580 --> 00:25:44.480
And this is the time that you got into Python as well,

00:25:44.480 --> 00:25:45.120
more or less,

00:25:45.120 --> 00:25:45.360
right?

00:25:45.360 --> 00:25:45.900
Absolutely.

00:25:45.900 --> 00:25:52.340
I feel like so many people came from these not traditional programming spaces.

00:25:52.340 --> 00:25:52.680
I mean,

00:25:52.680 --> 00:25:53.620
still interested in programming,

00:25:53.620 --> 00:25:57.100
but not like a CS degree type of programming in.

00:25:57.100 --> 00:26:01.380
And it just brought so much diversity in terms of the problems being solved.

00:26:01.380 --> 00:26:04.120
And I think this graph is exactly what's happening here.

00:26:04.120 --> 00:26:05.020
It sounds like you're part of that,

00:26:05.020 --> 00:26:06.340
making that curve go up there.

00:26:06.340 --> 00:26:06.720
Yes.

00:26:06.720 --> 00:26:07.200
Yeah,

00:26:07.200 --> 00:26:07.780
I guess so.

00:26:07.780 --> 00:26:09.680
And I think for me as well,

00:26:09.680 --> 00:26:11.020
when Pandas came out,

00:26:11.020 --> 00:26:12.920
I think around in 2012 for working with,

00:26:12.920 --> 00:26:13.120
you know,

00:26:13.120 --> 00:26:14.240
data frames as objects,

00:26:14.240 --> 00:26:15.320
I've used R.

00:26:15.320 --> 00:26:18.540
I really liked that kind of data frame feature in R initially.

00:26:18.540 --> 00:26:22.320
And it was a little bit frustrating before Pandas was a thing,

00:26:22.320 --> 00:26:23.400
being able to,

00:26:23.400 --> 00:26:24.380
having to deal with,

00:26:24.380 --> 00:26:24.580
you know,

00:26:24.580 --> 00:26:28.100
CSV files and having to treat them as lists and indexing.

00:26:28.100 --> 00:26:30.400
So when Pandas became a thing,

00:26:30.620 --> 00:26:34.520
that was almost one of the big reasons I pushed into using Python for so much.

00:26:34.520 --> 00:26:37.320
And I still feel like I've been using Pandas for,

00:26:37.320 --> 00:26:37.860
yeah,

00:26:37.860 --> 00:26:39.360
I guess eight or nine years.

00:26:39.360 --> 00:26:42.220
And I'm pretty sure the project I'm on currently,

00:26:42.220 --> 00:26:46.160
I'm pretty sure I've learned a few extra things about the library just in the last couple of weeks.

00:26:46.160 --> 00:26:46.540
Yeah.

00:26:46.540 --> 00:26:47.620
It's crazy how that works,

00:26:47.620 --> 00:26:47.820
right?

00:26:47.820 --> 00:26:48.100
You're like,

00:26:48.100 --> 00:26:48.880
I've been doing this forever.

00:26:48.880 --> 00:26:51.440
How did I not know about this part of it?

00:26:51.440 --> 00:26:51.620
Right?

00:26:51.620 --> 00:26:52.100
Absolutely.

00:26:52.100 --> 00:26:52.840
Amazing.

00:26:52.840 --> 00:26:53.300
Amazing.

00:26:53.300 --> 00:26:54.020
All right.

00:26:54.140 --> 00:26:54.540
Well,

00:26:54.540 --> 00:26:55.920
super cool project you had there.

00:26:55.920 --> 00:26:57.060
Let's talk about energy.

00:26:57.060 --> 00:27:01.120
So you work for the Australian Energy Market Commission?

00:27:01.120 --> 00:27:01.560
Yes.

00:27:01.700 --> 00:27:01.920
Yeah.

00:27:01.920 --> 00:27:02.480
What's this?

00:27:02.480 --> 00:27:02.980
What do you do there?

00:27:02.980 --> 00:27:06.620
You can almost think of them as the rulemaker for the energy market.

00:27:06.620 --> 00:27:08.880
We don't run the energy market.

00:27:08.880 --> 00:27:10.520
That's the Australian Energy Market Operator.

00:27:10.920 --> 00:27:17.380
But they effectively pass the legislation that determines how people have to act within the

00:27:17.380 --> 00:27:17.980
energy market.

00:27:17.980 --> 00:27:23.120
The reason I really joined the organization was because when I was working in consulting,

00:27:23.120 --> 00:27:24.980
I started doing work in the energy sector.

00:27:24.980 --> 00:27:30.380
And I do work for energy retailers, the people that you pay for your electricity.

00:27:30.380 --> 00:27:32.380
I just work for some industrial companies.

00:27:33.040 --> 00:27:38.880
And one of the things I found was when I bumped into the wholesale energy data, it was almost

00:27:38.880 --> 00:27:40.960
like this, what was it?

00:27:40.960 --> 00:27:43.400
The, you know, the city of gold in some way.

00:27:43.400 --> 00:27:51.600
It was immense amounts of reasonably well-structured and cleansed data where the limitation wasn't,

00:27:51.600 --> 00:27:53.700
you know, the data or cleaning it.

00:27:53.700 --> 00:27:58.040
The limitation was understanding the domain well enough to do interesting things with it.

00:27:58.040 --> 00:27:58.320
Right.

00:27:58.320 --> 00:27:58.680
Okay.

00:27:58.680 --> 00:28:03.340
And so that's really became my obsession was to learn as much as I could.

00:28:03.340 --> 00:28:06.360
So I could actually do more and more interesting things with the data.

00:28:06.360 --> 00:28:13.580
And so the reason I joined the AAMC was because it's one of the most amazing workplaces in terms

00:28:13.580 --> 00:28:19.100
of the capability of everyone there is so passionate and incredible at what they do.

00:28:19.100 --> 00:28:25.020
And so just being around these people and learning from them is just an experience in itself.

00:28:25.020 --> 00:28:25.400
Yeah.

00:28:25.400 --> 00:28:25.960
Fantastic.

00:28:25.960 --> 00:28:27.440
That sounds super interesting.

00:28:27.640 --> 00:28:30.840
And it sounds like things like your network experience, you know, there's probably a lot

00:28:30.840 --> 00:28:33.620
of networks and energy and suppliers and whatnot.

00:28:33.620 --> 00:28:35.040
There might go together.

00:28:35.040 --> 00:28:35.900
Absolutely.

00:28:35.900 --> 00:28:36.380
Yeah.

00:28:36.380 --> 00:28:42.300
Basically there's, it's kind of a market that they set the price energy and then generators

00:28:42.300 --> 00:28:47.340
like private companies that are, you know, have power plants and solar forms and whatnot.

00:28:47.340 --> 00:28:52.560
They can decide whether or not they want to participate at that very moment in the grid or how does

00:28:52.560 --> 00:28:52.820
it work?

00:28:52.820 --> 00:28:53.600
Yeah, absolutely.

00:28:53.600 --> 00:28:56.800
So yeah, this is one of the fascinating things about the wholesale energy market.

00:28:57.200 --> 00:29:02.400
You can almost think that every five minutes, the market operator is effectively running

00:29:02.400 --> 00:29:08.300
an auction where all power stations around on the East Coast of Australia are bidding in

00:29:08.300 --> 00:29:12.640
bids for how much they were willing to sell different volumes of electricity at.

00:29:12.640 --> 00:29:19.820
So for instance, a wind farm might say that they will sell this volume of power quite cheaply,

00:29:19.820 --> 00:29:25.160
whereas a gas generator that has quite a high cost of fuel will set a higher price.

00:29:25.160 --> 00:29:31.960
And the market operator will take all of these bids and it knows the locations of these generators.

00:29:31.960 --> 00:29:35.860
It knows the capabilities of the transmission lines and the network.

00:29:35.860 --> 00:29:42.440
And it will run this linear optimization to figure out, okay, what is the cheapest mix of

00:29:42.440 --> 00:29:48.180
generators that I should dispatch to satisfy demand while still making sure the network is secure?

00:29:48.380 --> 00:29:48.600
Okay.

00:29:48.600 --> 00:29:51.400
So it's like trying to optimize certain goals.

00:29:51.400 --> 00:29:55.480
Like we are going to need however much energy in the grid at this very moment.

00:29:55.480 --> 00:30:00.800
And these people are willing to supply it at this, like, you know, who do we take however

00:30:00.800 --> 00:30:05.160
much energy from until we get like both enough people that are willing to participate from a

00:30:05.160 --> 00:30:08.140
financial perspective and then what people also need, huh?

00:30:08.220 --> 00:30:09.000
Yes, absolutely.

00:30:09.000 --> 00:30:14.260
And that's the thing that's so fascinating about this market is that at all times, supply

00:30:14.260 --> 00:30:16.160
and demand have to be matched.

00:30:16.160 --> 00:30:20.920
Very, very carefully because it'll break the grid if there's, well, too much is probably

00:30:20.920 --> 00:30:23.300
worse than too little because you just get a brownout, right?

00:30:23.300 --> 00:30:25.100
But too much could destroy things, right?

00:30:25.100 --> 00:30:25.460
Yeah.

00:30:25.460 --> 00:30:26.760
You don't want too much.

00:30:26.760 --> 00:30:31.740
If you have too much, then you need generators to start to try and reduce the output.

00:30:31.740 --> 00:30:36.000
And at the same time, if you have too little, then it can also create problems.

00:30:36.000 --> 00:30:43.360
And in fact, the grid has to be kept at this such a precise level of balance that if it

00:30:43.360 --> 00:30:47.940
actually you have too much or too little for too long, it will damage the machines that are

00:30:47.940 --> 00:30:48.640
connected to it.

00:30:48.640 --> 00:30:53.300
And in fact, to protect themselves, you will actually see them start to disconnect and it

00:30:53.300 --> 00:30:55.860
can actually create these kind of cascading problems.

00:30:55.860 --> 00:31:05.100
So unless you, we actually had a fascinating example recently in Queensland where a turbine,

00:31:05.240 --> 00:31:12.140
a coal turbine blew up and it then tripped a whole bunch of other coal power stations that

00:31:12.140 --> 00:31:15.320
then couldn't, that then stopped creating load.

00:31:15.320 --> 00:31:21.060
And so you suddenly had this situation where you had all this demand for electricity and

00:31:21.060 --> 00:31:24.160
suddenly they just lost all of this generation ability.

00:31:24.160 --> 00:31:28.460
And what actually happened is the system just started disconnecting.

00:31:28.460 --> 00:31:29.860
Well, it caused a blackout.

00:31:30.100 --> 00:31:34.080
But there was this automated system in a fraction of a second that just started disconnecting

00:31:34.080 --> 00:31:39.400
load or demand to try and balance it as quickly as possible to try and arrest the problem.

00:31:39.400 --> 00:31:50.280
So, and one of the things I've actually been doing has been looking at this at like a, on a four second basis, the events that happened on this day and how different units responded to these events.

00:31:50.440 --> 00:31:51.180
It's amazing.

00:31:51.180 --> 00:31:54.540
Like there's, there's almost like the energy sector and the market.

00:31:54.540 --> 00:31:59.900
It's almost like there's the physical infrastructure of make and making everything work and all that amazing engineering.

00:31:59.900 --> 00:32:04.580
And then there's the financial market and the bids and everything like that, that's built on top of it.

00:32:04.780 --> 00:32:10.340
And the market and the bids are fascinating, but at the end of the day, everything has to bow to the engineering.

00:32:10.340 --> 00:32:11.320
It has to work.

00:32:11.320 --> 00:32:11.520
Right.

00:32:11.520 --> 00:32:12.320
It has to work.

00:32:12.320 --> 00:32:12.560
Yeah.

00:32:12.560 --> 00:32:13.180
Yeah.

00:32:13.180 --> 00:32:14.380
Or it's all just going to come apart.

00:32:14.380 --> 00:32:15.140
Interesting.

00:32:15.140 --> 00:32:15.900
Yeah.

00:32:15.900 --> 00:32:20.820
AR out in the live stream says, is AEMC doing anything with energy web?

00:32:20.820 --> 00:32:24.680
I'm not sure if I've come across that before, but I'd be interested in looking into it.

00:32:24.680 --> 00:32:25.000
Yeah.

00:32:25.000 --> 00:32:29.800
And then also, it sounds like DERMS, what you're describing or D-E-R-E-M-S.

00:32:29.800 --> 00:32:31.300
I'm not sure whether, how you pronounce it.

00:32:31.300 --> 00:32:36.600
That might be something, an acronym from the, from the, the U.S. energy markets.

00:32:36.600 --> 00:32:38.760
Everyone has their own kind of different acronyms.

00:32:38.760 --> 00:32:40.160
Oh yeah.

00:32:40.160 --> 00:32:41.160
That makes it easy, right?

00:32:41.160 --> 00:32:42.460
To not even be consistent.

00:32:42.460 --> 00:32:47.420
If you go to the, the market operators website, they have a glossary page where you can just

00:32:47.420 --> 00:32:52.000
scroll for, for all those days on all the acronyms that are used in the sector.

00:32:52.000 --> 00:32:53.760
Probably like an acronym thesaurus.

00:32:53.760 --> 00:32:55.420
We call it this, what do they call it?

00:32:55.420 --> 00:32:56.140
Exactly.

00:32:56.140 --> 00:32:56.700
Exactly.

00:32:56.700 --> 00:33:01.180
This portion of Talk Python to Me is sponsored by Linode.

00:33:01.580 --> 00:33:06.220
Visit talkpython.fm/Linode to see why Linode has been voted the top infrastructure

00:33:06.220 --> 00:33:09.620
as a service provider by both G2 and TrustRadius.

00:33:09.620 --> 00:33:16.260
From their award-winning support, which is offered 24, 7, 365 to every level of user, to the ease

00:33:16.260 --> 00:33:20.500
of use and setup, it's clear why developers have been trusting Linode for projects both

00:33:20.500 --> 00:33:22.340
big and small since 2003.

00:33:22.600 --> 00:33:27.940
Deploy your entire application stack with Linode's one-click app marketplace, or build

00:33:27.940 --> 00:33:32.280
it all from scratch and manage everything yourself with supported centralized tools like Terraform.

00:33:32.280 --> 00:33:38.520
Linode offers the best price-to-performance value for all compute instances, including GPUs,

00:33:38.520 --> 00:33:42.900
as well as block storage, Kubernetes, and their upcoming bare metal release.

00:33:43.840 --> 00:33:48.800
Linode makes cloud computing fast, simple, and affordable, allowing you to focus on your

00:33:48.800 --> 00:33:50.660
projects, not your infrastructure.

00:33:50.660 --> 00:33:55.960
Visit talkpython.fm/Linode and sign up with your Google account, your GitHub account,

00:33:55.960 --> 00:33:59.100
or your email address, and you'll get $100 in credit.

00:33:59.100 --> 00:34:04.200
That's talkpython.fm/Linode, or just click the link in your podcast player's show notes.

00:34:04.200 --> 00:34:06.160
And thank them for supporting Talk Python.

00:34:06.160 --> 00:34:13.320
So we have on the graph here, this picture on the screen, where energy went negative, actually.

00:34:13.320 --> 00:34:18.680
And so this is where people are willing to pay to take energy that you've generated?

00:34:18.680 --> 00:34:20.580
Like, that sounds completely insane.

00:34:20.580 --> 00:34:21.180
Yeah, I know.

00:34:21.180 --> 00:34:21.840
It sounds weird.

00:34:21.840 --> 00:34:27.420
So yeah, to explain this figure, what's been happening this year in South Australia, the

00:34:27.420 --> 00:34:34.960
wholesale price of electricity has been around, averaged around negative $20 during the middle

00:34:34.960 --> 00:34:36.640
of the day, pretty much consistently.

00:34:36.640 --> 00:34:42.860
And so the way this works is because the generators submit bids for how much they're willing to

00:34:42.860 --> 00:34:47.540
sell their electricity for, because they'll effectively, when they run the optimization,

00:34:47.540 --> 00:34:52.160
the price of the bid that satisfies demand is the price that everyone gets paid.

00:34:52.160 --> 00:34:58.640
So what a lot of generators will do is they'll bid in quite cheaply at negative prices so that

00:34:58.640 --> 00:35:00.700
they're sure that they will get dispatched.

00:35:00.700 --> 00:35:04.960
But if everyone bids in a negative prices, then everyone gets the negative price.

00:35:04.960 --> 00:35:09.620
And so what we've actually been seeing is because there's now so much generation in the middle

00:35:09.620 --> 00:35:13.480
of the day, you're ending up with these really fascinating market events.

00:35:13.480 --> 00:35:18.200
Like, yeah, these negative prices where literally you can get paid to consume electricity.

00:35:18.540 --> 00:35:20.020
As a consumer, that sounds pretty good.

00:35:20.020 --> 00:35:22.740
You know, get it nice and chilly and we'll all be fine.

00:35:22.740 --> 00:35:23.020
True.

00:35:23.020 --> 00:35:23.960
Yeah, that's true.

00:35:23.960 --> 00:35:28.580
One of the drivers of this, it sounds to me like, is solar energy in Australia, right?

00:35:28.580 --> 00:35:29.040
Yes.

00:35:29.040 --> 00:35:29.520
Yes.

00:35:29.520 --> 00:35:31.400
We now have so much rooftop solar.

00:35:31.400 --> 00:35:35.020
I can't remember the exact percentage, but a significant percentage of Australian households

00:35:35.020 --> 00:35:39.080
now have solar panels because the cost has come down so much.

00:35:39.080 --> 00:35:44.480
And so a lot of our work has involved looking at how that is impacting the grid.

00:35:44.480 --> 00:35:50.760
Because if you imagine historically the energy market, it was a process where, you know, the

00:35:50.760 --> 00:35:54.200
market operator could instruct generators to turn on or turn off.

00:35:54.200 --> 00:35:58.840
And now we're in a world where there's so much of these kind of small scale solars that

00:35:58.840 --> 00:36:01.440
solar that you can't tell what to do.

00:36:01.440 --> 00:36:05.600
How do you factor that into balancing supply and demand in the grid?

00:36:05.600 --> 00:36:05.860
Yeah.

00:36:05.860 --> 00:36:09.680
Well, it definitely sounds like some interesting Python must be at play there.

00:36:09.680 --> 00:36:13.760
So give us an overview of sort of the kind of tools you're using, the types of problems

00:36:13.760 --> 00:36:14.180
you're solving.

00:36:14.180 --> 00:36:14.940
Yeah, sure.

00:36:14.940 --> 00:36:21.240
In the solar place, we've been using a Python, a software package called SAM, which is a system

00:36:21.240 --> 00:36:26.060
advisor model, which is actually released by the National Renewable Energy Laboratory

00:36:26.060 --> 00:36:27.180
in the States.

00:36:27.180 --> 00:36:32.960
And so what it lets you do is if you provide solar irradiance data and data from weather

00:36:32.960 --> 00:36:40.140
stations, you can use it to simulate the generation of rooftop in different areas around the country

00:36:40.140 --> 00:36:43.940
on a granular, on a half hourly basis over the course of the year.

00:36:43.940 --> 00:36:49.620
And so what this lets us do is I can use, they've got a Python library that lets me kind of call

00:36:49.620 --> 00:36:51.040
and run this tool.

00:36:51.220 --> 00:36:57.460
And I can simulate different PV system sizes and different locations and angles and all

00:36:57.460 --> 00:36:59.140
for setups all around the country.

00:36:59.140 --> 00:37:03.220
So I can effectively simulate hundreds and hundreds of different PV systems.

00:37:03.440 --> 00:37:11.140
And if I combine that with how much the household is consuming and what the actual cost of electricity

00:37:11.140 --> 00:37:17.500
was and those half hourly intervals, you can suddenly build up a picture for the economic

00:37:17.500 --> 00:37:22.500
effect of different PV panels for different households around the country.

00:37:22.500 --> 00:37:23.240
Yeah, how interesting.

00:37:23.240 --> 00:37:24.600
Is this the right thing I pulled up here?

00:37:24.600 --> 00:37:25.360
This Pi Sam?

00:37:25.500 --> 00:37:25.720
Yes.

00:37:25.720 --> 00:37:32.720
And I will say that for your US listeners, the laboratory release all of the data for

00:37:32.720 --> 00:37:35.840
the US mainland in a format that's ready for you guys to go.

00:37:35.840 --> 00:37:41.760
I had to, a big part of my project was actually trying to turn the Australian data into a format

00:37:41.760 --> 00:37:43.580
that this program could understand.

00:37:43.580 --> 00:37:50.180
And that in itself was an interesting exercise in data cleaning and manipulation because, for

00:37:50.180 --> 00:37:56.180
instance, all of the data on the irradiance for the country came as tens of thousands of

00:37:56.180 --> 00:38:01.540
these text files that were just these kind of grids, which pretty much they said, each value

00:38:01.540 --> 00:38:05.600
represents a five by five kilometer grid on the Australian mainland.

00:38:05.600 --> 00:38:07.340
It starts at this coordinate.

00:38:07.340 --> 00:38:12.760
So I had to pretty much try and convert this text file into a map and then convert that into

00:38:12.760 --> 00:38:16.640
format so I could know where the house fell in that as well.

00:38:16.640 --> 00:38:17.140
Oh, wow.

00:38:17.140 --> 00:38:17.840
How interesting.

00:38:17.840 --> 00:38:23.960
Yeah, you're normally taking a bunch of text files and piecing those together in a map,

00:38:23.960 --> 00:38:25.340
but I guess you do.

00:38:25.340 --> 00:38:29.900
Eugene, who was on the show a little while ago about the life lessons from machine learning,

00:38:29.900 --> 00:38:32.200
brought an interesting quote.

00:38:32.200 --> 00:38:36.240
It was something to the effect of the data cleaning is not the grunt work.

00:38:36.240 --> 00:38:39.420
It is the work of so much of this, right?

00:38:39.540 --> 00:38:44.040
Like it's getting everything right, making sure it's correct, converting it, formatting it,

00:38:44.040 --> 00:38:46.940
and then you feed it off to the magic library and get the answer, right?

00:38:46.940 --> 00:38:47.240
Yep.

00:38:47.240 --> 00:38:48.100
Absolutely.

00:38:48.100 --> 00:38:54.340
And I think, yeah, the lessons that you learn from working with and cleaning the data often

00:38:54.340 --> 00:38:57.020
help inform your analysis later on.

00:38:57.220 --> 00:39:01.940
For instance, one of the things I was doing recently was I've been trying to correct for

00:39:01.940 --> 00:39:05.980
errors in this really large data set measuring output from these power stations.

00:39:05.980 --> 00:39:14.580
And so one of the pieces of advice I received was that if I see a data where the generation

00:39:14.580 --> 00:39:19.800
value from the power station does not change, it effectively says this power station is generating

00:39:19.800 --> 00:39:25.520
100 megawatts and that value doesn't change for more than a minute, for at least a minute,

00:39:25.520 --> 00:39:28.040
that means there's an error in the data collection.

00:39:28.040 --> 00:39:34.000
And so as I was cleaning up the data and I implemented that and I started looking for outliers,

00:39:34.000 --> 00:39:41.460
and I actually discovered that you could see for some solar farms that it looks like if I

00:39:41.460 --> 00:39:46.900
used this metric that I'd implemented to pick out the bad data, it was actually removing

00:39:46.900 --> 00:39:54.440
cases where the power station, the solar farm was deliberately keeping their output perfectly

00:39:54.440 --> 00:39:57.480
level to match this instruction from the market operator.

00:39:57.480 --> 00:40:03.960
And so I think this is a case where they were actually foregoing additional generation to be

00:40:03.960 --> 00:40:04.660
more predictable.

00:40:04.660 --> 00:40:09.460
And I would have missed this whole interesting power station behavior if I just, you know,

00:40:09.560 --> 00:40:14.520
if I wasn't thinking about what the implications were of these different, you know, cleaning

00:40:14.520 --> 00:40:15.760
techniques that I was doing.

00:40:15.760 --> 00:40:16.040
Okay.

00:40:16.040 --> 00:40:16.480
Yeah.

00:40:16.480 --> 00:40:22.200
Because maybe that advice comes from, I don't know, a gas power plant or a coal plant where

00:40:22.200 --> 00:40:25.620
they have to fluctuate because, you know, whatever reason, right?

00:40:25.620 --> 00:40:31.280
And this new world, the assumptions changed or the situation changed and the assumptions didn't,

00:40:31.280 --> 00:40:31.500
right?

00:40:31.500 --> 00:40:32.000
Absolutely.

00:40:32.000 --> 00:40:32.740
Absolutely.

00:40:32.740 --> 00:40:39.120
And I think, yeah, like in a way, like part of the reason I think I've always gravitated towards

00:40:39.120 --> 00:40:44.680
being passionate about combining the programming and the analytics with like deep domain expertise

00:40:44.680 --> 00:40:50.220
is that I really love when I'm working with the data set, when I see something weird, I

00:40:50.220 --> 00:40:52.880
love that I can go, that's wrong.

00:40:52.880 --> 00:40:55.180
I can remove that or that looks weird.

00:40:55.180 --> 00:40:57.360
I'm going to investigate this because I think that's interesting.

00:40:57.820 --> 00:41:02.780
And one of the things I found in consulting was the projects where I didn't understand

00:41:02.780 --> 00:41:09.660
the data or the industry as well were always a bit, and I was brought into the team to provide,

00:41:09.660 --> 00:41:14.820
you know, the analytics capability, but I was effectively, you know, turning the understanding

00:41:14.820 --> 00:41:15.960
of others into code.

00:41:16.260 --> 00:41:21.780
I've always found them a little bit less satisfying from a personal perspective because I didn't

00:41:21.780 --> 00:41:27.000
feel like I was the one who was really, you know, getting, I felt like I was a vehicle other

00:41:27.000 --> 00:41:28.800
people turn their thoughts into code.

00:41:28.800 --> 00:41:33.680
Whereas I really like that if I understand the domain, then suddenly I can investigate and

00:41:33.680 --> 00:41:35.920
understand the area that I'm working in.

00:41:35.920 --> 00:41:36.120
Yeah.

00:41:36.200 --> 00:41:41.840
It becomes a puzzle, not just, I don't know, just more, get information from these people,

00:41:41.840 --> 00:41:43.560
apply it to the data, see what comes out.

00:41:43.560 --> 00:41:44.140
Yeah, for sure.

00:41:44.140 --> 00:41:47.560
You know, someone asked me recently, they were looking to hire somebody.

00:41:47.560 --> 00:41:51.460
It was, I don't know if it was exactly in the data science world, but it's close enough.

00:41:51.460 --> 00:41:56.800
They were asking something to the effect of, should I go and try to find a computer science

00:41:56.800 --> 00:42:03.780
type of background person who I can then teach the subject matter to and kind of get them

00:42:03.780 --> 00:42:05.840
up to speed there because we need good programmers.

00:42:05.840 --> 00:42:10.040
Or should I find some people who really understand what we're doing and then try to teach them

00:42:10.040 --> 00:42:10.340
Python?

00:42:10.340 --> 00:42:10.940
Yeah.

00:42:10.940 --> 00:42:12.040
What would you say to that?

00:42:12.040 --> 00:42:14.740
I had a thought on it, but I'd love to hear yours.

00:42:14.740 --> 00:42:21.560
I think to a certain extent, the experience, you want to have, I guess, the passion for learning

00:42:21.560 --> 00:42:22.580
about the domain.

00:42:22.580 --> 00:42:27.520
And obviously, if they understand the domain, that's really valuable, but you probably want

00:42:27.520 --> 00:42:31.820
them to be exposed at least a little bit to some programming concepts for them to know

00:42:31.820 --> 00:42:32.580
that they like it.

00:42:32.940 --> 00:42:38.020
In fact, I remember when I had a chat with my former boss who hired me into my current

00:42:38.020 --> 00:42:38.340
role.

00:42:38.340 --> 00:42:44.260
And he said that he's hiring philosophy is he looks for people with interesting backgrounds.

00:42:44.260 --> 00:42:47.920
You know, my background, he saw computational biology.

00:42:47.920 --> 00:42:52.020
And, you know, a lot of people would be like, oh, how does that apply to the energy sector?

00:42:52.020 --> 00:42:52.340
Yeah.

00:42:52.340 --> 00:42:52.760
That does.

00:42:52.760 --> 00:42:53.960
That's not for us.

00:42:53.960 --> 00:42:55.480
That's something totally different, right?

00:42:55.640 --> 00:42:56.040
Exactly.

00:42:56.040 --> 00:42:59.720
But he said, you know, for him, that's an interesting story.

00:42:59.720 --> 00:43:02.940
And he could see how those skills can generalize to different areas.

00:43:02.940 --> 00:43:06.480
And then it's more about, are you passionate about the thing you're working on as well?

00:43:06.480 --> 00:43:09.520
So like, I think people can learn, you know, people with domain expertise.

00:43:09.520 --> 00:43:14.660
I think learning Python can be like adding a bit of a superpower to your, you know, your

00:43:14.660 --> 00:43:16.740
skills and domain skills as well.

00:43:16.740 --> 00:43:21.280
But I also think that you wouldn't want to say, for instance, you wouldn't want to hire

00:43:21.280 --> 00:43:26.820
someone who had good domain expertise into the team to be a programmer who'd never programmed

00:43:26.820 --> 00:43:29.240
before and discovered they hated programming as well.

00:43:29.240 --> 00:43:29.440
Yeah.

00:43:29.440 --> 00:43:33.960
I think the assumption was that they had a little bit of programming experience or they were super

00:43:33.960 --> 00:43:35.960
interested in it, but maybe not all the way there.

00:43:35.960 --> 00:43:39.620
I think the subject matter expertise is really valuable.

00:43:39.620 --> 00:43:46.000
It's, I think these days there's so many amazing libraries and Python so accessible that it's

00:43:46.000 --> 00:43:49.460
really important to understand like deeply what's happening.

00:43:49.460 --> 00:43:53.840
But you should probably also have one or two people who have like a true software engineer

00:43:53.840 --> 00:43:57.220
experience like, hey, has anybody told anyone around here about Git?

00:43:57.220 --> 00:43:58.660
We need to be using source control.

00:43:58.660 --> 00:43:59.940
And what about continuous integration?

00:43:59.940 --> 00:44:01.440
And have you heard of testing, right?

00:44:01.440 --> 00:44:03.020
Like those kinds of things matter.

00:44:03.020 --> 00:44:06.820
But I think also having this like deep understanding of it really matters.

00:44:06.820 --> 00:44:07.320
Absolutely.

00:44:07.320 --> 00:44:08.300
Cool.

00:44:08.300 --> 00:44:08.780
Cool.

00:44:08.780 --> 00:44:08.820
Cool.

00:44:08.820 --> 00:44:08.820
Cool.

00:44:09.220 --> 00:44:09.660
All right.

00:44:09.660 --> 00:44:13.400
So are there, I mean, you talked about this system advisor model.

00:44:13.400 --> 00:44:18.960
Are there other things like in say the astronomy space, there's AstroPy, like all the astronomers

00:44:18.960 --> 00:44:20.940
talk about, this is the library.

00:44:20.940 --> 00:44:26.080
These are the things you talked about pandas and numpy and whatnot already, but is there something

00:44:26.080 --> 00:44:29.000
like that or a couple of libraries like that in the energy space?

00:44:29.000 --> 00:44:32.980
The closest I would probably say is the Pyomo optimization library.

00:44:32.980 --> 00:44:36.780
So that I think Clark mentioned in a previous interview.

00:44:36.780 --> 00:44:37.560
Yeah, yeah.

00:44:37.660 --> 00:44:39.460
We had Clark come on to talk about that.

00:44:39.460 --> 00:44:41.020
And he was doing really cool stuff.

00:44:41.020 --> 00:44:41.900
Clark, yeah.

00:44:41.900 --> 00:44:46.400
I'm trying to, I'm going to set up a chat with our team with Clark.

00:44:46.400 --> 00:44:47.900
And that's the plan at a later date.

00:44:47.900 --> 00:44:53.000
Because, yeah, it was very interesting that what he was able to do during his masters with

00:44:53.000 --> 00:44:54.300
linear optimization.

00:44:54.900 --> 00:45:00.640
And so I think, yeah, like really, there may be libraries out there that I haven't come

00:45:00.640 --> 00:45:01.900
across yet at this point.

00:45:01.900 --> 00:45:07.960
But I've really found that the whole, yeah, the Python stack of your pandas, Pyomo for

00:45:07.960 --> 00:45:13.380
optimizations, and even things like, have you come across a library called Geopandas at all?

00:45:13.380 --> 00:45:13.820
Yes.

00:45:14.000 --> 00:45:16.400
Which adds spatial elements to data frames.

00:45:16.400 --> 00:45:18.020
I use that for a lot of analysis.

00:45:18.020 --> 00:45:18.280
Yeah.

00:45:18.280 --> 00:45:19.420
Geopandas sounds cool.

00:45:19.420 --> 00:45:23.000
I haven't done anything with it, but I would love an opportunity to do something fun with

00:45:23.000 --> 00:45:23.540
Geopandas.

00:45:23.540 --> 00:45:26.360
I did that when I was working in consulting.

00:45:26.360 --> 00:45:30.880
I used that library once for looking at data from the Australian Bureau of Statistics.

00:45:30.880 --> 00:45:35.780
And then suddenly, I was in demand for every proposal to be making these heat maps of the

00:45:35.780 --> 00:45:36.160
country.

00:45:36.160 --> 00:45:40.160
I suddenly was just making, I had heat maps coming out everywhere.

00:45:40.460 --> 00:45:44.820
Yeah, they're like, if Jack knows how to make these graphs, give it to Jack.

00:45:44.820 --> 00:45:45.580
He'll build a flag.

00:45:45.580 --> 00:45:47.140
Exactly.

00:45:47.140 --> 00:45:51.960
But Geopandas, if you know a bit about using, you know, pandas and data frames for working

00:45:51.960 --> 00:45:56.360
with data sets, it's pretty much like using a pandas data frame, but it just adds a whole

00:45:56.360 --> 00:46:01.520
bunch of capability for working with spatial data sets and creating beautiful figures as

00:46:01.520 --> 00:46:01.660
well.

00:46:01.660 --> 00:46:03.040
It's amazing.

00:46:03.040 --> 00:46:03.420
Yeah.

00:46:03.420 --> 00:46:04.540
Oh, it sounds super cool.

00:46:04.540 --> 00:46:05.120
Super cool.

00:46:05.120 --> 00:46:05.280
Yeah.

00:46:05.280 --> 00:46:06.180
It works with Shapely.

00:46:06.440 --> 00:46:10.640
It sounds like it would work really well with your 10,000 text files almost even.

00:46:10.640 --> 00:46:11.240
Yeah.

00:46:11.240 --> 00:46:13.660
Some of those things linking it up.

00:46:13.660 --> 00:46:14.160
Yeah.

00:46:14.160 --> 00:46:14.420
Yeah.

00:46:14.420 --> 00:46:14.660
Yeah.

00:46:14.660 --> 00:46:17.280
Alexander out in the live streams coming back.

00:46:17.280 --> 00:46:20.200
Just one quick thought says, I wish people learned at least some programming.

00:46:20.200 --> 00:46:23.960
Making customs software to cover simple cases is definitely tiring.

00:46:23.960 --> 00:46:25.920
And most of the time, it's just a simple script.

00:46:25.920 --> 00:46:26.480
Yeah.

00:46:26.480 --> 00:46:30.100
I mean, kind of the automate the boring stuff could take a lot of people a long ways for sure.

00:46:30.100 --> 00:46:30.580
Yeah.

00:46:30.580 --> 00:46:31.220
At that level.

00:46:31.220 --> 00:46:31.700
Absolutely.

00:46:32.280 --> 00:46:36.360
In a way, a lot of the little things that I would go around and be useful for when I

00:46:36.360 --> 00:46:41.840
was working in consulting, if people had a little bit of programming background, then

00:46:41.840 --> 00:46:46.380
yeah, they almost wouldn't need my input because they understood the area better than me.

00:46:46.380 --> 00:46:52.160
And if they had a little bit of Python and knew how to link up some data sets, then it would

00:46:52.160 --> 00:46:56.520
be like they could just automate so much of some tedious things in their lives.

00:46:56.520 --> 00:47:01.980
One thing I heard a lot in that sort of realm was, if you automate all these things, you're

00:47:01.980 --> 00:47:02.920
going to take our jobs away.

00:47:02.920 --> 00:47:03.740
What are we going to do?

00:47:03.740 --> 00:47:07.960
Like this painful, tedious manual stuff that should be automated.

00:47:07.960 --> 00:47:12.160
Like that's our job because that's what a lot of the people that I had worked with for

00:47:12.160 --> 00:47:12.420
a while.

00:47:12.420 --> 00:47:13.460
That's what they did.

00:47:13.460 --> 00:47:18.540
And they were legitimately a little concerned that if we wrote software that would do those

00:47:18.540 --> 00:47:20.520
things automatically, well, then what would they do?

00:47:20.520 --> 00:47:23.280
And I saw year after year, we would write that software.

00:47:23.520 --> 00:47:26.220
They would say, thank goodness, we don't have to do this again.

00:47:26.220 --> 00:47:29.100
And they would just solve more problems, take on more data.

00:47:29.100 --> 00:47:33.040
Like they would just do more and almost never did it result in, well, we don't need these

00:47:33.040 --> 00:47:33.580
people anymore.

00:47:33.580 --> 00:47:36.760
It just meant they got to do more interesting stuff in a bigger scale.

00:47:36.760 --> 00:47:37.240
Absolutely.

00:47:37.240 --> 00:47:42.460
Like this is what I find that when I work with new data sets or problems, and once you've

00:47:42.460 --> 00:47:45.900
kind of, you know, solved the problem, you understand that data, you fix the issues with

00:47:45.900 --> 00:47:46.140
it.

00:47:46.140 --> 00:47:52.660
Suddenly having that kind of foundation and curated data set lets you actually build on it and do

00:47:52.660 --> 00:47:54.540
more interesting things going forward.

00:47:54.540 --> 00:47:55.840
It's not like, you know, you've done that.

00:47:55.840 --> 00:47:58.160
You can, you know, you never need to do that again.

00:47:58.160 --> 00:47:58.440
Yeah.

00:47:58.440 --> 00:48:01.960
And that's what drew me to the energy sector because it was like, the more I worked with

00:48:01.960 --> 00:48:05.680
these data sets, the more I understood and the more interesting questions I could answer,

00:48:05.680 --> 00:48:07.060
which is really satisfying.

00:48:07.060 --> 00:48:07.400
Yeah.

00:48:07.400 --> 00:48:07.660
Yeah.

00:48:07.660 --> 00:48:13.400
And the more things that are batch processes can become almost real time and really change

00:48:13.400 --> 00:48:13.560
things.

00:48:13.560 --> 00:48:17.720
So speaking of data, it sounds like you guys work with a ton of data over there.

00:48:17.720 --> 00:48:19.380
Give us a sense for the scale.

00:48:19.380 --> 00:48:19.700
Yeah.

00:48:19.700 --> 00:48:26.040
So I guess the more standard data set is there's a database that has pretty much everything

00:48:26.040 --> 00:48:29.060
going on in terms of dispatch on a five minute basis.

00:48:29.060 --> 00:48:32.820
And so for most of your users, if you just want to see what the power station is doing,

00:48:32.820 --> 00:48:34.400
what it's bidding, you can use that data.

00:48:34.400 --> 00:48:39.460
It's large, like pulling out some of these data sets in, it's in, you know, a hundred or

00:48:39.460 --> 00:48:41.680
200 million rows looking at certain parts of it.

00:48:42.000 --> 00:48:46.200
But the thing I'm working on at the moment, it almost makes this kind of look small.

00:48:46.200 --> 00:48:50.920
And this is kind of that same data from that same database, but it's on a four second basis.

00:48:50.920 --> 00:48:55.540
So a single month of data is about 750 million rows.

00:48:55.540 --> 00:49:00.660
And it gets all released as thousands of zip holders containing CSVs.

00:49:00.660 --> 00:49:02.360
One CSV for every half hour.

00:49:02.360 --> 00:49:04.040
Oh my goodness.

00:49:04.040 --> 00:49:08.340
And so is there like a big process that just goes along, unzips it, grabs it, inserts it

00:49:08.340 --> 00:49:10.420
into some database or something along those lines?

00:49:10.420 --> 00:49:13.080
I think that was how it gets shared in some format.

00:49:13.080 --> 00:49:16.800
So what I actually, so this is how I was given the data on my current project.

00:49:16.800 --> 00:49:20.380
And so it's so big, I can't actually unzip it on the machine.

00:49:20.380 --> 00:49:25.820
So I have to use Python to kind of spin up a number of separate processes that will kind

00:49:25.820 --> 00:49:28.340
of work through the different zip folders.

00:49:28.340 --> 00:49:31.600
It will then use, I think Python has a library called zip file.

00:49:31.600 --> 00:49:37.920
So it will unzip the folder in memory, read in the CSVs, process them, and then it will

00:49:37.920 --> 00:49:44.280
eventually concatenate it all back into a cleaned data frame that I can work with going forward.

00:49:44.280 --> 00:49:49.320
And so, and so then I'm trying to use those sets of tools to try and then turn this into

00:49:49.320 --> 00:49:53.100
a more compressed, cleaned data set that I can work with going forward.

00:49:53.100 --> 00:49:58.660
So does that fit in memory or do you have to like only pull out slices sort of dynamically

00:49:58.660 --> 00:49:59.940
with the zip file processing?

00:49:59.940 --> 00:50:00.400
Yeah.

00:50:00.400 --> 00:50:03.840
So I can fit about a month in memory on my machine.

00:50:03.840 --> 00:50:05.220
We do have some large servers.

00:50:05.220 --> 00:50:10.840
And so I will transition to processing this in parallel on the servers, which should get

00:50:10.840 --> 00:50:12.120
an even better speed up.

00:50:12.340 --> 00:50:15.740
But yeah, at the moment, I really just kind of look at things on a monthly basis.

00:50:15.740 --> 00:50:20.700
And so what I can actually do is, and then there's a ton of processing I have to do with

00:50:20.700 --> 00:50:26.540
this four second interval data, because what I can see is I will break the data up then into

00:50:26.540 --> 00:50:27.520
five minute intervals.

00:50:27.520 --> 00:50:31.660
And I, what I can do is I can see what the generator was doing on a four second basis.

00:50:31.660 --> 00:50:34.400
And then I can see what its target was.

00:50:34.400 --> 00:50:38.860
So when they run their optimization, they will say, we know you're sitting at this point here,

00:50:38.980 --> 00:50:43.080
you have to ramp up to hit this target here at the end of this five minute period.

00:50:43.080 --> 00:50:48.880
And so I can use this data to tell how well the generators are actually hitting their targets

00:50:48.880 --> 00:50:51.040
and how well they're following instructions.

00:50:51.040 --> 00:50:55.260
But the funny thing is, even though, you know, you think of four second data as being, you know,

00:50:55.260 --> 00:50:58.300
very, very, such a short interval of time.

00:50:58.300 --> 00:51:04.560
But if you look at some of the big batteries in the grid, that data is actually too slow for

00:51:04.560 --> 00:51:08.960
some of the batteries, because batteries can actually turn on, inject power into the grid.

00:51:08.960 --> 00:51:11.500
turn off again, and I can miss it in the four second data.

00:51:11.500 --> 00:51:12.620
It's amazing.

00:51:12.620 --> 00:51:19.320
Some of these big grid scale batteries are like the big Tesla battery in South Australia at

00:51:19.320 --> 00:51:19.800
Hornsdale.

00:51:19.800 --> 00:51:23.460
They're amazing feats of engineering that you really appreciate when you realize you're

00:51:23.460 --> 00:51:24.880
missing things at a four second interval.

00:51:24.880 --> 00:51:27.240
They break your sensors and things like that.

00:51:27.240 --> 00:51:32.260
Yeah, Australia is really well known for having some of these big batteries in the energy sector.

00:51:32.260 --> 00:51:36.740
I think for some reason, Tesla seemed to have partnered up with you guys to build these.

00:51:36.740 --> 00:51:42.400
Yeah, the plan is to roll out a bunch more of these batteries around the grid as well.

00:51:42.400 --> 00:51:44.120
And they're just really impressive.

00:51:44.120 --> 00:51:50.160
You know how I mentioned the whole challenge of constantly balancing supply and demand?

00:51:50.160 --> 00:51:52.700
And really, that's what batteries are so good at doing.

00:51:52.700 --> 00:51:53.200
Right.

00:51:53.200 --> 00:51:55.300
Their response time is almost instant.

00:51:55.300 --> 00:51:55.580
Yeah.

00:51:55.580 --> 00:51:57.680
So you could just, they could take it in.

00:51:57.680 --> 00:51:58.060
Exactly.

00:51:58.060 --> 00:52:02.560
They could eat the energy or they could initially fill, like immediately fill the gap, right?

00:52:02.560 --> 00:52:03.240
For a while.

00:52:03.240 --> 00:52:03.520
Exactly.

00:52:03.520 --> 00:52:08.300
And sometimes with some of this data, you can actually see the battery will receive an

00:52:08.300 --> 00:52:08.680
instruction.

00:52:08.680 --> 00:52:10.040
It will quickly turn on.

00:52:10.040 --> 00:52:11.300
It will discharge some power.

00:52:11.300 --> 00:52:16.060
And then a couple of seconds later, it will actually then, because there's too much power

00:52:16.060 --> 00:52:20.040
in the grid, the battery will actually then suck up some of that power and recharge and

00:52:20.040 --> 00:52:20.840
do the opposite effect.

00:52:20.840 --> 00:52:22.220
It's just amazing.

00:52:22.220 --> 00:52:22.500
Yeah.

00:52:22.500 --> 00:52:22.960
Fantastic.

00:52:23.080 --> 00:52:27.860
I would love to dive into that, but let's say I'm super fascinated with batteries and

00:52:27.860 --> 00:52:28.540
their potential.

00:52:28.540 --> 00:52:34.540
Talk Python to me is partially supported by our training courses.

00:52:34.540 --> 00:52:39.580
When you need to learn something new, whether it's foundational Python, advanced topics like

00:52:39.580 --> 00:52:46.260
async or web apps and web APIs, be sure to check out our over 200 hours of courses at Talk Python.

00:52:46.260 --> 00:52:51.160
And if your company's considering how they'll get up to speed on Python, please recommend they

00:52:51.160 --> 00:52:52.280
give our content a look.

00:52:52.660 --> 00:52:52.960
Thanks.

00:52:52.960 --> 00:52:59.500
With all of this data, you said that you had basically learned some good advice, like certain

00:52:59.500 --> 00:53:05.500
things you can just easily do in Pandas and NumPy on small data sets, maybe not so much on

00:53:05.500 --> 00:53:07.060
large data sets like that.

00:53:07.060 --> 00:53:10.460
Give us some of the things that you found to be useful and some of the tips and tricks.

00:53:10.460 --> 00:53:10.920
Absolutely.

00:53:10.920 --> 00:53:13.700
So there's a concept called vectorization.

00:53:13.700 --> 00:53:17.800
I'm not sure if you've come across it, but it's effectively, how can you apply an operation

00:53:17.800 --> 00:53:18.820
to a whole column?

00:53:18.820 --> 00:53:22.580
So you're not writing a manual loop or using conditionals.

00:53:22.580 --> 00:53:28.860
For instance, if I try to multiply a column with millions of rows by a number, it's really,

00:53:28.860 --> 00:53:32.480
really fast because that's all kind of optimized to see under the hood.

00:53:32.480 --> 00:53:37.440
And so with a lot of this, when I'm working with smaller data sets, you can get away with

00:53:37.440 --> 00:53:42.000
doing some manual loops yourself or using Pandas to group by a column.

00:53:42.140 --> 00:53:46.340
For instance, I would often say, this is the identifier for a power station.

00:53:46.340 --> 00:53:52.000
I want you to group by this column identifier and then sum up.

00:53:52.000 --> 00:53:57.040
And even those things start to become too slow once your data is kind of at this scale.

00:53:57.040 --> 00:54:03.460
And so the real trick I find is, yeah, it's how do you find ways where you can apply some

00:54:03.460 --> 00:54:05.780
operation, a calculation to the whole column?

00:54:06.480 --> 00:54:10.000
And, but the tricky part with that starts to be what happens if you want to do conditional

00:54:10.000 --> 00:54:10.760
calculations?

00:54:10.760 --> 00:54:17.260
And so one of the things I find is sometimes I want to see how much the output of, on a four

00:54:17.260 --> 00:54:21.040
second basis, how much is the generation of a power station changing?

00:54:21.040 --> 00:54:27.600
And so you can imagine that Pandas has a calculation that lets you effectively calculate the difference

00:54:27.600 --> 00:54:31.000
between the previous value that came before really, really efficiently.

00:54:31.600 --> 00:54:36.840
But because, you know, I've got all these different generators and intervals, like kind of all

00:54:36.840 --> 00:54:41.540
in the same, you know, data frame, I don't want to consider the first value in a five minute

00:54:41.540 --> 00:54:46.220
interval, because that's affected by, you know, a different time interval as well.

00:54:46.220 --> 00:54:55.360
So what you can do is NumPy has these great functionality called where or select, where you can pretty much

00:54:55.360 --> 00:55:00.120
pass it a column that turns out to be true or false for the whole data set.

00:55:00.120 --> 00:55:04.480
And it will then replace the value with something else really efficiently.

00:55:04.480 --> 00:55:08.860
So what I can do is I can, I can run my calculation for the whole column.

00:55:08.860 --> 00:55:14.660
And then I can use a NumPy where to replace the first value in each five minute interval with a

00:55:14.660 --> 00:55:15.380
missing value.

00:55:15.380 --> 00:55:21.420
And that pretty much does things in, you know, a few seconds that would have taken, I don't

00:55:21.420 --> 00:55:23.960
even know how long with the other way hours, at least.

00:55:23.960 --> 00:55:24.220
Wow.

00:55:24.220 --> 00:55:24.800
It's amazing.

00:55:25.000 --> 00:55:30.360
Yeah, I think that the whole computational space with pandas and with NumPy's, there's,

00:55:30.360 --> 00:55:33.560
you know, like in Python, we speak about Pythonic code, right?

00:55:33.560 --> 00:55:37.560
You would use a foreign loop instead of trying to index into things and so on.

00:55:37.560 --> 00:55:41.860
And then there's a whole special flavor of that in the pandas world, right?

00:55:41.920 --> 00:55:47.140
And a lot of it almost has the guidance of if you're doing a for loop, you're doing it

00:55:47.140 --> 00:55:47.980
wrong, right?

00:55:47.980 --> 00:55:53.420
Like there should be some sort of vector operation or something passed into pandas or something

00:55:53.420 --> 00:55:54.520
along those lines, right?

00:55:54.520 --> 00:55:55.000
Absolutely.

00:55:55.000 --> 00:55:59.260
Like, yeah, it's almost like its own kind of type of problem solving in a way, because it's

00:55:59.260 --> 00:56:08.020
like, how can I apply this calculation to everything in a column, but also in these cases, do something

00:56:08.020 --> 00:56:08.320
else.

00:56:08.320 --> 00:56:10.460
That's really the problem solving in a lot of ways.

00:56:10.460 --> 00:56:11.040
Yeah.

00:56:11.040 --> 00:56:11.440
Yeah.

00:56:11.440 --> 00:56:14.080
It's a lot more set-based thinking, almost like databases.

00:56:14.080 --> 00:56:14.560
Yeah.

00:56:14.560 --> 00:56:18.520
What about things like threading or multiprocessing or stuff like that?

00:56:18.520 --> 00:56:22.520
Like, have you tried to scale out some of the things that you're doing in that way?

00:56:22.520 --> 00:56:27.980
So yeah, so we have a server that has about 60 cores and about 700 gig of RAM on it.

00:56:28.120 --> 00:56:31.640
So that's the plan is I can shift my things over there once this project-

00:56:31.640 --> 00:56:32.260
60 cores?

00:56:32.260 --> 00:56:34.120
That's pretty awesome, actually.

00:56:34.120 --> 00:56:34.380
Yeah.

00:56:34.380 --> 00:56:38.660
We've got a couple of them, which is very useful for all of the energy modeling that we do.

00:56:38.660 --> 00:56:46.500
And usually what I'm doing is kind of a mix of, yes, using Python's multiprocessing library

00:56:46.500 --> 00:56:49.260
to try and, yeah, just split.

00:56:49.260 --> 00:56:56.380
Usually what I'm doing is I'm just processing a whole heap of data frames in parallel and then

00:56:56.380 --> 00:57:00.020
concatenating them back into a single data frame once they're kind of processed.

00:57:00.020 --> 00:57:06.260
That workflow seems to work pretty well for a lot of the requirements that I have on projects.

00:57:06.260 --> 00:57:06.440
Yeah.

00:57:06.440 --> 00:57:12.020
Because you can get each subset data frame bit to do its own computation in parallel, right?

00:57:12.120 --> 00:57:12.360
Yes.

00:57:12.360 --> 00:57:13.740
Yeah, exactly.

00:57:13.740 --> 00:57:19.100
And the other thing too that can also benefit is that usually as part of the cleaning process,

00:57:19.100 --> 00:57:20.920
I'm kind of subsetting the data as well.

00:57:20.920 --> 00:57:27.740
So while the data is starting off at an immense size as well, I'm figuring out which parts of

00:57:27.740 --> 00:57:29.480
it I need and cleaning it.

00:57:29.480 --> 00:57:35.060
And then so then the data frame I end up concatenating back together can be a more manageable size as

00:57:35.060 --> 00:57:35.240
well.

00:57:35.400 --> 00:57:36.200
Right, right, right.

00:57:36.200 --> 00:57:36.560
Interesting.

00:57:36.560 --> 00:57:39.280
Have you looked at Dask for any of this?

00:57:39.280 --> 00:57:39.620
Yes.

00:57:39.620 --> 00:57:44.260
We've had, I did some work on the server for a different project looking at it.

00:57:44.260 --> 00:57:50.260
And I think Dask might be, once I've kind of built up a more curated version of this four

00:57:50.260 --> 00:57:55.960
second interval data, I think Dask will probably be what I'll use on the server for working with

00:57:55.960 --> 00:57:57.660
the whole data set in the future.

00:57:57.880 --> 00:57:58.000
Yeah.

00:57:58.000 --> 00:58:02.500
It sounds like it might really be, I mean, I haven't actually tried to apply to that much

00:58:02.500 --> 00:58:05.600
data that you got there, but it's sort of its functionality.

00:58:05.600 --> 00:58:10.240
It sounds like it really might be the thing to do because it'll take, it basically, your

00:58:10.240 --> 00:58:13.440
description of breaking into the many data frames, having them run and then bringing it back

00:58:13.440 --> 00:58:13.760
together.

00:58:13.760 --> 00:58:16.320
That sounds to me like what Dask is built for, right?

00:58:16.320 --> 00:58:16.580
Yeah.

00:58:16.580 --> 00:58:20.800
And the brilliance as well, I think of the Dask project is how they were able to kind of

00:58:20.800 --> 00:58:25.220
emulate the Python, sorry, the Pandas way of doing things as well, which is great because,

00:58:25.320 --> 00:58:30.720
you know, it's nice not to have to relearn too many things and be efficient from the beginning.

00:58:30.720 --> 00:58:36.100
Also, I should probably just flag as well that these data sets that I'm working with, the four

00:58:36.100 --> 00:58:40.120
second interval, and then the actual database on the five minute basis, one of the things

00:58:40.120 --> 00:58:45.140
that got me so into the energy sector, and that's, I think, unique in a way about the Australian

00:58:45.140 --> 00:58:48.900
energy market, although I stand to be corrected, is that this is all public data.

00:58:48.900 --> 00:58:53.720
If you want, you can go and download all of this data from the market operators website, which

00:58:53.720 --> 00:58:58.160
is, you know, an amazing amount of kind of openness to be able to go in and look at what

00:58:58.160 --> 00:59:02.380
these power stations are doing and what prices that we're getting on such a granular basis

00:59:02.380 --> 00:59:03.080
as well.

00:59:03.080 --> 00:59:05.140
That's been really what fascinated me.

00:59:05.140 --> 00:59:06.380
Yeah, that's super cool.

00:59:06.380 --> 00:59:11.000
You know, if people are out there trying to do research, working on a thesis or something

00:59:11.000 --> 00:59:12.620
like that, they could just grab this data.

00:59:12.620 --> 00:59:14.560
And it's like you said, it's real.

00:59:14.560 --> 00:59:18.860
And a lot of people have both physical machine reasons and financial reasons.

00:59:18.860 --> 00:59:19.740
Keep it accurate, right?

00:59:19.940 --> 00:59:20.700
Yes, absolutely.

00:59:20.700 --> 00:59:26.840
And really, I guess I come back to that original point where the limitation for this data isn't

00:59:26.840 --> 00:59:29.040
how clean it is or the amount of data.

00:59:29.040 --> 00:59:33.240
It's just understanding the processes well enough to know what you can do with it.

00:59:33.240 --> 00:59:33.520
Right.

00:59:33.520 --> 00:59:40.080
A little bit like that example you had about the solar farms versus coal generation, right?

00:59:40.080 --> 00:59:40.640
Exactly.

00:59:40.640 --> 00:59:41.180
Exactly.

00:59:41.180 --> 00:59:41.560
Yeah.

00:59:41.560 --> 00:59:42.860
Know that I mean different things.

00:59:42.860 --> 00:59:43.160
Yeah.

00:59:43.160 --> 00:59:43.720
Yeah.

00:59:43.720 --> 00:59:44.040
Very cool.

00:59:44.460 --> 00:59:44.680
All right.

00:59:44.680 --> 00:59:49.180
Other advice or interesting things going on before we're getting short on time, but

00:59:49.180 --> 00:59:50.340
anything else you want to throw out there?

00:59:50.340 --> 00:59:51.600
Work with all this data?

00:59:51.600 --> 00:59:55.840
One of the areas I'm quite interested in at the moment is Python's number library.

00:59:55.840 --> 00:59:57.620
N-U-M-V-A.

00:59:57.620 --> 00:59:57.800
Yeah.

00:59:57.800 --> 01:00:03.580
I think it uses the able to kind of compile Python code under the hood to get really high

01:00:03.580 --> 01:00:03.900
performance.

01:00:03.900 --> 01:00:06.720
And it can be perfect for my use.

01:00:06.720 --> 01:00:11.860
And the reason I'm rather interested in it is that if I can vectorize a calculation,

01:00:11.860 --> 01:00:13.640
you know how I'm applying it to the whole column.

01:00:13.640 --> 01:00:20.000
But for instance, if I'm trying to do some calculation where I want to loop through it

01:00:20.000 --> 01:00:25.560
because my current calculation depends on the state of a previous calculation, then that can

01:00:25.560 --> 01:00:29.000
be a limitation of this kind of vectorization approach.

01:00:29.000 --> 01:00:29.420
Whereas...

01:00:29.420 --> 01:00:29.880
Right, right.

01:00:29.940 --> 01:00:35.700
You can't just apply it to the set and go, hey, every row here, just look back at yourself

01:00:35.700 --> 01:00:38.840
a little bit in that place and then do the thing.

01:00:38.840 --> 01:00:42.060
It's got some dependencies on what happened before, right?

01:00:42.060 --> 01:00:44.040
And that, I have no idea how you would fix that.

01:00:44.040 --> 01:00:46.160
Maybe it's possible, but it's very tricky, right?

01:00:46.160 --> 01:00:47.540
And so number does that, okay?

01:00:47.540 --> 01:00:54.460
So number is effectively a way to write Python loops that run as fast as C, but within for

01:00:54.460 --> 01:00:55.460
numeric calculations.

01:00:55.460 --> 01:01:00.440
So this is why I'm very interested in this for some of the areas that are a little bit

01:01:00.440 --> 01:01:04.080
trickier for me to vectorize using data frames.

01:01:04.080 --> 01:01:08.200
I'm very interested in the number library as a solution for some of those challenges.

01:01:08.200 --> 01:01:08.460
Yeah.

01:01:08.460 --> 01:01:10.660
So number makes Python code fast.

01:01:10.660 --> 01:01:15.660
It says it's an open source JIT compiler that translates a subset of Python and NumPy

01:01:15.660 --> 01:01:17.340
code into fast machine code.

01:01:17.340 --> 01:01:22.320
So I haven't used it, but it sounds like it really knows about NumPy in addition, right?

01:01:22.320 --> 01:01:25.880
Because you could use Cython, but Cython doesn't necessarily know anything about NumPy, for

01:01:25.880 --> 01:01:26.600
example, right?

01:01:26.600 --> 01:01:26.920
Yes.

01:01:26.920 --> 01:01:28.540
Yeah, you're exactly right.

01:01:28.540 --> 01:01:33.780
Like in a way, number has kind of replaced what I would have used Cython for in the past,

01:01:33.780 --> 01:01:34.980
but for my application.

01:01:34.980 --> 01:01:40.000
What I could do, say for instance, if I have a NumPy array and I want to loop through it

01:01:40.000 --> 01:01:44.160
and there's some calculation I want to do and then my next calculation depends on that previous

01:01:44.160 --> 01:01:45.480
calculation going forward.

01:01:45.480 --> 01:01:47.100
This lets me do that.

01:01:47.200 --> 01:01:49.580
Yeah, in a way, and I'm writing Python code.

01:01:49.580 --> 01:01:51.040
I don't have to write C or C++.

01:01:51.040 --> 01:01:52.200
You can see it.

01:01:52.200 --> 01:01:58.500
You're literally adding decorators, just like how Flask has that lovely kind of decorator

01:01:58.500 --> 01:01:59.100
syntax.

01:01:59.100 --> 01:02:01.320
It's almost like that to an extent.

01:02:01.320 --> 01:02:01.980
Yeah, exactly.

01:02:01.980 --> 01:02:06.980
You say at number.jit and then do you want this to run in parallel or not?

01:02:06.980 --> 01:02:07.420
Yeah, sure.

01:02:07.420 --> 01:02:07.820
Why not?

01:02:07.820 --> 01:02:08.360
Exactly.

01:02:08.480 --> 01:02:12.980
And also it even lets you run your calculations in parallel as well.

01:02:12.980 --> 01:02:14.480
You can see that little parallelism true.

01:02:14.480 --> 01:02:19.360
And it's actually true parallelism without the GIL as well, which is amazing.

01:02:19.360 --> 01:02:20.660
Yeah, this is super interesting.

01:02:20.660 --> 01:02:25.420
I knew that it was a compiler along the lines of Cython, but I didn't realize that it had

01:02:25.420 --> 01:02:26.900
this special integration with NumPy.

01:02:26.900 --> 01:02:27.460
That's very neat.

01:02:27.540 --> 01:02:33.000
Yeah, I really recommend, like, I think for most people, Pandas is probably what you need.

01:02:33.000 --> 01:02:37.620
But if you're running into these kinds of, yeah, these types of problems, then I think

01:02:37.620 --> 01:02:43.340
NumPy would be a solution before you would have to look to, necessarily have to look to

01:02:43.340 --> 01:02:44.360
a different programming language.

01:02:44.360 --> 01:02:45.100
Yeah, absolutely.

01:02:45.100 --> 01:02:48.480
And like, this is how I started off our conversation together.

01:02:48.480 --> 01:02:53.580
The performance side of Python is super interesting because it's like, oh, well, it's not really

01:02:53.580 --> 01:02:54.040
fast enough.

01:02:54.040 --> 01:02:57.340
Until you apply this decorator, then all of a sudden it's just as fast and it's amazing.

01:02:57.440 --> 01:03:00.280
There's just all these little edge cases that are super neat.

01:03:00.280 --> 01:03:00.540
Yeah.

01:03:00.540 --> 01:03:01.060
Very, very cool.

01:03:01.060 --> 01:03:07.200
I look back to some of the code I wrote during my PhD and I cringe at some of the bad performance

01:03:07.200 --> 01:03:09.460
practices I probably had for working with them.

01:03:09.460 --> 01:03:14.340
And I think this comes back to your point about having people in the team who are a bit more

01:03:14.340 --> 01:03:15.440
experienced in this area.

01:03:15.440 --> 01:03:20.260
Because if you can have people who understand this and point team members to these tools

01:03:20.260 --> 01:03:23.920
for optimizing their code, then I think that can deal with a lot of the issues for people

01:03:23.920 --> 01:03:26.960
who may not be as experienced with writing Python themselves.

01:03:27.340 --> 01:03:28.520
Yeah, that's super advice.

01:03:28.520 --> 01:03:32.440
And then if you've got data that maybe is like the other side of your story, it's like

01:03:32.440 --> 01:03:39.660
too big to fit in RAM or you want more sort of automatic, rather, parallelism across, say,

01:03:39.660 --> 01:03:42.920
a large data frame, then Dask is definitely a good thing to look at.

01:03:42.920 --> 01:03:43.380
Absolutely.

01:03:43.380 --> 01:03:44.160
All right, Jack.

01:03:44.160 --> 01:03:45.300
This has been super interesting.

01:03:45.300 --> 01:03:47.000
I think we're getting a little long on time.

01:03:47.000 --> 01:03:49.080
I don't want to take up your entire day.

01:03:49.080 --> 01:03:52.140
So I will have to call it a show on that bit.

01:03:52.140 --> 01:03:52.560
No problem.

01:03:52.680 --> 01:03:56.280
But before we get out of here, of course, you have to answer the two final questions,

01:03:56.280 --> 01:03:56.860
as always.

01:03:56.860 --> 01:04:02.120
So if you're going to write some code, work on some of these projects, what editor do you

01:04:02.120 --> 01:04:02.340
use?

01:04:02.340 --> 01:04:02.860
VS Code.

01:04:02.860 --> 01:04:07.680
Especially since they added Jupyter Notebooks into the editor as well.

01:04:07.860 --> 01:04:12.580
Yeah, it's really interesting to see both what VS Code and PyCharm are doing to try to bring

01:04:12.580 --> 01:04:18.560
either just bring notebooks into the space or try to come up with a more native alternative,

01:04:18.560 --> 01:04:19.040
right?

01:04:19.040 --> 01:04:23.740
Like, well, here's a cell and it's separated by like this special comment, but you can still

01:04:23.740 --> 01:04:25.340
run it in notebook style.

01:04:25.340 --> 01:04:27.960
But it's like feels like a text file you're working with.

01:04:27.960 --> 01:04:29.940
And yeah, it's an exciting time for that stuff.

01:04:29.940 --> 01:04:30.340
Absolutely.

01:04:30.340 --> 01:04:30.720
Yeah.

01:04:30.720 --> 01:04:34.680
And then you've already given a shout out to a couple of different projects.

01:04:34.680 --> 01:04:38.120
But any notable PyPI packages you want to tell people about?

01:04:38.120 --> 01:04:43.240
Yeah, I mean, Numbers is the one I'm fascinated with in terms of learning more about at the

01:04:43.240 --> 01:04:43.480
moment.

01:04:43.480 --> 01:04:49.820
But I think for in terms of getting things done, just Pandas and Geopandas and the kind

01:04:49.820 --> 01:04:54.420
of scientific stack, it's just, it's amazing what people, the code that people have done

01:04:54.420 --> 01:04:58.360
that makes me so effective just by understanding, just being able to use their libraries.

01:04:58.360 --> 01:04:59.440
It's phenomenal.

01:04:59.440 --> 01:05:00.160
It's phenomenal.

01:05:00.160 --> 01:05:00.440
Yeah.

01:05:00.440 --> 01:05:04.460
Are you a Jupyter or a JupyterLab person or something else?

01:05:04.460 --> 01:05:09.040
I use mainly Jupyter, mainly because at least at the time when I tried out JupyterLab, I couldn't

01:05:09.040 --> 01:05:11.680
collapse some of the outputs from the cells as well.

01:05:11.680 --> 01:05:16.960
They may have fixed that, but I'll take a peek at JupyterLab every couple of months or so

01:05:16.960 --> 01:05:18.380
and see what's new.

01:05:18.380 --> 01:05:18.860
All right.

01:05:18.860 --> 01:05:19.740
Fantastic.

01:05:19.740 --> 01:05:20.260
All right.

01:05:20.260 --> 01:05:21.440
Well, final call to action.

01:05:21.440 --> 01:05:26.460
People are interested in, maybe they work in energy somewhere else in the world or they're

01:05:26.460 --> 01:05:27.660
trying to do research with it.

01:05:27.660 --> 01:05:28.460
What do you tell them?

01:05:28.460 --> 01:05:32.140
If you're interested in getting in touch with me, we run a few meetups for energy modelers

01:05:32.140 --> 01:05:32.640
in Sydney.

01:05:32.640 --> 01:05:36.400
So if you're ever interested in getting in touch to chat about some of the data in Australia

01:05:36.400 --> 01:05:38.100
or some of the work we're doing, feel free.

01:05:38.100 --> 01:05:41.400
Is that Zoomable these days or is it in person?

01:05:41.500 --> 01:05:44.500
The plan is for the meetup to be up as a Zoom one.

01:05:44.500 --> 01:05:46.020
So that's the plan.

01:05:46.020 --> 01:05:46.540
Yeah.

01:05:46.540 --> 01:05:46.880
All right.

01:05:46.880 --> 01:05:47.520
Fantastic.

01:05:47.520 --> 01:05:49.720
Well, Jack, it's been great to have you here.

01:05:49.720 --> 01:05:51.640
Thanks so much for sharing what you're up to.

01:05:51.640 --> 01:05:52.480
Thanks so much, Michael.

01:05:52.480 --> 01:05:53.200
It was great meeting you.

01:05:53.200 --> 01:05:53.880
Thanks for having me.

01:05:53.880 --> 01:05:54.120
Yeah.

01:05:54.120 --> 01:05:55.440
Keep the lights on down under.

01:05:55.440 --> 01:05:56.540
Thank you.

01:05:56.540 --> 01:05:56.940
I will.

01:05:56.940 --> 01:05:58.020
Bye.

01:05:58.020 --> 01:05:58.300
Bye.

01:05:58.300 --> 01:05:58.840
Have a good night.

01:05:59.920 --> 01:06:02.600
This has been another episode of Talk Python to Me.

01:06:02.600 --> 01:06:07.340
Our guest on this episode was Jack Simpson, and it's been brought to you by Square, Linode,

01:06:07.340 --> 01:06:08.340
and Assembly AI.

01:06:08.340 --> 01:06:13.900
With Square, your web app can easily take payments, seamlessly accept debit and credit cards, as

01:06:13.900 --> 01:06:15.200
well as digital wallet payments.

01:06:15.400 --> 01:06:20.800
Get started building your own online payment form in three steps with Square's Python SDK

01:06:20.800 --> 01:06:23.880
at talkpython.fm/square.

01:06:23.880 --> 01:06:29.000
Simplify your infrastructure and cut your cloud bills in half with Linode's Linux virtual machines.

01:06:29.000 --> 01:06:32.360
Develop, deploy, and scale your modern applications faster and easier.

01:06:32.800 --> 01:06:37.340
Visit talkpython.fm/linode and click the Create Free Account button to get started.

01:06:37.340 --> 01:06:41.620
Transcripts for this and all of our episodes are brought to you by Assembly AI.

01:06:41.620 --> 01:06:44.300
Do you need a great automatic speech-to-text API?

01:06:44.300 --> 01:06:46.840
Get human-level accuracy in just a few lines of code.

01:06:46.840 --> 01:06:49.700
Visit talkpython.fm/assembly AI.

01:06:49.700 --> 01:06:51.480
Want to level up your Python?

01:06:51.480 --> 01:06:55.520
We have one of the largest catalogs of Python video courses over at Talk Python.

01:06:55.520 --> 01:07:00.700
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:07:00.700 --> 01:07:03.380
And best of all, there's not a subscription in sight.

01:07:03.380 --> 01:07:06.280
Check it out for yourself at training.talkpython.fm.

01:07:06.280 --> 01:07:10.940
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:07:10.940 --> 01:07:12.260
We should be right at the top.

01:07:12.260 --> 01:07:17.420
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:07:17.420 --> 01:07:21.620
and the direct RSS feed at /rss on talkpython.fm.

01:07:21.620 --> 01:07:25.060
We're live streaming most of our recordings these days.

01:07:25.060 --> 01:07:28.460
If you want to be part of the show and have your comments featured on the air,

01:07:28.460 --> 01:07:32.900
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:07:32.900 --> 01:07:34.740
This is your host, Michael Kennedy.

01:07:34.740 --> 01:07:36.040
Thanks so much for listening.

01:07:36.040 --> 01:07:37.220
I really appreciate it.

01:07:37.220 --> 01:07:39.100
Now get out there and write some Python code.

01:07:39.100 --> 01:07:59.720
I'll see you next time.

01:07:59.720 --> 01:08:29.700
Thank you.

