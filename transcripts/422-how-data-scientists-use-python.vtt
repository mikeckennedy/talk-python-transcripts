WEBVTT

00:00:00.000 --> 00:00:04.320
Regardless of which side of Python you sit on, software developer or data scientist,


00:00:04.320 --> 00:00:10.240
you surely know that data scientists and software devs seem to have different styles and priorities.


00:00:10.240 --> 00:00:14.960
Why is that? And what are the benefits as well as the pitfalls of this separation?


00:00:14.960 --> 00:00:19.280
That's the topic of this conversation with our guest, Dr. Jody Burchill,


00:00:19.280 --> 00:00:21.600
data science developer advocate at JetBrains.


00:00:22.160 --> 00:00:27.280
This is Talk Python to Me, episode 422, recorded May 31st, 2023.


00:00:27.280 --> 00:00:45.360
Welcome to Talk Python to Me, a weekly podcast on Python. This is your host, Michael Kennedy.


00:00:45.360 --> 00:00:50.560
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,


00:00:50.560 --> 00:00:52.840
both on fosstodon.org.


00:00:52.840 --> 00:00:55.480
Be careful with impersonating accounts on other instances.


00:00:55.480 --> 00:00:56.680
There are many.


00:00:56.680 --> 00:00:58.820
Keep up with the show and listen to over seven years


00:00:58.820 --> 00:01:02.180
of past episodes at talkpython.fm.


00:01:02.180 --> 00:01:04.240
We've started streaming most of our episodes


00:01:04.240 --> 00:01:05.680
live on YouTube.


00:01:05.680 --> 00:01:06.880
Subscribe to our YouTube channel


00:01:06.880 --> 00:01:09.280
over at talkpython.fm/youtube


00:01:09.280 --> 00:01:11.480
to get notified about upcoming shows


00:01:11.480 --> 00:01:13.680
and be part of that episode.


00:01:13.680 --> 00:01:16.120
This episode is brought to you by JetBrains,


00:01:16.120 --> 00:01:19.760
who encourage you to get work done with PyCharm.


00:01:19.760 --> 00:01:22.260
Download your free trial of PyCharm Professional


00:01:22.260 --> 00:01:26.780
at talkbython.fm/done-with-pycharm.


00:01:26.780 --> 00:01:30.440
And it's brought to you by Prodigy from Explosion AI.


00:01:30.440 --> 00:01:31.960
Spend better time with your data


00:01:31.960 --> 00:01:34.340
and build better ML-based applications


00:01:34.340 --> 00:01:37.760
with Prodigy, a radically efficient data annotation tool.


00:01:37.760 --> 00:01:39.960
Get it at talkbython.fm/prodigy


00:01:39.960 --> 00:01:42.800
and use our code TALKBYTHON, all caps,


00:01:42.800 --> 00:01:45.140
to save 25% off a personal license.


00:01:45.140 --> 00:01:48.160
Jodi, welcome to TalkBythonomy.


00:01:48.160 --> 00:01:50.840
- Thank you, I am so thrilled to be on the show.


00:01:50.840 --> 00:01:52.560
- I'm so thrilled to have you on the show.


00:01:52.560 --> 00:01:54.040
I've been a fan of your work for a while


00:01:54.040 --> 00:01:56.020
and we got a chance to get to know each other


00:01:56.020 --> 00:01:57.880
at this year's PyCon.


00:01:57.880 --> 00:02:00.440
And so here you are on the podcast as well.


00:02:00.440 --> 00:02:03.800
- Thank you, we had some very nice Mexican food actually,


00:02:03.800 --> 00:02:06.440
or maybe Utah Mexican.


00:02:06.440 --> 00:02:08.200
I don't know how I would interpret it.


00:02:08.200 --> 00:02:09.400
It was very good though.


00:02:09.400 --> 00:02:10.720
- It was very good, yeah.


00:02:10.720 --> 00:02:11.960
The food was excellent.


00:02:11.960 --> 00:02:14.920
I thought the parties were great at the conference


00:02:14.920 --> 00:02:18.120
and people who are maybe still holding out


00:02:18.120 --> 00:02:20.600
ongoing. Personally, I really enjoyed being there.


00:02:20.600 --> 00:02:24.600
I think it's probably the best conference that I go to yearly.


00:02:24.600 --> 00:02:27.000
And it's like the vibe is so nice.


00:02:27.000 --> 00:02:31.240
On this show, we're going to talk about how data scientists


00:02:31.240 --> 00:02:35.880
use Python, which is somewhat different than maybe a software developer.


00:02:35.880 --> 00:02:39.960
We have, which I guess I'll put myself solidly into that, that camp.


00:02:39.960 --> 00:02:43.680
I do a bunch of web development, make APIs, I build apps and ship them.


00:02:43.680 --> 00:02:45.480
That's quite a different story.


00:02:45.480 --> 00:02:47.460
And I'm going to have a, I think we're have a really great time


00:02:47.460 --> 00:02:48.320
talking about those things.


00:02:48.320 --> 00:02:51.720
But before we do, let's get a little, get to know you a bit.


00:02:51.720 --> 00:02:54.280
Let's see, how'd you get into programming, Python, data science?


00:02:54.280 --> 00:02:54.780
Yeah.


00:02:54.780 --> 00:02:59.680
So, probably going hand in hand with maybe not being a developer.


00:02:59.680 --> 00:03:02.120
My story is perhaps a little unconventional.


00:03:02.120 --> 00:03:05.240
So my background is academic, like a lot of data scientists.


00:03:05.240 --> 00:03:10.240
And unsurprisingly, the first language that I learned was R because I was doing


00:03:10.240 --> 00:03:13.600
psychology and health sciences and a lot of statistics.


00:03:13.680 --> 00:03:17.680
And I was procrastinating once during my PhD.


00:03:17.680 --> 00:03:20.560
You will find any excuse to not work on your thesis.


00:03:20.560 --> 00:03:22.280
And I think I was reading, oh, you know,


00:03:22.280 --> 00:03:24.440
people who are into statistics,


00:03:24.440 --> 00:03:26.800
you should really learn Python, it's the future.


00:03:26.800 --> 00:03:28.600
And I was like, I should learn Python.


00:03:28.600 --> 00:03:30.200
So I sat down and-


00:03:30.200 --> 00:03:32.080
- Because I really don't wanna write that next chapter.


00:03:32.080 --> 00:03:33.920
I just don't. - Exactly, exactly.


00:03:33.920 --> 00:03:37.280
So I remember it, like I actually had this long weekend


00:03:37.280 --> 00:03:38.320
and I worked my way through,


00:03:38.320 --> 00:03:41.440
I think it was Zed Shaw's "Learn Python the Hard Way."


00:03:41.440 --> 00:03:43.200
This is showing my age, I think.


00:03:43.200 --> 00:03:48.440
I loved it. Like I completed the course in three days. And then I didn't know what to


00:03:48.440 --> 00:03:52.440
do with Python because the stats libraries weren't as developed back then. So I just


00:03:52.440 --> 00:03:57.800
put it aside for a couple of years and ended up picking it up again when I started working


00:03:57.800 --> 00:04:03.280
in industry, because obviously I've left academia. And you sort of fairly quickly, once you start


00:04:03.280 --> 00:04:07.560
in data science, move away from more sort of statistical stuff to machine learning.


00:04:07.560 --> 00:04:12.560
And Python really has the libraries for that. So that's my journey. It's a little bit bibs


00:04:12.560 --> 00:04:15.200
and bobs and stops and starts.


00:04:15.200 --> 00:04:18.600
But once I kind of picked up Python, it really was love at first sight.


00:04:18.600 --> 00:04:19.720
Oh, that's that's excellent.


00:04:19.720 --> 00:04:20.880
What's your PhD in?


00:04:20.880 --> 00:04:22.400
It's actually computer science, of course.


00:04:22.400 --> 00:04:22.720
Right.


00:04:22.720 --> 00:04:23.520
Of course.


00:04:23.520 --> 00:04:24.360
Of course.


00:04:24.360 --> 00:04:25.360
You know, it's so funny.


00:04:25.360 --> 00:04:28.360
You are the third person to ask me in two weeks.


00:04:28.360 --> 00:04:30.600
And no one has asked me this question for like two years.


00:04:30.600 --> 00:04:32.520
My PhD was in hurt feelings.


00:04:32.520 --> 00:04:33.400
Hurt feelings?


00:04:33.400 --> 00:04:33.920
Yeah.


00:04:33.920 --> 00:04:34.360
OK.


00:04:34.360 --> 00:04:35.920
I say this a little bit blithely.


00:04:35.920 --> 00:04:39.840
So my PhD being in psychology, I was really interested


00:04:39.840 --> 00:04:42.240
in emotions research and relationships research.


00:04:42.240 --> 00:04:49.240
So, I kind of wanted to see what happens to people emotionally when close relationships go bad.


00:04:49.240 --> 00:04:55.240
And it's hurt feelings, like things like, you know, infidelities, rejections, all of that.


00:04:55.240 --> 00:04:55.740
It's hurt.


00:04:55.740 --> 00:05:04.240
So, I was just studying what generates like and regulates the intensity of hurt and studied that for four and a half years.


00:05:04.240 --> 00:05:05.740
- Yeah, sounds interesting.


00:05:05.740 --> 00:05:07.740
I'm sure there was a lot of data to process.


00:05:07.740 --> 00:05:09.460
There was a lot of data to process


00:05:09.460 --> 00:05:13.380
and a lot of very interesting statistic.


00:05:13.380 --> 00:05:15.180
That was sort of how I got into data science.


00:05:15.180 --> 00:05:16.980
I fell in love with stats in undergrad


00:05:16.980 --> 00:05:19.060
and just kept going down that path.


00:05:19.060 --> 00:05:22.520
- I think a lot of people are drawn to data science


00:05:22.520 --> 00:05:25.380
not with the intent of waking up one day


00:05:25.380 --> 00:05:27.100
and saying, "I'm gonna be a data scientist,"


00:05:27.100 --> 00:05:29.140
but they're excited or inspired


00:05:29.140 --> 00:05:30.820
about something tangential and they're like,


00:05:30.820 --> 00:05:34.420
"Well, I really need to get something better than Excel


00:05:34.420 --> 00:05:35.500
to work on this."


00:05:35.500 --> 00:05:36.620
Right? - Absolutely.


00:05:36.620 --> 00:05:37.460
Yeah, yeah.


00:05:37.460 --> 00:05:42.820
And we'll probably talk about this a little bit later about why data scientists use programming.


00:05:42.820 --> 00:05:47.860
And it kind of is like, in some ways that need to jump from something way more powerful


00:05:47.860 --> 00:05:49.420
and reproducible than Excel.


00:05:49.420 --> 00:05:51.020
Yeah, yeah, for sure.


00:05:51.020 --> 00:05:52.100
So how about now?


00:05:52.100 --> 00:05:53.860
You said you've left academics.


00:05:53.860 --> 00:05:56.340
And what are you doing these days?


00:05:56.340 --> 00:06:00.940
Yeah, so that leap from academia was a long time ago now, I think that was like seven


00:06:00.940 --> 00:06:03.140
years again, showing my age.


00:06:03.140 --> 00:06:06.540
So for six of those years, I was a data scientist.


00:06:06.540 --> 00:06:13.480
So day to day was, you know, pretty varied, but the job I have now is very different.


00:06:13.480 --> 00:06:17.120
So I currently work as a developer advocate at JetBrains.


00:06:17.120 --> 00:06:23.660
And the way I would describe my job is I'm a liaison between data scientists and JetBrains.


00:06:23.660 --> 00:06:27.980
So I try and advocate for our tools to be as good as they can be.


00:06:27.980 --> 00:06:31.900
And I try to recommend ways that people can use our tools if I think it's useful.


00:06:31.900 --> 00:06:33.860
But I'm definitely not marketing or sales.


00:06:33.860 --> 00:06:36.380
more if I think this is the right fit for you, I'll do it.


00:06:36.380 --> 00:06:41.140
So it's like the way I achieve that is really up to me.


00:06:41.140 --> 00:06:46.260
For me, I really kind of I like to do a mixture of what I call internal


00:06:46.260 --> 00:06:50.620
and external activities. So external activities are actually kind of only tangentially


00:06:50.620 --> 00:06:54.260
related to the products. So this would be an example of an external activity.


00:06:54.260 --> 00:06:58.580
It's just getting out there and educating people about data science or educating data


00:06:58.580 --> 00:07:03.300
scientists about technical topics, things like conference talks or webinars,


00:07:03.460 --> 00:07:09.540
you know, all this sort of stuff. And then internal stuff is more focused on maybe things a bit more


00:07:09.540 --> 00:07:13.380
related to the product. So if I think there's a feature that people would be really interested in,


00:07:13.380 --> 00:07:19.620
I might make a video about it or create, you know, a blog post. So yeah, it's a real hodgepodge. So


00:07:19.620 --> 00:07:26.100
this week, for example, I've been working on actually materials for a free workshop that


00:07:26.100 --> 00:07:30.340
they're organizing at EuroPython. So I'm going to be volunteering to help out that. It's completely


00:07:30.340 --> 00:07:33.740
unrelated to anything I'm doing at JetBrains. It's just a volunteer activity.


00:07:33.740 --> 00:07:36.580
But last week I was at a conference week before that.


00:07:36.580 --> 00:07:38.800
So I can see the jobs pretty varied.


00:07:38.800 --> 00:07:41.880
I think developer evangelists, it seems like such a fun job.


00:07:41.880 --> 00:07:45.540
You know, I had your colleague Paul Everett on and we actually talked.


00:07:45.540 --> 00:07:48.340
It's quite a while ago, a couple of years ago, three, four.


00:07:48.340 --> 00:07:53.300
And we had a whole episode on like a panel on what is the developer


00:07:53.300 --> 00:07:56.000
advocate, developer relations job.


00:07:56.000 --> 00:08:00.300
But it's it just seems like such a great mix of you still get to travel


00:08:00.300 --> 00:08:07.120
a little bit, see people, but you also get to write code and work on influencing technology


00:08:07.120 --> 00:08:08.820
and products and stuff.


00:08:08.820 --> 00:08:09.820
Yeah.


00:08:09.820 --> 00:08:13.540
And I think the thing that I started to appreciate about the job a few months in is you have


00:08:13.540 --> 00:08:18.180
a platform with this job, and that means you can choose to promote the message that you


00:08:18.180 --> 00:08:19.180
want.


00:08:19.180 --> 00:08:25.020
And a message that, no surprise, is very meaningful for me is data science is for everyone.


00:08:25.020 --> 00:08:28.620
Like I hate the gatekeeping that can happen in tech communities.


00:08:28.620 --> 00:08:34.020
I think it's quite bad in terms of like people being intimidated by math in data science.


00:08:34.020 --> 00:08:37.500
And like, I'm here to say to you, if you want it, it's for you.


00:08:37.500 --> 00:08:39.140
It is a very cool field.


00:08:39.140 --> 00:08:41.260
And yeah, doesn't matter what background you come from.


00:08:41.260 --> 00:08:42.260
I absolutely agree.


00:08:42.260 --> 00:08:45.940
And I was kind of hinting at that saying like a lot of people who don't see themselves as


00:08:45.940 --> 00:08:51.540
developers or programmers, like still find really great places, really great fits in


00:08:51.540 --> 00:08:53.980
data science and in programming as well.


00:08:53.980 --> 00:08:57.820
And I also want to second that I don't think you really need that much math.


00:08:57.820 --> 00:09:04.260
Maybe if you're trying to build the next machine learning model platform, then yes, okay.


00:09:04.260 --> 00:09:06.180
But that's not what most people do.


00:09:06.180 --> 00:09:09.820
They take the data, they clean it up, they do interesting visualizations and maybe put


00:09:09.820 --> 00:09:12.100
it into some framework for production, right?


00:09:12.100 --> 00:09:13.100
Yeah.


00:09:13.100 --> 00:09:17.380
And the nice thing is the field is in such a point where you have so many frameworks


00:09:17.380 --> 00:09:20.820
or tools that will handle a lot of this stuff for you.


00:09:20.820 --> 00:09:24.780
Like, I'm not saying you don't need any understanding of what's going on under the hood, but you


00:09:24.780 --> 00:09:26.180
can learn it incrementally.


00:09:26.180 --> 00:09:39.560
A lot of it is like with software development, where you develop that, that smell or that instinct for when something is not right, that will benefit you more than, you know, knowing how backpropagation works from a calculus perspective.


00:09:39.560 --> 00:09:41.480
Like that stuff is maybe a bit too much.


00:09:41.480 --> 00:09:42.720
You don't necessarily need it.


00:09:42.720 --> 00:09:43.120
Yeah.


00:09:43.120 --> 00:09:52.680
Let's get into the main topic and talk a little bit about how does programming in Python differ on the data science side than say me as somebody who builds web apps.


00:09:52.720 --> 00:09:59.960
Yeah. And maybe we can start by doing an orientation to like, what does a data scientist do? Because I think this confuses a lot of people. Yeah.


00:09:59.960 --> 00:10:17.680
Yeah. So basically, the role of a data scientist is to sort of like, like the reason you would hire a data scientist is you have a bunch of data and you have an instinct that you can use that data to either improve your internal processes or sell some sort of IP.


00:10:17.920 --> 00:10:27.340
So the reason, you know, we differ from BI analysts is BI analysts are doing analysis, but it's more about business as usual, which is really important.


00:10:27.340 --> 00:10:29.540
You absolutely need BI analysts.


00:10:29.540 --> 00:10:30.860
How are sales going?


00:10:30.860 --> 00:10:32.820
How much have we made versus last year?


00:10:32.820 --> 00:10:34.480
Like those kinds of charts, right?


00:10:34.480 --> 00:10:36.540
Like absolutely fundamental questions.


00:10:36.540 --> 00:10:44.200
So you need to be an analyst before you need a data scientist, but your data scientists are more there to push the envelope in a data driven way.


00:10:44.740 --> 00:10:48.420
So we have two main outputs, I would say.


00:10:48.420 --> 00:10:53.180
You can either create an analysis and do a report, or you can build some sort of


00:10:53.180 --> 00:10:55.100
model that will go into production.


00:10:55.100 --> 00:10:59.940
So an example might be as a business, I have an instinct that I can get my


00:10:59.940 --> 00:11:04.460
customers to buy more things based on people like them


00:11:04.460 --> 00:11:05.780
also buying those things.


00:11:05.780 --> 00:11:09.820
So in that case, your data scientists might be able to build you a recommendation


00:11:09.820 --> 00:11:13.660
engine. And this will have a business outcome.


00:11:13.820 --> 00:11:16.940
Developers, obviously, on the other hand, have a very different goal.


00:11:16.940 --> 00:11:20.100
Their goal is to create robust software systems.


00:11:20.100 --> 00:11:24.260
So the concerns that they have are things like latency,


00:11:24.260 --> 00:11:27.420
server load, downtime, things like that.


00:11:27.420 --> 00:11:29.580
And it's very interesting.


00:11:29.580 --> 00:11:32.620
And we'll talk about it a bit more when we talk about code, if we kind of get into that


00:11:32.620 --> 00:11:37.060
topic. But basically, data scientists are not really interested in creating


00:11:37.060 --> 00:11:41.300
code for the long term, whereas the code becomes


00:11:41.340 --> 00:11:43.820
the product that software developers write often.


00:11:43.820 --> 00:11:46.660
And you have to think about things like legacy systems,


00:11:46.660 --> 00:11:49.060
because eventually every Greenfield project


00:11:49.060 --> 00:11:51.460
becomes a legacy system if it lasts for long enough.


00:11:51.460 --> 00:11:52.820
- Yeah, if you're lucky, right?


00:11:52.820 --> 00:11:55.340
Because the alternative is it never really got used


00:11:55.340 --> 00:11:56.860
or it didn't add that much value


00:11:56.860 --> 00:11:59.100
and got discarded, shut down, all right.


00:11:59.100 --> 00:12:01.220
So even though people talk about


00:12:01.220 --> 00:12:02.860
how much they don't want legacy code


00:12:02.860 --> 00:12:06.260
or how they kind of don't necessarily want to work on it


00:12:06.260 --> 00:12:08.740
'cause they want to work on something new and shiny,


00:12:08.740 --> 00:12:12.860
That's kind of the success side of software development, right?


00:12:12.860 --> 00:12:14.100
Yeah, exactly.


00:12:14.100 --> 00:12:16.020
I do think it's super interesting,


00:12:16.020 --> 00:12:20.260
the different lifecycle of code on the data science side,


00:12:20.260 --> 00:12:24.060
because you might be just looking to explore a concept


00:12:24.060 --> 00:12:26.460
or understand an idea better


00:12:26.460 --> 00:12:30.140
and not necessarily ever intend to put it into production


00:12:30.140 --> 00:12:32.380
in the traditional software sense, right?


00:12:32.380 --> 00:12:37.140
So I've seen some pretty interesting code written


00:12:37.140 --> 00:12:43.620
that people would look at and go, oh my goodness, what is, there's not even a function here.


00:12:43.620 --> 00:12:49.140
How is this possible? You know, it's like copy and paste, reuse almost. And yet it really


00:12:49.140 --> 00:12:55.220
does go from having no idea to pictures and understanding and then maybe handing that off


00:12:55.220 --> 00:13:02.020
potentially to be written more robustly or better. Exactly. And it's really interesting. Like,


00:13:02.020 --> 00:13:08.020
They're kind of two very different processes. And that point actually where engineering and


00:13:08.020 --> 00:13:13.140
research meets is a very, very interesting one. And I've seen it work in multiple different ways


00:13:13.140 --> 00:13:17.540
in multiple different workplaces. So, for example, I've worked in places where the


00:13:17.540 --> 00:13:22.340
data scientists were completely sequestered away from the engineers. And there really wouldn't be


00:13:22.340 --> 00:13:27.540
that much discussion between the engineers and the data scientists during the research phase,


00:13:27.540 --> 00:13:32.340
which I do not advise. So what that means is the data scientists will come at the end and


00:13:32.340 --> 00:13:38.660
hand over this chunk of perhaps very difficult to read code to an engineer and be like, "Hey,


00:13:38.660 --> 00:13:43.620
so we need to implement this." And the engineer is like, "What is this? Okay, I will schedule that


00:13:43.620 --> 00:13:50.260
for the next six months." And then I've seen, or I've been a data scientist embedded within a


00:13:50.260 --> 00:13:55.460
software development team. And in that case, your project is marching in lockstep with what the


00:13:55.460 --> 00:13:59.920
the engineers are doing. And from the very start, you know, you've been discussing important


00:13:59.920 --> 00:14:03.700
things like you need to build a model that has latency constraints. You need to think


00:14:03.700 --> 00:14:07.940
about this as the data scientist in terms of like the model that you run, but also how


00:14:07.940 --> 00:14:08.940
it's implemented.


00:14:08.940 --> 00:14:13.100
Right. Like how much memory does it use? Because if you run it on your own machine by yourself,


00:14:13.100 --> 00:14:16.660
then, well, it's kind of the limit of your computer sort of sometimes. But if you're


00:14:16.660 --> 00:14:20.620
running a thousand of them concurrently, because people are interacting at the website, all


00:14:20.620 --> 00:14:23.180
of a sudden that might make a difference.


00:14:23.180 --> 00:14:28.260
Or like one of the most interesting problems I think I ever solved in my career was basically


00:14:28.260 --> 00:14:30.300
I was working at a job board.


00:14:30.300 --> 00:14:34.260
We're trying to improve the search using natural language processing.


00:14:34.260 --> 00:14:39.820
So we had this idea that we could build a model that found out the probabilistic relations


00:14:39.820 --> 00:14:42.180
between skills and job titles.


00:14:42.180 --> 00:14:46.260
So if someone typed a skill into the search, we could expand it with job titles and then


00:14:46.260 --> 00:14:50.900
find all of the jobs that we indexed with that at search time and vice versa with job


00:14:50.900 --> 00:14:52.180
titles and skills.


00:14:52.180 --> 00:14:55.660
The thing is, we need to find those relations at search time.


00:14:55.660 --> 00:14:57.780
That is a very low latency system.


00:14:57.780 --> 00:15:02.180
And it was super interesting because we had to think about how we could search that vector


00:15:02.180 --> 00:15:06.380
space in really, really quickly.


00:15:06.380 --> 00:15:10.220
Instead of having to calculate the distance between that and every single vector, we had


00:15:10.220 --> 00:15:12.620
to work out how to do that more efficiently.


00:15:12.620 --> 00:15:16.820
That sort of stuff I really like because it's so applied and it's so...


00:15:16.820 --> 00:15:20.980
It's this really nice intersection between computer science and data science, I think.


00:15:20.980 --> 00:15:21.980
It's super cool.


00:15:21.980 --> 00:15:28.540
One of the things I really like about working with programming broadly is how concrete it is.


00:15:28.540 --> 00:15:32.940
Right? You came from academics. You know, I was in grad school for a while as well.


00:15:32.940 --> 00:15:37.980
And it's, you could debate on and on about a certain idea or concept. And it's like,


00:15:37.980 --> 00:15:43.900
well, you might be right. Or I'm here, you push a button and you get the answer or it runs or


00:15:43.900 --> 00:15:48.700
like, there's a really nice feedback of like, I built this thing and it's look, it's really


00:15:48.700 --> 00:15:52.580
really connecting these people and you know, then it comes down to can you do it in real


00:15:52.580 --> 00:16:00.740
time and other things like that. But that's a really cool aspect of programming.


00:16:00.740 --> 00:16:05.260
This portion of talk Python to me is brought to you by JetBrains and PyCharm. Are you a


00:16:05.260 --> 00:16:09.860
data scientist or a web developer looking to take your projects to the next level? Well,


00:16:09.860 --> 00:16:14.580
I have the perfect tool for you. PyCharm. PyCharm is a powerful integrated development


00:16:14.580 --> 00:16:20.060
environment that empowers developers and data scientists like us to write clean and efficient


00:16:20.060 --> 00:16:21.940
code with ease.


00:16:21.940 --> 00:16:26.740
Whether you're analyzing complex datasets or building dynamic web applications, PyCharm


00:16:26.740 --> 00:16:28.120
has got you covered.


00:16:28.120 --> 00:16:32.380
With its intuitive interface and robust features, you can boost your productivity and bring


00:16:32.380 --> 00:16:35.220
your ideas to life faster than ever before.


00:16:35.220 --> 00:16:39.620
For data scientists, PyCharm offers seamless integration with popular libraries like NumPy,


00:16:39.620 --> 00:16:41.540
Pandas, and Matplotlib.


00:16:41.540 --> 00:16:46.580
You can explore, visualize, and manipulate data effortlessly, unlocking valuable insights


00:16:46.580 --> 00:16:48.700
with just a few lines of code.


00:16:48.700 --> 00:16:53.300
And for us web developers, PyCharm provides a rich set of tools to streamline your workflow.


00:16:53.300 --> 00:16:57.340
From intelligent code completion to advanced debugging capabilities, PyCharm helps you


00:16:57.340 --> 00:17:02.260
write clean, scalable code that powers stunning web applications.


00:17:02.260 --> 00:17:07.680
Plus, PyCharm's support for popular frameworks like Django, FastAPI, and React make it a


00:17:07.680 --> 00:17:10.740
breeze to build and deploy your web projects.


00:17:10.740 --> 00:17:15.540
It's time to say goodbye to tedious configuration and hello to rapid development.


00:17:15.540 --> 00:17:17.020
But wait, there's more.


00:17:17.020 --> 00:17:21.980
With PyCharm, you get even more advanced features like remote development, database integration,


00:17:21.980 --> 00:17:25.760
and version control, ensuring your projects stay organized and secure.


00:17:25.760 --> 00:17:29.380
So whether you're diving into data science or shaping the future of the web, PyCharm


00:17:29.380 --> 00:17:30.900
is your go-to tool.


00:17:30.900 --> 00:17:32.980
Join me and try PyCharm today.


00:17:32.980 --> 00:17:40.140
Just visit talkpython.fm/done-with-pycharm, links in your show notes, and experience the


00:17:40.140 --> 00:17:46.140
power of PyCharm first hand for three months free. PyCharm, it's how I get work done.


00:17:46.140 --> 00:17:55.980
I think it's kind of a shame that a lot of places do set up their engineering and data science teams


00:17:55.980 --> 00:18:00.860
so separately. Sure, we have quite different roles and we have quite different backgrounds


00:18:00.860 --> 00:18:06.300
sometimes. But I really think that having the two teams at least planning things together,


00:18:06.300 --> 00:18:09.260
you can really actually learn a lot from each other


00:18:09.260 --> 00:18:10.760
about how to approach problems.


00:18:10.760 --> 00:18:12.300
When you were describing,


00:18:12.300 --> 00:18:14.260
you know, either having those groups really separated


00:18:14.260 --> 00:18:15.720
or working really closely together,


00:18:15.720 --> 00:18:20.220
maybe an analogous relationship that people could relate with


00:18:20.220 --> 00:18:22.840
is maybe front-end developers


00:18:22.840 --> 00:18:25.520
and people building the APIs in the back-end, right?


00:18:25.520 --> 00:18:29.860
Like the people doing React or Angular or Vue


00:18:29.860 --> 00:18:32.520
or whatever it is, you know, in the web design.


00:18:32.520 --> 00:18:35.480
Having those completely separated as well is also,


00:18:35.480 --> 00:18:36.840
you know, it's terrible, not a good idea.


00:18:36.840 --> 00:18:38.000
- It doesn't make any sense.


00:18:38.000 --> 00:18:39.920
And like, I can totally understand it


00:18:39.920 --> 00:18:41.960
from the point of view of like team composition,


00:18:41.960 --> 00:18:44.240
because it is, I think, better


00:18:44.240 --> 00:18:45.800
to have all your data scientists together


00:18:45.800 --> 00:18:47.520
because they can learn from each other.


00:18:47.520 --> 00:18:48.840
But then I think having,


00:18:48.840 --> 00:18:50.240
I don't want to use the squad term


00:18:50.240 --> 00:18:52.200
'cause I know it's become a little bit unpopular to use it,


00:18:52.200 --> 00:18:55.360
but you know, this idea of project-oriented teams,


00:18:55.360 --> 00:18:56.560
I think are quite important.


00:18:56.560 --> 00:18:57.520
- Let's dive a little bit more


00:18:57.520 --> 00:18:59.360
into the research side of things


00:18:59.360 --> 00:19:01.160
that I want to ask you about.


00:19:01.160 --> 00:19:02.280
Why Python?


00:19:02.280 --> 00:19:04.840
Let's talk about how the research process works


00:19:04.840 --> 00:19:10.840
and maybe why that results in different priorities and styles of code and styles of engineering.


00:19:10.840 --> 00:19:15.880
It starts at a similar point to all software projects, which is business comes to you and


00:19:15.880 --> 00:19:21.880
they have some sort of goal. Sometimes it's very vague and you need to interpret that and turn it


00:19:21.880 --> 00:19:27.800
into an executable project. But where the sort of uncertainty starts and like where it sort of


00:19:27.800 --> 00:19:32.840
becomes a research project rather than a project, and I don't know if I described that very well,


00:19:32.840 --> 00:19:38.760
but it becomes research versus something you're building concretely is even know at the start


00:19:38.760 --> 00:19:43.400
of a research project, whether it's even possible to answer the question that you're being asked or


00:19:43.400 --> 00:19:45.800
build the internal product that you're being asked for.


00:19:45.800 --> 00:19:50.440
You might not understand the domain entirely, right? You're trying to gain understanding even.


00:19:50.440 --> 00:19:54.840
In the very worst cases, you won't even know if you have the data because maybe your company has


00:19:54.840 --> 00:19:59.480
so much data and it's so poorly organized, again, something I've seen that you don't even know if


00:19:59.480 --> 00:20:06.040
the data exists to answer this question. So, first is going and getting your data. And you spend quite


00:20:06.040 --> 00:20:10.360
a lot of time with the data because the data will be the one that tells you the story. It'll tell you


00:20:10.360 --> 00:20:16.440
whether what you even want is possible. And you probably like heard data scientists hammering on


00:20:16.440 --> 00:20:20.120
about, you know, garbage in, garbage out. Like, you can build the most beautiful,


00:20:20.120 --> 00:20:24.680
sophisticated model you want. But if you have crap data where there's no signal,


00:20:24.680 --> 00:20:28.920
you're not going to get anything because it's just not there. Like, the relationship you're


00:20:28.920 --> 00:20:30.160
you're looking for is not there.


00:20:30.160 --> 00:20:33.880
- Yeah, the side of that I've heard is 80% of the work


00:20:33.880 --> 00:20:36.240
is actually the data cleanup, data wrangling,


00:20:36.240 --> 00:20:38.920
data gathering before you just magically hit it


00:20:38.920 --> 00:20:41.080
with a plot or something, right?


00:20:41.080 --> 00:20:44.280
- Absolutely, and it's interesting because that data


00:20:44.280 --> 00:20:47.560
cleaning, data wrangling step also doesn't happen in one go,


00:20:47.560 --> 00:20:48.960
especially if you're building a model.


00:20:48.960 --> 00:20:51.040
So what will happen is you'll try something out


00:20:51.040 --> 00:20:52.920
and you'll be like, okay, it didn't quite work.


00:20:52.920 --> 00:20:55.040
Maybe I need to manipulate the data in a different way


00:20:55.040 --> 00:20:57.000
or I need to create this new variable


00:20:57.000 --> 00:21:02.200
then you'll go again. And it's this super iterative process where you have this tightly coupled


00:21:02.200 --> 00:21:08.440
relationship between both the models and the data. So, it really is sort of, you know, how I was


00:21:08.440 --> 00:21:12.600
talking about the instinct, this is sort of where that comes in, because you're going to spend like


00:21:12.600 --> 00:21:17.640
80% of your time honing your skills. But it's the most, I think, valuable part of the process.


00:21:17.640 --> 00:21:24.040
And if the signal's there, you can usually get away with using really dumb and simple models,


00:21:24.040 --> 00:21:28.440
you know, things that are unfashionable now, like decision trees or linear regression,


00:21:28.440 --> 00:21:32.920
you can get away with them because you've just got such good data, but just go with a simpler


00:21:32.920 --> 00:21:37.640
model. It's got all the advantages. This is sort of, I think, what makes it different that


00:21:37.640 --> 00:21:42.680
you're sort of moving towards a goal, but you don't know what that goal is.


00:21:42.680 --> 00:21:47.960
Estimation is always hard, right? What I found is best is really just time boxing each step,


00:21:47.960 --> 00:21:53.240
seeing if you are up to where you thought you'd be up to by a certain point. And if not, you need


00:21:53.240 --> 00:21:57.240
to just keep having those discussions with the business stakeholders because otherwise they're


00:21:57.240 --> 00:22:02.200
going to not be very happy if you've spent six months just looking at something and you have


00:22:02.200 --> 00:22:08.120
nothing. What have you built? Well, I have some notebooks I could show you. I have 40,000


00:22:08.120 --> 00:22:14.200
notebooks and they're all terrible. Yeah. Speaking of the data, Diego in the audience has an


00:22:14.200 --> 00:22:18.360
interesting question. How big are the data sets businesses will bring to you typically?


00:22:18.360 --> 00:22:21.000
enough that you don't need to go out and find more data?


00:22:21.000 --> 00:22:48.200
This is a good question. So I hate to be it depends, you know, I get to say that, though, because, you know, I was a lead data scientist. So I earned that, that rank, it really does depend on the problem you need to solve. So typically, business will have enough data to cover at least some of the use cases. So to give you a really concrete example, this job board that I was talking about that I worked at, we actually had like a bunch of different job boards


00:22:48.200 --> 00:23:02.920
across Europe. So we had some that were a lot bigger, like Germany or the UK, and we had some that were really small, like Poland or Spain. And we wanted to build these multi-language models or models maybe for different languages.


00:23:02.920 --> 00:23:09.640
We played around with both. And I don't think we really had enough data to support the models in these smaller languages.


00:23:09.640 --> 00:23:12.960
So the models were just not as good quality because we didn't have enough data.


00:23:12.960 --> 00:23:14.600
But for the bigger languages we did.


00:23:14.600 --> 00:23:18.960
And then it sort of becomes a case of, OK, well, we have more data for these particular


00:23:18.960 --> 00:23:21.720
websites because they're the most like they're the ones that are bringing the most


00:23:21.720 --> 00:23:25.760
revenue. So then it sort of became like, well, OK, maybe it's good enough that we improve


00:23:25.760 --> 00:23:27.640
the search on the most important ones.


00:23:27.640 --> 00:23:30.840
And for the smaller ones, we just wait until we accumulate more data.


00:23:30.840 --> 00:23:35.840
So, yeah, most of the time I found that there's a way to make it work for at least


00:23:35.840 --> 00:23:37.280
part of the solution.


00:23:37.480 --> 00:23:41.640
And then sometimes, like in the case of my last job, we had something like 170


00:23:41.640 --> 00:23:44.440
billion auctions per day.


00:23:44.440 --> 00:23:44.840
Sorry.


00:23:44.840 --> 00:23:48.240
So we had so much data.


00:23:48.240 --> 00:23:50.360
We even had problems like processing it.


00:23:50.360 --> 00:23:54.640
So sometimes, you know, that's the other side of the story is when you've got too


00:23:54.640 --> 00:23:56.360
much and then how do you throw it away?


00:23:56.360 --> 00:23:56.720
Right.


00:23:56.720 --> 00:23:59.080
I mean, you've got this auction story.


00:23:59.080 --> 00:24:02.240
Like another one that comes to mind is the large Hadron collider.


00:24:02.240 --> 00:24:03.560
Oh yes.


00:24:03.560 --> 00:24:04.000
Yes.


00:24:04.240 --> 00:24:10.400
They've got layers and layers of like chips on hardware and then chips or machines right next to the


00:24:10.400 --> 00:24:13.760
Collectors and then on it where it's all about. How do we throw away?


00:24:13.760 --> 00:24:18.000
You know terabytes of data down to get it to megabytes per second, right?


00:24:18.000 --> 00:24:25.600
Yeah, and it's interesting because what you can end up in this within those situations is even then you can have underrepresented groups


00:24:25.600 --> 00:24:32.240
so for example, we had we're working with advertisers and apps, you know, basically trading ads and


00:24:32.720 --> 00:24:35.400
we ended up with some apps that were just so small


00:24:35.400 --> 00:24:37.640
that you were like, "Even with all this data,


00:24:37.640 --> 00:24:39.200
I really don't have enough


00:24:39.200 --> 00:24:42.520
to represent this particular combination in this country."


00:24:42.520 --> 00:24:45.240
>> Interesting. Very interesting.


00:24:45.240 --> 00:24:48.920
Why Python? You started out in R,


00:24:48.920 --> 00:24:53.440
and of course, any distraction from writing a PhD is a good distraction.


00:24:53.440 --> 00:24:58.040
But I do think there's been a really interesting graph.


00:24:58.040 --> 00:24:59.840
If people go and look at,


00:24:59.840 --> 00:25:02.520
what is it, Stack Overflow Insights.


00:25:02.520 --> 00:25:05.400
If you go look at Stack Overflow Insights,


00:25:05.400 --> 00:25:08.600
they had a really great graph


00:25:08.600 --> 00:25:12.640
that shows you the popularity of Python over time.


00:25:12.640 --> 00:25:15.800
And there's just this huge inflection point around 2012.


00:25:15.800 --> 00:25:18.840
And I feel like that's when a lot of the data science libraries


00:25:18.840 --> 00:25:21.640
really came around and took off.


00:25:21.640 --> 00:25:23.840
It seems like there was a big inflection at one point,


00:25:23.840 --> 00:25:25.600
but, you know, why?


00:25:25.600 --> 00:25:30.320
To be honest, I can talk about why I like Python


00:25:30.320 --> 00:25:31.600
from my background.


00:25:31.600 --> 00:25:36.160
I couldn't really tell you exactly what caused that takeoff, but, you know, apart from, you know,


00:25:36.160 --> 00:25:41.840
this idea that the libraries were maturing enough. But the thing is, looking even at current surveys,


00:25:41.840 --> 00:25:46.640
around 60% of data scientists do not have a software development or a software engineering


00:25:46.640 --> 00:25:52.160
background. So, for people like us, we don't really understand, like, it sounds terrible,


00:25:52.160 --> 00:25:57.920
we don't really understand basic constructs in how a programming language works. And that can


00:25:57.920 --> 00:26:03.600
actually mean that going to some sort of compiled language even can be quite a steep learning curve.


00:26:03.600 --> 00:26:07.680
Sure. Pointers to pointers, for example. Like, "Oh, no thanks."


00:26:07.680 --> 00:26:13.600
Yeah. Or having to deal with the fact that in Java, everything is a class. You're just like,


00:26:13.600 --> 00:26:19.280
"What is this?" But of course, you understand why if you have that background. But if you're trying


00:26:19.280 --> 00:26:23.520
to learn it yourself, you then have a lot of background you need to cover. But in Python,


00:26:23.520 --> 00:26:26.560
and in R as well, you don't need to cover those things.


00:26:26.560 --> 00:26:30.160
It's super easy to prototype, it's super easy to script.


00:26:30.160 --> 00:26:33.000
The flexibility of Python is what makes it, I think,


00:26:33.000 --> 00:26:34.560
the perfect prototyping language.


00:26:34.560 --> 00:26:37.380
And that's essentially what you're doing, you're prototyping.


00:26:37.380 --> 00:26:40.720
So we talked a little bit earlier about like,


00:26:40.720 --> 00:26:41.840
why not just Excel?


00:26:41.840 --> 00:26:42.760
We didn't quite say that,


00:26:42.760 --> 00:26:45.680
but this was sort of what we were maybe getting at.


00:26:45.680 --> 00:26:48.880
And yeah, we could do some of our work in Excel.


00:26:48.880 --> 00:26:50.280
I've tried this.


00:26:50.280 --> 00:26:53.300
And first I can tell you Excel really starts


00:26:53.300 --> 00:26:56.380
to struggle when you have too many calculations going on under the hood,


00:26:56.380 --> 00:26:59.980
it gets very, very slow. But to be honest, it's sort of just,


00:26:59.980 --> 00:27:03.020
it's just cleaner to code this sort of logic.


00:27:03.020 --> 00:27:06.700
It's much more reproducible when you need to do this iterative sort of stuff.


00:27:06.700 --> 00:27:11.060
And it also means that you can use much more powerful tools.


00:27:11.060 --> 00:27:13.060
So you can say,


00:27:13.060 --> 00:27:17.500
use APIs that developers have made to process your data. You can use powerful.


00:27:17.500 --> 00:27:22.020
- Or get data, right? Like I need live, live currency conversion data,


00:27:22.260 --> 00:27:23.820
Right. So much easier than in Excel.


00:27:23.820 --> 00:27:25.540
Yes, yes, yes. Exactly.


00:27:25.540 --> 00:27:29.600
Like you can like scrape data or you can, yeah, pull


00:27:29.600 --> 00:27:33.480
data in of an API or you can use powerful tools


00:27:33.480 --> 00:27:37.200
like Spark to process 170 billion


00:27:37.200 --> 00:27:40.740
auctions per day in order to reduce it down to something manageable.


00:27:40.740 --> 00:27:43.060
So, yeah, it just gives you a lot more power.


00:27:43.060 --> 00:27:46.880
But at the same time, why we use programming


00:27:46.880 --> 00:27:49.860
languages is it's just such a different focus.


00:27:50.060 --> 00:27:52.380
it's a bit overkill to use something like Java.


00:27:52.380 --> 00:27:55.060
I know some people do do natural language processing in Java,


00:27:55.060 --> 00:27:58.860
but that's more on the engineering side to build maintainable systems.


00:27:58.860 --> 00:28:02.860
>> One of the things I like to say when thinking about how people who are coming


00:28:02.860 --> 00:28:06.340
from tangential interests like biology or whatever,


00:28:06.340 --> 00:28:09.900
is you can be really effective with Python and I suspect R as well,


00:28:09.900 --> 00:28:14.500
with a really partial understanding of what Python is and what it does.


00:28:14.500 --> 00:28:16.940
You pointed out you don't even have to know what a class is or


00:28:16.940 --> 00:28:19.780
even really how to create a function.


00:28:19.780 --> 00:28:26.780
You just, I can put these six magical incantations in a file and then I can do way more than otherwise could, right?


00:28:26.780 --> 00:28:30.580
Then you learn one more, you make it better and better as you kind of gain experience.


00:28:30.580 --> 00:28:36.580
Pretty much, and this is where I started, like, obviously I learned what functions and classes were when I first started programming.


00:28:36.580 --> 00:28:43.080
But in the end, you will just, maybe it's not the best thing and we can sort of maybe get into this.


00:28:43.080 --> 00:28:48.120
I suppose part of the confusion or not confusion, but internal debate I've had over the years is


00:28:48.120 --> 00:28:54.120
how good does data science code really need to be? Like, how much would data scientists benefit


00:28:54.120 --> 00:28:59.240
from knowing more about computer science topics or software engineering topics, maybe more to


00:28:59.240 --> 00:29:03.640
the point? And, you know, because like the thing is, every field has so much to learn.


00:29:03.640 --> 00:29:06.680
Don't even get started on what's happening with large language models at the moment. Like,


00:29:06.680 --> 00:29:11.560
it's just overwhelming. Should we take some of our precious time and learn software engineering


00:29:11.560 --> 00:29:14.200
concepts. I'm not sure. Like, I'm not sure if I have the answer to that.


00:29:14.200 --> 00:29:21.160
This portion of Talk Python to Me is brought to you by Prodigy, a data annotation tool from


00:29:21.160 --> 00:29:27.320
Explosion AI. Prodigy is created by Ines Montani and her team at Explosion, and she's been doing


00:29:27.320 --> 00:29:32.840
machine learning and NLP for a long time. Ines is a friend and frequent guest on the show,


00:29:32.840 --> 00:29:37.160
and if you've listened to any of her episodes, you know that she knows her ML tools.


00:29:37.160 --> 00:29:43.240
So what is Prodigy? It's a modern, scriptable annotation tool for machine learning developers


00:29:43.240 --> 00:29:49.800
made by the team behind the popular NLP library, spaCy. You can easily and visually annotate and


00:29:49.800 --> 00:29:55.080
develop data for named entity recognition, text classification, span categorization,


00:29:55.080 --> 00:30:01.160
computer vision, audio, video, and more, and put your model in the loop for even faster results.


00:30:01.160 --> 00:30:05.560
After collecting data, you can quickly train and export a custom spaCy model


00:30:05.560 --> 00:30:09.400
or download annotations to use it with any other library or framework.


00:30:09.400 --> 00:30:13.720
Prodigy is entirely scriptable, in Python of course, the language we all love,


00:30:13.720 --> 00:30:16.600
and it seamlessly integrates with your favorite libraries and tools.


00:30:16.600 --> 00:30:22.840
Plus, the new alpha version they just released also introduces a built-in support for large


00:30:22.840 --> 00:30:28.440
language models such as OpenAI's GPT models, and new tools for dividing up your data between


00:30:28.440 --> 00:30:33.880
multiple annotators. TalkByThon listeners get a massive discount on a lifetime license.


00:30:33.880 --> 00:30:37.640
You'll get 25% off using the discount code Talk Python.


00:30:37.640 --> 00:30:40.120
But don't wait too long. This offer does expire.


00:30:40.120 --> 00:30:47.400
Get Prodigy at talkpython.fm/Prodigy and use our code Talk Python, all caps,


00:30:47.400 --> 00:30:50.120
to save 25% off a personal license.


00:30:50.120 --> 00:30:52.760
This link is in your podcast player show notes.


00:30:52.760 --> 00:30:55.080
Thank you to Explosion AI for sponsoring the show.


00:30:55.080 --> 00:31:02.120
I think it really depends on what kind of data scientist you are.


00:31:02.680 --> 00:31:06.120
if what you are is someone doing research, as you described before,


00:31:06.120 --> 00:31:11.400
you're like, is there a trend between the type of device that they use to buy their thing


00:31:11.400 --> 00:31:17.320
at our store and how much they're buying on the second, you know, how much are likely to come


00:31:17.320 --> 00:31:21.800
back? Like if they're using an iPhone, do they, do they tend to spend more than if they're using


00:31:21.800 --> 00:31:26.680
an Android? And is that a thing that we should consider or, you know, is there any like that


00:31:26.680 --> 00:31:31.720
kind of exploration, which you can judge whether or not you should make that exploration, but


00:31:32.440 --> 00:31:35.480
just put that aside for a minute. That kind of stuff, like once you


00:31:35.480 --> 00:31:39.280
know that answer, maybe you don't need to run that code again. Maybe you don't care. You just


00:31:39.280 --> 00:31:42.640
you just want to kind of discover if there is a trend. And there,


00:31:42.640 --> 00:31:47.000
maybe you need to know software engineering techniques, but should you be writing unit tests for that?


00:31:47.000 --> 00:31:51.040
I'd say maybe not, honestly. On the other hand, if your job is to


00:31:51.040 --> 00:31:56.600
create a model that's going to go into production, that's going to run behind a flask or fast API endpoint,


00:31:56.600 --> 00:31:59.400
then you're kind of in the realm of


00:31:59.400 --> 00:32:04.880
continuously running for many people over a long time. And I think that really is a different situation.


00:32:04.880 --> 00:32:08.680
I think this is where you actually move from data science to machine learning engineering.


00:32:08.680 --> 00:32:15.720
This term has a lot of different definitions. For me, I base my definition of ML engineers on the two people that I've worked with,


00:32:15.720 --> 00:32:23.400
who were like true full stack kind of people who could go from research and prototyping to deployment.


00:32:23.400 --> 00:32:32.880
And they were data scientists who really cared enough to actually learn how to do proper engineering, and they could actually deploy their own things.


00:32:32.880 --> 00:32:39.440
But then this leads to another one of my very favorite topics, which is who is responsible for apps in production.


00:32:39.440 --> 00:32:41.920
And here's the thing.


00:32:41.920 --> 00:32:49.560
So I think as good as your data scientist is going to be, or your ML engineer, let's say an ML engineer, let's say that they can actually deploy their own code.


00:32:49.560 --> 00:32:54.840
If they're then responsible for that code in production, that then eats up the time that they


00:32:54.840 --> 00:33:00.600
can be prototyping and researching new things for you. So the conclusion I've come to over time,


00:33:00.600 --> 00:33:06.680
and again, this is a matter of debate. This is just my opinion. Basically, I think if your company


00:33:06.680 --> 00:33:12.120
is above any sort of level of size or complexity in terms of the data products it has, I think you


00:33:12.120 --> 00:33:17.800
really do need dedicated data science and engineering teams. Because in the end, no matter


00:33:17.800 --> 00:33:20.560
how good your data scientist code is going to be.


00:33:20.560 --> 00:33:23.520
It needs to be implemented by the person who's going to maintain it.


00:33:23.520 --> 00:33:26.720
And maybe they're not the ones writing the code from scratch.


00:33:26.720 --> 00:33:29.520
Maybe they can adapt the data scientist code if it's good enough.


00:33:29.520 --> 00:33:33.600
But in the end, they need to be comfortable and familiar enough with that code to be


00:33:33.600 --> 00:33:38.320
like, yeah, if I get pinged at three in the morning, I'm OK knowing what to do with


00:33:38.320 --> 00:33:40.120
this code. Yeah, that's a good point.


00:33:40.120 --> 00:33:44.480
Yeah. So I think it's just easier to scale these teams in parallel rather than trying to


00:33:44.480 --> 00:33:47.520
hire this like all in one person who can do everything.


00:33:47.520 --> 00:33:48.780
they're impossible to hire.


00:33:48.780 --> 00:33:51.400
Like I've only ever met two over the course of my career


00:33:51.400 --> 00:33:54.080
and quickly they become overwhelmed


00:33:54.080 --> 00:33:55.600
by having to maintain projects.


00:33:55.600 --> 00:33:57.320
- Right, is that the best use of their time?


00:33:57.320 --> 00:33:59.920
- Yeah, and like it's maybe it's not necessarily


00:33:59.920 --> 00:34:01.840
even if it's the best use of their time,


00:34:01.840 --> 00:34:05.560
it's more like then who's gonna do your research


00:34:05.560 --> 00:34:07.920
because now you've used up that resource


00:34:07.920 --> 00:34:10.000
on maintaining two or three projects.


00:34:10.000 --> 00:34:11.600
- Right, absolutely.


00:34:11.600 --> 00:34:13.280
Chris May's got an interesting question


00:34:13.280 --> 00:34:14.120
out here in the audience.


00:34:14.120 --> 00:34:15.760
It's kind of turns us on a little bit.


00:34:15.760 --> 00:34:17.160
It says, "Development teams tend to work better


00:34:17.160 --> 00:34:19.720
and they focus on writing and refactoring code


00:34:19.720 --> 00:34:21.960
to make it testable and understandable.


00:34:21.960 --> 00:34:24.600
And we've talked a little bit about maybe stuff


00:34:24.600 --> 00:34:27.160
that data scientists shouldn't care about or whatever.


00:34:27.160 --> 00:34:31.000
So are there ideas that are like good practices


00:34:31.000 --> 00:34:33.560
for data scientists and teams of them?


00:34:33.560 --> 00:34:35.480
- This is actually a really great question.


00:34:35.480 --> 00:34:39.040
So basically, it's an interesting thing with data scientists


00:34:39.040 --> 00:34:41.280
that unlike software developers,


00:34:41.280 --> 00:34:44.280
we often tend to work alone on projects


00:34:44.280 --> 00:34:46.200
or maybe in very, very small teams,


00:34:46.200 --> 00:34:48.680
like maybe two or three people.


00:34:48.680 --> 00:34:53.360
And I think it's probably a hangover from the fact a lot of us at XAcademics,


00:34:53.360 --> 00:34:57.320
we're just used to having like, it's not great, but it's...


00:34:57.320 --> 00:35:01.560
A whiteboard, an office in the corner and no one knows what you're doing.


00:35:01.560 --> 00:35:05.440
Exactly. And no one cares. That paper that three people read,


00:35:05.440 --> 00:35:10.480
took me three years. So what I think has been neglected,


00:35:10.480 --> 00:35:14.400
you know, aside from learning software engineering best practices,


00:35:14.520 --> 00:35:19.160
is more fundamental things, which is like writing maintainable code. And I don't mean maintainable


00:35:19.160 --> 00:35:26.120
in the sense of it's a system that needs to be able to run regularly. It's more like this is a


00:35:26.120 --> 00:35:31.000
piece of code that I can come back to in six months and understand what I was doing. Because,


00:35:31.000 --> 00:35:35.720
you know, research projects can be shelved forever, but maybe they need to be revisited


00:35:35.720 --> 00:35:40.920
and, you know, built upon. So, this was actually a topic I got really interested when I first


00:35:40.920 --> 00:35:45.920
move to industry, like the idea of reproducibility with data science projects.


00:35:45.920 --> 00:35:49.920
It's about the code, but it's also about things like dependency management, which


00:35:49.920 --> 00:35:56.360
is notoriously difficult in Python to get reproducible environments later.


00:35:56.360 --> 00:35:58.240
And even the operating system.


00:35:58.240 --> 00:36:03.240
If Linux has really dramatically changed over time, then maybe, maybe your, your


00:36:03.240 --> 00:36:06.200
dependency, your old dependency, you want to keep that one, but it won't run on the


00:36:06.200 --> 00:36:09.880
new operating system or there's a whole spectrum of challenges there.


00:36:09.960 --> 00:36:17.280
Exactly. Exactly. And it's sort of something that can be solved with using poetry, which is a little bit more robust.


00:36:17.280 --> 00:36:23.840
But even then, it's you've still got it like it runs on my machine effect where your machine will not be the same machine.


00:36:23.840 --> 00:36:31.320
Increasingly, there's actually a move towards doing more sort of cloud-based stuff for data science, which solves a few of these problems.


00:36:31.320 --> 00:36:36.320
And it also solves the additional problem where data scientists often need to do remote development for various reasons.


00:36:36.320 --> 00:36:40.080
like you need access to GPUs in order to train models.


00:36:40.080 --> 00:36:44.400
So, you know, obviously, if you have a server, you have a Docker


00:36:44.400 --> 00:36:48.280
container which has environment specifications, you can power up that exact same


00:36:48.280 --> 00:36:51.120
environment. And that actually helps with that reproducibility a lot.


00:36:51.120 --> 00:36:55.440
And then another point which I think is really important


00:36:55.440 --> 00:36:59.040
for data scientists and can be neglected is literate programming.


00:36:59.040 --> 00:37:01.160
So this is an idea from Donald Knuth.


00:37:01.160 --> 00:37:05.520
And it's this idea that you should write your code in such a way


00:37:05.680 --> 00:37:11.680
that it's actually understandable later. With data science work, it's also that you really


00:37:11.680 --> 00:37:16.720
need to document a lot of the implicit kind of assumptions that you make or decisions that you


00:37:16.720 --> 00:37:21.120
make as part of the research project process. And this is one of the reasons, probably a good


00:37:21.120 --> 00:37:26.560
segue, why Jupyter is so important. Jupyter notebooks are designed to be research documents.


00:37:26.560 --> 00:37:30.240
So this is why you have the markdown cells if you've seen a Jupyter notebook,


00:37:30.240 --> 00:37:35.680
because it's this idea that you really, really need to document along with the code,


00:37:35.680 --> 00:37:41.040
the decisions that you made. Like, why did you choose this sample? Why did you decide to create


00:37:41.040 --> 00:37:44.880
the inputs to your models the way that you did it? You need to document all this stuff. So,


00:37:44.880 --> 00:37:49.360
yeah, reproducibility is a super interesting topic. And I think it's, yeah, something that


00:37:49.360 --> 00:37:54.800
really needs to be thought about carefully, even if you're not collaborating with anyone else,


00:37:54.800 --> 00:37:58.160
because otherwise your piece of research is going to be worthless in three months,


00:37:58.160 --> 00:37:59.500
'cause you're not gonna remember what you did.


00:37:59.500 --> 00:38:01.340
- I think notebooks are quite interesting.


00:38:01.340 --> 00:38:02.760
They go a long ways to solving that.


00:38:02.760 --> 00:38:04.640
When used in the right way,


00:38:04.640 --> 00:38:07.420
you can just jam a bunch of non-understandable stuff in there


00:38:07.420 --> 00:38:09.760
and it's just, well, now it's not understandable,


00:38:09.760 --> 00:38:11.680
but it's in a webpage instead of in an editor.


00:38:11.680 --> 00:38:14.860
But I think as in, you know, not just programmers,


00:38:14.860 --> 00:38:16.400
but tech in general,


00:38:16.400 --> 00:38:21.400
we're just bad at thinking about the long-term life cycle


00:38:21.400 --> 00:38:24.620
of information and compute.


00:38:24.620 --> 00:38:27.000
For example, I got a new heat pump


00:38:27.000 --> 00:38:32.440
to replace the furnace at my house. The manual for it came on a CD drive and I'm like, I don't


00:38:32.440 --> 00:38:37.720
think I have a CD. Where did I put that? I would go dig through a closet full of electronics. I'm


00:38:37.720 --> 00:38:44.440
not sure I can read that, right? And CDs seem so ubiquitous for so long, right? And just simple


00:38:44.440 --> 00:38:50.760
little mismatches like that just get worse over time. It's going to be tough to keep some of this


00:38:50.760 --> 00:38:56.120
older research and reproducibility around. >> Yeah, like it's super interesting that


00:38:56.120 --> 00:39:01.120
There are packages I used to use, you know, back when I first started in natural language processing.


00:39:01.120 --> 00:39:03.520
Some of them haven't been updated from Python 2.


00:39:03.520 --> 00:39:04.820
So I can't use them anymore.


00:39:04.820 --> 00:39:07.920
Because they were just some, probably like a PhD project,


00:39:07.920 --> 00:39:12.220
and no one really had the time or energy to maintain it after that person graduated.


00:39:12.220 --> 00:39:16.220
And the person graduated, got a job and doesn't really care that much anymore, potentially.


00:39:16.220 --> 00:39:16.720
Exactly.


00:39:16.720 --> 00:39:17.720
Not enough to keep it going.


00:39:17.720 --> 00:39:19.620
Yeah, it's not even necessarily their fault.


00:39:19.620 --> 00:39:21.020
It's just life.


00:39:21.020 --> 00:39:21.820
Yeah, yeah.


00:39:21.820 --> 00:39:24.620
Let's talk about some of the libraries and tools.


00:39:24.620 --> 00:39:25.820
You mentioned Jupyter.


00:39:25.820 --> 00:39:29.420
I think Jupiter is one of the absolute cornerstones, right?


00:39:29.420 --> 00:39:33.340
So, Jupiter or Jupiter Lab? What are your thoughts here?


00:39:33.340 --> 00:39:38.540
It's funny, actually, for years I was just working in Jupiter, playing Jupiter on my computer.


00:39:38.540 --> 00:39:42.140
Maybe give people a quick summary of the difference, just so, who don't know.


00:39:42.140 --> 00:39:46.540
Very good idea. So basically, Jupiter is, I suppose you could call it an editor.


00:39:46.540 --> 00:39:51.900
It's basically an interactive document which you run against a Python kernel,


00:39:51.900 --> 00:39:55.740
or you can run it against different language kernels. There are, there are Julia, there are


00:39:55.740 --> 00:39:59.540
Kotlin notebooks. Should I give my little advertisement for JetBrains? Basically, what


00:39:59.540 --> 00:40:04.940
you can do is you can run code in cell blocks. Then you can also create markdown cells in


00:40:04.940 --> 00:40:10.500
between them. And this allows you to basically have markdown chunks and then cell chunks.


00:40:10.500 --> 00:40:16.220
JupyterLab is hosted remotely. So you have basically a bunch of other functionality built


00:40:16.220 --> 00:40:20.740
in so you can open terminals, you can create scripts, things like that. But basically,


00:40:20.740 --> 00:40:25.800
It's like a little Jupyter ecosystem, which is designed to be remotely hosted, and it


00:40:25.800 --> 00:40:28.880
can be accessed simultaneously by several people.


00:40:28.880 --> 00:40:35.220
So I would say Jupyter is good if you are just starting out and you're dealing with


00:40:35.220 --> 00:40:37.100
small data sets.


00:40:37.100 --> 00:40:42.540
Maybe you're even retrieving things from databases, but you're not saving anything too heavy locally.


00:40:42.540 --> 00:40:46.020
You're not using a huge amount of memory, like maybe unless you got one of those new


00:40:46.020 --> 00:40:48.940
M2 Macs and server in your office.


00:40:48.940 --> 00:40:49.940
So go for it.


00:40:49.940 --> 00:40:56.180
Yeah, JupyterLab, I think is good if basically you need to access different types of machines.


00:40:56.180 --> 00:41:00.420
So maybe you need to be able to access GPU machines easily. You kind of want that remote


00:41:00.420 --> 00:41:05.060
first experience where you don't have to then connect to a remote machine. And I have found


00:41:05.060 --> 00:41:09.620
JupyterLab helpful in the past for sharing. But the thing you can't do with JupyterLab


00:41:09.620 --> 00:41:13.540
is real-time collaboration. And that's a bit of a pain in the butt. Obviously,


00:41:13.540 --> 00:41:18.820
since I started at JetBrains, I kind of, you know, like I'm using our tools and I like them a lot.


00:41:18.820 --> 00:41:20.260
Obviously I wouldn't advocate them.


00:41:20.260 --> 00:41:23.140
Yeah, I was going to ask, is this PyCharm, Dataspell?


00:41:23.140 --> 00:41:26.660
When you actually do that, are you using some of those type of tools?


00:41:26.660 --> 00:41:31.060
I am. So I won't turn this into too much of an advertiser for our tools,


00:41:31.060 --> 00:41:33.220
because it's not really the point of me being here.


00:41:33.220 --> 00:41:38.580
But we've kind of tried, or my teams have tried to solve some of these problems that


00:41:38.580 --> 00:41:41.300
you might have with just using plain Jupyter notebooks,


00:41:41.300 --> 00:41:46.100
or even working with JupyterLab, maybe a bit more, like, robustly.


00:41:46.100 --> 00:41:50.060
So we have actually three data science projects, products.


00:41:50.060 --> 00:41:52.780
We have PyCharm and Dataspell, which you've mentioned.


00:41:52.780 --> 00:41:55.260
They're desktop IDEs with the ability


00:41:55.260 --> 00:41:57.100
to connect to remote machines,


00:41:57.100 --> 00:41:58.740
but they're not really collaborative,


00:41:58.740 --> 00:42:01.500
but they do give you like really like nice experience


00:42:01.500 --> 00:42:04.140
with using Jupyter debugging and co-completion


00:42:04.140 --> 00:42:05.420
and all those sort of things.


00:42:05.420 --> 00:42:07.260
We have another one, which is Datalore.


00:42:07.260 --> 00:42:09.500
And this falls into those managed notebooks


00:42:09.500 --> 00:42:12.400
that I was talking about, it's cloud hosted.


00:42:12.400 --> 00:42:13.980
And the nice thing about Datalore actually


00:42:13.980 --> 00:42:17.860
you can do real-time collaboration. So it sort of helps overcome...


00:42:17.860 --> 00:42:18.860
- Comp style, sort of.


00:42:18.860 --> 00:42:21.020
- Yes, it's the same technology, actually. So...


00:42:21.020 --> 00:42:21.500
- Okay.


00:42:21.500 --> 00:42:27.340
- Yeah. So it's kind of a very interesting thing because there will be times where, you know,


00:42:27.340 --> 00:42:31.580
maybe you're not working on a project with a data scientist, but you need them to have a look at


00:42:31.580 --> 00:42:37.420
your work. And when I was working with JupyterLab, what we would do is we would clone the notebook


00:42:37.420 --> 00:42:42.620
to our own folder, and then we were in the same environment, so it was okay. And you would rerun


00:42:42.620 --> 00:42:46.060
the whole thing again. And sometimes it would be pretty time consuming.


00:42:46.060 --> 00:42:52.140
Datalore is an alternative to that. It may or may not be kind of your style. But it's pretty cool


00:42:52.140 --> 00:42:57.100
because you can actually just invite someone to the same notebook instance that you're in,


00:42:57.100 --> 00:43:01.820
and you're basically hosting them. And they have access to everything that you've already run.


00:43:01.820 --> 00:43:04.060
So it's like true kind of real time.


00:43:04.060 --> 00:43:08.060
Yeah, that's nice. Because sometimes a cell has to run for 30 minutes,


00:43:08.060 --> 00:43:11.340
but then it has this nice little answer and you can work with that afterwards, right?


00:43:11.340 --> 00:43:14.300
- Exactly, or you want a model to be available


00:43:14.300 --> 00:43:16.340
and maybe you haven't saved it or something.


00:43:16.340 --> 00:43:18.300
Like this is just a way around


00:43:18.300 --> 00:43:19.660
some of these friction points.


00:43:19.660 --> 00:43:21.620
- I want to circle back just really quickly


00:43:21.620 --> 00:43:24.420
for a testimony, I guess, out in the audience.


00:43:24.420 --> 00:43:27.060
Michael says, "I started teaching basic Git,


00:43:27.060 --> 00:43:28.480
"Docker and Python packaging


00:43:28.480 --> 00:43:31.440
"to bioinformatics students at UCLA


00:43:31.440 --> 00:43:33.900
"and it's made a huge difference in the handoff."


00:43:33.900 --> 00:43:36.180
And I think for actual projects,


00:43:36.180 --> 00:43:38.100
you know, I just think, as we were talking about


00:43:38.100 --> 00:43:39.940
what should people learn at data science


00:43:39.940 --> 00:43:40.780
and what they shouldn't,


00:43:40.780 --> 00:43:44.380
A little bit of the fluency with some of these tools is really helpful.


00:43:44.380 --> 00:43:45.980
I absolutely agree.


00:43:45.980 --> 00:43:48.380
I know it can be really overwhelming,


00:43:48.380 --> 00:43:51.060
especially Git initially for students.


00:43:51.060 --> 00:43:53.100
Git is overwhelming at first.


00:43:53.100 --> 00:43:57.260
Yeah. I would say because I tend to work on things by myself.


00:43:57.260 --> 00:43:59.780
Yeah. This falls into


00:43:59.780 --> 00:44:02.980
the reproducibility and stuff that I was talking about earlier.


00:44:02.980 --> 00:44:05.260
It's super, super important.


00:44:05.260 --> 00:44:08.140
Once you get comfortable with just basic use of these tools,


00:44:08.140 --> 00:44:09.300
you can get really far.


00:44:09.300 --> 00:44:12.800
Okay. Back to some of the tools, Jupyter, JupyterLab.


00:44:12.800 --> 00:44:14.400
What about JupyterLite?


00:44:14.400 --> 00:44:15.960
Have you, have you played with JupyterLite?


00:44:15.960 --> 00:44:16.240
Any?


00:44:16.240 --> 00:44:20.000
Only a teeny tiny bit because of this workshop that I'm going to be


00:44:20.000 --> 00:44:21.600
helping out with at EuroPython.


00:44:21.600 --> 00:44:25.200
So they're going to be running the whole thing in, in JupyterLite, hopefully.


00:44:25.200 --> 00:44:28.960
Couple of bugs to solve, but I think they're overcomable, but yeah, it's a


00:44:28.960 --> 00:44:33.180
really interesting alternative to Google Colab actually.


00:44:33.180 --> 00:44:33.480
Yeah.


00:44:33.520 --> 00:44:39.400
JupyterLite, take Pyodied, which is CPython running a WebAssembly,


00:44:39.400 --> 00:44:42.820
and then build a bunch of the data science libraries


00:44:42.820 --> 00:44:44.820
like Matplotlib and stuff in WebAssembly.


00:44:44.820 --> 00:44:48.400
And then the benefit is you don't need a complex server


00:44:48.400 --> 00:44:51.480
to handle the compute and run arbitrary Python code,


00:44:51.480 --> 00:44:52.560
which is a little sketchy.


00:44:52.560 --> 00:44:54.600
You just run it on the front end in WebAssembly,


00:44:54.600 --> 00:44:55.600
which is pretty cool.


00:44:55.600 --> 00:44:59.120
I interviewed the folks at PySport a little while ago.


00:44:59.120 --> 00:45:02.320
And it's just the ability to just take code


00:45:02.320 --> 00:45:06.000
and run all these different pieces on your front end


00:45:06.000 --> 00:45:08.640
without worrying about a server, I think is super cool.


00:45:08.640 --> 00:45:11.080
If I get that right or not, but anyway,


00:45:11.080 --> 00:45:14.120
just I think running it on top of people using it,


00:45:14.120 --> 00:45:17.000
on top of the browsers, like you do JavaScript,


00:45:17.000 --> 00:45:18.880
is it's an interesting thing to throw


00:45:18.880 --> 00:45:20.640
into the mix for notebooks.


00:45:20.640 --> 00:45:22.440
- Actually, a lot of these projects coming out


00:45:22.440 --> 00:45:24.160
using Pyodide are really interesting.


00:45:24.160 --> 00:45:26.960
Obviously, PyScript is the big one from last year.


00:45:26.960 --> 00:45:29.520
- Yeah, I think PyScript actually has really


00:45:29.520 --> 00:45:31.320
lots of interesting possibilities


00:45:31.320 --> 00:45:33.060
beyond just the data science side, right?


00:45:33.060 --> 00:45:36.620
Whereas Pyodide is a little more focused on just,


00:45:36.620 --> 00:45:38.620
I think, really providing the data science tools


00:45:38.620 --> 00:45:40.340
on the client side.


00:45:40.340 --> 00:45:41.420
We'll see where PyScript goes.


00:45:41.420 --> 00:45:44.620
If they can make an equivalent of Vue.js


00:45:44.620 --> 00:45:45.500
or something like that,


00:45:45.500 --> 00:45:47.100
where people can start building


00:45:47.100 --> 00:45:50.060
legitimate front-end interactive web apps,


00:45:50.060 --> 00:45:52.940
like Airbnb or Google Maps or something,


00:45:52.940 --> 00:45:55.300
but with Python, that's gonna unlock something


00:45:55.300 --> 00:45:58.160
that has been locked away for a really long time.


00:45:58.160 --> 00:46:01.360
With PioDyte, you know, that's like a nine or 10 meg download.


00:46:01.360 --> 00:46:05.400
That's too much for the front end, just for like a public facing site generally


00:46:05.400 --> 00:46:09.640
at the start of time, but they're moving it to MicroPython as an option.


00:46:09.640 --> 00:46:12.920
And that's a couple hundred K, which is like these other front end frameworks.


00:46:12.920 --> 00:46:14.000
So it's very exciting.


00:46:14.000 --> 00:46:17.160
I think that's going to be, that's definitely the most exciting thing in that area.


00:46:17.160 --> 00:46:18.680
But all right, back to data science.


00:46:18.680 --> 00:46:20.160
Let's see where you want to go next.


00:46:20.160 --> 00:46:21.280
You want to talk pandas maybe?


00:46:21.280 --> 00:46:24.280
- Yeah, let's jump into pandas, which is the other, the other biggie


00:46:24.280 --> 00:46:26.160
when you're talking about data science.


00:46:26.160 --> 00:46:31.520
So what pandas is really important for is, it's basically the entry point of you working with


00:46:31.520 --> 00:46:38.240
your data. So it's a library, which basically allows you to work with data frames, data frames,


00:46:38.240 --> 00:46:43.920
basically tables. And from there, you can do data manipulation, you can explore your data and


00:46:43.920 --> 00:46:50.240
visualize it. And it also is an entry point to passing your data into models. Sometimes it'll


00:46:50.240 --> 00:46:54.720
need additional transformations, but say scikit-learn, which we can talk about in a sec,


00:46:54.720 --> 00:46:59.320
you can basically pass Panda's data frames directly into scikit-learn models.


00:46:59.320 --> 00:47:03.280
Panda's also, because of its popularity, has kind of opened up this


00:47:03.280 --> 00:47:08.880
easy access to grid computing and other types of processing


00:47:08.880 --> 00:47:10.880
database stuff that


00:47:10.880 --> 00:47:12.880
you don't really need to learn those tools,


00:47:12.880 --> 00:47:16.240
but you get to take advantage of. And so two things that come to mind for me are Dask.


00:47:16.240 --> 00:47:16.800
Yes.


00:47:16.800 --> 00:47:21.360
It's kind of like a Panda's code, but instead,


00:47:21.360 --> 00:47:25.520
you can say actually run this across this cluster of machines


00:47:25.520 --> 00:47:29.320
or larger than memory or stuff on my personal computer


00:47:29.320 --> 00:47:34.920
or even just take advantage of all 10 cores on my M2 instead of the one.


00:47:34.920 --> 00:47:35.520
Yes.


00:47:35.520 --> 00:47:37.200
Have you done anything with Dask? Are you a fan of it?


00:47:37.200 --> 00:47:39.360
I was kind of there when Dask was new.


00:47:39.360 --> 00:47:43.160
And let's just say they find out a lot of the bugs.


00:47:43.160 --> 00:47:43.960
Yeah, yeah.


00:47:43.960 --> 00:47:46.800
So what ended up happening was I ended up learning PySpark instead.


00:47:46.800 --> 00:47:49.720
So I went down a different kind of route.


00:47:49.720 --> 00:47:52.400
But I think, you know, they solve very similar problems.


00:47:52.400 --> 00:47:55.160
It's just Dask is much more similar to pandas.


00:47:55.160 --> 00:47:57.920
And so you don't really need to deal with learning.


00:47:57.920 --> 00:48:00.400
It's similar, but it's a new API.


00:48:00.400 --> 00:48:03.920
Yeah. Another one that I was thinking of, I just had these guys on the show, sort of,


00:48:03.920 --> 00:48:05.120
is Ponder.


00:48:05.120 --> 00:48:07.320
Oh, I have not heard of this.


00:48:07.320 --> 00:48:11.200
So Ponder, they were at startup row at PyCon.


00:48:11.200 --> 00:48:13.560
And they basically build on top of Moden,


00:48:13.560 --> 00:48:16.240
which is important, moden.pandas as PD.


00:48:16.240 --> 00:48:17.360
And what it does is it,


00:48:17.360 --> 00:48:20.560
instead of pulling all the data back and executing the commands


00:48:20.560 --> 00:48:23.600
on your machine in memory, which maybe that data transfer is huge,


00:48:23.600 --> 00:48:26.440
it actually runs it inside of Postgres and other data,


00:48:26.440 --> 00:48:28.560
and I think PySpark as well.


00:48:28.560 --> 00:48:32.200
Like it translates all these pandas commands to SQL commands


00:48:32.200 --> 00:48:34.840
to run inside the database where the data is,


00:48:34.840 --> 00:48:37.280
which is also a pretty interesting thing.


00:48:37.280 --> 00:48:38.440
That is amazing.


00:48:38.440 --> 00:48:41.240
So yeah, it's just interpreting the code in a completely different way.


00:48:41.240 --> 00:48:44.160
You can do like query planning and optimize the code.


00:48:44.160 --> 00:48:45.520
Yeah, exactly.


00:48:45.520 --> 00:48:48.440
- I think they said that df.describe


00:48:48.440 --> 00:48:50.400
is like 300 lines of SQL.


00:48:50.400 --> 00:48:51.560
It's really, really tough.


00:48:51.560 --> 00:48:53.400
But once this thing writes it, then it's good to go.


00:48:53.400 --> 00:48:55.200
And I think the reason I bring this up is like,


00:48:55.200 --> 00:48:56.480
you don't have to write that code.


00:48:56.480 --> 00:48:58.080
You just have to know Pandas.


00:48:58.080 --> 00:49:00.280
And then all of a sudden, there's these libraries


00:49:00.280 --> 00:49:01.800
that'll do either grid computing


00:49:01.800 --> 00:49:05.160
or really complex SQL queries that you don't care about.


00:49:05.160 --> 00:49:06.240
- Yes. - You don't care to write


00:49:06.240 --> 00:49:07.080
or so on.


00:49:07.080 --> 00:49:09.160
So I think it's, Pandas is interesting on its own,


00:49:09.160 --> 00:49:10.560
but it's almost like a gateway


00:49:10.560 --> 00:49:12.400
to the broader data science community.


00:49:12.400 --> 00:49:13.360
- Agreed, agreed.


00:49:13.360 --> 00:49:18.000
And it's such a de facto, I think, for data analysis now


00:49:18.000 --> 00:49:20.740
or data manipulation transformation.


00:49:20.740 --> 00:49:23.320
Yeah, like I don't see it going away anytime soon.


00:49:23.320 --> 00:49:27.120
And actually, Pandas 2.0 just came out.


00:49:27.120 --> 00:49:28.760
And instead of being, yeah,


00:49:28.760 --> 00:49:31.880
instead of, Pandas is NumPy under the hood,


00:49:31.880 --> 00:49:34.800
which is fast, but it's not really equipped


00:49:34.800 --> 00:49:38.680
to deal with certain kinds of structures like strings,


00:49:38.680 --> 00:49:41.400
because, you know, it's not really what NumPy is about.


00:49:41.400 --> 00:49:44.920
and also missing values, the way that it handles it is pretty janky.


00:49:44.920 --> 00:49:48.360
So yeah, it's been rewritten with PyArrow under the hood.


00:49:48.360 --> 00:49:48.680
>> Right.


00:49:48.680 --> 00:49:52.040
>> Yeah. Apparently, the performance is so much better.


00:49:52.040 --> 00:49:54.520
Something I need to sit down and actually try.


00:49:54.520 --> 00:49:57.920
It's been out for like a month and I'm feeling a bit bad, but yeah.


00:49:57.920 --> 00:49:59.980
>> Yeah, that's cool. It probably has support for some of


00:49:59.980 --> 00:50:03.360
the serialization formats to back up our term like,


00:50:03.360 --> 00:50:06.440
I said, Parquet and some of those types of things.


00:50:06.440 --> 00:50:08.840
I think that comes straight out of PyArrow.


00:50:08.840 --> 00:50:09.440
>> Yeah.


00:50:09.440 --> 00:50:14.840
Excellent. So that kind of brings me to a trade-off I wanted to talk to you about before we get off of pandas.


00:50:14.840 --> 00:50:18.880
Although it sounds like pandas 2.0, it makes this less important.


00:50:18.880 --> 00:50:21.980
But you know, another sort of competitor that came out is Polars,


00:50:21.980 --> 00:50:26.580
which is a data framing library for Python written in Rust.


00:50:26.580 --> 00:50:30.220
Many of the things are written in Rust these days when they care about performance.


00:50:30.220 --> 00:50:33.720
It's like a big trend. It's the new C extensions of Python.


00:50:33.720 --> 00:50:37.800
But this one is supposed to also be way faster than pandas 1.


00:50:37.800 --> 00:50:41.900
and I think it's also based on PyArrow amongst other things.


00:50:41.900 --> 00:50:43.200
The details are not super important.


00:50:43.200 --> 00:50:44.500
More what I wanted to ask you is like,


00:50:44.500 --> 00:50:45.760
well, here's another way.


00:50:45.760 --> 00:50:47.080
This is a totally different API.


00:50:47.080 --> 00:50:48.720
It doesn't try to be compatible,


00:50:48.720 --> 00:50:49.880
so you got to learn it.


00:50:49.880 --> 00:50:52.400
The question is, as a data scientist,


00:50:52.400 --> 00:50:54.720
as a data science team leader,


00:50:54.720 --> 00:50:56.120
how should you think about,


00:50:56.120 --> 00:50:59.040
do we keep chasing the shiny new thing,


00:50:59.040 --> 00:51:01.480
or do we stick with stuff that one,


00:51:01.480 --> 00:51:02.680
people know like pandas,


00:51:02.680 --> 00:51:05.200
but two, also extends into


00:51:05.200 --> 00:51:08.720
this broader space as a gateway, as we described, like, what are your thoughts here?


00:51:08.720 --> 00:51:14.480
This is a super interesting question. So data scientists in some ways, have the luxury of


00:51:14.480 --> 00:51:22.720
being able to maybe use newer packages faster, because we build these small kind of atomic


00:51:22.720 --> 00:51:26.880
projects that we can just update to the next library that we feel like using in the next


00:51:26.880 --> 00:51:30.560
project. And maybe we're the only ones who ever look at that code. So it's cool. The


00:51:30.560 --> 00:51:32.600
The problem is though, of course,


00:51:32.600 --> 00:51:36.020
is if someone else needs to look at your code,


00:51:36.020 --> 00:51:38.200
they are gonna need to be able to read it,


00:51:38.200 --> 00:51:40.200
which is not maybe the biggest problem.


00:51:40.200 --> 00:51:43.320
The biggest problem of course, is any new library,


00:51:43.320 --> 00:51:44.920
you have less documentation


00:51:44.920 --> 00:51:47.440
and you have less entries on stack overflows.


00:51:47.440 --> 00:51:49.300
So I would say you need to make a trade-off


00:51:49.300 --> 00:51:52.340
between the time you're not only gonna spend learning it,


00:51:52.340 --> 00:51:54.880
but also debugging it, 'cause it's gonna be slower,


00:51:54.880 --> 00:51:57.680
but your ChatGPT doesn't know much about polars.


00:51:57.680 --> 00:52:00.420
basically you're essentially going to need


00:52:00.420 --> 00:52:01.580
to trade that off against,


00:52:01.580 --> 00:52:03.460
are you gonna see a benefit from that?


00:52:03.460 --> 00:52:07.160
So do you actually have problems


00:52:07.160 --> 00:52:09.180
with processing your data fast enough?


00:52:09.180 --> 00:52:11.260
If you're working on small data sets, probably not.


00:52:11.260 --> 00:52:13.780
If you're not, then maybe try something


00:52:13.780 --> 00:52:15.180
pandas or pandas adjacent.


00:52:15.180 --> 00:52:18.580
- Yeah, that sort of community support side is important.


00:52:18.580 --> 00:52:20.740
And I'm pretty sure there are a lot of data scientists


00:52:20.740 --> 00:52:22.580
out there who are the data,


00:52:22.580 --> 00:52:25.660
the one data scientist at their organization.


00:52:25.660 --> 00:52:26.660
And so it's not like,


00:52:26.660 --> 00:52:29.120
- Oh, we'll go ask the other expert down the hall


00:52:29.120 --> 00:52:31.540
because if it's not you, there's no answer, right?


00:52:31.540 --> 00:52:32.380
- Exactly.


00:52:32.380 --> 00:52:34.980
I do think though, like, it's good to be curious.


00:52:34.980 --> 00:52:37.620
It's good to try out new things as well.


00:52:37.620 --> 00:52:39.540
And again, part of being a data scientist


00:52:39.540 --> 00:52:41.380
is you can experiment a bit more.


00:52:41.380 --> 00:52:42.220
So--


00:52:42.220 --> 00:52:47.220
- You know, 2017, 18, sort of the peak Python two


00:52:47.220 --> 00:52:52.060
versus three tension, I guess, maybe one year before then.


00:52:52.060 --> 00:52:54.300
I noticed that the data scientists were like,


00:52:54.300 --> 00:52:55.420
I don't know what y'all are arguing about.


00:52:55.420 --> 00:52:57.160
we're done with this.


00:52:57.160 --> 00:52:58.540
What we're arguing about is,


00:52:58.540 --> 00:53:00.420
when can we take the Python 2 code out


00:53:00.420 --> 00:53:02.800
to absolutely 100% drop support for it,


00:53:02.800 --> 00:53:04.460
not when are we moving over?


00:53:04.460 --> 00:53:06.940
Whereas people running that Django site


00:53:06.940 --> 00:53:08.420
that's been around for eight years,


00:53:08.420 --> 00:53:10.000
that's still on Python 2,


00:53:10.000 --> 00:53:11.320
they're starting to get nervous


00:53:11.320 --> 00:53:13.380
'cause they don't wanna rewrite it 'cause it works,


00:53:13.380 --> 00:53:15.000
but they know they're gonna have to.


00:53:15.000 --> 00:53:18.700
And I feel like, we talked about the legacy code


00:53:18.700 --> 00:53:22.180
as sort of the success story that is dreaded of software


00:53:22.180 --> 00:53:23.900
on the computer science side.


00:53:23.900 --> 00:53:26.460
because that is less of a thing in data science,


00:53:26.460 --> 00:53:28.660
it's easier to go, well, this next project


00:53:28.660 --> 00:53:29.940
that we're starting in a couple of months,


00:53:29.940 --> 00:53:31.340
we can start with newer tools.


00:53:31.340 --> 00:53:34.340
- Yeah, and I actually remember the point where I decided,


00:53:34.340 --> 00:53:37.340
okay, this is the last project I'm doing into


00:53:37.340 --> 00:53:40.420
because the thing that was keeping me into


00:53:40.420 --> 00:53:43.420
was actually one of those libraries that I mentioned,


00:53:43.420 --> 00:53:45.260
which built by a university.


00:53:45.260 --> 00:53:46.100
And I was like, you know what?


00:53:46.100 --> 00:53:48.100
I'm just gonna go find some alternative tool.


00:53:48.100 --> 00:53:50.280
I think at that time, Spacey,


00:53:50.280 --> 00:53:53.380
which is a very well-known NLP library,


00:53:53.380 --> 00:53:56.220
actually, based here in Berlin, the company.


00:53:56.220 --> 00:53:58.500
- Yeah, exactly, basically a neighbor of yours.


00:53:58.500 --> 00:53:59.820
- That's right.


00:53:59.820 --> 00:54:02.220
But I think Spacey was really getting off its feet


00:54:02.220 --> 00:54:03.100
in that time.


00:54:03.100 --> 00:54:04.340
So I was like, you know what,


00:54:04.340 --> 00:54:06.620
I'm just gonna switch over to this new library and try that.


00:54:06.620 --> 00:54:07.860
And it's excellent.


00:54:07.860 --> 00:54:09.420
So I didn't look back.


00:54:09.420 --> 00:54:10.900
- Yeah, Spacey's cool.


00:54:10.900 --> 00:54:13.140
Enos Montani is doing really great work


00:54:13.140 --> 00:54:15.740
and everyone over at Explosion AI.


00:54:15.740 --> 00:54:18.180
And that's the thing, sometimes it seems like a hassle,


00:54:18.180 --> 00:54:20.780
right, but if it forces you out of your comfort zone


00:54:20.780 --> 00:54:23.020
to pick stuff that's being actively developed,


00:54:23.020 --> 00:54:24.060
maybe it's worth it, right?


00:54:24.060 --> 00:54:24.900
- Exactly.


00:54:24.900 --> 00:54:26.220
- All right, we're getting short on time.


00:54:26.220 --> 00:54:27.860
So you want to give us a lightning round


00:54:27.860 --> 00:54:29.540
and the other important libraries


00:54:29.540 --> 00:54:31.820
you think data scientists should pay attention to?


00:54:31.820 --> 00:54:34.340
- Yeah, so let's just quickly go through


00:54:34.340 --> 00:54:35.820
the visualization side of things.


00:54:35.820 --> 00:54:37.800
So visualization is massive.


00:54:37.800 --> 00:54:40.440
So matplotlib is really the biggie


00:54:40.440 --> 00:54:42.100
and it's what a lot of libraries


00:54:42.100 --> 00:54:44.460
are actually built on top of in Python.


00:54:44.460 --> 00:54:46.860
So the syntax is not that friendly.


00:54:46.860 --> 00:54:49.220
So there's a lot of alternatives.


00:54:49.220 --> 00:54:51.980
So Seaborn is a very popular one.


00:54:51.980 --> 00:54:54.380
we actually have an internal one called Let's Plot,


00:54:54.380 --> 00:54:56.180
which is a port of ggplot2,


00:54:56.180 --> 00:54:57.500
and there's another one called plot9,


00:54:57.500 --> 00:54:58.740
and I think there actually may even be one


00:54:58.740 --> 00:55:00.200
called ggplot.


00:55:00.200 --> 00:55:01.040
Plotly--


00:55:01.040 --> 00:55:02.660
- Some of the fancy new ones that people hear about,


00:55:02.660 --> 00:55:05.500
they're actually internally just controlling Matplotlib


00:55:05.500 --> 00:55:06.860
in a cleaner API, right?


00:55:06.860 --> 00:55:08.620
- Pretty much, and let me tell you,


00:55:08.620 --> 00:55:11.140
Matplotlib needs a clean API, it's a bit,


00:55:11.140 --> 00:55:13.540
let's say archaic.


00:55:13.540 --> 00:55:17.380
- Although, give it some props for its XKCD graph style.


00:55:17.380 --> 00:55:18.900
I mean-- - Yes, yes.


00:55:18.900 --> 00:55:21.940
- That is pretty cool that you can get it to do that.


00:55:21.940 --> 00:55:24.940
- I actually have done,


00:55:24.940 --> 00:55:27.420
I've done XKCD graphs in Python as well.


00:55:27.420 --> 00:55:29.780
It's a goal that you aim for to do like


00:55:29.780 --> 00:55:31.980
elite visualizations.


00:55:31.980 --> 00:55:35.740
- It's fun and XKCD is amazing in a lot of ways.


00:55:35.740 --> 00:55:39.980
However, I think it also can serve an important role


00:55:39.980 --> 00:55:43.420
when you're presenting to like leaders of an organization,


00:55:43.420 --> 00:55:44.540
non-technical people,


00:55:44.540 --> 00:55:46.860
'cause if they look and see a beautiful,


00:55:46.860 --> 00:55:49.020
pristine production already,


00:55:49.020 --> 00:55:50.900
sort of like, we're done.


00:55:50.900 --> 00:55:53.900
No, no, no, this is the prototype. No, we're done. Look, you look, you already got it.


00:55:53.900 --> 00:55:58.500
But if it comes out and sort of cartoony, kind of like wireframing for UI design, you're like,


00:55:58.500 --> 00:56:03.900
oh, there are no expectations. It's done. It's XKCD. We're going to get you the real graphs later, right?


00:56:03.900 --> 00:56:04.600
Yeah, yeah.


00:56:04.600 --> 00:56:05.900
There may be some value there.


00:56:05.900 --> 00:56:10.200
Like a psychological effect where you make it look like a hand-drawn prototype.


00:56:10.200 --> 00:56:12.700
Exactly. It looks just hand-drawn. It's barely done.


00:56:12.700 --> 00:56:13.400
That's right.


00:56:13.400 --> 00:56:14.500
It's really just theme equals.


00:56:14.500 --> 00:56:15.900
It didn't take me two days.


00:56:15.900 --> 00:56:17.100
[Laughter]


00:56:17.100 --> 00:56:19.500
Scikit-learn, you mentioned that before.


00:56:19.500 --> 00:56:25.180
Yes. So there are a whole bunch of libraries for doing machine learning. Scikit-learn is kind of


00:56:25.180 --> 00:56:30.140
your all-in-one for classic machine learning. But then, you know, you have this whole other branch


00:56:30.140 --> 00:56:36.300
of data science, which is around neural nets or deep learning. So you have Keras, TensorFlow,


00:56:36.300 --> 00:56:44.940
you have PyTorch, and then you have a package for working with a lot of like these generative AI


00:56:44.940 --> 00:56:51.420
models or large language models called Transformers from a company called Hugging Face. So, all of


00:56:51.420 --> 00:56:56.300
these are actually super accessible. I wouldn't say TensorFlow and PyTorch can be tricky, but Keras


00:56:56.300 --> 00:57:00.860
is like a friendly front end for them. Actually, if anyone is interested in getting into this side


00:57:00.860 --> 00:57:06.780
of things, there's a book called Deep Learning in Python by a AI researcher at Google called


00:57:06.780 --> 00:57:08.160
called Francois Chollet.


00:57:08.160 --> 00:57:10.360
It is actually, I think,


00:57:10.360 --> 00:57:13.580
the most popular book ever on Manning.


00:57:13.580 --> 00:57:16.000
So it's an amazing book.


00:57:16.000 --> 00:57:17.480
I can only recommend it.


00:57:17.480 --> 00:57:19.680
And it's very gentle for beginners


00:57:19.680 --> 00:57:21.160
who have no background in the area.


00:57:21.160 --> 00:57:22.240
- Okay, yeah, cool.


00:57:22.240 --> 00:57:23.600
I'll put that in the show notes.


00:57:23.600 --> 00:57:25.080
- Awesome. - Yeah.


00:57:25.080 --> 00:57:27.120
All right, well, there are many other things


00:57:27.120 --> 00:57:28.440
we can talk about.


00:57:28.440 --> 00:57:30.200
Maybe just let's close this out


00:57:30.200 --> 00:57:34.160
with a quick shout out to your PyCon talk.


00:57:34.160 --> 00:57:39.160
Eventually, someday, I'm sure that the talks for PyCon


00:57:39.160 --> 00:57:41.160
will be on YouTube.


00:57:41.160 --> 00:57:44.040
They were last year, but I looked back


00:57:44.040 --> 00:57:45.840
and I was so excited near the end of the conference,


00:57:45.840 --> 00:57:47.080
I'm like, "Look, the talks are up."


00:57:47.080 --> 00:57:48.340
And I was talking to someone like,


00:57:48.340 --> 00:57:49.280
"Look, here's your talk."


00:57:49.280 --> 00:57:51.000
They're like, "No, that's my talk from last year."


00:57:51.000 --> 00:57:52.120
I'm like, "Oh." - Aw.


00:57:52.120 --> 00:57:55.120
- Yeah, so it was maybe three or four months delayed


00:57:55.120 --> 00:57:56.160
till it actually came out.


00:57:56.160 --> 00:57:58.720
So maybe this midsummer,


00:57:58.720 --> 00:58:00.520
the video of Virginia Talk will be out,


00:58:00.520 --> 00:58:03.120
but maybe just give people a quick elevator pitch


00:58:03.120 --> 00:58:03.960
of your talk here.


00:58:03.960 --> 00:58:06.360
- Yeah, so I decided to give this talk


00:58:06.360 --> 00:58:09.680
because I kind of had to learn things the hard way


00:58:09.680 --> 00:58:12.080
in terms of performance with Python.


00:58:12.080 --> 00:58:15.440
So basically I used to do everything with loops


00:58:15.440 --> 00:58:18.280
and then I had to start working with larger amounts of data


00:58:18.280 --> 00:58:20.140
and it just doesn't scale.


00:58:20.140 --> 00:58:23.080
So over time, as I got better with Python,


00:58:23.080 --> 00:58:24.720
I learned more about NumPy,


00:58:24.720 --> 00:58:27.240
which is another important data science library.


00:58:27.240 --> 00:58:28.880
And it basically allows you to do


00:58:28.880 --> 00:58:30.480
what's called vectorized operations.


00:58:30.480 --> 00:58:34.280
So in this talk, I basically talk about like the math


00:58:34.280 --> 00:58:36.800
behind why vectorized operations work.


00:58:36.800 --> 00:58:38.560
You don't need any math background to understand it.


00:58:38.560 --> 00:58:39.880
It's very gentle.


00:58:39.880 --> 00:58:43.880
And then just show like why some of these operations work


00:58:43.880 --> 00:58:46.860
in NumPy and how you can implement it yourself


00:58:46.860 --> 00:58:51.000
to get like really like massive gains in performance speed.


00:58:51.000 --> 00:58:52.040
- Yeah, that's incredible.


00:58:52.040 --> 00:58:55.480
Move a lot of that stuff down into like a C or a Rust layer


00:58:55.480 --> 00:58:58.840
and just let it do its magic instead of looping in Python.


00:58:58.840 --> 00:59:00.000
Yeah. - Exactly.


00:59:00.000 --> 00:59:00.840
- Yeah, very cool.


00:59:00.840 --> 00:59:03.180
So I don't know when, but eventually this will be out


00:59:03.180 --> 00:59:05.900
as a video people can check out from me.


00:59:05.900 --> 00:59:07.780
Now they know to go look for it.


00:59:07.780 --> 00:59:10.100
- Yeah, I think the port team is still recovering.


00:59:10.100 --> 00:59:11.260
So much work.


00:59:11.260 --> 00:59:12.580
- I know.


00:59:12.580 --> 00:59:15.000
All right, well, Jody, it's been great to have you


00:59:15.000 --> 00:59:15.840
on the show.


00:59:15.840 --> 00:59:18.000
Before you get out of here, final two questions.


00:59:18.000 --> 00:59:19.400
If you're gonna write some Python code,


00:59:19.400 --> 00:59:21.180
what editor are you using these days?


00:59:21.180 --> 00:59:24.060
- So I'm actually using all three that I talked about.


00:59:24.060 --> 00:59:27.820
I use PyCharm if I need to do something like a bit more


00:59:27.820 --> 00:59:30.260
on the engineering side, which is not that often for me.


00:59:30.260 --> 00:59:33.820
Data Spell, if I'm doing sort of very local development


00:59:33.820 --> 00:59:35.900
and doing more of the research side,


00:59:35.900 --> 00:59:39.420
and then if I need some GPUs, I'm using Datalore.


00:59:39.420 --> 00:59:42.740
So a bit boring, but using all of our tools,


00:59:42.740 --> 00:59:44.500
and I really like them.


00:59:44.500 --> 00:59:45.600
- Yeah, they are good.


00:59:45.600 --> 00:59:49.140
All right, and then notable PyPI package,


00:59:49.140 --> 00:59:51.080
something you wanna give a shout out to,


00:59:51.080 --> 00:59:52.740
or if you prefer a conda package,


00:59:52.740 --> 00:59:54.220
there's a lot of intersection there.


00:59:54.220 --> 00:59:56.940
- I think my favorite package at the moment is Transformers.


00:59:56.940 --> 00:59:58.480
It is amazing.


00:59:58.480 --> 01:00:00.740
And the documentation that Hugging Face have put together


01:00:00.740 --> 01:00:01.580
is so good.


01:00:01.580 --> 01:00:04.760
And just the work they're doing in open data science


01:00:04.760 --> 01:00:06.220
is so, so important.


01:00:06.220 --> 01:00:08.500
So like big props to Hugging Face.


01:00:08.500 --> 01:00:10.540
Like we should really support the work that they're doing.


01:00:10.540 --> 01:00:11.380
- Excellent.


01:00:11.380 --> 01:00:13.140
All right, well, thanks for being on the show


01:00:13.140 --> 01:00:15.220
and sharing your experience.


01:00:15.220 --> 01:00:16.260
- Thank you so much for having me.


01:00:16.260 --> 01:00:17.660
I had an absolute blast.


01:00:17.660 --> 01:00:18.500
- Yeah, same.


01:00:18.500 --> 01:00:19.320
Bye. - Bye.


01:00:19.320 --> 01:00:23.380
- This has been another episode of Talk Python to Me.


01:00:23.380 --> 01:00:24.820
Thank you to our sponsors.


01:00:24.820 --> 01:00:26.180
Be sure to check out what they're offering.


01:00:26.180 --> 01:00:28.460
It really helps support the show.


01:00:28.460 --> 01:00:32.980
The folks over at JetBrains encourage you to get work done with PyCharm.


01:00:32.980 --> 01:00:38.720
PyCharm Professional understands complex projects across multiple languages and technologies,


01:00:38.720 --> 01:00:44.500
so you can stay productive while you're writing Python code and other code like HTML or SQL.


01:00:44.500 --> 01:00:49.820
Download your free trial at talkpython.fm/donewithpycharm.


01:00:49.820 --> 01:00:53.740
Spend better time with your data and build better ML-based applications.


01:00:53.740 --> 01:00:58.420
Use Prodigy from Explosion AI, a radically efficient data annotation tool.


01:00:58.420 --> 01:01:04.360
Get it at talkpython.fm/prodigy and use our code TALKPYTHON all caps to save 25% off a


01:01:04.360 --> 01:01:05.360
personal license.


01:01:05.360 --> 01:01:07.760
Want to level up your Python?


01:01:07.760 --> 01:01:11.860
We have one of the largest catalogs of Python video courses over at Talk Python.


01:01:11.860 --> 01:01:16.960
Our content ranges from true beginners to deeply advanced topics like memory and async.


01:01:16.960 --> 01:01:19.640
And best of all, there's not a subscription in sight.


01:01:19.640 --> 01:01:22.600
Check it out for yourself at training.talkpython.fm.


01:01:22.600 --> 01:01:27.240
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.


01:01:27.240 --> 01:01:28.600
We should be right at the top.


01:01:28.600 --> 01:01:34.140
You can also find the iTunes feed at /iTunes, the Google Play feed at /play, and the Direct


01:01:34.140 --> 01:01:38.680
RSS feed at /rss on talkpython.fm.


01:01:38.680 --> 01:01:41.200
We're live streaming most of our recordings these days.


01:01:41.200 --> 01:01:44.800
If you want to be part of the show and have your comments featured on the air, be sure


01:01:44.800 --> 01:01:49.520
to subscribe to our YouTube channel at talkpython.fm/youtube.


01:01:49.520 --> 01:01:50.840
This is your host, Michael Kennedy.


01:01:50.840 --> 01:01:51.960
Thanks so much for listening.


01:01:51.960 --> 01:01:54.920
I really appreciate it. Now, get out there and write some Python code.


01:01:54.920 --> 01:02:16.920
[MUSIC]

