WEBVTT

00:00:00.001 --> 00:00:03.780
Do you obsess about writing your code just the right way before you get started?

00:00:03.780 --> 00:00:07.520
Maybe you have some ugly code on your hands and you need to make it better.

00:00:07.520 --> 00:00:10.920
Either way, refactoring could be your ticket to happier days.

00:00:10.920 --> 00:00:16.020
On this episode, we'll walk through a powerful example of iteratively refactoring some code

00:00:16.020 --> 00:00:19.960
until we eventually turn our ugly duckling into a Pythonic beauty.

00:00:19.960 --> 00:00:25.340
Connor Hoekstra is our guest on this episode to talk us through refactoring some web-scraping Python code.

00:00:25.740 --> 00:00:30.780
This is Talk Python to Me, episode 275, recorded July 9th, 2020.

00:00:30.780 --> 00:00:49.980
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:00:49.980 --> 00:00:51.920
This is your host, Michael Kennedy.

00:00:51.920 --> 00:00:54.060
Follow me on Twitter where I'm @mkennedy.

00:00:54.220 --> 00:00:57.820
Keep up with the show and listen to past episodes at talkpython.fm.

00:00:57.820 --> 00:01:00.240
And follow the show on Twitter via at Talk Python.

00:01:00.240 --> 00:01:04.520
This episode is brought to you by us over at Talk Python Training.

00:01:04.520 --> 00:01:09.720
Python's async and parallel programming support is highly underrated.

00:01:09.720 --> 00:01:14.980
Have you shied away from the amazing new async and await keywords because you've heard it's way too complicated

00:01:14.980 --> 00:01:17.100
or that it's just not worth the effort?

00:01:17.100 --> 00:01:22.720
With the right workloads, a hundred times speed up is totally possible with minor changes to your code.

00:01:23.120 --> 00:01:25.160
But you do need to understand the internals.

00:01:25.160 --> 00:01:33.360
And that's why our course, Async Techniques and Examples in Python, show you how to write async code successfully as well as how it works.

00:01:33.360 --> 00:01:39.260
Get started with async and await today with our course at talkpython.fm/async.

00:01:39.260 --> 00:01:41.360
Connor, welcome to Talk Python to Me.

00:01:41.360 --> 00:01:42.160
Thanks for having me on.

00:01:42.160 --> 00:01:42.820
Excited to be here.

00:01:42.820 --> 00:01:43.640
I'm excited too.

00:01:43.640 --> 00:01:44.620
It's going to be beautiful, man.

00:01:44.620 --> 00:01:45.920
Hopefully.

00:01:45.920 --> 00:01:47.080
Hopefully.

00:01:47.080 --> 00:01:47.320
Yeah.

00:01:47.320 --> 00:01:48.960
It's going to be a beautiful refactorings.

00:01:49.220 --> 00:01:51.640
So I am a huge fan of refactoring.

00:01:51.640 --> 00:01:57.060
I've seen so many people try to just overthink the code that they're writing.

00:01:57.060 --> 00:01:58.660
They're like, well, I got to get it right.

00:01:58.660 --> 00:02:02.180
And I got to think about the algorithms and the way I'm writing it and all this stuff.

00:02:02.180 --> 00:02:06.860
And what I found is you don't really end up with what you want in the end a lot of times anyway.

00:02:07.060 --> 00:02:13.160
And if you just go in with an attitude of this code is plastic, it is malleable, and I can just keep changing it.

00:02:13.160 --> 00:02:15.380
And you always are on the lookout for making it better.

00:02:15.380 --> 00:02:16.720
You end up in a good place.

00:02:16.720 --> 00:02:17.920
Yeah, I completely agree.

00:02:17.920 --> 00:02:23.780
Refactoring is not a one-time thing or something that happens only, you know, two years from when you initially write the code.

00:02:23.780 --> 00:02:29.120
I heard once actually that refactoring goes a lot in hand with legacy code.

00:02:29.120 --> 00:02:33.280
And there's a number of different definitions for legacy code.

00:02:33.280 --> 00:02:38.180
But one definition is legacy code is code that isn't actively being written.

00:02:38.180 --> 00:02:46.680
So if you write something once and then you consider it done, and then the next week, like no one's working on it, that technically, according to that person's definition is legacy code.

00:02:46.680 --> 00:02:48.060
So that can be refactored.

00:02:48.060 --> 00:02:50.980
You know, you can refactor something you wrote earlier in the day.

00:02:50.980 --> 00:02:52.780
It doesn't have to be a year later or 10.

00:02:52.780 --> 00:02:53.520
Yeah, absolutely.

00:02:53.520 --> 00:02:58.840
I mean, you just, you get it working, you know a little bit more, you apply that learning back to it.

00:02:58.840 --> 00:03:01.860
And with the tooling these days, it's really good.

00:03:01.860 --> 00:03:12.040
It's not just a matter of, you know, if you go back to 1999 and you read Martin Fowler's refactoring book, he talks about these are the steps that you take by hand to make sure you don't make a mistake.

00:03:12.040 --> 00:03:16.820
And now the steps are highlight, right click, apply, refactoring.

00:03:16.820 --> 00:03:18.920
I mean, that's not 100% true.

00:03:18.920 --> 00:03:21.860
And the example we're going to talk through is not like that exactly.

00:03:21.860 --> 00:03:24.080
But there are steps along the way where it is, potentially.

00:03:24.080 --> 00:03:24.580
Definitely.

00:03:24.580 --> 00:03:29.140
Linters and static analyzers are heavily underutilized, I feel.

00:03:29.140 --> 00:03:32.800
And so many of them will just automatically apply the changes that you want to do.

00:03:32.800 --> 00:03:34.800
And it's fantastic for huge code bases.

00:03:34.800 --> 00:03:37.260
It would be almost impossible to do it by hand.

00:03:37.380 --> 00:03:38.020
Yeah, absolutely.

00:03:38.020 --> 00:03:39.160
It would definitely be risky.

00:03:39.160 --> 00:03:42.020
So maybe that's why people sometimes avoid it.

00:03:42.020 --> 00:03:44.520
Now, before we get into that, though, let's start with your story.

00:03:44.520 --> 00:03:46.160
How do you get into programming into Python?

00:03:46.160 --> 00:03:47.420
I know you're into a lot of languages.

00:03:47.420 --> 00:03:48.300
We're going to talk about that.

00:03:48.300 --> 00:03:49.140
But Python too?

00:03:49.140 --> 00:03:49.980
Python also?

00:03:49.980 --> 00:03:50.340
Yeah.

00:03:50.460 --> 00:03:56.840
So the shorter, it's a long story, but the shorter version of it is my degree in university,

00:03:56.840 --> 00:04:02.140
which wasn't computer science, required at least two introductory CS courses.

00:04:02.140 --> 00:04:04.380
So the first intro course was in Python.

00:04:04.380 --> 00:04:06.320
The second one was in Java.

00:04:06.320 --> 00:04:09.320
And then I ended up really, really enjoying the classes.

00:04:09.320 --> 00:04:15.560
I ended up taking a couple more, but ultimately stuck with the career that I had entered into,

00:04:15.560 --> 00:04:17.440
which was actuarial science.

00:04:17.440 --> 00:04:18.660
That's like insurance statistics.

00:04:18.940 --> 00:04:19.060
Yeah.

00:04:19.060 --> 00:04:21.380
So you were in some form of math program, I'm guessing?

00:04:21.380 --> 00:04:22.040
Yeah, yeah.

00:04:22.040 --> 00:04:22.600
Yeah, cool.

00:04:22.600 --> 00:04:25.300
It's very, very boring to explain.

00:04:25.300 --> 00:04:27.700
But if you like math, it's a great career.

00:04:27.700 --> 00:04:28.940
Yeah, awesome.

00:04:28.940 --> 00:04:34.920
And so I ended up, for my first job at a university, I ended up working at a software company, basically,

00:04:34.920 --> 00:04:41.800
that very simply explained, created the insurance calculator that many insurance companies use.

00:04:41.800 --> 00:04:47.420
And after working there for about four or five years, I had just fallen in love with the

00:04:47.420 --> 00:04:54.940
software engineering side of my job and had decided that I wanted to transition full time to like a purely technical company.

00:04:54.940 --> 00:04:58.140
So it's several years or a couple years later.

00:04:58.140 --> 00:05:01.760
And now I work for NVIDIA as a senior library software engineer.

00:05:02.440 --> 00:05:04.620
And that's how I got into programming.

00:05:04.620 --> 00:05:11.420
And our code base that we work on is it's completely open source and primarily uses C++14 and Python 3.

00:05:11.420 --> 00:05:13.020
That's where Python enters.

00:05:13.020 --> 00:05:14.420
That sounds like a dream job.

00:05:14.420 --> 00:05:15.140
Yeah, that sounds awesome.

00:05:15.140 --> 00:05:16.340
Yeah, I absolutely love it.

00:05:16.420 --> 00:05:19.300
Yeah, so you're working on the Rapids team, right?

00:05:19.300 --> 00:05:24.600
Which works on doing a lot of the computation that might be in Pandas, but over on GPUs.

00:05:24.600 --> 00:05:25.580
Is that roughly right?

00:05:25.580 --> 00:05:27.340
Yeah, that's a great description.

00:05:27.340 --> 00:05:31.180
So yeah, within NVIDIA, I work for an organization called Rapids.

00:05:31.180 --> 00:05:33.520
We have a number of different projects.

00:05:33.520 --> 00:05:35.900
So specifically, I work on CUDF.

00:05:36.360 --> 00:05:37.860
That is C-U-D-F.

00:05:37.860 --> 00:05:46.000
So the CU is two letters C-U from CUDA, which is like the parallel programming language that NVIDIA has made.

00:05:46.000 --> 00:05:48.900
And the DF stands for data frame.

00:05:48.900 --> 00:05:53.940
And so this is basically a very similar library to Pandas.

00:05:53.940 --> 00:05:56.700
The difference being that it runs on the GPUs.

00:05:56.700 --> 00:06:03.200
So sort of the one liner for Rapids is it's a completely open source, end-to-end data science pipeline that runs on the GPUs.

00:06:03.240 --> 00:06:07.540
So if you're using Pandas and it works great for you, like there's no reason to switch.

00:06:07.540 --> 00:06:13.740
But if you run into a situation where you have a performance bottleneck, CUDAF can be like a great drop-in replacement.

00:06:13.740 --> 00:06:25.120
We don't have 100% parity with like the Pandas library, but we have enough that a lot of Fortune 500 companies that pick up and use us are able to very easily transition their existing code in Pandas to CUDAF.

00:06:25.120 --> 00:06:25.340
Right.

00:06:25.340 --> 00:06:28.780
Change an import line, go much faster, something incredible like that.

00:06:28.780 --> 00:06:29.400
That's the goal.

00:06:29.400 --> 00:06:30.780
That's the dream.

00:06:31.260 --> 00:06:35.880
Yeah, I just recently got a new Alienware, a high-end Alienware desktop.

00:06:35.880 --> 00:06:43.720
And it's the first GeForce I've had in a long time that's, you know, not like, I don't know, some AMD Radeon in a MacBook or something like that.

00:06:43.720 --> 00:06:47.500
So I'm pretty excited to have a machine that I can now test some of these things out on at some point.

00:06:47.500 --> 00:06:47.760
Yeah.

00:06:47.760 --> 00:06:51.840
Acceleration on different devices is, it is very exciting.

00:06:51.840 --> 00:06:52.560
Awesome.

00:06:52.560 --> 00:06:53.300
All right.

00:06:53.300 --> 00:06:58.580
Well, let's start by introducing real briefly a little bit about refactoring.

00:06:58.580 --> 00:07:00.760
We've talked a tiny bit about it in general.

00:07:00.760 --> 00:07:06.760
And then we're going to dive into a cool example that you put together that really brings a lot together.

00:07:06.760 --> 00:07:11.240
And what I love about your example is it's something you've just gone and grabbed off the internet.

00:07:11.240 --> 00:07:16.700
It's not like a contrived, like, well, let's do this and then unwind the refactorings until it does it.

00:07:16.700 --> 00:07:17.700
It's like you just found it.

00:07:17.700 --> 00:07:19.040
And like, well, let's see what this thing does.

00:07:19.040 --> 00:07:19.960
That's going to be fun.

00:07:19.960 --> 00:07:23.240
But let's just start with a quick definition of refactoring.

00:07:23.240 --> 00:07:25.280
Maybe how do you know when you need it?

00:07:25.480 --> 00:07:27.640
How do you know when you need refactoring?

00:07:27.640 --> 00:07:37.080
For me, I have a sort of number of anti-patterns in my head that when I recognize them in the code, some people might refer to them as sort of technical debt.

00:07:37.080 --> 00:07:42.620
This idea that the first time you write things or maybe initially when you write things, you don't have the full picture in mind.

00:07:42.620 --> 00:07:46.640
And then as time goes on, you start to build up technical debt in your code.

00:07:46.800 --> 00:07:58.200
And a refactoring can be reorganizing or restructuring your code or rewriting little bits of it to basically reduce tech, to make it more readable, maintainable, scalable, and just in better, in general, better code.

00:07:58.200 --> 00:07:59.640
That's sort of the way I think of it.

00:07:59.640 --> 00:08:01.680
Yeah, it is pure sense, right?

00:08:01.680 --> 00:08:05.560
It should not change the behavior, at least in terms of like inputs, outputs.

00:08:05.560 --> 00:08:06.160
Exactly.

00:08:06.160 --> 00:08:06.420
Yes.

00:08:06.420 --> 00:08:14.440
The easiest code to refactor is code with tests, whether that's unit tests or regression tests or any of the other number of tests that there are.

00:08:14.600 --> 00:08:24.480
If you have a code base that has zero tests, refactoring is very, very dangerous because you can refactor something and completely change the behavior and not know about it, which is not ideal at all.

00:08:24.480 --> 00:08:26.440
Somewhat suboptimal, indeed.

00:08:26.440 --> 00:08:33.940
You know, Martin Fowler, when he came up with the idea of refactoring, or at least he publicized, I don't know, I'm sure the ideas were basically there before.

00:08:33.940 --> 00:08:40.100
One of the things that struck me most was not the refactorings, but was this idea of code smells.

00:08:40.320 --> 00:08:49.860
And it's like this aesthetic of, right, like I look at the code and it, yeah, it works, but like your nose kind of turns out, you're kind of like, ew, no, ew, but it still works, right?

00:08:49.860 --> 00:08:53.260
It's like not broken, but it's not nice.

00:08:53.820 --> 00:08:59.520
And, you know, there's all sorts of code smells like too many parameters, long method, things like that.

00:08:59.520 --> 00:09:02.140
But they rarely have clear cutoffs, right?

00:09:02.140 --> 00:09:06.320
Like, well, if it's over 12 lines, the function is too large, but under that, it's totally fine, right?

00:09:06.320 --> 00:09:08.640
Like that's not, it's never really super clear cut.

00:09:08.640 --> 00:09:20.640
So I think this whole idea of refactoring, much like refactoring itself, requires like going over it and over it as sort of through your career to refine, like what the right aesthetic to achieve is.

00:09:20.920 --> 00:09:22.640
And it probably varies by language as well a little.

00:09:22.640 --> 00:09:22.980
Yeah.

00:09:22.980 --> 00:09:30.880
If you start to do it like consciously when you're looking at code and asking yourself, like when you have that code smell feeling like something's not right here.

00:09:31.100 --> 00:09:37.800
If you are conscientiously like paying attention to what it is, like slowly over time, you will start to pick up on exactly what it is about it.

00:09:37.800 --> 00:09:39.720
Like a very, very small one for me.

00:09:39.720 --> 00:09:44.200
And I think this is mentioned in maybe a clean code or it might've been Martin Fowler's book.

00:09:44.200 --> 00:09:48.520
It's like declaring a variable earlier than it needs to be declared.

00:09:48.520 --> 00:09:53.860
So you might declare like all your variables at the top of a function, but then like two of them you use immediately.

00:09:53.860 --> 00:09:57.220
But the other three you don't use until the last, you know, four lines of the function.

00:09:57.220 --> 00:09:58.720
Small things like that.

00:09:58.720 --> 00:10:03.680
It seems simple, but I've made the change where I've put the declaration closer to where it's get used.

00:10:03.860 --> 00:10:07.280
And then you realize, oh, wait a second, this isn't actually reference.

00:10:07.280 --> 00:10:10.000
Like it's set to something, but then it's not actually used later on.

00:10:10.000 --> 00:10:11.000
So I can just delete this.

00:10:11.000 --> 00:10:12.740
And it's because it was at the top of the function.

00:10:12.740 --> 00:10:20.400
You can't see where it's being declared or if it's used somewhere else that like you actually just have an, a phantom unused variable that can be deleted.

00:10:20.400 --> 00:10:24.000
It's simple things that lead to better changes later on.

00:10:24.000 --> 00:10:26.660
Well, and just mental overhead.

00:10:26.660 --> 00:10:28.900
Like you said, the technical debt side of things.

00:10:28.900 --> 00:10:31.860
So for example, there's the variable that was at the top.

00:10:32.340 --> 00:10:37.080
Literally when the code was written, it was being used, but it's been modified over the years.

00:10:37.080 --> 00:10:41.840
And now no longer is it being used, but because it's separated from where it's declared to where it's used.

00:10:41.840 --> 00:10:43.020
You don't want to mess with that.

00:10:43.020 --> 00:10:47.100
Like if you start messing with that, you're earning more work, right?

00:10:47.100 --> 00:10:47.940
You're asking for more.

00:10:47.940 --> 00:10:50.060
I'm just going to make the minor change.

00:10:50.060 --> 00:10:51.160
I don't want to break anything.

00:10:51.160 --> 00:10:51.720
Who knows?

00:10:51.720 --> 00:10:58.360
And then the next person that comes to try to understand it, they got to figure out, well, why is there that like set count variable?

00:10:58.360 --> 00:11:01.280
Like, I don't feel like it's being used, but it's there.

00:11:01.280 --> 00:11:04.480
And like, you know, you just got to, it's another thing to think about that's in the way.

00:11:04.480 --> 00:11:05.380
Yeah, for sure.

00:11:05.380 --> 00:11:06.160
Yeah.

00:11:06.160 --> 00:11:07.900
So certainly I think it's viable.

00:11:07.900 --> 00:11:13.300
There are fantastic tools that will like highlight this variable is unused or this assignment.

00:11:13.300 --> 00:11:15.500
Is it meaningless or something like that?

00:11:15.540 --> 00:11:20.860
So there are options, but still it's better to not let that stuff live in the code.

00:11:20.860 --> 00:11:21.060
Yeah.

00:11:21.060 --> 00:11:21.860
A hundred percent agree.

00:11:21.860 --> 00:11:33.800
Let's talk about this example that you've got here and maybe you should give a little background on your language, enthusiasm and programming competition interests and so on.

00:11:33.800 --> 00:11:38.900
Your interest in coding competitions, I think it's probably worth touching on already.

00:11:38.900 --> 00:11:46.560
But then this example is from you trying to reach out and understand it and do some analysis of those environments or those ecosystems, right?

00:11:46.560 --> 00:11:50.500
What's the background with this, these different languages and coding competition?

00:11:50.500 --> 00:11:54.820
Yeah, so I initially got into competitive programming, quote unquote.

00:11:54.820 --> 00:12:09.000
So just the one sentence description is there's a number of websites online, HackerRank, LeakCode, CodeForces, that they host these one to three hour contests where they have three to four or five problems that start out easy and then get harder as you progress through them.

00:12:09.000 --> 00:12:11.500
And you can choose any language you want to solve them in.

00:12:11.500 --> 00:12:16.960
And the goal is just to get a solution that passes as quickly as possible.

00:12:16.960 --> 00:12:20.320
So it's not necessarily about how efficient your code is.

00:12:20.400 --> 00:12:22.440
It has to run within a certain time limit.

00:12:22.440 --> 00:12:28.200
But if you can get it to run or pass in Python versus C++ versus Java, any code solution works.

00:12:28.200 --> 00:12:31.600
I started doing these to prepare for technical interviews.

00:12:31.600 --> 00:12:38.720
So if you're interviewing for companies like Google, Facebook, etc., a lot of their interview questions are very similar to the questions on these websites.

00:12:38.720 --> 00:12:44.640
And so I at one point was looking for a resource online, like for YouTube videos that just explain this stuff.

00:12:44.640 --> 00:12:46.060
But at the time, I couldn't really find any.

00:12:46.060 --> 00:12:49.560
So I started a YouTube channel covering the solutions to these problems.

00:12:50.040 --> 00:12:55.620
And I thought it would be better to solve it in a number of languages than opposed to just C++.

00:12:55.620 --> 00:12:59.380
So I started solving them in C++, Python, and Java.

00:12:59.380 --> 00:13:03.200
And that's sort of what led to my interest in competitive programming.

00:13:03.420 --> 00:13:06.040
Even though I'm not interviewing actively anymore.

00:13:06.040 --> 00:13:08.240
I just find these, they're super fun.

00:13:08.240 --> 00:13:12.920
It keeps you sort of on your toes in terms of your data structure and algorithms knowledge.

00:13:12.920 --> 00:13:15.240
And you can treat them as like code katas.

00:13:15.240 --> 00:13:22.640
I'm not sure if you're familiar with the concept of just sort of writing one little small program and trying it a couple times in different languages.

00:13:22.640 --> 00:13:28.520
And you learn different ways of solving the problem that you might not would have initially solved the problem that way.

00:13:28.520 --> 00:13:38.780
This example, I decided to just figure out what are the top languages that people use to solve these competitive programming problems on a given website.

00:13:38.780 --> 00:13:40.480
So the site that I chose was Code Forces.

00:13:40.480 --> 00:13:40.940
Yeah.

00:13:41.240 --> 00:13:45.420
And you're like, hey, I'm working on this new data frame library that's like pandas.

00:13:45.420 --> 00:13:49.940
Let me see how I can use pandas to solve this problem and get some practice or something, right?

00:13:49.940 --> 00:13:50.440
Yeah, yeah.

00:13:50.440 --> 00:13:56.060
So when I had just started NVIDIA, I knew that the pandas library existed, but I had zero experience with it.

00:13:56.100 --> 00:14:10.580
And I knew that it had this sort of group by reduction functionality that if you had a big table of elements, you could get these sort of statistics on, you know, what's the top language or what's, you know, the average time it takes for people to submit very easily with this kind of library.

00:14:10.580 --> 00:14:18.600
So I thought, what better way to learn pandas than by trying to build a simple example that uses this library for something that I'm interested in.

00:14:18.600 --> 00:14:24.220
And so the first thing that I did was I googled, you know, how to scrape HTML tables using pandas.

00:14:24.480 --> 00:14:29.040
And then it brought me to this blog that at the end of the day has about 60 lines of code.

00:14:29.040 --> 00:14:30.600
And it's a tutorial blog.

00:14:30.600 --> 00:14:36.080
So it walks you through how to get this code off of an HTML table.

00:14:36.080 --> 00:14:40.400
And basically the PyCon talk that I gave, it came out of doing this.

00:14:40.400 --> 00:14:43.400
I had no plans of giving a PyCon talk on this.

00:14:43.400 --> 00:14:53.240
I just after having gone through it and sort of refactoring one by one, I realized that like I could give a pretty simple talk to like Connor like five years ago.

00:14:53.420 --> 00:14:57.060
That didn't know about any of the I didn't know about list comprehension.

00:14:57.060 --> 00:14:58.460
I didn't know about enumerate.

00:14:58.460 --> 00:15:00.540
I didn't know about all the different techniques I was using.

00:15:00.540 --> 00:15:04.360
And I figured it would be at least for some individuals out there.

00:15:04.360 --> 00:15:09.400
It would be a useful talk highlighting the things that I didn't know when I first started coding in Python.

00:15:09.400 --> 00:15:12.000
But that now are like second nature for me.

00:15:12.000 --> 00:15:13.640
And that's sort of where the talk came from.

00:15:13.640 --> 00:15:13.840
Yeah.

00:15:13.840 --> 00:15:14.740
And it's really interesting.

00:15:14.740 --> 00:15:15.740
The example is cool.

00:15:15.740 --> 00:15:23.300
I do think that a lot of the refactorings were let's try to make a more Pythonic version of this and more idiomatic.

00:15:23.300 --> 00:15:29.680
version of this like misunderstanding the for in loop, for example, and treat them all right.

00:15:29.680 --> 00:15:32.380
So in a lot of ways, it's a cool refactoring.

00:15:32.380 --> 00:15:37.700
But it's also kind of leveraging more of the native bits of the language, if you will.

00:15:37.700 --> 00:15:38.100
Absolutely.

00:15:38.260 --> 00:15:38.380
Yeah.

00:15:38.380 --> 00:15:38.880
Yeah.

00:15:38.880 --> 00:15:42.020
So you went and grabbed this code and it does two basic things.

00:15:42.020 --> 00:15:50.360
It goes and downloads some HTML and then pulls it apart using, I think, LXML HTML parser.

00:15:50.460 --> 00:15:59.180
And then it's going to loop over the results that it gets from the HTML parser and turn this into basically a list or a dictionary.

00:15:59.180 --> 00:16:00.920
Then you're going to feed that over to pandas.

00:16:00.920 --> 00:16:03.100
Ask pandas some pretty interesting questions.

00:16:03.100 --> 00:16:09.540
And most of the challenge or most of the messy code lived in this HTML side of things, right?

00:16:09.540 --> 00:16:09.820
Yeah.

00:16:09.820 --> 00:16:11.820
That's a pretty good description of what's happening.

00:16:11.980 --> 00:16:12.100
Cool.

00:16:12.100 --> 00:16:21.800
So let's go and just talk through some of the issues you identified and then the fix, basically knowing like how did you identify that as a problem?

00:16:21.800 --> 00:16:25.020
And then what fix did you apply to it?

00:16:25.020 --> 00:16:28.000
Now, there's a lot of code and it's hard to talk about code and audio.

00:16:28.000 --> 00:16:33.860
So we'll maybe try to just like as high level as possible, talk about like the general patterns and what we fixed.

00:16:33.860 --> 00:16:42.000
The first part of the code would go through and it would create an empty list and it would create like an index to keep track of where it was and then did a loop over all of the elements.

00:16:42.000 --> 00:16:46.540
Increment the index, add a thing to the list, print out some information as it went, right?

00:16:46.540 --> 00:16:46.780
Yep.

00:16:46.780 --> 00:16:51.480
And I think the first thing that you talked about was the code comments, actually.

00:16:51.480 --> 00:16:53.560
You're like, what is this code comment here?

00:16:53.560 --> 00:16:55.160
It just says we're looping over these things.

00:16:55.160 --> 00:16:56.220
Well, what do you think a loop is?

00:16:56.220 --> 00:16:57.400
Why do we have this comment?

00:16:57.400 --> 00:17:03.760
Yeah, even worse was like arguably the second comment some might argue is add some value.

00:17:03.760 --> 00:17:10.140
But the first comment above the line that creates an empty list, it says create empty list.

00:17:10.140 --> 00:17:13.740
And it's only a what is that six characters if you don't include the spaces.

00:17:13.740 --> 00:17:24.100
And I think that's definitely one of the things that's called out in a number of refactoring books is comments should add value that is not explicitly clear from the code.

00:17:24.100 --> 00:17:28.220
I think even beginners are able to tell that you're creating an empty list there.

00:17:28.220 --> 00:17:31.460
There's no reason to basically state what the code is doing.

00:17:31.460 --> 00:17:40.380
Typically, comments should say why if it's not clear why something is being done a certain way or something that's implicit and not explicitly clear from what the code is doing.

00:17:40.380 --> 00:17:40.640
Yeah.

00:17:40.640 --> 00:17:46.480
In terms of refactoring, I love this idea of these comments are sort of almost warning signs.

00:17:46.620 --> 00:17:51.620
Because if I find myself writing one of these comments to make stuff more clear, I'm like, wait a minute, wait a minute.

00:17:51.620 --> 00:17:56.080
If this is just describing what's here, something about what I'm doing is wrong.

00:17:56.080 --> 00:17:59.360
Maybe the variable name is not at all clear what the heck it is.

00:17:59.360 --> 00:18:03.640
Or maybe it could use a type annotation to say what types come in instead of here's a list of strings.

00:18:03.640 --> 00:18:06.740
Like how about list bracket string goes there to just say what type it is.

00:18:06.740 --> 00:18:07.960
It's Python 3 after all.

00:18:07.960 --> 00:18:16.940
And, you know, from the Code Smells book, Fowler had this great description of calling these types of comments deodorant for Code Smells.

00:18:16.940 --> 00:18:18.200
So there's something wrong.

00:18:18.200 --> 00:18:21.800
It smells a little less bad if we like lay it out, set the stage.

00:18:21.800 --> 00:18:24.320
But every time I see one of those, I'm like, you know what?

00:18:24.320 --> 00:18:27.900
I just need to rename this function to like a short version of what this comment would say.

00:18:27.900 --> 00:18:29.020
Or rename this variable.

00:18:29.020 --> 00:18:31.860
Or like restructure and break these things apart.

00:18:31.860 --> 00:18:34.420
Because if it needs a comment, it's probably just too complicated.

00:18:34.420 --> 00:18:36.540
There's an individual in the C++ community.

00:18:36.540 --> 00:18:37.860
His name is Tony Van Eerd.

00:18:37.860 --> 00:18:45.360
And he has a rule, or not a rule, but a recommendation that you should grep your code base for step one, step two, step three.

00:18:45.360 --> 00:18:48.940
And guaranteed you're going to get like one or two matches.

00:18:48.940 --> 00:18:54.360
And a lot of times it's these steps of comments on top of pieces of code and like a larger function.

00:18:54.360 --> 00:19:00.860
And odds are you could make that code a lot better by refactoring each of those steps into its own small function.

00:19:00.860 --> 00:19:05.780
And just whatever the step, like if you put step one in a description, you've already given that piece of code a name.

00:19:05.780 --> 00:19:09.560
You just need to take the next step, put it in a function and give that function that name.

00:19:09.560 --> 00:19:10.060
Yes, exactly.

00:19:10.060 --> 00:19:11.320
Which is exactly what you said.

00:19:11.320 --> 00:19:12.040
Exactly.

00:19:12.040 --> 00:19:23.660
I think there was even some tool way, way, way back in the early days of C# that if you would highlight some code to refactor it and you highlighted a comment, it would function nameify.

00:19:23.660 --> 00:19:31.860
It would try to guess the function name by using the comment, turning it into a function, you know, like something that would work as a identifier in the language.

00:19:31.860 --> 00:19:34.020
Anyway, it's totally a good idea.

00:19:34.020 --> 00:19:36.340
So there's a couple of things going on here.

00:19:36.340 --> 00:19:38.280
One is like, why is there a print statement?

00:19:38.280 --> 00:19:39.060
Nobody needs this.

00:19:39.260 --> 00:19:42.420
Once you take that out, though, you are able to identify this.

00:19:42.420 --> 00:19:43.960
Well, let's take a step back.

00:19:43.960 --> 00:19:54.280
First, if you have an integer and you're incrementing it every time through the loop so that it stays in sync with the index of the elements you're looping over, that's probably not the best way to do it, right?

00:19:54.280 --> 00:19:56.540
Like Python has a built-in enumerate.

00:19:56.540 --> 00:19:56.840
Yeah.

00:19:56.840 --> 00:20:00.340
This is probably one of the most common things I see in Python.

00:20:00.340 --> 00:20:04.320
Sadly, in certain languages, they don't have this function.

00:20:04.320 --> 00:20:07.380
But in Python, it's right there built into the language.

00:20:07.380 --> 00:20:08.900
And as you mentioned, it's called enumerate.

00:20:09.060 --> 00:20:13.280
So you can pass whatever thing you're looping over to enumerate.

00:20:13.400 --> 00:20:22.300
And that's going to bundle it with an index that you can then inline destructure into an index and the element that you were getting from your ranged for loop before.

00:20:22.620 --> 00:20:31.080
So anytime you see an index, IDX or I or something that's keeping track of the index and that's getting it could be J.

00:20:31.080 --> 00:20:32.080
Sometimes it's J.

00:20:32.080 --> 00:20:32.960
Sometimes it's J.

00:20:32.960 --> 00:20:33.840
Sometimes it's K.

00:20:33.840 --> 00:20:35.880
X or Y if you're being really creative.

00:20:36.240 --> 00:20:39.460
And yeah, like there is a built-in pattern for basically avoiding that.

00:20:39.460 --> 00:20:41.620
And it makes me extremely happy.

00:20:41.620 --> 00:20:47.080
Like it happens actually not just once in this piece of code, but twice where you can make use of enumerate.

00:20:47.140 --> 00:20:49.920
And once you see it, it's very hard to unsee it.

00:20:49.920 --> 00:20:53.480
But like I said, this was something that I learned enumerate from Python.

00:20:53.920 --> 00:20:57.800
And this was not something that I knew of and I didn't learn in school.

00:20:57.800 --> 00:21:02.840
So there's a lot of Python developers and just developers in many languages out there that I think they're just not aware.

00:21:02.840 --> 00:21:05.080
And as soon as you tell them, I think they'll agree.

00:21:05.080 --> 00:21:07.220
Oh, yeah, this is way better than what I was doing before.

00:21:07.220 --> 00:21:07.880
Yeah.

00:21:07.880 --> 00:21:09.000
You just need to be aware of it.

00:21:09.000 --> 00:21:10.240
You know, you always run into these issues.

00:21:10.240 --> 00:21:11.400
You've got to create the variable.

00:21:11.400 --> 00:21:12.740
Then like, why is the variable there?

00:21:12.740 --> 00:21:14.220
Then you've got to make sure you increment it.

00:21:14.320 --> 00:21:18.220
Do you increment it before you work on that with the value or do you increment it after?

00:21:18.220 --> 00:21:19.200
Is it zero based?

00:21:19.200 --> 00:21:20.040
Is it one based?

00:21:20.040 --> 00:21:23.600
All of these things are just like complexities that are like, what is happening here?

00:21:23.600 --> 00:21:29.420
Like, what if you have a have an if test continue and you skip the loop, but you forget to increment it?

00:21:29.420 --> 00:21:30.880
Like there's all these little edge cases.

00:21:30.880 --> 00:21:34.060
And you can just with enumerate, you can say, you know, it's always going to work.

00:21:34.060 --> 00:21:37.680
You can even set the start position to be one if you want it to go one, two, three.

00:21:37.680 --> 00:21:38.280
Beautiful.

00:21:38.280 --> 00:21:39.240
Yeah, that's a great point.

00:21:39.240 --> 00:21:42.660
Yeah, there are use cases where you're going to run into bugs.

00:21:42.860 --> 00:21:46.240
Whereas with enumerate, you know, at least you're not going to have a bug with that index.

00:21:46.240 --> 00:21:46.840
Right.

00:21:46.840 --> 00:21:50.720
It's always going to be tied to the position with the starting place the way you want it.

00:21:50.720 --> 00:21:52.680
So yeah, yeah, that's really nice.

00:21:52.680 --> 00:21:54.340
But it's not super discoverable, right?

00:21:54.340 --> 00:21:57.420
Like there's nothing in the language that screams and waves its hands.

00:21:57.420 --> 00:21:59.260
It says, yeah, you're in a for loop.

00:21:59.260 --> 00:22:03.480
We don't have this concept of a numerical for loop, but this is actually better than what

00:22:03.480 --> 00:22:04.260
this is what you wanted.

00:22:04.260 --> 00:22:05.560
You didn't even know you wanted it.

00:22:05.560 --> 00:22:07.900
Yeah, it has to be something that you stumble across.

00:22:07.900 --> 00:22:12.140
Interestingly, some languages go is the one that comes to mind.

00:22:12.300 --> 00:22:16.480
They actually build in the enumerate into their range based for loop.

00:22:16.480 --> 00:22:21.920
So in Go, they have built in basically the destructuring.

00:22:21.920 --> 00:22:25.500
And if you don't want the index, if you just want a range based for loop and you want to

00:22:25.500 --> 00:22:29.420
ignore the index, then you're just supposed to use the underbar to say, I don't need the

00:22:29.420 --> 00:22:30.240
index for this loop.

00:22:30.240 --> 00:22:35.180
But it's interesting that like Go is a more recently created language than Python, at least.

00:22:35.180 --> 00:22:40.320
When they decided like they thought it was such a common use case that they would think that

00:22:40.320 --> 00:22:42.240
most people need it more often than they wouldn't.

00:22:42.240 --> 00:22:43.600
So they built it into their for loop.

00:22:43.600 --> 00:22:47.880
So with that language, you can't avoid learning about it because it's in their for loop.

00:22:48.200 --> 00:22:51.600
It's a syntax error to not at least say I explicitly ignore this.

00:22:51.600 --> 00:22:51.840
Yeah.

00:22:51.840 --> 00:22:52.380
Oh, interesting.

00:22:52.380 --> 00:22:53.240
I didn't know that about Go.

00:22:53.240 --> 00:22:55.480
So now you've got this little cleaner.

00:22:55.480 --> 00:22:59.860
You look at it again and you say, well, now what we're doing is we're creating a list,

00:22:59.860 --> 00:23:02.360
an empty list, which we commented, create empty list.

00:23:02.360 --> 00:23:03.120
That was cool.

00:23:03.120 --> 00:23:06.120
Took that comment out, but it was very helpful in the beginning to help you understand.

00:23:06.120 --> 00:23:06.920
No, just kidding.

00:23:06.920 --> 00:23:10.780
And then you say we're going to loop over these items and then append something to that

00:23:10.780 --> 00:23:11.100
list.

00:23:11.100 --> 00:23:12.420
Well, that's possible.

00:23:12.420 --> 00:23:18.540
But this is one of your anti-patterns that you like to find and get rid of, right?

00:23:18.540 --> 00:23:21.460
This is an anti-pattern that I call initialize, then modify.

00:23:21.460 --> 00:23:27.200
And actually, the enumerate example previously also falls into this anti-pattern.

00:23:27.200 --> 00:23:32.940
So anytime you have a variable that it doesn't need to be a for loop, but many, many times it

00:23:32.940 --> 00:23:37.500
is that inside each iteration of that for loop, you are then modifying what you just

00:23:37.500 --> 00:23:38.500
initialized outside.

00:23:38.500 --> 00:23:40.760
That is initializing and then modifying.

00:23:40.760 --> 00:23:44.720
And my assertion is that you should try to avoid this as much as possible.

00:23:44.720 --> 00:23:48.940
And when it comes to the pattern of initializing an empty list, and then in each iteration

00:23:48.940 --> 00:23:50.460
of your for loop, you're calling append.

00:23:50.460 --> 00:23:56.740
That is built in to the Python language as something that can be used as a list comprehension,

00:23:56.740 --> 00:24:02.140
which is so much more beautiful, in my opinion, compared to just a raw for loop and then

00:24:02.140 --> 00:24:03.400
appending for each iteration.

00:24:03.400 --> 00:24:03.800
Yeah.

00:24:03.800 --> 00:24:09.160
Every now and then, there's like a complicated enough set of tests or conditionals or something

00:24:09.160 --> 00:24:11.700
going on in there that maybe not.

00:24:11.700 --> 00:24:13.880
But I agree with you most of the time.

00:24:13.880 --> 00:24:17.100
That just means what I really wanted to write was a list comprehension.

00:24:17.100 --> 00:24:17.620
It is.

00:24:17.620 --> 00:24:22.940
So, you know, bracket item for item in such and such, if such and such, right?

00:24:22.940 --> 00:24:24.240
That's what you got to do.

00:24:24.240 --> 00:24:24.460
Yeah.

00:24:24.460 --> 00:24:27.980
List comprehension, once you start to use it, moving to a language that doesn't have it

00:24:27.980 --> 00:24:31.100
makes you very sad because it's such a convenient syntax.

00:24:31.480 --> 00:24:32.600
It totally makes you sad.

00:24:32.600 --> 00:24:40.040
And I really, really wish list comprehensions had some form of sorting clause because at

00:24:40.040 --> 00:24:45.720
that point, you're almost into like in-memory database type of behaviors, right?

00:24:45.720 --> 00:24:50.840
Like I would love to say projection, you know, thing, transform thing, for thing in collection,

00:24:50.840 --> 00:24:54.160
where the test is, order by, whatever, right?

00:24:54.160 --> 00:24:58.360
I mean, you can always put a sorted around it, but it'd be lovely if they're like, it's

00:24:58.360 --> 00:24:59.660
already got those nice steps.

00:24:59.660 --> 00:25:01.640
I like to write it on three lines, right?

00:25:01.640 --> 00:25:06.760
The projection, the set, and the conditional, like just one more line, put the order by in

00:25:06.760 --> 00:25:09.580
there, but maybe someone, or maybe I should put a PEP in there.

00:25:09.580 --> 00:25:09.940
Who knows?

00:25:10.040 --> 00:25:11.960
I was going to say that sounds like a future pep, but.

00:25:11.960 --> 00:25:13.700
It definitely does.

00:25:13.700 --> 00:25:17.460
I mean, it would be easy to implement, just transform it to a sorted and pass that as a

00:25:17.460 --> 00:25:18.440
key or something like that.

00:25:18.440 --> 00:25:19.820
But anyway, it would be really cool.

00:25:19.820 --> 00:25:22.940
But they're very, very nice, even without that.

00:25:23.240 --> 00:25:29.340
And once you have it as a list comprehension, then it unlocks the ability to do some other

00:25:29.340 --> 00:25:32.320
interesting stuff, which you didn't cover in yours because it didn't really matter.

00:25:32.320 --> 00:25:37.740
But if you have square brackets there, and those brackets are turning a large data collection

00:25:37.740 --> 00:25:43.100
into a list, if you put rounded brackets, all of a sudden you have a much more efficient

00:25:43.100 --> 00:25:43.620
generator.

00:25:43.620 --> 00:25:43.980
Yep.

00:25:43.980 --> 00:25:46.440
That is something I don't call out at that point.

00:25:46.440 --> 00:25:51.320
But at the end of the talk, I allude to a article that was mentioned on the other podcast

00:25:51.320 --> 00:25:53.080
that you co-host, Python Bytes.

00:25:53.080 --> 00:25:53.400
Yeah.

00:25:53.400 --> 00:25:54.860
Thanks for the shout out on that one, by the way.

00:25:54.860 --> 00:25:59.100
Yeah, no, it was a great article, but it mentions generator expressions right after it mentions

00:25:59.100 --> 00:25:59.740
list comprehension.

00:25:59.740 --> 00:26:03.800
And I mentioned that these things go hand in hand and that you should familiarize yourself

00:26:03.800 --> 00:26:08.940
because if at any point you're passing a list comprehension to like an algorithm, like

00:26:08.940 --> 00:26:13.940
any or all or something, you can drop the square brackets and then just pass at the generator

00:26:13.940 --> 00:26:15.840
and it'll become much more efficient.

00:26:15.840 --> 00:26:17.520
So it's good to know both of them.

00:26:17.520 --> 00:26:22.800
And there's no way to go from a for loop really quickly and easily to a generator.

00:26:22.920 --> 00:26:23.700
That's a good thing.

00:26:23.700 --> 00:26:24.700
That's a good thing.

00:26:24.700 --> 00:26:25.620
Right.

00:26:25.620 --> 00:26:28.980
There's not like for yield, I and whatever, right?

00:26:28.980 --> 00:26:34.280
Like there, but with the comprehensions, it's square brackets versus rounded parentheses, right?

00:26:34.280 --> 00:26:38.240
It's so, it's so close that if that makes sense, it's like basically no effort to make

00:26:38.240 --> 00:26:38.560
it happen.

00:26:38.560 --> 00:26:38.780
Yeah.

00:26:38.880 --> 00:26:39.220
Yeah, nice.

00:26:39.220 --> 00:26:39.740
Okay.

00:26:39.740 --> 00:26:43.220
So we've got into a list comprehension, which is beautiful.

00:26:43.220 --> 00:26:48.060
And then you say, all right, it's time to turn our attention to this doubly nested for loop.

00:26:48.260 --> 00:26:50.040
And it's going to go over a bunch of items.

00:26:50.040 --> 00:26:57.700
And it's going to go over a bunch of the items and pull out an index and then, you know, go and work with that index.

00:26:57.700 --> 00:26:59.120
So it's another enumerate.

00:26:59.120 --> 00:27:06.040
And then I think another thing that's pretty interesting that you talk about, I don't remember exactly where it came in the talk, but you're like, look,

00:27:06.040 --> 00:27:13.440
what you're doing in this loop is actually looping from like the second onward for all the items.

00:27:13.440 --> 00:27:15.420
And that really is just a slice.

00:27:15.420 --> 00:27:15.740
Yeah.

00:27:15.740 --> 00:27:16.000
Yeah.

00:27:16.000 --> 00:27:26.740
So in this nested for loop, the outer for loop is basically reads for J in range of one to the length of your list.

00:27:26.740 --> 00:27:31.240
So you're basically creating a range of numbers from one to the length of your list.

00:27:31.360 --> 00:27:40.680
And then right inside that for loop, you're creating a basically a variable that's the Jth element of your list.

00:27:40.680 --> 00:27:44.480
So all you're doing is skipping the very first element of your list.

00:27:44.480 --> 00:27:52.660
But the way you're doing this is generating explicit indices based on the range function and the length function.

00:27:52.660 --> 00:28:00.880
And I thought at first that they must be doing this because we need access to the index later or we need access to our elements later.

00:28:01.300 --> 00:28:02.420
But that wasn't the case.

00:28:02.420 --> 00:28:07.220
It just seemed like the only reason they were doing all of this was to skip over the first element.

00:28:07.220 --> 00:28:12.220
And so very nicely, once again, Python has very, very many nice features.

00:28:12.220 --> 00:28:20.740
They have something called slicing where you can basically pass it the syntax, which is square bracket, and then something in the middle and square brackets.

00:28:20.740 --> 00:28:23.760
And in order to skip the first one, you just go one colon.

00:28:23.760 --> 00:28:24.940
Yeah, one to the end.

00:28:24.940 --> 00:28:27.880
And that's beautiful because you don't even have to check the length of the items.

00:28:28.060 --> 00:28:32.360
You just say go to the end, which avoids errors of like, do I have to plus one here?

00:28:32.360 --> 00:28:33.040
Do I not?

00:28:33.040 --> 00:28:34.020
Is it minus one?

00:28:34.020 --> 00:28:35.360
Like, what is the ending piece?

00:28:35.360 --> 00:28:38.420
But you don't have to worry about just from I skip the first one and the rest.

00:28:38.420 --> 00:28:39.580
Yeah, it's so convenient.

00:28:39.580 --> 00:28:41.580
You avoid making a call to Len.

00:28:41.580 --> 00:28:43.200
You avoid making a call to range.

00:28:43.360 --> 00:28:47.000
And you avoid your local assignment on the first line of your for loop.

00:28:47.000 --> 00:28:52.040
You can basically remove all of that and just use slicing and you're good to go.

00:28:52.040 --> 00:28:55.400
And yeah, slicing is slicing is a really, really awesome feature.

00:28:55.400 --> 00:28:59.820
It actually comes from a super old language that was created in the 60s called APL.

00:29:00.020 --> 00:29:04.860
And Python is one of the only languages that has something called negative index slicing,

00:29:04.860 --> 00:29:09.660
where you can pass it a negative one so that it wraps around sort of to the last element,

00:29:09.660 --> 00:29:12.160
which is a super, super, it sort of looks weird.

00:29:12.160 --> 00:29:18.360
But once you use it, it's so much more convenient than doing like a Len minus one or something like

00:29:18.360 --> 00:29:18.640
that.

00:29:18.640 --> 00:29:20.740
It's it is a little bit unreadable.

00:29:20.740 --> 00:29:22.020
But once you know what it does, it's great.

00:29:22.020 --> 00:29:22.540
It's great.

00:29:22.540 --> 00:29:23.980
It's like I want the last three.

00:29:23.980 --> 00:29:25.560
I don't want to care how long it is.

00:29:25.560 --> 00:29:26.560
I just want the last three.

00:29:26.720 --> 00:29:31.300
And that's yeah, it's fantastic slicing, I think is fairly underused for people who

00:29:31.300 --> 00:29:32.260
come from other languages.

00:29:32.260 --> 00:29:36.080
But yeah, and it fits the bill because there's so many of these little edge case.

00:29:36.080 --> 00:29:40.960
You talk about errors and programming, like off by one errors are a significant part of

00:29:40.960 --> 00:29:42.420
problems programming, right?

00:29:42.420 --> 00:29:44.120
And it just skips that altogether.

00:29:44.120 --> 00:29:44.660
It's beautiful.

00:29:44.660 --> 00:29:44.920
Yeah.

00:29:44.920 --> 00:29:51.120
So the next thing to do is so you're parsing this stuff out of the Internet, which means

00:29:51.120 --> 00:29:52.840
you're working with 100% strings.

00:29:52.840 --> 00:29:55.460
But some of the time you need numerical data.

00:29:55.460 --> 00:29:58.800
So you can ask questions like, is this the sixth or seventh or whatever?

00:29:58.800 --> 00:30:02.380
And so they have this is going to be fun to talk about.

00:30:02.380 --> 00:30:06.180
They have try value equals int of data.

00:30:06.180 --> 00:30:11.960
So pass the integer has the potentially integer like data over to the int initializer.

00:30:11.960 --> 00:30:16.320
Either that's going to work, or it's going to throw an exception, which case you will say

00:30:16.320 --> 00:30:17.520
except pass.

00:30:17.520 --> 00:30:19.940
Well, not you, the original article had that right.

00:30:19.940 --> 00:30:23.080
So it's this try pars except pass.

00:30:23.580 --> 00:30:26.660
Otherwise, it's going to be none or it's going to be set to the string value or something

00:30:26.660 --> 00:30:27.240
to that effect.

00:30:27.240 --> 00:30:28.360
So what do you think about this?

00:30:28.360 --> 00:30:29.320
How do you feel when you saw that?

00:30:29.320 --> 00:30:29.720
Yeah.

00:30:29.860 --> 00:30:36.920
So my initial reaction was that this is four lines of code that can potentially be done

00:30:36.920 --> 00:30:40.540
in a single line using something called a conditional expression.

00:30:40.540 --> 00:30:45.560
So in many other languages, they have something called a ternary operator, which is typically

00:30:45.560 --> 00:30:50.780
a question mark, where you can do an assignment to a variable based on a conditional predicate.

00:30:50.780 --> 00:30:52.920
So something that's just asking true or false.

00:30:53.080 --> 00:30:55.020
And if it's true, you assign it one value.

00:30:55.020 --> 00:30:56.820
And if it's false, you assign it another value.

00:30:56.820 --> 00:31:03.040
So in Python, they have something called a conditional if expression, which has the syntax assigned

00:31:03.040 --> 00:31:06.320
to value using the equal sign, ask your question.

00:31:06.320 --> 00:31:09.220
So in this case, we just ask, is it an int?

00:31:09.220 --> 00:31:13.680
Or sorry, it's so the first thing that returns, it's actually backwards from ternary operator.

00:31:13.800 --> 00:31:19.160
So the line reads data equals int of data if, and then check your predicate.

00:31:19.160 --> 00:31:24.280
And in Python, we can just call is numeric on our value, which will return us true or false

00:31:24.280 --> 00:31:25.400
based on whether it's a number.

00:31:25.400 --> 00:31:30.140
So if that returns true, then it'll end up assigning to data int of data.

00:31:30.140 --> 00:31:33.300
Otherwise, you can just assign it itself data.

00:31:33.300 --> 00:31:38.220
And then it's not going to do any transformation on that variable because it's not numeric.

00:31:38.220 --> 00:31:39.520
It's one line of code.

00:31:39.840 --> 00:31:43.820
It's more expressive, in my opinion, and it avoids using try and accept.

00:31:43.820 --> 00:31:46.340
And it's preferable from my point of view.

00:31:46.340 --> 00:31:49.660
I would say it's probably preferable from my point of view as well.

00:31:49.660 --> 00:31:55.080
I have mixed feelings about this, but I do think it's nice under certain circumstances.

00:31:55.080 --> 00:32:00.640
One, for example, if you say try, do a thing, accept, pass, a lot of linters and PyCharm

00:32:00.640 --> 00:32:03.420
and whatnot will go, this is too broad of a clause.

00:32:03.420 --> 00:32:04.780
You're catching too much.

00:32:04.780 --> 00:32:10.040
And you're like, okay, well, now to make the little squiggly in the scroll bar go away,

00:32:10.040 --> 00:32:14.980
I have to put a hashtag disable check, whatever, right?

00:32:14.980 --> 00:32:18.840
And I'm like, well, now it's five lines, one with a weird exception to say, no, no, this time

00:32:18.840 --> 00:32:19.360
it's fine.

00:32:19.360 --> 00:32:20.900
So that's not ideal.

00:32:20.900 --> 00:32:26.640
I definitely think that it's more expressive to use this conditional if one liner.

00:32:26.960 --> 00:32:32.300
The one situation where I might step back and go, you know, let's just do the try is if

00:32:32.300 --> 00:32:34.060
there's more variability in the data.

00:32:34.060 --> 00:32:38.520
So this assumes that the data is not none and that it's string like, right?

00:32:38.520 --> 00:32:43.260
But if you got potentially objects back or you got none some of the time, then you need a

00:32:43.260 --> 00:32:44.420
little bit more of a test.

00:32:44.420 --> 00:32:47.820
I mean, you could always do if data and data is numeric.

00:32:47.820 --> 00:32:48.440
That's okay.

00:32:48.440 --> 00:32:54.020
But then it's like if data and is instance of string data and like there's some level

00:32:54.020 --> 00:32:58.040
where there's enough tests that it becomes, you kind of like, fine, just let it crash.

00:32:58.040 --> 00:32:58.540
Right.

00:32:58.540 --> 00:33:00.800
And then we'll just catch it and go.

00:33:00.800 --> 00:33:03.180
But we were talking before we hit record.

00:33:03.180 --> 00:33:06.100
Also, like there's a performance consideration potentially.

00:33:06.100 --> 00:33:06.740
Yeah, definitely.

00:33:06.740 --> 00:33:07.680
And it's interesting.

00:33:07.680 --> 00:33:09.740
I'll let you speak to what you found.

00:33:09.740 --> 00:33:15.500
But on the YouTube comments of the PyCon talk, that was one of the probably the most discussed

00:33:15.500 --> 00:33:22.060
things was whether or not the conditional expression was less performant than the original try and

00:33:22.060 --> 00:33:26.740
accept because a couple individuals commented that it was it was more Pythonic to use the

00:33:26.740 --> 00:33:29.980
try and accept and therefore it might be more performant.

00:33:29.980 --> 00:33:31.600
But you can share with what you found.

00:33:31.600 --> 00:33:31.980
Sure.

00:33:31.980 --> 00:33:36.300
Well, I think in terms of the Pythonic side, like certainly from other languages, like say

00:33:36.300 --> 00:33:38.900
C, C++, there's more of this.

00:33:38.900 --> 00:33:44.360
It's easier to ask for forgiveness than permission style of programming rather than the alternative.

00:33:44.360 --> 00:33:45.520
Look before you leap.

00:33:45.520 --> 00:33:45.860
Right.

00:33:45.860 --> 00:33:50.020
Because in like C, it can be a page fault and the program just goes poof and goes away.

00:33:50.020 --> 00:33:52.980
If you do something wrong, whereas this, it's just going to throw an exception.

00:33:52.980 --> 00:33:54.720
You're going to catch it or something like that.

00:33:54.720 --> 00:33:56.720
So there's like this tendency to do this style.

00:33:56.720 --> 00:34:01.140
But in terms of performance, I wrote a little program because I wanted to I'm like, maybe this

00:34:01.140 --> 00:34:01.660
is faster.

00:34:01.660 --> 00:34:02.380
Maybe it's slower.

00:34:02.380 --> 00:34:03.420
Like, let's think about that.

00:34:03.420 --> 00:34:03.620
Right.

00:34:03.980 --> 00:34:06.260
So I wrote a little program, which I'll link to.

00:34:06.260 --> 00:34:07.260
There's a simple gist.

00:34:07.260 --> 00:34:08.600
I'll link to it in the show notes.

00:34:08.600 --> 00:34:11.440
It creates one million, a list with one million items.

00:34:11.440 --> 00:34:14.260
And it uses a random seed that is always the same.

00:34:14.260 --> 00:34:17.700
So there's no, there's zero variability, even though it's random.

00:34:17.700 --> 00:34:19.240
It's like predictable random.

00:34:19.240 --> 00:34:24.180
And it builds up this list of either strings or numbers randomly, a million of them.

00:34:24.180 --> 00:34:26.320
About two third strings, one third number.

00:34:26.320 --> 00:34:28.680
And then it goes through and it just tries both of them.

00:34:28.680 --> 00:34:33.240
It says like, let's just convert this as many of them as we can over to integers and do it

00:34:33.240 --> 00:34:36.680
either with the tri-except pass or just do it with this is numeric test.

00:34:36.680 --> 00:34:38.580
It is six times.

00:34:38.580 --> 00:34:45.060
I got about 6.5 times faster to do the test, the one line test than it is to let it crash

00:34:45.060 --> 00:34:46.520
and realize that it didn't work.

00:34:46.520 --> 00:34:46.680
Yeah.

00:34:46.680 --> 00:34:47.300
So there you go.

00:34:47.300 --> 00:34:49.260
You heard it here on Talk Python to Me.

00:34:49.260 --> 00:34:50.320
That's right, man.

00:34:50.320 --> 00:34:52.700
Conditional expressions faster than try-except.

00:34:52.700 --> 00:34:57.420
Talk Python to Me is partially supported by our training courses.

00:34:57.920 --> 00:35:00.420
How does your team keep their Python skills sharp?

00:35:00.420 --> 00:35:04.560
How do you make sure new hires get started fast and learn the Pythonic way?

00:35:04.560 --> 00:35:13.560
If the answer is a series of boring videos that don't inspire or a subscription service you pay way too much for and use way too little, listen up.

00:35:14.360 --> 00:35:17.460
At Talk Python Training, we have enterprise tiers for all of our courses.

00:35:17.460 --> 00:35:22.020
Get just the one course you need for your team with full reporting and monitoring.

00:35:22.020 --> 00:35:29.740
Or ditch that unused subscription for our course bundles, which include all the courses and you pay about the same price as a subscription once.

00:35:29.800 --> 00:35:37.020
For details, visit training. talkpython.fm/business or just email sales at talkpython.fm.

00:35:37.020 --> 00:35:42.140
I mean, there's a lot of overhead to throw in an exception and catching it and dealing with all that.

00:35:42.140 --> 00:35:49.160
Now, right, this is a particular use case that varies and like all these benchmarks like might vary.

00:35:49.160 --> 00:35:54.380
Like if you've got 95% numbers and 5% strings, it might behave differently.

00:35:54.380 --> 00:35:59.240
Like, so there's a lot of variations, but here's an example you can play with in what seems like a reasonable example to me.

00:35:59.240 --> 00:36:02.360
It's faster to do the is numeric test.

00:36:02.360 --> 00:36:03.620
So a lot faster, right?

00:36:03.620 --> 00:36:07.160
Not like 5% faster, but 650% faster.

00:36:07.160 --> 00:36:08.480
So it's worth thinking about.

00:36:08.480 --> 00:36:08.700
Yeah.

00:36:08.700 --> 00:36:09.320
Yeah, for sure.

00:36:09.320 --> 00:36:10.220
Let's see.

00:36:10.220 --> 00:36:11.320
So come through.

00:36:11.320 --> 00:36:14.980
And in the end, you had, I mean, a ton of stuff was here.

00:36:14.980 --> 00:36:17.780
It was like 20 lines of code just for these two loops.

00:36:17.780 --> 00:36:27.620
And now you've got it down to four lines of code by basically an outer loop and inner loop, grab the data and append it with this little test that you've got.

00:36:27.620 --> 00:36:28.360
Much nicer.

00:36:28.360 --> 00:36:28.920
I agree.

00:36:28.920 --> 00:36:29.280
Yeah.

00:36:29.280 --> 00:36:35.920
So you went, I think if you look at the overall program at this point, you were doing some analysis or like some reporting.

00:36:35.920 --> 00:36:39.420
You said it started at 60 lines of code and now it's down to 20.

00:36:39.420 --> 00:36:39.940
Yeah.

00:36:39.940 --> 00:36:40.240
That's pretty good.

00:36:40.240 --> 00:36:40.840
Roughly.

00:36:40.840 --> 00:36:46.780
Depending on if you count, you know, empty lines and whatnot, but it was about 60 down to about 10 or 20 lines.

00:36:46.780 --> 00:36:52.140
And at this point, I had sort of pointed out that I had made a mistake.

00:36:52.140 --> 00:36:53.400
So like this was fantastic.

00:36:53.400 --> 00:36:56.140
At least I had thought that, you know, I'd taken a code.

00:36:56.140 --> 00:37:04.620
I'd taken a code snippet from a blog, reduced it by, you know, roughly 75% or 67%, depending on how you measure it.

00:37:04.620 --> 00:37:09.060
But that I had made an even bigger mistake than I had realized.

00:37:09.300 --> 00:37:17.360
And it was that when I had originally, I'd shown Googling for, you know, how to scrape HTML using pandas that I read the second results.

00:37:17.360 --> 00:37:21.060
And the third result was actually what I should have chosen.

00:37:21.060 --> 00:37:28.100
And it was that I had pandas actually has a read HTML method in the library.

00:37:28.100 --> 00:37:34.760
And so the point that I go on to make, if you use that, you go from, you know, 10 or 20 lines down to like four lines of code.

00:37:34.760 --> 00:37:38.220
And you're just invoking this one pandas API, read HTML.

00:37:38.220 --> 00:37:40.000
And it's so much better.

00:37:40.000 --> 00:37:41.940
So, you know, refactoring is fantastic.

00:37:41.940 --> 00:37:44.780
But there's some quote about like the best code is no code.

00:37:44.780 --> 00:37:49.840
If you don't have to write anything to do what you want to do and you can just use an existing library.

00:37:50.100 --> 00:37:55.600
That's the best thing that you can do because that's going to be way more tested than the custom code that you've written.

00:37:55.600 --> 00:37:57.460
It's going to save you a ton of time.

00:37:57.460 --> 00:38:01.220
And you're going to end up with ultimately less code to maintain yourself.

00:38:01.220 --> 00:38:05.880
And what's better than having someone else maintain the code that you're using for you?

00:38:05.880 --> 00:38:07.440
Exactly right.

00:38:07.540 --> 00:38:10.020
It gets better for no effort on your part.

00:38:10.020 --> 00:38:10.660
Yeah.

00:38:10.660 --> 00:38:15.860
It might get faster or it might handle more cases of like broken HTML or who knows.

00:38:15.860 --> 00:38:17.760
But you don't have to keep maintaining that.

00:38:17.760 --> 00:38:20.060
It's just read underscore HTML on pandas.

00:38:20.060 --> 00:38:21.600
Just it's probably getting maintained.

00:38:21.600 --> 00:38:21.940
Yeah.

00:38:21.940 --> 00:38:27.460
And so like one of the things that I've echoed in some of the other talks that I've given is knowing your algorithms.

00:38:27.460 --> 00:38:30.580
In C++, definitely there's a whole standard library.

00:38:30.580 --> 00:38:32.300
There's a lot of built-in functions.

00:38:32.300 --> 00:38:34.040
I guess they're not so much called algorithms.

00:38:34.040 --> 00:38:35.620
They call them built-in functions in Python.

00:38:36.280 --> 00:38:39.660
But like there's a whole page where I was just looking at it the other day.

00:38:39.660 --> 00:38:42.220
And there's a ton of them that I'm just not aware of.

00:38:42.220 --> 00:38:45.140
Everyone knows about map, filter, any all.

00:38:45.140 --> 00:38:51.560
Like I just saw, I think it was called div mod, which was a built-in function for giving you both like the quotient and the remainder.

00:38:51.560 --> 00:38:56.740
Which is like, there's definitely been a couple times where I've needed both of those and you do those operations separately.

00:38:56.740 --> 00:39:02.740
And it's like, if I just knew about it, you can in a single line, you know, you can destructure it using the iterable unpacking.

00:39:02.740 --> 00:39:05.920
Knowing your algorithms is great, but also knowing your libraries.

00:39:06.020 --> 00:39:06.780
Knowing your collections.

00:39:06.780 --> 00:39:13.200
Like the more you get familiar with what exists out there, the less you have to write and the more readable your code is.

00:39:13.200 --> 00:39:19.940
Because if everybody knows about it, we have a common knowledge base that it's transferable from every project you work on.

00:39:19.940 --> 00:39:20.260
Right.

00:39:20.260 --> 00:39:20.480
Yeah.

00:39:20.480 --> 00:39:23.040
Your final version basically had two really meaningful lines.

00:39:23.040 --> 00:39:25.060
One was request.get.

00:39:25.060 --> 00:39:27.760
The other was pandas.readHTML.

00:39:28.000 --> 00:39:32.980
You don't have to explain to anyone who has done almost anything with Python what request.get means.

00:39:32.980 --> 00:39:33.680
Like, oh yeah.

00:39:33.680 --> 00:39:33.960
Okay.

00:39:33.960 --> 00:39:34.620
So got it.

00:39:34.620 --> 00:39:35.140
Next.

00:39:35.140 --> 00:39:35.680
Right.

00:39:35.680 --> 00:39:36.480
We all know how that works.

00:39:36.480 --> 00:39:37.420
We know it's going to work.

00:39:37.420 --> 00:39:38.600
And so on.

00:39:38.600 --> 00:39:39.660
And it's really nice.

00:39:39.880 --> 00:39:47.940
I think, though, what you've touched on here actually is really important, but it also shows why it's kind of hard to get really good at a language.

00:39:48.060 --> 00:39:51.660
And the reason is there are so many packages, right?

00:39:51.660 --> 00:39:52.580
You go to PyPI.

00:39:52.580 --> 00:39:54.720
Let me try pyp.org.now.

00:39:54.720 --> 00:39:57.080
Every time I go there, it's always more, right?

00:39:57.080 --> 00:39:59.120
So 245,000 packages.

00:39:59.120 --> 00:40:05.900
If you want to learn to be a good Python programmer, you need to at least have awareness at a lot of those and probably some skill set in some of them.

00:40:06.340 --> 00:40:08.520
Because like Panda is one of those.

00:40:08.520 --> 00:40:09.840
Request is another one, right?

00:40:09.840 --> 00:40:15.500
The four-line solution that you came up with was building on those two really cool libraries.

00:40:15.500 --> 00:40:20.640
And so to be a good programmer and effective means like keeping your eye on all those things.

00:40:20.640 --> 00:40:26.960
And I just think that's, it's both amazing, but it's also kind of tricky because it's like, well, I'm really good with for loops and I create functions now.

00:40:26.960 --> 00:40:27.440
You're like, great.

00:40:27.440 --> 00:40:29.420
You've got 200,000 packages of study.

00:40:29.420 --> 00:40:29.680
Go.

00:40:30.620 --> 00:40:36.340
There's some quote that I've heard before where being a language expert is 10% language, 90% ecosystem.

00:40:36.340 --> 00:40:43.520
And it's, you can't be a guru and insert any language if you don't know the tools, if you don't know the libraries.

00:40:43.520 --> 00:40:49.640
It's so much more than just learning the syntax and learning the built-in functions that come with your language.

00:40:49.640 --> 00:40:52.420
It takes years and it definitely doesn't happen overnight.

00:40:52.420 --> 00:40:53.940
It's a challenge for all of us.

00:40:53.940 --> 00:40:54.580
Yeah, for sure.

00:40:54.980 --> 00:41:01.860
You know, maybe it's worth a shout out to awesome-python.com right now as well, which like has different categories you maybe care about.

00:41:01.860 --> 00:41:05.180
And then we'll like highlight some of the more popular libraries in that area.

00:41:05.180 --> 00:41:05.820
That sounds awesome.

00:41:05.820 --> 00:41:06.720
That's a good one.

00:41:06.720 --> 00:41:07.260
Yeah, for sure.

00:41:07.260 --> 00:41:10.140
So you went through and you did nine different steps.

00:41:10.140 --> 00:41:13.080
You actually have those called out very clearly in your slides.

00:41:13.080 --> 00:41:18.820
You can get the slides from the GitHub repo associated with your talk, which I'll link to in the show notes, of course.

00:41:19.260 --> 00:41:28.720
But all of this refactoring talk was really part of the journey to come up with a totally different answer, which was what are the most popular languages for these coding competitions?

00:41:28.720 --> 00:41:29.080
Yeah.

00:41:29.080 --> 00:41:34.680
Ultimate goal was to scrape the data and then to use pandas in order to do that analysis.

00:41:34.680 --> 00:41:42.640
And at the end of the day, I believe the number one, I definitely know the number one language was C++ at about, I think it was 89%.

00:41:42.900 --> 00:41:50.500
And that typically is the case because certain websites, they give the same time limit per language.

00:41:50.500 --> 00:41:53.440
So a website like HackerRank, they vary by language.

00:41:53.440 --> 00:41:59.640
So Python, your execution time that you're allotted is 10 times more for Python.

00:41:59.640 --> 00:42:03.200
So even though Python's slower, they give you a proportionate amount of time.

00:42:03.200 --> 00:42:04.840
But most websites don't do that.

00:42:04.840 --> 00:42:12.220
So the CodeForces website, it gives like you, I think, two seconds execution time, regardless of the language you use.

00:42:12.220 --> 00:42:16.660
And so due to that, most people choose the most performant language, which is C++.

00:42:16.660 --> 00:42:18.380
But in second place was Python.

00:42:18.380 --> 00:42:32.640
And I know a lot of competitive programmers that for the problems where performance isn't an issue that you're trying to solve for, they always use Python because it's about a fraction of the number of lines of code to solve it in Python than it is in any other language.

00:42:32.640 --> 00:42:35.340
Sometimes you can solve a problem in one line in Python.

00:42:35.340 --> 00:42:40.300
And the next closest language is like five lines, which is a big deal when time matters.

00:42:40.540 --> 00:42:40.620
Yeah.

00:42:40.620 --> 00:42:41.020
Yeah.

00:42:41.020 --> 00:42:45.540
Are you optimizing execution time or developer time in this competition?

00:42:45.540 --> 00:42:45.860
Right?

00:42:45.860 --> 00:42:46.220
Yeah.

00:42:46.220 --> 00:42:48.380
It definitely matters what you're trying to solve for.

00:42:48.380 --> 00:42:49.780
So yeah, C++ was first.

00:42:49.780 --> 00:42:50.720
Python was second.

00:42:50.720 --> 00:42:52.060
Java was third.

00:42:52.060 --> 00:42:54.040
And then there was a bunch of fringe languages.

00:42:54.040 --> 00:42:57.020
The top three were C#, Pascal, and Kotlin.

00:42:57.480 --> 00:43:00.400
And yeah, you can see a full list if you go watch the PyCon talk.

00:43:00.400 --> 00:43:03.800
But it was cool, yeah, to find out what was used and what wasn't.

00:43:03.800 --> 00:43:04.500
Yeah, it sure was.

00:43:04.500 --> 00:43:09.700
And it was cool to see the evolution of what you created to answer that question, which is pretty neat.

00:43:09.940 --> 00:43:12.500
All right, well, let's just talk a little bit about Rapids.

00:43:12.500 --> 00:43:18.360
Because I know that people out there are, there's a lot of data scientists, and they're probably interested in that project.

00:43:18.360 --> 00:43:30.120
So we did mention a tiny bit that it's basically take Handa's data frames, apply something like that, that API, pretty close, not 100% identical and everything, but pretty close.

00:43:30.120 --> 00:43:31.360
And it runs on GPUs.

00:43:31.360 --> 00:43:33.240
So why are GPUs better?

00:43:33.240 --> 00:43:35.380
Like, I have a really fast computer.

00:43:35.520 --> 00:43:38.740
I have a core I9 with like six cores I got a couple years ago.

00:43:38.740 --> 00:43:39.940
That's a lot of cores, right?

00:43:39.940 --> 00:43:46.340
So yeah, well, first thing I should highlight, too, is that Rapids is more than just QDF.

00:43:46.340 --> 00:43:48.720
So QDF is the library I work on.

00:43:48.720 --> 00:43:53.920
We also have QIO, QGraph, QSignal, QSpacial, QML.

00:43:53.920 --> 00:43:59.640
And each of those sort of map to a different thing in like the data science ecosystem.

00:43:59.640 --> 00:44:02.740
So QDF definitely is the analog of pandas.

00:44:03.360 --> 00:44:07.200
QML, I think the sort of analog you can think of is like scikit-learn.

00:44:07.200 --> 00:44:10.740
But also, too, like none of this is meant as replacements.

00:44:10.740 --> 00:44:12.440
They're just meant as alternatives.

00:44:12.440 --> 00:44:16.720
Like if performance is not an issue for you, like stick with what you have.

00:44:16.720 --> 00:44:17.820
There's no reason to switch.

00:44:17.820 --> 00:44:21.900
Yeah, don't do it because, for example, I couldn't run it on my MacBook, right?

00:44:21.900 --> 00:44:22.800
Because I have a Radeon.

00:44:22.800 --> 00:44:23.460
Right, right.

00:44:23.460 --> 00:44:26.580
If you do want to try it out, I think they're on the Rapids.

00:44:26.580 --> 00:44:32.160
So if you go to rapids.ai, we have a link to a couple examples using like Google CoLab

00:44:32.160 --> 00:44:35.040
that are hooked up to like free GPUs that you can just take it for a spin.

00:44:35.040 --> 00:44:38.480
And you need the hardware, but you can go try it out.

00:44:38.480 --> 00:44:43.000
But like our pitch is sort of like this is useful for people that have issues with compute.

00:44:43.000 --> 00:44:43.620
Right.

00:44:43.620 --> 00:44:46.760
And for different pieces, you're going to want different projects.

00:44:46.760 --> 00:44:50.640
So if you're doing pandas like sort of data manipulation, QDF is what you want.

00:44:50.640 --> 00:44:53.380
But yeah, why are our GPUs faster?

00:44:53.380 --> 00:44:56.540
It's just a completely different device and a completely different model.

00:44:56.540 --> 00:45:00.980
So GPUs, typically it's in the G of the GPU.

00:45:00.980 --> 00:45:06.160
We're known for being great for graphics processing, which is why it's called a GPU.

00:45:06.160 --> 00:45:08.900
But at some point, someone coined the term.

00:45:08.900 --> 00:45:11.840
He actually works on the Rapids team, Mark Harris.

00:45:12.040 --> 00:45:17.580
He coined the term GPGPU, which stands for general processing GPU compute.

00:45:17.580 --> 00:45:20.420
It's now typically referred to as just GPU computing.

00:45:20.420 --> 00:45:26.680
But it's this idea that even though the GPU model is great for graphics processing, there

00:45:26.680 --> 00:45:31.200
are other applications that GPUs are also amazing for.

00:45:31.200 --> 00:45:36.200
The next best one is matrix multiplication, which is why they sort of became huge in neural

00:45:36.200 --> 00:45:37.360
nets and deep learning.

00:45:37.360 --> 00:45:42.160
But since then, we've basically discovered that there's not really any domain that we can't

00:45:42.160 --> 00:45:43.920
find a use for GPUs for.

00:45:43.920 --> 00:45:48.280
So there is a standard library in the CUDA model called Thrust.

00:45:48.280 --> 00:45:54.660
So if you're familiar with C++, the standard library is called STL, and it has a suite of algorithms

00:45:54.660 --> 00:45:56.600
and data structures that you can use.

00:45:56.600 --> 00:45:59.220
Thrust is the analog of that for CUDA.

00:45:59.620 --> 00:46:05.240
And it has reductions, it has scans, and it basically has all the algorithms that you

00:46:05.240 --> 00:46:07.140
might find in your C++ STL.

00:46:07.140 --> 00:46:12.380
And if you can build a program that uses those algorithms, you've just GPU accelerated your

00:46:12.380 --> 00:46:12.680
code.

00:46:12.680 --> 00:46:16.400
However, using Thrust isn't as easy as some might like.

00:46:16.400 --> 00:46:21.680
And a lot of data scientists, they're currently operating in Python and R, and they don't want

00:46:21.680 --> 00:46:27.340
to go and learn C++ and then CUDA and then master the Thrust library just in order to accelerate

00:46:27.340 --> 00:46:28.380
their data science code.

00:46:28.380 --> 00:46:35.540
The Rapids goal is to basically bring this GPU computing model for a sort of general purpose

00:46:35.540 --> 00:46:41.020
acceleration of data science compute or whatever compute you want to the data scientists.

00:46:41.020 --> 00:46:45.740
And so if they're familiar with the Pandas API, let's just do all that work for them.

00:46:45.740 --> 00:46:49.740
Put the so so Rapids is built heavily on top of Thrust and CUDA.

00:46:50.000 --> 00:46:54.720
And so we're basically just doing all this work for the data scientists so that they can take

00:46:54.720 --> 00:46:59.480
their Pandas code, like you said, hopefully just replace the import, and you're off to

00:46:59.480 --> 00:46:59.860
the races.

00:46:59.860 --> 00:47:03.540
And some of the performance wins are pretty impressive.

00:47:03.540 --> 00:47:05.260
Like I'm not on the marketing side of things.

00:47:05.260 --> 00:47:10.520
But in the talk I mentioned, I just happened to be listening to a podcast called the NVIDIA

00:47:10.520 --> 00:47:11.200
AI podcast.

00:47:11.200 --> 00:47:13.440
And they had, I believe his name was Kyle Nicholson.

00:47:13.440 --> 00:47:22.740
And by swapping out CUDA for Pandas for their model, they were able to get a 100x performance

00:47:22.740 --> 00:47:26.240
win and a 30x reduction in cost.

00:47:26.540 --> 00:47:28.680
That's 30 times, not 30%.

00:47:28.680 --> 00:47:28.940
Yeah.

00:47:28.940 --> 00:47:32.540
So 30,000 times, like multiplicatively, which is massive.

00:47:32.540 --> 00:47:34.900
That's the difference between something running.

00:47:34.900 --> 00:47:38.760
So if it's 100x in terms of performance, that's the difference between something running in 60

00:47:38.760 --> 00:47:41.200
seconds or an hour and 40 minutes.

00:47:41.200 --> 00:47:47.160
And if you can also save 30x, if that cost you 100 bucks, and now you only have to pay $3,

00:47:47.160 --> 00:47:52.740
it seems like a no brainer for those individuals that are impacted by performance bottleneck.

00:47:52.840 --> 00:47:57.540
Like I said, if you're hitting Pandas, and it runs in a super short number of seconds,

00:47:57.540 --> 00:47:59.600
it's probably not worth it to switch over.

00:47:59.600 --> 00:47:59.960
Yeah.

00:47:59.960 --> 00:48:04.420
Well, and you probably, you tell me how realistic you think this is, but you could probably do

00:48:04.420 --> 00:48:11.100
some kind of import, conditional import, like in the import, you could try to get the rapid

00:48:11.100 --> 00:48:12.000
stuff working.

00:48:12.000 --> 00:48:15.540
If that fails, you could just import Pandas as the same thing.

00:48:15.540 --> 00:48:17.080
One is PD, the other is PD.

00:48:17.080 --> 00:48:21.600
And maybe it just falls back to just working on regular hardware, but faster when it works.

00:48:21.600 --> 00:48:22.120
What do you think?

00:48:22.420 --> 00:48:23.900
That is definitely possible.

00:48:23.900 --> 00:48:29.780
There's going to be limitations to it, though, obviously, if you have a sort of QDF data frame,

00:48:29.780 --> 00:48:32.360
like I don't think you wouldn't be able to do it piecemeal.

00:48:32.360 --> 00:48:34.180
But if you have a large product,

00:48:34.180 --> 00:48:40.140
what I'm thinking is if you wrote it for the Rapids version, but then let it fall back to

00:48:40.140 --> 00:48:41.160
Pandas, not the other way around.

00:48:41.160 --> 00:48:44.860
If you take arbitrary Pandas code, you try to rapidify it, that might not work.

00:48:44.860 --> 00:48:47.240
But it seems like the other one may well work.

00:48:47.520 --> 00:48:50.400
And that way, if somebody tries to run it, they don't have the right setup.

00:48:50.400 --> 00:48:51.720
It's just slower possible.

00:48:51.720 --> 00:48:52.380
What do you think?

00:48:52.380 --> 00:48:54.940
There's definitely a way to do that, to make that work.

00:48:54.940 --> 00:48:59.700
It might require a little bit of, you know, some sort of boilerplate framework code that

00:48:59.700 --> 00:49:02.600
is doing some sort of checking, you know, is this compatible else?

00:49:02.600 --> 00:49:04.420
But like, that definitely sounds automatable.

00:49:04.420 --> 00:49:05.260
Like, yeah.

00:49:05.260 --> 00:49:05.780
Yeah.

00:49:05.780 --> 00:49:06.260
That sounds cool.

00:49:06.260 --> 00:49:10.260
Because that would be great to have it just fall back to like, not not working, just not

00:49:10.260 --> 00:49:10.780
so fast.

00:49:10.780 --> 00:49:11.180
Right?

00:49:11.300 --> 00:49:11.640
Yeah, yeah.

00:49:11.640 --> 00:49:17.700
The future of computing is headed to a place where we can dispatch compute to like different

00:49:17.700 --> 00:49:24.420
devices without having to like, manually specify that, like, I need this code to run on the CPU

00:49:24.420 --> 00:49:29.900
versus the GPU versus the TPU versus in the future, I'm sure there's going to be a QPU for

00:49:29.900 --> 00:49:31.180
quantum processing unit.

00:49:31.180 --> 00:49:32.400
Like, like, exactly.

00:49:32.400 --> 00:49:37.160
Currently, we all think serially or most of us that don't work at NVIDIA, we think serially

00:49:37.160 --> 00:49:43.020
in terms of like, the way that CPUs do compute, but I think in 10 or 20 years, we're all going

00:49:43.020 --> 00:49:44.600
to be learning about different devices.

00:49:44.600 --> 00:49:49.980
And it's going to be too much work to, in our head, always have to be keeping track of which

00:49:49.980 --> 00:49:54.100
devices it's going to, at some point, there's going to be a programming model that comes out

00:49:54.100 --> 00:49:58.400
that just automatically handles when it can go to the fast device, and when we can just

00:49:58.400 --> 00:49:59.120
send it to the CPU.

00:49:59.120 --> 00:50:00.200
Yeah, absolutely.

00:50:00.200 --> 00:50:05.300
So just while you were talking, I pulled it up on that Alienware gaming machine I got.

00:50:05.660 --> 00:50:12.140
It has a GeForce RTX 270, which has 2,304 cores.

00:50:12.140 --> 00:50:14.600
So that's a lot.

00:50:14.600 --> 00:50:16.260
That's a lot of cores.

00:50:16.260 --> 00:50:23.960
And if you look somewhere, Google claims that it achieves 7.5 teraflops in the super, increases

00:50:23.960 --> 00:50:27.160
that to 9 teraflops, which is just insane.

00:50:27.160 --> 00:50:33.460
It's like a core i7 doing like 0.35, 0.28 or something like that.

00:50:33.460 --> 00:50:37.700
So anyway, the numbers, they just are like, they boggle the mind when you think of how

00:50:37.700 --> 00:50:40.220
much computation graphics cards do these days.

00:50:40.220 --> 00:50:45.540
I think top of the line, I might get this wrong, but like the modern GPUs are capable of 15 teraflops.

00:50:46.040 --> 00:50:51.940
It's an immense amount of compute that's hard to fathom, especially when coming from a CPU sort of way of thinking.

00:50:51.940 --> 00:50:52.620
Yeah, absolutely.

00:50:52.620 --> 00:50:57.660
Yeah, the only reason I didn't get a higher graphics card is every other version required water cooling.

00:50:57.660 --> 00:50:59.940
I'm like, that sounds like more effort than I want for a computer.

00:50:59.940 --> 00:51:01.260
I'll just go with this one.

00:51:01.260 --> 00:51:02.400
Yeah.

00:51:03.520 --> 00:51:04.000
All right.

00:51:04.000 --> 00:51:06.500
Well, Rapid sounds like a super cool project.

00:51:06.500 --> 00:51:12.420
And maybe we should do another show with the Rapid's theme across these things to talk a little bit more deeply.

00:51:12.420 --> 00:51:14.120
But it sounds like a great project.

00:51:14.120 --> 00:51:14.940
Glad you're working on it.

00:51:14.940 --> 00:51:22.420
I work on the C++ lower engine of it, but I'd be happy to connect you with some of the Python folks that work on that side of things.

00:51:22.420 --> 00:51:23.900
And I'm sure they'd love to come on.

00:51:23.900 --> 00:51:24.540
Yeah, that'd be fun.

00:51:24.540 --> 00:51:25.200
All right.

00:51:25.200 --> 00:51:27.640
Now, before we get out of here, I've got to ask you the two questions.

00:51:27.640 --> 00:51:30.500
If you're going to write some Python code, what editor do you use?

00:51:30.740 --> 00:51:33.260
So I am a VS Code convert.

00:51:33.260 --> 00:51:35.120
That's what I typically use day to day.

00:51:35.120 --> 00:51:35.420
Nice.

00:51:35.420 --> 00:51:36.960
Yeah, that's quite a popular one these days.

00:51:36.960 --> 00:51:39.200
And then notable PyPI package.

00:51:39.200 --> 00:51:41.600
Then you ran across like, oh, people should know about this.

00:51:41.600 --> 00:51:41.900
Yeah.

00:51:41.900 --> 00:51:49.200
So I like to recommend there's a built in standard library, which I'm pretty sure most Python developers are familiar with.

00:51:49.200 --> 00:51:52.080
Itertools, which has a ton of great functions.

00:51:52.080 --> 00:51:57.020
But less well known is a PyPI package called more hyphen itertools.

00:51:57.020 --> 00:51:59.940
And I'm not sure if this one's been recommended on the show before.

00:52:00.180 --> 00:52:05.000
But if you like what's in itertools, you'll love what's in more itertools.

00:52:05.000 --> 00:52:09.700
It has a ton of my favorite algorithms, chunked being one of them.

00:52:09.700 --> 00:52:15.900
You basically pass it a list and a number, and it gives you a list of lists consisting of that many things.

00:52:15.900 --> 00:52:17.340
It's like paging for lists.

00:52:17.340 --> 00:52:17.920
Yeah, yeah.

00:52:17.920 --> 00:52:19.840
And there's tons of neat functions.

00:52:19.840 --> 00:52:25.100
Another great one that's so simple, but doesn't exist built in all underscore equal.

00:52:25.340 --> 00:52:28.920
It just checks, given a list, are all of the elements the same?

00:52:28.920 --> 00:52:30.740
And it's a simple thing to do.

00:52:30.740 --> 00:52:35.560
You can do it with all, but you have to check is every element equal to the first one or the last one.

00:52:35.740 --> 00:52:40.220
So there's just a ton of really convenient functions and algorithms in more itto tools.

00:52:40.220 --> 00:52:40.940
That's the one I recommend.

00:52:40.940 --> 00:52:41.560
Yeah, that's cool.

00:52:41.560 --> 00:52:44.820
And you can combine these with like generator expressions and stuff.

00:52:44.820 --> 00:52:50.800
They are all these, you know, pull some element out of each object that's in there and generate that collection.

00:52:50.800 --> 00:52:52.060
Ask if all those are equal.

00:52:52.060 --> 00:52:54.420
And they go to all these ideas go together well there.

00:52:54.560 --> 00:52:55.840
Yeah, they compose super nicely.

00:52:55.840 --> 00:52:56.640
Yeah, for sure.

00:52:56.640 --> 00:52:57.280
All right.

00:52:57.280 --> 00:52:58.360
Final call to action.

00:52:58.360 --> 00:53:03.640
People are interested in doing refactoring, making their code better, maybe even checking out Rapids.

00:53:03.640 --> 00:53:04.100
What do you say?

00:53:04.100 --> 00:53:08.420
I'd say if you're interested in what you heard on the podcast, check out the PyCon talk.

00:53:08.420 --> 00:53:09.420
It's on YouTube.

00:53:09.420 --> 00:53:14.200
If you search for PyCon 2020, you'll find the YouTube channel.

00:53:14.200 --> 00:53:18.640
And yeah, if you're definitely interested in rapids.ai, check us out there.

00:53:18.640 --> 00:53:20.600
I assume all this stuff will be in the show notes as well.

00:53:20.600 --> 00:53:22.340
So maybe that's easier than YouTube searching.

00:53:23.180 --> 00:53:26.380
Yeah, well, and then also you talked about YouTube channel a little bit.

00:53:26.380 --> 00:53:27.960
Maybe just tell people how to find that.

00:53:27.960 --> 00:53:29.560
We'll put a link in the show notes as well.

00:53:29.560 --> 00:53:34.020
So they can, if they want to watch you, you know, talk about some of these solutions and these competitions.

00:53:34.020 --> 00:53:34.400
Yeah.

00:53:34.400 --> 00:53:37.120
So my online alias is code underscore report.

00:53:37.120 --> 00:53:42.180
If you search for that on Twitter or YouTube or Google, I'm sure all the links will come up.

00:53:42.180 --> 00:53:43.400
And yeah, you can find me that way.

00:53:43.400 --> 00:53:43.680
Awesome.

00:53:43.680 --> 00:53:44.040
All right.

00:53:44.040 --> 00:53:45.000
Yeah, we'll link to that as well.

00:53:45.000 --> 00:53:45.440
All right.

00:53:45.440 --> 00:53:47.280
Well, Connor, thank you so much for being on the show.

00:53:47.280 --> 00:53:48.820
It was a lot of fun to talk about these things with you.

00:53:48.820 --> 00:53:49.560
Thanks for having me on.

00:53:49.560 --> 00:53:50.100
This was awesome.

00:53:50.100 --> 00:53:50.640
Yeah, you bet.

00:53:50.640 --> 00:53:50.880
Bye-bye.

00:53:51.520 --> 00:53:54.140
This has been another episode of Talk Python to Me.

00:53:54.140 --> 00:53:58.660
Our guest on this episode was Connor Hoekstra, and it's been brought to you by us over at

00:53:58.660 --> 00:53:59.560
Talk Python Training.

00:53:59.560 --> 00:54:01.680
Want to level up your Python?

00:54:01.680 --> 00:54:06.540
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

00:54:06.540 --> 00:54:11.640
Or if you're looking for something more advanced, check out our new async course that digs into

00:54:11.640 --> 00:54:14.700
all the different types of async programming you can do in Python.

00:54:14.960 --> 00:54:18.660
And of course, if you're interested in more than one of these, be sure to check out our

00:54:18.660 --> 00:54:19.340
everything bundle.

00:54:19.340 --> 00:54:21.260
It's like a subscription that never expires.

00:54:21.260 --> 00:54:23.400
Be sure to subscribe to the show.

00:54:23.400 --> 00:54:25.900
Open your favorite podcatcher and search for Python.

00:54:25.900 --> 00:54:27.040
We should be right at the top.

00:54:27.040 --> 00:54:32.600
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the

00:54:32.600 --> 00:54:36.020
direct RSS feed at /rss on talkpython.fm.

00:54:36.020 --> 00:54:38.100
This is your host, Michael Kennedy.

00:54:38.100 --> 00:54:39.600
Thanks so much for listening.

00:54:39.600 --> 00:54:40.660
I really appreciate it.

00:54:40.920 --> 00:54:42.440
Now get out there and write some Python code.

00:54:42.440 --> 00:55:03.200
I really appreciate it.

00:55:03.200 --> 00:55:33.180
Thank you.

