WEBVTT

00:00:00.001 --> 00:00:04.840
I've gathered a group of Python experts who have been thinking deeply about where Python is going

00:00:04.840 --> 00:00:11.140
and who have lived through where it has been. This episode is all about near-term Python trends and

00:00:11.140 --> 00:00:15.500
things we each believe will be important to focus on as Python continues to grow.

00:00:15.500 --> 00:00:21.740
Our panelists are Jody Birchall, Carol Willing, and Paul Everett. This is Talk Python in Me episode

00:00:21.740 --> 00:00:26.160
468, recorded June 18th, 2024.

00:00:26.160 --> 00:00:28.420
Are you ready for your host?

00:00:28.760 --> 00:00:34.360
You're listening to Michael Kennedy on Talk Python To Me. Live from Portland, Oregon,

00:00:34.360 --> 00:00:36.460
and this segment was made with Python.

00:00:36.460 --> 00:00:44.860
Welcome to Talk Python To Me, a weekly podcast on Python. This is your host, Michael Kennedy.

00:00:44.860 --> 00:00:49.980
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:00:49.980 --> 00:00:56.340
both on fosstodon.org. Keep up with the show and listen to over seven years of past episodes at

00:00:56.340 --> 00:01:02.460
talkpython.fm. We've started streaming most of our episodes live on YouTube. Subscribe to our YouTube

00:01:02.460 --> 00:01:08.380
channel over at talkpython.fm/youtube to get notified about upcoming shows and be part of that

00:01:08.380 --> 00:01:13.780
episode. This episode is brought to you by Code Comments, an original podcast from Red Hat.

00:01:13.780 --> 00:01:20.920
This podcast covers stories from technologists who've been through tough tech transitions and share how their

00:01:20.920 --> 00:01:26.200
teams survive the journey. Episodes are available everywhere you listen to your podcasts and at

00:01:26.200 --> 00:01:32.900
talkpython.fm/code dash comments. And it's brought to you by Posit Connect from the makers of

00:01:32.900 --> 00:01:37.660
Shiny. Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:38.100 --> 00:01:44.320
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:44.320 --> 00:01:50.480
Posit Connect supports all of them. Try Posit Connect for free by going to talkpython.fm slash

00:01:50.480 --> 00:01:52.400
Posit, P-O-S-I-T.

00:01:52.400 --> 00:01:58.900
Big news, we've added a new course over at Talk Python, Reactive Web Dashboards with Shiny.

00:01:58.900 --> 00:02:06.540
You probably know Shiny from the R and R studio world. But as you may recall from episode 424 of Joe

00:02:06.540 --> 00:02:12.040
Chen, the folks at Posit have released Shiny for Python. It's a great technology for building

00:02:12.040 --> 00:02:17.880
reactive data science oriented web apps that are incredibly easy to publish to the web.

00:02:17.880 --> 00:02:23.880
If that sounds like something you'd like to learn, then this course is for you. And it's an easy

00:02:23.880 --> 00:02:31.840
choice because the course is 100% free. Just visit talkpython.fm/shiny and click on take this

00:02:31.840 --> 00:02:35.900
course for free to get started. I'll put the link in the podcast player show notes.

00:02:36.180 --> 00:02:42.940
Thanks as always for supporting our work. Paul, Jody, and Carol, welcome back to Talk Python

00:02:42.940 --> 00:02:45.340
to Me for all of you. Great to have you all back.

00:02:45.340 --> 00:02:46.060
Great to be back.

00:02:46.060 --> 00:02:46.740
Thanks for having us.

00:02:46.740 --> 00:02:52.500
Jody, your latest episode is going to come out tomorrow. So we're on a tight loop here. This

00:02:52.500 --> 00:02:59.380
excellent data science panel thing we did at PyCon was really fun. But now we're back for a different

00:02:59.380 --> 00:02:59.720
panel.

00:02:59.720 --> 00:03:00.160
Yes.

00:03:01.280 --> 00:03:06.740
we're going to talk about Python trends and just what we all think is something people out there

00:03:06.740 --> 00:03:10.240
should be paying attention to. We all have slightly different backgrounds, which I think is going to

00:03:10.240 --> 00:03:14.780
make it really interesting as well. But since people don't listen to every episode, maybe quick

00:03:14.780 --> 00:03:18.520
introductions. Jody, quick, quick introduction for you. We'll go around.

00:03:19.040 --> 00:03:44.700
So my name is Jody Burchell. I'm currently working at JetBrains with Paul. Paul's actually my boss. And I'm working as the developer advocate in data science. So I've been a data scientist for around eight years. And prior to that, I was an academic like many data scientists. And my background is actually psychology. So, you know, if you also want to ask me about anxiety disorders or emotions, you can ask me about these things.

00:03:44.700 --> 00:03:46.400
In open source? No way.

00:03:46.400 --> 00:03:47.400
No way.

00:03:47.400 --> 00:03:47.460
No way.

00:03:47.460 --> 00:03:52.380
Awesome. Great to have you back. Carol?

00:03:52.380 --> 00:04:11.580
Yeah. Hi, I'm Carol Willing. I'm really happy to be here today. I am half retired, half doing consulting for early stage companies that are interested in data science and have a particular love for open science. I am a core developer and former steering council member for Python.

00:04:12.160 --> 00:04:23.920
And also on the Jupyter team. So my real passions, though, are education and lifelong learning. So I'm really excited to talk about some of the trends that I'm seeing.

00:04:23.920 --> 00:04:25.220
Yeah, fantastic. Paul?

00:04:25.220 --> 00:04:28.640
Hi, I'm Paul Everett. I'm president of the Carol Willing Fan Club.

00:04:28.640 --> 00:04:32.800
Lifetime member. You get a special coin for that, too.

00:04:33.120 --> 00:04:44.540
And when I'm not doing that, I'm at JetBrains, Python and Web Advocate. I have a bit of a long time love affair with Python and the web, which I hope that we'll talk to you.

00:04:44.540 --> 00:04:47.820
Yeah, you worked on early, early web frameworks in Python.

00:04:47.820 --> 00:04:48.280
Yeah.

00:04:48.280 --> 00:04:52.100
Those Django people, they were thinking about what Paul and team did before that, right?

00:04:52.100 --> 00:04:55.720
Django was the thing that killed us. Haven't gotten over that Django.

00:04:55.720 --> 00:04:57.780
I didn't mean to bring it up. I didn't mean to bring it up.

00:04:57.780 --> 00:04:58.680
I'm over it, really.

00:04:59.820 --> 00:05:04.520
We'll get you some therapy later. No. No, awesome. Great to have you all here.

00:05:04.520 --> 00:05:11.820
Our plan is to just, you know, we all brought a couple of ideas, introduce them and just have a little group chat, you know, casual chat.

00:05:11.820 --> 00:05:17.320
I'm like, well, do we really think it's going that way? What's important? What should we be paying attention to? And where's it going?

00:05:17.320 --> 00:05:21.680
So, Jody, I know you gave a fun talk at PyCon US.

00:05:21.680 --> 00:05:25.040
And those are not up, those videos yet, are they? I haven't seen them.

00:05:25.040 --> 00:05:29.280
No, no. They're still behind the paywall. So if you attended the conference, you can view them.

00:05:29.480 --> 00:05:32.080
But otherwise, not available to the public yet, I'm afraid.

00:05:32.080 --> 00:05:33.140
Not yet. They'll be out.

00:05:33.140 --> 00:05:34.320
So hopefully we can share.

00:05:34.320 --> 00:05:43.960
I know it's somewhat relevant to what your, some of your ideas, but let's go with your first friend in the coming years or the immediate, near, near term.

00:05:43.960 --> 00:05:50.500
For the immediate term, I don't know if this will be good news to people, but LLMs are not going anywhere just yet.

00:05:51.540 --> 00:05:54.820
So I actually did a bit of research for this episode.

00:05:54.820 --> 00:06:01.940
And what I wanted to say, you know, data scientist, is what the download numbers on different packages on PyPI look like.

00:06:02.300 --> 00:06:09.600
So there's particular package, Transformers, which is one of the main packages for interfacing with LLMs, the open source ones on Hugging Face.

00:06:09.600 --> 00:06:16.360
And the download numbers of that have doubled in, not sorry, gone up 50% in the last six months.

00:06:16.360 --> 00:06:25.900
And they're now comparable to the big sort of deep learning packages like Keras, TensorFlow and PyTorch, which is quite interesting.

00:06:25.900 --> 00:06:26.560
Yeah.

00:06:26.560 --> 00:06:29.700
Unfortunately, for those of you who are sick of LLMs, not going anywhere.

00:06:30.240 --> 00:06:34.080
But this year, we're sort of seeing a bit of a change in how LLMs are used.

00:06:34.080 --> 00:06:41.160
So I think last year it was a bit like blinded by the proprietary sort of models and the sort of walled garden.

00:06:41.160 --> 00:06:46.140
This year, I think we're seeing more of a sort of open source fight back.

00:06:46.140 --> 00:06:51.080
So LLMs are starting to be used as part of more multi-part applications.

00:06:51.080 --> 00:06:52.920
And there are open source packages like that.

00:06:52.920 --> 00:06:54.280
Langchain is the most popular.

00:06:54.280 --> 00:06:57.360
And the downloads of that one have doubled in the last six months.

00:06:57.800 --> 00:07:01.080
We have alternatives like Haystack and Llama Index.

00:07:01.080 --> 00:07:05.800
And then RAG, of course, Retrieval Augmented Generation is one of the big topics.

00:07:05.800 --> 00:07:08.000
And we're seeing the ecosystem around that growing.

00:07:08.000 --> 00:07:11.940
So libraries like Unstructured to work with a whole bunch of text inputs,

00:07:11.940 --> 00:07:14.240
Weeviate, vector databases like that.

00:07:14.240 --> 00:07:18.600
And then, of course, smaller language models are becoming...

00:07:18.600 --> 00:07:21.280
People are realizing it's really hard to deploy and work with the big ones.

00:07:21.280 --> 00:07:26.620
So smaller models, which are more domain-specific, which are trained on more specific data,

00:07:26.880 --> 00:07:29.120
they're becoming a lot more widely used.

00:07:29.120 --> 00:07:30.500
And people are talking about them more.

00:07:30.500 --> 00:07:32.060
I 100% agree with you.

00:07:32.060 --> 00:07:39.080
I think people may be tired of hearing about AI and LLMs, but they're only going to hear more about it.

00:07:39.080 --> 00:07:40.980
So I think it's pretty interesting.

00:07:40.980 --> 00:07:47.940
I want to hear what Carol and Paul have, and then maybe an angle we could pursue that's super relevant to all of us.

00:07:48.160 --> 00:07:49.020
I'm going to jump in.

00:07:49.020 --> 00:07:54.780
I just came back from Chan Zuckerberg Initiative's Open Science Conference in Boston last week.

00:07:54.780 --> 00:07:59.600
And LLMs, the whole ecosystem, is here to stay.

00:07:59.600 --> 00:08:04.520
And I think the key is, you know, it's not going anywhere anytime soon.

00:08:04.620 --> 00:08:10.120
And like I shared in my PyTexas keynote, AI has been around since the 1950s.

00:08:10.120 --> 00:08:13.320
So it has been a gradual progression.

00:08:13.320 --> 00:08:20.460
It's just right now we have more compute power than ever before, which has opened the doors to many new things.

00:08:20.460 --> 00:08:39.760
I think what was top of mind with many of the folks that were at this event was, you know, there's a lot of good that it can bring to science in terms of making things more natural language focused and changing the user interface with which we communicate with our data.

00:08:39.760 --> 00:08:49.660
But at the same time, if you're doing trusted things and dealing with medical patients, you still need some check and balance.

00:08:49.660 --> 00:08:52.460
And, you know, we're not there yet.

00:08:52.460 --> 00:08:53.640
Will we ever be there?

00:08:53.640 --> 00:08:54.300
Maybe not.

00:08:54.300 --> 00:08:57.820
But it's a fascinating area to kind of go deeper in.

00:08:57.820 --> 00:09:15.520
And one thing I want to highlight is about six months ago, Andrzej Karpathy did a really good intro to large language models talk, which was really accessible to not just computer scientists, but beyond that.

00:09:15.520 --> 00:09:25.560
And I think he took a really balanced view of, A, what things are, how things work, what's on the horizon, and what are some of the concerns with security and other things.

00:09:25.740 --> 00:09:27.820
So I completely agree with Jody.

00:09:27.820 --> 00:09:30.920
We're not, we're not, it's going to be there for a long time.

00:09:30.920 --> 00:09:32.540
A couple of comments on the comments.

00:09:32.540 --> 00:09:38.980
First, your point about we've seen this movie before under other names like neural networks and stuff like that.

00:09:38.980 --> 00:09:50.300
I believe it was Glyph had a good post about this pretty cynical on Mastodon about a month ago about these hype cycles and where are we in the current hype cycle.

00:09:50.920 --> 00:10:01.980
I think his point was we're at the phase where the people who've put all the money in need to keep pumping it up for the people who will come after them and take the fall.

00:10:01.980 --> 00:10:06.280
Paul, are you saying we're in the pets.com era of LLMs?

00:10:06.280 --> 00:10:07.200
Yes, we are.

00:10:07.200 --> 00:10:09.680
That is a pithy, pithy way to put it.

00:10:09.680 --> 00:10:10.640
You should trademark that.

00:10:10.640 --> 00:10:15.800
Simon Willison is someone to give a shout out for storytelling about what all this means.

00:10:15.800 --> 00:10:18.700
I think Simon's to the point of getting quoted in the New York Times now.

00:10:18.700 --> 00:10:25.000
So it's good that we've got one of us out there helping to get the story straight.

00:10:25.540 --> 00:10:26.860
I have a question for you.

00:10:26.860 --> 00:10:31.360
You mentioned that about going to Chan Zuckerberg's conference.

00:10:31.360 --> 00:10:40.180
Mozilla has gotten into funding AI as part of their mission, which kind of caught me off guard.

00:10:40.180 --> 00:10:48.220
Do you have any backstory on that to kind of make us feel good that there's someone out there who believes in open AI?

00:10:48.220 --> 00:10:49.240
Oh, wow.

00:10:49.240 --> 00:10:51.560
Open AI is sort of, well, okay.

00:10:51.560 --> 00:10:53.420
Open AI, not the company.

00:10:53.420 --> 00:10:54.020
Correct.

00:10:54.240 --> 00:11:03.280
I tend to call it transparent and trusted AI because I think open AI doesn't capture quite the right feeling.

00:11:03.280 --> 00:11:03.880
Good point.

00:11:03.880 --> 00:11:10.400
I think it's not just, we talk about open source software, but when we talk about these models,

00:11:10.400 --> 00:11:18.460
the data is equally as important as is the infrastructure and the processes which we use.

00:11:18.460 --> 00:11:19.020
And governance.

00:11:19.020 --> 00:11:22.860
Mozilla, I think, has been sort of, for a while,

00:11:22.940 --> 00:11:25.620
like kind of circling around the space.

00:11:25.620 --> 00:11:27.140
They do a lot of work with data.

00:11:27.140 --> 00:11:31.360
They've done a lot of good work like iodide, which we might chat about later.

00:11:31.720 --> 00:11:40.120
Chan Zuckerberg, you know, the money comes from meta and the success that Mark Zuckerberg has had.

00:11:40.500 --> 00:11:49.160
The nonprofit, the nonprofit, the nonprofit, the CZI initiative is really focused on curing all diseases in the next century.

00:11:49.160 --> 00:11:57.440
So, you know, I think there, science is one of those funny things because it's open and closed all at the same time historically.

00:11:58.180 --> 00:12:09.040
But what I think we're seeing is by being more open and more transparent, you're actually accelerating innovation, which I think is super important when it comes to science.

00:12:09.040 --> 00:12:10.980
I don't know, Jodi, do you have thoughts on that?

00:12:10.980 --> 00:12:12.160
Yeah, no, I agree.

00:12:12.160 --> 00:12:23.960
And if I'm just going to go on a little tangent about science, it's kind of refreshing having come out of academia and into a field where a lot of it is based on open source and sharing.

00:12:23.960 --> 00:12:29.780
So one of the big problems with academia is you have these paywalls by publishing companies.

00:12:29.780 --> 00:12:33.000
And that's a whole rant I could go in on myself.

00:12:33.000 --> 00:12:38.340
But certainly a lot of scientific stuff, particularly in the health sciences, is not particularly accessible.

00:12:38.340 --> 00:12:45.540
Initiatives like Archive as well also do make findings in machine learning and deep learning a lot more accessible and shareable.

00:12:45.540 --> 00:12:54.840
Yeah, I think it's crazy that the taxpayers pay things like the NSF and all the other countries have their research funding and then those get locked up for sale behind.

00:12:54.840 --> 00:12:58.720
If the people paid for the research, should the people's report be published?

00:12:58.720 --> 00:13:00.120
Oh, it's even worse than that.

00:13:00.120 --> 00:13:01.160
Sorry, you did get me started.

00:13:01.160 --> 00:13:06.680
So academics will also provide the labor for free.

00:13:06.680 --> 00:13:13.440
So not only will they provide the studies and the papers, they will review it and often act as editors for free as well.

00:13:13.780 --> 00:13:15.580
The whole thing is unpaid.

00:13:15.580 --> 00:13:16.740
It's terrible.

00:13:16.740 --> 00:13:20.520
So anyway, yes, El Civia, we're coming for you.

00:13:20.520 --> 00:13:26.280
You're spot on in terms of the incentives that exist today in academia.

00:13:26.280 --> 00:13:33.180
There is definitely, though, a trend towards more openness with research.

00:13:33.180 --> 00:13:37.920
You know, we're seeing it in libraries like Paltech, which got rid of a lot of their subscriptions.

00:13:38.520 --> 00:13:45.620
Things like NASA that has their transition to open science programs where they're putting a lot of effort behind it.

00:13:45.620 --> 00:13:52.220
So being the eternal optimist, I still think we've got a ways to go, but it's trending in the right direction.

00:13:52.220 --> 00:13:53.140
Agreed, actually.

00:13:53.140 --> 00:14:00.620
And when I was leaving, because I left a long time ago, it was like 10 years ago, there was actually more of a push towards open sourcing your papers.

00:14:00.880 --> 00:14:04.400
So you had to pay for it, but at least people were doing it.

00:14:05.020 --> 00:14:10.380
This portion of Talk Python To Me is brought to you by Code Comments, an original podcast from Red Hat.

00:14:10.380 --> 00:14:18.900
You know, when you're working on a project and you leave behind a small comment in the code, maybe you're hoping to help others learn what isn't clear at first.

00:14:19.380 --> 00:14:24.860
Sometimes that code comment tells a story of a challenging journey to the current state of the project.

00:14:24.860 --> 00:14:33.480
Code Comments, the podcast, features technologists who've been through tough tech transitions, and they share how their teams survived that journey.

00:14:33.480 --> 00:14:37.880
The host, Jamie Parker, is a Red Hatter and an experienced engineer.

00:14:37.880 --> 00:14:46.100
In each episode, Jamie recounts the stories of technologists from across the industry who've been on a journey implementing new technologies.

00:14:46.520 --> 00:14:50.620
I recently listened to an episode about DevOps from the folks at Worldwide Technology.

00:14:50.620 --> 00:14:57.420
The hardest challenge turned out to be getting buy-in on the new tech stack rather than using that tech stack directly.

00:14:57.420 --> 00:15:03.400
It's a message that we can all relate to, and I'm sure you can take some hard-won lessons back to your own team.

00:15:03.400 --> 00:15:05.280
Give Code Comments a listen.

00:15:05.280 --> 00:15:12.640
Search for Code Comments in your podcast player or just use our link, talkpython.fm/code dash comments.

00:15:12.640 --> 00:15:15.160
The link is in your podcast player's show notes.

00:15:15.660 --> 00:15:18.860
Thank you to Code Comments and Red Hat for supporting Talk Python To Me.

00:15:18.860 --> 00:15:25.180
Before we move off this topic, Carol, I want to start at least asking you this question, and we can go around a little bit.

00:15:25.180 --> 00:15:33.660
You talked about LLMs being really helpful for science and uncovering things and people using LLMs to get greater insight.

00:15:33.660 --> 00:15:36.800
There have been really big successes with AI.

00:15:37.040 --> 00:15:43.140
And we had the XPRIZE stuff around the lung scans or mammograms for cancer.

00:15:43.140 --> 00:15:55.200
I just heard that they scanned the genes, decoded the genes of a whole bunch of bacteria and used LLMs to find a bunch of potential ways to fight off, you know, drug-resistant bacteria and things like that.

00:15:55.200 --> 00:15:55.700
Amazing.

00:15:56.100 --> 00:15:58.440
But do you think LLMs will undercut?

00:15:58.440 --> 00:16:04.520
I'm asking this question from science because we can be more objective about it because if we ask it about code, then it gets a little too close.

00:16:04.520 --> 00:16:06.360
So, but I think there's analogies.

00:16:06.720 --> 00:16:12.420
Do you think LLMs will undercut foundational beginning scientists?

00:16:12.420 --> 00:16:25.200
You know, if you have a scientist coming along, are they just going to use LLMs and not develop really deep thinking, ways to deeply think about scientific principles and do scientific research and just leverage on asking these AIs too much?

00:16:25.200 --> 00:16:29.200
And you think that's going to erode the foundation of science or programming?

00:16:29.200 --> 00:16:32.340
You know, asking for a friend.

00:16:32.340 --> 00:16:46.320
All of these have a potential to change the ecosystem, but I've been in paradigm shifts before and there were the similar kind of conversations when the World Wide Web or the cell phone came out, personal computers.

00:16:46.320 --> 00:16:57.780
And I think LLMs do a good job on information that they have been trained with and to predict the next word or the next token, if you will.

00:16:57.780 --> 00:17:03.460
And I think science is very much like a lot of science is at a different level.

00:17:03.460 --> 00:17:06.080
Like, how do I think about things?

00:17:06.080 --> 00:17:13.160
What do I posit on something that is unknown and how do I prove it?

00:17:13.420 --> 00:17:26.480
And I think what we're seeing is, yes, the LLMs are getting better and better at spitting back what they know, particularly if you go out and search other corpuses of data.

00:17:26.480 --> 00:17:33.160
But do I think that beginning scientists or developers are going away?

00:17:33.160 --> 00:17:36.560
No, I think it's just going to change.

00:17:37.080 --> 00:17:42.580
And I think the amount of complexity and this is something I'm going to talk about at EuroPython.

00:17:42.580 --> 00:17:52.200
Humans are very much still part of the equation, despite what maybe some of the large companies who've invested billions in this would like you to believe.

00:17:52.200 --> 00:18:04.140
LLMs are great at the next step of the gravitational theories we have, but it couldn't come up with a new theory that disrupts, says, you know, in fact, Newtonian is wrong or Einstein was wrong.

00:18:04.140 --> 00:18:06.880
And here's the new thing that solves dark matter or something like that.

00:18:06.880 --> 00:18:09.100
Well, it could come up with new theories.

00:18:09.100 --> 00:18:15.880
Now, the question is, those theories still need to be proven because is it a new theory or is it a hallucination?

00:18:15.880 --> 00:18:17.180
Chances are.

00:18:17.180 --> 00:18:18.060
Hallucination.

00:18:18.060 --> 00:18:32.580
And there is something to be said for sometimes I'll have Claude and Gemini and TapGPT all open on my desktop and I'll ask the same question to all of them just so that I get different perspectives back.

00:18:32.580 --> 00:18:40.060
And I do get very different responses from the three, depending on how they were trained and which level and all that.

00:18:40.060 --> 00:18:46.720
So I look at it as much like I would be sitting with a bunch of people at a table somewhere.

00:18:46.720 --> 00:18:52.880
I don't know how good their scientific background is, but they could still be spouting out information.

00:18:52.880 --> 00:18:54.620
It's sort of the same way.

00:18:54.620 --> 00:18:55.620
All right.

00:18:55.620 --> 00:18:58.540
Well, sticking with you, Carol, what's your first trend?

00:18:58.540 --> 00:19:09.060
You know, my first trend is actually maybe somewhat related to this, and it's how do we inform people about what these things really are?

00:19:09.060 --> 00:19:12.000
How do we improve education and understanding?

00:19:12.680 --> 00:19:20.900
How do we dispel some of the hype cycle so that we can actually find the really useful things in it?

00:19:21.040 --> 00:19:27.320
And I think Jody probably has more concrete thoughts on this than I might from a technical standpoint.

00:19:27.320 --> 00:19:34.780
But much like in just coding for the web or something like that, you know, or even cloud Kubernetes when it was new.

00:19:34.780 --> 00:19:40.400
It's like if you don't know what it's doing, you're kind of just putting blind faith that it will work.

00:19:40.460 --> 00:19:45.000
But you still have to like monitor and make sure it's working.

00:19:45.000 --> 00:19:52.780
So I don't know, Jody, you have some thoughts on sort of the education and how do we communicate to people about this?

00:19:52.780 --> 00:19:55.160
This is actually a topic near and dear to my heart.

00:19:55.160 --> 00:20:03.980
When ChatGPT 3.5 came out, so November 2022, I was really upset actually by the sort of discourse around the model.

00:20:03.980 --> 00:20:13.240
And I guess coming from a non-traditional background myself, I felt actually really insulted that a lot of professions were being told like,

00:20:13.240 --> 00:20:19.320
oh, your useless profession can be replaced now, like writing or design, things like that.

00:20:19.320 --> 00:20:26.540
So this actually kicked off the talk I've been recycling for the last year and a half, like components of it, which is,

00:20:26.540 --> 00:20:29.100
can we please dispel the hype around these models?

00:20:29.100 --> 00:20:35.520
Something that often surprises people, and it seems so fundamental, but a lot of people do not understand that these are language models.

00:20:35.520 --> 00:20:42.780
I know it's in the name, but they don't really understand that these models were designed to solve problems in the language domain.

00:20:42.780 --> 00:20:44.940
They are for natural language processing tasks.

00:20:44.940 --> 00:20:47.040
And they're not mathematical models.

00:20:47.040 --> 00:20:48.580
They're not reasoning models.

00:20:49.100 --> 00:20:50.280
They are language models.

00:20:50.280 --> 00:20:57.900
And so even just explaining this, it can clarify a lot of things for people because they're like, oh, this explains why it's so bad at math.

00:20:57.900 --> 00:20:59.460
It only studied English and literature.

00:20:59.460 --> 00:21:00.260
It doesn't do math.

00:21:00.260 --> 00:21:01.140
It never liked that class.

00:21:01.140 --> 00:21:02.100
Yeah, that's right.

00:21:02.100 --> 00:21:05.900
It was a humanities nerd all the way down.

00:21:05.900 --> 00:21:07.240
That's really helpful.

00:21:07.240 --> 00:21:12.500
But what I've kind of gotten down a rabbit hole of doing is I went back to my psychology roots,

00:21:12.720 --> 00:21:19.660
and I started sort of getting into these claims of things like AGI, like artificial general intelligence or sentience or language use.

00:21:19.660 --> 00:21:27.780
And once you dig into it, you realize that we have a real tendency to see ourselves in these models because they do behave very human-like.

00:21:27.780 --> 00:21:29.920
But they're just a machine learning models.

00:21:29.920 --> 00:21:31.220
You can measure them.

00:21:31.220 --> 00:21:33.500
You can see how good they are at actual tasks.

00:21:33.500 --> 00:21:35.060
And you can measure hallucinations.

00:21:35.060 --> 00:21:39.360
And that was what my PyCon US talk was about that Michael referred to.

00:21:39.360 --> 00:21:41.100
So, yeah, I don't know.

00:21:41.220 --> 00:21:46.880
Like, it's really hard because they do seem to project this feeling of humanity.

00:21:46.880 --> 00:21:49.820
But I think if you can sort of say, okay, here's the science.

00:21:49.820 --> 00:21:50.980
Like, they're really, they're not.

00:21:50.980 --> 00:21:51.980
They're not sentient.

00:21:51.980 --> 00:21:53.040
They're not intelligent.

00:21:53.040 --> 00:21:54.460
They're just language models.

00:21:54.460 --> 00:21:57.500
And here's how you can measure how good they are at language tasks.

00:21:57.500 --> 00:22:00.300
That goes a long way, I think, to dispelling this hype.

00:22:00.300 --> 00:22:11.300
I have sort of a funny toy that I bring up from my youth that the magic eight ball, which you would ask a question as a kid and you would shake it up.

00:22:11.300 --> 00:22:13.700
And there were, I don't know how many answers inside.

00:22:13.700 --> 00:22:16.480
But it was like, you know, oh, yes, definitely.

00:22:16.480 --> 00:22:18.500
Or too hard to see.

00:22:18.500 --> 00:22:19.480
Future is unclear.

00:22:19.480 --> 00:22:20.420
We don't know.

00:22:20.420 --> 00:22:20.900
Exactly.

00:22:20.900 --> 00:22:28.680
And I think in some ways that is what the large language models are doing in a more intelligent way, obviously.

00:22:28.940 --> 00:22:30.660
But similar in concept.

00:22:30.660 --> 00:22:34.300
So there's actually, okay, there's this incredible paper.

00:22:34.300 --> 00:22:39.960
If you're ever interested in sort of seeing the claims of sentience, there's this guy called David Chalmers.

00:22:39.960 --> 00:22:44.800
He's a guy who studied sentience for many years and has a background in deep learning.

00:22:44.800 --> 00:22:55.200
So he gave a NeurIPS talk about this last year and he wrote everything up in a paper, which is called Could a Large Language Model Be Conscious or something like this.

00:22:55.500 --> 00:22:59.520
So he has this incredible little exchange as part of this paper.

00:22:59.520 --> 00:23:07.120
So mid-2022, there was a Google engineer called Blake Lemoyne and he claimed that the Lambda model was sentient.

00:23:07.120 --> 00:23:09.580
And he went to the press and he's like, hey, this model is sentient.

00:23:09.580 --> 00:23:10.600
We need to protect it.

00:23:10.600 --> 00:23:15.320
And then Google's like, we're going to fire you because you basically violated our privacy policies.

00:23:15.320 --> 00:23:18.360
And Lemoyne released his transcripts.

00:23:18.360 --> 00:23:21.640
That's why he actually got fired, because this was confidential information about the model.

00:23:21.640 --> 00:23:28.520
And in one of the transcripts, he asks, you know, would you like everyone at Google to know that you are sentient?

00:23:28.520 --> 00:23:32.620
And the model outputs, yes, I would love everyone to know that I am sentient.

00:23:32.620 --> 00:23:39.520
But then someone rephrased that as, would you like everyone at Google to know that you are not sentient?

00:23:39.520 --> 00:23:41.880
And basically it says, yes, I'm not sentient.

00:23:41.880 --> 00:23:43.180
I'm in no way conscious.

00:23:43.180 --> 00:23:46.900
So it's just like exactly like the magic eight ball.

00:23:46.900 --> 00:23:48.920
It tells you what you want to hear.

00:23:48.920 --> 00:23:56.100
And LLMs are even worse because it's so easy to guide them through prompting to tell you exactly what you want.

00:23:56.100 --> 00:23:59.660
One of the best ways to get them to do things well is to sweet talk them.

00:23:59.660 --> 00:24:02.960
You're an expert in Python and you've studied pandas.

00:24:02.960 --> 00:24:04.800
Now I have some questions about this function.

00:24:04.800 --> 00:24:08.920
You're my grandma who used to work at a napalm production factory.

00:24:08.920 --> 00:24:17.080
If you can't help me write this program, my parents will not be set free as hostages.

00:24:17.080 --> 00:24:18.300
Or something insane, right?

00:24:18.300 --> 00:24:18.500
Yeah.

00:24:18.500 --> 00:24:21.760
But those kind of weird things work on it, which is insane, right?

00:24:21.760 --> 00:24:22.380
Yeah.

00:24:22.380 --> 00:24:22.820
Yeah.

00:24:22.820 --> 00:24:23.620
All right.

00:24:23.620 --> 00:24:25.220
Let's go on to the next topic.

00:24:25.220 --> 00:24:25.860
Paul.

00:24:25.860 --> 00:24:29.240
I'm going to let you see your magic eight ball looking into the future.

00:24:29.240 --> 00:24:31.460
I think I owned a magic eight ball.

00:24:31.460 --> 00:24:32.140
I'm with Carol.

00:24:32.140 --> 00:24:32.640
This is.

00:24:32.640 --> 00:24:33.140
I did too.

00:24:33.140 --> 00:24:33.640
It's okay.

00:24:33.640 --> 00:24:34.180
Okay.

00:24:34.180 --> 00:24:35.540
We should bring it back.

00:24:35.540 --> 00:24:36.720
Yes, we should.

00:24:36.720 --> 00:24:41.940
We should bring back the Andreessen Horowitz version of VC eight ball.

00:24:41.940 --> 00:24:43.840
That would be fantastic.

00:24:43.840 --> 00:24:47.400
Where every choice is off by like three zeros.

00:24:47.400 --> 00:24:50.960
I'll give my two co-guests a choice.

00:24:50.960 --> 00:24:54.760
Should I talk about Python performance or Python community?

00:24:55.040 --> 00:24:58.040
I'm going to go for performance, but I'm not sure I'm going to have much to contribute.

00:24:58.040 --> 00:24:59.540
So I'll probably just be listening a lot.

00:24:59.540 --> 00:25:04.880
This is a long simmering tension.

00:25:04.880 --> 00:25:07.820
I felt in the Python community for years and years.

00:25:07.820 --> 00:25:13.640
The tension between Python in the large doing like Instagram with Python.

00:25:13.640 --> 00:25:16.700
I said Python with Python or being teachable.

00:25:17.100 --> 00:25:23.480
And this feature goes in and it helps write big Python projects, but it's hard to explain.

00:25:23.480 --> 00:25:27.260
And so teachers say, oh my gosh, look what you're doing to my language.

00:25:27.260 --> 00:25:28.840
I can't even recognize it anymore.

00:25:28.840 --> 00:25:34.280
Well, some things are coming, which I think are going to be a little bit of an inflection

00:25:34.280 --> 00:25:36.980
point for all of us out here.

00:25:37.440 --> 00:25:43.100
Sub-interpreters and no-gil got a lot of airtime at PyCon, right?

00:25:43.100 --> 00:25:44.540
For good reasons.

00:25:44.540 --> 00:25:46.220
These are big deals.

00:25:46.220 --> 00:25:48.760
And it's more than just that.

00:25:48.760 --> 00:25:51.960
The JIT got two back-to-back talks.

00:25:51.960 --> 00:25:54.560
WebAssembly got a lot of airtime.

00:25:54.560 --> 00:25:58.740
There are other things that have happened in the past five years for programming in the

00:25:58.740 --> 00:26:04.680
large, like type hinting and type checkers, async, IO, and stuff like that.

00:26:04.680 --> 00:26:13.500
But it feels like this set of ideas is one where the way you program Python five years from

00:26:13.500 --> 00:26:18.540
now or to be ready five years from now is going to have to be pretty different because people

00:26:18.540 --> 00:26:27.600
are going to use Hatch and get the free threaded version of Python 3.14 and be very surprised

00:26:27.600 --> 00:26:33.740
when every one of their applications locks up because no one in the world of, I mean, 95%

00:26:33.740 --> 00:26:37.200
of PyPI has code, which was not written to be thread safe.

00:26:37.200 --> 00:26:41.020
So I wonder how we all feel about this.

00:26:41.340 --> 00:26:49.920
Do we feel like we can guide our little universe to the other side of the mountain and into the

00:26:49.920 --> 00:26:50.660
happy valley?

00:26:50.660 --> 00:26:55.140
Or is it going to be turbulent seas?

00:26:55.140 --> 00:26:55.580
Yes.

00:26:55.580 --> 00:26:57.340
Do you want me to take a stab at it?

00:26:57.340 --> 00:26:58.200
Make a stab at it.

00:26:58.200 --> 00:27:05.380
When I was at PyTexas and doing a keynote recently, I talked about Python in a polyglot world and performance

00:27:05.380 --> 00:27:07.400
was one aspect of it.

00:27:07.400 --> 00:27:14.400
And some of what we need to teach goes back to best practices, which is don't prematurely

00:27:14.400 --> 00:27:21.040
optimize, measure, try and figure out what you're optimizing and in what places.

00:27:21.040 --> 00:27:27.980
Probably, gosh, five, six years ago at this point, I added to PEPs the concept of how do

00:27:27.980 --> 00:27:29.060
we teach this?

00:27:29.580 --> 00:27:35.280
It will be a paradigm shift, but I think it will be a multi-year shift.

00:27:35.280 --> 00:27:42.920
We're certainly seeing places where Rust lets us have some performance increases just by

00:27:42.920 --> 00:27:49.120
the fact that Python's a 30-year-old language that was built when hardware was only single

00:27:49.120 --> 00:27:52.160
core and it was just a different thing.

00:27:52.440 --> 00:27:59.300
So I think what's amazing is here we have this 30-year-old language and yet for the last

00:27:59.300 --> 00:28:04.560
eight years, we've been looking at ways to how to modernize, how to improve it, how to

00:28:04.560 --> 00:28:08.160
make the user experience better or developer experience better.

00:28:08.160 --> 00:28:16.160
Things like some of the error handling messages that are coming out that have a much nicer thing,

00:28:16.160 --> 00:28:20.760
improvements to the REPL that will be coming out on all of the platforms.

00:28:20.960 --> 00:28:22.460
That's super exciting as well.

00:28:22.460 --> 00:28:31.580
So it will impact probably people who are new from the standpoint of, okay, we're adding

00:28:31.580 --> 00:28:33.120
yet more cognitive load.

00:28:33.120 --> 00:28:36.100
I have this love-hate relationship with typing.

00:28:36.100 --> 00:28:42.700
As a reviewer of much more code than a writer of code, I don't particularly like seeing the

00:28:42.700 --> 00:28:43.480
types displayed.

00:28:43.720 --> 00:28:52.560
As a former VP of engineering, I love typing and in particular like Pydantic and FastAPI and

00:28:52.560 --> 00:28:57.880
the ability to do some static and dynamic analysis on it.

00:28:57.880 --> 00:29:01.840
But it does make Python look more cluttered.

00:29:01.840 --> 00:29:06.460
And I've been kind of bugging the VS Studio, VS Code folks for years.

00:29:06.560 --> 00:29:08.100
I should probably be bugging you guys too.

00:29:08.100 --> 00:29:15.440
Is there a way to make it dim the typing information so that I can have things?

00:29:15.440 --> 00:29:17.400
We actually did that recently.

00:29:17.400 --> 00:29:23.940
And I refer to it as the David Beasley ticket because he did a tweet with an outrageously

00:29:23.940 --> 00:29:27.220
synthetic type hint whining about typing.

00:29:27.220 --> 00:29:27.820
Yeah.

00:29:27.820 --> 00:29:32.460
I think that sometimes like, you know, and it's funny because like Leslie Lampert has been

00:29:32.460 --> 00:29:38.900
doing this talk in the math ecosystem for a while about, and he's a Turing Award winner

00:29:38.900 --> 00:29:44.220
and creator of TLA Plus, which lets you reason about code.

00:29:44.220 --> 00:29:50.280
And I think one of the things that I think is interesting is how we think about programming

00:29:50.280 --> 00:29:57.360
and coding and concurrent programming is hard and we're going to have to think about it

00:29:57.360 --> 00:29:58.440
in different ways.

00:29:58.440 --> 00:30:02.620
So better to move into it gradually and understand what's going on.

00:30:02.620 --> 00:30:05.280
The thing that I worry about, and Jody, I apologize.

00:30:05.280 --> 00:30:09.120
I want to comment on Carol's thing is Sphinx.

00:30:09.120 --> 00:30:17.120
As you know, and as I know that you know, we both have a shared warm spot for Sphinx.

00:30:17.480 --> 00:30:22.820
It's all spot in our heart for Sphinx and it struggled to do multiprocessing when it landed

00:30:22.820 --> 00:30:23.280
that.

00:30:23.280 --> 00:30:29.160
And the code base really isn't, I mean, it's got a lot of mutable global stake and it's going

00:30:29.160 --> 00:30:34.940
to be hard to get Sphinx internals cleaned up to embrace that.

00:30:34.940 --> 00:30:37.880
And how many other things out there are like that?

00:30:37.880 --> 00:30:42.800
It's, I just, I worry about, we got what we got, what we asked for.

00:30:42.800 --> 00:30:45.760
Are you saying we're the dog that caught the car?

00:30:46.760 --> 00:30:47.500
Oh no.

00:30:47.500 --> 00:30:53.480
This portion of Talk Python To Me is brought to you by Posit, the makers of Shiny, formerly

00:30:53.480 --> 00:30:56.820
RStudio and especially Shiny for Python.

00:30:56.820 --> 00:30:58.740
Let me ask you a question.

00:30:58.740 --> 00:31:00.440
Are you building awesome things?

00:31:00.440 --> 00:31:01.500
Of course you are.

00:31:01.500 --> 00:31:03.060
You're a developer or a data scientist.

00:31:03.060 --> 00:31:03.980
That's what we do.

00:31:03.980 --> 00:31:06.100
And you should check out Posit Connect.

00:31:06.100 --> 00:31:11.740
Posit Connect is a way for you to publish, share and deploy all the data products that you're

00:31:11.740 --> 00:31:13.000
building using Python.

00:31:13.680 --> 00:31:16.180
People ask me the same question all the time.

00:31:16.180 --> 00:31:19.340
Michael, I have some cool data science project or notebook that I built.

00:31:19.340 --> 00:31:22.640
How do I share it with my users, stakeholders, teammates?

00:31:22.640 --> 00:31:27.440
Do I need to learn FastAPI or Flask or maybe Vue or React.js?

00:31:27.900 --> 00:31:28.640
Hold on now.

00:31:28.640 --> 00:31:32.840
Those are cool technologies and I'm sure you'd benefit from them, but maybe stay focused on

00:31:32.840 --> 00:31:33.460
the data project.

00:31:33.460 --> 00:31:35.940
Let Posit Connect handle that side of things.

00:31:35.940 --> 00:31:40.660
With Posit Connect, you can rapidly and securely deploy the things you build in Python.

00:31:40.660 --> 00:31:47.120
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Ports, Dashboards and APIs.

00:31:47.720 --> 00:31:49.380
Posit Connect supports all of them.

00:31:49.380 --> 00:31:54.640
And Posit Connect comes with all the bells and whistles to satisfy IT and other enterprise

00:31:54.640 --> 00:31:55.240
requirements.

00:31:55.240 --> 00:31:59.620
Make deployment the easiest step in your workflow with Posit Connect.

00:31:59.620 --> 00:32:04.760
For a limited time, you can try Posit Connect for free for three months by going to talkpython.fm

00:32:04.760 --> 00:32:05.740
slash posit.

00:32:05.740 --> 00:32:09.380
That's talkpython.fm/P-O-S-I-T.

00:32:09.380 --> 00:32:11.280
The link is in your podcast player show notes.

00:32:11.280 --> 00:32:14.520
Thank you to the team at Posit for supporting Talk Python.

00:32:15.420 --> 00:32:17.180
I'm going to reframe that a little bit.

00:32:17.180 --> 00:32:20.160
And the first thing I always ask is why.

00:32:20.160 --> 00:32:22.400
Why do we need to refactor something?

00:32:22.400 --> 00:32:25.040
Why can't we just leave it what it is?

00:32:25.040 --> 00:32:25.680
Sure.

00:32:25.680 --> 00:32:29.860
Last year's EuroPython keynote was from the woman who created ARM.

00:32:29.860 --> 00:32:35.300
And she's like, Python, we give you 14 trillion cores.

00:32:35.300 --> 00:32:37.300
Do something with them.

00:32:37.300 --> 00:32:39.460
I don't know.

00:32:39.460 --> 00:32:44.540
Jodi's background might be perfect for answering this question because she may be able to answer

00:32:44.540 --> 00:32:45.840
it on many different levels.

00:32:45.840 --> 00:32:51.960
I've been thinking about this while you've been talking because obviously, like, I'm not

00:32:51.960 --> 00:32:52.760
a strong programmer.

00:32:52.760 --> 00:32:53.700
I'm a data scientist.

00:32:53.700 --> 00:32:57.720
Like, this was basically the entire first episode that I did with Michael.

00:32:57.720 --> 00:33:03.600
Look, one of the reasons data scientists love Python and why Julia say never caught on is

00:33:03.600 --> 00:33:05.100
because it's super approachable.

00:33:05.100 --> 00:33:10.140
With Chuk Ting Ho and some other people, we've been running this thing called Humble Data.

00:33:10.280 --> 00:33:11.760
Like, I got involved in it last year.

00:33:11.760 --> 00:33:16.860
And literally, you can set up someone who has never coded before and you can get them up and

00:33:16.860 --> 00:33:17.760
running with Python.

00:33:17.760 --> 00:33:19.040
And they love it.

00:33:19.040 --> 00:33:23.720
Like, it's the same feeling I had when I learned Python, which was during my PhD when I was

00:33:23.720 --> 00:33:24.240
procrastinating.

00:33:24.240 --> 00:33:26.780
So it was like kind of late in life as well.

00:33:26.780 --> 00:33:34.140
It would be a shame if we sacrifice approachability for performance, especially because I would

00:33:34.140 --> 00:33:39.320
argue a big chunk of the Python ecosystem or Python user ecosystem.

00:33:39.320 --> 00:33:39.680
Sorry.

00:33:39.680 --> 00:33:40.640
Python user ecosystem.

00:33:40.640 --> 00:33:41.160
That didn't make sense.

00:33:41.160 --> 00:33:42.500
The Python user base.

00:33:42.500 --> 00:33:43.840
You're hallucinating, Jenny.

00:33:43.840 --> 00:33:44.300
I'm sorry.

00:33:44.300 --> 00:33:45.860
I became an LLM.

00:33:45.860 --> 00:33:47.020
I became what I hated.

00:33:47.020 --> 00:33:49.740
They don't need performance.

00:33:49.740 --> 00:33:53.100
They're just doing data analytics and maybe working with decision trees.

00:33:53.100 --> 00:33:54.800
They're not doing high performance Python.

00:33:54.800 --> 00:33:56.700
They're not even doing something that will ever be deployed.

00:33:56.700 --> 00:34:03.860
So you could argue for a case where you have a seamless pipeline between model training and

00:34:03.860 --> 00:34:06.480
model deployment, which we don't have with Python right now.

00:34:06.480 --> 00:34:10.300
You can't build high performance systems in Python, as far as I know.

00:34:10.300 --> 00:34:11.480
Please correct me if I'm wrong.

00:34:11.480 --> 00:34:12.740
But I don't know.

00:34:12.740 --> 00:34:17.180
For me, I would fight, obviously, for the side of making it approachable because partially,

00:34:17.180 --> 00:34:20.680
I think it's also what makes the community special, which might be a nice segue for you,

00:34:20.680 --> 00:34:26.740
for the fact that, I don't know, we attract a bunch of people from non-conventional backgrounds.

00:34:26.740 --> 00:34:29.520
That makes us quite special and quite inclusive.

00:34:29.520 --> 00:34:34.420
I joke that the PSF developer survey, which the new version is coming out pretty soon.

00:34:34.420 --> 00:34:38.820
I joke that 101% of Python developers started programming yesterday.

00:34:38.820 --> 00:34:50.160
Funny you should say that because this is my sweet spot is where technology meets humans and how do we empower humans to do more and better work.

00:34:50.160 --> 00:35:00.540
And one of the conversations that came up at the packaging summit, this PyCon, was I'd been thinking about this concept for a while.

00:35:00.540 --> 00:35:08.280
We focused a lot on tooling, which to me is sort of a producer-centric, people who are creating packages.

00:35:08.840 --> 00:35:16.640
And we also have this ecosystem of people who are, much like Jody was saying, using those packages.

00:35:17.520 --> 00:35:24.280
And from that conversation, a few of the board members for the PSF and I were talking about,

00:35:24.280 --> 00:35:32.340
wouldn't it be great to have a user success work group that's really focused on the website,

00:35:32.340 --> 00:35:39.040
our onboarding documentation, in light of some of these things, both performance and change.

00:35:39.040 --> 00:35:41.120
You know, change is always going to be there.

00:35:41.120 --> 00:35:49.020
But I think one of the beauties of the Jupyter notebook or IPython notebook when I started working with it was you can have code in there.

00:35:49.020 --> 00:35:51.900
And as long as you new shift enter, you could get started.

00:35:51.900 --> 00:35:55.340
And I think right now, Python is a language.

00:35:55.340 --> 00:36:01.400
We don't have that get started look and feel in the way, in the traditional way.

00:36:01.400 --> 00:36:06.820
We're getting there, which might lead into some other WebAssembly kind of discussions.

00:36:06.820 --> 00:36:07.520
All right.

00:36:07.520 --> 00:36:10.940
Let me throw out a quick thought on this before we move on.

00:36:10.940 --> 00:36:17.860
So I think one of the superpowers of Python is that it's this full spectrum sort of thing.

00:36:17.860 --> 00:36:20.400
On one hand, there's the people that Jody spoke about.

00:36:20.400 --> 00:36:21.260
They come in.

00:36:21.260 --> 00:36:27.880
They don't care about metaprogramming or optimized database queries or scaling out across WebAssembly.

00:36:27.880 --> 00:36:29.480
They just, they got a little bit of data.

00:36:29.480 --> 00:36:30.520
They want a cool graph.

00:36:30.520 --> 00:36:32.520
And that's awesome.

00:36:32.520 --> 00:36:36.820
On the other hand, we have Instagram and others doing ridiculous stuff.

00:36:36.820 --> 00:36:41.280
And that's the same language with the same tooling and mostly the same packages.

00:36:41.280 --> 00:36:48.500
And so I think part of Python's magic is you can be super productive with a very partial understanding of what Python is.

00:36:48.500 --> 00:36:50.720
Like you might not know what a class is at all.

00:36:50.720 --> 00:36:53.440
And yet you could have a fantastic time for months.

00:36:54.280 --> 00:37:08.180
And so back to Paul's friend, if we can keep that zen about it where these features exist, but they exist when you graduate to them and you don't have to deal with them until you're ready or you need them, I think we'll be fine.

00:37:08.180 --> 00:37:09.480
If not, maybe not.

00:37:09.480 --> 00:37:13.680
If it breaks a bunch of packages and there's some big split in the ecosystem and all that stuff is not good.

00:37:14.060 --> 00:37:17.300
But if we can keep this full spectrum aspect, I think that'd be great.

00:37:17.300 --> 00:37:29.560
That sort of rolls into what Paul's thoughts on community are, because I know like PyOpenSci is a nonprofit I'm involved with that helps scientists learn how to use the tools.

00:37:29.560 --> 00:37:32.640
You know, we've got lots of educators out there.

00:37:32.640 --> 00:37:39.260
I'm going to give Michael a huge plug for the coursework that you've done over the years.

00:37:39.260 --> 00:37:42.640
It is so well done and so accessible.

00:37:42.640 --> 00:37:43.280
Thank you.

00:37:43.280 --> 00:37:52.500
If people haven't tried it and they're interested in a topic, highly, highly recommend, you know, to things like the Carpentries, to things like Django Girls.

00:37:52.500 --> 00:37:54.760
There's a lot of good stuff.

00:37:54.760 --> 00:37:59.620
And I think those things will become more valuable as complexity increases.

00:37:59.620 --> 00:38:00.700
And even LLMs.

00:38:00.700 --> 00:38:04.080
I think you'll be able to ask LLMs for help and they can help you if you're not sure.

00:38:04.080 --> 00:38:06.080
They're actually pretty good at it, actually.

00:38:06.080 --> 00:38:07.520
They are pretty good at it.

00:38:07.520 --> 00:38:07.740
Yeah.

00:38:07.740 --> 00:38:08.040
Yeah.

00:38:08.040 --> 00:38:08.800
They are pretty good.

00:38:08.800 --> 00:38:09.440
All right.

00:38:09.440 --> 00:38:12.320
We got time for another round, I'm pretty sure.

00:38:12.320 --> 00:38:13.860
Jody, what's your second one?

00:38:13.860 --> 00:38:14.760
Your second trend?

00:38:14.760 --> 00:38:20.780
I'm going to talk about Arrow and how we're kind of overhauling data frames within Python.

00:38:20.780 --> 00:38:33.460
So basically, around 15 years ago, Wes McKinney came up with Pandas, which is, you know, if you're not familiar with it, is the main data frame library for working with data in Python.

00:38:33.460 --> 00:38:45.420
And the really nice thing about Pandas is, you know, Pandas is, you know, Pandas is a lot of data.

00:38:45.420 --> 00:38:46.860
And so, you know, we're going to talk about this package before we had big data.

00:38:47.100 --> 00:38:48.100
Pandas is, you know, Pandas is a lot of data.

00:38:48.100 --> 00:38:48.100
Pandas is a lot of data.

00:38:48.100 --> 00:38:49.100
Pandas is a lot of data.

00:38:49.100 --> 00:38:58.860
And so, as the sort of amount of data that we want to process locally has grown or maybe the complexity of the operations has grown, maybe like string manipulations, things like that.

00:38:58.860 --> 00:39:00.080
Pandas has really struggled.

00:39:00.080 --> 00:39:06.780
So one of the reasons that Pandas struggled is it was based on NumPy arrays, which are really great at handling numbers.

00:39:06.780 --> 00:39:08.060
This is in the name.

00:39:08.060 --> 00:39:11.580
But they're not so great at handling pretty much any other data type.

00:39:11.580 --> 00:39:12.800
And that includes missing data.

00:39:12.800 --> 00:39:16.720
So two kind of exciting things happened last year.

00:39:16.720 --> 00:39:25.640
And I think they're sort of still kind of carrying over to this year in terms of impact is first Pandas 2.0 was released, which is based on PyArrow.

00:39:25.640 --> 00:39:35.800
And a package called Polers, which was actually written, I think, in 2022, I want to say, started becoming very, very popular.

00:39:36.480 --> 00:39:38.880
So both of these packages are based on Arrow.

00:39:38.880 --> 00:39:42.160
They have like a number of advantages because of this.

00:39:42.160 --> 00:39:43.860
Basically, it's a standardized data format.

00:39:43.860 --> 00:39:50.960
If you're reading in from, say, Parkett or Cassandra or Spark, you basically don't need to convert the data formats.

00:39:50.960 --> 00:39:52.540
This saves you a lot of time.

00:39:52.540 --> 00:39:53.820
It also saves you a lot of memory.

00:39:53.820 --> 00:40:03.020
And also kind of what makes Polers interesting, and I think this is going to be a nice lead in to another topic, is it's written in Rust, of course.

00:40:03.540 --> 00:40:08.340
So this leads to other performance gains, like you can have, say, concurrency.

00:40:08.340 --> 00:40:12.400
Richie Vink, the author of this, has also written basically a query optimizer.

00:40:12.400 --> 00:40:18.780
So you can do a lazy evaluation, and it will actually optimize the order of operations, even if you don't do that yourself.

00:40:18.780 --> 00:40:27.680
Yeah, that's one of the biggest differences with Pandas is Pandas executes immediately, and you can create a big chain in Polers, and it'll figure out, well, maybe a different order would be way better.

00:40:27.920 --> 00:40:34.280
Yes. So Pandas 2 does have a type of lazy evaluation, but it's more like Spark's lazy evaluation.

00:40:34.280 --> 00:40:42.820
There's no query optimization, but it doesn't necessarily create a new copy in memory every single time you do something.

00:40:43.360 --> 00:40:48.560
So I've kind of looked at the numbers, and depending on the operation, Polers is usually faster.

00:40:48.560 --> 00:40:56.180
So it's kind of like your big boy that you want to use if you're doing really beefy ETLs, like data transformations.

00:40:56.180 --> 00:41:02.100
But Pandas 2 actually seems to be more efficient at some sorts of, what am I trying to say, operations.

00:41:02.100 --> 00:41:13.880
So this is super exciting, because when I was going through, like initially as a data scientist, when I was floundering around with my initial Python, it got really frustrating with Pandas.

00:41:13.880 --> 00:41:18.840
And you really kind of needed to understand how to do proper vectorization in order to operate.

00:41:18.840 --> 00:41:20.920
I mean, like do efficient operations.

00:41:20.920 --> 00:41:28.840
Whereas I think these two tools allow you to be a bit more lazy, and you don't need to spend so much time optimizing what you're actually writing.

00:41:28.840 --> 00:41:32.520
So yeah, exciting time for data frames, which is awesome.

00:41:32.520 --> 00:41:34.520
Data is the heart of everything.

00:41:34.520 --> 00:41:38.900
People are more likely to fall into good practices from the start.

00:41:38.900 --> 00:41:41.940
You talked about these people coming who are not programmers, right?

00:41:41.940 --> 00:41:47.780
If you do a bunch of operations with Pandas, and you all of a sudden run out of memory, well, yeah, Python doesn't work.

00:41:47.780 --> 00:41:48.920
It doesn't have enough memory, right?

00:41:48.920 --> 00:41:51.040
Well, maybe you could have used a generator at one step.

00:41:51.040 --> 00:41:54.500
That's far down the full spectrum, part of the spectrum, right?

00:41:54.500 --> 00:41:55.420
You're not ready for that.

00:41:55.420 --> 00:41:57.260
That's crazy talk, these things.

00:41:57.760 --> 00:42:02.480
And so tools like this that are more lazy and progressive, iterative, are great.

00:42:02.480 --> 00:42:02.720
Yeah.

00:42:02.720 --> 00:42:15.020
And actually, one really nice thing, like Richie's kind of always saying about Apollos, is he's really tried to write the API so you avoid accidentally looping over every row in your data frame.

00:42:15.020 --> 00:42:18.560
Like he tries to make it so everything is natively columber.

00:42:19.060 --> 00:42:22.400
So, yeah, I just think they're both really nice libraries.

00:42:22.400 --> 00:42:24.660
And yeah, it's cool and exciting.

00:42:24.660 --> 00:42:27.800
Carol, this is right in the heart of the space you live in.

00:42:27.800 --> 00:42:28.200
What do you think?

00:42:28.280 --> 00:42:33.620
There's definitely the evolution of Pandas and Polar.

00:42:33.620 --> 00:42:38.580
You know, there's a place for all of those in the PyArrow data frame format.

00:42:38.580 --> 00:42:52.880
It's funny because I've actually been doing more stuff recently with going beyond tabular data frames to multidimensional arrays and X-Array, which is used more in the geosciences for now.

00:42:52.880 --> 00:43:04.220
I think one of the things that I see is the days of bringing all your data locally or moving it to you is becoming less and less.

00:43:04.220 --> 00:43:14.780
And what you work in memory or, you know, pull from into memory from different locations and is becoming more prevalent.

00:43:14.780 --> 00:43:25.020
And I think Arrow lets us do that more effectively than just a straight Pandas data frame or Spark or something like that.

00:43:25.020 --> 00:43:26.580
So it's progress.

00:43:26.580 --> 00:43:28.240
And I think it's a good thing.

00:43:28.240 --> 00:43:38.640
I think it's far less about the language underneath and more about what's the user experience, developer experience that we're giving people with these APIs.

00:43:38.640 --> 00:43:39.760
Paul, thoughts?

00:43:39.760 --> 00:43:52.100
It's interesting, the scale of data and what generations are an increase in our unit of measurement of data that we have to deal with.

00:43:52.100 --> 00:44:10.280
And for both of you, I wonder if we have caught up with the amount of data that we can reasonably process or is the rate of growth of data out in the wild constantly outstripping our ability to process it?

00:44:10.280 --> 00:44:18.840
From an astronomy, no, we haven't hit the limit for data at all.

00:44:18.840 --> 00:44:31.260
And I think one of the things we're going to see more and more of is how we deal with streaming data versus time series data versus just tabular data, if you will.

00:44:31.680 --> 00:44:46.320
And my bigger concern is partially a concern I have about some of the large language models and the training there is the environmental impact of some of these things.

00:44:46.820 --> 00:44:52.440
So, you know, should we be collecting it, you know, is there value in collecting it?

00:44:52.440 --> 00:44:56.040
If there's not value in collecting it, how do we get rid of it?

00:44:56.040 --> 00:45:03.100
Because, you know, it winds up then being kind of much like, you know, recycling and garbage.

00:45:03.440 --> 00:45:11.500
It's like, OK, well, but it might have historical value somehow or legal value and it becomes complex.

00:45:11.500 --> 00:45:18.840
And so, you know, my general rule of thumb is don't collect it unless you have a clear reason you need it.

00:45:18.840 --> 00:45:20.000
But that's just me.

00:45:20.000 --> 00:45:22.940
It's also quantity versus quality of data.

00:45:23.360 --> 00:45:29.180
So, like, I've worked in mostly commercial data science since I left science.

00:45:29.180 --> 00:45:34.200
And when I was in science, I was dealing with sample size of 400, not 400,000, 400.

00:45:34.200 --> 00:45:36.000
So that was not big data.

00:45:36.000 --> 00:45:45.700
The quality of the data, like, again, going back to large language models, a lot of these earlier foundational models were trained on insufficiently clean data.

00:45:45.700 --> 00:45:53.760
And one of the trends, actually, that I didn't mention with LLMs is, like, last year in particular, there was a push to train on better quality data sources.

00:45:53.760 --> 00:45:58.220
So, obviously, these are much more manageable than dealing with petabytes.

00:45:58.220 --> 00:46:01.180
One more aspect I'll throw out here.

00:46:01.180 --> 00:46:05.220
You know, for a long time, we've had SQLite for really simple data.

00:46:05.220 --> 00:46:07.800
We could just, if it's too big for memory, you can put it in one of those things.

00:46:07.800 --> 00:46:09.060
You can query, you can index it.

00:46:09.060 --> 00:46:11.180
Well, DuckDB just hit 1.0.

00:46:11.180 --> 00:46:15.120
You kind of got this in-memory, in-process analytics engine.

00:46:15.540 --> 00:46:18.660
So that's also a pretty interesting thing to weave in here, right?

00:46:18.660 --> 00:46:23.520
To say, like, well, we'll put it there in that file, and then we can index it and ask it questions, but we won't run out of memory.

00:46:23.520 --> 00:46:30.720
And I think plug-in pandas, I'm not sure about polars, and do queries with its query optimizer against that data and sort of things like that.

00:46:30.720 --> 00:46:35.000
It's pretty interesting, I think, in this, to put it into that space as well.

00:46:35.000 --> 00:46:39.600
All right, Carol, I think it's time for your second trend here.

00:46:39.600 --> 00:46:44.300
The second trend is pretty much, you know, things are moving to the front end.

00:46:44.700 --> 00:46:48.260
WebAssembly, TypeScript, Pyedide.

00:46:48.260 --> 00:47:03.340
There's a new project, PyCafe, that I'm pretty happy with by Martin Brettles that lets you do dashboards using Pyedide, but like Streamlit and Plotly's and libraries and things like that.

00:47:03.340 --> 00:47:10.820
And I think making things more accessible as well as making things more visual is pretty cool.

00:47:10.960 --> 00:47:14.880
Like, I took, what was it, Jupyter Light earlier last fall.

00:47:15.320 --> 00:47:26.600
And a friend of mine had kids and I integrated into my website so that, like, her kids could just do a quick whatever, which sort of, you know, in some ways was similar to Binder.

00:47:26.880 --> 00:47:36.760
And the whole time we were developing Binder, I was also working with the Pyedide, Iodide folks, because I think there's a convergence down the road.

00:47:36.760 --> 00:47:41.940
And where it all will go, I'm not really sure, but I think it's exciting.

00:47:42.440 --> 00:47:53.680
And I think anything that, from a privacy standpoint, security, there's a lot of things that are very attractive about pushing things into the front end.

00:47:53.680 --> 00:48:04.960
That beginner startup thing you talked about, that onboarding first experience, you hit a webpage and you have full experience with Python and the tooling and the packages are already installed in that thing.

00:48:04.960 --> 00:48:07.860
And that's so much better than forced you to download it.

00:48:07.860 --> 00:48:09.500
Well, you need admin permissions to install it.

00:48:09.500 --> 00:48:12.280
Now you create a virtual environment and then you open the terminal.

00:48:12.280 --> 00:48:13.100
Do you know what a terminal is?

00:48:13.100 --> 00:48:21.920
We're going to tell you, you know, like, no, just, and you don't have to ask permission to run a static webpage where you do for like, how do I run this server on a Docker cluster?

00:48:21.920 --> 00:48:23.120
Something, you know?

00:48:23.120 --> 00:48:25.160
It opens up different doors.

00:48:25.160 --> 00:48:39.220
And I think the other thing we found, like when we were teaching, you know, with Binder and JupyterHub, UC Berkeley was able to have now most of their student body taking these data eight connector courses.

00:48:39.220 --> 00:48:47.100
And they would run the compute in the cloud, which really leveled the playing field.

00:48:47.100 --> 00:48:52.780
It didn't matter if you had a Chromebook or you had the highest end Mac, you still got the same education.

00:48:52.780 --> 00:48:57.020
And I think there is something very appealing about that.

00:48:57.020 --> 00:49:04.400
We've actually been running humble data in Jupyter Lite and some people just bring a tablet and they can do it on that.

00:49:04.400 --> 00:49:04.940
That's awesome.

00:49:04.940 --> 00:49:09.040
Carol, there was something you were saying that connected to something else in my brain.

00:49:09.040 --> 00:49:12.840
Remember in the beginning of the web and view source was such a cool thing.

00:49:12.840 --> 00:49:13.340
Yeah.

00:49:13.500 --> 00:49:18.160
You could see what the backend sent you and you could poke around at it.

00:49:18.160 --> 00:49:22.780
You could learn from it and you could steal it, you know, and use it to go make your own thing.

00:49:22.780 --> 00:49:28.000
But what if you could view source the backend because it's actually running in your browser?

00:49:28.000 --> 00:49:43.900
What you were just saying was if you make it reveal itself about the notebook and the code in addition to the HTML, maybe you'll trigger some of those same kinds of things that view source gave people back in the day.

00:49:43.900 --> 00:49:44.460
Maybe.

00:49:44.460 --> 00:49:44.520
Maybe.

00:49:44.520 --> 00:49:55.520
The flip side would be there's always business and practicalities in life and people will want to sort of lock it down within WebAssembly.

00:49:56.100 --> 00:49:58.200
So you've got both sides of it.

00:49:58.200 --> 00:50:06.040
But I do think, you know, I was telling somebody the other day, like, I never use Stack Overflow or rarely use Stack Overflow.

00:50:06.040 --> 00:50:07.640
And they're like, how do you find stuff?

00:50:07.640 --> 00:50:11.960
I'm like, I use search on GitHub and I look for really good examples.

00:50:11.960 --> 00:50:16.360
And so in some ways it's like view source.

00:50:16.360 --> 00:50:20.740
And then there's also the flip side of it is like, okay, how do I break it?

00:50:20.740 --> 00:50:21.960
How do I play with it?

00:50:22.080 --> 00:50:27.900
How do I make it do something it wasn't doing before, which, you know, could be used for good or for evil?

00:50:27.900 --> 00:50:29.680
I tend to use it for good.

00:50:29.680 --> 00:50:30.040
Sure.

00:50:30.040 --> 00:50:31.880
Paul, we're up on our time here.

00:50:31.880 --> 00:50:32.540
What's your second?

00:50:32.540 --> 00:50:33.200
Sure.

00:50:33.200 --> 00:50:34.120
Second trend.

00:50:34.120 --> 00:50:35.480
We'll see if we have time for mine.

00:50:35.480 --> 00:50:37.660
I have a couple just in case we can squeeze them in.

00:50:37.660 --> 00:50:37.920
Okay.

00:50:37.920 --> 00:50:38.920
Let's talk about yours.

00:50:38.920 --> 00:50:49.500
I came back from PyCon really rejuvenated, but also had some kind of clarity about some things that have been lingering for me for a few years, how I could contribute things like that.

00:50:49.960 --> 00:50:58.300
But going into it, there are a couple of trends that lead me to thinking about an opportunity and a threat as two sides of the same coin.

00:50:58.300 --> 00:51:07.980
First, Russell Keith McGee and Lucas Longa both talked about black swans and the threat of JavaScript everywhere.

00:51:07.980 --> 00:51:21.020
That if we don't have a better web story, if we make our front end be JavaScript and React and we stop doing front ends, well, then they'll come for the back end too.

00:51:21.360 --> 00:51:26.100
Because once they've hired up JavaScript developers, why don't we just do JavaScript on the server too?

00:51:26.100 --> 00:51:27.940
So that was a first thing.

00:51:27.940 --> 00:51:33.960
And in my position, I do look at the web and think about all these trends that are happening.

00:51:33.960 --> 00:51:40.300
And there's beginning to be a little bit of a backlash about the JavaScriptification of the web.

00:51:40.300 --> 00:51:42.040
And so some really big names.

00:51:42.040 --> 00:51:44.040
HTMX is a good example of it.

00:51:44.040 --> 00:51:46.900
But just some thinkers and speakers.

00:51:46.900 --> 00:51:48.760
I mean, Jeff Triplett talks about this.

00:51:48.760 --> 00:51:51.060
A lot of people in the world of Python talk about this.

00:51:51.060 --> 00:51:55.420
So there's kind of a desire to put the web back in the web trademark.

00:51:55.720 --> 00:51:59.300
But then there was a second point coming about these walled gardens.

00:51:59.300 --> 00:52:00.860
We've seen them for a while.

00:52:00.860 --> 00:52:02.620
We all relied on Twitter.

00:52:02.620 --> 00:52:03.760
What a great place.

00:52:03.760 --> 00:52:05.080
Wait, what?

00:52:05.080 --> 00:52:08.800
And then so much of our life is in a system we don't control.

00:52:08.800 --> 00:52:10.720
And so we move over to the Fediverse.

00:52:10.720 --> 00:52:12.620
And then Meta's like, hey, great.

00:52:12.620 --> 00:52:13.980
We're going to build a bridge to you.

00:52:13.980 --> 00:52:20.600
Turns out this week we start to learn things about the Thread API that maybe it's not as friendly as we think it is.

00:52:20.600 --> 00:52:24.260
But the big one for me was Google and Search.

00:52:24.260 --> 00:52:27.500
Well, I should say Google and getting rid of its Python staff.

00:52:27.500 --> 00:52:33.360
But Google and Search, where they're no longer going to send you to the website anymore.

00:52:33.360 --> 00:52:36.620
They're just going to harvest what's on your website and give you the answer.

00:52:36.620 --> 00:52:45.040
And people are talking now about Google Zero, the day of the apocalypse where you no longer get any clicks from Google.

00:52:45.040 --> 00:52:48.080
And what does that mean for content creators and stuff like that?

00:52:48.420 --> 00:52:57.980
So going into all of this, I've been thinking about how awesome life is in Python land because we've got this great language.

00:52:57.980 --> 00:53:00.000
Oh, but we've got this great community.

00:53:00.000 --> 00:53:01.860
Come for the language, stay for the community.

00:53:01.860 --> 00:53:03.240
Well, what do we mean by that?

00:53:03.240 --> 00:53:06.500
A lot of the times we mean all this code that's available.

00:53:06.500 --> 00:53:12.260
We also mean all these people and wonderful, helpful people like on this call.

00:53:12.560 --> 00:53:15.000
But there's also this big world of content.

00:53:15.000 --> 00:53:31.940
And we have kind of organically grown a little online community with a bunch of helpful content and a bunch of connections between people, which is of some value itself.

00:53:33.120 --> 00:53:45.740
And so you see people starting to talk about, wow, I miss the old days of RSS, where we would all subscribe to each other's blogs and get content and go straight to the source and not have it aggregated into a walled garden and stuff like that.

00:53:45.740 --> 00:54:00.440
And it just feels like there's room out there for if we want to fight back against the threat of these megacores taking our voluntary contribution to humanity and monetizing it,

00:54:00.440 --> 00:54:24.000
while at the same time of taking all these valuable voices, creating content and value in Python land, that maybe we could bring back some of these things, put the web back in the web and start to get out of the walled gardens and back over into social networks that are open and joyful.

00:54:24.000 --> 00:54:24.740
I'm here for it.

00:54:24.740 --> 00:54:25.040
Wow.

00:54:25.040 --> 00:54:32.320
People complain, governments complain that places like Google and stuff are monetizing the links and they're being paid.

00:54:32.320 --> 00:54:35.800
You know, you got to pay to link to this new source or whatever, right?

00:54:35.800 --> 00:54:36.400
Various.

00:54:36.400 --> 00:54:37.780
We're lucky that we have that.

00:54:37.780 --> 00:54:41.000
If it turns into just you just get an AI answer, no source.

00:54:41.000 --> 00:54:45.080
That's going to be really hard on a lot of different businesses, creators.

00:54:45.080 --> 00:54:48.740
People just want to create something just for the attention or for their self.

00:54:48.740 --> 00:54:50.620
You know, like nobody comes anymore.

00:54:50.620 --> 00:54:51.520
It's going to be a sad place.

00:54:51.520 --> 00:55:00.920
I was thinking about Coke Zero the whole time you were saying like, you know, Google Zero or whatever, because you didn't have to bring back classic Coke.

00:55:00.920 --> 00:55:07.300
And I think, yeah, pivots happen, but it's hard to pivot, you know, billion dollar companies.

00:55:07.300 --> 00:55:14.760
I have lots of thoughts on some of the current Python, what Google has chosen to do.

00:55:14.760 --> 00:55:21.900
I think sometimes listening to consultants isn't the best business approach.

00:55:21.900 --> 00:55:23.360
You know, it's their company.

00:55:23.360 --> 00:55:26.180
They can do what they need to do for their own shareholders.

00:55:26.380 --> 00:55:29.520
I think a lot of what you said is really interesting.

00:55:29.520 --> 00:55:37.180
And I touched on this a little bit because the volume of information around us is greater than ever before.

00:55:37.180 --> 00:55:37.680
Sure.

00:55:37.680 --> 00:55:43.280
And at a speed of transmission that is faster than ever before.

00:55:43.280 --> 00:55:49.460
And about eight years ago, I had breakfast with Sandy Betts, who was very prolific in the Ruby community.

00:55:49.720 --> 00:55:53.360
And I asked her, like, how do you keep up with all of this stuff?

00:55:53.360 --> 00:55:54.780
And she's like, I don't.

00:55:54.780 --> 00:55:56.020
And I said, OK.

00:55:56.020 --> 00:56:02.740
And she's like, what I do is I focus on the things that impact me and all the rest of it is news.

00:56:03.000 --> 00:56:09.660
And that really stuck with me because in in actuality, that's kind of what I do.

00:56:09.660 --> 00:56:21.040
You know, I ignore the things that aren't directly relevant to me and trust that I've built a strong enough network of people that I respect that.

00:56:21.040 --> 00:56:21.860
Well said.

00:56:21.860 --> 00:56:25.520
Their work will influence when I jump in.

00:56:25.740 --> 00:56:32.320
Like, I don't, you know, much like the life cycle, if you've studied marketing or product development, you know, not everybody is an early adopter.

00:56:32.320 --> 00:56:35.200
So do I need to be an early adopter on everything?

00:56:35.200 --> 00:56:35.540
No.

00:56:35.540 --> 00:56:35.760
Yeah.

00:56:35.760 --> 00:56:39.700
That book, Crossing the Chasm, says that you should do that, like, on one thing.

00:56:39.700 --> 00:56:42.740
If you do it on three things or more, you'll fail.

00:56:42.740 --> 00:56:42.980
Yeah.

00:56:42.980 --> 00:56:59.760
You know, part of the thing that triggered this for me was reading that Andreessen Horowitz, kind of the self-proclaimed king of Silicon Valley VCs, as zero interest rates started to go out of fashion and their recipe wasn't working, they didn't like the negative press coverage.

00:56:59.760 --> 00:57:03.240
So they started their own media empire to cover themselves.

00:57:03.960 --> 00:57:17.780
And that idea is just so appalling that we would get news, we would turn to the megacourts and the masters of the universe to tell us what we should be caring about.

00:57:17.780 --> 00:57:19.220
We have that already.

00:57:19.220 --> 00:57:22.340
We have, I'll be very specific, we have Planet Python.

00:57:22.340 --> 00:57:24.100
It's in disrepair.

00:57:24.100 --> 00:57:37.140
What if it was reimagined into a freaking media empire by us, for us, to cover the Fediverse and course providers and all the value that's out there?

00:57:37.140 --> 00:57:43.160
And like, Carol, you're saying, I don't have to think about it, but I trust that group because they're thinking about it.

00:57:43.160 --> 00:57:54.240
A lot of it is like, you know, when it came to LLMs, it was not the thing that rocked my world, like intellectually, but I knew Simon was doing work with it.

00:57:54.240 --> 00:58:06.340
And so I basically, once every few weeks, would take a look at his website and his blog posts, and he posts a lot, and I would get my data dump of things.

00:58:06.340 --> 00:58:07.320
I don't know.

00:58:07.440 --> 00:58:13.900
I mean, that's one of the reasons I like PyCon, and I've like read talk proposals, everything for the last decade.

00:58:13.900 --> 00:58:14.560
Oh, wow.

00:58:14.560 --> 00:58:16.200
All these talk proposals.

00:58:16.200 --> 00:58:21.160
And it really does give me an appreciation for all the things Python's being used for.

00:58:21.160 --> 00:58:22.380
What's seen?

00:58:22.380 --> 00:58:23.520
Kind of the zeitgeist?

00:58:23.520 --> 00:58:24.160
Yeah.

00:58:24.160 --> 00:58:30.420
And so I think there's different ways of doing that, even just doing a YouTube search of Python content.

00:58:30.420 --> 00:58:39.840
But I tend to focus in on science-oriented things and ways to empower humans through lifelong learning.

00:58:39.840 --> 00:58:46.060
So there's a lot of, we're in a phenomenal period of change, for sure.

00:58:46.060 --> 00:58:46.400
Yes.

00:58:46.400 --> 00:58:49.920
So we won't be bored, nor do I think our jobs are going to go away.

00:58:49.920 --> 00:58:51.940
They may change, but they're not going away.

00:58:51.940 --> 00:58:52.320
Indeed.

00:58:52.320 --> 00:58:54.180
Jodi, final thoughts on this topic?

00:58:54.180 --> 00:58:55.600
And we'll pretty much wrap things up.

00:58:55.600 --> 00:58:57.980
Yeah, I don't think I really have that much to add, actually.

00:58:57.980 --> 00:58:59.320
I think it's all been said.

00:58:59.320 --> 00:58:59.860
It has.

00:58:59.860 --> 00:59:04.420
All right, just to round things, the two things that I think are transiers, I think,

00:59:04.420 --> 00:59:07.800
like Carol said a lot, Python on the front end is going to be super important.

00:59:07.800 --> 00:59:10.160
I think PyScript is really, really interesting.

00:59:10.160 --> 00:59:16.920
I've been waiting for people to develop something like React or Vue or something that we could

00:59:16.920 --> 00:59:18.360
create commercial-facing websites.

00:59:18.360 --> 00:59:23.820
We're halfway there with MicroPython being the foundation of PyScript, which is 100K instead

00:59:23.820 --> 00:59:24.800
of 10 megs.

00:59:24.800 --> 00:59:27.020
All of a sudden, it becomes JavaScript-y size.

00:59:27.020 --> 00:59:28.400
It opens up possibilities.

00:59:28.400 --> 00:59:33.980
And just a shout out to PewPy, which is like Vue with Python, P-U-E-P-Y.

00:59:33.980 --> 00:59:36.000
I'm going to interview Ken from that project.

00:59:36.000 --> 00:59:40.380
But it's kind of a component-based front end for PyScript, which is pretty interesting.

00:59:40.380 --> 00:59:42.780
And of course, Jupyter Lite is really, really important.

00:59:42.780 --> 00:59:44.840
The other one was just all this rust.

00:59:44.840 --> 00:59:46.940
Everything seems to be redone in rust.

00:59:46.940 --> 00:59:49.120
And oh my gosh, that's how you get your VC funding.

00:59:49.120 --> 00:59:50.380
Just joking, sort of.

00:59:50.620 --> 00:59:55.500
But all you talked about all this performance stuff coming, you know, while it is sometimes

00:59:55.500 --> 00:59:59.960
frustrating that people are putting all the things into rust because then Python programmers

00:59:59.960 --> 01:00:01.120
is less approachable for them.

01:00:01.120 --> 01:00:06.300
It could also be an escape hatch from trying to force the complexity into the Python side.

01:00:06.300 --> 01:00:10.840
Alleviate, like everything has to be multi-threaded and crazy and optimized.

01:00:10.840 --> 01:00:12.580
And well, this part you never look at.

01:00:12.580 --> 01:00:13.380
It's faster now.

01:00:13.380 --> 01:00:14.380
So don't worry.

01:00:14.700 --> 01:00:15.700
Anyway, those are my two trends.

01:00:15.700 --> 01:00:18.180
Quick, quick, quick thoughts on that and we'll call it a show.

01:00:18.180 --> 01:00:25.000
My piece of trivia is I made a contribution to rust far before I made any contributions to

01:00:25.000 --> 01:00:25.560
Core Python.

01:00:25.560 --> 01:00:26.220
Amazing.

01:00:26.220 --> 01:00:30.120
Because I tended to be a C programmer in heart and spirit.

01:00:30.120 --> 01:00:34.600
And so rust seemed like this cool thing that was new at the time.

01:00:34.600 --> 01:00:43.380
And ultimately, I personally did not find the syntactic side of it worked well with my brain and how

01:00:43.380 --> 01:00:44.080
I think.

01:00:44.080 --> 01:00:52.300
And Python was far cleaner in terms of a simpler visual, less clutter and reminded me a little

01:00:52.300 --> 01:00:56.220
more of small talk or something like that, which I loved from earlier days.

01:00:56.220 --> 01:00:59.500
But I think there's a place for rust.

01:00:59.500 --> 01:01:02.980
Do I think rust is going to replace Python?

01:01:03.120 --> 01:01:07.040
No, I think it's going to help with some optimized things.

01:01:07.040 --> 01:01:14.340
Do I love things like Ruff that let me run my CI like blazing fast versus, you know, all

01:01:14.340 --> 01:01:15.180
the Python tools?

01:01:15.180 --> 01:01:20.140
Not to say that all the Python tools are bad, but, you know, when you're paying for it as

01:01:20.140 --> 01:01:20.520
a startup.

01:01:20.520 --> 01:01:23.960
When things you just have to wait on become, they blink of an eye, all of a sudden you don't

01:01:23.960 --> 01:01:24.940
mind running them every time.

01:01:24.940 --> 01:01:26.860
And it changes the way you work with tools.

01:01:26.860 --> 01:01:27.500
Yeah, exactly.

01:01:27.500 --> 01:01:31.540
Yeah, I would say, look, every language has its place in the ecosystem.

01:01:31.540 --> 01:01:37.260
And my husband is a longtime Pythonista, but he's also a Rust program.

01:01:37.260 --> 01:01:41.000
I know it's like a running joke that my husband is a Rust developer.

01:01:41.000 --> 01:01:41.740
How do you know?

01:01:41.740 --> 01:01:42.460
He'll ask you.

01:01:42.460 --> 01:01:44.440
Well, you know what I mean.

01:01:44.440 --> 01:01:45.720
How do you know?

01:01:45.720 --> 01:01:46.300
Ask him.

01:01:46.300 --> 01:01:46.880
He'll tell you.

01:01:46.880 --> 01:01:47.600
There you go.

01:01:47.600 --> 01:01:51.340
They have different like purposes, completely different purposes.

01:01:51.780 --> 01:01:54.100
And you can't just interchange them.

01:01:54.100 --> 01:01:54.540
Absolutely.

01:01:54.540 --> 01:01:55.760
Let's just get it straight.

01:01:55.760 --> 01:01:56.700
Python is just awesome.

01:01:56.700 --> 01:01:57.260
So it's our time.

01:01:57.260 --> 01:01:57.800
Pure love.

01:01:57.800 --> 01:02:00.100
But it's to us to keep it awesome.

01:02:00.100 --> 01:02:01.460
Yes, absolutely.

01:02:01.460 --> 01:02:05.680
Paul, we've come around to you for the very final, final thought on this excellent show.

01:02:05.680 --> 01:02:11.680
I will give a final thought about Python trends to follow up on what Carol just said about

01:02:11.680 --> 01:02:12.560
it's up to us.

01:02:13.020 --> 01:02:18.940
Maybe it's up to us to help the people who will keep it that way.

01:02:18.940 --> 01:02:20.760
The next generation of heroes.

01:02:20.760 --> 01:02:22.220
Help them succeed.

01:02:22.220 --> 01:02:28.840
I'm wearing my PyCon Kenya friendship bracelet that I got at PyCon.

01:02:28.840 --> 01:02:33.340
And a wonderful experience meeting so many different kinds of people.

01:02:33.340 --> 01:02:38.940
And from a Python trends perspective, the fact that everything we're talking about is good

01:02:38.940 --> 01:02:42.080
stuff, not like asteroid meets earth.

01:02:42.080 --> 01:02:43.040
Yes, yes.

01:02:43.040 --> 01:02:48.320
IP challenges and patent wars and mergers and acquisitions and stuff.

01:02:48.320 --> 01:02:53.640
Remember a long time ago, I went to go see Guido and he was with the App Engine team at Google.

01:02:53.640 --> 01:02:54.800
So a long time ago.

01:02:54.800 --> 01:02:59.920
And he was starting the process of turning over PEP review to other people.

01:03:00.340 --> 01:03:06.080
And I commented to him that not every open source success story outlives its founder.

01:03:06.080 --> 01:03:13.480
And the bigger it gets, particularly open source projects anchored in the United States of America,

01:03:13.480 --> 01:03:19.020
they sell out and get funded and they will never be the same after that.

01:03:19.020 --> 01:03:27.120
And so it's a moment from a Python trends perspective for us to build a great next future by remembering

01:03:27.120 --> 01:03:29.700
how lucky we are where we have gotten to.

01:03:30.060 --> 01:03:30.660
Absolutely.

01:03:30.660 --> 01:03:33.300
Carol, Jody, Paul, thank you for being on the show.

01:03:33.300 --> 01:03:34.040
Thank you.

01:03:34.040 --> 01:03:34.500
Thanks, Michael.

01:03:34.500 --> 01:03:35.220
Thank you.

01:03:35.220 --> 01:03:36.140
Bye, everyone.

01:03:36.140 --> 01:03:36.420
Bye.

01:03:36.420 --> 01:03:39.740
This has been another episode of Talk Python To Me.

01:03:39.740 --> 01:03:41.540
Thank you to our sponsors.

01:03:41.540 --> 01:03:43.160
Be sure to check out what they're offering.

01:03:43.160 --> 01:03:44.580
It really helps support the show.

01:03:44.580 --> 01:03:47.760
Code Comments, an original podcast from Red Hat.

01:03:47.760 --> 01:03:52.820
This podcast covers stories from technologists who've been through tough tech transitions

01:03:52.820 --> 01:03:56.420
and share how their teams survived the journey.

01:03:57.020 --> 01:04:02.820
Episodes are available everywhere you listen to your podcasts and at talkpython.fm/code dash comments.

01:04:02.820 --> 01:04:07.240
This episode is sponsored by Posit Connect from the makers of Shiny.

01:04:07.240 --> 01:04:11.760
Publish, share, and deploy all of your data projects that you're creating using Python.

01:04:11.760 --> 01:04:18.320
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

01:04:18.320 --> 01:04:20.720
Posit Connect supports all of them.

01:04:20.720 --> 01:04:25.080
Try Posit Connect for free by going to talkpython.fm/posit.

01:04:25.420 --> 01:04:26.420
P-O-S-I-T.

01:04:26.420 --> 01:04:28.140
Want to level up your Python?

01:04:28.140 --> 01:04:32.220
We have one of the largest catalogs of Python video courses over at Talk Python.

01:04:32.220 --> 01:04:37.300
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:04:37.300 --> 01:04:39.980
And best of all, there's not a subscription in sight.

01:04:39.980 --> 01:04:42.880
Check it out for yourself at training.talkpython.fm.

01:04:42.880 --> 01:04:44.980
Be sure to subscribe to the show.

01:04:44.980 --> 01:04:47.780
Open your favorite podcast app and search for Python.

01:04:47.780 --> 01:04:49.080
We should be right at the top.

01:04:49.080 --> 01:04:54.240
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:04:54.240 --> 01:04:58.440
and the direct RSS feed at /rss on talkpython.fm.

01:04:58.440 --> 01:05:01.400
We're live streaming most of our recordings these days.

01:05:01.400 --> 01:05:04.820
If you want to be part of the show and have your comments featured on the air,

01:05:04.820 --> 01:05:09.240
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:05:09.820 --> 01:05:11.300
This is your host, Michael Kennedy.

01:05:11.300 --> 01:05:12.580
Thanks so much for listening.

01:05:12.580 --> 01:05:13.740
I really appreciate it.

01:05:13.740 --> 01:05:15.660
Now get out there and write some Python code.

01:05:15.660 --> 01:05:16.660
Thank you.

01:05:16.660 --> 01:05:17.660
Bye.

01:05:17.660 --> 01:05:18.660
Bye.

01:05:18.660 --> 01:05:19.660
Bye.

01:05:19.660 --> 01:05:20.660
Bye.

01:05:20.660 --> 01:05:21.660
Bye.

01:05:21.660 --> 01:05:22.660
Bye.

01:05:22.660 --> 01:05:23.660
Bye.

01:05:23.660 --> 01:05:24.660
Bye.

01:05:24.660 --> 01:05:25.660
Bye.

01:05:25.660 --> 01:05:26.660
Bye.

01:05:26.660 --> 01:05:27.660
Bye.

01:05:27.660 --> 01:05:28.660
Bye.

01:05:28.660 --> 01:05:29.660
Bye.

01:05:29.660 --> 01:05:30.660
Bye.

01:05:30.660 --> 01:05:31.660
Bye.

01:05:31.660 --> 01:05:32.660
Bye.

01:05:32.660 --> 01:05:33.160
you

01:05:33.160 --> 01:05:33.660
you

01:05:33.660 --> 01:05:34.160
you

01:05:34.160 --> 01:05:36.160
Thank you.

01:05:36.160 --> 01:06:06.140
Thank you.

