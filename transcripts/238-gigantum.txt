00:00:00 Collaborative data science has a few challenges.

00:00:02 First of all, those who you're collaborating with might not be savvy enough in the computer science techniques.

00:00:07 For example, Git in source control or Docker in Linux.

00:00:10 Second, seeing the work and changes others have made is a challenge too.

00:00:14 That's why Dean Klysis and his co-founders created Gigantum.

00:00:18 It's a platform that runs either locally or in the cloud, and it spins up data science environments into Docker containers seamlessly on your local computer.

00:00:26 And it syncs collaborative updates from machine to machine.

00:00:29 This is Talk Python to Me, episode 238, recorded October 17th, 2019.

00:00:34 Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:00:53 This is your host, Michael Kennedy.

00:00:55 Follow me on Twitter where I'm @mkennedy.

00:00:58 Keep up with the show and listen to past episodes at talkpython.fm.

00:01:01 And follow the show on Twitter via at Talk Python.

00:01:04 This episode is brought to you by Linode and Tidelift.

00:01:07 Please check out what they're offering during their segments.

00:01:09 It really helps support the show.

00:01:11 Dean, welcome to Talk Python to Me.

00:01:13 Hey, how's it going?

00:01:14 Hey, it's going really well.

00:01:15 It's good to have you here.

00:01:16 Yeah, it's great to be here.

00:01:17 Yeah, it's going to be a lot of fun to talk about repeatable data science

00:01:21 and collaborative data science and stuff like that.

00:01:23 And you and your co-founder have put a ton of work into turning this into some platform

00:01:31 that folks can use.

00:01:32 And that's really great.

00:01:33 So we're going to talk all about that.

00:01:35 Before we get into it, though, let's just start with your story.

00:01:37 How did you get into programming in Python?

00:01:38 I was pretty fortunate early on.

00:01:40 You know, my parents got us a computer.

00:01:42 So I've always kind of had computers around.

00:01:44 You know, I remember battling with my parents to get like dial up in the house.

00:01:48 And that was like a huge deal.

00:01:49 You know, I definitely was in the AOL era getting home, you know, from school and like

00:01:54 jumping right on.

00:01:55 So like, like everybody.

00:01:57 Yeah, of course.

00:01:58 And, you know, the worst was when somebody would pick up the phone, right?

00:02:01 You're in the middle of something and they wouldn't know.

00:02:03 They'd pick up the phone in some other part of the house and it would kill your connection.

00:02:06 You'd be like, come on, I was downloading something.

00:02:09 It took an hour to get a megabyte and you just killed it.

00:02:11 That's why definitely overnight you were definitely like downloading stuff, you know?

00:02:15 And like, we definitely were the one phone line still.

00:02:17 Like everyone, I had my GeoCities website packed with like our construction gifts, you know,

00:02:23 all the staples.

00:02:24 So, you know, that kind of got me going, web development, you know, poking around, if you

00:02:30 would call it that.

00:02:30 Then, you know, and then high school, I did a bunch of random programming classes and through

00:02:35 college, you know, kind of more like, you know, dabbling here and there.

00:02:38 I took, you know, I had a visual basic thing, some Java.

00:02:41 I was doing mechanical engineering at first and started doing a lot of MATLAB and then

00:02:46 picked up electrical engineering at the University of Rochester.

00:02:49 And that's kind of like where I was started getting a little bit more into programming as

00:02:53 more of a serious thing and then just something I poked around at.

00:02:55 And, you know, really because of my initial career path, I started at Northrop Grumman for

00:03:01 a little while before I went to Johns Hopkins, was doing like a lot of MATLAB.

00:03:04 And that kind of got me started and then started using Python and, you know, was just

00:03:10 like, wow, this is amazing.

00:03:11 Never looked back.

00:03:11 Right?

00:03:12 Like, why was I using MATLAB?

00:03:12 Never looked back.

00:03:13 And so, yeah.

00:03:16 So especially when I was at Johns Hopkins at the Applied Physics Laboratory, I was there

00:03:19 for a while.

00:03:19 Did a lot of Python, mainly, mostly Python development there.

00:03:23 What kind of stuff were you studying there?

00:03:24 When I was at...

00:03:25 At Johns Hopkins, yeah.

00:03:26 Yeah.

00:03:26 So, like I said, I did my undergrad at the University of Rochester.

00:03:29 I'm in mechanical engineering and electrical computer engineering.

00:03:31 And then I did a master's at Johns Hopkins in...

00:03:34 Focused in robotics and control.

00:03:36 Okay, cool.

00:03:36 And then when I was at the Applied Physics Lab, that was as like a staff member engineer

00:03:41 there.

00:03:41 And so that...

00:03:43 My time there was in this group called the Intelligent Systems Center.

00:03:47 And it's this really wild place.

00:03:49 They kind of took a bunch of neuroscientists, a bunch of computer scientists, a bunch of

00:03:52 roboticists, kind of like smashed us together in a building and, you know, hoped for...

00:03:56 novel things to happen.

00:03:57 And it was, you know, really cool.

00:03:59 Did a bunch of really interesting things with a lot of external collaborators.

00:04:02 So working in a lot of applied neuroscience work, doing some high-resolution brain mapping,

00:04:07 some things with the hospital.

00:04:09 So doing some natural language processing and machine learning in the clinical setting for

00:04:13 quality improvement.

00:04:14 So got to do a lot of really interesting stuff.

00:04:16 And almost all of that was really in Python.

00:04:18 And we would build these pretty large production quality systems.

00:04:21 And often, you know, we would do it on Python.

00:04:25 And then there would be little bits where there was something that was really computationally

00:04:28 intensive or whatever.

00:04:29 And that little bit would be written in C.

00:04:30 And we'd C-type bit.

00:04:31 And everything else is just, you know, lots and lots of Python.

00:04:35 So...

00:04:35 Yeah, that sounds like a ton of fun.

00:04:36 I worked in some research groups with a bunch of cognitive scientists before.

00:04:41 And there's a lot of computation for what, to me, kind of felt at first, like, almost like

00:04:47 psychology and stuff.

00:04:48 And but it turns out there's a lot of computational stuff going on in those research groups and

00:04:54 in that discipline.

00:04:55 If you're collecting some sort of data, you eventually need to do something with it.

00:04:58 And this is like across all fields.

00:05:00 You weren't...

00:05:01 You know, recently, I was speaking with a bunch of, you know, we're working more and more with

00:05:05 people in the social sciences.

00:05:06 So, you know, people doing food science, people doing, you know, economics, obviously.

00:05:10 But these places that you don't treat, think as traditionally as, you know, the hard sciences

00:05:15 as being so data-driven and data science-driven are just, you know, they're getting into it,

00:05:19 too.

00:05:20 And they're just all the same problems.

00:05:22 Yeah, they are.

00:05:23 One of my daughters is in their second year of college, and she's studying psychology.

00:05:27 And she sent me a text yesterday.

00:05:29 And it said, Dad, do you know what our studio is?

00:05:33 I'm like, what?

00:05:33 It's like, yeah, we're using this for my psychology class.

00:05:36 I'm like, oh, okay, that's pretty...

00:05:38 Too bad it's not Python or Jupyter.

00:05:39 But, you know, still, it's interesting how, like, prevalent this type of computing that

00:05:45 the platform that you built for and that we're talking about is across all the disciplines,

00:05:50 right?

00:05:50 When I think of Python and who should be a developer or any language, but especially Python,

00:05:56 and who should become a developer and get these skills, I often, maybe you've heard me

00:06:00 say it, is that Python can be a superpower for what you actually do, not your job.

00:06:06 It doesn't have to be I'm a Python developer.

00:06:08 It can be I'm a, like you said, economist, and I'm really good at it because I know Python

00:06:12 and Jupyter or something like that.

00:06:14 And I see that kind of spreading quite a bit.

00:06:17 Absolutely.

00:06:17 Yeah.

00:06:18 The ecosystem has gotten so rich, and the tooling has gotten so good.

00:06:22 You know, really, it's opening to everybody.

00:06:25 And we do see almost this split between, you know, there's Python and, you know, Python

00:06:30 Jupyter and then RStudio.

00:06:32 You know, it's kind of like, and it's often aligned with fields, like some fields use RStudio

00:06:36 more, some fields use Python more.

00:06:38 So it's kind of interesting to see how that all has played out as well.

00:06:41 Yeah, for sure.

00:06:42 I think there's some good inner exchanges between the two environments as well.

00:06:46 So when you're doing this research, one of the things that was a bit of a motivation for

00:06:52 you to create this project that we're going to talk about is that you had folks from all

00:06:56 these different skill levels, from these different backgrounds, these different specialties, trying

00:07:01 to work together, right?

00:07:02 And that's got to be a problem or challenging, rather.

00:07:05 Yeah, so, you know, that experience at, you know, six or so years at Johns Hopkins doing

00:07:10 these research projects and helping run these research projects really was, you know, you

00:07:14 feel this pain that makes you want to do something about it, right?

00:07:17 And there was a couple issues that we kept running up to that were, you know, became very obvious

00:07:23 after we spent like loads of energy doing something, you know, and it's like there's this issue

00:07:28 with asymmetries, right?

00:07:30 So you have people that want to work together that have very different skill sets.

00:07:35 And they also care about different things about a project.

00:07:38 And so how can you make these people work together?

00:07:41 And when it comes down to like the technical asymmetries, it's like, even if you know how

00:07:45 to use Git, or you know how to use Docker, or you know how to use some tool that makes

00:07:49 your work better, that person on the other side of that exchange, if they don't know it

00:07:53 as well, like all the energy you spent is potentially wasted because you just can't work together.

00:07:58 You know, and so as you start building, you know, we're seeing the science is getting

00:08:03 harder, as people are starting to say, you know, discovery is getting harder, teams are

00:08:08 getting bigger, teams are getting more heterogeneous to solve more complicated problems.

00:08:12 And it just like compounds this issue of asymmetries.

00:08:15 And, you know, everybody's contributions on these projects is important.

00:08:19 That's why we're all working together.

00:08:20 And so if we can make it easier for people to work together, to not need to learn every single

00:08:26 complex tool to be able to see something or interact with something or contribute, you know,

00:08:31 it's just going to be better. And so we definitely were going that route to start of,

00:08:35 no, everyone will just learn these complicated things. Like it's this is the way you do it.

00:08:39 Like, why aren't you going to be so better off?

00:08:41 People should be building these Docker images.

00:08:42 Exactly. If they just learn Docker and Kubernetes, what's wrong with them?

00:08:46 Yeah, like, I know they have a day job. That's fine. I know you're a doctor, but you need to learn

00:08:51 how to run this Docker container. So you can run this training for me, right? Like it just,

00:08:55 it took a while to like learn that firsthand that everybody's, you have to, you know,

00:09:00 everybody's time is important. Everybody's busy and you want us all just to move as fast as we can

00:09:05 together. And that was a big motivator for a lot of the design decisions we made. And, you know,

00:09:09 as doing this, we were coming, a lot of these collaborations were coming from this angle that

00:09:13 we were pairing with biologists, with neuroscientists. So our first big thing, we started working with

00:09:19 this lab at Harvard run by Jeff Lickman, Bobby Casturi, and a bunch of people there doing awesome

00:09:24 high resolution brain mapping stuff. So they're using electron microscopy to actually map the brain

00:09:29 at single synapse resolution. So you can see how every single neuron and every single synapse is made.

00:09:34 And so that whole field in general has exploded. They've got all this awesome stuff coming out now

00:09:40 out of this program called IR microns, which is what, you know, we worked on as well,

00:09:44 where they imaged cubic millimeter of brain tissues. This is like two and a half petabytes

00:09:49 of image data, right? And it's that small, right? It's like a cubic millimeter, which is actually an

00:09:54 incredibly small part of the brain. Correct. And this was done at the Allen Institute in Seattle

00:09:59 is where that imaging was done. In 2011, when we started that, it was this one lab in Harvard

00:10:04 imaging it, we go up there, the data's on a hard drive, you know, and it's like beginning the

00:10:09 application of can we apply some engineering to these, to the, you know, the science and make

00:10:14 it better. And it was an interesting collaboration. We built some database systems that were like

00:10:18 optimized for this type of thing. You know, we learned a lot. And it was that idea of like,

00:10:23 well, can we apply these like things we know from like software development, from proper engineering

00:10:27 and help apply them to the science? You know, that was a very obvious thing that like that needs to

00:10:31 kind of happen in data science, right? Like software engineering has done all these awesome things.

00:10:35 Data science kind of needs some of that help. So that was kind of one of the founding

00:10:38 things we wanted to do as well. Right. Because we definitely have a lot of folks coming into

00:10:43 the data science world, not specifically from the computer science side, right? They're coming from

00:10:49 all these other fields as we've spoken about. And, you know, it's probably a bit of a stretch

00:10:55 just to be doing the programming at all. Much less go, yeah, we're going to learn about like refactoring

00:11:02 and unit testing and Docker and all these other things. And so with this big influx of folks,

00:11:08 right, like it's, it seems almost like there's two paths. One path is to say, well, we're going to

00:11:13 all work together. And so what we're going to do is we're going to use the simplest, lightweight,

00:11:17 least structured world as possible. And we're just going to use we're all going to install Anaconda.

00:11:23 We're all going to run Jupyter. And we're just going to try to just, you know, maybe we'll use

00:11:29 version control, right? Because we got to share the files, or maybe we'll use something in the cloud.

00:11:33 And that's one option. Another one is like what you guys went after, which is to build a platform

00:11:38 that makes those things transparent, but also actually does a lot of that stuff like

00:11:43 versioning with Docker. So you get exactly the same stuff over time and things like this. Yeah.

00:11:47 Yeah. So there's all these things that are required to do good data science that aren't actually data

00:11:54 science. And so like, it's kind of unfair to expect these people to be required to know it like over time,

00:12:01 you will learn like this idea that, you know, it's right now getting into data science is like a step

00:12:06 function, right? It's like, you don't just slowly start, you have to make this leap. Chris Holgraf

00:12:11 had this quote on Twitter the other day. That's from the Pangeo conference that I thought was perfect.

00:12:16 That was, you know, learning data science often feels like needing a pair of scissors to open a package

00:12:20 of scissors. You know what I'm saying? It's like, yeah, this is what we expect from people. And so what we

00:12:26 really wanted to try to do is like, can we make this more of a ramp? Can you click a button and

00:12:31 get started? And that's fine. And then eventually you're like, oh, I see this is doing Git stuff.

00:12:36 And I just merged something. And then you can learn what that means. And you can get under the hood.

00:12:40 And you can write your own Docker snippets that get inserted in your Docker file if you want.

00:12:44 But if you want to use a package manager, you can click some buttons. And you know, with time,

00:12:48 you become more skilled. And it like, let's just say symmetry map, be a little bit less crazy. So that's a great segue, I think, over to this project that you guys

00:12:56 built called Gigantum. It's sort of the project to solve this problem that you've laid out for us,

00:13:01 right? Yeah. So we kind of had the opportunity to, you know, get a little bit of money to try to start

00:13:07 this. So we were able to kind of, you know, quit day jobs, 100% effort to work on this project.

00:13:12 It sounds like a dream, honestly.

00:13:13 It kind of was. We spent so much time working on this project at Putt Hopkins that was just coming to its

00:13:19 peak. It was kind of hard to, you know, I left right around this time. It was kind of hard to do that.

00:13:24 But like you said, it was just perfect to go and have an opportunity to go do this thing you've been

00:13:28 whining about for six years that someone needs to go fix this thing. And you finally have an

00:13:31 opportunity to maybe contribute and do it.

00:13:33 You can like, you can work on one project like at Johns Hopkins and make that project great. Or you

00:13:38 can work on something like this and you could sort of meta solve it for the world, right?

00:13:42 Right. So fingers crossed. That's the plan.

00:13:44 That's the plan. All right. So tell us about it.

00:13:46 So yeah, what we built is this suite of tools that, you know, helps people of different skill

00:13:50 levels do like transparent, reproducible data science way faster and easier than they could

00:13:55 through kind of automation and ergonomics around all those, like I said, all those things that you

00:14:00 need to do good data science, but aren't data science. So the core of it is this thing we call

00:14:05 a gigantic client. It's open source, MIT licensed, basically web application. So you can run it anywhere

00:14:12 that manages a data science project or a data set. And so when I say project, that was another thing

00:14:19 that we felt was kind of the first thing that needed to be solved was there was no real, no real

00:14:23 currency in data science. There's no standards. There's no, there's no way to make an exchange with

00:14:29 another person because, you know, there's no standard way that you represent your environment

00:14:34 or your data or organize things. There's no easy way to ship it up, pack it up and ship it.

00:14:38 Yeah. Just because you have a Jupyter notebook, that's not potentially enough. You also need the

00:14:43 libraries that notebook is going to depend upon. So something like a requirements file,

00:14:48 if you have data, right, you've got to package that data. Somehow all these things need to go

00:14:53 together, right? Like the read me about it and so on. Yeah.

00:14:56 To make a project that's reproducible, but more importantly, kind of transparent so somebody

00:15:03 could understand what you did, why you did it, how you did it. You know, you need to bundle together

00:15:07 the code, the data, the environment, like you said, a read me, the work history, like who did what,

00:15:13 when, and you need to bundle that together. You need to track that and make it be automatic. So

00:15:18 that's what we did it. So the big thing that the client does is it tightly integrates with

00:15:22 Jupyter and RStudio. And it kind of gives you this interface, lets you upload your data,

00:15:27 drag and drop your code, build your environment. So you configure your environment. You can drag and

00:15:32 drop a requirements.txt file. If you got that, you can use package managers like PIP, Conda,

00:15:37 Act, or you can write custom Docker if you want to get under the hood. You know, it's really important

00:15:42 that it's that flexible because people really, you know, not every tool people need to use is sitting

00:15:46 in some package manager as well. And so the ability to be able to really build whatever you want was

00:15:52 really important. And so by putting that all together, the client then versions this all in

00:15:56 unison lockstep. So at any point in time, you can roll back and get the same environment, the same data,

00:16:02 view of your data, code. And because these tight integrations, what's really cool with what we've done is

00:16:07 as you are running your codes, you're writing in your Jupyter notebook, you execute some cells, we will detect

00:16:13 that that happened. We will automatically create a version. We will automatically generate some metadata to

00:16:18 like, let you know what you were doing. If you generate a figure, we kind of extract it and recompress it and save it,

00:16:24 so that you can get this visual history of what you've done as well. So it's not just about, you know, making this

00:16:30 thing easy to share, but it's kind of making it a little bit more intelligible. You're not looking at like some git history,

00:16:36 where it was just like, ran my code, ran my code, fixed the bug. Oh, crap, what's going on? It's like,

00:16:42 created this figure, change these parameters, right? And that's going to be getting a lot better with time as we kind of

00:16:48 push on that.

00:16:49 Yeah, that's really cool. And it's worth pointing out, I guess it wasn't obvious to folks, everything you've talked about so far

00:16:55 runs locally on your machine, 100%. Right?

00:16:59 Right. So yeah, like I said, the client's designed to run kind of wherever, just a web application. So you can run on your

00:17:05 laptop, you can run it on a server in Amazon, we have lots of users that like to do that, right? They run on their laptop, they sync it

00:17:12 to some GPU instance or whatever, they do some training, they sync it back to their laptop and keep on working and only pay for

00:17:17 like a little bit of cloud time. You can also run it in our cloud. So you can click a project and play with it there

00:17:24 as well. It's an easier no installation. Because like I mentioned, this does require Docker. So you if you want to run on

00:17:31 your laptop, you have to install Docker on your laptop. That's gotten a lot easier.

00:17:35 It's so much easier. It used to be really like quite, I hope I can make this work sort of feeling. But now it's like on the

00:17:43 Mac, you download the Docker Mac app, you double click it, it runs in the menu bar. And that's pretty

00:17:49 much the extent of it, right? Like you don't really have to know more. So it's pretty easy.

00:17:53 Yeah. And Windows is getting a lot better. And Windows, there's some really awesome advances

00:17:57 coming out of the Windows team. Oh, yeah. Windows subsystem for Linux 2. It's gonna make Docker

00:18:02 containers run essentially almost native on Windows. It's gonna be great. It's gonna be coming out.

00:18:06 Maybe tell people about the Windows subsystem for Linux, just what that is real quick.

00:18:10 they might not be aware of it. Sure. So there's a version now that you can get if you've got Windows

00:18:15 that lets you effectively run a Linux kernel on Windows, like a shipping a Linux kernel with Windows

00:18:21 now and you can install Ubuntu and fire it up right there in Windows. And it's not really using a VM. So

00:18:27 in the sense that it was before. So if you install Docker desktop, which is Docker's product that you should

00:18:33 install when you're running on your laptop, it's got like little applique, like you're describing,

00:18:37 you know, that's going to run in a virtual machine to give you that Linux environment.

00:18:42 So Windows subsystem for Linux is pushing all of this way farther down closer to the operating system

00:18:48 so that it's really almost like native performance. And this WSL 2 or Windows subsystem for Linux 2

00:18:53 that's coming out is just a much, much better version of that that lets you run Docker inside of it,

00:18:59 which is what's really exciting. Right.

00:19:01 And so, yeah. So thanks for the sidetrack. Yeah. So you were talking about it's pretty easy to run

00:19:05 Docker on your machine now. Yeah. And we do like, as we talked about asymmetries, like installing software

00:19:10 on your computer is a thing people don't really do as much anymore and it's daunting. And so we do have

00:19:15 a desktop app that helps walk you through the Docker install and configure our stuff and just get it all

00:19:21 going for you as well. So you just kind of download that, double click it, and it should hold your hand to

00:19:27 the point where you just got a Jupyter notebook open. And that Jupyter notebook is running in a Docker

00:19:30 container in a Git repository for you. Yeah. When I was playing with it, that's how it worked. I

00:19:35 downloaded the app. I ran it. It just said, you know, please wait. We've got to download a bunch

00:19:39 of data because we're downloading, you know, Ubuntu or something like that. And it was fine. I just

00:19:44 chilled for a minute. And then, you know, you're right. I was right there. First thing it dropped me

00:19:48 is into Gigantum, the web app, which is a little bit like a Jupyter lab feel, a tiny bit. It shows you

00:19:54 like your projects and your data and stuff. And then you can actually launch or create new projects,

00:19:59 which then launch into Jupyter or RStudio, like, and so on.

00:20:02 This portion of Talk Python To Me is brought to you by Linode. Are you looking for hosting that's fast,

00:20:10 simple, and incredibly affordable? Well, look past that bookstore and check out Linode at

00:20:14 talkpython.fm/Linode. That's L-I-N-O-D-E. Plans start at just $5 a month for a dedicated server

00:20:22 with a gig of RAM. They have 10 data centers across the globe. So no matter where you are

00:20:26 or where your users are, there's a data center for you. Whether you want to run a Python web app,

00:20:30 host a private Git server, or just a file server, you'll get native SSDs on all the machines,

00:20:36 a newly upgraded 200 gigabit network, 24-7 friendly support, even on holidays, and a seven-day money-back

00:20:43 guarantee. Need a little help with your infrastructure? They even offer professional

00:20:47 services to help you with architecture, migrations, and more. Do you want a dedicated server for free

00:20:51 for the next four months? Just visit talkpython.fm/Linode.

00:20:58 That's really the client. And like I said, we have these apps that help run the client for you and

00:21:02 make it real easy. So you could run on your laptop with our desktop app, or you can run it on a server.

00:21:06 We have a CLI. So if you prefer the command line, there's a little CLI version that you can just be

00:21:11 like, install Gigantum, run it. And so that's good for when you're running on some remote resource.

00:21:15 And then we have our gigantum.com. There is this hub, which lets you sync and share your work and

00:21:22 preview other people's work and play around. And that's kind of how you can collaborate and move

00:21:27 things around from computer to computer, find content, find examples. That's kind of our,

00:21:32 it's a very decentralized system in that you can copy things wherever you want. And it's kind of like,

00:21:37 then there's this central piece where if you want to, you know, put your stuff in one place,

00:21:41 that's where it goes. Yeah. And you can synchronize across that. So a lot of cloud

00:21:45 systems, you log in, you run your code there and it just stays there, right? I'm editing there and

00:21:51 you're in that cloud for this project or whatever. But at least the desktop client version, the way it

00:21:58 works is it kind of synchronized, you can synchronize it up to the cloud and other people can download it

00:22:03 locally and run it and so on, right? And basically behind the scenes, seamlessly uses Git to keep

00:22:09 everything in sync, right? Yeah. So we're using Git or using Git LFS, which is Git large file service.

00:22:14 So it's like when files get over a certain size, Git explodes. And so this is a way to handle

00:22:18 files that are bigger. And then when files get even larger, we use a different service that we've built

00:22:24 and that all is transparent. So you upload your data, we'll use LFS if we need to use it, we won't,

00:22:29 we'll use regular Git if we don't. So that's kind of managed as well for the user. But yeah,

00:22:33 so that lets you this idea of being able to sync versus like you said, having your code right there

00:22:39 in that platform, it lets you move it around wherever you want and put it on the right resource

00:22:43 to do what you want to do.

00:22:45 Yeah. I was looking over at your GitHub organization for Gigantum and you have a bunch of different

00:22:51 projects there. And it looks like the stuff that you're talking about is open source, not necessarily

00:22:56 the cloud because a lot of SaaS providers, well, almost every SaaS provider does not open source their

00:23:01 SaaS thing. And that makes a lot of sense. But the Gigantum client and a lot of that stuff seems to

00:23:07 be open source. Is that the right reading of that?

00:23:09 The client is open source, MIT licensed. Also our desktop application and our CLI are there.

00:23:14 We've got some other smaller packages we've built for various reasons as well. And that will always

00:23:19 be the case, right? The whole idea is this client, the actual workhorse of the whole thing

00:23:23 is free to use, lets you use it wherever you want for however long you want. And then it's only,

00:23:29 you know, like you said, we do have this somewhat proprietary piece, which is our

00:23:32 cloud infrastructure that lets you run a compute in our cluster and all of that sort of thing.

00:23:37 Yeah. Okay. Interesting. So let's maybe talk through creating a project. I think that'll give

00:23:43 people a sense of what Gigantum offers and like why they might use it and so on.

00:23:48 Sure.

00:23:48 So yeah, go ahead and take us through it.

00:23:49 When you create a project, effectively you're creating this specially formatted Git repository

00:23:54 with a bunch of extra information in it. So you start by running the client. Again,

00:23:59 like we just talked about, you could run it on your laptop, you can run it wherever you can

00:24:02 run it in our cloud. You create a project and you choose a base. So all projects start from

00:24:07 some base container. So we build a handful of them and have them available. So you can use Python 2,

00:24:13 Python 3, RStudio, Jupyter, JupyterLab. You know, they're kind of different configurations.

00:24:18 We've got some that have CUDA support. If you want to do deep learning with GPUs,

00:24:22 we have some that come prebuilt with a whole bunch of data science packages.

00:24:26 It's kind of like, you know, choose what you want there.

00:24:29 Yeah, I could choose, you know, like, for example, if I pick Python 3, it says, do you want like

00:24:33 the full on data science workstation Docker image? Or do you want like the bare bones

00:24:38 just as Python 3 on it? Why would I choose one over the other? I mean, first impressions are maybe if I

00:24:44 choose the full on data science one, like it's another gig download or something like, but what

00:24:48 are the, why would you choose one over the other?

00:24:50 Yeah, basic. I mean, really, it just comes down to disk space, right? Like the pre-baked one has

00:24:55 a ton of packages that are kind of this somewhat community agreed upon set of things that are,

00:25:02 you know, core data science tools in Python. And so it's much larger. And then the minimal one is

00:25:07 obviously smaller. And so let's say, if you know what you're doing, if you were doing something where

00:25:11 you only need, you know, a couple packages, then maybe you just install those yourself. But if you,

00:25:16 you know, quick start, I just need requests and pandas. That's all I need. I know it.

00:25:20 Yeah, something like that, right?

00:25:22 Then you don't need the rest of this. Yeah, absolutely.

00:25:24 Cool. Okay. So you pick one of these base images and technically it's a Docker image,

00:25:28 but people don't really know that. Like they don't need to know that. They just need to know, I get a Linux operating system that has these capabilities,

00:25:36 right?

00:25:37 Yeah. I get a Linux operating system that has Jupyter and ready to go for me basically.

00:25:41 And once you get the project created, you can augment this environment. So like you said,

00:25:46 if you want to install, you know, pandas and requests, you click on an environment tab. There's

00:25:51 a little widget there that lets you enter in the package name. If you have a specific version you

00:25:55 want, if not, it'll look it up for you. And that's an important thing to like all packages that get

00:25:59 installed are automatically pinned to a version. So there's none of this just install the latest every

00:26:04 time you run. It's no, it installed a specific version. And if you want to upgrade it, you can

00:26:08 upgrade it right there in the UI and it lets you know that there's an update available, but everything

00:26:12 is pinned.

00:26:13 That definitely feeds into the reproducible science, reproducible computation side of things,

00:26:18 right?

00:26:18 Right. Making things reproducible is kind of a side effect of what we wanted to do, right? Like that

00:26:25 should just be the default world we want to live in where you're, we started talking about this as a

00:26:30 reproducible work environment. It's not, I did something and now I want to be able to do that

00:26:34 exact same thing later. So I do a bunch of work to make it reproducible. It's because I did this the

00:26:39 way I did this from day one. I can at any point in time reproduce that. And it's just, it's even if

00:26:45 you're not sharing with other people, your future self, like going back to a project you worked on

00:26:49 six months ago is like incredibly challenging. And so, you know, where were those files? What

00:26:55 virtual environment was I using? You know, where is it? And just having that taken care of,

00:27:00 it's just one less thing to worry about.

00:27:02 Right. So the first time that you go through this project process and you pick a Docker image,

00:27:07 obviously underneath the scenes, it's doing like a Docker build, which might do a Docker pull and

00:27:12 download some of the various container images. I would guess the second, third and fourth time,

00:27:17 those are like just cached and nearly instant. So that's nice, right?

00:27:21 Yeah, absolutely. So we take advantage of the Docker caching. So if you reuse the same environment,

00:27:26 build almost instantly, all that kind of stuff is really nice.

00:27:30 Yeah. So it goes in, it creates the Docker image and it runs through all the startup, which is like

00:27:34 pip install or condo install the things that are associated with that. You can even watch it build.

00:27:38 Like I watched the little installer screen because I was just sitting there waiting like,

00:27:43 oh, let me just watch the build. If I go like, yeah, a bunch of pip install, just like I thought. Right.

00:27:46 So that's all pretty good. And then it basically, once it's all done, it launches that and it drops you

00:27:52 into a web app pointing back at localhost, some port, 8000, 8888, something like that, that goes back to

00:28:00 this web view into your workspace. And that's really the view of Gigantum that people see, right? That's

00:28:07 what they perceive it as, I would guess.

00:28:08 Right. So that's where you can see, you know, if there's a readme, you can see the environment

00:28:13 configuration, you can upload. If you've got existing files, you know, that's where you would drag and

00:28:16 drop some notebooks or drag and drop a bunch of data. And it kind of gives you that organization

00:28:22 as well. You know, we kind of wanted to not so much in like, you know, enforce this and say,

00:28:29 this is how you have to organize things. But at the end of the day, we decided it was important,

00:28:33 like having starting to build some expectation around how things are organized, not only makes

00:28:39 building the software easier, but it just builds this intuition into what people, when you open up a

00:28:43 Gigantum project, you know where the code is, you know where the input data is, you know where the

00:28:48 output data is, at least you have that much, and then you're free to organize it however else you

00:28:52 want, right? But that's kind of how it's broken apart is you have these different bins, you drop

00:28:57 your data into your code into. And then there's we touched on a little bit as this activity feed. So

00:29:02 this is the history of everything you've done. So you'll see if you add a package, there'll be a

00:29:08 little entry that you change the package, if you add some files, if you delete some files,

00:29:12 if you run code. So everything you do, the system's constantly monitoring it. And it's

00:29:17 automatically making Git commits for you under the hood. And that's visible in that project view as

00:29:21 well. If you want to share with people, you can like push it to the cloud and give them a link and

00:29:26 they can download it or you can invite them to it or something like that. Does that include their history

00:29:31 in your local version as well? What's the collaboration look like around that?

00:29:35 Yeah. So if two people want to work together on a project, you know, someone creates it,

00:29:38 they publish it. By default, everything publishes privately. So only you will be able to access it.

00:29:43 You're going to have to add a collaborator. And we've got permission model where you can add

00:29:47 somebody as an administrator, they can have read write, and they can have read only access. And that

00:29:52 kind of limits what they can edit, what they can see. But if they're able to write to the project,

00:29:56 they're able to run the code, make changes, change packages, whatever they want to do.

00:30:00 And when they sync and you sync, we deal with that Git operation of fetch, pull, merge, push. So,

00:30:09 you know, by clicking sync, we're doing all of that for you. And you'll see in the activity feed,

00:30:14 your changes interleave together as well. So you'll be able to scroll and see,

00:30:18 oh, they changed this package or they added this data set or whatever.

00:30:23 That's interesting. So if they like, they sync it down locally, they jump on a plane and they're

00:30:27 like working on the project. Maybe they change some of the code, they make some comments, they edit the

00:30:32 readme, whatever, and they get back and they push sync. It doesn't just sync like, well, here's their

00:30:37 commit message and their commit that actually goes into Git, but it actually syncs that activity back

00:30:43 in like a richer way.

00:30:45 Yeah, everything they did, you see.

00:30:47 Which, you know, is interesting. We have more features coming around this, particularly in the activity feed

00:30:53 around searching and filtering and changing views on that data because it's this rich set of information

00:30:58 that we've never really had, to be honest.

00:31:01 Yeah, like how are people expected to work with it? What questions do they have?

00:31:04 Right. So like a common one we want to be able to make real easy is like, give me all versions of like this figure

00:31:08 or this cell, you know, so you can see as things change visually instead of trying to somehow do

00:31:16 Git diffs over and over or something crazy, right?

00:31:19 Yeah, I like it a lot. The activity feed can get pretty busy because it has like executed cells

00:31:24 and stuff like that. But yeah, so maybe some filters for like important, whatever you deem important.

00:31:29 Like you guys just define important, like a figure was created or like code was changed or something like that.

00:31:34 Yeah, yeah. That's definitely something we're working on improving is the having a small lightweight model,

00:31:40 especially around text output of saying what's important, what's not and making that very streamlined.

00:31:45 So yeah, for sure. Let me think about this idea with you for a second here. One of the things that's

00:31:50 cool is it launches into JupyterLab, right? And JupyterLab is nice. It's sort of the premier way to do

00:31:55 Jupyter things these days, right? And it gives you more than just the notebook. It gives you like GUI access to the file system.

00:32:03 It gives you a terminal. It gives you like a markdown editor, other stuff like that, right?

00:32:08 So maybe I could fire up my project and I'm like, oh, I realize I need, I don't know, some library.

00:32:15 I need this version of OpenSSL or I need to install, I don't know, something that I've got to do on Linux.

00:32:22 Maybe I drop into the terminal, which you can do from Jupyter, right?

00:32:26 You can go and configure your environment and do all the things there, which is cool.

00:32:30 What's the right flow? So maybe I've done that. I've created a project and I'm like, oh, I had to drop into the terminal and do this.

00:32:36 Now I want to share this thing with people. What is the right way to sort of record that that happened?

00:32:45 Should I go back and make an equal change in like my Docker config on my project in Gigantum that would have had that effect of what I did in the terminal and then I could push that out?

00:32:56 Or do I create a new project and start over? Like what's the workflow there?

00:32:59 Yeah. If you go in and edit that runtime environment, you know, it's going to be lost effectively.

00:33:06 So you would have to go back to the Gigantum client and just go to the environment tab and add that package or whatever.

00:33:12 This is a really common thing we've heard is, you know, it's really annoying that you have to like remember to do that because that's a very common workflow.

00:33:21 It's like I'm doing in the middle of something. I don't know how to do something. I look on the Internet.

00:33:25 The Internet tells me what to do.

00:33:27 Yeah, exactly.

00:33:28 The Internet says install this package and I need to do that right now.

00:33:31 And that means I have to shut everything off because I need to edit this Docker container.

00:33:34 So that's something we're very much thinking about making a better experience of like being able to edit the runtime environment.

00:33:41 But then when you stop, have that edit persist back because it's so common and it's like such a common way that people drift their project.

00:33:50 Right. Like you you start all good at day one.

00:33:52 You write your requirements.txt file, but then you just like get into it and you drift.

00:33:57 Right. Right. Right. And it might not even be a Python thing.

00:34:00 It might be some apt install type of thing.

00:34:03 Right. Right. Or like I changed this environment variable in Linux so that it would work.

00:34:08 Right. And so how do we make that better?

00:34:10 We've got a bunch of ideas that we've you know, we're starting to work on and and we do.

00:34:15 You know, one thing that's been really fun in getting into this project is going from being this researcher mind of like just building tools to get it done to more like product development.

00:34:25 So like this is something we know we want to solve, but like we've got ideas, but maybe our ideas are wrong.

00:34:31 So we actually try to like do some user testing and that type of thing and like test it out before we build it.

00:34:36 So, you know, more complicated features like this where it's not obvious what the right answer is takes a little bit more time because you have to actually like not just build what you think because, you know, it's right.

00:34:47 So that's been that's been really fun and interesting.

00:34:49 It's definitely something we're going to be focusing on because we hear it.

00:34:51 You know, it's one of those things where people are like, man, this is really annoying.

00:34:54 And those are the things you want to try to fix.

00:34:56 You know, yeah.

00:34:57 Go where the pain is and solve it for people.

00:35:00 That stuff.

00:35:00 That's almost always a good business opportunity.

00:35:03 Right.

00:35:03 Yeah.

00:35:04 It sounds really hard to me, though.

00:35:05 Like, how do you capture what people randomly did as they flailed about on the command line in a terminal?

00:35:11 So I'm not really saying like you must do this.

00:35:14 I was just wondering like, OK, well, what is my proper if I were to correct my just bouncing around on the terminal?

00:35:21 What would I do in that platform?

00:35:23 Right.

00:35:24 Yeah.

00:35:24 Yeah.

00:35:24 And so it would be you'd have to go to the environment tab and edit it yourself.

00:35:27 But it's interesting because of these tight integrations and because of the, you know, the architecture of Jupyter and Jupyter Lab, which is really cool in that it's basically under the hood.

00:35:37 They've got this pub sub architecture.

00:35:39 So there's just messages flying around of like everything you're doing in the interface.

00:35:43 We can listen to those messages.

00:35:45 And that's how we're built this tight integration.

00:35:47 So that's how we know when you executed some cells and you produced a figure.

00:35:52 There's this under the hood in Jupyter, there's this pub sub architecture that's emitting messages that are containing what you're doing and containing the figure.

00:36:00 I mean, we're able to scoop all that up and analyze it.

00:36:03 And that's how this auto activity is happening.

00:36:04 I see.

00:36:05 OK, so you probably could capture like an apt install such and such.

00:36:08 Yeah.

00:36:08 Potentially, right?

00:36:09 I mean, yeah, maybe editing files is tricky.

00:36:11 But some of the command line options, yeah, for sure.

00:36:14 It seems like you could say, hey, it looks like you installed Nginx.

00:36:18 Did you really do that?

00:36:19 Because if you did, we're going to need to put that into the config for Docker because that's like a Linux wide thing that you need to have possibly to keep working the way you are.

00:36:28 Right.

00:36:28 Right.

00:36:28 Yeah.

00:36:28 Right.

00:36:29 Nice.

00:36:31 This portion of Talk Python to Me is brought to you by Tidelift.

00:36:34 Tidelift is the first managed open source subscription, giving you commercial support and maintenance for the open source dependencies you use to build your applications.

00:36:44 And with Tidelift, you not only get more dependable software, but you pay the maintainers of the exact packages you're using, which means your software will keep getting better.

00:36:53 The Tidelift subscription covers millions of open source projects across Python, JavaScript, Java, PHP, Ruby, .NET, and more.

00:37:00 And the subscription includes security updates, licensing, verification, and indemnification, maintenance and code improvements, package selection and version guidance, roadmap input, and tooling and cloud integration.

00:37:12 The bottom line is you get the capabilities you'd expect and require from commercial software.

00:37:17 But now, for all the key open source software you depend upon, just visit talkpython.fm/Tidelift to get started today.

00:37:25 Maybe we could talk a little bit about some of the projects you have on the website.

00:37:32 Actually, before that, let's take a step back.

00:37:34 So at the time of the recording, basically, your cloud is kind of like a synchronization, bookkeeping location, but you're just about to roll out the ability to run the code on the cloud as well.

00:37:47 If you don't want to install the client and run Docker, maybe just tell us what's the story around that.

00:37:53 And then I'm going to talk to you about some of the demo apps you got out there.

00:37:56 Sure.

00:37:56 Yeah.

00:37:56 So this has been a really big effort to basically, from the ground up, completely rebuilt our cloud platform for this big change.

00:38:03 And so what we're adding is when you sync a project to Gigantum.com, it now becomes much more interactive and rich.

00:38:12 You can preview files.

00:38:14 You can look at the notebooks.

00:38:15 You can see the activity.

00:38:16 All those sorts of really useful things right there just on the website.

00:38:20 But then you can also, like you said, you can click a button and launch that JupyterLab instance right there in the cloud.

00:38:26 And that's going to let people with zero install play with their projects, explore other people's projects.

00:38:33 You know, we've really found from talking to users, there's all different reasons you do different things.

00:38:39 And so, like, if you're just quickly looking at somebody's project or you see some link on Twitter and you're like, what is this thing?

00:38:45 And you look at the thing, you know, you're not going to then go install Docker on your laptop just to, like, see what the thing is.

00:38:51 Right.

00:38:51 And so, again, this idea of asymmetries and it's what you actually care about really brings that barrier down to being able to just click a button, play with somebody's code or, you know, do something real quick with your code and your data.

00:39:04 We also are going to allow some anonymous use as well because I think that's really useful to just be able to, like, I just don't need to sign up.

00:39:10 I don't need to log in.

00:39:11 I just want to see this thing real quick.

00:39:12 What is this?

00:39:13 And so that's going to be a big piece of it as well.

00:39:15 Right.

00:39:15 Maybe you just want to read it, but, like, it's got to execute it, right?

00:39:18 Like, you want to just see what is this thing?

00:39:22 I just want to see the output and maybe I just need to run it real quick to get fresh data or something like that, right?

00:39:27 Right.

00:39:27 And it's going to just let you do that right there, right there in the platform.

00:39:30 So we've been working real hard.

00:39:31 It's really interesting new stuff.

00:39:33 It's a mix of, you know, under the hood, Python and Go.

00:39:36 It's on Kubernetes.

00:39:37 It's the main orchestrator for all the containers and everything.

00:39:41 Yeah, okay.

00:39:42 That sounds really...

00:39:43 Very excited about it.

00:39:44 Yeah, that sounds very exciting.

00:39:45 It's a cool addition to the project.

00:39:47 You know, there are some places that will, like, give you this read-only executed view of these Jupyter Notebooks.

00:39:55 And honestly, I don't know how they work super reliably.

00:39:58 But there's things like Binder and there's...

00:40:01 Even if you go to GitHub, like, they'll run some Jupyter Notebooks for you there.

00:40:05 Mm-hmm.

00:40:05 It sounds to me like those can't have, like, a complete underlying environment configured for that notebook, I would guess.

00:40:13 Is that right?

00:40:14 For GitHub, they're doing, you know, kind of static rendering of the notebooks.

00:40:19 So if, you know, what's nice about Jupyter Notebooks, well, depending who you talk to, this is nice but also annoying sometimes, is, like, everything is in the notebook, right?

00:40:28 It's this big JSON document.

00:40:29 And all...

00:40:30 The last state of your notebook, if you ran your cells and you've got figures, it's there.

00:40:35 So you can run it through an awesome tool called NB Convert, which will turn it into, like, an HTML page, for example.

00:40:41 Yeah.

00:40:42 And then you can view it on the web.

00:40:43 So we do that on the website.

00:40:45 So you can view previewed notebooks.

00:40:47 And you mentioned Binder.

00:40:49 So Binder's a great tool that lets you take a Git repo and click it and execute it.

00:40:55 So it actually gives you a working Jupyter environment as long as you've configured your repository in a certain way and you've got all your package dependencies and all of that.

00:41:02 And so that actually gives you an interactive version, kind of similar to what we're doing, where you can get an interactive version.

00:41:07 You can actually edit.

00:41:08 I would say, like, kind of the one difference is because of how we build things, you know, to put it in Gigantum means that that environment's correct for that notebook.

00:41:17 So you'll be guaranteed to be able to run it, to render it.

00:41:20 And because we have that environment, especially like in R, to render some of the R notebooks for previews, you kind of need that actual environment as well.

00:41:28 Right.

00:41:29 So having that around, it makes it a little bit easier for us to be able to render these things for WebView.

00:41:34 Yeah.

00:41:36 Give me this project.

00:41:37 And you literally have everything set up in a Docker container, right?

00:41:41 Yeah.

00:41:41 Yeah.

00:41:41 Yeah.

00:41:42 Super cool.

00:41:42 Let's talk about some of the demo projects.

00:41:45 There's something just fun about going around nice written notebooks and just clicking through them and watching them do their magic.

00:41:52 So you guys have some of those up on the site.

00:41:55 Like you mentioned the Allen Brain Institute before about the measuring the millimeter Cuba brain.

00:42:01 You've got some stuff like that up there that people can explore, right?

00:42:04 They have an SDK, so they have like a little library you can install with Python.

00:42:07 It lets you access some of their data sets and visualize the data and play with it.

00:42:11 And so there's an example project that kind of shows you some examples of how to do that.

00:42:16 We have some other examples for doing things like transfer learning and some NLP tasks, some plotting.

00:42:23 So like a lot of people do, there's some great geospatial plotting libraries.

00:42:27 So we're working to kind of build some of these examples that are very obvious that, like you said, you're a new user.

00:42:33 You just want to get started, dip your toes in.

00:42:36 Sometimes that's hard to just, what do I even do?

00:42:39 Or what can I do?

00:42:40 Like I don't even know what's possible that I could do if I had the data and the skills, right?

00:42:45 Right.

00:42:45 So having something that you said is like organized nicely and simple, you can click, run, get your feel of what's going on.

00:42:51 We have a bunch of those going up as well.

00:42:53 Yeah.

00:42:54 Yeah.

00:42:54 Awesome.

00:42:54 We can put some links just in the show notes for people to check out.

00:42:57 So one thing I did want to talk to you about while we were on these things is I recently had the folks from Doc Assemble on.

00:43:06 And you probably don't know what Doc Assemble is, but Doc Assemble is a project.

00:43:12 It's a web app with a bunch of cool features for like a super advanced survey monkey type thing.

00:43:20 If I want to interview a bunch of people, collect the data, have a lot of flow control and only ask questions conditionally and so on.

00:43:27 There's a really cool project that does that.

00:43:29 And the way they, it's for mostly for lawyers, but it can be used for anything.

00:43:33 And the way they do that is they have one or more Docker containers that work together and they deliver those.

00:43:39 And some of the feedback I've got from multiple people was that's really awesome.

00:43:43 It's super hard for me to work with Docker.

00:43:46 This is not making it better.

00:43:48 It might be worse for me than installing, just installing like Postgres and Redis and Python.

00:43:58 Like this might actually be harder than those things, trying to get multiple containers to talk to each other and stuff.

00:44:02 So the reason I bring that up is it seems like what you all have done here is doing the same thing.

00:44:08 But the way that I experienced it as a user was, well, I have to have my system be Docker capable.

00:44:14 So I had to install Docker, the app.

00:44:16 And then I double clicked your app.

00:44:18 It gave me a cool progress bar, which took a minute or two.

00:44:21 And then it was working.

00:44:22 Right.

00:44:23 And that feels like a great way to use Docker.

00:44:24 So I don't know.

00:44:25 What are your thoughts on like trying to deliver products to users through Docker or shipping with Docker just in general?

00:44:33 What's your experience there?

00:44:34 Yeah, that's an awesome question because very early on, it was like something we kind of battled with for a bit and then made this decision like this is the way we want to go.

00:44:43 Right.

00:44:43 So you mentioned, you know, Conda as a way to package all your code and data.

00:44:48 You know, people use that a lot as a way to manage their environment.

00:44:51 And we were like, well, should we reinvent the wheel or should we go with something more complicated?

00:44:55 And it just really came down to not everything's in a package manager.

00:44:59 And you really the only real way is to right now that we see is you need to put everything in a container.

00:45:06 That's the only real way you'll be able to bundle everything up.

00:45:08 And then you go and you look at the space and Docker is the provides the easiest user experience for that.

00:45:15 And so that's the decision.

00:45:16 Right.

00:45:17 We're going to go with Docker.

00:45:18 And when we started this, the experience wasn't perfect, but we're kind of making this gamble that we're going to meet Docker when they're ready.

00:45:25 We'll be ready.

00:45:26 Right.

00:45:27 And so they've really been spending.

00:45:28 I'm going to schedule where the puck is and I'm pretty sure it's going to be in the place we want it to be.

00:45:32 So let's try that.

00:45:33 Absolutely.

00:45:33 That's definitely what happened.

00:45:35 And so we're feeling pretty good.

00:45:38 Like Docker desktop team, they've been doing an awesome job just building these tools, making them more robust.

00:45:44 Like they've been focusing super heavily on performance fixes because there were also disk IO problems with Docker on your laptop for a while.

00:45:52 So they've been working super hard on making those better, making the installation process better.

00:45:56 And so we think, you know, if a user can get Docker installed on their laptop, we can, they don't know how to need to know how to use Docker, how to make everything work.

00:46:04 We can do that.

00:46:05 Right.

00:46:05 But it's just, can we get Docker on their laptop?

00:46:08 And so we've been testing with that recently because we didn't actually think that was an issue at first.

00:46:15 It's one of those things like it's an afterthought for you to install Docker.

00:46:19 So why would people have problems doing this?

00:46:20 And that's like so flawed.

00:46:21 Right.

00:46:22 It's something that no one even did.

00:46:23 The user might even know what Docker is.

00:46:25 And you're like, hey, go install this crazy thing.

00:46:27 So what we've recently been working on is we've this new version of our desktop application, which is very lightweight.

00:46:33 You double click this thing.

00:46:35 It helps you install Docker and answer.

00:46:39 The other thing, too, we found a lot of users just have questions like, why do I need Docker right now?

00:46:43 How much disk space?

00:46:45 What is this thing doing?

00:46:46 So even just like right there as they're walking through the Docker install process, let them know what's going on, help them do it.

00:46:52 And then there's nothing to worry about.

00:46:54 And so that's kind of this handholdy approach where we like we tell you what to do.

00:47:00 And then since we're on the computer already, we can wait until you've done it.

00:47:03 Like until you actually install Docker, we know you haven't installed it yet.

00:47:07 And as soon as it's working, we're like, great.

00:47:09 Now we need to adjust your memory and your CPU to make it work right.

00:47:12 And then we can do that for you.

00:47:14 Right.

00:47:14 Instead of having to read, you know, our previous installation process was like, it's easy.

00:47:18 It's three steps.

00:47:20 And then you click on it and like step one expands to like this bulletin list.

00:47:23 And you're like, well, it doesn't seem very easy.

00:47:25 Right.

00:47:25 And that's not just three.

00:47:26 And that's really.

00:47:27 Yeah.

00:47:28 So really, it's about that.

00:47:30 You know, I do think that delivering this application in a Docker container is an interesting way to do it and the right way to do it right now.

00:47:37 It lets us also like we deliver our application in a container as well.

00:47:42 But it's just really just working on the ergonomics a bit about around the installation process and making it very streamlined and kind of a closed loop.

00:47:51 This is what we've been trying to do with our desktop application.

00:47:53 It's not like follow these instructions.

00:47:55 It's like we're here.

00:47:56 Let's get from A to B.

00:47:57 And once we get there, then there's nothing to worry about.

00:48:00 Yeah, I think it's a pretty polished process.

00:48:02 And it worked pretty seamlessly for me.

00:48:04 So, yeah, nice work on that one.

00:48:07 One thing I do want to talk to you about on this, of course, is business models, lock-in, things like this, right?

00:48:14 Because what you guys are building is really cool.

00:48:16 However, when I go to the site, it's in beta mode and it doesn't have like a pricing.

00:48:22 And it doesn't have an obvious way that I'm going to get charged.

00:48:27 So I always wonder about companies when there's, is it going to be a paid product?

00:48:32 Is it going to have like a premium angle?

00:48:35 Just, you know, just give us a sense of like where you guys are going as a business.

00:48:38 Because not just is it interesting as a user, but as just observers of the open source space, how are companies doing open source plus business, I think is an interesting view.

00:48:49 This was, again, one of these conscious decisions where like we think we can do this way because it'll help us keep this whole endeavor sustainable.

00:48:59 And we're living in this world of like movie pass a bit where just free money is just given away, you know, freely.

00:49:07 And we really wanted to build something that we hope we can make sustainable by actually trying to build a company around it instead of just an open source project.

00:49:15 So that was kind of why we did it this way in terms of like how would we plan to monetize the core platform, the core piece, this client, like all that stuff, MIT license, free forever.

00:49:26 So we're not like going to try to ever charge for use.

00:49:29 You know, you working on your on your local system.

00:49:32 It's like it's yours, whatever.

00:49:33 Right.

00:49:33 Where the monetization is going to come in.

00:49:35 You have a six core laptop.

00:49:36 So we're going to charge you $10 per core per month.

00:49:40 It's like, no, what is this?

00:49:41 This is not Oracle.

00:49:42 Exactly.

00:49:43 This is not Oracle.

00:49:44 Yeah, that's like the motto, right?

00:49:46 Okay.

00:49:47 So the desktop experience is basically going to be free.

00:49:50 Is that my hand in that right?

00:49:52 Correct.

00:49:52 Okay.

00:49:52 And also, like I said, you can run that desktop experience.

00:49:55 You can also run that on your own Amazon, GCP, DigitalOcean, Azure, whatever it's or, you know, you need more compute horsepower.

00:50:03 It runs on whatever you put it on.

00:50:06 Right.

00:50:06 So that's free forever.

00:50:07 Our hub that where you sync to, there's always going to be this free tier where we're going to allow you to store, you know, something like five gigs for free.

00:50:15 Get a certain amount.

00:50:16 If you sign up, you get a certain amount of compute per month.

00:50:20 That'll kind of be like a refreshing quota every month that you can just poke around for free.

00:50:24 And then there'll be like a little bit of a tiering on that.

00:50:27 That's when you actually end up paying.

00:50:28 So if you need to store 50 gigs, 100 gigs, whatever, you'll have to, you know, pay a little bit of money per month for that.

00:50:34 And then there'll be an on-prem enterprise offering.

00:50:38 This idea where people want to use this, but they've got restrictions because, and this is moving more out of academia towards like industry a bit.

00:50:47 But like, you know, you can't put your data in somebody else's cloud for whatever reason, whatever.

00:50:51 You want to control everything.

00:50:52 Sure.

00:50:53 Similar to like GitHub Enterprise, that kind of model and customer base.

00:50:58 Correct.

00:50:58 Very similar to that.

00:50:59 Okay.

00:51:00 And so that's the plan for, you know, monetization of the platform.

00:51:03 With, you know, our goal to our core, right, is to try to make this as an effective tool for people to use that, you know, isn't something that you get locked into.

00:51:14 And then you screw it.

00:51:15 I guess that's a good place to talk about like lock-in.

00:51:17 Fundamental principle kind of as we built this, right, is this under the hood, if you look at what's going on, it's just a bucket.

00:51:25 It's just files.

00:51:26 It's just a repository, right?

00:51:28 We don't have some complicated database that you have to export your stuff out of.

00:51:34 Like, we're built on top of Git, built on top of Docker.

00:51:37 You know, we've built our custom extensions on top of it that you do not need.

00:51:41 So if you want to take your stuff and pull it out of Gigantum, like you click the export button, all we're doing is just zipping up the thing and giving it to you as a single archive, right?

00:51:51 But you can go in your file system, take your files out, take your Docker file out, and do whatever you want with it.

00:51:57 So there is no real lock-in in that sense.

00:52:00 We're keeping it all built on top of these standard tools.

00:52:04 It sounds really good.

00:52:05 And so I'm looking at my home directory in my MacBook here, and I see a Gigantum folder and then my username and then more username and then probably my Gigantum username.

00:52:17 And then lab books and other things that are basically the projects that you guys have.

00:52:24 And it looks like you just get cloning that stuff into those subdirectories even, right?

00:52:28 So I have  and the file formats are things like Jupyter Notebooks and text files and whatnot, right?

00:52:33 So I could just take those and run with them if I wanted.

00:52:36 I mean, you would lose the activity stream and collaboration, but you would still  you could just grab the files and go if you need to, right?

00:52:42 Absolutely, yeah.

00:52:43 And so you'll see how we've done this activity, this  you know, the thing that's the rich layer on top.

00:52:48 It's really built on top of the Git log.

00:52:51 So, you know, when you do Git commit and you type a message, that message is getting written into the Git log.

00:52:56 And so what we are doing is we're auto-generating that message.

00:52:59 And then if you'll see, there's kind of like a new line, and then there's some cryptic messages below that, some like random text.

00:53:05 And those are pointers into this like Git compliant data store we've built.

00:53:10 And so you can lose that extra rich metadata of like the figures that were extracted and stuff like that.

00:53:16 But at the end of the day, every Git message is still there.

00:53:20 The history is still there.

00:53:21 It's just you lose a little bit of the automation, a little bit of like the rich history if you pull it out.

00:53:26 But it's trivial to pull out.

00:53:28 And that's kind of  was intentional.

00:53:29 Sure, that's cool.

00:53:30 So if people want to try it out and they use it and they decide, well, I don't want to necessarily be committed to this thing, they could take their code and run, it sounds like.

00:53:38 Yep, absolutely.

00:53:39 It's not like a Gigantum notebook that's not really a Jupyter notebook underneath or something.

00:53:45 Right.

00:53:45 One of these principles is we just wanted to keep it as close as possible to the originals, you know, these core technologies.

00:53:51 We want to get out of your way, you know, and let people just click a button, get into Jupyter, get in our studio, do what they're used to.

00:53:58 Don't try to really change these flows too much.

00:54:01 That's cool.

00:54:01 As maybe a Git power user, maybe I like really want my stuff in GitHub in some project there, even if that's not the primary.

00:54:09 It's not a primary source, but like kind of a copy in Git.

00:54:11 Would it be reasonable to drop into that local Git repository that Gigantum is creating and then create a new origin, like a remote branch and push to that one?

00:54:21 Do I just get it up to  Yeah, you could definitely do that.

00:54:24 The only thing to keep in mind there is because we are doing Git LFS.

00:54:27 So if you've got a lot of LFS data, it's going to use LFS to push that to GitHub and GitHub charges you for LFS.

00:54:35 Right.

00:54:36 So that's kind of the one thing to think about if you want to try to do a mirror to GitHub is that they might start charging you money at some point for your usage there.

00:54:44 I think it's one gigabyte tree or something like that.

00:54:46 Okay.

00:54:46 But in general, I could mirror it to another Git repository and periodically sync that if I wanted, right?

00:54:53 Absolutely.

00:54:53 Yeah, I like that.

00:54:54 That's a pretty not super locked in lock-in story.

00:54:57 I like it.

00:54:58 That's the goal.

00:54:58 You know, we want to make it easy to pull stuff in to Gigantum.

00:55:02 We also want to make it easy to push stuff out, right?

00:55:04 Like the idea of building these walled gardens is kind of where the data science world has gone a bit with these massive cloud-only platforms.

00:55:12 There's only so much utility to that.

00:55:15 Again, if you want to work with somebody who doesn't have access to that thing or doesn't want to use it, right?

00:55:20 So being able to  even if you lose some capability, like being able to move things around is just in everybody's best interest.

00:55:26 Yeah.

00:55:26 Something that really bothers me a lot, I don't know.

00:55:30 It might be that I don't go to like a giant office building that has like a floor with a bunch of cubicles and I sit down and want to work and that's how I work.

00:55:37 But like I work more sort of freely as I like roam about throughout my life, right?

00:55:43 Like, you know, I might decide I want to go to a coffee shop because I'm tired of being at my house totally alone.

00:55:47 And I'm going to go crazy, right?

00:55:50 But the thing that I think drives me crazy about a lot of the cloud stuff, and I'm not thinking just the notebooks, but also like AWS or Azure.

00:55:58 If you're like bound in deeply into all those services, like working disconnected on an airplane, at a conference, on a business trip, at a coffee shop, it's super hard to like just keep working, right?

00:56:10 But it sounds like what you guys have here is like I could go and go on a camping trip and do some data science if that's how I want to disconnect and come back and it would totally work, right?

00:56:20 Yeah, you come back, connect to the internet, click sync, and there you go.

00:56:23 I really like that.

00:56:24 I think that's quite a compelling option actually.

00:56:26 So super, super cool.

00:56:28 Let me just ask you something really quick.

00:56:29 We don't have a ton of time to spend on it, but you get to see a lot of folks.

00:56:33 And maybe that's also another final question is who is this for?

00:56:38 If I am a professional data scientist at an insurance company, is this for me?

00:56:43 If I am a professor, is it for me?

00:56:46 If I'm teaching a class, is it for my students, right?

00:56:49 Who is this for?

00:56:49 Today, I would say because of what we have, it's maybe not for like you at an insurance company yet because they do need these very enterprise-y features we haven't built yet, right?

00:57:00 So it's really, you know, that's where we went ahead because we think that's, you know, a huge space where data science is kind of taking over industry like it is everywhere, right?

00:57:08 But right now, you know, if you're a student, if you're someone who wants to get into data science, you know, if you do data science for research, academic research, publishing, you know, this is kind of the core people we've been working with to start.

00:57:22 We have one of the co-founders, Randall Burns, is he's a computer science, chair of computer science at Johns Hopkins.

00:57:28 And he, you know, he ran a course inside Gigana.

00:57:31 And we learned a lot from that.

00:57:32 We've kind of made some changes.

00:57:34 Like running courses certainly is reasonable because you can deliver to your students both like notebooks, but also the environment, right?

00:57:42 And they don't have to install stuff.

00:57:44 It seems like it would be really good for teachers actually, you know, assuming there's enough teachers on Docker.

00:57:48 Yeah.

00:57:49 Yeah.

00:57:49 That's definitely, you know, target audience.

00:57:52 But right now, you know, users have been very academic focused, but we've started to get lots more in smaller industry, you know, commercial interests because it's just a different way of doing things.

00:58:04 And it's like a bunch of small teams working distributed, you know, just kind of set up to support that.

00:58:10 So we're definitely thinking about moving there and building things, you know, more for kind of like an enterprise-y use case.

00:58:17 But, you know, for today, it's really if you're doing something in Jupyter, you're doing something in our studio, we think we can make that easier basically.

00:58:24 That's cool.

00:58:25 All right.

00:58:26 Well, it seems like you've built a pretty cool environment and I like it.

00:58:30 Let me just ask you really quick.

00:58:31 What are some of the trends you see in data science and scientific computing?

00:58:35 Because you're interacting with all these different folks from these different environments.

00:58:39 Like, what should people maybe be paying attention to in that space?

00:58:42 Yeah.

00:58:43 So we see a lot of interesting stuff and it's definitely changed over the course even of us starting this project.

00:58:49 One thing that's very obvious, at least from our users and all the people we talk to, is this really this move towards the open source languages, right?

00:58:58 It's Python.

00:59:00 It's R.

00:59:01 It's much less MATLAB, right?

00:59:04 It's these things people are moving.

00:59:06 And it's because the communities are there.

00:59:09 The tooling is there.

00:59:11 The libraries are there.

00:59:12 I believe it's been interesting to see.

00:59:15 And so that's kind of also a conscious decision for us is that's what we're supporting right now.

00:59:18 Like we don't support, you know, MATLAB out of the box.

00:59:21 We don't support SAS or some of these other things because not running through a web app is hard, but also dealing with licensing is hard.

00:59:29 And we're just seeing people more and more be like, yeah, this is hard.

00:59:34 And I can get this great environment in Python, this great ecosystem of tools and this great community of support.

00:59:40 And so I think as you see increasingly more and more stuff getting published that's built on Python tooling and R tooling.

00:59:48 And that's been really, really apparent.

00:59:51 Yeah, that's great.

00:59:52 Another thing that we're starting to see a lot more of and it's something we were obviously like predicting a bit, not necessarily predicting, but banking on, right, is this idea of hybrid architecture in terms of, yeah, you use the cloud a bit, but you also have local resources that you want to run your compute on.

01:00:09 And we're seeing people want this more and talk about it now as if it's like this great idea.

01:00:13 And if anybody really starts doing like legit machine learning, like deep learning where you're training a lot, like you very quickly realize how expensive GPUs are to use in the cloud.

01:00:26 I mean, if you're paying, like if someone's paying the bill for you, you don't notice, or if you got a bunch of credits, you don't notice.

01:00:32 But like eventually you realize that, wow, this is really expensive.

01:00:37 And so we're starting to see a lot of people that got started doing their machine learning in the cloud because it was so easy.

01:00:44 And then they realize it's really expensive.

01:00:46 And so they're buying GPUs.

01:00:47 And this is also kind of crazy to, you know, there's some interest, like Lambda Labs is an interesting company in the US that's building GPU boxes, like workstations.

01:00:55 And, you know, but there's not much around this like turnkey GPU local thing, but it's people are, I think, want that because it's expensive.

01:01:04 And it changes the psychology a bit of doing your work, I think.

01:01:08 When you're not worried about paying for every cycle, it changes how you work, right?

01:01:14 So I'm definitely thinking that's going to be a larger trend.

01:01:17 I think the cloud is this great thing that gives us all these awesome capabilities.

01:01:22 But I do think this, at least for the near future, it's going to be, you know, we have so much compute power locally.

01:01:28 It's, you know, you're going to want to run distributed.

01:01:31 You're going to have jobs you want to run on your laptop.

01:01:33 You're going to have jobs you're going to want to run on a server.

01:01:35 You have jobs you're going to run in the cloud.

01:01:37 And we just want to make that easier.

01:01:38 And we see that being a trend.

01:01:40 Yeah, my laptop has a core i9 with six cores.

01:01:43 Each hyperthread is a 12 and 32 gigs of RAM.

01:01:47 Like that probably solves most people's computational problems unless you're doing like truly big data or massive machine learning.

01:01:54 Yeah.

01:01:54 Right.

01:01:55 And it's like, especially with some of these great libraries that are coming out and Dask and all the stuff that like Rapids, all these things.

01:02:01 It's just like you have all this power, but you're using your 12 cores to run Chrome, right?

01:02:08 Like that's what if you want to use a cloud platform, I mean, you may need some of most of those cores to run Chrome.

01:02:13 But like that's like the value proposition people are being sold as.

01:02:17 And I think, you know, right size for the right job is going to be the way that people are going to go because they're going to realize as more and more stuff gets more and more computationally intensive in all these different fields and all these different industries.

01:02:30 You know, not everybody has incredible amounts of money to just, you know.

01:02:34 Yeah.

01:02:34 It totally makes sense.

01:02:35 Now, are you guys thinking you're going to have this run it in the cloud for free thing?

01:02:39 Are you thinking of having a premium offer there?

01:02:41 Like I really do need to run this on a GPU for an hour.

01:02:44 Can I just push a button into your platform and make that happen and pay you $10 or like what are you thinking there?

01:02:49 Yeah.

01:02:50 So right now at launch, not yet.

01:02:53 That's something we're definitely playing with and trying to learn how people want that to work.

01:02:59 I think that's the kind of why we built some of this was, you know, also some of the some cloud platforms, this pricing model of, you know, I pay the same thing every month forever.

01:03:09 It's not really how people work either.

01:03:11 They need bursts of compute because they're late for a paper deadline or they're running something now.

01:03:16 But then they're like not doing data science for a month because their job is like more than just that.

01:03:20 Right.

01:03:20 And so, yeah, how can we provide that in a good way is something we're playing with for sure.

01:03:25 And then making that easy to being able to like scale up without having no anything.

01:03:29 If you know how to do your own Amazon stuff, then you could do it yourself.

01:03:32 But sometimes, yeah, it's just can I click a button and solve this problem and go away is what people want.

01:03:38 So sure.

01:03:39 Yeah.

01:03:39 And I guess if they're right there in your platform, they can click a button.

01:03:41 You would want to make that possible.

01:03:43 But no, it sounds like a great platform.

01:03:44 And I like the sort of trend back towards like I can mostly work local, but not always.

01:03:49 All right.

01:03:50 So I think we'll leave it there for the data science gigantum conversation.

01:03:54 It's been really interesting.

01:03:55 But before you get out of here, let me ask you the final two questions.

01:03:57 If you're going to write some Python code, what editor do you use?

01:04:00 I use PyCharm.

01:04:01 We like PyCharm a lot.

01:04:03 I especially like, you know, started using PyCharm a long time ago.

01:04:06 So I've just always used that really.

01:04:08 I know a lot of there's a lot of VS Code love right now, but I do love PyCharm.

01:04:13 And their Docker integration has been really convenient for us, too, because, you know, we're building in Docker.

01:04:18 And so what's real nice is we've got like all of our build tooling.

01:04:21 So our application that runs in Docker, you know, I didn't have PyCharm connect to that.

01:04:27 So when you run a test or want to debug code, you're running it in the actual productionally built, you know, container and everything.

01:04:34 So that's real, real convenient.

01:04:36 So we enjoy that a lot.

01:04:37 That's a good one.

01:04:38 The notable PyPI package?

01:04:40 Recently, I've been using a new, we use GraphQL for our APIs.

01:04:44 That's a way to write an API that is really interesting.

01:04:48 And so Graphene is the big library we've been using a lot.

01:04:50 But I started using a new one recently called Ariadne, which is a schema first GraphQL library, which I like a lot.

01:04:57 So you write your schema and it like makes it real easy to just wire everything up.

01:05:01 And it's all asynchronous, which I've been playing a lot with.

01:05:04 That sounds cool.

01:05:05 I love all the new Python 3.

01:05:07 I've been really getting into a lot of the asynchronous Python and typing and like mypy.

01:05:11 All that stuff has been awesome.

01:05:13 So I like this library a lot.

01:05:15 I've been playing with it a lot lately.

01:05:16 So it's been good.

01:05:17 Oh, that's a good recommendation.

01:05:17 And I hadn't heard of it.

01:05:18 Awesome.

01:05:18 All right.

01:05:19 Well, Dean, final call to action.

01:05:21 People want to check out Gigantum and this kind of stuff.

01:05:23 What do you say to them?

01:05:24 Just, you know, gigantum.com.

01:05:26 Check that out.

01:05:27 That's where you go to learn about what it is, to explore people's projects, to just click a button and try it out.

01:05:33 It's kind of a place to go.

01:05:35 Right on.

01:05:36 All right.

01:05:37 Well, thanks for sharing what you guys are up to.

01:05:39 It's been good to talk to you.

01:05:40 Yeah.

01:05:40 Thanks so much.

01:05:40 It's been great.

01:05:41 You bet.

01:05:41 Bye.

01:05:41 This has been another episode of Talk Python to Me.

01:05:46 Our guest on this episode was Dean Klysis.

01:05:48 And it's been brought to you by Linode and Tidelift.

01:05:50 Linode is your go-to hosting for whatever you're building with Python.

01:05:55 Get four months free at talkpython.fm/linode.

01:05:58 That's L-I-N-O-D-E.

01:06:01 If you run an open source project, Tidelift wants to help you get paid for keeping it going strong.

01:06:06 Just visit talkpython.fm/Tidelift, search for your package, and get started today.

01:06:11 Want to level up your Python?

01:06:14 If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

01:06:19 Or if you're looking for something more advanced, check out our new async course that digs into

01:06:23 all the different types of async programming you can do in Python.

01:06:27 And of course, if you're interested in more than one of these, be sure to check out our

01:06:31 Everything Bundle.

01:06:31 It's like a subscription that never expires.

01:06:33 Be sure to subscribe to the show.

01:06:35 Open your favorite podcatcher and search for Python.

01:06:38 We should be right at the top.

01:06:39 You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:06:44 and the direct RSS feed at /rss on talkpython.fm.

01:06:48 This is your host, Michael Kennedy.

01:06:50 Thanks so much for listening.

01:06:51 I really appreciate it.

01:06:52 Now get out there and write some Python code.

01:06:54 I'll see you next time.

