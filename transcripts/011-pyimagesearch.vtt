WEBVTT

00:00:00.001 --> 00:00:02.540
Does a computer see in color or black and white?

00:00:02.540 --> 00:00:06.700
It's time to find out on episode 11 of Talk Python to Me

00:00:06.700 --> 00:00:08.960
with our guest, Adrian Rosebrock,

00:00:08.960 --> 00:00:12.040
recorded Thursday, May 20th, 2015.

00:00:12.040 --> 00:00:42.020
Welcome to Talk Python to Me.

00:00:42.020 --> 00:00:45.160
A weekly podcast on Python, the language, the libraries,

00:00:45.160 --> 00:00:47.000
the ecosystem, and the personalities.

00:00:47.000 --> 00:00:48.840
This is your host, Michael Kennedy.

00:00:48.840 --> 00:00:51.380
Follow me on Twitter where I'm @mkennedy

00:00:51.380 --> 00:00:54.000
and keep up with the show and listen to past episodes

00:00:54.000 --> 00:00:55.900
at talkpythontome.com.

00:00:55.900 --> 00:00:58.820
This episode, we'll be talking with Adrian Rosebrock

00:00:58.820 --> 00:01:03.240
about computer vision, OpenCV, and PyImage Search.

00:01:03.240 --> 00:01:05.740
Hello, everyone.

00:01:05.740 --> 00:01:08.780
I have a bunch of cool news and announcements for you this week.

00:01:08.940 --> 00:01:11.960
First, this show on PyImage Search

00:01:11.960 --> 00:01:13.760
is a listener-suggested show.

00:01:13.760 --> 00:01:16.180
Thank you to J.I. Lorenzetti

00:01:16.180 --> 00:01:18.660
for reaching out to me and suggesting this topic.

00:01:18.660 --> 00:01:21.100
You can find his contact details in the show notes.

00:01:21.100 --> 00:01:24.900
As always, I'm also excited to be able to tell you

00:01:24.900 --> 00:01:27.680
that this episode is brought to you by CodeShip.

00:01:27.680 --> 00:01:30.980
CodeShip is a platform for continuous integration

00:01:30.980 --> 00:01:33.060
and continuous delivery as a service.

00:01:33.060 --> 00:01:36.000
Please take a moment and check them out at codeship.com

00:01:36.000 --> 00:01:38.440
or follow them on Twitter where they're at codeship.

00:01:38.440 --> 00:01:42.020
Did you know that most of our shows come with full transcripts

00:01:42.020 --> 00:01:43.900
and a cool little search filter feature?

00:01:43.900 --> 00:01:46.480
If you're looking for something you hear in an episode,

00:01:46.480 --> 00:01:49.000
just click the full transcript button on the episode page

00:01:49.000 --> 00:01:49.960
and search for it.

00:01:49.960 --> 00:01:52.360
Also, I want to say thank you to everyone

00:01:52.360 --> 00:01:55.180
who has been participating in the conversation on Twitter

00:01:55.180 --> 00:01:56.840
where we're at Talk Python.

00:01:57.580 --> 00:02:00.140
It's a great feeling to see all the feedback and thoughts

00:02:00.140 --> 00:02:01.700
every week when we release a new show.

00:02:01.700 --> 00:02:04.420
But if you have something more nuanced to say

00:02:04.420 --> 00:02:06.380
that doesn't fit in 140 characters

00:02:06.380 --> 00:02:09.420
or you want it to be more permanent than Twitter,

00:02:09.420 --> 00:02:13.560
every episode page has a Discus comment section at the bottom.

00:02:13.560 --> 00:02:15.140
I encourage you to post your thoughts there.

00:02:15.140 --> 00:02:18.880
This week, I ran across a really awesome GitHub project

00:02:18.880 --> 00:02:20.520
called Python-Patterns.

00:02:20.520 --> 00:02:22.700
You can find it at github.com

00:02:22.700 --> 00:02:26.460
slash f-a-i-f slash python dash patterns.

00:02:26.460 --> 00:02:29.900
It's a collection of really crisp design patterns

00:02:29.900 --> 00:02:31.760
implemented in a Pythonic manner.

00:02:31.760 --> 00:02:34.060
For example, you'll find patterns such as

00:02:34.060 --> 00:02:37.100
the adapter, builder, chain, decorator, facade,

00:02:37.100 --> 00:02:39.260
and flyweight patterns, just to name a few.

00:02:39.260 --> 00:02:41.180
It's really extensive and pretty cool.

00:02:41.180 --> 00:02:42.860
I think you'll learn something if you check it out.

00:02:42.860 --> 00:02:45.900
Finally, I put together a cool YouTube playlist.

00:02:45.900 --> 00:02:50.620
This is a series of nine lectures from Dr. Philip Gao,

00:02:50.620 --> 00:02:53.240
a professor at the University of Rochester, New York.

00:02:53.240 --> 00:02:58.520
Find him on Twitter where he's at P-G-B-O-V-I-N-E, P-G-Bovine.

00:02:58.520 --> 00:03:01.960
The video series is entitled C Internals,

00:03:01.960 --> 00:03:05.800
a 10-hour code walk through the Python interpreter source code.

00:03:05.800 --> 00:03:10.520
You can find it at bit.ly.com slash cpythonwalk,

00:03:10.520 --> 00:03:12.720
all lowercase, no spaces.

00:03:12.720 --> 00:03:15.580
Also, you'll find all these links in the show notes.

00:03:16.520 --> 00:03:18.780
Now, let's get to the interview with Adrian.

00:03:18.780 --> 00:03:23.800
Let me introduce Adrian.

00:03:23.800 --> 00:03:28.460
Adrian Rosebrock is an author and blogger at pyimagesearch.com.

00:03:28.460 --> 00:03:32.800
He has a PhD in computer science with a focus on computer vision and machine learning

00:03:32.800 --> 00:03:36.020
and has been studying computer vision his entire adult life.

00:03:36.020 --> 00:03:41.720
He has consulted for the National Cancer Institute to develop methods to predict breast cancer risks

00:03:41.720 --> 00:03:48.080
using breast histology images and authored a book, Practical Python and OpenCV,

00:03:48.080 --> 00:03:52.400
on utilizing Python and OpenCV to build real-world computer vision applications.

00:03:52.400 --> 00:03:56.200
Adrian, welcome to the show.

00:03:56.200 --> 00:03:57.060
Oh, thank you.

00:03:57.060 --> 00:03:58.000
It's great to be here.

00:03:58.180 --> 00:04:04.420
I'm very excited about computer vision and sort of merging the real world with computer science,

00:04:04.420 --> 00:04:05.320
with robotics.

00:04:05.320 --> 00:04:07.920
And I think there's just some really neat stuff going on.

00:04:07.920 --> 00:04:10.320
And you're doing a very cool part in that.

00:04:10.320 --> 00:04:11.120
Oh, thank you.

00:04:11.120 --> 00:04:13.340
So we're going to talk about PyImageSearch.

00:04:13.340 --> 00:04:18.600
We're going to talk about OpenCV and some of the challenges and even the future of these types of technologies.

00:04:18.600 --> 00:04:22.940
But before we get there, you know, everyone's interested in how people got started in programming and Python.

00:04:22.940 --> 00:04:23.680
What's your story?

00:04:23.680 --> 00:04:27.400
I started programming when I was in high school.

00:04:27.400 --> 00:04:33.380
I started out with the basics of HTML, JavaScript, CSS, did some basic programming.

00:04:33.380 --> 00:04:36.140
And, you know, I'm probably getting a lot of hate mail about this.

00:04:36.140 --> 00:04:41.960
But when I first started learning how to program, I did not like the Python programming language that much.

00:04:41.960 --> 00:04:45.560
And this was around the early version 2 of Python.

00:04:45.740 --> 00:04:47.760
I didn't like the syntax.

00:04:47.760 --> 00:04:49.420
I didn't like the white space.

00:04:49.420 --> 00:04:52.880
And for a long time, I was really, really put off by Python.

00:04:52.880 --> 00:04:55.640
And that was a huge mistake on my part.

00:04:55.640 --> 00:04:57.120
I don't know what was wrong with me back then.

00:04:57.120 --> 00:04:59.340
I guess it was just high school ignorance or something.

00:04:59.340 --> 00:05:04.620
But by the time I got to college, I started working in Python a lot more.

00:05:04.620 --> 00:05:07.500
And that's especially true in the scientific area.

00:05:07.500 --> 00:05:15.340
You see all these incredible packages in Python like NumPy and SciPy that just integrate with computer vision and machine learning.

00:05:15.660 --> 00:05:17.480
And all other types of libraries.

00:05:17.480 --> 00:05:25.060
And more and more people were transitioning over from languages like MATLAB to languages like Python.

00:05:25.060 --> 00:05:26.440
And that's so cool.

00:05:26.440 --> 00:05:30.580
And it really wasn't until college that I got into Python.

00:05:30.580 --> 00:05:32.740
And I remember this one girl.

00:05:32.740 --> 00:05:34.260
She was in my machine learning class.

00:05:34.260 --> 00:05:38.740
And she had a sticker on the back of her laptop that said, Python will save the world.

00:05:38.900 --> 00:05:40.780
I don't know how, but it will.

00:05:40.780 --> 00:05:42.460
And that resonated with me.

00:05:42.460 --> 00:05:44.600
I'm like, that sticker's true.

00:05:44.600 --> 00:05:46.540
That is absolutely true.

00:05:46.540 --> 00:05:48.520
It's such a great language.

00:05:48.520 --> 00:05:52.060
So unfortunately, I did not have the best first experience with Python.

00:05:52.060 --> 00:05:55.900
It took me four or five years later to actually come around.

00:05:56.120 --> 00:05:58.560
But now that I'm here, I love it.

00:05:58.560 --> 00:06:01.200
And I can't imagine programming in any other language.

00:06:01.200 --> 00:06:07.320
It's almost a freeing feeling, a relaxing zen when you're coding in Python.

00:06:07.320 --> 00:06:09.560
Yeah, that's a funny story.

00:06:09.560 --> 00:06:11.360
It really is a wonderful language.

00:06:11.940 --> 00:06:13.840
I also took a while to get there.

00:06:13.840 --> 00:06:16.960
But looking back, I would have enjoyed being there sooner.

00:06:16.960 --> 00:06:21.020
I went from MATLAB to C++ on Silicon Graphics machines.

00:06:21.020 --> 00:06:23.960
So I had a bit of a torturous introduction.

00:06:23.960 --> 00:06:24.760
But it was all good.

00:06:24.760 --> 00:06:41.120
CodeShip is a hosted, continuous delivery service focused on speed, security, and customizability.

00:06:41.260 --> 00:06:46.920
You can set up continuous integration in a matter of seconds and automatically deploy when your tests have passed.

00:06:46.920 --> 00:06:50.160
CodeShip supports your GitHub and BitBucket projects.

00:06:50.160 --> 00:06:52.940
You can get started with CodeShip's free plan today.

00:06:52.940 --> 00:06:55.080
Should you decide to go with a premium plan,

00:06:55.080 --> 00:07:01.460
Talk Python listeners can save 20% off any plan for the next three months by using the code TALKPYTHON.

00:07:01.460 --> 00:07:03.160
All caps, no spaces.

00:07:03.160 --> 00:07:05.800
Check them out at CodeShip.com.

00:07:05.800 --> 00:07:10.500
And tell them thanks for sponsoring the show on Twitter where they're at CodeShip.

00:07:10.580 --> 00:07:24.200
So you're focused on computer vision and image processing.

00:07:24.200 --> 00:07:25.900
Where did that story begin?

00:07:25.900 --> 00:07:29.120
That story also started in high school.

00:07:29.360 --> 00:07:33.680
Originally, I had this idea that I wanted to go work for Adobe.

00:07:33.680 --> 00:07:37.740
And I wanted to work on developing Photoshop and Illustrator.

00:07:37.740 --> 00:07:42.660
I love the idea of being able to write code that could analyze an image.

00:07:42.660 --> 00:07:46.820
And for whatever reason, that just like really captured my imagination.

00:07:47.240 --> 00:07:49.920
I could see these algorithms running in Photoshop.

00:07:49.920 --> 00:07:52.860
And I was like, you know, what's really going on behind the scenes?

00:07:52.860 --> 00:07:54.520
Like, how are they manipulating these images?

00:07:54.520 --> 00:07:56.020
What does this code look like?

00:07:56.020 --> 00:08:01.880
So for the longest time, I really wanted to develop these graphic editing applications.

00:08:02.280 --> 00:08:07.080
But I didn't have the math experience.

00:08:07.080 --> 00:08:11.600
This may surprise some people, given that I have a PhD in computer science.

00:08:11.600 --> 00:08:16.760
But up until late high school, I did not do well in mathematics courses.

00:08:17.320 --> 00:08:22.400
I got C's in algebra and geometry.

00:08:22.400 --> 00:08:27.180
And it really wasn't until I kind of really put my back against the wall.

00:08:27.180 --> 00:08:28.480
And I said, you know what?

00:08:28.480 --> 00:08:30.780
I got to learn calculus and statistics.

00:08:30.780 --> 00:08:33.420
So I did a self-study in AP Calc.

00:08:33.420 --> 00:08:34.600
And I took AP statistics.

00:08:34.600 --> 00:08:36.280
And I did well with those.

00:08:36.360 --> 00:08:38.080
I'm like, man, math is fun now.

00:08:38.080 --> 00:08:40.040
Like, I understand this.

00:08:40.040 --> 00:08:41.980
So I got to college.

00:08:41.980 --> 00:08:47.920
And I only took one computer vision course at the, because the school I went to didn't really

00:08:47.920 --> 00:08:49.380
have a computer vision focus.

00:08:49.380 --> 00:08:53.220
They had a wonderful machine learning focus, but not really a computer vision focus.

00:08:53.220 --> 00:09:00.200
And what I found out was that, you know, you don't need a mathematical background to get

00:09:00.200 --> 00:09:01.280
started in computer vision.

00:09:01.280 --> 00:09:05.480
And I think this is true in a lot of areas of computer science, whether or not people want

00:09:05.480 --> 00:09:06.140
to admit it.

00:09:06.140 --> 00:09:11.260
A lot of people talk themselves out of getting started and stuff, especially challenging things,

00:09:11.260 --> 00:09:13.320
because they're just scared of it.

00:09:13.320 --> 00:09:14.180
They don't want to fail.

00:09:14.180 --> 00:09:17.700
And that's the cool thing about Python.

00:09:17.700 --> 00:09:20.140
Like, you almost don't have to worry about the code.

00:09:20.140 --> 00:09:23.260
You get to focus on learning a new skill.

00:09:23.260 --> 00:09:25.300
And for me, that was computer vision.

00:09:25.300 --> 00:09:30.680
And that was the OpenCV library, an open source library that makes working with computer vision

00:09:30.680 --> 00:09:31.520
a lot easier.

00:09:31.520 --> 00:09:36.120
So again, it really wasn't until college that I really started to get into it.

00:09:36.120 --> 00:09:37.020
getting interested.

00:09:37.020 --> 00:09:38.680
Or not necessarily getting interested.

00:09:38.680 --> 00:09:42.320
More so being able to take action on what I wanted to do.

00:09:42.320 --> 00:09:43.060
Right.

00:09:43.060 --> 00:09:45.660
Maybe, you know, it felt a little unattainable.

00:09:45.660 --> 00:09:48.480
Like, I'm going to go be an engineer, but I don't know math.

00:09:48.480 --> 00:09:49.860
And so there's no way I can do this.

00:09:49.860 --> 00:09:53.120
But once you kind of got over that hump, then it was no big deal, right?

00:09:53.120 --> 00:09:53.820
Right.

00:09:53.820 --> 00:09:54.720
Yeah.

00:09:54.720 --> 00:09:55.760
That's very freeing.

00:09:55.860 --> 00:10:00.000
So you mentioned OpenCV and your project is PyImageSearch.

00:10:00.000 --> 00:10:01.260
What's the relationship there?

00:10:01.260 --> 00:10:08.640
So OpenCV, again, it's a computer vision library that makes working with images a lot easier.

00:10:08.640 --> 00:10:14.920
You know, it abstracts the code that loads an image off of disk or does edge detection or

00:10:14.920 --> 00:10:19.720
thresholding or any other simple image processing function like that.

00:10:19.780 --> 00:10:23.580
allows you to actually build complicated computer vision programs.

00:10:23.580 --> 00:10:28.580
You can do things like tracking objects and images or video streams, for example.

00:10:28.580 --> 00:10:29.460
Detecting faces.

00:10:29.460 --> 00:10:31.480
Recognizing whose face it is.

00:10:31.480 --> 00:10:34.960
And OpenCV really facilitates this process.

00:10:35.940 --> 00:10:41.900
And OpenCV really is like the de facto library for computer vision and image processing.

00:10:41.900 --> 00:10:44.820
And you have bindings for it in countless languages.

00:10:44.820 --> 00:10:52.480
The library itself is written in C and C++, but you can get bindings and access it in Java

00:10:52.480 --> 00:10:55.620
and any of the .NET frameworks in Python.

00:10:57.240 --> 00:11:03.820
So again, while you can access it in a programming language, I have this love for Python now.

00:11:03.820 --> 00:11:10.000
And when I took the course, the computer vision course in college, I realized, man, like, people

00:11:10.000 --> 00:11:14.180
are spending a lot of time writing their class projects in C and C++.

00:11:14.180 --> 00:11:15.320
Why are they doing that?

00:11:15.320 --> 00:11:18.980
Like, you're fighting over these weird compile time errors.

00:11:18.980 --> 00:11:21.180
And, you know, you're not really learning anything.

00:11:21.680 --> 00:11:24.680
And that's kind of the tenet behind PyImageSearch.

00:11:24.680 --> 00:11:30.220
It's a blog that I run dedicated to teaching computer vision, image processing, and OpenCV using

00:11:30.220 --> 00:11:31.600
the Python programming language.

00:11:31.600 --> 00:11:32.140
That's great.

00:11:32.140 --> 00:11:36.040
And I think that, you know, using Python seems like the perfect choice.

00:11:36.040 --> 00:11:41.920
You're sort of orchestrating these high-level functions that are calling down into C++, doing

00:11:41.920 --> 00:11:43.740
high-performance stuff, and then giving you the answer.

00:11:43.740 --> 00:11:46.740
And that seems like the right way to be using Python.

00:11:46.740 --> 00:11:48.820
So what's the actual package I use?

00:11:48.860 --> 00:11:51.920
If I were to say pip install something, what do I type to get started?

00:11:51.920 --> 00:11:56.480
So unfortunately, OpenCV is not pip installable.

00:11:56.480 --> 00:11:58.980
I wish it was, but it is not.

00:11:58.980 --> 00:12:04.480
And it is not the easiest package to get installed on your system.

00:12:04.480 --> 00:12:14.280
If you're using Ubuntu or any Debian-based operating system, you technically can do an app git install.

00:12:14.280 --> 00:12:17.680
But that's going to pull down a previous version of OpenCV.

00:12:18.100 --> 00:12:22.180
You're going to run into a lot of problems with the Python bindings, and it's not a very

00:12:22.180 --> 00:12:22.720
good experience.

00:12:22.720 --> 00:12:28.220
So what you actually have to do is compile it from source, download the code from their

00:12:28.220 --> 00:12:32.720
GitHub or the SourceForge account, and manually compile it and install it.

00:12:32.720 --> 00:12:37.980
And in fact, that's really the only way to do it if you're interested in using virtual environments,

00:12:37.980 --> 00:12:44.720
which, as most Python developers are interested in, sequestering their packages.

00:12:45.400 --> 00:12:45.840
Yeah, absolutely.

00:12:45.840 --> 00:12:46.300
Okay.

00:12:46.300 --> 00:12:47.940
So I go and I download that.

00:12:47.940 --> 00:12:51.800
And then what packages are in there that I would work with?

00:12:51.800 --> 00:12:53.700
Is that CV2?

00:12:53.700 --> 00:12:55.080
Is that the one I would import?

00:12:55.080 --> 00:12:55.720
Yep.

00:12:55.780 --> 00:13:01.440
So if you were to open up your favorite editor, you would just type in import CV2, and I'll

00:13:01.440 --> 00:13:04.100
give you access to all of your OpenCV bindings.

00:13:04.100 --> 00:13:04.900
Okay, great.

00:13:04.900 --> 00:13:11.440
And now I looked at some samples on your blog about how I might go and grab like an image

00:13:11.440 --> 00:13:13.780
from a camera hooked to an Adreno.

00:13:14.640 --> 00:13:20.220
Maybe we could talk a little bit about the type of hardware that you need and the spectrum

00:13:20.220 --> 00:13:24.500
of devices you can interact with and that kind of stuff before we get into the more theoretical

00:13:24.500 --> 00:13:24.880
bits.

00:13:24.880 --> 00:13:25.700
Sure.

00:13:25.700 --> 00:13:31.760
So that's kind of the cool thing about OpenCV is that it's meant to be run in real time.

00:13:31.760 --> 00:13:38.800
So you can easily process video files, raw video streams without too much of a problem,

00:13:38.900 --> 00:13:41.780
again, depending on the complexity of your algorithm.

00:13:41.780 --> 00:13:46.800
And OpenCV is meant to run on a variety of different devices.

00:13:46.800 --> 00:13:54.660
I personally develop applications on my MacBook, but I also own a Raspberry Pi and a camera module

00:13:54.660 --> 00:13:55.760
for the Raspberry Pi.

00:13:55.760 --> 00:14:02.960
And using OpenCV, I can access the Raspberry Pi video stream and then actually build like

00:14:02.960 --> 00:14:08.000
a home surveillance system using nothing but OpenCV and a Raspberry Pi.

00:14:08.480 --> 00:14:14.900
I built this one project where I had a Raspberry Pi camera mounted on my kitchen cabinets looking

00:14:14.900 --> 00:14:17.000
over the front door of my apartment.

00:14:17.000 --> 00:14:22.280
And it would detect motion, such as when you're opening the door and somebody's walking inside.

00:14:22.280 --> 00:14:27.980
So once it detected motion, it would snap a photo of whoever was walking inside, try and identify

00:14:27.980 --> 00:14:33.320
their face, and then it would take that screenshot or the screen capture and then upload it to my

00:14:33.320 --> 00:14:34.260
personal Dropbox.

00:14:34.260 --> 00:14:37.340
So I had like this real-time home surveillance system.

00:14:37.940 --> 00:14:39.940
That was really, really cool to develop.

00:14:39.940 --> 00:14:43.140
And again, like this is using simple hardware.

00:14:43.140 --> 00:14:48.480
The Raspberry Pi is not a powerful machine, but you could still build some really cool computer

00:14:48.480 --> 00:14:49.760
vision applications with it.

00:14:49.760 --> 00:14:50.420
Yeah.

00:14:50.420 --> 00:14:51.680
And it's cheap too, right?

00:14:51.680 --> 00:14:52.700
Yeah.

00:14:52.700 --> 00:14:58.460
The Pi itself is, I think, $35 and probably another $20 for the camera module.

00:14:58.460 --> 00:14:59.460
Yeah.

00:14:59.460 --> 00:15:01.240
That's really easy to get started.

00:15:01.240 --> 00:15:02.920
So very cool.

00:15:02.920 --> 00:15:03.360
Very cool.

00:15:03.360 --> 00:15:05.620
How does computer vision work?

00:15:05.620 --> 00:15:10.600
I mean, I have a little bit of a background in trying to identify things and images.

00:15:11.280 --> 00:15:18.240
I worked at this place called eye tracking, E-Y-E, tracking, not I, the letter I, tracking.

00:15:18.240 --> 00:15:22.380
And we did a lot of stuff with image recognition and detecting eyes.

00:15:22.380 --> 00:15:26.560
And I know enough to know that it seems really hard, but how does it work?

00:15:27.600 --> 00:15:34.500
So computer vision as a field is really just encompassing methods on acquiring, processing,

00:15:34.500 --> 00:15:38.860
analyzing, and just understanding and interpreting the contents of an image.

00:15:38.860 --> 00:15:41.080
For humans, this is really, really easy.

00:15:41.440 --> 00:15:43.860
We see a picture of a cat, and we know, like, oh, that's a cat.

00:15:43.860 --> 00:15:46.660
And we see a picture of a dog, and we obviously know that's a dog.

00:15:46.660 --> 00:15:48.820
But a computer, it doesn't have a clue.

00:15:48.820 --> 00:15:53.260
It just sees a bunch of pixels, just a big matrix of pixels.

00:15:53.260 --> 00:15:58.080
And the challenging part, as you suggested, is writing code and creating these algorithms

00:15:58.080 --> 00:16:00.660
that can understand the contents of an image.

00:16:00.660 --> 00:16:06.520
You can't open up your Python source file and then write if statements that say,

00:16:06.740 --> 00:16:12.620
if this pixel equals, you know, whatever RGB code, you know, then this is a cat, right?

00:16:12.620 --> 00:16:15.040
If it equals this pixel value, then it's a dog.

00:16:15.040 --> 00:16:16.080
Like, you can't do that.

00:16:16.080 --> 00:16:21.700
So what happens is computer vision really leverages machine learning as well.

00:16:21.700 --> 00:16:26.300
So we can take this data-driven approach and say, here's a ton of examples of a cat,

00:16:26.300 --> 00:16:28.660
and here's a ton of examples of a dog.

00:16:28.660 --> 00:16:35.100
Let's see how we can abstractly quantify and represent this huge image.

00:16:35.640 --> 00:16:37.780
And just like a small, what they call feature vector.

00:16:37.780 --> 00:16:40.860
It's a fancy academic way of saying a list of numbers.

00:16:40.860 --> 00:16:49.100
I'm going to quantify this big 3,000 by 3,000 pixel image into a feature vector that's 128 numbers long.

00:16:49.100 --> 00:16:50.860
And then I can compare them to each other.

00:16:50.860 --> 00:16:52.160
I can rank them for similarity.

00:16:52.160 --> 00:16:56.020
I can pass them to machine learning algorithms to actually classify them.

00:16:57.020 --> 00:17:00.420
So the field of computer vision is very large.

00:17:00.420 --> 00:17:06.020
And again, it spans so many different areas of processing and analyzing images.

00:17:06.020 --> 00:17:10.980
But if we're talking strictly about classifying an image and detecting objects in an image,

00:17:10.980 --> 00:17:14.900
then we're most likely leveraging some machine learning at some point.

00:17:14.900 --> 00:17:15.800
Okay, and cool.

00:17:15.800 --> 00:17:21.900
And when you say machine learning, is that like neural networks or what's going on back there?

00:17:21.900 --> 00:17:25.560
The machine learning algorithm you would use really depends on your application.

00:17:25.560 --> 00:17:31.180
Deep learning has gotten so much attention over the past few years.

00:17:31.180 --> 00:17:34.260
And deep learning has its roots in neural networks.

00:17:34.260 --> 00:17:36.340
So we see a lot of that.

00:17:36.340 --> 00:17:44.000
You also see very simple machine learning methods like support vector machines, logistic aggression.

00:17:44.000 --> 00:17:46.220
You see that a lot as well.

00:17:46.220 --> 00:17:57.440
And these methods, while simple, they're actually â€“ the bulk of the work is actually happening on describing the image itself, you know, quantifying it.

00:17:57.440 --> 00:18:06.220
So if you have a really good quantification of an image, it's a lot easier for the machine learning algorithm to take that and perform the classification.

00:18:06.880 --> 00:18:07.520
Right, sure.

00:18:07.520 --> 00:18:16.340
And so how much of this exists in external libraries like scikit-learn or OpenCV or something like this?

00:18:16.340 --> 00:18:23.700
And how much of that is like I've got to create that system for myself when I'm getting started based on my application?

00:18:24.580 --> 00:18:35.580
So OpenCV does include some machine learning components, but I really don't recommend that people use them just because they're a little finicky and they're not that fun to use.

00:18:35.580 --> 00:18:38.820
And especially in the Python ecosystem, you have scikit-learn.

00:18:38.820 --> 00:18:41.920
So you should be defaulting to that.

00:18:42.460 --> 00:18:52.240
And to give an example, I wrote my entire dissertation, gathered all the examples using OpenCV and scikit-learn.

00:18:52.240 --> 00:18:59.140
I took the results that OpenCV was giving me and I passed them on to the machine learning methods and scikit-learn.

00:18:59.140 --> 00:18:59.760
Right.

00:18:59.760 --> 00:19:01.620
Oh, that sounds very useful.

00:19:01.620 --> 00:19:12.420
I think a lot of the challenging aspects of getting started in something new like this, if you're not already involved in it, is just knowing what exists, what you can reuse, and what you have to write yourself.

00:19:12.420 --> 00:19:14.520
So knowing that that's out there is really nice.

00:19:14.520 --> 00:19:15.720
Yeah, for sure.

00:19:15.720 --> 00:19:20.560
And some of these algorithms you definitely don't want to be implementing yourself.

00:19:20.560 --> 00:19:22.180
No, I'm sure you don't.

00:19:22.180 --> 00:19:29.820
Unless you're really, really into high-performance matrix multiplication and other types of processing that make your day, right?

00:19:29.820 --> 00:19:30.680
Exactly.

00:19:31.000 --> 00:19:34.520
I have some sort of mental models of how I might use computer vision.

00:19:34.520 --> 00:19:37.180
And then you have the Hollywood models, right?

00:19:37.180 --> 00:19:39.140
Like Minority Report and so on.

00:19:39.140 --> 00:19:41.420
But what's the current state of the art?

00:19:41.420 --> 00:19:44.720
Like where do you see computer vision really prominently being used in the world?

00:19:44.720 --> 00:19:51.500
So computer vision is used in your everyday life, whether you realize it or not.

00:19:51.500 --> 00:19:55.140
And it's kind of scary, but it's also kind of cool.

00:19:56.840 --> 00:20:07.980
Back about a year ago, I was traveling back and forth between Maryland and Connecticut on the East Coast of the United States constantly for work-related activities.

00:20:07.980 --> 00:20:10.820
And one day I was exhausted.

00:20:10.820 --> 00:20:12.300
It was Friday.

00:20:12.780 --> 00:20:20.500
I just really wanted to leave Maryland and get back up to Connecticut and sleep in my own bed and just pass out.

00:20:20.640 --> 00:20:22.380
So I left to work a little early.

00:20:22.380 --> 00:20:24.900
And I started tearing up 95.

00:20:24.900 --> 00:20:26.620
It was a beautiful summer day.

00:20:26.620 --> 00:20:28.980
Sunlight streaming down.

00:20:28.980 --> 00:20:32.900
Had my windows open and the wind blowing in.

00:20:33.040 --> 00:20:42.260
And if you've ever driven on 95, specifically on the East Coast of the United States, you know there's always just like a ton of traffic or just lots of construction to ruin your drive.

00:20:42.260 --> 00:20:46.280
And for whatever reason this day, there was no traffic.

00:20:46.280 --> 00:20:47.940
There was no construction.

00:20:47.940 --> 00:20:49.720
And I was just flying down the road.

00:20:49.720 --> 00:20:51.600
And I made excellent time getting home.

00:20:51.600 --> 00:20:55.260
However, two weeks later, I get my mail.

00:20:55.260 --> 00:20:59.880
And I noticed that there is a speeding citation addressed to me.

00:21:00.360 --> 00:21:05.080
Apparently, I had passed one of the speeding cameras that was mounted along the side of the road.

00:21:05.080 --> 00:21:09.080
It detected that my car was traveling above the posted speed limit.

00:21:09.080 --> 00:21:11.700
It snapped a photo of my license plate.

00:21:11.700 --> 00:21:24.940
And then it applied what's called automatic license plate recognition where it takes the image, automatically analyzes it, finds my license plate, and then looks it up in a database and mails me a ticket.

00:21:24.940 --> 00:21:28.280
I was like, man, I've written code to do this.

00:21:28.700 --> 00:21:30.640
I know exactly how this worked.

00:21:30.640 --> 00:21:38.160
So, like, it was the only time where I had a smile on my face as I was writing out the $40 check or whatever it was.

00:21:38.160 --> 00:21:39.740
I'm like, you guys got me.

00:21:39.740 --> 00:21:41.780
And I know how you did it.

00:21:41.780 --> 00:21:42.820
Yeah, exactly.

00:21:42.820 --> 00:21:47.940
Like, your love for image recognition is slightly turned against you.

00:21:47.940 --> 00:21:48.820
Just briefly there.

00:21:48.820 --> 00:21:49.820
Just briefly.

00:21:49.820 --> 00:21:53.320
You said you worked on this thing called ID My Pill.

00:21:53.320 --> 00:21:54.160
What's that?

00:21:54.640 --> 00:22:04.940
So, ID My Pill is an iPhone application and an API that allows you to identify your prescription pills in the snap of your phone.

00:22:04.940 --> 00:22:13.140
So, the general idea is that we are a little too faithful in pharmacists and our doctors.

00:22:13.140 --> 00:22:16.160
And not to say there's anything against that, but mistakes do happen.

00:22:16.160 --> 00:22:19.400
And people do get hurt.

00:22:19.400 --> 00:22:20.000
They get sick.

00:22:20.000 --> 00:22:23.580
And some of them do die every year due to taking the wrong medication.

00:22:23.580 --> 00:22:27.200
So, the idea behind ID My Pill is to validate your prescription pills.

00:22:27.740 --> 00:22:35.260
And it's also a way for pharmacies, for healthcare providers to facilitate better care for their patients.

00:22:35.260 --> 00:22:43.240
So, you just take your pills, snap a photo of them, and then computer vision algorithms are used to automatically analyze and recognize the pill.

00:22:43.240 --> 00:22:46.420
That way, you can validate that, yes, this is the correct pill.

00:22:46.420 --> 00:22:48.960
This is what it says on the pill bottle.

00:22:48.960 --> 00:22:51.340
And I know what I'm taking is correct.

00:22:52.080 --> 00:22:53.240
That sounds really useful.

00:22:53.240 --> 00:22:58.120
What do you think the chances are, like, something along those lines could be automated?

00:22:58.120 --> 00:23:05.520
So, as the pharmacists are, like, actually filling the prescription, you know, the computer knows what they're filling and it sees what they're putting into bottles.

00:23:05.520 --> 00:23:08.400
Could it say, whoa, whoa, whoa, this does not look legit?

00:23:08.400 --> 00:23:12.500
Yeah, I think it absolutely can be automated.

00:23:12.500 --> 00:23:20.680
The current systems right now that pharmacies use, especially within hospitals, some of them are taking RFID chips.

00:23:20.680 --> 00:23:21.960
So...

00:23:21.960 --> 00:23:30.140
You know, when you take a pill bottle off the shelf, it's able to validate that you are taking the correct medication and filling it.

00:23:30.140 --> 00:23:32.700
But again, that's not perfect.

00:23:32.700 --> 00:23:35.240
And pills can get mixed up.

00:23:35.240 --> 00:23:40.260
So, in a perfect world, what you end up doing is you would have that RFID mechanism in place.

00:23:40.260 --> 00:23:48.080
And then, you know, you have a mounted camera looking down at their workstation, at their desk.

00:23:48.080 --> 00:23:51.180
And then, you know, it validates the pills in real time.

00:23:51.180 --> 00:23:56.680
And they get a nice little thumbs up on the screen or whatever heads up display that they have in front of them.

00:23:56.680 --> 00:23:58.180
And they can continue filling the medication.

00:23:58.540 --> 00:24:00.240
Yeah, that sounds really helpful.

00:24:00.240 --> 00:24:06.780
So, I used a slightly less productive, contribute to society sort of computer vision last night.

00:24:06.780 --> 00:24:08.340
I was out with some friends and my wife.

00:24:08.340 --> 00:24:09.900
We were having some wine.

00:24:10.240 --> 00:24:13.180
And there's this really cool iPhone app called Vivino.

00:24:13.180 --> 00:24:14.260
I think I'm saying it right.

00:24:14.260 --> 00:24:14.780
Yeah.

00:24:14.780 --> 00:24:21.560
And you can just take a picture of a bottle, even if the background is all messy and there's people around and so on.

00:24:21.560 --> 00:24:27.040
And it'll tell you what the ratings are, how much it should cost at, you know, sort of standard retail price.

00:24:27.520 --> 00:24:29.380
And I was really impressed with that.

00:24:29.380 --> 00:24:35.200
You know, there's a lot of interesting sort of consumer style uses as well, I think.

00:24:35.200 --> 00:24:36.720
Oh, for sure.

00:24:36.720 --> 00:24:40.180
Vivino is one of the major ones.

00:24:40.180 --> 00:24:50.240
And another one that you can see computer vision used a lot in, and I don't think people really notice it, but they appreciate it, is within sports.

00:24:50.660 --> 00:25:04.460
So, in America, if you're watching a football game, you'll notice that they have, like, a yellow line drawn across the field marking the, you know, the spot of the ball along with the first down marker.

00:25:04.460 --> 00:25:08.260
And these lines are drawn using calibrated cameras.

00:25:08.260 --> 00:25:15.140
So, computer vision is used to calibrate the cameras and then know where to actually draw that line on the broadcast of the game.

00:25:15.620 --> 00:25:25.860
And then, similarly, you can use computer vision and machine learning in the back end and analyze games to determine, you know, what's the optimal strategy.

00:25:25.860 --> 00:25:29.720
And this is actually done in Europe a lot in soccer games.

00:25:29.720 --> 00:25:34.580
So, they'll detect how players are moving around, how the ball is passed back and forth.

00:25:34.580 --> 00:25:41.800
And they can almost run these data mining algorithms to learn how you're going to beat the other team and try and learn their strategy.

00:25:41.800 --> 00:25:43.020
It's pretty cool.

00:25:43.020 --> 00:25:45.080
Yeah, that really is amazing.

00:25:45.200 --> 00:25:54.100
I feel like these days watching sports on television is actually a better experience than going to them live a lot of times because of these types of things, right?

00:25:54.100 --> 00:25:55.040
It's very clear.

00:25:55.040 --> 00:25:59.360
Oh, look, they've got to go, like, a foot and a half forward and then they get the first down.

00:25:59.360 --> 00:26:00.240
Otherwise, they're going to fail.

00:26:00.240 --> 00:26:04.100
And, you know, you don't really quite get the same feel live, which is ironic.

00:26:04.100 --> 00:26:04.900
Right.

00:26:04.900 --> 00:26:09.420
It's almost that it used to be that you didn't get the full story unless you were there.

00:26:09.420 --> 00:26:10.900
And now it's kind of flipped around.

00:26:10.900 --> 00:26:14.480
Like, you get more than the full story if you're watching the game on TV.

00:26:14.580 --> 00:26:16.440
You get all the detail that you could possibly want.

00:26:16.440 --> 00:26:17.360
Yeah, that's right.

00:26:17.360 --> 00:26:29.360
So, you know, that sort of leads into the whole story of augmented reality and stuff like that with, you know, the Microsoft HoloLens, Google Glass, and, you know, a bunch of iPhone apps and other mobile apps as well.

00:26:29.360 --> 00:26:31.540
What kind of interesting stuff do you see out in that world?

00:26:31.960 --> 00:26:34.140
I have not had a chance to play around with the HoloLens.

00:26:34.140 --> 00:26:37.980
I have used the Google Glass and played around with that.

00:26:37.980 --> 00:26:45.920
Most of the applications I see, again, this is just because of my work with ID mypyll, is medical related.

00:26:46.300 --> 00:26:54.240
So, you'll see surgeons going into really, really long, you know, 10 plus hour surgeries that they perform these complex operations.

00:26:54.240 --> 00:26:59.800
And they may need to look up some sort of reference material while they're doing this surgery.

00:27:00.020 --> 00:27:06.800
And instead of having an assistant doing that for them, I mean, they could put on the Google Glass and have this information right there in front of them.

00:27:06.800 --> 00:27:08.700
So, you see a lot of that.

00:27:08.700 --> 00:27:20.000
And since the Glass has a camera, there's a lot of research focused on, especially within medicine, identifying various body parts as you're performing this surgery.

00:27:20.000 --> 00:27:24.720
So, you can have this documented procedure pulled up in front of you as you're working.

00:27:24.720 --> 00:27:27.780
There's no need to instruct the Google Glass to do it for you.

00:27:27.780 --> 00:27:28.900
Yeah, that's pretty wild.

00:27:28.900 --> 00:27:34.860
I can imagine calibrating some kind of augmented reality thing to the body that is there.

00:27:34.860 --> 00:27:37.620
And you could almost see, like, the organs and stuff overlaid.

00:27:37.620 --> 00:27:38.900
Yeah, absolutely.

00:27:38.900 --> 00:27:41.920
Some really interesting new uses there.

00:27:41.920 --> 00:27:43.280
Very cool.

00:27:43.280 --> 00:27:46.480
What about things like the Google self-driving cars?

00:27:47.540 --> 00:27:53.680
What role does image recognition and computer vision work there versus, say, GPS versus laser versus whatever else?

00:27:53.680 --> 00:27:54.220
Do you know?

00:27:54.220 --> 00:27:56.120
That remains to be seen.

00:27:56.120 --> 00:28:02.940
I guess I am a little bit of a pessimist when it comes to computer vision being used for driving cars.

00:28:02.940 --> 00:28:06.460
You maybe know too much about the little problems you're into, right?

00:28:06.460 --> 00:28:17.460
Well, that's the thing is I don't believe computer vision itself will ever be adequate, again, by itself, for self-driving cars.

00:28:17.460 --> 00:28:20.160
I think you need a lot more sensors.

00:28:20.160 --> 00:28:27.840
I think you do need things like radar to help you out with that and help detect objects in front of you.

00:28:27.840 --> 00:28:37.720
And that's a problem computer vision does face is when you take a photo of something, it is a 2D representation of a 3D world.

00:28:37.980 --> 00:28:41.960
So, it makes it very hard to compute depth based off of that.

00:28:41.960 --> 00:28:51.540
And now we have things like the Xbox 360 Kinect and stereo cameras where we can compute depth, which is making things like the self-driving cars more feasible.

00:28:51.800 --> 00:28:57.500
But, again, for something like a self-driving car, it doesn't make sense to rely strictly on computer vision.

00:28:57.500 --> 00:29:01.240
I think you want to incorporate as many sensors as you possibly can.

00:29:01.240 --> 00:29:03.320
Yeah, I think that makes a lot of sense.

00:29:03.320 --> 00:29:13.620
And it might make sense to actually have the road have things like RFID style stuff in it where the car can be sure it's between the lanes, at least on the major long part of the drives.

00:29:14.300 --> 00:29:15.220
Oh, for sure.

00:29:15.220 --> 00:29:25.740
And I think that's kind of the point I will say is just because you can use computer vision to solve something doesn't necessarily mean that you should.

00:29:25.740 --> 00:29:28.840
There might be better solutions out there.

00:29:28.840 --> 00:29:29.180
Yeah, sure.

00:29:29.180 --> 00:29:33.480
You don't want to be the solution in search of a problem.

00:29:33.480 --> 00:29:37.460
You want to be the solution to a problem.

00:29:37.460 --> 00:29:38.500
Yeah, yeah.

00:29:39.000 --> 00:29:44.820
There's a really good show I'd like to recommend to people, by the way, about this whole computers, driving cars, and that.

00:29:44.820 --> 00:29:48.480
Nova did a show called The Great Robot Race.

00:29:48.480 --> 00:29:51.540
And you can just Google The Great Robot Race or whatever.

00:29:51.540 --> 00:29:58.800
And it's all about this DARPA competition that kind of preceded the whole Google self-driving cars and so on.

00:29:58.800 --> 00:30:05.360
And it's like a two-hour really sort of technical documentary on, like, the problems these teams technically faced and stuff.

00:30:05.360 --> 00:30:06.060
It was very cool.

00:30:06.060 --> 00:30:07.840
So if you want to learn more, check that out.

00:30:07.840 --> 00:30:08.240
Nice.

00:30:08.860 --> 00:30:09.100
Yeah.

00:30:09.100 --> 00:30:11.900
It's a really good sort of conceptual idea of what's going on.

00:30:11.900 --> 00:30:13.360
But, you know, what do I do?

00:30:13.360 --> 00:30:17.260
Like, what kind of code do I write as a Python developer to get started?

00:30:17.260 --> 00:30:21.120
I mean, it's tough to talk about code on audio only.

00:30:21.120 --> 00:30:22.900
So don't do too much.

00:30:22.900 --> 00:30:29.160
But just, like, can you give me a sense of what kind of code I would write to maybe grab an image and ID something in it?

00:30:29.160 --> 00:30:30.100
Yeah.

00:30:30.100 --> 00:30:32.700
So let's take a fun example.

00:30:33.240 --> 00:30:44.400
If you've ever used your smartphone to scan a document, you've basically taken, you've, like, set a piece of paper on your desk, held your phone above it, and snapped a photo.

00:30:44.400 --> 00:30:49.700
And then the document's already scanned and stored as an image on your phone.

00:30:49.700 --> 00:30:53.380
And you could email it to yourself or text it to someone.

00:30:53.880 --> 00:31:02.120
What's really cool is that while those programs and those applications almost seem like magic, they're really, really simple to build.

00:31:02.480 --> 00:31:08.540
So if I were to build a mobile document scanner, I would basically say, first up, capture the image.

00:31:08.540 --> 00:31:10.100
So I'm going to read it from disk.

00:31:10.100 --> 00:31:11.720
I'm going to read it from a camera sensor.

00:31:11.720 --> 00:31:12.480
Nice.

00:31:12.480 --> 00:31:18.580
I'm going to convert it to grayscale because color doesn't really matter.

00:31:18.580 --> 00:31:23.060
I'm going to assume there's enough contrast between a document and a desk that I'll be able to detect it.

00:31:23.480 --> 00:31:32.900
And I'm probably going to blur it, get rid of any type of high-frequency noise, just allowing me to focus more on the structural objects inside the image and less on the detail.

00:31:32.900 --> 00:31:36.920
From there, I'll say, yeah, let's perform edge detection.

00:31:36.920 --> 00:31:39.600
Let's find all the edges in the image.

00:31:39.600 --> 00:31:47.820
And based on the outlines of the objects in the image, I'm going to take these, and I'm going to look for a rectangle.

00:31:47.820 --> 00:31:52.720
And if you consider the geometry of a rectangle, it just has four points, four vertices.

00:31:53.400 --> 00:32:01.460
So I'm going to loop over the largest regions in this image, and I'm going to find the largest one that has four vertices.

00:32:01.460 --> 00:32:04.080
And I'm going to assume that's my document.

00:32:04.080 --> 00:32:14.160
And then once I have the region of the image, I'm going to perform a perspective transform to give me this top-down, bird's-eye view of the document.

00:32:14.160 --> 00:32:19.200
And from there, you've basically built yourself a document scanner.

00:32:19.400 --> 00:32:29.100
You can apply OCR, optical character recognition to try and convert the text in the image to a string in Python.

00:32:29.100 --> 00:32:33.440
Or you could just save the scanned document as a raw image.

00:32:33.440 --> 00:32:34.700
That works, too.

00:32:34.700 --> 00:32:38.600
It's really actually not a complicated system to build.

00:32:38.600 --> 00:32:47.480
How do you deal with the slight imperfections of reality, like a crumpled receipt or document or something like that?

00:32:48.200 --> 00:32:59.300
So to handle, as you suggested, like these slight imperfections, I would suggest for the document scanner example to do what's called contour approximation.

00:33:00.120 --> 00:33:13.920
So, again, if a region of an image can be defined as a set of vertices, and due to the crumpling of the piece of paper, maybe I find a region of an image that has eight vertices or 12 vertices.

00:33:14.460 --> 00:33:16.880
It's not a perfect rectangle.

00:33:16.880 --> 00:33:18.540
It's kind of jagged in some places.

00:33:18.540 --> 00:33:21.500
Well, what I can actually do is I can approximate that contour.

00:33:21.500 --> 00:33:28.960
And I could basically do line splitting and try and reduce the number of points to form that contour.

00:33:28.960 --> 00:33:40.460
And that's actually a very critical step in building a mobile document scanner because you're not going to find perfect rectangles in the real world just due to noise capturing the photo.

00:33:40.460 --> 00:33:42.520
Even perspective, right?

00:33:42.520 --> 00:33:44.040
Yeah, even perspective.

00:33:44.040 --> 00:33:45.700
That can dramatically distort things.

00:33:45.700 --> 00:33:49.600
Are there libraries out there that help you with that kind of stuff, or is that where you need to know some math?

00:33:49.600 --> 00:33:52.760
You don't really need to know that much math at all for it.

00:33:52.760 --> 00:33:56.080
It's all about gluing the right functions together at the right time.

00:33:56.080 --> 00:34:01.580
And I think that's one of the harder points of learning computer vision and why I run the PyMid Search blogs.

00:34:01.580 --> 00:34:06.580
I want to show people real-world solutions to problems using computer vision.

00:34:06.580 --> 00:34:12.820
And when I do that, it's not really the actual code that matters.

00:34:12.820 --> 00:34:19.360
It's learning why I'm applying certain functions at different times in the context of the end goal.

00:34:19.360 --> 00:34:23.920
It's about taking these functions and gluing them together in a way that gives you a real solution.

00:34:23.920 --> 00:34:25.160
Okay, that makes sense.

00:34:25.260 --> 00:34:30.880
Sounds a little bit like the code variation of I open up Photoshop and there's a thousand things it does.

00:34:30.880 --> 00:34:38.640
And individually, they're all simple, but I don't know how to go from a bad picture to a great picture with all of my little pieces, right?

00:34:38.640 --> 00:34:43.180
It's kind of like that with the code libraries for image stuff, right?

00:34:43.180 --> 00:34:43.820
For sure.

00:34:44.320 --> 00:34:48.500
There's a couple of really cool apps that are coming to mind when you're talking about that.

00:34:48.500 --> 00:34:50.000
One is called WordLens.

00:34:50.000 --> 00:34:51.620
Do you know about WordLens?

00:34:51.620 --> 00:35:00.680
Yeah, that's the one where you have your iPhone or your smartphone and you can hold it over a foreign language and it automatically translates it for you.

00:35:00.680 --> 00:35:01.080
Is that right?

00:35:01.080 --> 00:35:01.780
Yeah, that's right.

00:35:01.860 --> 00:35:08.380
And it will basically replace a menu or a street sign with whatever language you want, English in my case, right?

00:35:08.380 --> 00:35:11.460
That seems like a really cool use as well.

00:35:11.460 --> 00:35:15.600
Another one that I liked is this thing called Peak.AR.

00:35:15.980 --> 00:35:25.100
And if you're out hiking in the mountains, you can hold it up and it'll like highlight the various mountaintop names and how high they are and how far away they are using computer vision.

00:35:25.100 --> 00:35:26.220
Very nice.

00:35:26.220 --> 00:35:27.100
Yeah, that's pretty cool.

00:35:27.100 --> 00:35:29.620
Let's talk about your blog and your book a little bit.

00:35:29.620 --> 00:35:33.060
Like what kind of stuff do you have on there for people to go learn?

00:35:33.060 --> 00:35:39.200
You have like a short course people can sign up for and I saw you also have like a video course that they could take as well.

00:35:39.200 --> 00:35:39.540
Is that right?

00:35:39.540 --> 00:35:41.940
So it's not a video course.

00:35:41.940 --> 00:35:46.220
I have two small mini courses on the PyImageSearch blog.

00:35:46.220 --> 00:35:54.420
One is like a 21-day crash course on building image search engines, which is my area of expertise within computer vision.

00:35:54.420 --> 00:35:59.600
We're all familiar with going to Google and typing in our query and finding results.

00:35:59.600 --> 00:36:03.060
And that's essentially what image search engines are.

00:36:03.060 --> 00:36:05.720
Only instead of using text as our query, we're using images.

00:36:05.720 --> 00:36:11.760
We're analyzing the image and then searching databases for images with similar visual content.

00:36:11.760 --> 00:36:17.160
And again, this is without any knowledge of text associated with the image.

00:36:17.160 --> 00:36:17.420
Right.

00:36:17.420 --> 00:36:18.680
That's really cool.

00:36:18.680 --> 00:36:25.900
You know, I think I first saw that with Google image search where I could take a picture of like the Sydney Bridge and it would say, hey, that's the Sydney Bridge.

00:36:25.900 --> 00:36:28.860
But it seems like there might be more practical uses for that.

00:36:28.860 --> 00:36:30.620
Oh, there definitely are.

00:36:32.220 --> 00:36:38.740
I've used image search at sea in the National Cancer Institute, actually.

00:36:38.740 --> 00:36:49.580
I worked as a consultant there for about six months and we developed methods to automatically analyze breast histology images for cancer risk factors.

00:36:49.780 --> 00:36:55.980
So we would actually develop algorithms that would go in and automatically analyze these cellular structures.

00:36:56.400 --> 00:37:04.340
And then based off of that, be able to kind of predict that person's cancer risk factor five years from now, 10 years from now, 15 years from now.

00:37:04.340 --> 00:37:10.600
But you could also apply image search to that and say, you know, here's an example of these cellular structures.

00:37:10.600 --> 00:37:15.580
Go and find the other cellular structures in this image data set that look like that.

00:37:15.580 --> 00:37:20.420
And then you can compare them, compare their cancer risk factors and look for correlations.

00:37:20.420 --> 00:37:25.480
So there's image search is a wonderful, wonderful field.

00:37:25.480 --> 00:37:27.420
I personally love it.

00:37:27.420 --> 00:37:28.580
Then again, I'm biased.

00:37:28.580 --> 00:37:32.500
So there's an incredible number of uses for it.

00:37:32.500 --> 00:37:34.840
And it's not all consumer facing.

00:37:34.840 --> 00:37:41.020
It's also, you know, on the back end, on the business facing, on government and all other sectors.

00:37:41.020 --> 00:37:42.200
Yeah, that's cool.

00:37:42.360 --> 00:37:52.540
One company I saw, I can't remember where I saw them, but they were basically starting a company that would help you identify parts of like machines and cars and stuff.

00:37:52.540 --> 00:37:53.520
And you're like, I have a part.

00:37:53.520 --> 00:37:54.180
I know it's broken.

00:37:54.180 --> 00:37:55.460
I have no idea what it is.

00:37:55.460 --> 00:37:56.360
Take a picture of it.

00:37:56.360 --> 00:37:59.340
And they'll say, oh, this is, you know, widget X and it costs $32.

00:37:59.340 --> 00:38:00.540
Here's how you order it.

00:38:00.540 --> 00:38:01.500
Oh, cool.

00:38:01.500 --> 00:38:01.820
Yeah.

00:38:01.820 --> 00:38:05.100
So, you know, it doesn't help people quite as much, but still very, very cool.

00:38:05.100 --> 00:38:06.760
Tell us about your book.

00:38:06.760 --> 00:38:07.280
What's the title?

00:38:07.280 --> 00:38:12.060
So I have a book called Practical Python and OpenCV.

00:38:12.180 --> 00:38:20.860
And it's just a really quick, really quick kickstart guide to like get you through learning the basics of computer vision and image processing.

00:38:20.860 --> 00:38:25.440
It starts off with very rudimentary things like here's how you load an image off of a disk.

00:38:25.440 --> 00:38:28.180
And here's how you detect edges in an image.

00:38:28.180 --> 00:38:37.560
And then it goes on to show you how to detect faces and images in video streams and how to track objects in images and how to recognize handwritten characters.

00:38:38.140 --> 00:38:51.500
So it really takes you from assuming you have very basic programming experience and no prior experience in computer vision all the way to, hey, look, I'm solving some real world problems using computer vision.

00:38:51.900 --> 00:38:57.280
And again, it's a quick read and you can learn a ton about computer vision really quickly.

00:38:57.920 --> 00:39:06.380
And I would also love to offer a discount to talk Python listeners if they want to go to pyimagesearch.com slash talk Python.

00:39:06.860 --> 00:39:11.860
You can get 20% off of any of the books that I offer on that page.

00:39:11.860 --> 00:39:14.340
And I'll keep that open for the next two weeks.

00:39:14.340 --> 00:39:15.260
That's awesome.

00:39:15.260 --> 00:39:15.960
Thanks for doing that.

00:39:15.960 --> 00:39:16.720
Oh, thank you.

00:39:16.720 --> 00:39:19.100
Thank you so much for having this opportunity.

00:39:19.100 --> 00:39:19.680
This is great.

00:39:20.540 --> 00:39:22.000
Yeah, so people should check out your book.

00:39:22.000 --> 00:39:22.900
That's really cool.

00:39:22.900 --> 00:39:29.160
Is it used for like any university classes or is it more not so academic, a little more like industry focused?

00:39:29.160 --> 00:39:31.980
It is much more practical and hands on.

00:39:31.980 --> 00:39:36.780
So it's not used that much in college level classrooms.

00:39:36.780 --> 00:39:43.680
However, I have seen it used in Amsterdam and a few universities in the United States as well.

00:39:43.680 --> 00:39:44.740
Yeah, that's really cool.

00:39:44.740 --> 00:39:45.660
It's got to make you feel good.

00:39:46.460 --> 00:39:47.540
It certainly does.

00:39:47.540 --> 00:39:52.260
I'm happy that I can contribute and give back to a field that I love so much.

00:39:52.260 --> 00:39:53.520
Yeah, that's awesome.

00:39:53.520 --> 00:39:58.200
A lot of people build web apps and web apps don't have attached cameras.

00:39:58.200 --> 00:40:00.340
Well, I guess you could get one from the browser, right?

00:40:00.340 --> 00:40:02.700
You could do something with that if you could capture the people's browser.

00:40:02.700 --> 00:40:09.420
But what are some like web scenarios rather than say iPhone or Raspberry Pi type scenarios for computer vision?

00:40:09.420 --> 00:40:14.760
Let's say that we're going to build, you know, like a Twitter or Facebook style application

00:40:14.760 --> 00:40:16.900
where a user has a profile picture.

00:40:16.900 --> 00:40:21.600
And we're going to build the functionality to upload a profile picture and then set it.

00:40:21.600 --> 00:40:26.600
Well, there's a naive way of doing it where you just kind of upload a profile picture

00:40:26.600 --> 00:40:35.560
and maybe you ask the user to crop the image or maybe you just automatically assume that the user's face or their profile is directly in the center.

00:40:35.720 --> 00:40:38.220
So you just automatically resize the image and crop it.

00:40:38.220 --> 00:40:41.240
Those are viable solutions and there's nothing wrong with them.

00:40:41.240 --> 00:40:45.620
But we could also use computer vision to create a much more fluid user experience.

00:40:45.620 --> 00:40:48.380
So the user can upload a profile picture.

00:40:48.380 --> 00:40:52.320
And in the background, we're running these computer vision algorithms.

00:40:52.320 --> 00:40:59.580
So we can analyze the image and find the face and automatically crop that face from the image and set it as the user's profile picture.

00:41:00.300 --> 00:41:03.820
And again, the goal here is making a much more seamless experience.

00:41:03.820 --> 00:41:04.660
That's really cool.

00:41:04.660 --> 00:41:13.240
I think, you know, people's expectations of consumer focused and even B2B type apps to some degree, you know, things like Slack and so on,

00:41:13.240 --> 00:41:17.420
are there definitely have gone up in the last three or four years.

00:41:17.420 --> 00:41:19.140
And, you know, I blame the iPhone, right?

00:41:19.140 --> 00:41:23.200
We can no longer build just ugly, crummy apps that users are forced to use, right?

00:41:23.200 --> 00:41:24.500
They expect a cool experience.

00:41:24.500 --> 00:41:26.780
And something like that is just, you know, really nice touch.

00:41:27.400 --> 00:41:27.980
Yeah, for sure.

00:41:27.980 --> 00:41:32.700
And from a business perspective, I mean, making a good impression on your users is crucial.

00:41:32.700 --> 00:41:40.740
So you want them to have this really, really great experience when using your app, even if it is something as simple as a profile picture.

00:41:40.740 --> 00:41:44.020
I mean, things like those do matter from a user experience level.

00:41:44.020 --> 00:41:44.540
Right.

00:41:44.540 --> 00:41:47.140
If somebody goes, oh, my gosh, you wouldn't believe what happened.

00:41:47.140 --> 00:41:50.180
I uploaded this and it made the best profile picture ever, right?

00:41:50.180 --> 00:41:53.660
That could possibly be something, a little bit of word of mouth marketing.

00:41:53.660 --> 00:41:54.160
That'd be cool.

00:41:54.660 --> 00:41:54.920
Yeah.

00:41:54.920 --> 00:42:01.240
And then getting back to the Facebook example and the Twitter example, if you've uploaded a picture to Facebook recently,

00:42:01.240 --> 00:42:06.800
you've probably noticed that it can not only detect your face or other people's faces and images,

00:42:06.800 --> 00:42:09.560
but it can recognize whose face that belongs to.

00:42:09.560 --> 00:42:12.620
So these images are being automatically tagged for you.

00:42:12.620 --> 00:42:13.580
And maybe that's creepy.

00:42:13.580 --> 00:42:16.240
Maybe that's not, you know, kind of beside the point.

00:42:16.240 --> 00:42:19.620
But again, it's these computer vision algorithms running behind the scenes.

00:42:19.620 --> 00:42:20.280
Right.

00:42:20.340 --> 00:42:21.180
That's really fantastic.

00:42:21.180 --> 00:42:24.360
Have you played with Google Auto Awesome from Google Plus?

00:42:24.360 --> 00:42:25.360
No, I haven't.

00:42:25.360 --> 00:42:26.360
Oh, my gosh.

00:42:26.360 --> 00:42:27.980
There's amazing stuff that happens.

00:42:27.980 --> 00:42:29.320
I don't do much with Google Plus.

00:42:29.320 --> 00:42:33.720
I mean, there's some people on it and I check it every now and then and it's okay and so on.

00:42:33.720 --> 00:42:35.640
But, you know, Twitter is really my place.

00:42:35.640 --> 00:42:38.300
But for images, Google Plus is crazy.

00:42:38.480 --> 00:42:41.020
So it'll do things like take a picture.

00:42:41.020 --> 00:42:48.060
If you have like three pictures of a group and in one picture, there's somebody frowning and there's another picture.

00:42:48.060 --> 00:42:49.460
Someone else has their eyes closed.

00:42:49.460 --> 00:42:52.860
But in the other picture, the closed eyes persons were open.

00:42:52.860 --> 00:42:57.180
The other, you know, if you could combine them and they would all like look good, right?

00:42:57.180 --> 00:43:00.200
You could take out the bad faces and put the good faces in from the other pictures.

00:43:00.200 --> 00:43:01.980
And it'll do that automatically for you.

00:43:01.980 --> 00:43:02.720
Wow.

00:43:03.220 --> 00:43:09.660
So it'll like take a set of group pictures and make the best possible like unified group picture of all the different faces.

00:43:09.660 --> 00:43:10.840
That's pretty crazy.

00:43:10.840 --> 00:43:11.720
That is.

00:43:11.720 --> 00:43:16.420
And other things like that as well, like focusing on faces and so on.

00:43:16.420 --> 00:43:19.780
So I'm sure there's some really cool computer vision stuff going on there.

00:43:19.780 --> 00:43:21.440
Yeah, I'll definitely have to check that out.

00:43:21.440 --> 00:43:26.100
Yeah, you can just like turn, install Google Plus, turn on your iPhone and just tell it to auto backup.

00:43:26.100 --> 00:43:28.320
And then like you'll get these notifications every now and then.

00:43:28.320 --> 00:43:29.260
You have these crazy pictures.

00:43:29.260 --> 00:43:30.320
Nice.

00:43:30.320 --> 00:43:30.780
Yeah.

00:43:30.780 --> 00:43:32.580
So suppose I'm new.

00:43:32.800 --> 00:43:34.860
I'm pretty new to computer vision.

00:43:34.860 --> 00:43:35.840
How do I get started?

00:43:35.840 --> 00:43:42.280
So if you want to get started, the first thing I would suggest doing is installing OpenCV.

00:43:42.280 --> 00:43:44.680
I mean, that's a pretty important prerequisite.

00:43:44.680 --> 00:43:50.480
Another library that you might want to look into that is pip installable is Scikit Image.

00:43:50.480 --> 00:43:59.020
And this library, I love OpenCV, but Scikit Image releases updates a lot, lot faster.

00:43:59.020 --> 00:44:02.620
It's a smaller library, but it's very good at what it does.

00:44:02.620 --> 00:44:08.460
And in my opinion, it stays a little bit closer to what the state of the art is in computer vision.

00:44:08.460 --> 00:44:21.080
So if an academic paper is published and they implement some new algorithm, Scikit Image is much more likely to have that implementation than OpenCV will, simply because it's a smaller community.

00:44:21.220 --> 00:44:22.700
But it's a faster moving community.

00:44:22.700 --> 00:44:24.660
So they can release updates faster.

00:44:24.660 --> 00:44:25.540
Okay.

00:44:25.540 --> 00:44:26.700
Yeah, that sounds really cool.

00:44:26.700 --> 00:44:27.660
And do I need hardware?

00:44:27.660 --> 00:44:30.920
Do I need a Raspberry Pi and a camera kit or can I just use my webcam?

00:44:31.780 --> 00:44:35.500
You know, you can use pretty much whatever you want.

00:44:35.500 --> 00:44:39.100
I recommend just starting out with your laptop or your desktop system.

00:44:39.100 --> 00:44:41.240
There's no reason that you need any special hardware.

00:44:41.240 --> 00:44:47.580
And realistically, you don't even need a webcam unless you plan on processing video, real-time video.

00:44:48.620 --> 00:44:51.700
And in the meantime, if you do, you could still go ahead and get started.

00:44:51.700 --> 00:44:54.080
You could just work with pre-recorded videos.

00:44:54.080 --> 00:44:59.560
Maybe you recorded from years ago from files you have lying around on your system.

00:44:59.560 --> 00:45:02.640
There's no reason why you can't get started.

00:45:02.640 --> 00:45:12.400
And I think that's what's really cool about computer vision is, you know, back in high school, I had this impression that computer vision and image processing was just magic going on behind the scenes.

00:45:12.400 --> 00:45:25.240
But it's really not, and it is possible to learn these algorithms and understand them without having a degree in computer science or a focus in machine learning or, you know, tons of understanding of high-level mathematics.

00:45:25.240 --> 00:45:26.480
Yeah, very cool.

00:45:26.480 --> 00:45:32.000
Especially with things like OpenCV where you don't have to understand, like, the video encoding format and all that kind of stuff, right?

00:45:32.000 --> 00:45:35.080
Yeah, that's taken care of for you behind the scenes.

00:45:35.380 --> 00:45:42.500
All right, well, maybe you could tell everyone a few of your favorite packages or libraries out there that you like to use.

00:45:42.500 --> 00:45:47.420
You know, everyone has their own flavor and things they've discovered and problems they're solving.

00:45:47.420 --> 00:45:48.600
So, you got any favorites?

00:45:48.600 --> 00:45:51.000
Yeah, so I mentioned two of my favorites already.

00:45:51.000 --> 00:45:54.020
The first one is scikit-learn for machine learning.

00:45:54.020 --> 00:45:57.340
The other is Scikit-image for computer vision.

00:45:57.340 --> 00:46:01.740
OpenCV is great, but again, not pip installable.

00:46:02.620 --> 00:46:10.780
If you do decide to play around with computer vision, I would suggest that you check out the imutils package that I created.

00:46:10.780 --> 00:46:25.360
It's basically a set of basic functions for image manipulations, such as resizing, rotation, translations, that can take a little bit of code to do in OpenCV, and then it just reduces it to a single function call inside the imutils package.

00:46:25.360 --> 00:46:26.480
Yeah, that's great.

00:46:26.480 --> 00:46:27.440
I'll put that in the show notes.

00:46:27.440 --> 00:46:29.760
Yeah, it's definitely worth taking a look at.

00:46:30.260 --> 00:46:37.980
The other fun one that I like to play around with doesn't have a ton of real-world application, but it's called Color Transfer.

00:46:38.760 --> 00:46:51.260
And the idea is that, let's say you went to the beach at 1 p.m. in the afternoon, and you took this really great picture, but you wanted to make it look like it was taken at sunset.

00:46:51.480 --> 00:46:55.880
So you would have this beautiful orange glow of the sun over top of the ocean.

00:46:55.880 --> 00:47:10.480
Maybe you could create that effect in Photoshop, or you could just have an example image of a sunset and then algorithmically take the color space from the sunset image and then transfer it to the image you took.

00:47:10.940 --> 00:47:15.420
So if you want to play around with that, that's in the color transfer package on PyPy.

00:47:15.420 --> 00:47:16.760
Oh, that sounds really interesting.

00:47:16.760 --> 00:47:18.620
Yeah, it's a lot of fun.

00:47:18.620 --> 00:47:23.100
Not exactly the most real-world applicable package, but it's fun nonetheless.

00:47:23.100 --> 00:47:24.280
Yeah, it sounds really fun.

00:47:24.280 --> 00:47:29.040
Okay, any final shout-outs or things you want to tell the listeners?

00:47:30.340 --> 00:47:35.880
Yeah, if you want to learn more about computer vision, definitely head over to pyimagesearch.com.

00:47:35.880 --> 00:47:37.960
Check out the blog posts I have.

00:47:37.960 --> 00:47:45.440
I have, at the time of this recording, at least 80 free blog posts that discuss computer vision and solving real-world problems.

00:47:45.440 --> 00:47:49.980
I have two courses, mini courses that you can take and learn about computer vision.

00:47:49.980 --> 00:47:59.060
And again, I have my book, Practical Python, an open CV that you can purchase and read through and learn computer vision and get up to speed really quickly.

00:47:59.260 --> 00:48:06.920
And again, I'm offering that 20% off to all Talk Python podcast listeners at pyimagesearch.com slash Talk Python.

00:48:06.920 --> 00:48:09.440
All right, that's really interesting.

00:48:09.440 --> 00:48:10.280
I appreciate the offer.

00:48:10.280 --> 00:48:14.680
And I think everyone out there should go and check out your blog.

00:48:14.680 --> 00:48:18.120
You have some tutorials you can go look at, and they're really short.

00:48:18.120 --> 00:48:24.800
And they both walk you through the code as well as maybe setting this up on a Raspberry Pi with a camera board and all those kinds of things.

00:48:24.800 --> 00:48:25.900
So I found it really helpful.

00:48:25.900 --> 00:48:29.020
And hopefully, if anyone wants to try it out, I encourage you to do so.

00:48:29.020 --> 00:48:29.500
Cool.

00:48:29.500 --> 00:48:31.400
Thank you so much for having me on the show.

00:48:31.400 --> 00:48:32.920
This was a great experience.

00:48:32.920 --> 00:48:34.980
Yeah, Adrian, it was great to talk to you.

00:48:34.980 --> 00:48:39.700
And I'd love to bring a different perspective on the cool stuff you can do with Python.

00:48:39.700 --> 00:48:44.560
So here's one more awesome thing that people can do if they want to try it, right?

00:48:44.560 --> 00:48:45.680
Yep, for sure.

00:48:45.680 --> 00:48:46.160
All right.

00:48:46.160 --> 00:48:46.700
Thanks for being here.

00:48:46.700 --> 00:48:47.160
Talk to you later.

00:48:47.160 --> 00:48:48.060
See you.

00:48:48.060 --> 00:48:48.360
Bye.

00:48:48.360 --> 00:48:52.980
This has been another episode of Talk Python to Me.

00:48:52.980 --> 00:48:55.100
Today's guest was Adrian Rosebrock.

00:48:55.100 --> 00:48:57.920
And this episode has been sponsored by Codeship.

00:48:57.920 --> 00:49:03.180
Please check them out at Codeship.com and thank them on Twitter via at Codeship.

00:49:03.180 --> 00:49:05.120
Don't forget the discount code for listeners.

00:49:05.120 --> 00:49:05.820
It's easy.

00:49:05.820 --> 00:49:06.980
Talk Python.

00:49:06.980 --> 00:49:08.340
All caps, no spaces.

00:49:09.120 --> 00:49:16.220
Remember, you can find the links from the show at Talk Python To Me.com slash episodes slash show slash 11.

00:49:16.220 --> 00:49:23.300
And if you want to support the show, please check out our Patreon campaign at Patreon.com slash mkennedy,

00:49:23.300 --> 00:49:26.480
where you can contribute as little as $1 per episode.

00:49:26.480 --> 00:49:28.960
Be sure to subscribe to the show.

00:49:28.960 --> 00:49:35.800
Visit the website and choose subscribe in iTunes or grab the episode RSS feed and drop it into your favorite podcatcher.

00:49:36.320 --> 00:49:38.280
You'll find both at the footer of every page.

00:49:38.280 --> 00:49:40.500
This is your host, Michael Kennedy.

00:49:40.500 --> 00:49:41.680
Thanks for listening.

00:49:41.680 --> 00:49:43.900
Smix, take us out of here.

00:49:43.900 --> 00:49:46.320
Stating with my voice.

00:49:46.320 --> 00:49:48.100
There's no norm that I can feel within.

00:49:48.100 --> 00:49:49.320
Haven't been sleeping.

00:49:49.320 --> 00:49:50.960
I've been using lots of rest.

00:49:50.960 --> 00:49:53.800
I'll pass the mic back to who rocked it best.

00:49:53.800 --> 00:50:06.120
I'll pass the mic back to who rocked it best.

