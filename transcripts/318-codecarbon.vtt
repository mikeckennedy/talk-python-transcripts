WEBVTT

00:00:00.001 --> 00:00:03.000
Machine learning has made huge advancements in the past couple of years.

00:00:03.000 --> 00:00:06.360
We now have ML models helping doctors catch disease early.

00:00:06.360 --> 00:00:13.280
Google is using machine learning to suggest routes in their Maps app that will lessen the amount of gasoline used in a trip, and many more examples.

00:00:13.280 --> 00:00:17.340
But there's also a heavy cost for training these machine learning models.

00:00:17.340 --> 00:00:21.560
In this episode, you'll meet Victor Schmidt, Jonathan Wilson, and Boris Feld.

00:00:21.560 --> 00:00:24.140
They work on the Code Carbon project together.

00:00:24.280 --> 00:00:32.180
This project offers a Python package and dashboarding tool that will help you understand and minimize your ML model's environmental impact.

00:00:32.180 --> 00:00:37.720
This is Talk Python To Me, episode 318, recorded May 19th, 2021.

00:00:50.920 --> 00:00:56.980
Welcome to Talk Python To Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:00:56.980 --> 00:00:58.760
This is your host, Michael Kennedy.

00:00:58.760 --> 00:01:00.980
Follow me on Twitter where I'm @mkennedy.

00:01:00.980 --> 00:01:04.700
And keep up with the show and listen to past episodes at talkpython.fm.

00:01:04.700 --> 00:01:07.820
And follow the show on Twitter via at Talk Python.

00:01:07.820 --> 00:01:12.260
This episode is brought to you by Square and us over at Talk Python Training.

00:01:12.260 --> 00:01:14.500
Please check out what we're offering during our segments.

00:01:14.500 --> 00:01:15.880
It really helps support the show.

00:01:16.880 --> 00:01:23.300
When you need to learn something new, whether it's foundational Python, advanced topics like async, or web apps and web APIs,

00:01:23.300 --> 00:01:27.900
be sure to check out our over 200 hours of courses at Talk Python.

00:01:27.900 --> 00:01:33.960
And if your company's considering how they'll get up to speed on Python, please recommend they give our content a look.

00:01:33.960 --> 00:01:34.660
Thanks.

00:01:34.660 --> 00:01:38.720
Boris, Victor, Jonathan, welcome to Talk Python To Me.

00:01:38.720 --> 00:01:39.600
Thanks for having us.

00:01:39.600 --> 00:01:40.360
Glad to be here.

00:01:40.360 --> 00:01:41.560
It's great to be here with you.

00:01:41.560 --> 00:01:42.220
Welcome, everyone.

00:01:42.340 --> 00:01:45.860
You all are doing really important work, and I'm super excited to talk to you about it.

00:01:45.860 --> 00:01:54.160
So we're going to talk about machine learning, how much carbon is being used for training machine learning models, and things like that.

00:01:54.160 --> 00:01:59.080
And some cool tools you built over at CodeCarbon.io and that collaboration you got going on there.

00:01:59.080 --> 00:02:04.200
But before we get into all those sides of the stories, let's just start with yours.

00:02:04.200 --> 00:02:05.180
Jonathan, you want to go first?

00:02:05.180 --> 00:02:06.160
How did you get into Python?

00:02:06.160 --> 00:02:06.620
Sure.

00:02:06.620 --> 00:02:07.720
Yeah, thanks for having us, Michael.

00:02:07.720 --> 00:02:08.580
My name is John Wilson.

00:02:08.580 --> 00:02:11.980
I'm an associate professor of environmental studies at Haverford College.

00:02:11.980 --> 00:02:13.180
I'm actually an environmental scientist.

00:02:13.180 --> 00:02:17.740
So I was brought in to kind of consult from the environmental side of this project.

00:02:17.740 --> 00:02:25.820
But I have a secret history as a computer science undergraduate back in the dark ages, learning to code on C, C++, and Java.

00:02:25.820 --> 00:02:30.140
And yeah, so I was brought in to kind of like provide that environmental perspective on the project.

00:02:30.360 --> 00:02:41.020
And, you know, having a little bit of a coding background, you know, despite how rusty it is, has been pretty helpful at thinking some of these connections through between computational issues and environmental issues.

00:02:41.020 --> 00:02:41.960
Yeah, I can imagine.

00:02:41.960 --> 00:02:46.060
Did you find Python to be pretty welcoming, given like a C background and stuff?

00:02:46.060 --> 00:02:46.820
Oh, gosh, yeah.

00:02:46.820 --> 00:02:54.100
I mean, you know, I learned back in the bad old days of, not bad old days, I shouldn't say that, scheme, things like that, you know, a little bit more challenging, you know, where it derives.

00:02:54.100 --> 00:02:58.400
Yeah, that's one of the first languages I had to learn for like a few CS classes I took.

00:02:58.400 --> 00:03:01.560
I was like, we're going to start with scheme, like anything with this.

00:03:01.560 --> 00:03:02.740
Give me something mainstream, please.

00:03:02.740 --> 00:03:11.280
Yeah, sometimes I feel like, you know, the sort of like older person, you know, telling the kids these days about how, you know, we had to walk uphill both ways in the snow to learn programming.

00:03:11.280 --> 00:03:12.680
And it's much, much easier.

00:03:12.680 --> 00:03:17.120
And it's one of the things I like about Python is it's really accessible to people from different fields.

00:03:17.280 --> 00:03:25.220
You know, you get into it from aspects of natural sciences, but even people who are like in the digital humanities are using it to, you know, for language processing and things like that.

00:03:25.220 --> 00:03:27.040
It's super flexible, which is really neat.

00:03:27.040 --> 00:03:31.460
Yeah, it's really impressive what people in those different fields are doing, how they can bring that in.

00:03:31.460 --> 00:03:32.560
Boris, how about yourself?

00:03:32.560 --> 00:03:33.220
How did you get into Python?

00:03:33.220 --> 00:03:36.240
I actually discovered Python during my master's degree.

00:03:36.240 --> 00:03:42.860
And I got a math teacher that introduced us to Python because they use Python for his own thesis.

00:03:43.460 --> 00:03:47.020
And I had one stuff to do, which was implementing RSA encryption.

00:03:47.020 --> 00:03:51.240
And I didn't want to do it because math was not my forte.

00:03:51.240 --> 00:03:55.080
So instead, I did some encryption inside images in Python.

00:03:55.080 --> 00:03:57.220
And I fell in love with Python.

00:03:57.220 --> 00:03:58.000
Oh, fantastic.

00:03:58.000 --> 00:03:58.780
Victor?

00:03:58.780 --> 00:04:04.200
I discovered this taking a data science class in, when was that?

00:04:04.200 --> 00:04:06.040
2014, I think it was.

00:04:06.040 --> 00:04:10.780
That's really, I really entered Python through the data science perspective.

00:04:11.620 --> 00:04:15.100
And then I took a course in general web development.

00:04:15.100 --> 00:04:16.400
And we used Django.

00:04:16.400 --> 00:04:16.980
Oh, right.

00:04:16.980 --> 00:04:17.480
Nice.

00:04:17.480 --> 00:04:21.100
And so it's been, yeah, so it's been really like the main language I've been using.

00:04:21.100 --> 00:04:24.100
I was taught CS with Java and so on.

00:04:24.100 --> 00:04:28.420
So I was never a computer science fan.

00:04:28.420 --> 00:04:30.080
Like, I liked math.

00:04:30.460 --> 00:04:33.180
And I found Python to be really flexible in that regard.

00:04:33.180 --> 00:04:36.680
Like, you can do math super easily without, like, getting lost in translation.

00:04:36.680 --> 00:04:37.000
Yeah.

00:04:37.000 --> 00:04:42.320
One of the things that just came out is one of the new Texas instruments, the TI-84 calculator.

00:04:42.320 --> 00:04:44.860
They have a, you can now program it with Python.

00:04:44.860 --> 00:04:53.240
So that's kind of interesting now that it's one of the old calculators that everyone's probably used going through math and whatnot.

00:04:53.480 --> 00:04:56.080
Is now sort of, you know, more in the modern space.

00:04:56.080 --> 00:05:01.600
I think my first program was on my TI because I was bored in math course.

00:05:01.600 --> 00:05:02.420
And I cannot follow.

00:05:02.420 --> 00:05:04.120
So instead, I wrote some programs.

00:05:04.120 --> 00:05:04.780
Yeah.

00:05:04.780 --> 00:05:07.160
That's not a terrible way to spend your time.

00:05:07.160 --> 00:05:07.880
All right.

00:05:07.880 --> 00:05:12.180
So let's go ahead and talk about the main, you know, get to the main subject here.

00:05:12.380 --> 00:05:15.240
So let's start by just setting the stage.

00:05:15.240 --> 00:05:18.340
There's an interesting article here that came out.

00:05:18.340 --> 00:05:19.600
This is not even that new.

00:05:19.600 --> 00:05:20.640
It's, you know, 2019.

00:05:20.640 --> 00:05:23.520
And it's in the MIT Technology Review.

00:05:23.520 --> 00:05:28.300
So, you know, that gives it probably a little more than just some random blog says this.

00:05:28.300 --> 00:05:30.740
And it's got a picture, a big picture of a data center.

00:05:30.740 --> 00:05:34.160
And the title of the article by Karen Ho is,

00:05:34.160 --> 00:05:40.100
Training a Single AI Model Can Emit As Much Carbon As Five Cars Throughout Their Lifetime.

00:05:40.100 --> 00:05:41.940
So that sounds pretty horrible.

00:05:42.520 --> 00:05:47.020
But we also know that machine learning has a lot of value to society,

00:05:47.020 --> 00:05:48.620
a lot of important things that it can do.

00:05:48.620 --> 00:05:50.720
So here's where we are.

00:05:50.720 --> 00:05:55.240
And this seems like a good place to start the conversation for what you all are doing.

00:05:55.240 --> 00:05:57.340
I have a mixed feeling about this article.

00:05:57.340 --> 00:06:03.100
I think one of the great things it did is raise a lot of attention and awareness about this topic.

00:06:03.100 --> 00:06:06.400
I think a lot of approximations were made.

00:06:06.400 --> 00:06:10.080
And the goal here is not to criticize authors,

00:06:10.280 --> 00:06:12.740
but rather to say that in the meantime,

00:06:12.740 --> 00:06:16.920
things have evolved and our understanding has, I think, been a little more precise.

00:06:16.920 --> 00:06:20.660
Well, maybe because people are building tools that measure it instead of estimate.

00:06:20.800 --> 00:06:22.040
So there's that, definitely.

00:06:22.040 --> 00:06:23.580
And we hope that helps.

00:06:23.580 --> 00:06:31.440
But it's also one of the things you need to put in perspective is that the kind of model they're looking at is not necessarily your everyday model.

00:06:31.440 --> 00:06:36.660
Someone can just train on their local computer or even in academia.

00:06:36.900 --> 00:06:43.640
It's hard to get your hands on such large clusters and the number of GPUs used and so on.

00:06:43.640 --> 00:06:48.340
So like, I just want to put that in perspective that even if those numbers were accurate,

00:06:48.340 --> 00:06:51.060
and they are not, but I mean, it's a ballpark.

00:06:51.220 --> 00:07:01.740
It's not like every data scientist you'll meet and every AI researcher you'll meet is going to have something in that level of complexity that they train every day.

00:07:01.740 --> 00:07:02.120
Right.

00:07:02.120 --> 00:07:06.620
So I have over here a sim racing setup for some sim racing I do,

00:07:06.620 --> 00:07:10.440
and it has a GeForce 2070 in it.

00:07:10.440 --> 00:07:14.340
It would have to run a very long time to emit this much carbon, right?

00:07:14.340 --> 00:07:21.080
Like, you got to have the necessary money and compute resources to, you know, even get there, right?

00:07:21.080 --> 00:07:21.380
Yeah.

00:07:21.380 --> 00:07:26.600
Like the number, I don't remember exactly the setup that they're looking at in this paper,

00:07:26.600 --> 00:07:32.000
but like typically the modern language models that you hear about, like, oh,

00:07:32.000 --> 00:07:38.760
OpenAI has a new NLP model and like GPG-3, and it's that number of billion of parameters.

00:07:38.760 --> 00:07:43.500
Like, they train those things on hundreds and hundreds of machines for a very long time.

00:07:43.580 --> 00:07:44.960
This is not something you can do easily.

00:07:44.960 --> 00:07:52.460
It costs millions of dollars in investment upfront, and then just using those things is super expensive.

00:07:52.460 --> 00:07:56.560
So while I think we should be careful, it's not like the whole field is like that.

00:07:56.560 --> 00:07:57.600
Yeah, that's a very good point.

00:07:57.600 --> 00:08:02.000
I recall there was some cancer research that needed to answer some big problem,

00:08:02.000 --> 00:08:10.520
and there was an article where they spun up something like 6,000 virtual machines across AWS clusters for an hour

00:08:10.520 --> 00:08:15.140
and had it go crazy to answer, you know, some protein folding question or something like that.

00:08:15.140 --> 00:08:18.760
That would use a lot of energy, but it's extremely, extremely rare as well.

00:08:18.760 --> 00:08:23.460
On the other hand, you know, if you created that model and it solved cancer, well, you know,

00:08:23.460 --> 00:08:27.580
people drive cars all the time for less valuable reasons than, you know, curing cancer.

00:08:27.780 --> 00:08:32.660
Yeah, and I think just to build on what Victor said, you know, I think there was something really valuable about this article coming out.

00:08:32.660 --> 00:08:39.840
You know, I think for a long time, there's been attention that's been paid to the sort of environmental toll of supply chains in computing.

00:08:39.840 --> 00:08:42.280
You know, people have talked a lot about where minerals come from.

00:08:42.500 --> 00:08:48.440
Yeah, and one of the things that was really interesting about this article was, you know, with the approximations,

00:08:48.440 --> 00:08:52.220
it caught people thinking about the question that kind of animates our collaboration,

00:08:52.220 --> 00:08:56.560
which is when you're doing any kind of energy-intensive computational issue,

00:08:56.560 --> 00:08:59.780
you might want to think about where your electrons come from.

00:08:59.780 --> 00:09:04.000
You know, what's actually powering the hardware that you're using to do this?

00:09:04.040 --> 00:09:09.900
And I think this article did a really nice job of, like, focusing attention that there are some really energy-intensive projects

00:09:09.900 --> 00:09:14.240
that in particular ways, particularly if they're located in particular locations,

00:09:14.240 --> 00:09:20.980
they can have a really large environmental cost that isn't really transparent to the user or the person training the model.

00:09:20.980 --> 00:09:21.300
Yeah, yeah.

00:09:21.300 --> 00:09:23.820
Well, I don't want to go down this road just yet.

00:09:23.820 --> 00:09:26.200
I want to keep talking about the more high-level a little bit.

00:09:26.200 --> 00:09:29.180
But, you know, if the people who did this very expensive model,

00:09:29.180 --> 00:09:32.340
if they just said, I'm going to pick the closest AWS data center to me,

00:09:32.720 --> 00:09:39.320
that rather than, let me find the data center by just flipping a switch and say,

00:09:39.320 --> 00:09:43.540
no, no, maybe the one up in Prinnville, Oregon, by the dam,

00:09:43.540 --> 00:09:47.520
would be better than the one by the coal factory, for example, right?

00:09:47.520 --> 00:09:51.220
Like, that's something they could easily do, and it maybe doesn't change anything for them, right?

00:09:51.220 --> 00:09:54.660
Yeah, it's not always the case, because when you have, for example, health data and so on,

00:09:54.660 --> 00:09:58.580
there are legislations, but definitely, like, if you can,

00:09:58.580 --> 00:10:02.680
and there's more than just the money at stake here,

00:10:02.680 --> 00:10:05.060
and it's probably going to be a marginal change,

00:10:05.060 --> 00:10:09.400
because the prices tend to be not equal, but kind of uniform still.

00:10:09.600 --> 00:10:12.140
I think it's another decision item.

00:10:12.140 --> 00:10:12.520
Yeah.

00:10:12.520 --> 00:10:15.660
Boris, you got any thoughts on this article before we move on?

00:10:15.660 --> 00:10:21.400
Yeah, I think it came with a good, to highlight a serious issue,

00:10:21.400 --> 00:10:26.000
and if people want to improve it, as most of my manager told me,

00:10:26.000 --> 00:10:28.360
if you want to improve it, you must measure it before.

00:10:28.360 --> 00:10:39.720
So we are there to give us a start of an answer to, and give them action how to improve the cut carbon emission on training models.

00:10:39.720 --> 00:10:44.000
Hopefully to not train less models, but train better models.

00:10:44.000 --> 00:10:44.300
Yeah.

00:10:44.420 --> 00:10:50.340
I think, for example, this is part of what the recent Google paper, led by David Patterson,

00:10:50.340 --> 00:10:54.580
on training neural networks and their environmental impact.

00:10:54.580 --> 00:10:58.800
This is one of the things they say, and it's quite a dense paper,

00:10:58.800 --> 00:11:00.980
and a lot of metrics and so on.

00:11:00.980 --> 00:11:02.040
But one of the things they say is,

00:11:02.280 --> 00:11:06.760
if you don't want people caricaturing your numbers and putting approximations out there,

00:11:06.760 --> 00:11:09.660
well, you'd better publish those numbers yourself, right?

00:11:09.660 --> 00:11:11.580
And you need tools to do that.

00:11:11.580 --> 00:11:17.340
So if you're Google or if you're close to the infrastructure that you use, it's easier.

00:11:17.340 --> 00:11:20.140
It's even better if you have access to the plugs.

00:11:20.140 --> 00:11:22.040
But that's not the case of everyone, right?

00:11:22.040 --> 00:11:22.340
Right.

00:11:22.340 --> 00:11:27.560
So you're saying if you could put something to actually measure the electricity going through the wire,

00:11:27.560 --> 00:11:30.880
instead of some approximation, you're in a better place to know the answer.

00:11:30.880 --> 00:11:31.580
Yeah, definitely.

00:11:32.180 --> 00:11:36.180
That's where I think we might be a little ahead of your schedule,

00:11:36.180 --> 00:11:38.060
but we might go there still.

00:11:38.060 --> 00:11:41.240
Which is like, that's where Code Carbon comes into play, right?

00:11:41.240 --> 00:11:43.140
This is why we want to create this tool.

00:11:43.140 --> 00:11:46.220
This is a user-facing product, right?

00:11:46.220 --> 00:11:48.680
And I think it's very important to highlight that.

00:11:48.680 --> 00:11:53.880
It is not intended to be the solution for a data center.

00:11:53.880 --> 00:11:58.900
This is not something that we think should be deployed as a cloud provider,

00:11:58.900 --> 00:12:00.860
or if you own your own infrastructure,

00:12:01.080 --> 00:12:04.160
if you want to have centralized numbers, there are alternatives out there.

00:12:04.160 --> 00:12:04.420
Yeah.

00:12:04.420 --> 00:12:06.160
Things like scapandre.

00:12:06.160 --> 00:12:08.100
I don't know how you say that.

00:12:08.100 --> 00:12:08.700
It's a French word.

00:12:08.700 --> 00:12:10.440
Anyway, it's out there on GitHub.

00:12:10.440 --> 00:12:11.720
You can find it by just looking this way.

00:12:11.720 --> 00:12:15.420
But the goal here is, as a user, what can you do if you don't have those numbers?

00:12:15.420 --> 00:12:21.940
Do you do nothing, or do you try to at least have the start of an estimation,

00:12:22.260 --> 00:12:26.660
and maybe start the conversation with your organization or your provider?

00:12:26.660 --> 00:12:27.520
Yeah, fantastic.

00:12:27.520 --> 00:12:31.700
And you guys are putting some really concrete things out there for Python developers.

00:12:31.700 --> 00:12:33.800
Two quick high-level comments.

00:12:33.800 --> 00:12:36.620
One, Corey Adkins from the live stream says,

00:12:36.620 --> 00:12:39.400
would it be the same or worse for quantum computers?

00:12:39.400 --> 00:12:41.740
Okay, I'm going to talk out of my depth here.

00:12:41.740 --> 00:12:45.860
So the first, the best answer I can use, I don't know.

00:12:45.860 --> 00:12:51.140
And then to go beyond that, my understanding of quantum computers is that they do very different

00:12:51.140 --> 00:12:51.400
things.

00:12:51.400 --> 00:12:57.240
And you can't just compare the computations made on classical computers with the things

00:12:57.240 --> 00:12:59.400
quantum computers are intended for.

00:12:59.680 --> 00:13:05.640
I think intrinsically, because of the state of that technology, it is extremely energy intensive,

00:13:05.640 --> 00:13:10.800
just because you usually have to pull things down to a few millikelvins or something like that.

00:13:10.800 --> 00:13:13.300
So that may be transitory.

00:13:13.300 --> 00:13:14.120
I'm not sure.

00:13:14.120 --> 00:13:15.220
I don't know about that either.

00:13:15.220 --> 00:13:16.720
I was thinking the same thing.

00:13:16.720 --> 00:13:19.520
You know, just yesterday, Google had Google I.O.

00:13:19.520 --> 00:13:25.000
And they talked about building clusters of qubit sort of supercomputer type things.

00:13:25.560 --> 00:13:31.120
And apparently, they've got to cool it down so much that it's some of the coldest places in the

00:13:31.120 --> 00:13:32.420
universe inside those.

00:13:32.420 --> 00:13:37.020
So on one hand, if quantum computers can do the math super quick, it doesn't take a lot of time

00:13:37.020 --> 00:13:38.460
to run them to get the answer.

00:13:38.460 --> 00:13:41.620
But on the other, if you've got to keep them that cold, that can't be free.

00:13:41.620 --> 00:13:44.600
But it's a very particular kind of math, right?

00:13:44.600 --> 00:13:51.580
And not all problems are translatable from the classical formulation to a quantum compatible

00:13:51.580 --> 00:13:52.120
formulation.

00:13:52.120 --> 00:13:52.940
I'm not sure.

00:13:53.060 --> 00:13:57.620
I think there are problems that we can solve easily on our classical computers that would be

00:13:57.620 --> 00:14:01.540
very hard, if not theoretically impossible to run on quantum computers.

00:14:01.540 --> 00:14:06.240
And it's like, it's a different tool and it's not intended for the same problems.

00:14:06.240 --> 00:14:08.320
So I think it's hard to compare.

00:14:08.320 --> 00:14:08.640
Yeah.

00:14:08.640 --> 00:14:14.600
You will still have some parts of the model training that won't run on quantum computers

00:14:14.600 --> 00:14:15.720
because that doesn't make sense.

00:14:15.720 --> 00:14:21.240
Like pre-processing data, getting data from your different data source, mapping them to a

00:14:21.240 --> 00:14:25.900
common format, exporting your model, creating Docker images, servers.

00:14:25.900 --> 00:14:32.220
There will still be part of the model training process that won't run on those quantum computers.

00:14:33.160 --> 00:14:37.460
This portion of Talk Python To Me is brought to you by Square.

00:14:37.720 --> 00:14:42.500
Payment acceptance can be one of the most painful parts of building a web app for a business.

00:14:42.500 --> 00:14:47.480
When implementing checkout, you want it to be simple to build, secure, and slick to use.

00:14:47.480 --> 00:14:56.800
Square's new web payment SDK raises the bar in the payment acceptance developer experience and provides a best-in-class interface for merchants and buyers.

00:14:57.280 --> 00:15:02.360
With it, you can build a customized, branded payment experience and never miss a sale.

00:15:02.360 --> 00:15:08.800
Deliver a highly responsive payments flow across web and mobile that integrates with credit cards and debit cards,

00:15:08.800 --> 00:15:13.460
digital wallets like Apple Pay and Google, ACH bank payments, and even gift cards.

00:15:13.460 --> 00:15:20.240
For more complex transactions, follow-up actions by the customer can include completing a payment authentication step,

00:15:20.240 --> 00:15:25.580
filling in a credit line application form, or doing background risk checks on the buyer's device.

00:15:26.040 --> 00:15:29.400
And developers don't even need to know if the payment method requires validation.

00:15:29.400 --> 00:15:34.400
Square hides the complexity from the seller and guides the buyer through the necessary steps.

00:15:34.400 --> 00:15:37.140
Getting started with a new web payment SDK is easy.

00:15:37.140 --> 00:15:43.000
Simply include the web payment SDK JavaScript, flag an element on the page where you want the payment form to appear,

00:15:43.000 --> 00:15:45.340
and then attach hooks for your custom behavior.

00:15:45.340 --> 00:15:51.600
Learn more about integrating with Square's web payments SDK at talkpython.fm/square,

00:15:51.600 --> 00:15:54.160
or just click the link in your podcast player's show notes.

00:15:54.160 --> 00:15:56.360
That's talkpython.fm/square.

00:15:56.360 --> 00:16:04.280
Another thing I think it's worth pointing out is it's the training of the models that is expensive,

00:16:04.280 --> 00:16:07.540
but to use them to get an answer, it's pretty quick, right?

00:16:07.540 --> 00:16:09.220
That's pretty low cost.

00:16:09.460 --> 00:16:11.520
It depends on what you're using it for, right?

00:16:11.520 --> 00:16:16.960
So if you have a user-facing model that's going to serve thousands of requests per second,

00:16:16.960 --> 00:16:23.980
then deploying it for a year might be more energy intensive than training it for three days.

00:16:24.100 --> 00:16:28.900
We all know the machine learning lifecycle is not just like you train one model and you succeed and well,

00:16:28.900 --> 00:16:30.000
hooray, right?

00:16:30.000 --> 00:16:35.160
You usually have a lot of iterations, building the models, looking for hyperparameters and so on.

00:16:35.160 --> 00:16:42.560
But even if that takes six months and your model stays online for months or years and serving thousands of people,

00:16:42.800 --> 00:16:43.940
it's not obvious.

00:16:43.940 --> 00:16:48.620
It might even be worse, not worse, more energy intensive.

00:16:48.620 --> 00:16:51.300
Yeah, I guess it depends how many times you run it.

00:16:51.300 --> 00:16:55.640
Another thought, you know, there's a lot of places creating models, like you talked about,

00:16:55.640 --> 00:17:01.260
was it GP3, GPT-3, and whatnot, that are training the models and letting people use them.

00:17:01.640 --> 00:17:07.360
Do you see that as a thing that might be useful and helpful is having these pre-created, pre-trained models?

00:17:07.360 --> 00:17:11.140
Like I know Microsoft has a bunch of pre-trained models with their cognitive services,

00:17:11.140 --> 00:17:16.740
and Apple has their ML stuff like baked into their devices that you don't have to train, you can just use.

00:17:16.740 --> 00:17:20.440
Are the problems being solved and the data being understood usually too general,

00:17:20.440 --> 00:17:22.520
or is that something we can make use of?

00:17:22.520 --> 00:17:29.140
I think pre-trained models are the advantage to keep, as you are training a model once,

00:17:29.460 --> 00:17:35.100
the cost emission of the model during training is amortized for each usage.

00:17:35.100 --> 00:17:40.340
So the more user you have, the more part of the training emission is low.

00:17:40.340 --> 00:17:47.040
But usually you still have to tune the model a bit, so you still have to train it,

00:17:47.040 --> 00:17:50.480
and you're using energy even for prediction.

00:17:50.480 --> 00:17:51.740
So yes and no.

00:17:51.740 --> 00:17:57.840
I'm going to also do the transition to throw the ball to Jonathan for something I think we shouldn't forget

00:17:57.840 --> 00:18:01.420
when we talk about these gains in efficiency, which is like Jevon's paradox,

00:18:01.420 --> 00:18:07.360
and the fact that if you create something that is cheaper to use, and more people use it,

00:18:07.360 --> 00:18:10.900
then the overall impact is lower.

00:18:10.900 --> 00:18:15.840
And I think this is something we tend to forget when we talk about massive improvements,

00:18:15.840 --> 00:18:21.480
or not even massive, just like this is something that is, I think, hard to grasp and anticipate

00:18:21.480 --> 00:18:25.380
when you think about technological advances under the constraint of climate change.

00:18:25.380 --> 00:18:32.820
But this rebound effect is something we should plan for and not just think, well, if you have cheaper models,

00:18:32.820 --> 00:18:38.340
but more people can use them, I think it's not that obvious that it's an overall gain in terms of energy.

00:18:38.440 --> 00:18:44.120
Like then you can talk about all the societal consequences and the advances in cancer research.

00:18:44.120 --> 00:18:46.420
It's really hard to have a definitive answer.

00:18:46.420 --> 00:18:52.860
Yeah, just to build on what Victor said, it really is a difficult, I mean, this is a classic environmental conundrum, right?

00:18:52.860 --> 00:18:59.200
When, you know, the classic example of the Jevons paradox is, you know, adding more roads leads to more traffic

00:18:59.200 --> 00:19:02.040
because more people believe that there's more space for them to drive.

00:19:02.040 --> 00:19:06.580
And so you've seen this over and over again in all sorts of different contexts, that when you build these tools,

00:19:06.580 --> 00:19:12.440
more people will use them and that can end up costing more than not building them in the first place.

00:19:12.440 --> 00:19:16.940
So I think this is something to really be aware of, you know, as we're democratizing these kinds of tools.

00:19:16.940 --> 00:19:18.740
There's a real pro here.

00:19:18.740 --> 00:19:23.680
There are some real strengths of having these tools, you know, easily accessible and that can be used.

00:19:23.680 --> 00:19:30.220
But one has to worry about the potential costs of, you know, having all these tools being employed,

00:19:30.220 --> 00:19:34.800
in particular being employed in all sorts of different kind of sub-energy grids around the world.

00:19:34.800 --> 00:19:37.500
Not all grids are, you know, connected up to solar panels.

00:19:37.500 --> 00:19:42.320
You know, many are connected to coal-fired power plants and that can outweigh the cost.

00:19:42.320 --> 00:19:45.440
Yeah, we can hope, but it's not today, is it?

00:19:45.440 --> 00:19:46.860
Yeah, not yet, not yet.

00:19:46.860 --> 00:19:48.880
One would hope, but maybe soon.

00:19:48.880 --> 00:19:54.940
One last thought about pre-trained model is usually they are trained for more diverse usage.

00:19:54.940 --> 00:20:04.780
So I would think that they tend to be larger than model trained, especially for a single usage inside a single company with a single type of data.

00:20:04.780 --> 00:20:11.820
So I would say they are likely bigger, so they use more energy to train and to use, but by homage, I couldn't say.

00:20:11.820 --> 00:20:12.060
Yeah.

00:20:12.500 --> 00:20:21.640
Well, I think the paradox that you all are speaking about, you know, one of the ways we could see that is just the ability to use machine learning to solve problems is so much easier now.

00:20:21.640 --> 00:20:28.800
That what used to be a simple if-else runs in a microsecond is now a much more complicated part of your program.

00:20:28.800 --> 00:20:32.640
And so, yeah, there's got to be just a raising of the cost there.

00:20:32.780 --> 00:20:39.640
Now, before we make it all sound like machine learning bad for the environment, 100%, there are good things, you know.

00:20:39.640 --> 00:20:56.580
Google, like I said, Google I.O. was yesterday, and they were talking about doing the navigation so that taking into account things like topography, speed, and whatnot, to actually try to optimize, minimize gas consumption with the directions they give you, right?

00:20:56.580 --> 00:21:04.180
And if they could do that with a little bit of computer code to save a ton of CO2 out of cars, like that's a really big win.

00:21:04.180 --> 00:21:04.960
More ML.

00:21:04.960 --> 00:21:05.660
Definitely.

00:21:05.660 --> 00:21:19.960
And I think the reason why we're like, we have started with the online carbon emissions on our side at Mila in Montreal, and Jonathan and colleagues at Haverford with energy usage, and then we came together for quick carbon.

00:21:19.960 --> 00:21:27.660
It's not to say that machine learning is bad, like just as most technologies, it's technology, and it depends on how you use it.

00:21:27.660 --> 00:21:37.500
But where we're going as societies under the constraint of climate change can't leave any field out of questioning themselves of how they use their resources.

00:21:37.500 --> 00:21:43.700
So, yeah, it's something you can't leave out of the picture, which doesn't mean that you can't use it.

00:21:43.700 --> 00:21:48.260
It's like you have to think about it, and we can't have a single rule for everyone.

00:21:48.260 --> 00:21:53.180
It's just you have to take that into account, and you can very well make the decision that it is worth it.

00:21:53.180 --> 00:21:54.580
In many cases, it will be.

00:21:54.580 --> 00:21:55.640
Sometimes, maybe not.

00:21:55.640 --> 00:21:56.680
But be conscious of it.

00:21:56.680 --> 00:21:57.560
Yeah, for sure.

00:21:57.560 --> 00:21:58.140
All right.

00:21:58.140 --> 00:22:01.440
So, I think that brings us to your project, Code Carbon.

00:22:01.440 --> 00:22:03.780
You mentioned it a couple of times.

00:22:03.780 --> 00:22:16.180
So, looking in from the outside, it seems to me like the primary thing that what you guys have done is you've built some Python libraries, a Python package that lets you answer these questions and track these things, right?

00:22:16.180 --> 00:22:19.380
And then a dashboard and data that will help you improve it.

00:22:19.380 --> 00:22:21.280
Is that a good elevator pitch?

00:22:21.280 --> 00:22:21.840
Very good.

00:22:21.840 --> 00:22:22.980
Fantastic.

00:22:22.980 --> 00:22:23.920
All right.

00:22:23.920 --> 00:22:24.900
So, tell us about Code Carbon.

00:22:24.900 --> 00:22:25.700
Do you want to work for us?

00:22:25.700 --> 00:22:26.260
Yeah, sure.

00:22:26.260 --> 00:22:28.240
I'm not busy enough yet.

00:22:28.240 --> 00:22:29.860
We don't have any money, though.

00:22:29.860 --> 00:22:30.420
Oh, good.

00:22:30.420 --> 00:22:31.880
No, but I think it's a great cause.

00:22:31.880 --> 00:22:33.560
And so, tell everyone about it.

00:22:33.600 --> 00:22:34.500
Thank you for the opportunity.

00:22:34.500 --> 00:22:46.180
I think one of the reasons we came together was like, we all know that in the machine learning lifecycle, a lot of the computations you just forget about because there are so many experiments that you run.

00:22:46.180 --> 00:22:50.960
Like, say you have a project and you're going to work on it for like 3, 6, 12 months.

00:22:50.960 --> 00:22:52.460
How many experiments are you going to run?

00:22:52.460 --> 00:22:54.340
How many hyperparameter searches are you going to run?

00:22:54.340 --> 00:22:57.120
It's a very important problem.

00:22:57.120 --> 00:23:02.680
I think this is also something that is central to Comet.ml, which is the company where Boris works.

00:23:03.420 --> 00:23:05.600
They manage experiments.

00:23:05.600 --> 00:23:09.040
And I use that in my daily work.

00:23:09.040 --> 00:23:11.820
And I thought, well, we need something similar to track the carbon.

00:23:11.820 --> 00:23:14.000
It can't just be about the metrics.

00:23:14.000 --> 00:23:18.680
It can't just be about the images you generate because you're turning a GAN, for instance.

00:23:19.000 --> 00:23:21.100
So, how do we go about this?

00:23:21.100 --> 00:23:29.520
And, well, because Python was, I think, the go-to language for AI research and development also.

00:23:29.980 --> 00:23:32.820
Although, in very optimized settings, you might want to go away from that.

00:23:32.820 --> 00:23:36.660
But we thought, well, we need to do something that is going to be plug and play.

00:23:36.660 --> 00:23:37.940
So, it has to be Python.

00:23:37.940 --> 00:23:39.700
It has to run in the background.

00:23:39.700 --> 00:23:40.800
It has to be light.

00:23:41.360 --> 00:23:52.820
And it has to be also something that is versatile in that it is not only about you're just getting yet another metric, but it's also about understanding what it means.

00:23:52.820 --> 00:23:55.240
It's about also education.

00:23:55.240 --> 00:23:59.140
It's about education for yourself, but also maybe for other members of your organization.

00:23:59.140 --> 00:24:06.060
The people who might say, like, say you work in a company and you're thinking, well, I have hundreds of data scientists.

00:24:06.060 --> 00:24:07.600
Like, this is not marginal.

00:24:07.600 --> 00:24:09.280
I want to have an estimation.

00:24:09.800 --> 00:24:16.540
And if estimation is not good enough for you, well, contact your provider and maybe have a wattmeter plugged in somewhere where it matters.

00:24:16.540 --> 00:24:17.840
It's not my expertise.

00:24:17.840 --> 00:24:19.300
But that's basically the idea.

00:24:19.300 --> 00:24:19.820
Yeah, yeah.

00:24:19.820 --> 00:24:24.520
Well, I think plugging in a wattmeter somewhere, that used to be a thing that you could do.

00:24:24.520 --> 00:24:29.920
But now it's Amazon or Azure or Linode or whoever.

00:24:29.920 --> 00:24:33.100
They're not going to let you go plug it into their data center.

00:24:33.100 --> 00:24:35.540
And if you did, there's probably a bunch of other things happening there, right?

00:24:35.540 --> 00:24:39.620
Direct access to the compute resources is just hard to come by.

00:24:39.720 --> 00:24:40.240
Yeah, exactly.

00:24:40.240 --> 00:24:42.280
This is a very big constraint for us.

00:24:42.280 --> 00:24:45.260
I think I expect we'll get into a little more details about that.

00:24:45.260 --> 00:24:50.940
But this is why you need to understand carbon as a tool to estimate things and have approximations.

00:24:50.940 --> 00:24:52.100
And we use heuristics.

00:24:52.100 --> 00:24:59.480
And basically, if a consultant is having you pay for carbon offsets based on those kinds of numbers, you shouldn't pay.

00:24:59.480 --> 00:25:00.680
Because that's not the point.

00:25:00.680 --> 00:25:02.720
Yeah, it's really about giving you the information.

00:25:02.720 --> 00:25:07.020
One of the things I like about what you're doing is you can recommend other areas.

00:25:07.020 --> 00:25:09.200
Like we talked about, like you could switch to this data center.

00:25:09.640 --> 00:25:11.000
And then it would have this impact, right?

00:25:11.000 --> 00:25:13.020
Yeah, I think it's part of the educational mission.

00:25:13.020 --> 00:25:18.500
It's like we all know, or at least I wish we all knew or we want everyone to know.

00:25:18.500 --> 00:25:19.340
I don't know how to put that.

00:25:19.340 --> 00:25:23.240
But that it's the climate change is a very serious threat.

00:25:23.240 --> 00:25:32.220
And being conscious about your energy usage and your consumption of resources in general is one thing.

00:25:32.220 --> 00:25:32.840
It's very important.

00:25:32.840 --> 00:25:36.800
But then I think you consciously leave people out there with that feeling of guilt.

00:25:36.800 --> 00:25:39.080
And there has to be actionable items.

00:25:39.080 --> 00:25:44.900
Changing your region is probably the easiest thing you can do, especially in the age of the cloud.

00:25:44.900 --> 00:25:53.860
And at a time when basically moving your data across continents is about picking a few checkboxes on a web interface.

00:25:54.580 --> 00:25:54.620
Yeah.

00:25:54.620 --> 00:26:01.240
I think just to pick up a little bit on what Vic Victor has said here is that the educational part of this is a very important part of the Code Carbon project.

00:26:01.240 --> 00:26:11.860
Because we know as we have been involved in this, that answering this question, like what's the CO2 footprint of my computational work, is actually a very, very difficult question to answer.

00:26:11.860 --> 00:26:14.260
And it's opaque for a variety of reasons.

00:26:14.260 --> 00:26:23.200
It's opaque because the way that the energy industry deals with CO2 emissions is pretty opaque, unless you know the language of how they express this.

00:26:23.200 --> 00:26:28.900
And it's also difficult to understand when you are able to make the calculation, what does that mean?

00:26:29.120 --> 00:26:34.240
What's one gram of CO2 emitted relative to, say, everyday activities?

00:26:34.240 --> 00:26:39.840
So one of the things that we've tried to do as part of this dashboard is simplify those two steps for people.

00:26:39.840 --> 00:26:45.860
Because we've been approached by people via email, via Slack, and we know we're not the only people concerned about this.

00:26:45.860 --> 00:26:56.280
And so this is just a way to help make these approximations both visible, but also kind of comprehensible and put it in the context of human activities.

00:26:56.280 --> 00:26:56.680
You're right.

00:26:56.720 --> 00:27:03.760
There's a lot of layers and, you know, companies that run the clouds, they are trying to be more responsible with their energy.

00:27:03.760 --> 00:27:04.460
But you don't know.

00:27:04.460 --> 00:27:14.160
A lot of times you don't know if this data center, US, East, one, and AWS, how much energy from different sources is that actually using?

00:27:14.160 --> 00:27:18.020
How much have they actually built their own solar and wind?

00:27:18.020 --> 00:27:19.180
We don't know, right?

00:27:19.180 --> 00:27:21.460
But you get a better sense using your tool.

00:27:21.460 --> 00:27:27.680
You've got better data than the random person who just kind of estimates, well, they're doing some stuff, so it must be fine.

00:27:27.680 --> 00:27:39.520
Another important thing I think is, and Jonathan is much more an expert in that than I am, but not emitting is very different from offsetting in whatever way, wrecks or whatever.

00:27:39.520 --> 00:27:40.360
Yeah.

00:27:40.360 --> 00:27:44.220
Your emissions and our atmosphere, our climate has inertia.

00:27:44.220 --> 00:27:51.820
And the expected compensation in 5, 10, 20 years of your current emissions.

00:27:51.820 --> 00:27:54.120
Those are two very different things, right?

00:27:54.120 --> 00:28:00.260
And it's much easier to put carbon in the atmosphere than taking it away from it.

00:28:00.260 --> 00:28:10.060
And so I think it's not just because you read Google and others, Microsoft are carbon neutral, which comes from compensations of many forms.

00:28:10.060 --> 00:28:13.420
It doesn't mean no carbon was emitted, right?

00:28:13.420 --> 00:28:29.480
Yeah, there's just to build on Victor's point again, you know, there's decades of research in sort of what you'd call, you know, environmental psychology, explaining to people the consequences of inaction or, you know, of diffuse environmental costs to a particular action causes long-term behavior change.

00:28:29.480 --> 00:28:48.600
And I think, you know, one of the things that's been really exciting about seeing the, you know, the machine learning and AI communities kind of like grapple with this question in a very public way is we've started to see articles of, you know, pressure being put on organizations to why don't we have more green energy infrastructure, you know, undergirding our work.

00:28:48.600 --> 00:28:58.240
And so, you know, the speed at which this has become, you know, a public conversation is really heartening, you know, as somebody who's been working in the environment for quite a bit of time.

00:28:59.020 --> 00:29:02.140
Yeah, I would say it does seem to be getting a lot of attention, which is good.

00:29:02.140 --> 00:29:03.020
It's a big problem.

00:29:03.020 --> 00:29:06.560
But attention instead of just head in the sand is a really big deal.

00:29:06.560 --> 00:29:08.220
Like we've been driving cars for a long time.

00:29:08.220 --> 00:29:10.060
We've been flying planes for a long time.

00:29:10.060 --> 00:29:17.380
There's a lot of like raised trucks with super big wheels with, you know, dual coal stack pipes on them, right?

00:29:17.380 --> 00:29:20.280
Like that's, I can't speak for everyone that gets a truck like that.

00:29:20.280 --> 00:29:29.000
But I feel there's a lot of times when we have these conversations, people are just like, well, this is so horrible and so vague that I'm just going to live my life and enjoy it.

00:29:29.000 --> 00:29:31.480
Because I seem to not be able to do anything anyway.

00:29:31.480 --> 00:29:36.180
So I might as well have fun instead of not have fun while things are going wrong, right?

00:29:36.180 --> 00:29:37.700
Like that's kind of that psychology, right?

00:29:37.700 --> 00:29:38.580
And so I don't know.

00:29:38.580 --> 00:29:39.360
How do you all deal with that?

00:29:39.360 --> 00:29:47.560
It's also something that like when it's not before your eyes, it's much more difficult to answer, to understand and to respond to.

00:29:47.560 --> 00:30:00.020
And I think this is part of what we're seeing today with decades of activism is like facts, hard facts are not enough to convince humans.

00:30:00.020 --> 00:30:02.820
And then to some extent, it's also a good thing.

00:30:02.820 --> 00:30:06.100
And it has, I think, value in our recognition.

00:30:06.100 --> 00:30:18.540
But it also has this downside that it's just because you say a number to someone, if they don't understand it, if they don't see it for themselves in their everyday life, it's going to be very hard to understand.

00:30:18.540 --> 00:30:29.200
So until you have used something like Code Carbon, like I code every day, I train models every day, and I train a model for five days on a GPU in Quebec.

00:30:29.200 --> 00:30:31.400
That's my daily life, basically.

00:30:31.400 --> 00:30:33.300
And some might find it dull.

00:30:33.300 --> 00:30:34.520
I like it.

00:30:34.520 --> 00:30:36.600
Anyway, that's not the point.

00:30:36.980 --> 00:30:39.940
I mean, until you have that and you're like, oh, this is what I do.

00:30:39.940 --> 00:30:41.860
Those numbers start to make sense.

00:30:41.860 --> 00:30:48.500
Even if you have numbers for your day to day, that doesn't seem that much, like thousands of grams or kilograms.

00:30:48.900 --> 00:31:06.100
But once you sum all the emissions for all the model trained, for all the machine learning teams, for all the machine learning data scientists, for a company for a year or even for academia, that start to get, depending on your size of the company, of course, that start to get sizable.

00:31:06.100 --> 00:31:09.500
And you might want to take a serious look at it.

00:31:09.500 --> 00:31:09.780
Yeah.

00:31:09.780 --> 00:31:12.620
I want to dive into the code and talk about this.

00:31:13.140 --> 00:31:17.180
But I guess maybe speak really quickly to, I work at a company.

00:31:17.180 --> 00:31:18.820
We make shoes.

00:31:18.820 --> 00:31:26.000
They want me to use ML to figure out how to get better behaviors out of the materials for track runners or whatever.

00:31:26.000 --> 00:31:26.800
So I do that.

00:31:26.800 --> 00:31:35.980
That company, how do I get that company to say, yes, we should measure our scientific data science work and we should offset it?

00:31:35.980 --> 00:31:43.240
There's a lot of layers between the people who care about shoes and sales and people who care about machine learning carbon offsets.

00:31:43.240 --> 00:31:53.740
My personal understanding of this situation is that empowering individuals with tools and numbers to convince organizations is part of our mission.

00:31:53.740 --> 00:32:08.220
So if what the person in charge, whatever their role in the organization, thinks that in order to have an estimation of their carbon impact, they have to find a consulting firm, pay people for five weeks.

00:32:08.220 --> 00:32:11.840
If they think this is the process, they're going to be reluctant.

00:32:11.840 --> 00:32:13.860
And I can understand why.

00:32:14.240 --> 00:32:22.460
If you have a plug and play tool that even you as the evangelizer, if that's a word, you get the idea.

00:32:22.460 --> 00:32:23.260
Yeah.

00:32:23.260 --> 00:32:24.820
It doesn't cost you much to try.

00:32:24.820 --> 00:32:29.380
The way we want to build this thing is just like one import and full of lines.

00:32:29.380 --> 00:32:29.660
Yeah.

00:32:29.660 --> 00:32:30.360
So, yeah.

00:32:30.360 --> 00:32:31.260
So let's talk about the code.

00:32:31.260 --> 00:32:38.620
I think maybe the answer, maybe an approach that you could have there is we'll run something like this on all of the training that we do.

00:32:38.700 --> 00:32:43.460
And then we're going to report up our division in this company generates as much carbon.

00:32:43.460 --> 00:32:45.960
So if you care about carbon, you need to take that into account.

00:32:45.960 --> 00:32:47.040
I think that's a good selling point.

00:32:47.040 --> 00:32:56.680
I think as we can see today together, I mean, those conversations are hard and long and it's not easy to understand all that matters.

00:32:56.680 --> 00:33:02.820
And you may need that consulting firm in the end to help you understand what's at stake in your whole value chain.

00:33:02.820 --> 00:33:04.080
You got to start somewhere.

00:33:04.300 --> 00:33:04.700
Right.

00:33:04.700 --> 00:33:13.020
And if you're an individual and you want to change your organization, well, I think if you want to have an impact, those kinds of tools should be easy to start with.

00:33:13.020 --> 00:33:16.100
And then, as we've said, it's not enough and it's not precise enough.

00:33:16.100 --> 00:33:18.460
And then there are other steps you can take.

00:33:18.460 --> 00:33:22.040
But you need to get the conversations going and started.

00:33:22.040 --> 00:33:22.360
Yeah.

00:33:22.360 --> 00:33:24.060
And to start that, you got to start measuring.

00:33:24.060 --> 00:33:26.960
So in order to do that, let's talk about the code.

00:33:26.960 --> 00:33:28.520
It's literally four lines of code.

00:33:28.520 --> 00:33:29.560
It's all you got to do.

00:33:29.560 --> 00:33:34.260
So you pip install Code Carbon and then from Code Carbon, import Emissions Tracker.

00:33:34.260 --> 00:33:35.160
Create one.

00:33:35.160 --> 00:33:36.280
Tracker.start.

00:33:36.280 --> 00:33:36.920
Do your training.

00:33:36.920 --> 00:33:37.820
Tracker.stop.

00:33:37.820 --> 00:33:38.680
And that's it, right?

00:33:38.680 --> 00:33:39.000
Right.

00:33:39.000 --> 00:33:42.480
And with the decorator solution, it's seven, two lines of code.

00:33:42.480 --> 00:33:44.080
Yeah.

00:33:44.080 --> 00:33:46.980
With the decorator, you can just put a decorator on a function.

00:33:46.980 --> 00:33:53.120
And then basically any training that happens during that will be measured and then saved to a CSV file.

00:33:53.120 --> 00:33:53.720
Right?

00:33:53.720 --> 00:33:54.300
That's correct.

00:33:54.300 --> 00:33:59.100
And if you think a context manager should be implemented, well, you're welcome to create a PR.

00:33:59.100 --> 00:34:00.160
It's going to be super easy.

00:34:00.160 --> 00:34:01.160
Everything is already there.

00:34:01.160 --> 00:34:02.560
Yeah, exactly.

00:34:02.560 --> 00:34:07.600
I can already see it in my mind with Emissions Tracker, you know, as Tracker.

00:34:07.600 --> 00:34:10.420
So it creates one of these CSV files and then what?

00:34:10.420 --> 00:34:12.420
So there are a bunch of things that happen.

00:34:12.960 --> 00:34:19.520
If you want to, like, the two big steps are, one, you look for the hardware you understand,

00:34:19.520 --> 00:34:26.420
like Code Carbon understands, then you track those, you measure the energy consumed, right?

00:34:26.420 --> 00:34:29.140
And so you have that, basically, you measure the energy.

00:34:29.140 --> 00:34:35.080
And then next step is, well, how much carbon does energy has emitted?

00:34:35.080 --> 00:34:36.420
How does energy emitted?

00:34:36.540 --> 00:34:39.580
And so you need to map the code to your location.

00:34:39.580 --> 00:34:39.880
Right.

00:34:39.880 --> 00:34:45.260
And do you do that by just, like, a get location from IP address type of thing or something like that?

00:34:45.260 --> 00:34:53.380
So you can either do that or provide the country ISO code for a couple of countries, Canada, the US.

00:34:53.380 --> 00:34:55.840
We have regions below the national level.

00:34:55.840 --> 00:34:59.860
Another thing that you can actually do is, well, it's not going to help you with the location,

00:34:59.860 --> 00:35:05.260
but it's going to help you with the carbon impact is we can bring CO2 signal,

00:35:05.260 --> 00:35:12.020
which is an API that is being developed, the electricity map, initiative, group, organization, company,

00:35:12.020 --> 00:35:13.140
whatever their status.

00:35:13.140 --> 00:35:17.680
And so that's going to help you an exact estimation at that moment in time,

00:35:17.680 --> 00:35:20.700
depending on what data you have of those computations.

00:35:20.700 --> 00:35:24.260
Otherwise, we need your country code and we're going to map that to historical data.

00:35:24.260 --> 00:35:26.380
This CO2 signal, this is new to me.

00:35:26.380 --> 00:35:26.900
What is this?

00:35:26.900 --> 00:35:28.940
I think you'd better look at them.

00:35:28.940 --> 00:35:29.840
Exactly.

00:35:29.840 --> 00:35:31.480
The electricity map.

00:35:31.480 --> 00:35:31.940
Look at the map.

00:35:31.940 --> 00:35:32.520
Exactly.

00:35:32.520 --> 00:35:32.900
Yeah.

00:35:32.900 --> 00:35:38.080
So they have products, they have predictions of carbon emissions and so on.

00:35:38.080 --> 00:35:40.200
But that's basically, it's an initiative.

00:35:40.200 --> 00:35:42.100
The organization is called Tomorrow.

00:35:42.100 --> 00:35:48.380
The goal here, at least with the electricity map, is to gather data about carbon intensity

00:35:48.380 --> 00:36:00.840
and the energy mix of countries through the forest of APIs and standards countries have for countries and companies and have for that kind of thing.

00:36:00.840 --> 00:36:07.080
So you can see that in Canada, not all or in the US, not all regions are going to work similarly.

00:36:07.080 --> 00:36:11.760
And some regions might not even provide that kind of data in the open.

00:36:11.940 --> 00:36:12.960
Yeah, that's too bad.

00:36:12.960 --> 00:36:18.880
Yeah, but it's really different depending on where you are and just even the US, right?

00:36:18.880 --> 00:36:22.540
Like in the Pacific Northwest, I think it's like very high levels of hydro.

00:36:22.540 --> 00:36:25.440
Southeast, a lot of coal still.

00:36:25.440 --> 00:36:27.500
Like it's not just what country.

00:36:27.500 --> 00:36:29.740
It's even like maybe a little more granular than that, right?

00:36:29.740 --> 00:36:29.940
No.

00:36:30.060 --> 00:36:31.420
At least for large places.

00:36:31.420 --> 00:36:44.500
And also, as you can see, I think this is also a very interesting map because you can see that energy grids are very different from the grid that you know, like nation, state, whatever it is after that, right?

00:36:44.500 --> 00:36:45.400
Yeah, county, city.

00:36:45.400 --> 00:36:46.620
County, city, all of that.

00:36:46.620 --> 00:36:50.900
Like you can see, for example, the one that spans something like Iowa.

00:36:50.900 --> 00:36:51.760
Italy, for example.

00:36:51.760 --> 00:36:56.660
I was thinking, it already are like this thing that goes from Montana to Texas or something.

00:36:56.660 --> 00:36:59.220
Yeah, that doesn't look like any state I learned in school.

00:36:59.380 --> 00:37:05.920
No, but it's probably it's unified grid for some reason because providers got together for under some constraint.

00:37:05.920 --> 00:37:06.520
Yeah, exactly.

00:37:06.520 --> 00:37:14.680
So when I'm looking at this code here, I run that and then I get this map and it can give you recommendations on the cloud regions, right?

00:37:14.680 --> 00:37:15.760
And where you might go.

00:37:15.760 --> 00:37:18.300
So for example, CA Central 1.

00:37:18.300 --> 00:37:20.820
This is something that we might want to change, right?

00:37:20.820 --> 00:37:23.440
The UI of this thing might not be obvious, but you're on the left.

00:37:23.840 --> 00:37:29.300
This, I just want to specify clarification because I even, I sometimes forget.

00:37:29.300 --> 00:37:32.160
I'm like, where did this, where was this thing run?

00:37:32.160 --> 00:37:33.340
That's actually, yeah.

00:37:33.340 --> 00:37:36.480
You run on the left and we show you how it could have been different.

00:37:36.480 --> 00:37:36.840
Interesting.

00:37:36.840 --> 00:37:37.380
Somewhere out.

00:37:37.380 --> 00:37:37.880
Yeah.

00:37:37.880 --> 00:37:46.340
So if I pick say US West 1 for AWS versus EU West 3, you can see the relative carbon offset or production.

00:37:46.340 --> 00:37:46.860
Yes.

00:37:46.940 --> 00:37:48.420
How bad that was or how good it was.

00:37:48.420 --> 00:37:52.400
And these are all comes from those reports generated out of that CSV file.

00:37:52.400 --> 00:37:52.840
Exactly.

00:37:52.840 --> 00:37:53.300
That's correct.

00:37:53.300 --> 00:37:55.700
I just want to be clear about how the data was gathered.

00:37:55.700 --> 00:37:57.660
That's a very important topic.

00:37:58.120 --> 00:38:06.440
So we still need to update the data for GCP, Google Cloud Platform, because they recently released those numbers.

00:38:06.440 --> 00:38:10.360
But for most of those locations, we had to make an assumption.

00:38:10.360 --> 00:38:15.040
The assumption was that the data center was plugged to the local grid.

00:38:15.480 --> 00:38:24.460
So if a data center is in Boston, we assume the data center uses the same energy as Boston's grid, which might not be the case.

00:38:24.460 --> 00:38:24.860
Right.

00:38:24.860 --> 00:38:30.200
Many providers would not now have their own solar panels and whatnot.

00:38:30.200 --> 00:38:31.740
So that might not be the case.

00:38:31.740 --> 00:38:37.240
And so, but unless they release those numbers and I can find the link, I'll share it with you.

00:38:37.240 --> 00:38:42.440
Unless we have those numbers publicized by the providers, I mean, there's only so much we can do.

00:38:42.600 --> 00:38:42.680
Yeah.

00:38:42.680 --> 00:38:43.340
So, yeah.

00:38:43.340 --> 00:38:46.520
Well, here's a call to action for those who haven't released it.

00:38:46.520 --> 00:38:47.420
Get on it, right?

00:38:47.420 --> 00:38:54.340
I think it was part of Jonathan's message earlier, which is like, there are so many layers and so many of them are opaque.

00:38:54.340 --> 00:38:58.680
That's part of the, I think, our responsibility as users.

00:38:58.680 --> 00:38:59.040
Yeah.

00:38:59.040 --> 00:39:01.520
I don't like to put too much weight on individuals' shoulders.

00:39:01.520 --> 00:39:06.680
And I think structural changes have a much wider, well, much more potential.

00:39:06.680 --> 00:39:09.020
But I think it's still interconnected.

00:39:09.020 --> 00:39:11.500
And if you can do something about it, well, you should.

00:39:11.500 --> 00:39:11.780
Yeah.

00:39:12.160 --> 00:39:14.460
Let's talk a little bit about running it.

00:39:14.460 --> 00:39:20.440
So when I go over here and I say start and then stop, like, how do you know how much energy I've used?

00:39:20.440 --> 00:39:26.000
I mean, I know once it leaves the computer, like, there's a lot of assumptions and various things like we talked about.

00:39:26.000 --> 00:39:29.760
But how do you estimate how much that that code has taken?

00:39:29.760 --> 00:39:31.060
That's a very good question.

00:39:31.060 --> 00:39:33.160
And Victor, can I answer this one?

00:39:33.160 --> 00:39:33.780
Oh, yes.

00:39:33.780 --> 00:39:34.500
Sure.

00:39:34.500 --> 00:39:35.000
Okay.

00:39:35.300 --> 00:39:41.020
When you're training and you're running a machine learning program, you are mostly using GPU.

00:39:41.020 --> 00:39:43.680
And you are mostly using NVIDIA GPU.

00:39:43.900 --> 00:39:55.500
And thankfully, NVIDIA has a nice SDK to get, at a given time, the current estimated plus or minus 5% energy usage of the GPU.

00:39:55.740 --> 00:39:56.580
So we get...

00:39:56.580 --> 00:39:57.080
Oh, really?

00:39:57.080 --> 00:39:57.480
Okay.

00:39:57.480 --> 00:40:04.520
So it's not like you're saying, oh, it's a 3070 super and it must be pinned CPU-wise or GPU-wise.

00:40:04.600 --> 00:40:11.000
So let's just assume this much time times this kind of computer, it gives you more narrow, exact measurements.

00:40:11.000 --> 00:40:11.780
Okay.

00:40:11.780 --> 00:40:12.540
Fantastic.

00:40:12.540 --> 00:40:16.500
We still get the energy consumption from all GPU.

00:40:16.500 --> 00:40:22.100
So if you are training multiple models, we might get higher or lower energy estimation.

00:40:22.100 --> 00:40:22.800
I'm not sure there.

00:40:22.800 --> 00:40:24.280
So that's for GPU.

00:40:24.280 --> 00:40:26.620
For CPU, we are supporting Intel.

00:40:27.040 --> 00:40:34.080
And we have several ways of doing that as we get a measurement at the beginning of the training and at the end.

00:40:34.080 --> 00:40:37.340
And we get the total energy usage between the two.

00:40:37.340 --> 00:40:38.920
So we can get the difference.

00:40:38.920 --> 00:40:43.620
Or we can also regularly get the immediate usage, I think.

00:40:43.620 --> 00:40:54.820
We are working to add memory usage because even if GPU and CPU are the topmost resources that you use for multi-gigabytes,

00:40:54.820 --> 00:40:57.700
it tends to be not negligible.

00:40:57.700 --> 00:40:58.960
And once you get...

00:40:58.960 --> 00:41:00.040
Probably disk as well.

00:41:00.040 --> 00:41:00.580
Yeah.

00:41:00.580 --> 00:41:01.980
Everything takes energy.

00:41:01.980 --> 00:41:09.240
The goal is to focus on what takes most of the energy and how easy it is to get that consumption.

00:41:09.240 --> 00:41:15.040
So you get all of that either during the training frequently or at the beginning and the end.

00:41:15.040 --> 00:41:17.280
In addition, we get the duration.

00:41:17.280 --> 00:41:21.900
And we detect if you are running in a data center or not.

00:41:22.320 --> 00:41:33.280
So in case we don't have access to anything, like you are running on AMD GPU, on an AMD CPU, on Windows,

00:41:33.280 --> 00:41:39.220
we can still give you an estimation based on the duration, on your estimated location.

00:41:39.220 --> 00:41:46.140
Or if you are running inside a data center or a specific location, we can also get a more precise estimation for you.

00:41:46.140 --> 00:41:49.860
And we are measuring what energy usage.

00:41:49.860 --> 00:41:58.120
And then we can use our data to estimate again, like estimation of estimation, the CO2 emitted for that usage.

00:41:58.360 --> 00:42:04.020
I don't know how deep you want to go into how it works, but I do want to point out that...

00:42:04.020 --> 00:42:05.540
Give us a little look inside.

00:42:05.540 --> 00:42:05.740
Yeah.

00:42:05.740 --> 00:42:06.020
Yeah.

00:42:06.020 --> 00:42:12.320
Given that it's one of the most difficult areas, I think I also want to use your platform to call for help, which is...

00:42:12.320 --> 00:42:18.960
It's actually the low-level inner workings of CPUs are hard to understand.

00:42:18.960 --> 00:42:22.160
At least for me, I have a background and I'm a researcher, right?

00:42:22.160 --> 00:42:25.840
So it's an area where we need help.

00:42:25.840 --> 00:42:27.700
Not necessarily a hardware specialist, right?

00:42:27.700 --> 00:42:29.180
And writing on hardware, yeah.

00:42:29.180 --> 00:42:29.580
Exactly.

00:42:29.580 --> 00:42:43.680
And so, for example, the way we read the energy consumption of Intel CPUs, I mean, the GPUs, as Boris said, have, at least NVIDIA's GPUs, have this driver that we can ping.

00:42:43.680 --> 00:42:54.260
And NVIDIA SMI is all the INVML package is very useful because we can just ping this and not care about how it's done and trust NVIDIA and use that number.

00:42:54.260 --> 00:42:57.040
But for the CPUs, it's much more complicated.

00:42:57.600 --> 00:43:09.980
The reason is that what happens under the hood is modern Intel CPUs under the right settings write, actually, their energy usage, millijoules to a textile.

00:43:09.980 --> 00:43:23.620
It's the Rappel interface and they write to a textile the number of millijoules they have consumed since, I don't know when, since they were turned on or the 1st of January 1970 or whatever other random date.

00:43:23.620 --> 00:43:23.840
Yeah.

00:43:23.840 --> 00:43:26.380
What matters is that and we look at the difference in it.

00:43:26.700 --> 00:43:30.480
But those numbers are written by the CPU socket.

00:43:30.480 --> 00:43:32.460
So let me give you an example.

00:43:32.460 --> 00:43:37.000
In the academic setting where I work, we have shared clusters.

00:43:37.000 --> 00:43:45.000
I can request part of a node and I'm going to request one GPU and 20 CPUs to do my computations.

00:43:45.600 --> 00:43:53.280
But what I saw looking at the Rappel files is that there are two sockets of 40 CPUs.

00:43:53.280 --> 00:43:56.900
Like we have 80 CPUs per node and two sockets of 40.

00:43:56.900 --> 00:43:59.020
So there's no way to read from the Rappel files.

00:43:59.020 --> 00:44:00.200
Your granularity is 40.

00:44:00.200 --> 00:44:00.640
Yeah.

00:44:00.640 --> 00:44:01.200
Yeah.

00:44:01.340 --> 00:44:04.560
Like the CPUs that are allocated to me might change over time.

00:44:04.560 --> 00:44:05.140
Maybe not.

00:44:05.140 --> 00:44:07.560
It depends on the resource manager.

00:44:07.560 --> 00:44:12.020
You use Slurm and those CPUs will be split across those two sockets.

00:44:12.020 --> 00:44:16.200
And so we have that level of problems too.

00:44:16.200 --> 00:44:22.060
So the high level, you're working in a dedicated environment and it's only your program, then

00:44:22.060 --> 00:44:25.060
Rappel is perfect and we couldn't have dreamt for something better.

00:44:25.060 --> 00:44:33.920
But it does not allow us to go to the core, let alone the process granularity of power consumption.

00:44:33.920 --> 00:44:37.500
So I just want to put a big warning here.

00:44:37.500 --> 00:44:43.820
And one of the things that we need to look into, and it's very hard and there are no good numbers.

00:44:43.820 --> 00:44:46.720
Maybe even what I'm going to say won't make sense.

00:44:46.720 --> 00:44:54.440
But the only solution we have left is, is there some kind of heuristic to map the CPU utilization

00:44:54.440 --> 00:44:57.740
to the energy consumption, basically.

00:44:57.740 --> 00:45:04.140
Because otherwise, we're never going to be able to attribute your processes and sub-processes'

00:45:04.140 --> 00:45:07.040
CPU usage to WAPs, basically.

00:45:07.040 --> 00:45:10.920
Because of this Rappel setup that is written by a socket.

00:45:11.580 --> 00:45:17.080
And I've talked a little to people who understand this way better than I do.

00:45:17.080 --> 00:45:20.700
And they thought this endeavor was very risky.

00:45:20.700 --> 00:45:22.260
And they were pessimistic.

00:45:22.260 --> 00:45:23.300
But I mean...

00:45:23.300 --> 00:45:25.300
And you're like, what else do we have to work with?

00:45:25.300 --> 00:45:25.580
Yeah.

00:45:25.580 --> 00:45:31.160
And so I think next thing is like, we're going to need to get our hands on hardware, have

00:45:31.160 --> 00:45:32.680
it run and see how bad it is.

00:45:32.680 --> 00:45:40.360
And it's going to be one setup with one mode for the compilation of the math libraries I'm

00:45:40.360 --> 00:45:41.680
going to use to benchmark and whatnot.

00:45:41.680 --> 00:45:46.540
Like, there's only so much we can do if the hardware providers don't give, don't tell

00:45:46.540 --> 00:45:46.860
us more.

00:45:46.860 --> 00:45:53.080
It would be nice to see operating systems and then the hardware providers as well allow

00:45:53.080 --> 00:45:54.840
you to access that information, right?

00:45:54.840 --> 00:46:00.120
Like, how much, you know, how much voltage am I, how much am I currently consuming with

00:46:00.120 --> 00:46:01.260
just this process, right?

00:46:01.260 --> 00:46:02.860
And you don't want to profile it.

00:46:02.860 --> 00:46:06.080
Because if you profile it, you'll be like 50% of the problem, right?

00:46:06.080 --> 00:46:08.480
And you'll slow it down and people won't want to touch it.

00:46:08.600 --> 00:46:13.580
And talk to people at Power API and Pyjool initiatives.

00:46:13.580 --> 00:46:21.180
And even they, from what I remember, explained that even if you had total control on the hardware,

00:46:21.180 --> 00:46:26.900
on the software, or the hardware, both of those things are going to be so dependent on the way

00:46:26.900 --> 00:46:28.480
you compile the libraries you use.

00:46:28.480 --> 00:46:35.020
And a number of other facts that it's even the very definition of those things that we're

00:46:35.020 --> 00:46:36.160
looking for is not obvious.

00:46:36.160 --> 00:46:40.580
Or whether it's Linux versus macOS versus Windows, it's got to make a difference.

00:46:40.640 --> 00:46:41.320
It all matters.

00:46:41.320 --> 00:46:48.260
And the reason why I think it's still worth looking for an approximation through CPU utilization,

00:46:48.260 --> 00:46:52.440
even if it's a bad proxy, is it's all bad proxies.

00:46:52.440 --> 00:46:59.000
So why is it like, it doesn't matter if you're precise to the millijoule on your CPU,

00:46:59.000 --> 00:47:03.900
if your uncertainty around carbon emissions is huge, right?

00:47:04.020 --> 00:47:07.720
Otherwise, you end up with something as much carbon as five cars, right?

00:47:07.720 --> 00:47:09.060
And so...

00:47:09.060 --> 00:47:11.820
We can get it down to 2.1 or 2.2 cars.

00:47:11.820 --> 00:47:12.680
Come on, let's go with that.

00:47:12.680 --> 00:47:12.940
Yeah.

00:47:12.940 --> 00:47:15.860
So it's really a very complex endeavor.

00:47:15.860 --> 00:47:16.200
Yeah.

00:47:16.200 --> 00:47:17.260
Yeah, absolutely.

00:47:17.260 --> 00:47:19.800
So it sounds like it runs on multiple platforms.

00:47:19.800 --> 00:47:21.460
We'll try to, at least.

00:47:21.840 --> 00:47:22.440
Yeah, yeah.

00:47:22.440 --> 00:47:24.960
So Windows, Linux, macOS.

00:47:24.960 --> 00:47:25.500
Exactly.

00:47:25.500 --> 00:47:29.360
I'm sitting here recording on my Mac Mini M1, Apple Silicon.

00:47:29.360 --> 00:47:30.440
Can I run it here?

00:47:30.440 --> 00:47:30.900
Yeah.

00:47:30.900 --> 00:47:37.140
You would need to install the Intel Power Gadget, restart your computer, allow specific security

00:47:37.140 --> 00:47:37.920
permissions.

00:47:37.920 --> 00:47:38.880
Not an Intel CPU.

00:47:38.880 --> 00:47:43.640
So I'm guessing you will be back to the simple realistic base on the duration.

00:47:43.640 --> 00:47:47.700
We realized, actually, the Intel Power Gadget also tracks some AMD CPUs.

00:47:47.700 --> 00:47:51.200
Like, we had a user say, like, you don't seem to support AMD.

00:47:51.200 --> 00:47:53.500
And then they still installed the Intel Power Gadget.

00:47:53.500 --> 00:47:54.860
I don't know why, but they did.

00:47:54.860 --> 00:47:55.740
And then it worked.

00:47:55.740 --> 00:47:58.040
So I'm like, I'm not sure how this thing works.

00:47:58.040 --> 00:48:00.580
So Intel AMD, but maybe not Apple Silicon.

00:48:00.580 --> 00:48:01.920
I don't think so.

00:48:01.920 --> 00:48:02.260
Okay.

00:48:02.260 --> 00:48:05.560
Well, probably most people won't be doing training on that.

00:48:05.560 --> 00:48:09.300
The Apple Silicon platform has a dedicated course for machine learning, you know?

00:48:09.300 --> 00:48:11.300
It does have, I think, 16 ML cores.

00:48:11.300 --> 00:48:11.820
Yeah.

00:48:11.820 --> 00:48:12.660
So yeah, maybe.

00:48:12.660 --> 00:48:13.540
Maybe they are.

00:48:13.860 --> 00:48:17.820
They're coming out with the Mac Pro, which is supposed to have Mini Mini 4.

00:48:17.820 --> 00:48:20.260
So maybe that'll be where people do it more.

00:48:20.260 --> 00:48:21.760
So if Apple is hearing you.

00:48:21.760 --> 00:48:22.280
Yeah, pretty.

00:48:22.280 --> 00:48:23.200
Is hearing us.

00:48:23.200 --> 00:48:28.120
Send us a Mac Mini and we'll work on improving the tracking of.

00:48:28.120 --> 00:48:30.160
And one Mac Mini is for all three of you.

00:48:30.160 --> 00:48:30.920
The whole team.

00:48:30.920 --> 00:48:31.380
Come on.

00:48:31.380 --> 00:48:32.180
Let's send it along.

00:48:32.180 --> 00:48:32.840
Make it happen.

00:48:32.840 --> 00:48:33.720
You have my Twitter handle.

00:48:33.720 --> 00:48:34.540
Send me a message.

00:48:34.540 --> 00:48:35.320
Fantastic.

00:48:35.320 --> 00:48:35.700
All right.

00:48:35.700 --> 00:48:36.980
Let's see.

00:48:36.980 --> 00:48:39.560
Before we move on, quick question from Brian in the live stream.

00:48:39.560 --> 00:48:42.820
Other than moving to different data centers, what are some of the highest impact

00:48:42.900 --> 00:48:44.120
changes people can make?

00:48:44.120 --> 00:48:46.340
Different training methods and so on.

00:48:46.340 --> 00:48:49.320
And by the way, that also leads exactly into where I was going.

00:48:49.320 --> 00:48:50.000
Thank you for that.

00:48:50.000 --> 00:48:51.480
A very timely question.

00:48:51.480 --> 00:48:53.440
Like patterns and things you can do.

00:48:53.440 --> 00:48:54.340
Let's talk about that.

00:48:54.420 --> 00:49:00.000
One of the things that we wrote in the carbon emissions of machine learning paper on the

00:49:00.000 --> 00:49:02.680
website is, well, there's hyperparameter searches.

00:49:02.680 --> 00:49:09.820
Like one of the worst thing you can do, both in terms of pure ML performance and carbon emissions

00:49:09.820 --> 00:49:10.900
is grid search, for instance.

00:49:10.900 --> 00:49:12.460
So maybe just don't do that.

00:49:12.760 --> 00:49:16.320
There are, if you're lazy, just do a random hyperparameter search.

00:49:16.320 --> 00:49:18.320
Or if you don't have a good metric.

00:49:18.320 --> 00:49:22.380
Or use Bayesian optimizers and so on to look for those hyperparameters.

00:49:22.380 --> 00:49:27.220
Another thing that is not mentioned in that paper, but I think is still very important.

00:49:27.220 --> 00:49:31.900
And that cycles back to one of your first questions about insurance versus training is,

00:49:32.300 --> 00:49:33.620
there are many methods out there.

00:49:33.620 --> 00:49:41.820
Pruning, distillation, quantization, all of like all that zoo of tools and techniques

00:49:41.820 --> 00:49:45.300
and algorithms to optimize your model.

00:49:45.300 --> 00:49:50.920
And if you're happy with your current model, chances are there are many techniques out there

00:49:50.920 --> 00:49:56.640
that can reduce its size and computational complexity by multiple factors.

00:49:56.640 --> 00:50:02.140
So if you're going to put a product out there with hundreds, thousands, millions,

00:50:02.140 --> 00:50:05.120
of inferences, maybe just think about that.

00:50:05.120 --> 00:50:09.300
I expect people who deploy such tools do think about that.

00:50:09.300 --> 00:50:14.640
If you're deploying a tool for millions, I mean, it's in your interest to think about it

00:50:14.640 --> 00:50:15.680
because it's also going to be cheaper.

00:50:15.680 --> 00:50:22.080
They probably think more about it in terms of just time, time to train, time to get an answer.

00:50:22.080 --> 00:50:25.720
But that also is exactly lining up with energy consumed.

00:50:25.720 --> 00:50:28.820
So, you know, CO2 reduction comes along for the ride.

00:50:29.020 --> 00:50:29.140
Yeah.

00:50:29.140 --> 00:50:34.940
It's often the case that if you invest in ecological solutions, they are going to end up being economical.

00:50:34.940 --> 00:50:38.820
Jonathan, it's more of your area.

00:50:38.820 --> 00:50:41.380
Maybe that's another bold pro to you.

00:50:41.380 --> 00:50:43.120
Oh, I couldn't underscore that more.

00:50:43.120 --> 00:50:47.740
I think, you know, something that I think that has come out of our results that we've seen is that

00:50:47.740 --> 00:50:52.960
there's not a strictly linear trade-off between energy usage and accuracy, for example.

00:50:53.100 --> 00:50:58.660
There's often, there's a shoulder usually there and finding that shoulder using code carbon to figure

00:50:58.660 --> 00:51:03.720
out, you know, if I throw this fraction of a kilogram of CO2 at this problem, I'm actually

00:51:03.720 --> 00:51:06.720
going to get a lower accuracy than if I had stopped beforehand.

00:51:06.720 --> 00:51:10.800
So using a tool to figure out where that is, I think is very helpful.

00:51:10.800 --> 00:51:16.560
And so just being aware of the impact of it and trying to maximize for accuracy and not just energy usage.

00:51:17.040 --> 00:51:17.200
Yeah.

00:51:17.200 --> 00:51:22.000
One of the things you called out is more energy, which means more emissions, is not necessarily

00:51:22.000 --> 00:51:22.760
more accuracy.

00:51:22.760 --> 00:51:23.120
Yeah.

00:51:23.120 --> 00:51:24.920
Adding on more practical solution.

00:51:24.920 --> 00:51:30.580
For example, when you're doing hyperparameter search, which is basically, are you doing the

00:51:30.580 --> 00:51:36.300
combination of numbers of variables and try to find the best combination to get the best results,

00:51:36.300 --> 00:51:40.800
the best, more precise model or whatever metrics you're optimizing for?

00:51:41.300 --> 00:51:45.840
You will likely, most of the machine learning libraries have an option to do early stop.

00:51:45.840 --> 00:51:53.140
Like instead of doing training new model for four days for all hundreds of thousands of combinations,

00:51:53.140 --> 00:51:59.000
you train 10 of them for one day and then you see how it evolved.

00:51:59.160 --> 00:52:05.360
And if you take only the two best of them and try again, you can reduce your training time

00:52:05.360 --> 00:52:08.020
and emission by a lot of percentage.

00:52:08.020 --> 00:52:15.540
And on other protocol, you can also move all known, all the code that doesn't need GPU to

00:52:15.540 --> 00:52:20.380
run something somewhere else, like for CPU, then you start on disk, it's still emitting less

00:52:20.380 --> 00:52:23.840
emission than not using the GPU on your server.

00:52:24.100 --> 00:52:31.900
And try to use your GPU better, even by training more model on the same GPU or changing your model

00:52:31.900 --> 00:52:35.540
to be more efficient to train in less time.

00:52:35.540 --> 00:52:39.700
One of the things that we've also advocated for, and it can sound a little naive, but as

00:52:39.700 --> 00:52:45.100
Jonathan said earlier, like this field has been moving fast is to publish and be transparent

00:52:45.100 --> 00:52:46.000
about those things.

00:52:46.460 --> 00:52:53.640
And I think if the community shows interest and shows that it is one of the broader impact

00:52:53.640 --> 00:52:59.120
features that they look for when they think about the systems they create and deploy, I

00:52:59.120 --> 00:53:04.760
think it's also something that can spread in other areas than just your very specific niche

00:53:04.760 --> 00:53:05.760
of research.

00:53:05.760 --> 00:53:10.640
For instance, I'm thinking about the research community here, but that's my environment.

00:53:10.800 --> 00:53:13.060
But I think it's also the case in the industry.

00:53:13.060 --> 00:53:18.020
Another thing that you all talked about is if you're computing locally, so maybe at your

00:53:18.020 --> 00:53:21.280
university or in your house these days, that's probably where you are.

00:53:21.280 --> 00:53:23.920
The local energy infrastructure matters, right?

00:53:23.920 --> 00:53:24.520
It does.

00:53:24.520 --> 00:53:25.260
It does.

00:53:25.260 --> 00:53:32.060
Like, for example, Quebec has an average of like 20 grams of CO2 per kilowatt hour or something,

00:53:32.060 --> 00:53:36.660
which is probably 40 times lower than some other regions.

00:53:36.940 --> 00:53:41.220
You can check the, well, no, because Quebec doesn't share the data with electricity map.

00:53:41.220 --> 00:53:41.700
It's a shame.

00:53:41.700 --> 00:53:47.140
But you can see other, like if you just compare the results in Europe, for instance, and you

00:53:47.140 --> 00:53:48.940
look for France, which is...

00:53:48.940 --> 00:53:50.980
Like France versus Germany.

00:53:50.980 --> 00:53:51.480
Yeah.

00:53:51.480 --> 00:53:54.980
It has a nuclear electricity grid, mostly France, right?

00:53:54.980 --> 00:53:58.620
So if you compare France to Germany, it's going to be very different.

00:53:58.620 --> 00:53:58.940
Look at that.

00:53:58.940 --> 00:54:00.680
95% low carbon.

00:54:00.680 --> 00:54:02.500
That's well done, France.

00:54:02.500 --> 00:54:03.480
Good job, Boris.

00:54:03.480 --> 00:54:09.120
I think if you click on Germany, what you'll see is you might have a time series somewhere

00:54:09.120 --> 00:54:10.720
for the last 24 hours.

00:54:10.720 --> 00:54:13.840
At least have this nice breakdown over here and you can move it.

00:54:13.840 --> 00:54:15.120
Yeah, there's your time series.

00:54:15.120 --> 00:54:15.420
Right.

00:54:15.420 --> 00:54:18.460
So you can even see that during the day.

00:54:18.460 --> 00:54:19.300
It's not the same.

00:54:19.300 --> 00:54:25.320
And just like your electricity provider will charge you differently for different times of

00:54:25.320 --> 00:54:29.400
usage, like high demand or lower demand times of the day.

00:54:29.400 --> 00:54:33.880
And like carbon emissions are also going to have that kind of variation that you could

00:54:33.880 --> 00:54:34.360
care for.

00:54:34.360 --> 00:54:39.480
One thing I wanted to give a quick shout out to, I don't know about different locations.

00:54:39.480 --> 00:54:45.280
Here in Portland, one of the options we have is to choose a slightly different energy choice.

00:54:45.280 --> 00:54:51.980
If we pay $6 more per month or $11 as a small business, it will basically be wind and solar.

00:54:52.220 --> 00:54:57.700
And if your local grid offers something where you literally pay $6 and it can dramatically

00:54:57.700 --> 00:54:59.620
change it, like, you know, do the world a favor.

00:54:59.620 --> 00:55:00.440
Opt in.

00:55:00.440 --> 00:55:02.580
We have the equivalent in France also.

00:55:02.580 --> 00:55:03.620
Same in the United States.

00:55:03.620 --> 00:55:07.920
There's a lot of, there's a patchwork of different state laws that mandate that these options are

00:55:07.920 --> 00:55:09.500
made available to people.

00:55:09.500 --> 00:55:11.280
So yeah, definitely take advantage of it.

00:55:11.280 --> 00:55:11.500
Yeah.

00:55:11.500 --> 00:55:12.080
Yeah.

00:55:12.080 --> 00:55:13.700
It's, I mean, it literally is a checkbox.

00:55:13.700 --> 00:55:16.120
Do you want to have this yes or no and a small fee?

00:55:16.120 --> 00:55:19.800
And they probably, you know, honestly, probably what's happening when you check that box,

00:55:19.800 --> 00:55:23.220
like some of that energy would have just gone to the general grid and now it's, it's promised

00:55:23.220 --> 00:55:23.620
to you.

00:55:23.620 --> 00:55:27.760
But soon as enough people check that box to go beyond the capacity, then that's going to

00:55:27.760 --> 00:55:30.600
be an economic driver to make more of it happen.

00:55:30.600 --> 00:55:30.820
Right.

00:55:30.820 --> 00:55:33.040
So hopefully, hopefully we can get there.

00:55:33.040 --> 00:55:37.400
Although I suspect data centers are where the majority of the computation happens.

00:55:37.400 --> 00:55:41.520
It doesn't, I mean, I'm not backing this by any knowledge here.

00:55:41.520 --> 00:55:45.780
I'm just, it's just my personal perception, but I feel it's like, it's too little.

00:55:46.060 --> 00:55:47.660
Like, this is too cheap.

00:55:47.660 --> 00:55:51.280
How come, like, it's so cheap, right?

00:55:51.280 --> 00:55:57.080
So, so many things in our data lab should actually be more expensive if we knew how much energy

00:55:57.080 --> 00:55:59.300
and resources and how much they cost the environment.

00:55:59.300 --> 00:56:04.380
And so it feels like it's a no brainer when it's so easy and it's so cheap in this case,

00:56:04.380 --> 00:56:10.300
but like how many other areas of our data lab and consumption have those, those biases?

00:56:10.640 --> 00:56:13.180
Would you pay three times as much to fly, right?

00:56:13.180 --> 00:56:17.640
Would you pay $3,000 to go from France to Portland rather than a thousand or whatever, right?

00:56:17.640 --> 00:56:19.860
That's a harder thing than checking a $6 box.

00:56:19.860 --> 00:56:20.220
Yeah.

00:56:20.220 --> 00:56:22.220
And probably a harder solve a problem.

00:56:22.220 --> 00:56:26.340
But luckily we're, we're talking about computers and ML and not air transportation.

00:56:26.340 --> 00:56:28.120
So don't have to solve it here.

00:56:28.120 --> 00:56:29.080
We'll do that next time.

00:56:29.080 --> 00:56:30.840
Speaking of solving it here, you know, what's next?

00:56:30.840 --> 00:56:32.280
Where are things going for you all in the future?

00:56:32.280 --> 00:56:35.440
So I'm a PhD student at Mila in Montreal.

00:56:35.440 --> 00:56:38.220
So it's a Quebec's AI Institute.

00:56:38.220 --> 00:56:43.240
So I feel like I'm going to stay there for at least two or three more years until I PhD

00:56:43.240 --> 00:56:44.020
and then we'll see.

00:56:44.020 --> 00:56:46.740
But the other two, where are you going with this project?

00:56:46.740 --> 00:56:49.200
Yeah, I think that we've got some things on the horizon.

00:56:49.200 --> 00:56:54.600
One is that the other part sort of under the hood that's kind of complicated is deriving

00:56:54.600 --> 00:56:58.980
the energy mix and getting the CO2 intensity of the energy grid from the energy mix.

00:56:58.980 --> 00:57:03.780
So figuring out, you know, okay, if you know, you have X percent natural gas, X percent coal

00:57:03.780 --> 00:57:06.840
and X percent oil, you know, how does that translate into CO2 emissions?

00:57:06.840 --> 00:57:12.300
That's actually an extremely complicated problem to answer because we have different chemical

00:57:12.300 --> 00:57:14.240
compositions of coal around the world.

00:57:14.240 --> 00:57:19.160
For example, you know, coal that comes out of Kentucky has a different CO2 impact per,

00:57:19.160 --> 00:57:22.740
you know, joule from combustion than coal that comes out of Wyoming, for example.

00:57:22.740 --> 00:57:25.340
So we've got all these different layers to figure out.

00:57:25.340 --> 00:57:28.460
For oil, you've got like the oil sands of Canada versus...

00:57:28.460 --> 00:57:28.860
Exactly.

00:57:28.860 --> 00:57:30.320
...Sahary Arabia or whatever, right?

00:57:30.320 --> 00:57:30.700
Exactly.

00:57:30.700 --> 00:57:31.020
Yeah.

00:57:31.020 --> 00:57:35.580
And all of these sort of chemical differences, you know, matter and they reflect different

00:57:35.580 --> 00:57:36.180
efficiencies.

00:57:36.180 --> 00:57:40.700
And that's not even getting into the difference in hardware in different power plants.

00:57:40.700 --> 00:57:45.340
So what we want to do is we want to actually dive in a bit deeper and get at some of these

00:57:45.340 --> 00:57:51.260
regional differences in carbon intensity and plug them into the data set here so that,

00:57:51.260 --> 00:57:54.040
you know, we can refine our estimates as much as possible.

00:57:54.040 --> 00:57:54.320
Yeah.

00:57:54.320 --> 00:57:54.360
Yeah.

00:57:54.360 --> 00:57:58.500
And shout out to the cloud providers, provide more data.

00:57:58.500 --> 00:57:58.880
Yeah.

00:57:58.880 --> 00:58:02.560
To the CPU providers, provide more hooks, things like that.

00:58:02.560 --> 00:58:08.680
My hope for the project is that in a few years, we don't need this project anymore because we are doing

00:58:08.680 --> 00:58:10.420
estimation of estimation of estimation.

00:58:11.100 --> 00:58:17.280
There's better people in the industry, cloud providers and hardware vendors that are suited

00:58:17.280 --> 00:58:19.900
to get more precise data.

00:58:19.900 --> 00:58:23.500
But until then, I hope that the project can...

00:58:23.500 --> 00:58:29.620
Companies be aware of their mission, take action on that and allow the project to be more precise

00:58:29.620 --> 00:58:33.740
and give some estimation range for everything we are measuring.

00:58:33.740 --> 00:58:38.480
I feel like there are five to 10 companies in the world that can control all of the information

00:58:38.480 --> 00:58:38.800
you have.

00:58:38.800 --> 00:58:42.120
So we've got Intel, AMD, Apple for the chips.

00:58:42.120 --> 00:58:49.340
We've got AMD and NVIDIA for the cards and Azure, AWS, GCP.

00:58:49.340 --> 00:58:54.960
If they all provided more information, then this would be not much of an estimate, more of a measure.

00:58:54.960 --> 00:58:57.120
A couple of comments from the live stream.

00:58:57.120 --> 00:58:59.820
Corey Adkins says, thank you all.

00:58:59.820 --> 00:59:02.620
I've recommended this package to my ML team, which is awesome.

00:59:02.620 --> 00:59:08.860
And then Ryan Clark says, the efficiency varies widely between countries and whatnot.

00:59:08.860 --> 00:59:14.980
But you sort of addressed that already with your comment about trying to work to understand

00:59:14.980 --> 00:59:16.260
the different sources and how they...

00:59:16.260 --> 00:59:19.520
Even though they both look like coal, for example, they're actually not the same.

00:59:19.520 --> 00:59:20.920
Yeah, it's a really great question.

00:59:20.920 --> 00:59:25.660
And it really is something that we've relied on data from the US because we have the highest

00:59:25.660 --> 00:59:30.380
resolution of this and of the CO2 impact per energy consumed.

00:59:30.380 --> 00:59:32.840
And we have the most transparency about the numbers.

00:59:32.840 --> 00:59:38.020
It's not just a number in the end of a report or a footnote of a report.

00:59:38.200 --> 00:59:41.080
We can actually trace it and do some due diligence on that.

00:59:41.080 --> 00:59:42.520
So we've used those numbers.

00:59:42.520 --> 00:59:48.180
But if anybody listening to this or hearing this has a connection with any of those companies,

00:59:48.180 --> 00:59:52.440
the hardware companies, or knows how to get more energy data, we are always looking for

00:59:52.440 --> 00:59:53.800
collaborators and contributors.

00:59:53.800 --> 00:59:55.220
So please reach out to us.

00:59:55.220 --> 00:59:56.160
Yeah, fantastic.

00:59:56.160 --> 00:59:56.840
All right.

00:59:56.840 --> 00:59:59.520
I know we're pretty much at the end of our time together.

00:59:59.520 --> 01:00:01.500
So let me just ask you one really quick question.

01:00:01.940 --> 01:00:04.680
I have a thing I want to, a model I want to train.

01:00:04.680 --> 01:00:09.520
So I'm going to fire up a Docker image, maybe a set of them on Kubernetes and kick them off,

01:00:09.520 --> 01:00:10.780
let them go do their thing.

01:00:10.780 --> 01:00:14.120
Then I'm going to come back next week, have another idea that I'm going to train up some

01:00:14.120 --> 01:00:14.540
more things.

01:00:14.540 --> 01:00:16.100
Maybe my colleague is doing the same.

01:00:16.100 --> 01:00:19.080
This is going to generate a bunch of a mission.csv files.

01:00:19.320 --> 01:00:21.340
How do I correlate?

01:00:21.340 --> 01:00:26.680
How do I put these all together so that I can see like, as a team, this month is here we

01:00:26.680 --> 01:00:26.880
are.

01:00:26.880 --> 01:00:27.960
Is that something that happens?

01:00:27.960 --> 01:00:33.280
So I'm really glad you asked this question, because this is something we're working on.

01:00:33.280 --> 01:00:37.440
So currently, I think you can just sum up those CSV files.

01:00:37.440 --> 01:00:38.080
I think that's...

01:00:38.080 --> 01:00:41.640
Yeah, it's up to you to keep track and like say, okay, here's when we're sending in from

01:00:41.640 --> 01:00:42.040
this run.

01:00:42.040 --> 01:00:44.740
CSV files have a lot of downsides.

01:00:44.740 --> 01:00:46.540
It's less object oriented.

01:00:46.540 --> 01:00:49.960
And you could have a JSON file that would be more structured and so on.

01:00:49.960 --> 01:00:52.500
But at least it's very easily...

01:00:52.500 --> 01:00:54.240
You can just concatenate them, right?

01:00:54.240 --> 01:00:54.900
So...

01:00:54.900 --> 01:00:56.120
I think it's totally good, actually.

01:00:56.120 --> 01:00:57.680
It's more about the...

01:00:57.680 --> 01:00:59.720
It's going to be transient files in lots of places.

01:00:59.720 --> 01:01:02.580
How do I put them in one place so I see it as a whole?

01:01:02.580 --> 01:01:02.920
Yeah.

01:01:02.920 --> 01:01:08.520
What we've been working on lately with a team of volunteers in France with the dataforgood.fr

01:01:08.520 --> 01:01:12.820
initiative is to create and deploy an API in a database.

01:01:13.100 --> 01:01:20.020
So we want to create this online storage of the time series and not just the final sum and

01:01:20.020 --> 01:01:29.180
have that in a hierarchy of ownership from the organization to the single run through teams

01:01:29.180 --> 01:01:29.820
and projects.

01:01:29.820 --> 01:01:31.200
That requires a lot of work.

01:01:31.200 --> 01:01:33.400
That requires deployment.

01:01:33.740 --> 01:01:36.740
That requires fans and sponsors to host that thing.

01:01:36.740 --> 01:01:38.920
That requires a lot of engineering.

01:01:38.920 --> 01:01:44.500
And I'm glad you asked that question because I also wanted to have one word about open source

01:01:44.500 --> 01:01:46.740
and who's doing this.

01:01:46.740 --> 01:01:48.660
And it's all about volunteers.

01:01:48.660 --> 01:01:51.240
And no one is paid for that.

01:01:51.820 --> 01:01:58.200
companies like Comet or the Boston Consulting Group, who've been a partner for more than a year,

01:01:58.200 --> 01:02:00.760
do dedicate some software engineering time.

01:02:00.760 --> 01:02:02.640
And we need more collaborations.

01:02:02.640 --> 01:02:07.340
And if you think this tool is great and you want to use it, I think we would really appreciate

01:02:07.340 --> 01:02:12.040
if some of you had time to help because it's a small team of volunteers.

01:02:12.740 --> 01:02:17.440
I mean, it's the same for most open source projects out there and they need collaborators

01:02:17.440 --> 01:02:18.500
and contributors.

01:02:18.500 --> 01:02:24.540
And I think it's one of the things you can do also is help out.

01:02:24.540 --> 01:02:27.440
And most of it is pure Python, right?

01:02:27.800 --> 01:02:30.980
So chances are you're going to be able to help.

01:02:30.980 --> 01:02:35.920
And or if you if you don't know Python, there's some data collection issues.

01:02:35.920 --> 01:02:38.260
And it's just about writing to a CSV file.

01:02:38.260 --> 01:02:40.520
You just got to find the time to go fetch those numbers.

01:02:40.520 --> 01:02:44.580
There are data visualization issues to help improve the dashboard.

01:02:44.580 --> 01:02:44.980
And so on.

01:02:44.980 --> 01:02:46.420
So like it's it's never ending.

01:02:46.420 --> 01:02:47.360
So everyone can help.

01:02:47.360 --> 01:02:47.640
Yeah.

01:02:47.640 --> 01:02:51.660
Sounds like a really great project to get involved in if people are looking to find an open source

01:02:51.660 --> 01:02:52.880
thing to work on.

01:02:52.880 --> 01:02:59.420
And we're willing to onboard you, which also is sometimes bumpy in open source projects.

01:02:59.420 --> 01:03:04.460
And I think, I mean, it's hard and there are hundreds of guides of how to contribute to

01:03:04.460 --> 01:03:05.520
open source projects out there.

01:03:05.520 --> 01:03:07.380
I think we want people.

01:03:07.380 --> 01:03:10.860
So like if you we're going to help you help us.

01:03:10.860 --> 01:03:11.340
Yeah.

01:03:11.340 --> 01:03:11.840
Very cool.

01:03:11.840 --> 01:03:13.160
I encourage people to do so.

01:03:13.160 --> 01:03:13.400
All right.

01:03:13.400 --> 01:03:15.000
Final quick question before we get out of here.

01:03:15.000 --> 01:03:20.560
Brian Hermsen says, I know this would be a big ask, but I would love to see this as a

01:03:20.560 --> 01:03:23.460
built in profiler for CPU intensive ML libraries.

01:03:23.460 --> 01:03:23.940
Yeah.

01:03:23.940 --> 01:03:25.980
We just told you CPU is super hard.

01:03:25.980 --> 01:03:28.200
Exactly.

01:03:28.200 --> 01:03:28.960
Yeah.

01:03:28.960 --> 01:03:33.280
I mean, it's I think this is going to go beyond what we know and can do.

01:03:33.280 --> 01:03:34.900
But yeah, I agree with you.

01:03:34.900 --> 01:03:40.860
It should be part of more decisions in computer science in general and software engineering and

01:03:40.860 --> 01:03:42.740
hardware engineering and everything.

01:03:42.740 --> 01:03:43.160
All right.

01:03:43.160 --> 01:03:47.340
Let me ask you all the final two questions really quickly since there's three of you.

01:03:47.340 --> 01:03:48.820
You're going to write some Python code.

01:03:48.820 --> 01:03:50.060
What editor do you use?

01:03:50.220 --> 01:03:50.680
VS Code.

01:03:50.680 --> 01:03:51.120
Me too.

01:03:51.120 --> 01:03:51.800
Sublime.

01:03:51.800 --> 01:03:52.600
Sorry, guys.

01:03:52.600 --> 01:03:56.680
I used to be a sublime fan, but VS Code is good now.

01:03:56.680 --> 01:03:56.980
Yeah.

01:03:56.980 --> 01:04:00.880
I feel like a lot of the sublime people have moved on to VS Code, but sublime is still popular

01:04:00.880 --> 01:04:01.280
as well.

01:04:01.280 --> 01:04:02.780
Notable PyPI package.

01:04:02.780 --> 01:04:08.140
Maybe some cool library that works with some of the things you're all interested in.

01:04:08.140 --> 01:04:08.800
Just quick.

01:04:08.800 --> 01:04:10.340
Maybe people haven't heard of.

01:04:10.340 --> 01:04:20.880
I like rich, which is a super flexible, colorful, versatile tool to print stuff instead of writing

01:04:20.880 --> 01:04:25.060
again and again the same quacky print functions.

01:04:25.060 --> 01:04:26.380
They call it a TUI.

01:04:26.380 --> 01:04:27.400
A TUI.

01:04:27.400 --> 01:04:28.360
Do they have it in here?

01:04:28.360 --> 01:04:29.020
A TUI.

01:04:29.020 --> 01:04:30.180
Some now use interface.

01:04:30.180 --> 01:04:31.520
A terminal interface.

01:04:31.520 --> 01:04:32.820
It's so good.

01:04:32.820 --> 01:04:33.120
It's cool.

01:04:33.120 --> 01:04:33.820
It's incredible.

01:04:33.820 --> 01:04:34.200
Yeah.

01:04:34.640 --> 01:04:40.040
And I just want to also give a shout out to computational open source libraries like

01:04:40.040 --> 01:04:44.720
NumPy, scikit-learn, and Matplotlib, Pandas, and so on.

01:04:44.720 --> 01:04:51.320
Because those things run the data sense world, and it's all open source, non-profits, and

01:04:51.320 --> 01:04:57.020
it's a few maintainers, and they deserve a lot of the credit for the recent advances.

01:04:57.020 --> 01:04:57.900
They definitely do.

01:04:57.900 --> 01:05:00.600
Boris or John, either want to give a quick shout out to anything?

01:05:00.600 --> 01:05:06.320
If I will do some shameless marketing, I would say the CometML, Python SDK, but more, I would

01:05:06.320 --> 01:05:13.420
say as a FastAPI or some basis library that everyone uses, requests, and even just the

01:05:13.420 --> 01:05:18.040
Python standard library, I know some CPython core developers that are doing a tremendous

01:05:18.040 --> 01:05:18.580
job.

01:05:18.580 --> 01:05:21.760
It's a stainless job, so thank you to them.

01:05:21.760 --> 01:05:22.240
Yeah, for sure.

01:05:22.240 --> 01:05:22.820
To them.

01:05:22.820 --> 01:05:26.360
Yeah, everything Boris and Victor have recommended are great stuff.

01:05:26.360 --> 01:05:27.340
Yeah, fantastic.

01:05:27.340 --> 01:05:28.180
All right.

01:05:28.180 --> 01:05:29.740
Well, final call to action.

01:05:29.740 --> 01:05:31.540
People out there are listening.

01:05:31.540 --> 01:05:33.560
They're doing machine learning.

01:05:33.560 --> 01:05:37.340
They want to be able to use this to measure their work and maybe make some change.

01:05:37.340 --> 01:05:37.840
What do you say?

01:05:37.840 --> 01:05:38.480
Use it.

01:05:38.480 --> 01:05:39.680
Contribute.

01:05:39.680 --> 01:05:40.880
Evangelize.

01:05:40.880 --> 01:05:41.520
Share.

01:05:41.520 --> 01:05:48.320
I think most of the thing you can do about climate change is spreading awareness, discussing

01:05:48.320 --> 01:05:50.860
those things, and challenging the status quo.

01:05:50.860 --> 01:05:51.120
Yeah.

01:05:51.120 --> 01:05:51.860
Fantastic.

01:05:51.860 --> 01:05:54.820
All right, Boris, Victor, John, thank you all for being here.

01:05:54.820 --> 01:05:55.960
It's been really great to have you.

01:05:55.960 --> 01:05:56.860
Thanks so much for your time.

01:05:56.860 --> 01:05:57.800
Yeah, thanks for having us.

01:05:57.800 --> 01:05:58.560
Have a great day, everyone.

01:05:58.560 --> 01:05:58.800
Bye.

01:05:58.800 --> 01:06:00.720
Or evening, if you're in France.

01:06:00.720 --> 01:06:02.180
Exactly.

01:06:02.180 --> 01:06:02.620
Bye, all.

01:06:02.620 --> 01:06:03.020
Bye.

01:06:03.020 --> 01:06:03.440
Bye.

01:06:04.440 --> 01:06:07.200
This has been another episode of Talk Python To Me.

01:06:07.200 --> 01:06:11.520
Our guests on this episode have been Victor Schmidt, Jonathan Wilson, and Boris Feld.

01:06:11.520 --> 01:06:15.060
It's been brought to you by Square and us over at Talk Python Training.

01:06:15.060 --> 01:06:20.900
With Square, your web app can easily take payments, seamlessly accept debit and credit cards, as well

01:06:20.900 --> 01:06:22.060
as digital wallet payments.

01:06:22.060 --> 01:06:27.640
Get started building your own online payment form in three steps with Square's Python SDK

01:06:27.640 --> 01:06:30.740
at talkpython.fm/Square.

01:06:30.740 --> 01:06:32.960
Want to level up your Python?

01:06:32.960 --> 01:06:37.020
We have one of the largest catalogs of Python video courses over at Talk Python.

01:06:37.020 --> 01:06:42.180
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:06:42.180 --> 01:06:44.860
And best of all, there's not a subscription in sight.

01:06:44.860 --> 01:06:47.760
Check it out for yourself at training.talkpython.fm.

01:06:47.760 --> 01:06:52.520
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:06:52.520 --> 01:06:53.740
We should be right at the top.

01:06:53.740 --> 01:06:58.920
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:06:58.920 --> 01:07:03.100
and the direct RSS feed at /rss on talkpython.fm.

01:07:03.100 --> 01:07:06.540
We're live streaming most of our recordings these days.

01:07:06.540 --> 01:07:09.960
If you want to be part of the show and have your comments featured on the air,

01:07:09.960 --> 01:07:14.340
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:07:14.340 --> 01:07:16.220
This is your host, Michael Kennedy.

01:07:16.220 --> 01:07:17.520
Thanks so much for listening.

01:07:17.520 --> 01:07:18.680
I really appreciate it.

01:07:18.680 --> 01:07:20.600
Now get out there and write some Python code.

01:07:20.600 --> 01:07:41.480
I really appreciate it.

01:07:41.480 --> 01:08:11.460
Thank you.

