WEBVTT

00:00:00.001 --> 00:00:03.880
What is the state of serverless computing and Python in 2024?

00:00:03.880 --> 00:00:06.600
What are some of the new tools and best practices?

00:00:06.600 --> 00:00:09.080
Well, we're lucky to have Tony Sherman,

00:00:09.080 --> 00:00:11.480
who has a lot of practical experience

00:00:11.480 --> 00:00:13.760
with serverless programming on the show.

00:00:13.760 --> 00:00:15.780
This is Talk Python to Me,

00:00:15.780 --> 00:00:19.960
episode 458, recorded January 25th, 2024.

00:00:19.960 --> 00:00:37.720
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:37.720 --> 00:00:39.480
This is your host, Michael Kennedy.

00:00:39.480 --> 00:00:42.120
Follow me on Mastodon, where I'm @mkennedy,

00:00:42.120 --> 00:00:44.520
and follow the podcast using @talkpython,

00:00:44.520 --> 00:00:46.960
both on fosstodon.org.

00:00:46.960 --> 00:00:49.520
Keep up with the show and listen to over seven years

00:00:49.520 --> 00:00:52.040
of past episodes at talkpython.fm.

00:00:52.040 --> 00:00:55.840
We've started streaming most of our episodes live on YouTube.

00:00:55.840 --> 00:00:58.900
Subscribe to our YouTube channel over at talkpython.fm

00:00:58.900 --> 00:01:01.920
slash YouTube to get notified about upcoming shows

00:01:01.920 --> 00:01:03.380
and be part of that episode.

00:01:03.380 --> 00:01:05.640
This episode is brought to you by Sentry.

00:01:05.640 --> 00:01:07.420
Don't let those errors go unnoticed.

00:01:07.420 --> 00:01:09.180
Use Sentry like we do here at Talk Python.

00:01:09.180 --> 00:01:12.620
Sign up at talkpython.fm/sentry.

00:01:12.620 --> 00:01:15.260
And it's brought to you by Mailtrap,

00:01:15.260 --> 00:01:18.220
an email delivery platform that developers love.

00:01:18.220 --> 00:01:21.420
Try for free at mailtrap.io.

00:01:21.420 --> 00:01:23.940
Tony, welcome to Talk Python to Me.

00:01:23.940 --> 00:01:24.760
Thank you.

00:01:24.760 --> 00:01:25.540
Thanks for having me.

00:01:25.540 --> 00:01:26.980
Fantastic to have you here.

00:01:26.980 --> 00:01:29.580
It's going to be really fun to talk about serverless.

00:01:29.580 --> 00:01:32.020
You know, the joke with the cloud is,

00:01:32.020 --> 00:01:33.920
well, I know you call it the cloud,

00:01:33.920 --> 00:01:35.480
but it's really just somebody else's computer.

00:01:35.480 --> 00:01:37.620
But we're not even talking about computer.

00:01:37.620 --> 00:01:38.760
We're just talking about functions.

00:01:38.760 --> 00:01:40.020
Maybe it's someone else's function.

00:01:40.020 --> 00:01:40.360
I don't know.

00:01:40.360 --> 00:01:40.960
We're going to find out.

00:01:40.960 --> 00:01:46.640
Yeah, I actually, I saw a recent article about server-free recently with somebody trying to,

00:01:46.640 --> 00:01:48.260
yeah, move completely.

00:01:48.260 --> 00:01:49.020
Yeah.

00:01:49.020 --> 00:01:49.420
Yeah.

00:01:49.420 --> 00:01:53.540
Because as you might know, serverless doesn't mean actually no servers.

00:01:53.540 --> 00:01:54.260
Of course.

00:01:54.260 --> 00:01:54.820
Of course.

00:01:54.820 --> 00:01:56.040
Server-free.

00:01:56.200 --> 00:01:56.460
All right.

00:01:56.460 --> 00:02:00.740
So we could just get the thing to run on the BitTorrent network.

00:02:00.740 --> 00:02:01.360
Got it.

00:02:01.360 --> 00:02:01.740
Okay.

00:02:01.740 --> 00:02:02.340
Yeah.

00:02:02.340 --> 00:02:03.360
I don't know.

00:02:03.360 --> 00:02:03.900
I don't know.

00:02:03.900 --> 00:02:04.540
We'll figure it out.

00:02:04.540 --> 00:02:06.180
But it's going to be super fun.

00:02:06.180 --> 00:02:10.060
And we're going to talk about your experience working with serverless.

00:02:10.060 --> 00:02:12.840
We'll talk about some of the choices people have out there

00:02:12.840 --> 00:02:18.840
and also some of the tools that we can use to do things like observe and test our serverless code.

00:02:18.840 --> 00:02:19.300
Yeah.

00:02:19.300 --> 00:02:21.580
For that, though, tell us a bit about yourself.

00:02:21.580 --> 00:02:22.320
Sure.

00:02:22.320 --> 00:02:26.660
So I'm actually a career changer.

00:02:26.660 --> 00:02:34.660
So I worked in the cable industry for about 10 years and doing a lot of different things

00:02:34.660 --> 00:02:40.520
from installing, you know, knock out the door cable guy to working on more of the outside plant.

00:02:40.740 --> 00:02:46.680
But at some point, I was seeing limits of career path there.

00:02:46.680 --> 00:02:50.120
And so my brother-in-law is a software engineer.

00:02:50.120 --> 00:02:54.780
And I had already started kind of going back to school, finishing my degree.

00:02:54.780 --> 00:02:57.820
And I was like, okay, well, maybe I should kind of look into this.

00:02:57.820 --> 00:03:00.380
And so I took an intro to programming class.

00:03:00.380 --> 00:03:01.240
It was in Python.

00:03:01.240 --> 00:03:05.440
And that just kind of, yeah, led me down this path.

00:03:05.440 --> 00:03:09.880
So now for the past, I don't know, four years or so, been working professionally in the software world,

00:03:09.880 --> 00:03:14.420
started out in a QA role at an IoT company.

00:03:14.420 --> 00:03:19.500
And now, yeah, doing a lot of serverless programming in Python these days.

00:03:19.500 --> 00:03:24.140
Second company now, but that does some school bus safety products.

00:03:24.140 --> 00:03:25.440
Interesting.

00:03:25.440 --> 00:03:26.120
Very cool.

00:03:26.120 --> 00:03:26.820
Yeah.

00:03:26.820 --> 00:03:27.180
Yep.

00:03:27.180 --> 00:03:29.560
But a lot of Python and a lot of serverless.

00:03:29.900 --> 00:03:34.420
Well, serverless and IoT, I feel like they go pretty hand in hand.

00:03:34.420 --> 00:03:35.320
Yes.

00:03:35.320 --> 00:03:35.920
Yep.

00:03:35.920 --> 00:03:36.320
Yeah.

00:03:36.320 --> 00:03:42.120
Another thing is with serverless is when you have very like spiky traffic.

00:03:42.120 --> 00:03:47.660
Like if you think about school buses that, you know, you have a lot coming on twice a day.

00:03:47.660 --> 00:03:48.340
To bimodal.

00:03:48.340 --> 00:03:48.720
Exactly.

00:03:48.720 --> 00:03:52.180
Like the 8 a.m. shift and then the 2.30 to 3 shift.

00:03:52.180 --> 00:03:56.840
So, yeah, that's a really good use case for serverless is something like that.

00:03:57.840 --> 00:03:58.360
Okay.

00:03:58.360 --> 00:04:01.780
Are you enjoying doing the programming stuff instead of the cable stuff?

00:04:01.780 --> 00:04:02.640
Absolutely.

00:04:02.640 --> 00:04:10.200
I sometimes I live in Michigan, so I look outside and look at, you know, the snow coming down or these storms.

00:04:10.200 --> 00:04:14.840
And yeah, I just, yeah, I really, some people like you don't miss being outside.

00:04:14.840 --> 00:04:18.780
I'm like, maybe every once in a while, but I can, I can go walk outside on a nice day.

00:04:19.700 --> 00:04:21.500
You can choose to go outside.

00:04:21.500 --> 00:04:24.200
You're not ready to go outside in the sleet or rain.

00:04:24.200 --> 00:04:25.040
Yeah.

00:04:25.040 --> 00:04:26.300
Yeah, absolutely.

00:04:26.300 --> 00:04:33.060
We just had a mega storm here and just the huge tall trees here in Oregon just fell left and right.

00:04:33.060 --> 00:04:39.920
And there's in every direction that I look, there's a large tree on top of one of the houses of my neighbors.

00:04:39.920 --> 00:04:40.920
Oh, man.

00:04:40.920 --> 00:04:42.120
Maybe a house or two over.

00:04:42.120 --> 00:04:46.140
But it just took out all the, everything that was a cable in the air was taken out.

00:04:46.220 --> 00:04:52.700
So it's just been a swarm of people who are out in 13 degree Fahrenheit, you know, negative nine Celsius weather.

00:04:52.700 --> 00:04:55.780
And I'm thinking, you know, not really choosing to be out there today, probably.

00:04:55.780 --> 00:04:56.100
Right.

00:04:56.100 --> 00:04:57.140
Excellent.

00:04:57.140 --> 00:04:58.860
Well, thanks for that introduction.

00:04:58.860 --> 00:05:07.760
I guess maybe we could, a lot of people probably know what serverless is, but I'm sure there's a lot who are not even really aware of what serverless programming is.

00:05:07.760 --> 00:05:08.000
Right.

00:05:08.000 --> 00:05:10.720
Let's talk about what's the idea.

00:05:10.720 --> 00:05:12.620
What's the, what's the Zen of this?

00:05:12.620 --> 00:05:13.660
Yeah.

00:05:13.900 --> 00:05:25.560
So, yeah, I kind of, you know, made the joke that serverless doesn't mean there are no servers, but, and there's, hopefully I don't butcher it too much, but it's more like, functions as a service.

00:05:25.560 --> 00:05:28.160
There's other things that can be serverless too.

00:05:28.160 --> 00:05:35.280
Like there's, you know, serverless databases or, a lot of different, services that can be serverless.

00:05:35.280 --> 00:05:40.380
Meaning you don't have to think about like how to operate them, how to think about, you know, scaling them up.

00:05:40.380 --> 00:05:45.900
You don't have to, you know, spin up, VMs or, or Kubernetes clusters or anything.

00:05:45.900 --> 00:05:48.300
You, you don't have to think about that part.

00:05:48.300 --> 00:05:51.260
It's just your, your code that goes into it.

00:05:51.260 --> 00:05:55.520
And so, yeah, serverless functions are probably what people are most familiar with.

00:05:55.520 --> 00:06:01.560
And that's, I'm sure what we'll talk about most today, but, and, yeah, that's really the idea.

00:06:01.560 --> 00:06:04.460
You don't have to, you don't have to manage the server.

00:06:04.460 --> 00:06:05.620
Oh, sure.

00:06:05.620 --> 00:06:07.180
And that's a huge barrier.

00:06:07.180 --> 00:06:19.400
I remember when I first started getting into web apps and programming and then another level, when I got into Python, because I had not done that much Linux work, getting stuff up running.

00:06:19.400 --> 00:06:20.860
It was really tricky.

00:06:20.860 --> 00:06:24.100
And then having the concern of, is it secure?

00:06:24.100 --> 00:06:25.360
How do I patch it?

00:06:25.360 --> 00:06:26.240
How do I back it up?

00:06:26.240 --> 00:06:27.840
How do I keep it going?

00:06:27.840 --> 00:06:31.020
All of those things, they're non-trivial, right?

00:06:31.020 --> 00:06:31.720
Right.

00:06:31.720 --> 00:06:32.080
Yeah.

00:06:32.080 --> 00:06:32.360
Yeah.

00:06:32.360 --> 00:06:33.820
There's, there's a lot to think about.

00:06:33.820 --> 00:06:39.320
And, and if you like work at an organization, it's probably different everywhere you go to that.

00:06:39.320 --> 00:06:42.020
They, you know, how they manage their servers and things.

00:06:42.020 --> 00:06:46.800
So, so putting in some stuff in the cloud kind of brings some, some commonality to it too.

00:06:46.800 --> 00:06:55.700
Like you can, you can learn how, you know, the Azure cloud or Google cloud or AWS, how those things work and, and kind of have some common ground too.

00:06:55.700 --> 00:06:58.040
So, yeah, for sure.

00:06:58.040 --> 00:07:03.760
Like having, I mean, also feels more accessible to the developers in a larger group.

00:07:03.760 --> 00:07:11.680
You know, in the sense that it's not a DevOps team that kind of takes care of the servers or a production engineers where you hand them your code.

00:07:11.680 --> 00:07:17.140
It's, it's a little closer to just, I have a function and then I get it up there and it continues to be the function, you know?

00:07:17.140 --> 00:07:17.720
Yeah.

00:07:17.720 --> 00:07:19.760
You, and that is a different mindset too.

00:07:19.880 --> 00:07:23.880
You kind of see it all the way through from writing your code to deploying it.

00:07:23.880 --> 00:07:25.420
Uh, yeah.

00:07:25.420 --> 00:07:31.640
With, without maybe an entire DevOps team that you just kind of say, here you go, go deploy this.

00:07:31.860 --> 00:07:32.420
Yeah.

00:07:32.420 --> 00:07:32.520
Yeah.

00:07:32.520 --> 00:07:37.300
So in my world, I mostly have virtual machines.

00:07:37.300 --> 00:07:40.160
I've moved over to kind of a Docker cluster.

00:07:40.160 --> 00:07:48.060
I think I've got 17 different things running in the Docker cluster at the moment, but both of those are really different than serverless.

00:07:48.060 --> 00:07:48.720
Right.

00:07:48.720 --> 00:07:49.260
Yeah.

00:07:49.260 --> 00:07:49.920
Yeah.

00:07:49.920 --> 00:07:55.040
So it's been working well for me, but when I think about serverless, let me know if this is true.

00:07:55.040 --> 00:08:04.420
It feels like you don't need to have as much of a, a Linux or server or, or sort of an ops experience to create these things.

00:08:04.420 --> 00:08:05.280
Yeah.

00:08:05.280 --> 00:08:09.200
I would say like you could probably get away with like almost none, right?

00:08:09.200 --> 00:08:19.660
Like at the simplest form, like with, like AWS, for instance, their Lambda functions, you can, and that's the one I'm most familiar with.

00:08:19.660 --> 00:08:22.740
So, forgive me for using them as an example for everything.

00:08:22.740 --> 00:08:37.980
There's a lot of, different, serverless, options, but, you could go into the AWS console and you could actually, write your, you know, Python code right in the console, deploy that they have function URLs now.

00:08:37.980 --> 00:08:43.760
So you could actually have like, I mean, within a matter of minutes, you can have a serverless function set up.

00:08:43.760 --> 00:08:46.960
And so, AWS Lambda, right.

00:08:46.960 --> 00:08:47.640
That's the one.

00:08:47.640 --> 00:08:48.260
Yep.

00:08:48.260 --> 00:08:50.620
Lambda being, I guess, a simple function, right?

00:08:50.620 --> 00:08:51.660
We have Lambdas in Python.

00:08:51.660 --> 00:08:52.880
They can only be one line.

00:08:52.880 --> 00:08:56.660
So I'm sure you can have more than one line in the AWS Lambda, but.

00:08:56.660 --> 00:08:56.980
Yeah.

00:08:56.980 --> 00:09:03.500
There are limitations though, with, with Lambda that you, that are, definitely some pain points that I ran into.

00:09:03.500 --> 00:09:03.900
So.

00:09:03.900 --> 00:09:04.400
Oh, really?

00:09:04.400 --> 00:09:04.640
Okay.

00:09:04.640 --> 00:09:05.620
What are some of the limitations?

00:09:05.620 --> 00:09:06.440
Yeah.

00:09:06.440 --> 00:09:09.460
So, package size is one.

00:09:09.460 --> 00:09:19.620
So if you start thinking about all these like amazing, packages on PyPI, you do have to start thinking about how, how many you're going to bring in.

00:09:19.620 --> 00:09:27.920
So, and I don't know the exact limits off the top of my head, but it's pretty quick Google search on their, their package size.

00:09:27.920 --> 00:09:31.160
It might be like 50 megabytes zipped, but two 50.

00:09:31.160 --> 00:09:41.000
Um, when you decompress it, to do a zip base, then they do have, containerized Lambda functions that go up to like a 10 gig limit.

00:09:41.000 --> 00:09:43.260
So that helps, but, okay.

00:09:43.260 --> 00:09:43.960
Yeah.

00:09:43.960 --> 00:09:44.280
Yeah.

00:09:44.280 --> 00:09:52.920
They, those ones, used to be less performant, but they're, they're kind of catching up to where they're, that was really on something called cold starts.

00:09:52.920 --> 00:09:56.740
Uh, but they're, they're getting, I think pretty close to it.

00:09:56.740 --> 00:10:03.880
Not, not being a very big difference, whether you Dockerize or zip these functions, but, but yeah.

00:10:03.880 --> 00:10:09.460
So when you start just like pip installing everything, you've got to think about how to get that code into your function.

00:10:10.040 --> 00:10:13.440
Uh, and, how much it's going to bring in.

00:10:13.440 --> 00:10:19.200
So yeah, that definitely was, a limitation that, had to quickly learn.

00:10:19.200 --> 00:10:20.100
Yeah.

00:10:20.100 --> 00:10:24.180
I guess it's probably trying to do pip install -r effectively.

00:10:24.180 --> 00:10:25.040
Yeah.

00:10:25.040 --> 00:10:27.720
And it's like, you know, you, you can't go overboard with this.

00:10:27.720 --> 00:10:28.000
Right.

00:10:28.000 --> 00:10:28.720
Right.

00:10:28.720 --> 00:10:29.200
Right.

00:10:29.200 --> 00:10:29.540
Yeah.

00:10:29.540 --> 00:10:29.880
Yeah.

00:10:29.880 --> 00:10:38.240
When you start bringing in packages, like, you know, maybe like some of the like, scientific packages, you're, you're definitely going to be hitting some, some size limits.

00:10:38.240 --> 00:10:38.680
Okay.

00:10:38.680 --> 00:10:49.040
And with the containerized ones, basically you get probably give it a Docker file and a command to run in it and it can, it can build those images before and then just execute and just do a Docker run.

00:10:49.040 --> 00:10:49.500
Yeah.

00:10:49.500 --> 00:10:58.800
I think how those ones work is you, you store an image, on like their container registry, Amazon's, is it ECR, I think.

00:10:58.800 --> 00:11:05.300
And so then you kind of pointed at that and yeah, it'll, execute your like handler function.

00:11:05.300 --> 00:11:07.840
Uh, when that, when the Lambda gets called.

00:11:08.120 --> 00:11:14.900
This portion of talk Python and me is brought to you by multi-platform error monitoring at Sentry.

00:11:14.900 --> 00:11:16.060
Code breaks.

00:11:16.060 --> 00:11:17.340
It's a fact of life.

00:11:17.340 --> 00:11:19.520
With Sentry, you can fix it faster.

00:11:19.520 --> 00:11:23.700
Does your team or company work on multiple platforms that collaborate?

00:11:23.700 --> 00:11:26.700
Chances are extremely high that they do.

00:11:27.020 --> 00:11:32.520
It might be a reactor view front end JavaScript app that talks to your FastAPI backend services.

00:11:32.520 --> 00:11:40.640
Could be a go microservice talking to your Python microservice or even native mobile apps talking to your Python backend APIs.

00:11:41.180 --> 00:11:42.560
Now let me ask you a question.

00:11:42.560 --> 00:11:47.540
Whatever combination of these that applies to you, how tightly do these teams work together?

00:11:47.960 --> 00:11:52.700
Especially if there are errors originating at one layer, but becoming visible at the other.

00:11:52.700 --> 00:11:56.940
It can be super hard to track these errors across platforms and devices.

00:11:56.940 --> 00:11:58.460
But Sentry has you covered.

00:11:58.460 --> 00:12:00.800
They support many JavaScript front end frameworks.

00:12:00.800 --> 00:12:04.340
Obviously Python backend, such as FastAPI and Django.

00:12:04.800 --> 00:12:06.980
And they even support native mobile apps.

00:12:06.980 --> 00:12:11.960
For example, at Talk Python, we have Sentry integrated into our mobile apps for our courses.

00:12:11.960 --> 00:12:15.100
Those apps are built and compiled in native code with Flutter.

00:12:15.100 --> 00:12:18.900
With Sentry, it's literally a few lines of code to start tracking those errors.

00:12:18.900 --> 00:12:20.220
Don't fly blind.

00:12:20.220 --> 00:12:22.000
Fix code faster with Sentry.

00:12:22.000 --> 00:12:25.240
Create your Sentry account at talkpython.fm/sentry.

00:12:25.240 --> 00:12:28.960
And if you sign up with the code TALKPYTHON, one word, all caps,

00:12:28.960 --> 00:12:32.060
it's good for two free months of Sentry's business plan,

00:12:32.160 --> 00:12:34.880
which will give you up to 20 times as many monthly events,

00:12:34.880 --> 00:12:36.140
as well as some other cool features.

00:12:36.140 --> 00:12:39.480
My thanks to Sentry for supporting Talk Python To Me.

00:12:39.480 --> 00:12:43.360
Yeah, so out in the audience, Kim says,

00:12:43.360 --> 00:12:48.600
AWS does make a few packages available directly just by default in Lambda.

00:12:48.600 --> 00:12:49.420
That's kind of nice.

00:12:49.420 --> 00:12:50.060
Yeah, yep.

00:12:50.060 --> 00:12:54.580
So, yeah, Bodo, which if you're dealing with AWS and Python,

00:12:54.580 --> 00:12:57.060
you're using the Bodo package.

00:12:57.060 --> 00:12:59.640
And yeah, that's included for you.

00:12:59.760 --> 00:13:02.220
So that's definitely helpful in any of their, you know,

00:13:02.220 --> 00:13:04.160
transitive dependencies would be there.

00:13:04.160 --> 00:13:08.320
I think Bodo used to even include, like, requests,

00:13:08.320 --> 00:13:12.720
but then I think they eventually dropped that with some, like, SSL stuff.

00:13:12.720 --> 00:13:17.460
But yeah, you definitely, you can't just, like, pip install anything

00:13:17.460 --> 00:13:21.380
and not think of it unless, depending on how you package these up.

00:13:21.380 --> 00:13:21.640
So.

00:13:21.640 --> 00:13:22.040
Sure.

00:13:22.040 --> 00:13:22.600
Sure.

00:13:22.600 --> 00:13:23.100
That makes sense.

00:13:23.100 --> 00:13:23.560
Yeah.

00:13:23.560 --> 00:13:26.120
Of course they would include their own Python libraries, right?

00:13:26.120 --> 00:13:26.600
Yeah.

00:13:26.600 --> 00:13:29.780
And it's not a, yeah, it's not exactly small.

00:13:29.780 --> 00:13:34.220
I think, like, Bodo core used to be, like, 60 megabytes,

00:13:34.220 --> 00:13:36.860
but I think they've done some work to really get that down.

00:13:36.860 --> 00:13:37.220
So.

00:13:37.220 --> 00:13:38.100
Yeah.

00:13:38.100 --> 00:13:40.220
Yeah, that's, yeah, that's not too bad.

00:13:40.220 --> 00:13:43.840
I feel like Bodo core, Bodo 3, those are constantly changing.

00:13:43.840 --> 00:13:45.140
Like, constantly.

00:13:45.140 --> 00:13:45.780
Yeah.

00:13:45.920 --> 00:13:52.680
Yeah, well, as fast as AWS adds services, they'll probably keep changing quickly.

00:13:52.680 --> 00:13:53.140
Yeah.

00:13:53.140 --> 00:13:57.440
I feel like those are auto-generated, maybe, just from looking at the way the API

00:13:57.440 --> 00:13:59.580
looks at it, you know, the way they look written.

00:13:59.580 --> 00:14:00.340
And so.

00:14:00.340 --> 00:14:00.680
Yeah.

00:14:00.680 --> 00:14:03.140
Yeah, that's probably the case.

00:14:03.140 --> 00:14:03.420
Yeah.

00:14:03.420 --> 00:14:09.260
I know they do that with, like, their infrastructure is code CDK.

00:14:09.260 --> 00:14:13.440
It's all, like, TypeScript originally, and then you have your Python bindings for it.

00:14:13.440 --> 00:14:13.800
And so.

00:14:13.800 --> 00:14:15.120
Right, right, right, right.

00:14:15.220 --> 00:14:18.880
I mean, it makes sense, but at the same time, when you see a change, it doesn't necessarily

00:14:18.880 --> 00:14:22.040
mean, oh, there's a, there's a new important aspect added.

00:14:22.040 --> 00:14:23.520
It's probably just, yeah, I don't know.

00:14:23.520 --> 00:14:29.980
People have actually pulled up the console for AWS, but just the amount of services that

00:14:29.980 --> 00:14:30.280
are there.

00:14:30.280 --> 00:14:33.980
And then each one of those has its own full API, like a little bit of the one of those

00:14:33.980 --> 00:14:34.340
things.

00:14:34.340 --> 00:14:38.760
So we regenerated it, but it might be for some part that you'd never, never call, right?

00:14:38.760 --> 00:14:41.400
Like you might only work with S3 and it's only changed.

00:14:41.400 --> 00:14:41.980
Yeah.

00:14:41.980 --> 00:14:43.660
I don't know, EC2 stuff, right?

00:14:44.000 --> 00:14:44.420
Right.

00:14:44.420 --> 00:14:45.400
Yep, exactly.

00:14:45.400 --> 00:14:47.020
Yeah, indeed.

00:14:47.020 --> 00:14:47.420
All right.

00:14:47.420 --> 00:14:53.160
Well, let's talk real quickly about some of the places where we could do serverless, right?

00:14:53.160 --> 00:14:53.400
Yeah.

00:14:53.400 --> 00:14:54.640
You mentioned AWS Lambda.

00:14:54.640 --> 00:14:55.260
Yeah.

00:14:55.340 --> 00:15:00.040
And I also maybe touch on just 1 million requests free per month.

00:15:00.040 --> 00:15:01.340
That's pretty cool.

00:15:01.340 --> 00:15:01.420
Yeah.

00:15:01.420 --> 00:15:02.180
Yeah.

00:15:02.180 --> 00:15:08.200
So yeah, getting like jumping into AWS sometimes sounds scary, but they have a pretty generous

00:15:08.200 --> 00:15:08.760
free tier.

00:15:08.760 --> 00:15:13.840
Definitely do your research on some of the security of this, but yeah, you can, you know, a million

00:15:13.840 --> 00:15:15.600
requests free per month.

00:15:15.600 --> 00:15:21.040
You probably have to look into that a little bit because it's, you know, you have your memory

00:15:21.040 --> 00:15:22.160
configurations too.

00:15:22.160 --> 00:15:26.480
So there's probably, I don't know exactly how that works within their free tier, but

00:15:26.480 --> 00:15:33.360
you're charged like with Lambda, at least it's your like invocation time and memory and

00:15:33.360 --> 00:15:34.840
also amount of requests.

00:15:34.840 --> 00:15:36.480
So yeah.

00:15:36.640 --> 00:15:41.780
I'm always confused when I look at that and go, okay, with all of those variables, is that

00:15:41.780 --> 00:15:42.720
a lot or a little?

00:15:42.720 --> 00:15:45.620
I know it's a lot, but it's hard for me to conceptualize.

00:15:45.620 --> 00:15:47.400
Like, well, I use a little more memory than I thought.

00:15:47.400 --> 00:15:48.560
So it costs like, wait a minute.

00:15:48.560 --> 00:15:49.960
How do I know how much memory I use?

00:15:49.960 --> 00:15:50.980
You know, like, yeah.

00:15:50.980 --> 00:15:52.000
What does this mean in practice?

00:15:52.000 --> 00:15:52.800
Yeah.

00:15:52.800 --> 00:15:55.360
It's built by how you configure it too.

00:15:55.360 --> 00:16:01.400
So if you say I need a Lambda with 10 gigs of memory, you're, you're being built at that

00:16:01.400 --> 00:16:05.180
like 10 gigabyte price threshold.

00:16:05.180 --> 00:16:13.140
So there is a really, a really cool tool called power to our AWS Lambda power tuner.

00:16:13.140 --> 00:16:19.180
So yeah, what that'll do is you can, it creates a state machine in AWS.

00:16:19.180 --> 00:16:19.660
Yeah.

00:16:19.660 --> 00:16:21.780
I think I did send you a link to that one.

00:16:21.840 --> 00:16:28.860
So the, the power tuner will create a state machine that, invocates your Lambda

00:16:28.860 --> 00:16:31.040
with several different memory configurations.

00:16:31.040 --> 00:16:37.240
And you can say, I want either the best cost optimized version or the best performance optimized

00:16:37.240 --> 00:16:37.800
version.

00:16:37.800 --> 00:16:43.560
So, and that'll tell you, like, it'll say, okay, yeah, you're best with a Lambda configured

00:16:43.560 --> 00:16:48.760
at, you know, 256 megabytes, you know, for memory.

00:16:48.760 --> 00:16:50.780
So, sorry.

00:16:50.780 --> 00:16:51.000
Yeah.

00:16:51.000 --> 00:16:54.020
For the, the link it's, this is power tools.

00:16:54.020 --> 00:16:55.580
This is a different, amazing package.

00:16:55.580 --> 00:16:56.200
Yeah.

00:16:56.200 --> 00:16:58.520
Maybe I didn't send you the, power tuner.

00:16:58.520 --> 00:16:59.420
I should, okay.

00:16:59.420 --> 00:16:59.740
Sorry.

00:16:59.740 --> 00:17:00.860
That's news to me.

00:17:00.860 --> 00:17:01.720
Okay.

00:17:01.720 --> 00:17:02.160
Sorry.

00:17:02.160 --> 00:17:02.560
Yeah.

00:17:02.560 --> 00:17:04.180
And they have similar names.

00:17:04.180 --> 00:17:04.800
Yeah.

00:17:04.800 --> 00:17:07.080
There's only so many ways to describe stuff.

00:17:07.080 --> 00:17:07.460
Right.

00:17:07.460 --> 00:17:08.200
Yeah.

00:17:08.200 --> 00:17:08.480
Okay.

00:17:08.480 --> 00:17:09.480
They have it right in their head.

00:17:09.480 --> 00:17:09.900
Yep.

00:17:09.900 --> 00:17:11.600
And it is an open source package.

00:17:11.600 --> 00:17:14.360
So there's probably a GitHub link in there, but yeah.

00:17:14.360 --> 00:17:14.400
Yeah.

00:17:14.400 --> 00:17:19.900
And, this will tell you like the best way to optimize your, your Lambda function, at

00:17:19.900 --> 00:17:22.040
least as far as memory is concerned.

00:17:22.040 --> 00:17:24.560
So, yeah, really good tool.

00:17:24.560 --> 00:17:28.740
It gives you a visualization and gives you a graph that will say like, okay, here's,

00:17:28.740 --> 00:17:30.840
here's kind of where cost and performance meet.

00:17:31.060 --> 00:17:36.560
And so, yeah, it's, it's really excellent for figuring that out.

00:17:36.560 --> 00:17:42.220
Um, yeah, at least in, in AWS land, I don't know if some of the other cloud providers have

00:17:42.220 --> 00:17:47.520
something similar to this, but, yeah, it's definitely a really helpful tool.

00:17:47.520 --> 00:17:48.840
Sure.

00:17:48.840 --> 00:17:49.320
Yeah.

00:17:49.320 --> 00:17:53.140
Like I said, I've, I'm confused and I've been doing cloud stuff for a long time when I look

00:17:53.140 --> 00:17:53.300
at it.

00:17:53.300 --> 00:17:53.540
Yeah.

00:17:53.540 --> 00:17:55.380
So, well, there's some interesting things here.

00:17:55.380 --> 00:18:02.740
So like, you can actually have, a Lambda invocation that costs less with a higher

00:18:02.740 --> 00:18:05.600
memory configuration because it'll run faster.

00:18:05.600 --> 00:18:09.260
So you're, I think Lambda bills like by the millisecond now.

00:18:09.260 --> 00:18:14.140
So, you can actually, because it runs faster, it can be cheaper to run.

00:18:14.140 --> 00:18:17.000
So, well, that explains all the rust that's been getting written.

00:18:17.000 --> 00:18:17.900
Yeah.

00:18:17.900 --> 00:18:18.300
Yeah.

00:18:19.500 --> 00:18:21.280
There's a real number behind this.

00:18:21.280 --> 00:18:23.080
I mean, we need to go faster, right?

00:18:23.080 --> 00:18:24.280
Okay.

00:18:24.280 --> 00:18:30.140
So, you know, the, the, I think maybe AWS Lambda is one of the very first ones as well to come

00:18:30.140 --> 00:18:32.180
on with this concept of serverless.

00:18:32.180 --> 00:18:32.920
Yeah.

00:18:32.920 --> 00:18:36.500
It, it, I don't know for sure, but it probably is.

00:18:36.500 --> 00:18:38.660
And then, yeah, your other big cloud providers have them.

00:18:38.660 --> 00:18:44.720
And now you're actually even seeing them, come up with, a lot of like Vercel has

00:18:44.720 --> 00:18:46.980
some kind of, some type of serverless function.

00:18:47.360 --> 00:18:51.780
Uh, I don't know what they're using behind it, but it's almost like they just put a,

00:18:51.780 --> 00:18:57.480
a nicer UI around AWS Lambda or whichever cloud provider that's, you know, that's potentially

00:18:57.480 --> 00:18:58.280
backing this up.

00:18:58.280 --> 00:19:03.520
But, yeah, they're just reselling their flavor of, of somebody else's cloud.

00:19:03.520 --> 00:19:03.720
Yeah.

00:19:03.720 --> 00:19:04.360
Yeah.

00:19:04.360 --> 00:19:09.600
It could be because yeah, Vercel, obviously they have a really, nice suite of products

00:19:09.600 --> 00:19:11.780
with a, with a good UI, very usable.

00:19:11.780 --> 00:19:12.960
So, no.

00:19:12.960 --> 00:19:13.280
Okay.

00:19:13.280 --> 00:19:15.660
So Vercel, some of them people can try.

00:19:15.800 --> 00:19:20.800
And then we've got the two other hyperscale clouds, I guess you call them.

00:19:20.800 --> 00:19:22.540
Google cloud has serverless, right?

00:19:22.540 --> 00:19:23.120
Yep.

00:19:23.120 --> 00:19:23.520
Okay.

00:19:23.520 --> 00:19:27.420
So I'm not sure which ones that they might just be called cloud functions.

00:19:27.420 --> 00:19:33.000
Uh, and yeah, Azure also has, they got cloud run and cloud functions.

00:19:33.000 --> 00:19:34.420
I have no idea what the difference is though.

00:19:35.920 --> 00:19:36.360
Yep.

00:19:36.360 --> 00:19:36.400
Yep.

00:19:36.400 --> 00:19:41.640
And, yeah, Azure also has a serverless product and I'd imagine there's probably like

00:19:41.640 --> 00:19:47.780
even more that we're, we're not aware of, but, yeah, it's kind of, nice to not think

00:19:47.780 --> 00:19:51.120
about, setting up servers for something.

00:19:51.120 --> 00:19:53.800
So then I think maybe, is it fast?

00:19:53.800 --> 00:19:54.020
Yeah.

00:19:54.020 --> 00:19:54.940
Function as a service.

00:19:54.940 --> 00:19:55.340
Let's see.

00:19:55.340 --> 00:19:55.580
Yeah.

00:19:55.960 --> 00:20:01.280
But if we search for F-A-A-S instead of pass or, IaaS, right?

00:20:01.280 --> 00:20:04.640
There's, we've got Almeda, Intel.

00:20:04.640 --> 00:20:09.660
I saw that IBM had some, oh, there's also, the, we've got digital ocean.

00:20:09.660 --> 00:20:14.660
I'm a big fan of digital ocean because I feel like their pricing is really fair and they've

00:20:14.660 --> 00:20:16.060
got good documentation and stuff.

00:20:16.060 --> 00:20:22.260
So they've got functionless, sorry, serverless functions, that you can,

00:20:22.260 --> 00:20:23.500
I don't use these.

00:20:23.500 --> 00:20:23.680
Yeah.

00:20:23.680 --> 00:20:24.400
Yeah.

00:20:24.400 --> 00:20:26.100
I haven't used these either, but yeah.

00:20:26.100 --> 00:20:30.860
Um, and, yeah, as far as costs, like for, especially for like small, like personal

00:20:30.860 --> 00:20:36.040
projects and things where you don't need to have a server on all the time, they're yeah,

00:20:36.040 --> 00:20:37.680
pretty, pretty nice.

00:20:37.680 --> 00:20:41.940
If you have a website that you need something server side where you got to have some Python,

00:20:41.940 --> 00:20:44.200
but you don't need a server going all the time.

00:20:44.200 --> 00:20:44.440
Yeah.

00:20:44.560 --> 00:20:44.920
Okay.

00:20:44.920 --> 00:20:49.300
Like maybe I have a static site, but then I want this one thing to happen.

00:20:49.300 --> 00:20:51.300
If somebody clicks a button, something like that.

00:20:51.300 --> 00:20:51.620
Yeah.

00:20:51.620 --> 00:20:52.840
Yeah, absolutely.

00:20:52.840 --> 00:20:53.280
Yep.

00:20:53.280 --> 00:20:57.040
You could be completely static, but have something that is, yeah.

00:20:57.040 --> 00:20:57.380
Yeah.

00:20:57.380 --> 00:20:59.280
That one function call that you do need.

00:20:59.280 --> 00:20:59.580
Yeah.

00:20:59.580 --> 00:21:00.520
Exactly.

00:21:00.520 --> 00:21:05.100
And then you also pointed out that cloud flare has some form of serverless.

00:21:05.100 --> 00:21:05.940
Yeah.

00:21:05.940 --> 00:21:11.340
And I, I haven't used these either, but, yeah, I do know that they have, some type

00:21:11.340 --> 00:21:14.440
of, you know, functions as a service.

00:21:14.440 --> 00:21:17.820
I don't know what frameworks for languages.

00:21:17.820 --> 00:21:19.340
They let you write them in there.

00:21:19.340 --> 00:21:19.840
Yeah.

00:21:19.840 --> 00:21:23.120
I use, bunny.net for my CDN.

00:21:23.120 --> 00:21:25.140
It's just absolutely awesome platform.

00:21:25.140 --> 00:21:26.060
I really, really love it.

00:21:26.060 --> 00:21:30.320
And one of the things that they've started offering, I can get this stupid, completely useless cookie

00:21:30.320 --> 00:21:35.400
banner to go away is they've offered a, what they call, edge compute.

00:21:35.580 --> 00:21:36.280
Oh, yeah.

00:21:36.280 --> 00:21:36.760
Okay.

00:21:36.760 --> 00:21:38.000
What you would do.

00:21:38.000 --> 00:21:46.220
I don't know where to find it somewhere, maybe, but basically the CDN has 115, 120 points of

00:21:46.220 --> 00:21:49.500
presence all over the world where, you know, this one's close to Brazil.

00:21:49.500 --> 00:21:51.460
This one's close to Australia, whatever.

00:21:51.460 --> 00:21:56.140
And, but you can actually run serverless functions on those things.

00:21:56.140 --> 00:21:57.720
Like, so you deploy them.

00:21:57.720 --> 00:22:01.200
So the code actually executes in 150, 115 locations.

00:22:01.200 --> 00:22:02.000
Yes.

00:22:02.000 --> 00:22:02.380
Yeah.

00:22:02.380 --> 00:22:04.820
Probably cloudflare or something like that as well, but I don't know.

00:22:04.820 --> 00:22:05.440
Yeah.

00:22:05.440 --> 00:22:10.720
AWS has, they have like Lambda at edge, at the edge.

00:22:10.720 --> 00:22:16.820
So that's kind of, goes hand in hand with their, like CDN, cloud, cloud front,

00:22:16.820 --> 00:22:17.280
I believe.

00:22:17.280 --> 00:22:17.580
Yeah.

00:22:17.580 --> 00:22:21.960
So they have something similar like that, where you have a, a Lambda that's going to

00:22:21.960 --> 00:22:23.820
be, you know, perform it because it's yeah.

00:22:23.820 --> 00:22:25.320
Distributed across their CDN.

00:22:25.320 --> 00:22:26.220
Yeah.

00:22:26.220 --> 00:22:27.980
CDN that's a whole nother world.

00:22:27.980 --> 00:22:30.000
They're, they're getting really advanced.

00:22:30.000 --> 00:22:30.760
Yeah.

00:22:30.760 --> 00:22:31.280
Yeah.

00:22:31.280 --> 00:22:33.160
Yeah.

00:22:33.160 --> 00:22:35.860
So, we won't, maybe that's a different show.

00:22:35.860 --> 00:22:40.360
It's not a show today, but it's just the idea of like you distribute the compute

00:22:40.360 --> 00:22:42.760
on the CDN is pretty nice.

00:22:42.760 --> 00:22:47.880
The drawback is just JavaScript, which is okay, but it's, it's not the same as right.

00:22:47.880 --> 00:22:48.400
Yes.

00:22:48.400 --> 00:22:48.740
Yeah.

00:22:48.740 --> 00:22:51.480
I wonder if you could do high script.

00:22:51.480 --> 00:22:52.280
Oh yeah.

00:22:52.280 --> 00:22:53.540
That's an interesting thought.

00:22:53.540 --> 00:22:53.800
Yeah.

00:22:53.800 --> 00:22:54.260
Yeah.

00:22:54.260 --> 00:22:54.440
Yeah.

00:22:54.440 --> 00:22:57.040
We're getting closer and closer to Python in the browser.

00:22:57.040 --> 00:22:57.660
So yeah.

00:22:57.660 --> 00:22:58.240
Yeah.

00:22:58.240 --> 00:23:02.700
My JavaScript includes this little bit of WebAssembly and I don't, I don't like semicolons,

00:23:02.700 --> 00:23:03.700
but go ahead and run it anyway.

00:23:03.700 --> 00:23:05.180
Yeah.

00:23:05.180 --> 00:23:06.480
Out in the audience.

00:23:06.480 --> 00:23:10.200
It looks like, Cloudflare probably does support Python, which is.

00:23:10.260 --> 00:23:10.520
Okay.

00:23:10.520 --> 00:23:11.020
Yeah.

00:23:11.020 --> 00:23:11.460
Yeah.

00:23:11.460 --> 00:23:15.620
There's, there's so many options out there for, for serverless functions that are, yeah,

00:23:15.620 --> 00:23:19.880
really, especially if you're already in, you know, if you're maybe deploying, you know,

00:23:19.880 --> 00:23:23.460
some static stuff over Cloudflare, Cloudflare or Vercel.

00:23:23.460 --> 00:23:24.460
Yeah.

00:23:24.460 --> 00:23:28.860
It's sometimes nice just to be all, all in on one, one service.

00:23:28.860 --> 00:23:29.600
Yeah.

00:23:29.600 --> 00:23:29.960
Yeah.

00:23:29.960 --> 00:23:30.540
It really is.

00:23:30.540 --> 00:23:35.260
Let's talk about using, choosing serverless over other things, right?

00:23:35.320 --> 00:23:39.520
You actually laid out two really good examples or maybe three, even with the static site

00:23:39.520 --> 00:23:43.140
example, but you know, I've got bursts of activity.

00:23:43.140 --> 00:23:43.920
Yeah.

00:23:43.920 --> 00:23:44.600
Right.

00:23:44.600 --> 00:23:50.420
And really, really low, incredibly, incredibly low usage other times.

00:23:50.420 --> 00:23:50.700
Right.

00:23:50.700 --> 00:23:51.380
Yeah.

00:23:51.380 --> 00:23:51.820
Yeah.

00:23:51.820 --> 00:23:54.920
You think of like, yeah, you're, you're black Friday traffic, right?

00:23:54.920 --> 00:24:01.320
Like you to not have to think of like how many servers to be provisioned for something

00:24:01.320 --> 00:24:02.040
like that.

00:24:02.040 --> 00:24:07.240
Or if you don't know, I think there's probably some like, well, I actually know there's

00:24:07.240 --> 00:24:11.080
been like some pretty popular articles about people like leaving the cloud.

00:24:11.080 --> 00:24:17.200
Uh, and, and yeah, like if you know your scale and you know, you know exactly what you

00:24:17.200 --> 00:24:24.220
need, yeah, you, you probably can save money by just having your, your own infrastructure

00:24:24.220 --> 00:24:30.520
set up or, but yeah, if you don't know, or it's very like spiky, you don't need

00:24:30.520 --> 00:24:34.960
to have a server that's consuming a lot of power running, you know, 24 hours a day.

00:24:34.960 --> 00:24:38.920
You can, just invoke a function as you need.

00:24:38.920 --> 00:24:46.000
So this portion of talk Python may is brought to you by Mailtrap and email delivery platform

00:24:46.000 --> 00:24:53.320
that developers love an email sending solution with industry, best analytics, SMTP and email

00:24:53.320 --> 00:24:59.360
APIs, SDKs for major programming languages and 24 seven human support.

00:24:59.360 --> 00:25:02.280
Try for free at Mailtrap.io.

00:25:02.280 --> 00:25:03.840
Yeah.

00:25:03.920 --> 00:25:10.140
There's a super interesting series by David Heinemeyer Hansen of Ruby on rails fame and

00:25:10.140 --> 00:25:15.900
from, base camp about how base camp has left the cloud and how they're saving $7 million

00:25:15.900 --> 00:25:19.040
and getting better performance over five years.

00:25:19.040 --> 00:25:19.620
Yeah.

00:25:19.620 --> 00:25:21.780
But that's, that's a big investment, right?

00:25:21.780 --> 00:25:26.420
They bought $600,000 for hardware, right?

00:25:26.420 --> 00:25:26.920
Yeah.

00:25:26.920 --> 00:25:27.340
Yeah.

00:25:27.340 --> 00:25:28.560
Only so many people can do that.

00:25:28.560 --> 00:25:29.280
Right.

00:25:29.280 --> 00:25:33.900
And you, you know, you gotta have that running somewhere that, you know, with, with,

00:25:33.900 --> 00:25:36.680
with backup power and, yeah.

00:25:36.680 --> 00:25:37.300
Yeah.

00:25:37.300 --> 00:25:43.000
So what they ended up doing for this one is they went with some service called theft,

00:25:43.000 --> 00:25:43.260
okay.

00:25:43.260 --> 00:25:46.400
Hosting, which is like white glove, white.

00:25:46.400 --> 00:25:52.120
So white, labeled is the word I'm looking for where it just looks like it's your hardware,

00:25:52.120 --> 00:25:57.220
but they put it into a mega data center and there's, you know, they'll have the hardware

00:25:57.220 --> 00:26:00.660
shipped to them and somebody will just come out and install it into racks and go, here's

00:26:00.660 --> 00:26:00.960
your IP.

00:26:00.960 --> 00:26:01.300
Right.

00:26:01.300 --> 00:26:02.260
Like a, yeah.

00:26:02.720 --> 00:26:09.000
Uh, virtual, virtual VM or a VM in a cloud that, but it takes three days, three

00:26:09.000 --> 00:26:09.660
weeks to boot.

00:26:09.660 --> 00:26:11.160
Right.

00:26:11.160 --> 00:26:11.640
Yeah.

00:26:11.640 --> 00:26:12.040
Yeah.

00:26:12.040 --> 00:26:12.220
Yeah.

00:26:12.220 --> 00:26:16.280
Which is kind of the opposite is almost, I mean, I'm kind of diving into it because it's,

00:26:16.280 --> 00:26:20.660
it's almost the exact opposite of the serverless benefits, right?

00:26:20.660 --> 00:26:22.820
This is insane stability.

00:26:22.820 --> 00:26:29.660
I have this thing for five years, 4,000 CPUs we've installed and we're using them for the

00:26:29.660 --> 00:26:33.480
next five years rather than how many milliseconds am I going to run this code for?

00:26:33.480 --> 00:26:34.460
Right.

00:26:34.460 --> 00:26:34.960
Exactly.

00:26:34.960 --> 00:26:35.400
Yeah.

00:26:35.400 --> 00:26:35.680
Yeah.

00:26:35.680 --> 00:26:36.060
Yeah.

00:26:36.060 --> 00:26:37.680
It's definitely the far opposite.

00:26:37.940 --> 00:26:42.960
And so, yeah, you kind of, you know, maybe serverless isn't for every use case, but it's

00:26:42.960 --> 00:26:45.180
definitely a nice like tool to have in the toolbox.

00:26:45.500 --> 00:26:51.060
And yeah, you definitely even working in serverless, like if you're, yeah, eventually you're going

00:26:51.060 --> 00:26:54.860
to need like maybe to interact with the database that's got to be on all the time.

00:26:54.860 --> 00:26:59.840
You know, it's yeah, there's a lot of, it's a good tool, but it's definitely not the,

00:26:59.840 --> 00:27:02.160
uh, one size fits all solution.

00:27:02.160 --> 00:27:07.380
So yeah, let's talk databases in a second, but for, you know, when does it make sense

00:27:07.380 --> 00:27:10.540
to say we're going to put this, like if this suppose I have an API, right?

00:27:10.540 --> 00:27:15.860
That's a pretty, an API is a real similar equivalent to what a serverless thing is.

00:27:15.860 --> 00:27:17.640
Like I'm going to call this API, I think it's going to happen.

00:27:17.640 --> 00:27:18.520
I'm going to call this function.

00:27:18.520 --> 00:27:19.160
The thing's going to happen.

00:27:19.160 --> 00:27:22.680
Let's suppose I have an API and it has eight endpoints.

00:27:22.680 --> 00:27:24.800
It's written in FastAPI or whatever it is.

00:27:24.800 --> 00:27:27.700
It might make sense to have that as serverless, right?

00:27:27.700 --> 00:27:29.700
You don't want to run a server and all that kind of thing.

00:27:29.700 --> 00:27:32.060
But what if I have an API with 200 endpoints?

00:27:32.480 --> 00:27:35.560
Like, where is the point where like, there are so many little serverless things.

00:27:35.560 --> 00:27:36.580
I don't even know where to look.

00:27:36.580 --> 00:27:37.160
They're everywhere.

00:27:37.160 --> 00:27:38.360
Which version is this one?

00:27:38.360 --> 00:27:38.860
You know what I mean?

00:27:38.860 --> 00:27:43.060
Like where, where's that trade-off and how do, you know, you and the people you work with

00:27:43.060 --> 00:27:43.680
think about that?

00:27:43.680 --> 00:27:48.080
Yeah, I guess that's a, a good, good question.

00:27:48.080 --> 00:27:54.000
I mean, as you start like, you know, getting into these like microservices, how small

00:27:54.000 --> 00:27:55.100
do you want to break these up?

00:27:55.100 --> 00:27:58.360
And so there, there, there is some different thoughts on that.

00:27:58.360 --> 00:28:03.760
Even like a, a Lambda function, for instance, if you, if you put this behind an API,

00:28:03.760 --> 00:28:12.320
uh, you can use a single Lambda function to, for your entire rest API, even if it is,

00:28:12.320 --> 00:28:13.620
you know, 200 endpoints.

00:28:13.620 --> 00:28:15.000
So, okay.

00:28:15.620 --> 00:28:19.840
So you put the whole app there and then when a request comes in, it routes to whatever

00:28:19.840 --> 00:28:20.700
part of your app.

00:28:20.700 --> 00:28:21.600
Theoretically.

00:28:21.600 --> 00:28:22.040
Yeah.

00:28:22.040 --> 00:28:22.380
Yeah.

00:28:22.380 --> 00:28:28.580
So there's, a package called power tools for, AWS power tools.

00:28:28.580 --> 00:28:29.180
I don't know.

00:28:29.180 --> 00:28:30.240
Power tools for Python.

00:28:30.240 --> 00:28:30.480
Yeah.

00:28:30.480 --> 00:28:30.860
I don't care.

00:28:30.860 --> 00:28:31.400
Yeah.

00:28:31.400 --> 00:28:31.980
Yeah.

00:28:31.980 --> 00:28:32.920
I know the similar name.

00:28:32.920 --> 00:28:33.100
Yeah.

00:28:33.100 --> 00:28:36.160
So they have a, a really good like event resolver.

00:28:36.160 --> 00:28:42.200
So you can actually, it's, it almost looks like, you know, flask or, some of the

00:28:42.200 --> 00:28:44.120
other Python web frameworks.

00:28:44.120 --> 00:28:49.620
And so you, you kind of have this resolver, whether it's, you know, API gateway and, and

00:28:49.620 --> 00:28:50.600
AWS are different.

00:28:50.600 --> 00:28:57.260
Um, they have a few different options for, the API itself, but yeah, you, in, in theory,

00:28:57.260 --> 00:29:03.680
you could have your entire API behind a single Lambda function, but then that's probably not

00:29:03.680 --> 00:29:04.120
optimal.

00:29:04.120 --> 00:29:04.560
Right.

00:29:04.560 --> 00:29:09.280
So you're, that's where you have to, figure out how to break that up.

00:29:09.280 --> 00:29:16.380
And so, yeah, they do like that same, the decorators, you know, app dot post or

00:29:16.380 --> 00:29:16.560
yeah.

00:29:16.560 --> 00:29:17.240
Yeah.

00:29:17.240 --> 00:29:17.560
Yeah.

00:29:17.560 --> 00:29:23.460
And your endpoints and you can do the, with the, have them, have variables in there

00:29:23.460 --> 00:29:29.180
where maybe you have like ID, as your lookup and it can, you know, slash user slash

00:29:29.180 --> 00:29:33.560
ID is going to find your, find, you know, a single user.

00:29:33.560 --> 00:29:38.160
So, and, and their documentation, they actually addressed this a little bit.

00:29:38.160 --> 00:29:44.400
Like, do you want to do, they, they call it either like a, a micro function pattern where

00:29:44.400 --> 00:29:48.240
maybe every single endpoint has its own Lambda function.

00:29:48.240 --> 00:29:51.140
Uh, but yeah, that's a lot of overhead to maintain.

00:29:51.140 --> 00:29:54.620
If you had, like you said, 200 endpoints, you have 200 Lambdas.

00:29:55.000 --> 00:29:58.200
Um, you gotta upgrade them all at the same time.

00:29:58.200 --> 00:29:58.960
So they have the right.

00:29:58.960 --> 00:29:59.320
Yeah.

00:29:59.320 --> 00:29:59.660
Yeah.

00:29:59.660 --> 00:29:59.900
Yeah.

00:29:59.900 --> 00:30:00.960
Yeah.

00:30:00.960 --> 00:30:01.800
That's right.

00:30:01.800 --> 00:30:02.840
So, yeah.

00:30:02.840 --> 00:30:07.820
So, there, there's definitely some, even, even conflicting views on this.

00:30:07.820 --> 00:30:09.820
How, how micro do you want to go?

00:30:09.980 --> 00:30:17.220
And so, I was able to go to AWS reinvent and, November and, and they actually kind

00:30:17.220 --> 00:30:22.080
of pitched this, this hybrid, maybe like if you take your like CRUD operations, right.

00:30:22.080 --> 00:30:29.340
And, and maybe you have, your create update and delete all on one Lambda that's con with

00:30:29.340 --> 00:30:33.700
its configuration for those, but your read is on another Lambda.

00:30:33.700 --> 00:30:39.480
So maybe your CRUD operations, they all interact with a relational database, but your reader just,

00:30:39.480 --> 00:30:45.520
uh, does like, reads from a dynamo database, where you kind of sync that, that data up.

00:30:45.520 --> 00:30:50.700
And so you could have your permissions kind of separated for each of those, Lambda functions.

00:30:50.700 --> 00:30:56.600
And, you know, people reading from an API don't always need the same permissions as,

00:30:56.600 --> 00:30:58.100
you know, updating, deleting.

00:30:58.100 --> 00:31:02.640
And so, so yeah, there's a lot of different ways to, to break that up and how, how micro

00:31:02.640 --> 00:31:03.680
do you go with this?

00:31:03.680 --> 00:31:04.600
Um, definitely.

00:31:04.600 --> 00:31:05.960
How micro can you go?

00:31:05.960 --> 00:31:06.520
Yeah.

00:31:06.520 --> 00:31:07.080
Yeah.

00:31:07.080 --> 00:31:11.100
Cause it sounds to me like if you had many, many of them, then all of a sudden you're back

00:31:11.100 --> 00:31:16.420
to like, wait, I did this because I didn't want to be in DevOps and now I'm a different

00:31:16.420 --> 00:31:17.160
kind of DevOps.

00:31:17.160 --> 00:31:18.340
Yeah.

00:31:18.340 --> 00:31:18.740
Yeah.

00:31:18.740 --> 00:31:20.600
So, yeah, that.

00:31:20.600 --> 00:31:27.080
Python, that package, the power tools is, is does a lot of like heavy lifting for you.

00:31:27.080 --> 00:31:34.000
Um, at PyCon, there was a talk on serverless that, they, the way they described the power

00:31:34.000 --> 00:31:39.480
tools package was it, they had said it like codified your, your serverless best practices.

00:31:39.880 --> 00:31:41.060
And, and it's really true.

00:31:41.060 --> 00:31:45.440
They give a lot, there's like so many different tools in there and there's a, a logger,

00:31:45.440 --> 00:31:50.180
like a structured logger, that works really well with Lambda and you, you don't even have

00:31:50.180 --> 00:31:54.640
to use like the AWS, login services.

00:31:54.640 --> 00:31:59.880
If you want to use like, you know, data dog or, or Splunk or something else, you, it's just

00:31:59.880 --> 00:32:01.980
a structured logger and how you aggregate them.

00:32:01.980 --> 00:32:07.100
It's like up to you and you can even customize how you format them, but it's, works really

00:32:07.100 --> 00:32:07.800
well with Lambda.

00:32:07.800 --> 00:32:09.080
Um, yeah.

00:32:09.080 --> 00:32:09.520
So that's.

00:32:09.520 --> 00:32:13.780
You probably could actually capture exceptions and stuff with something like century even.

00:32:13.780 --> 00:32:14.140
Right.

00:32:14.140 --> 00:32:14.860
Oh yeah.

00:32:14.860 --> 00:32:15.460
Python code.

00:32:15.460 --> 00:32:16.500
There's no reason you couldn't.

00:32:16.500 --> 00:32:16.960
Right.

00:32:16.960 --> 00:32:17.520
Exactly.

00:32:17.520 --> 00:32:17.960
Yep.

00:32:18.280 --> 00:32:23.060
Um, yeah, some of that comes into, you know, packaging up those, those libraries for

00:32:23.060 --> 00:32:23.420
that.

00:32:23.420 --> 00:32:29.120
Uh, you know, you, you do have to think of some of that stuff, but like, yeah, yeah.

00:32:29.120 --> 00:32:34.100
Data dog, for instance, they, they provide something called like a Lambda layer or a Lambda extension,

00:32:34.100 --> 00:32:37.120
which is another way to package code up.

00:32:37.120 --> 00:32:38.400
That just makes it a little bit easier.

00:32:38.400 --> 00:32:43.000
So, yeah, there's a lot of, a lot of different ways to, to attack some of these problems.

00:32:43.000 --> 00:32:47.260
A lot of that stuff, even though they have nice libraries for them, it's really just calling

00:32:47.260 --> 00:32:51.060
a HTTP endpoint and you could go, okay, we need something really light.

00:32:51.060 --> 00:32:54.560
I don't know if requests is already included or, but there's some gotta be some kind of HTTP

00:32:54.560 --> 00:32:55.640
thing already included.

00:32:55.640 --> 00:32:57.420
We're just going to directly call it.

00:32:57.420 --> 00:32:58.220
Not sure.

00:32:58.220 --> 00:32:58.580
Yeah.

00:32:58.580 --> 00:32:59.200
All these packages.

00:32:59.200 --> 00:32:59.540
Yeah.

00:32:59.540 --> 00:33:00.100
Yep.

00:33:00.100 --> 00:33:00.520
Yeah.

00:33:00.520 --> 00:33:01.020
Yeah.

00:33:01.020 --> 00:33:02.220
This code looks nice.

00:33:02.220 --> 00:33:07.200
This, this power tools code, it looks like well-written Python code.

00:33:07.200 --> 00:33:13.500
It's they, they do some really amazing stuff and they, they bring in a Pydantic too.

00:33:13.780 --> 00:33:20.580
So, yeah, like, being mostly in serverless, I I've never really gotten to use like FastAPI,

00:33:20.580 --> 00:33:20.920
right.

00:33:20.920 --> 00:33:25.220
And leverage Pydantic as much, but with, power tools, you really can.

00:33:25.220 --> 00:33:28.640
So, so they'll package up, Pydantic for you.

00:33:28.640 --> 00:33:35.580
And so you can actually, yeah, you can have Pydantic models for, you know, validation

00:33:35.580 --> 00:33:36.360
function on these.

00:33:36.360 --> 00:33:41.240
It's like a, a Lambda function, for instance, it always receives an event.

00:33:41.240 --> 00:33:43.760
There's always like two arguments to the fun, to the handler function.

00:33:43.760 --> 00:33:45.100
It's event and context.

00:33:45.100 --> 00:33:50.200
And like event is always a, it's a, a dictionary in Python.

00:33:50.200 --> 00:33:53.600
And so they, they can always look different.

00:33:53.600 --> 00:33:55.560
And so, yeah.

00:33:55.560 --> 00:33:56.540
Yeah.

00:33:56.540 --> 00:33:57.760
So, cause the event.

00:33:57.880 --> 00:33:58.120
Yeah.

00:33:58.120 --> 00:34:04.200
Uh, so if you look in the, the power tools, github their, their tests, they have like,

00:34:04.200 --> 00:34:07.340
uh, okay, here's what a, an event.

00:34:07.340 --> 00:34:11.620
API gateway proxy event dot JSON or whatever.

00:34:11.620 --> 00:34:11.920
Right.

00:34:11.920 --> 00:34:12.420
Yes.

00:34:12.420 --> 00:34:12.740
Yeah.

00:34:12.740 --> 00:34:14.140
So they have, yeah.

00:34:14.140 --> 00:34:14.680
Examples.

00:34:14.680 --> 00:34:15.780
Yes.

00:34:15.780 --> 00:34:16.200
Yeah.

00:34:16.200 --> 00:34:19.140
So like, you don't want to parse that out by, by yourself.

00:34:19.220 --> 00:34:25.440
Uh, you know, so they, they have, Pydantic models or they, they might actually just be

00:34:25.440 --> 00:34:31.240
Python data classes, but, that you can, you can say like, okay, yeah, this function

00:34:31.240 --> 00:34:32.560
is going to be for, yeah.

00:34:32.560 --> 00:34:38.040
An API gateway proxy event, or it's going to be an S3 event or whatever it is.

00:34:38.040 --> 00:34:42.560
You know, there's, there's so many different ways to receive events, from different AWS

00:34:42.560 --> 00:34:43.000
services.

00:34:43.000 --> 00:34:47.720
So, so yeah, power tools kind of gives you some, some nice validation.

00:34:47.720 --> 00:34:51.920
And yeah, you might just say like, okay, yeah, the body of this event, even though I,

00:34:51.920 --> 00:34:58.120
I don't care about all this other stuff, that they include the, the path headers,

00:34:58.120 --> 00:35:01.120
queer string parameters, but I just need like the body of this.

00:35:01.120 --> 00:35:06.700
So you just say, okay, event dot body, and you can even use, you can validate that further.

00:35:06.700 --> 00:35:10.160
The event body is going to be a Pydantic model that you created.

00:35:10.160 --> 00:35:12.520
So yeah, there's a lot of different pieces in here.

00:35:12.520 --> 00:35:17.260
If I was working on this and it didn't already have Pydantic models, I would take this and go

00:35:17.260 --> 00:35:19.080
to Jason Pydantic.

00:35:19.080 --> 00:35:21.240
Oh, I didn't even know this existed.

00:35:21.240 --> 00:35:21.940
That's where it's.

00:35:21.940 --> 00:35:22.200
Okay.

00:35:22.200 --> 00:35:22.720
Boom.

00:35:22.720 --> 00:35:23.620
Put that right in there.

00:35:23.620 --> 00:35:25.560
And boom, there you go.

00:35:25.560 --> 00:35:30.420
It parses it onto a nested tree, object tree of, of the model.

00:35:30.420 --> 00:35:30.860
Very nice.

00:35:30.860 --> 00:35:32.660
But if they already give it to you, they already give it to you.

00:35:32.660 --> 00:35:32.880
Yeah.

00:35:32.880 --> 00:35:33.200
Yeah.

00:35:33.200 --> 00:35:34.180
Just take what they give you.

00:35:34.460 --> 00:35:35.060
Yeah.

00:35:35.060 --> 00:35:38.780
Those specific events might be data classes instead of Pydantic.

00:35:38.780 --> 00:35:43.740
Um, just because you don't, that way you don't have to package Pydantic up in your Lambda.

00:35:43.740 --> 00:35:48.440
But, yeah, if you're already, figuring out a way to package power tools, you're, you're,

00:35:48.440 --> 00:35:51.200
you're, you're close enough that you probably just include Pydantic too.

00:35:51.340 --> 00:35:58.120
But yeah, yeah, it's, and they also, I think they just added this feature where

00:35:58.120 --> 00:36:02.180
it'll actually generate, open API schema for you.

00:36:02.180 --> 00:36:04.840
Uh, kind of, I think, yeah, fast, FastAPI does that as well.

00:36:04.840 --> 00:36:05.100
Right.

00:36:05.160 --> 00:36:10.860
So, yeah, so that's something you can leverage power tools to do now as well.

00:36:10.860 --> 00:36:11.520
Oh, excellent.

00:36:11.520 --> 00:36:15.940
And then you can actually take the open API schema and generate a Python client board on

00:36:15.940 --> 00:36:16.320
top of that.

00:36:16.320 --> 00:36:17.680
I think with, yeah, yeah.

00:36:17.680 --> 00:36:20.000
So you just say it's robots all the way down.

00:36:20.000 --> 00:36:20.620
Right.

00:36:20.620 --> 00:36:22.000
Turtles all the way down.

00:36:22.000 --> 00:36:22.320
Yeah.

00:36:22.320 --> 00:36:23.100
Yeah.

00:36:23.100 --> 00:36:23.880
Yeah.

00:36:23.880 --> 00:36:25.100
Um, yeah.

00:36:25.100 --> 00:36:30.060
I, I haven't used those open API generated clients, very much.

00:36:30.060 --> 00:36:32.860
I, I was always like skeptical of them, but, yeah.

00:36:32.860 --> 00:36:33.560
In theory.

00:36:34.120 --> 00:36:37.880
I just feel heartless or, you know, soulless, I guess the word looks more.

00:36:37.880 --> 00:36:42.500
And he's just like, okay, here's another star org, star, star KW orgs thing where it's like,

00:36:42.500 --> 00:36:46.200
couldn't you just like write it, make some reasonable defaults and give me some keyword

00:36:46.200 --> 00:36:50.040
argue, you know, just like, yeah, but if it's better than nothing, you know, it's better than

00:36:50.040 --> 00:36:50.420
right.

00:36:50.420 --> 00:36:50.920
Yeah.

00:36:50.920 --> 00:36:51.300
Yeah.

00:36:51.300 --> 00:36:55.020
So, but yeah, you, you can see like power tools.

00:36:55.020 --> 00:36:59.540
They, they took a lot of influence from FastAPI and it does seem like it.

00:36:59.540 --> 00:37:00.060
Yeah, for sure.

00:37:00.060 --> 00:37:00.500
Yeah.

00:37:00.500 --> 00:37:00.940
Yeah.

00:37:00.940 --> 00:37:03.080
Oh, it's, it's definitely really powerful.

00:37:03.080 --> 00:37:05.300
And you get some of those same benefits.

00:37:05.300 --> 00:37:05.800
Yeah.

00:37:05.800 --> 00:37:06.440
This is new to me.

00:37:06.440 --> 00:37:07.520
It looks, it looks quite nice.

00:37:07.520 --> 00:37:12.960
So, another comment by Kim is tended to use serverless functions for either things that

00:37:12.960 --> 00:37:17.800
run briefly, like once a month on a schedule or the code that processes stuff coming in on

00:37:17.800 --> 00:37:23.220
an AWS SQS simple queuing service queue of unknown schedule.

00:37:23.420 --> 00:37:29.080
So maybe that's an interesting segue into how do you call your serverless code?

00:37:29.080 --> 00:37:29.700
Yeah.

00:37:29.700 --> 00:37:30.040
Yeah.

00:37:30.040 --> 00:37:34.940
So, as we kind of touched on, there's a lot of different ways from like, you know,

00:37:34.940 --> 00:37:36.580
AWS for instance, to do it.

00:37:36.580 --> 00:37:43.660
So, yeah, like AWS Lambda has like Lambda function URLs, but I haven't used those as much,

00:37:43.660 --> 00:37:47.580
but if you just look at like the different options and, and like power tools, for instance,

00:37:47.580 --> 00:37:53.680
you can, you can have a, a load balancer that's gonna, where you set the endpoint to invoke

00:37:53.680 --> 00:37:59.280
a Lambda, you can have, API gateway, which is another service they have.

00:37:59.280 --> 00:38:02.460
Um, so there's a lot of different ways.

00:38:02.460 --> 00:38:02.700
Yeah.

00:38:02.700 --> 00:38:10.420
So, that's kind of almost getting into like a way of like streaming or an asynchronous

00:38:10.420 --> 00:38:11.940
way of processing data.

00:38:11.940 --> 00:38:17.600
So, yeah, maybe, in AWS, you're using a queue, right?

00:38:17.600 --> 00:38:22.380
That's, filling up and you say like, okay, yeah, every time this queue is at this size or,

00:38:22.380 --> 00:38:27.280
or this timeframe, invoke this Lambda and process all these messages.

00:38:27.280 --> 00:38:33.840
So there's a lot of different ways to, to, to invoke a Lambda function.

00:38:33.840 --> 00:38:40.140
So, if it's, I mean, really as simple as, you can invoke them like from the AWS CLI

00:38:40.140 --> 00:38:44.480
or, but yeah, most people are probably have some kind of API around it.

00:38:44.480 --> 00:38:44.880
Yeah.

00:38:44.880 --> 00:38:45.340
Yeah.

00:38:45.340 --> 00:38:47.900
Almost make them look like just HTTP endpoints.

00:38:47.900 --> 00:38:48.500
Right.

00:38:48.500 --> 00:38:48.900
Yeah.

00:38:48.900 --> 00:38:49.420
Yeah.

00:38:49.420 --> 00:38:53.400
Mark out there says not heard talk of ECS.

00:38:53.400 --> 00:38:59.640
I don't think, but I've been running web services using Fargate serverless tasks on ECS for years

00:38:59.640 --> 00:38:59.980
now.

00:38:59.980 --> 00:39:01.060
Are you familiar with this?

00:39:01.060 --> 00:39:01.620
I haven't done it.

00:39:01.620 --> 00:39:08.640
Uh, I, yeah, I, I'm like vaguely familiar with it, but yeah, this is like a, a serverless,

00:39:08.640 --> 00:39:08.840
yeah.

00:39:08.840 --> 00:39:10.740
Serverless compute for containers.

00:39:10.740 --> 00:39:18.340
So, I haven't used this personally, but yeah, very like similar concept where it

00:39:18.340 --> 00:39:22.940
kind of scales up for you and, yeah, you don't have to have things running all

00:39:22.940 --> 00:39:25.300
the time, but yeah, it can be dockerized applications.

00:39:25.300 --> 00:39:29.900
Um, yeah, in fact, the company I work for now, they do this with their Ruby on rails applications.

00:39:29.900 --> 00:39:34.100
They, they dockerize them and run, with, with Fargate.

00:39:34.100 --> 00:39:41.460
Uh, so, Docker creating Docker containers of these things, the less familiar you are with

00:39:41.460 --> 00:39:44.360
running that tech stack, the better it is in Docker.

00:39:44.360 --> 00:39:44.980
You know what I mean?

00:39:45.240 --> 00:39:45.520
Yeah.

00:39:45.520 --> 00:39:46.000
Yeah.

00:39:46.000 --> 00:39:50.540
Like I, I could run straight Python, but if it's Ruby on rails or PHP, maybe it's going

00:39:50.540 --> 00:39:53.400
into a container that would make me feel a little bit better about it.

00:39:53.400 --> 00:39:53.880
Yeah.

00:39:53.880 --> 00:39:58.200
Especially if you're in that workflow of like handing something over to a DevOps team, right?

00:39:58.200 --> 00:40:02.960
Like you, you can say like, here, here's an image or a container or Docker file that,

00:40:02.960 --> 00:40:04.400
you know, that will work for you.

00:40:04.400 --> 00:40:10.520
You know, that's maybe a little bit easier than, trying to explain how to set up an environment

00:40:10.520 --> 00:40:10.980
or something.

00:40:10.980 --> 00:40:11.680
So, yeah.

00:40:11.680 --> 00:40:12.220
Yeah.

00:40:12.220 --> 00:40:12.620
Yeah.

00:40:12.700 --> 00:40:15.220
Fargate's a really good serverless option too.

00:40:15.220 --> 00:40:16.120
Excellent.

00:40:16.120 --> 00:40:17.420
What about performance?

00:40:17.420 --> 00:40:23.260
You know, you talked about having like a whole API apps, like FastAPI or flask or whatever.

00:40:23.260 --> 00:40:23.940
Yeah.

00:40:23.940 --> 00:40:27.720
Start up those apps can be somewhat, can be non-trivial basically.

00:40:27.720 --> 00:40:31.400
And so then on the other side, we've got databases and stuff.

00:40:31.400 --> 00:40:36.360
And one of the bits of magic of databases is the connection pooling that happens, right?

00:40:36.360 --> 00:40:40.700
So the first connection might take 500 milliseconds, but the next one takes one.

00:40:40.700 --> 00:40:42.800
It's already open effectively, right?

00:40:42.800 --> 00:40:43.380
Yeah.

00:40:43.380 --> 00:40:43.760
Yeah.

00:40:43.940 --> 00:40:48.740
That's definitely something you really have to take into consideration is like how, how

00:40:48.740 --> 00:40:49.180
much you can do.

00:40:49.180 --> 00:40:53.380
That's where some, some of that like observability, some of like the, the tracing that you can do

00:40:53.380 --> 00:40:55.660
and profiling is, is really powerful.

00:40:56.320 --> 00:40:57.480
Yeah.

00:40:57.480 --> 00:40:57.620
Yeah.

00:40:57.620 --> 00:41:02.960
AWS Lambda, for instance, they have, they have something called cold starts.

00:41:02.960 --> 00:41:05.540
So like, yeah.

00:41:05.540 --> 00:41:12.460
So the first time like a Lambda gets invoked or maybe you have, you know, 10 Lambdas that

00:41:12.460 --> 00:41:17.240
get called at the same time, that's going to, you know, invoke 10 separate Lambda functions.

00:41:17.240 --> 00:41:19.900
So that's like great for the scale, right?

00:41:19.900 --> 00:41:26.620
That's really nice, but on a cold start, it's usually a little bit slower invocation because

00:41:26.620 --> 00:41:27.940
it has to initialize.

00:41:27.940 --> 00:41:33.720
Like I think what's happening, you know, behind the scenes is they're like, they're moving your

00:41:33.720 --> 00:41:34.480
code over.

00:41:34.480 --> 00:41:35.660
That's going to get executed.

00:41:35.660 --> 00:41:40.920
And anything that happens like outside of your handler function.

00:41:40.920 --> 00:41:46.500
So importing libraries sometimes you're establishing a database connection.

00:41:47.620 --> 00:41:52.240
Maybe you're, you know, loading some environment variables or, or some secrets.

00:41:52.240 --> 00:41:57.580
And so, yeah, there's definitely, performance is something to consider.

00:41:57.580 --> 00:42:01.860
Um, I, yeah, that's probably, you, you mentioned rust.

00:42:01.860 --> 00:42:06.760
Uh, yeah, there's probably some more performant, like run times for some of these serverless functions.

00:42:06.760 --> 00:42:14.720
So, I've even heard some people say, okay, for, for like client facing things, we're, we're

00:42:14.720 --> 00:42:15.840
not going to use serverless.

00:42:15.840 --> 00:42:17.200
Like we just want that performance.

00:42:17.200 --> 00:42:21.960
So, so that cold start definitely can, that can have an impact on you.

00:42:21.960 --> 00:42:23.100
Yeah.

00:42:23.100 --> 00:42:23.660
Yeah.

00:42:23.660 --> 00:42:28.440
On both ends that I've pointed out, like the app start, but also the, the service, the database

00:42:28.440 --> 00:42:29.560
stuff with like the connection.

00:42:29.560 --> 00:42:29.940
Right.

00:42:29.940 --> 00:42:30.340
Yeah.

00:42:30.340 --> 00:42:31.300
So yeah.

00:42:31.300 --> 00:42:32.500
Relational databases too.

00:42:32.500 --> 00:42:34.100
That's an interesting thing.

00:42:34.100 --> 00:42:34.920
Uh, with, yeah.

00:42:34.920 --> 00:42:35.540
What do you guys do?

00:42:35.540 --> 00:42:36.920
You mentioned Dynamo already.

00:42:36.920 --> 00:42:37.580
Yeah.

00:42:37.660 --> 00:42:41.880
So Dynamo really performant for, a lot of connections.

00:42:41.880 --> 00:42:42.220
Right.

00:42:42.220 --> 00:42:47.580
But a, so Dynamo is a, you know, serverless database that can, that can scale.

00:42:47.580 --> 00:42:52.960
You can query it over and over and that's not going to, it doesn't reuse a connection

00:42:52.960 --> 00:42:56.020
in the same way that like a SQL database would.

00:42:56.780 --> 00:43:02.420
Um, so that's, that's an excellent option, but if you do have to connect to a relational

00:43:02.420 --> 00:43:09.760
database and you have a lot of invocations, you can, you can use a, like a proxy,

00:43:09.760 --> 00:43:11.260
if, if you're all in on AWS.

00:43:11.260 --> 00:43:16.100
And so again, sorry for this is really AWS heavy, but, but if you're using their like

00:43:16.100 --> 00:43:22.600
relational database service, RDS, you can use RDS proxy, which will use like a pool of connections

00:43:22.600 --> 00:43:24.240
for your Lambda function.

00:43:24.240 --> 00:43:25.920
Oh, that can, yeah.

00:43:25.920 --> 00:43:33.120
That can give you a lot of, performance or, at least you won't be, you know, running

00:43:33.120 --> 00:43:34.580
out of connections to your database.

00:43:34.580 --> 00:43:39.260
So, another thing too, is just how you structure that connection.

00:43:39.260 --> 00:43:43.880
So, I mentioned cold Lambdas, you obviously have warm Lambdas too.

00:43:43.880 --> 00:43:47.500
So, a Lambda has its, its handler function.

00:43:47.500 --> 00:43:52.980
And so anything outside of the handler function can get reused on a, on a, on a warm Lambda.

00:43:52.980 --> 00:43:58.180
So you can establish the connection to a database and it'll get reused on every invocation that

00:43:58.180 --> 00:43:58.960
it, that it can.

00:43:58.960 --> 00:43:59.640
That's cool.

00:43:59.640 --> 00:44:02.340
Do you have to do anything explicit to make it do that?

00:44:02.340 --> 00:44:06.060
Or is that just, it just has to be outside of that handler function.

00:44:06.580 --> 00:44:10.460
So, you know, kind of at your, your top level of your, your file.

00:44:10.460 --> 00:44:10.800
So.

00:44:10.800 --> 00:44:11.340
Yeah.

00:44:11.340 --> 00:44:12.040
Excellent.

00:44:12.040 --> 00:44:12.280
Yeah.

00:44:12.280 --> 00:44:18.000
It makes me think almost one thing you would consider is like profiling the import statement

00:44:18.000 --> 00:44:18.480
almost.

00:44:18.480 --> 00:44:19.040
Right.

00:44:19.040 --> 00:44:24.800
And yeah, that's what we normally do, but there's a library called import profiler that actually

00:44:24.800 --> 00:44:27.820
lets you time how long different, different things take to import.

00:44:27.820 --> 00:44:33.960
It could take a while, especially if you come from, not from a native Python way of thinking

00:44:33.960 --> 00:44:40.900
in like C# or C++ or something you say hash include or using such and such

00:44:40.900 --> 00:44:44.020
like that's a compiler type thing that really has no cost.

00:44:44.020 --> 00:44:44.820
Yeah.

00:44:44.820 --> 00:44:46.220
There's code execution.

00:44:46.220 --> 00:44:49.480
And when you import something in Python and some of these can take a while, right?

00:44:49.480 --> 00:44:50.440
Yes.

00:44:50.440 --> 00:44:50.940
Yeah.

00:44:51.040 --> 00:44:53.260
So, there's a lot of tools for that.

00:44:53.260 --> 00:44:55.700
There's some, I think even maybe specific for Lambda.

00:44:55.700 --> 00:45:01.380
I don't like data dog has a profiler that gives you like this, I forget what the graphic

00:45:01.380 --> 00:45:03.820
is called, like a flame, a flame graph.

00:45:03.820 --> 00:45:04.100
Yeah.

00:45:04.100 --> 00:45:09.100
That'll give you like a flame graph and show like, okay, yeah, it took this long to,

00:45:09.100 --> 00:45:12.620
make your database connection this long to import Pydantic.

00:45:12.620 --> 00:45:19.740
And it took this long to, make a, a call to DynamoDB, you know, so you actually

00:45:19.740 --> 00:45:21.020
kind of like break that up.

00:45:21.020 --> 00:45:27.000
Uh, AWS has x-ray, I think, which does something similar to, so, yeah, it's definitely something

00:45:27.000 --> 00:45:27.640
to consider.

00:45:27.640 --> 00:45:34.700
Um, another, just what you're packaging, is definitely, something to, to watch

00:45:34.700 --> 00:45:35.020
for.

00:45:35.020 --> 00:45:42.960
And so, I mentioned, yeah, I mentioned using pants to package Lambdas and they, they

00:45:42.960 --> 00:45:48.080
do, hopefully I don't butcher how this works behind the scenes, but, they're using,

00:45:48.080 --> 00:45:52.800
they're using Rust and they'll actually kind of like infer your dependencies for you.

00:45:52.800 --> 00:45:58.020
And so they have a, an integration with AWS Lambda.

00:45:58.020 --> 00:46:00.560
They also have it for Google cloud function.

00:46:00.560 --> 00:46:02.240
So yeah, it'll go through.

00:46:02.320 --> 00:46:05.400
You say, here's like my, AWS Lambda function.

00:46:05.400 --> 00:46:09.660
This is the, the file for it and the function that needs to be called.

00:46:09.660 --> 00:46:15.400
And it's going to create a zip file for you, that has your, your Lambda code in it.

00:46:15.400 --> 00:46:17.580
And it's going to find all those dependencies you need.

00:46:17.580 --> 00:46:23.140
So it'll actually, you know, by default, it's going to include like, you know, Bodo that you

00:46:23.140 --> 00:46:23.520
need.

00:46:23.520 --> 00:46:30.220
If, if you're using Bodo, it'll, if you're going to use, you know, pie, my SQL or whatever

00:46:30.220 --> 00:46:34.500
library, it's going to pull all those in and zip that up for you.

00:46:34.500 --> 00:46:40.120
And so if you just like open up that zip and you see, and especially if you're,

00:46:40.120 --> 00:46:45.040
sharing code across your code base, maybe you have a shared function to, to make some of these

00:46:45.040 --> 00:46:46.360
database connections or calls.

00:46:46.360 --> 00:46:50.520
Like, you, you see everything that's going to go in there.

00:46:50.580 --> 00:46:52.620
And so, yeah.

00:46:52.620 --> 00:46:55.260
And so how, how like pants does it is it's, it's file-based.

00:46:55.260 --> 00:47:00.080
So, sometimes just for like ease of imports, you might throw a lot of stuff in like your,

00:47:00.080 --> 00:47:03.820
um, your init.py file and say like, okay, yeah.

00:47:03.820 --> 00:47:08.860
From, you know, you add all kind of bubble up all your things that you want to import in

00:47:08.860 --> 00:47:09.120
there.

00:47:09.120 --> 00:47:17.920
Um, well, if one of those imports, is also using, open CV and you don't need

00:47:17.920 --> 00:47:21.580
that, then pants is going to say like, oh, he's importing this.

00:47:21.580 --> 00:47:27.620
And because it's file-based now this Lambda needs open CV, which is a, you know, massive

00:47:27.620 --> 00:47:28.140
package.

00:47:28.140 --> 00:47:33.760
That's going to, it's going to impact your, your performance, especially in those cold

00:47:33.760 --> 00:47:36.940
starts because that, that code has to be moved over.

00:47:36.940 --> 00:47:38.780
So yeah, that's, that's pretty interesting.

00:47:38.780 --> 00:47:45.360
So kind of an alternative to saying, here's my requirements or my pyproject.toml, my lock

00:47:45.360 --> 00:47:48.980
file or whatever, that just lists everything the entire program might use.

00:47:48.980 --> 00:47:51.100
This could say, you're going to import this function.

00:47:51.100 --> 00:47:54.140
And to do that, it imports these things, which import those things.

00:47:54.140 --> 00:47:57.080
And then, and then it just says, okay, that means here's what you need.

00:47:57.080 --> 00:47:57.520
Right.

00:47:57.520 --> 00:47:57.960
Right.

00:47:57.960 --> 00:47:58.460
Yeah.

00:47:58.460 --> 00:47:59.080
Yeah.

00:47:59.080 --> 00:48:03.740
It's definitely one of like the best ways that I found to, to package up,

00:48:03.740 --> 00:48:04.480
Lambda functions.

00:48:04.480 --> 00:48:08.500
I think some of the other tooling might do some of this too, but yeah, a lot of times

00:48:08.500 --> 00:48:13.840
it, it would require like requirements that TXT, but if you have like a large code

00:48:13.840 --> 00:48:19.920
base to where maybe you do have this, this shared, you know, module for, that, you

00:48:19.920 --> 00:48:23.320
know, maybe you have, you know, 30 different Lambda functions that are all going to use

00:48:23.320 --> 00:48:24.800
some kind of helper function.

00:48:24.800 --> 00:48:27.040
It's just going to go in, like grab that.

00:48:27.040 --> 00:48:30.660
And it doesn't have to be like pip installable pants is smart enough to just be like, okay,

00:48:30.660 --> 00:48:31.720
it needs this code.

00:48:31.720 --> 00:48:33.600
And so, but yeah.

00:48:33.720 --> 00:48:34.600
You definitely have to be careful.

00:48:34.600 --> 00:48:35.080
Yeah.

00:48:35.080 --> 00:48:35.820
Yeah.

00:48:35.820 --> 00:48:39.100
And then there's so many other cool things that, that pants is doing that, you know,

00:48:39.100 --> 00:48:43.740
they have some, really nice stuff for testing and, linting and formatting.

00:48:43.740 --> 00:48:48.080
And it's, yeah, there's a lot of really good stuff that they're doing.

00:48:48.400 --> 00:48:49.300
Yeah.

00:48:49.300 --> 00:48:51.980
I had Benji on the show to talk about pants.

00:48:51.980 --> 00:48:52.780
That was, that was fun.

00:48:52.780 --> 00:48:53.400
Yeah.

00:48:53.400 --> 00:48:55.620
So let me go back to this picture.

00:48:55.620 --> 00:48:56.520
Is this the picture?

00:48:56.520 --> 00:48:59.760
I have a lot of things open on my screen now there.

00:49:00.160 --> 00:49:05.440
So on my server setup that I described, which is a bunch of Docker containers running on one

00:49:05.440 --> 00:49:06.080
big machine.

00:49:06.080 --> 00:49:11.440
I can go in there and I can say, tail this log and see all the traffic to all the different

00:49:11.440 --> 00:49:11.940
containers.

00:49:11.940 --> 00:49:17.420
I can tell another log and just see like the logging log book, log guru, whatever output

00:49:17.420 --> 00:49:19.040
of that, or just the web traffic.

00:49:19.120 --> 00:49:22.520
Like there's different ways to just go, I'm just going to sit back and look at it for

00:49:22.520 --> 00:49:24.360
a minute to make sure it's chilling.

00:49:24.360 --> 00:49:24.820
Right.

00:49:24.820 --> 00:49:28.940
If everything's so transient, not so easy in the same way.

00:49:28.940 --> 00:49:29.560
So what do you do?

00:49:29.560 --> 00:49:30.520
Yeah.

00:49:30.520 --> 00:49:37.120
So, yeah, power tools does, they have their, their structured logger that helps a lot, but

00:49:37.120 --> 00:49:39.420
yeah, you have to kind of like aggregate these logs somewhere.

00:49:39.420 --> 00:49:39.800
Right.

00:49:39.800 --> 00:49:44.760
Because yeah, you can't, you know, a Lambda function, you can't like SSH into.

00:49:44.760 --> 00:49:45.060
Right.

00:49:45.060 --> 00:49:47.400
So, yeah, you can't have to make too long.

00:49:47.400 --> 00:49:48.540
Yeah.

00:49:48.540 --> 00:49:48.900
Yeah.

00:49:48.900 --> 00:49:54.240
Um, so yeah, you, you need to have some way to aggregate these.

00:49:54.240 --> 00:50:00.320
So like AWS has cloud watch where, that will like by default kind of log all of your

00:50:00.320 --> 00:50:00.980
standard out.

00:50:00.980 --> 00:50:06.960
So even like a print statement would go to, cloud watch, just by, by default.

00:50:06.960 --> 00:50:11.720
Um, but you probably want to like structure these better with, most likely in, in, you

00:50:11.720 --> 00:50:16.900
know, JSON format, just most tooling around those is going to help you.

00:50:16.900 --> 00:50:20.960
So, yeah, the power tool structured logger is, is really good.

00:50:20.960 --> 00:50:26.500
And you can, you can, even like you can have like a single log statement, but you can

00:50:26.500 --> 00:50:28.140
append different keys to it.

00:50:28.140 --> 00:50:31.200
And, it's, it's pretty powerful.

00:50:31.200 --> 00:50:36.160
Um, especially cause you, you don't want to like, I think like, so if you just like

00:50:36.160 --> 00:50:40.100
printed something in a Lambda function, for instance, that's going to be like a different

00:50:40.100 --> 00:50:46.820
row on each of your, like, by like the default cloud watch, like it'll be, I, how

00:50:46.820 --> 00:50:50.660
it breaks it up is really odd unless you have some kind of structure to them.

00:50:50.660 --> 00:50:51.140
Okay.

00:50:51.140 --> 00:50:54.700
And so, yeah, so definitely something to, to consider.

00:50:54.700 --> 00:51:00.360
Um, something else you can do is, yeah, there's, there's metrics you can do.

00:51:00.600 --> 00:51:04.660
Uh, so like how it works with like cloud watch, they have a specific format.

00:51:04.660 --> 00:51:11.100
And if you use that format, you can, it'll automatically pull that in as a metric

00:51:11.100 --> 00:51:15.700
and like data dog has something, similar where you can actually kind of like go in there.

00:51:15.700 --> 00:51:20.380
You can look at your logs and say, like, find a value and be like, I want this to be a metric

00:51:20.380 --> 00:51:20.740
now.

00:51:20.740 --> 00:51:23.300
And so that's really powerful.

00:51:23.300 --> 00:51:24.980
Oh, the metric sounds cool.

00:51:24.980 --> 00:51:27.500
So I see logging and racing.

00:51:27.500 --> 00:51:29.560
What's the difference between those things?

00:51:29.560 --> 00:51:33.460
Like tracing as a level and just a high level of logging.

00:51:33.460 --> 00:51:34.820
Yeah.

00:51:34.820 --> 00:51:40.540
Tracing, and hopefully I do do the justice, differentiating too.

00:51:40.540 --> 00:51:45.120
Um, I, I feel like tracing does have a lot more to do with your, your performance

00:51:45.120 --> 00:51:49.320
or, maybe even closer to like tracking some of these metrics.

00:51:49.320 --> 00:51:49.640
Right.

00:51:49.640 --> 00:51:55.640
Um, I've used the, the data dog tracer a lot.

00:51:55.640 --> 00:52:01.600
Uh, and I've used the AWS, like X-ray, they're tracing utility a little bit too.

00:52:01.600 --> 00:52:04.520
And so like those might, those will show you.

00:52:04.520 --> 00:52:08.200
So like, maybe you are reaching out to a database, writing to S3.

00:52:08.200 --> 00:52:14.300
APM, application performance monitoring, where it says, yes, you spent this much time in a

00:52:14.300 --> 00:52:17.120
SQL query in this much time in.

00:52:17.120 --> 00:52:17.960
Identic serialization.

00:52:17.960 --> 00:52:22.180
Whereas the login would say a user has been sent a message.

00:52:22.180 --> 00:52:23.040
Right.

00:52:23.040 --> 00:52:23.620
Exactly.

00:52:23.620 --> 00:52:24.120
Yeah.

00:52:24.120 --> 00:52:24.380
Yeah.

00:52:24.380 --> 00:52:24.900
Yep.

00:52:24.900 --> 00:52:28.360
Tracing definitely is probably more around your, your performance and yeah.

00:52:28.360 --> 00:52:28.920
Things like that.

00:52:28.920 --> 00:52:29.220
I see.

00:52:29.220 --> 00:52:31.280
It's kind of insane that they can do that.

00:52:31.280 --> 00:52:36.040
You know, you, you, you see it in the Django debug tool bar and the pyramid debug tool bar,

00:52:36.040 --> 00:52:38.640
but they'll be like, here's your code and here's all your SQL queries.

00:52:38.640 --> 00:52:39.720
And here's how long they took.

00:52:39.720 --> 00:52:42.180
And you're just like, wow, that thing is reaching deep down in there.

00:52:42.180 --> 00:52:48.540
You know, the, the data dog one is very interesting because like it, it just knows like that this

00:52:48.540 --> 00:52:51.280
is a SQL connection and it tells you like, oh, okay.

00:52:51.280 --> 00:52:52.940
This SQL connection took this long.

00:52:52.940 --> 00:52:55.440
And it was like, I didn't tell it to even trace that.

00:52:55.440 --> 00:52:58.600
Like it just like, it, it knows really well.

00:52:58.600 --> 00:52:58.840
Yeah.

00:52:58.840 --> 00:53:04.420
So like the connections open is another to say, and here's what it sent over SSL, by the way.

00:53:04.420 --> 00:53:05.500
How'd you get in there?

00:53:05.500 --> 00:53:06.320
Yeah.

00:53:06.320 --> 00:53:06.720
Yeah.

00:53:06.720 --> 00:53:08.960
So it's in process.

00:53:08.960 --> 00:53:09.840
So it can do a lot.

00:53:09.840 --> 00:53:12.320
It is impressive to see those things that work.

00:53:12.320 --> 00:53:12.540
All right.

00:53:12.540 --> 00:53:14.380
So that's probably what the tracing is about, right?

00:53:14.380 --> 00:53:15.180
Yes.

00:53:15.180 --> 00:53:15.460
Yeah.

00:53:15.460 --> 00:53:15.700
Yeah.

00:53:15.700 --> 00:53:16.200
Definitely.

00:53:16.200 --> 00:53:17.680
Probably more around performance.

00:53:17.680 --> 00:53:20.300
You can put some different things in tracing too.

00:53:20.580 --> 00:53:25.680
Like I've, I've used it to say, like we talked about those like database connections to say

00:53:25.680 --> 00:53:29.300
like, oh yeah, I, this is a, this is reusing a connection here.

00:53:29.300 --> 00:53:33.560
Cause I was, I was trying to like debug some stuff on, am I creating a connection too many

00:53:33.560 --> 00:53:33.860
times?

00:53:33.860 --> 00:53:38.260
So I don't want to be, so yeah, you can, you can put some other useful things in tracing

00:53:38.260 --> 00:53:38.780
as well.

00:53:38.780 --> 00:53:39.440
But yeah.

00:53:39.440 --> 00:53:40.780
And pat out the audience.

00:53:40.780 --> 00:53:41.120
Oops.

00:53:41.120 --> 00:53:41.920
Move around.

00:53:41.920 --> 00:53:46.660
When you're using many microservices, like single execution involves many services.

00:53:46.660 --> 00:53:50.520
Basically it's hard to follow the logs between the services and tracing helps.

00:53:50.520 --> 00:53:51.360
Tie that together.

00:53:51.360 --> 00:53:52.200
Yeah.

00:53:52.200 --> 00:53:52.600
Yeah.

00:53:52.600 --> 00:53:53.180
That's for sure.

00:53:53.180 --> 00:53:54.040
All right.

00:53:54.040 --> 00:53:59.180
Let's close this out, Tony, with one more thing that I'm not sure how constructive it

00:53:59.180 --> 00:53:59.480
can be.

00:53:59.480 --> 00:54:02.320
There probably is some ways, but testing, right?

00:54:02.320 --> 00:54:02.660
Yeah.

00:54:02.660 --> 00:54:03.580
Yeah.

00:54:03.580 --> 00:54:05.540
That's definitely.

00:54:05.540 --> 00:54:09.980
If you could set up your own Lambda cluster, you might just run that for yourself.

00:54:09.980 --> 00:54:10.260
Right.

00:54:10.260 --> 00:54:11.760
So yeah.

00:54:11.760 --> 00:54:12.520
How do you do this?

00:54:12.520 --> 00:54:12.720
Right.

00:54:12.720 --> 00:54:13.100
Yeah.

00:54:13.100 --> 00:54:17.740
To some extent you can write like, like there's, there's a Lambda Docker image that you could run

00:54:17.740 --> 00:54:19.740
locally and you can do that.

00:54:19.800 --> 00:54:24.560
But if, if your Lambda is reaching out to DynamoDB, I guess there's, there's technically

00:54:24.560 --> 00:54:27.200
a DynamoDB container as well.

00:54:27.200 --> 00:54:32.440
Like, like you could, it's a lot of overhead to set this up, but rather than just doing like,

00:54:32.440 --> 00:54:37.980
you know, flask start or, you know, whatever the, the command is to like spin

00:54:37.980 --> 00:54:38.420
up a flask.

00:54:38.420 --> 00:54:40.680
I pressed the go button in my IDE and now it's.

00:54:41.480 --> 00:54:41.920
Yeah.

00:54:41.920 --> 00:54:42.040
Yeah.

00:54:42.040 --> 00:54:42.480
Yeah.

00:54:42.480 --> 00:54:47.540
So that's definitely, and there's more and more tooling coming out, you know,

00:54:47.540 --> 00:54:49.600
that's, that's coming out for this kind of stuff.

00:54:49.600 --> 00:54:55.600
But, if you can like unit tests, there's no reason you can't just like, you know,

00:54:55.600 --> 00:54:58.520
run, run unit tests, locally.

00:54:58.520 --> 00:55:03.700
But when you start getting into the integration test, you're probably getting to the point where

00:55:03.700 --> 00:55:07.800
maybe you just deploy to actual services.

00:55:08.060 --> 00:55:11.440
Um, and you know, it's, it's always trade-offs, right?

00:55:11.440 --> 00:55:13.820
Like there's, there's costs associated with it.

00:55:13.820 --> 00:55:19.300
There's the overhead of like, okay, how can I deploy to an isolated environment, but maybe

00:55:19.300 --> 00:55:20.960
it interacts with another microservice.

00:55:20.960 --> 00:55:25.880
So, yeah, so there's, there's definitely trade-offs, but.

00:55:25.880 --> 00:55:31.900
I can see that you might come up with, like a QA environment, almost like a mirror image

00:55:31.900 --> 00:55:37.000
that doesn't share any data, but it's sufficiently close, but then you're running, I mean, that's

00:55:37.000 --> 00:55:41.080
a pretty big commitment because you're running a whole replica of whatever you have.

00:55:41.080 --> 00:55:41.780
Right.

00:55:41.780 --> 00:55:42.280
Yeah.

00:55:42.280 --> 00:55:45.200
And so, yeah, QA environments are great.

00:55:45.200 --> 00:55:48.600
Um, but you might even want lower than QA.

00:55:48.600 --> 00:55:56.500
You might want to have a, dev or like a, one place I worked at, we would

00:55:56.500 --> 00:55:59.000
spin up an entire environment for every PR.

00:55:59.000 --> 00:56:05.380
So, you could actually, yeah, like when you created a PR, that environment got spun

00:56:05.380 --> 00:56:10.380
up and it ran your integration tests and system tests against that environment, which, you

00:56:10.380 --> 00:56:15.620
know, simulated, your prod environment a little bit better than running locally on your

00:56:15.620 --> 00:56:16.100
machine.

00:56:16.100 --> 00:56:20.860
So, certainly a challenge, to, to test this.

00:56:20.860 --> 00:56:21.960
And yeah.

00:56:21.960 --> 00:56:24.440
And there's always these like one-off things too.

00:56:24.440 --> 00:56:24.760
Right.

00:56:24.760 --> 00:56:30.740
Like, you can't really simulate like that memory limitation of a Lambda locally,

00:56:30.740 --> 00:56:33.580
you know, as much as when you deploy it and things like that.

00:56:33.580 --> 00:56:33.800
So.

00:56:33.800 --> 00:56:34.280
Yeah.

00:56:34.280 --> 00:56:34.840
Yeah.

00:56:34.840 --> 00:56:36.680
That would be much, much harder.

00:56:36.680 --> 00:56:40.940
I, maybe you could run a Docker container and put a memory limit on it.

00:56:40.940 --> 00:56:41.980
You know, that might work.

00:56:41.980 --> 00:56:42.200
Yeah.

00:56:42.200 --> 00:56:42.620
Yeah.

00:56:42.620 --> 00:56:46.540
Maybe you're back into like more and more DevOps to avoid DevOps.

00:56:46.540 --> 00:56:46.980
Right.

00:56:46.980 --> 00:56:47.600
Yeah.

00:56:47.600 --> 00:56:48.560
Yeah.

00:56:48.560 --> 00:56:49.780
So there it goes.

00:56:49.780 --> 00:56:50.820
But interesting.

00:56:50.820 --> 00:56:51.380
All right.

00:56:51.380 --> 00:56:55.460
Well, anything else you want to add to this conversation before we wrap it up about out of

00:56:55.460 --> 00:56:55.920
time here?

00:56:55.920 --> 00:56:56.440
Yeah.

00:56:56.440 --> 00:56:58.600
I guess, I don't know if I have it.

00:56:58.600 --> 00:56:59.960
Hopefully we covered enough.

00:56:59.960 --> 00:57:01.900
Uh, there's just a lot of like good.

00:57:01.900 --> 00:57:02.680
Yeah.

00:57:02.680 --> 00:57:03.840
There's a lot of good resources.

00:57:03.840 --> 00:57:09.640
The, the tooling that I've mentioned, like power tools and pants, just amazing communities

00:57:09.640 --> 00:57:13.120
like power tools has a discord and go on there and ask for help.

00:57:13.120 --> 00:57:14.160
And they're super helpful.

00:57:14.160 --> 00:57:16.480
Uh, pants has a Slack channel.

00:57:16.480 --> 00:57:19.820
You can join their Slack and ask, you know, about things.

00:57:19.820 --> 00:57:24.120
And, and so those two communities have been really good and really helpful in this.

00:57:24.120 --> 00:57:27.280
A lot of good, talks that are available on YouTube too.

00:57:27.280 --> 00:57:31.440
So just, yeah, there's definitely resources out there and, that a lot of people have,

00:57:31.440 --> 00:57:32.940
you know, fought this for a while.

00:57:32.940 --> 00:57:34.560
So yeah, excellent.

00:57:34.560 --> 00:57:38.280
And you don't have to start from just create function and start typing.

00:57:38.280 --> 00:57:38.660
Yeah.

00:57:38.660 --> 00:57:39.040
Yeah.

00:57:39.040 --> 00:57:39.660
Cool.

00:57:39.660 --> 00:57:40.160
All right.

00:57:40.160 --> 00:57:45.680
Well, before you get out of here though, let's, let's get your recommendation for a PI PI package,

00:57:45.680 --> 00:57:47.640
something, something fun.

00:57:47.640 --> 00:57:53.440
Um, I probably, you know, we've talked a lot about it, but power tools is definitely one,

00:57:53.440 --> 00:57:56.900
uh, that is like every day getting used for me.

00:57:56.900 --> 00:58:00.020
So the, yeah, power tools for Lambda and Python,

00:58:00.200 --> 00:58:03.500
they actually support other, other, languages too.

00:58:03.500 --> 00:58:08.020
So they have like the same functionality for like, you know, no JS, you know, for like

00:58:08.020 --> 00:58:09.160
typescript and.net.

00:58:09.160 --> 00:58:17.900
And so, yeah, but this one definitely, leveraging power tools and, Pydantic together

00:58:17.900 --> 00:58:22.080
just really made like, serverless, a lot of fun to, to write.

00:58:22.080 --> 00:58:25.080
So, yeah, definitely doing great things there.

00:58:25.080 --> 00:58:25.680
Excellent.

00:58:25.680 --> 00:58:29.540
Well, I'll put all those things in the show notes and it's been great to talk to you.

00:58:29.540 --> 00:58:33.860
Thanks for sharing your journey down the serverless path.

00:58:33.860 --> 00:58:34.060
Yeah.

00:58:34.060 --> 00:58:34.580
Yep.

00:58:34.580 --> 00:58:34.840
Thanks.

00:58:34.840 --> 00:58:35.800
Thanks for having me.

00:58:35.800 --> 00:58:36.500
You bet.

00:58:36.500 --> 00:58:36.720
Yeah.

00:58:36.720 --> 00:58:37.440
Enjoy chatting.

00:58:37.440 --> 00:58:37.960
Same.

00:58:37.960 --> 00:58:38.200
Bye.

00:58:38.320 --> 00:58:38.520
That's it.

00:58:38.520 --> 00:58:42.540
This has been another episode of talk Python to me.

00:58:42.540 --> 00:58:44.340
Thank you to our sponsors.

00:58:44.340 --> 00:58:45.960
Be sure to check out what they're offering.

00:58:45.960 --> 00:58:47.400
It really helps support the show.

00:58:47.400 --> 00:58:49.580
Take some stress out of your life.

00:58:49.580 --> 00:58:55.020
Get notified immediately about errors and performance issues in your web or mobile applications with

00:58:55.020 --> 00:58:55.340
Sentry.

00:58:55.620 --> 00:59:01.820
Just visit talkpython.fm/sentry and get started for free and be sure to use the promo

00:59:01.820 --> 00:59:03.940
code talkpython, all one word.

00:59:03.940 --> 00:59:07.760
Mailtrap, an email delivery platform that developers love.

00:59:07.760 --> 00:59:11.000
Try for free at mailtrap.io.

00:59:11.000 --> 00:59:12.940
Want to level up your Python?

00:59:12.940 --> 00:59:17.000
We have one of the largest catalogs of Python video courses over at Talk Python.

00:59:17.000 --> 00:59:22.100
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:59:22.100 --> 00:59:24.760
And best of all, there's not a subscription in sight.

00:59:25.160 --> 00:59:27.680
Check it out for yourself at training.talkpython.fm.

00:59:27.680 --> 00:59:29.780
Be sure to subscribe to the show.

00:59:29.780 --> 00:59:32.560
Open your favorite podcast app and search for Python.

00:59:32.560 --> 00:59:33.860
We should be right at the top.

00:59:33.860 --> 00:59:39.040
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:59:39.040 --> 00:59:43.220
and the direct RSS feed at /rss on talkpython.fm.

00:59:43.220 --> 00:59:46.200
We're live streaming most of our recordings these days.

00:59:46.200 --> 00:59:49.600
If you want to be part of the show and have your comments featured on the air,

00:59:49.600 --> 00:59:54.040
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

00:59:54.700 --> 00:59:56.080
This is your host, Michael Kennedy.

00:59:56.080 --> 00:59:57.380
Thanks so much for listening.

00:59:57.380 --> 00:59:58.540
I really appreciate it.

00:59:58.540 --> 01:00:00.460
Now get out there and write some Python code.

01:00:00.460 --> 01:00:01.840
We'll see you next time.

01:00:01.840 --> 01:00:01.900
Bye.

01:00:01.900 --> 01:00:01.900
Bye.

01:00:01.900 --> 01:00:01.900
Bye.

01:00:01.900 --> 01:00:01.900
Bye.

01:00:01.900 --> 01:00:02.460
Bye.

01:00:02.460 --> 01:00:02.460
Bye.

01:00:02.460 --> 01:00:02.800
Bye.

01:00:02.800 --> 01:00:02.900
Bye.

01:00:02.900 --> 01:00:03.500
Bye.

01:00:03.500 --> 01:00:03.500
Bye.

01:00:03.500 --> 01:00:03.900
Bye.

01:00:03.900 --> 01:00:04.340
Bye.

01:00:04.340 --> 01:00:04.900
Bye.

01:00:04.900 --> 01:00:04.900
Bye.

01:00:04.900 --> 01:00:21.900
I'll see you next time.

