WEBVTT

00:00:00.001 --> 00:00:02.880
You're using Pydantic and it seems pretty straightforward, right?

00:00:02.880 --> 00:00:08.000
But could you adopt some simple changes to your code that would make it a lot faster and more efficient?

00:00:08.000 --> 00:00:12.740
Chances are you'll find a couple of the tips from Sidney Runkel that will do just that.

00:00:12.740 --> 00:00:16.640
Join us to talk about Pydantic performance tips here on Talk Python.

00:00:16.640 --> 00:00:21.640
Episode 466 recorded June 13th, 2024.

00:00:21.640 --> 00:00:34.840
[music]

00:00:34.840 --> 00:00:38.240
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:38.240 --> 00:00:40.040
This is your host, Michael Kennedy.

00:00:40.040 --> 00:00:45.080
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:00:45.080 --> 00:00:47.640
both on fosstodon.org.

00:00:47.640 --> 00:00:52.880
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:52.880 --> 00:00:56.380
We've started streaming most of our episodes live on YouTube.

00:00:56.380 --> 00:01:00.040
Subscribe to our YouTube channel over at talkpython.fm/youtube

00:01:00.040 --> 00:01:04.380
to get notified about upcoming shows and be part of that episode.

00:01:04.380 --> 00:01:06.380
This episode is brought to you by Sentry.

00:01:06.380 --> 00:01:07.940
Don't let those errors go unnoticed.

00:01:07.940 --> 00:01:10.040
Use Sentry like we do here at Talk Python.

00:01:10.040 --> 00:01:13.380
Sign up at talkpython.fm/sentry.

00:01:13.380 --> 00:01:17.440
And it's brought to you by Code Comments, an original podcast from Red Hat.

00:01:17.440 --> 00:01:22.540
This podcast covers stories from technologists who've been through tough tech transitions

00:01:22.540 --> 00:01:26.140
and share how their teams survived the journey.

00:01:26.140 --> 00:01:32.640
Episodes are available everywhere you listen to your podcast and at talkpython.fm/code-comments.

00:01:32.640 --> 00:01:35.440
Hey, folks, I got something pretty excellent for you.

00:01:35.440 --> 00:01:38.780
PyCharm Professional for six months for free.

00:01:38.780 --> 00:01:44.380
Over at Talk Python, we partnered with the JetBrains team to get all of our registered users

00:01:44.380 --> 00:01:47.480
free access to PyCharm Pro for six months.

00:01:47.480 --> 00:01:49.680
All you have to do is take one of our courses.

00:01:49.680 --> 00:01:50.440
That's it.

00:01:50.440 --> 00:01:53.880
However, do note that this is not valid for renewals over at JetBrains.

00:01:53.880 --> 00:01:55.840
Only new users there.

00:01:55.840 --> 00:02:00.180
And if you're not currently a registered user at Talk Python, well, no problem.

00:02:00.180 --> 00:02:02.680
This offer comes with all of our courses.

00:02:02.680 --> 00:02:07.140
So even if you just sign up for one of our free courses at talkpython.fm,

00:02:07.140 --> 00:02:09.680
click on Courses in the menu, you're in.

00:02:09.680 --> 00:02:10.780
So how do you redeem it?

00:02:10.780 --> 00:02:12.740
Once you have an account over at Talk Python,

00:02:12.740 --> 00:02:14.080
then it's super easy.

00:02:14.080 --> 00:02:17.140
Just visit your account page on Talk Python Training.

00:02:17.140 --> 00:02:22.200
And in the Details tab, you'll have a code and a link to redeem your six months of PyCharm Pro.

00:02:22.200 --> 00:02:28.040
So why not take a course, even a free one, and get six months free of PyCharm?

00:02:28.040 --> 00:02:30.540
Sydney, welcome back to Talk Python.

00:02:30.540 --> 00:02:31.780
It's awesome to have you here.

00:02:31.780 --> 00:02:32.180
Thank you.

00:02:32.180 --> 00:02:33.240
I'm super excited to be here.

00:02:33.240 --> 00:02:34.880
And yeah, I'm excited for our chat.

00:02:34.880 --> 00:02:35.600
I am too.

00:02:35.600 --> 00:02:41.800
We're going to talk about Pydantic, one of my very favorite libraries that just makes working with Python data,

00:02:41.800 --> 00:02:45.480
data exchange so, so easy, which is awesome.

00:02:45.480 --> 00:02:49.440
And it's really cool that you're on the Pydantic team these days.

00:02:49.440 --> 00:02:52.440
More than I guess, you know, let's jump back just a little bit.

00:02:52.440 --> 00:02:57.780
A few weeks ago, got to meet up a little bit in Pittsburgh at PyCon.

00:02:57.780 --> 00:02:58.840
How was PyCon for you?

00:02:58.840 --> 00:02:59.880
It was great.

00:02:59.880 --> 00:03:02.500
So it was my first PyCon experience ever.

00:03:02.500 --> 00:03:03.880
It was a very, very large conference.

00:03:03.880 --> 00:03:08.040
So it was a cool kind of first introductory conference experience.

00:03:08.040 --> 00:03:10.040
I had just graduated not even a week before.

00:03:10.040 --> 00:03:16.340
So it was a fun way to kind of roll into full-time work and get exposed really to the Python community.

00:03:16.340 --> 00:03:22.680
And it was great to just kind of have a mix of getting to give a talk, getting to attend lots of awesome presentations,

00:03:22.680 --> 00:03:26.280
and then most of all, just like meeting a bunch of really awesome people in the community.

00:03:26.280 --> 00:03:27.040
Yeah.

00:03:27.040 --> 00:03:33.880
I always love how many people you get to meet from so many different places and perspectives.

00:03:33.880 --> 00:03:38.480
And it just reminds you, the world is really big, but also really small.

00:03:38.480 --> 00:03:41.940
You know, get to meet your friends and new people from all over the place.

00:03:41.940 --> 00:03:42.380
Definitely.

00:03:42.380 --> 00:03:45.080
I was impressed by the number of international attendees.

00:03:45.080 --> 00:03:46.240
I didn't really expect that.

00:03:46.240 --> 00:03:46.880
It was great.

00:03:46.880 --> 00:03:47.180
Yeah.

00:03:47.180 --> 00:03:48.180
Same here.

00:03:48.180 --> 00:03:48.640
All right.

00:03:48.640 --> 00:03:54.640
Well, maybe a quick introduction for yourself for those who didn't hear your previous episode,

00:03:54.640 --> 00:03:57.940
and then we'll talk a bit about this PyDantic library.

00:03:57.940 --> 00:03:58.640
Yeah, sure.

00:03:58.640 --> 00:03:59.240
Sounds great.

00:03:59.240 --> 00:04:00.700
So my name is Sydney.

00:04:00.700 --> 00:04:03.940
I just graduated from the University of Wisconsin.

00:04:03.940 --> 00:04:08.340
Last time I chatted with you, I was still pursuing my degree in computer science.

00:04:08.340 --> 00:04:12.080
And working part-time as an intern at the company PyDantic,

00:04:12.080 --> 00:04:17.080
which is kind of founded around the same ideas that inspired the open source tool,

00:04:17.080 --> 00:04:18.840
and now we're building commercial tools.

00:04:18.840 --> 00:04:23.340
And now I've rolled over into full-time work with them, primarily on the open source side.

00:04:23.340 --> 00:04:27.440
So yeah, very excited to kind of be contributing to the open source community,

00:04:27.440 --> 00:04:32.440
but also getting to help with our commercial tools and development there.

00:04:32.440 --> 00:04:33.180
Yeah, yeah.

00:04:33.180 --> 00:04:33.540
Awesome.

00:04:33.540 --> 00:04:35.040
We'll talk a bit about that later.

00:04:35.040 --> 00:04:40.440
Super cool to be able to work on open source as a job, as a proper job, right?

00:04:40.440 --> 00:04:41.780
Yeah, it's awesome.

00:04:41.780 --> 00:04:43.540
It's really unique.

00:04:43.540 --> 00:04:47.980
I've kind of encouraged lots of people to contribute to open source as kind of a jumpstart

00:04:47.980 --> 00:04:53.180
into their software development careers, especially like young folks who are looking to get started

00:04:53.180 --> 00:04:56.100
with things and maybe don't have an internship or that sort of thing set up yet.

00:04:56.100 --> 00:05:01.180
I think it's a really awesome pipeline for like getting exposed to good code and collaborating

00:05:01.180 --> 00:05:02.280
with others and that sort of thing.

00:05:02.280 --> 00:05:06.500
But it's definitely special to get to do and get paid as well.

00:05:06.500 --> 00:05:07.200
Indeed.

00:05:07.200 --> 00:05:12.840
So it's a little bit unbelievable to me, but I'm sure that it is true that there are folks

00:05:12.840 --> 00:05:16.940
out there listening to the podcast that are like, "Pydantic, maybe I've heard of that.

00:05:16.940 --> 00:05:19.800
What is this Pydantic thing?"

00:05:19.800 --> 00:05:20.580
Yeah, great question.

00:05:20.580 --> 00:05:22.040
What is Pydantic?

00:05:22.040 --> 00:05:26.040
So Pydantic is the leading data validation library for Python.

00:05:26.040 --> 00:05:31.540
And so Pydantic uses type hints, which are optional in Python, but kind of generally more

00:05:31.540 --> 00:05:37.340
and more encouraged to enforce constraints on data and kind of validate data structures,

00:05:37.340 --> 00:05:38.340
et cetera.

00:05:38.340 --> 00:05:43.220
So we're kind of looking at a very simple example together right now where we're importing

00:05:43.220 --> 00:05:46.860
things like date time and tuple types from typing.

00:05:46.860 --> 00:05:54.220
And then kind of the core of Pydantic is you define these classes that inherit from this

00:05:54.220 --> 00:05:57.260
class called base model that's in Pydantic.

00:05:57.260 --> 00:06:03.860
And that inheritance is what ends up helping you use methods to validate data, build JSON

00:06:03.860 --> 00:06:05.460
schema, things like that.

00:06:05.460 --> 00:06:09.780
And so in our case, we have this delivery class that has a timestamp, which is of type

00:06:09.780 --> 00:06:16.120
date time, and then a dimensions tuple, which has two int parts.

00:06:16.120 --> 00:06:22.240
And so then when you pass data into this delivery class to create an instance, Pydantic handles

00:06:22.240 --> 00:06:27.860
validating that data to make sure that it conforms to those constraints we've specified.

00:06:27.860 --> 00:06:31.600
And so it's really a kind of intermediate tool that you can use for deserialization

00:06:31.600 --> 00:06:34.840
or loading data and then serialization, dumping data.

00:06:34.840 --> 00:06:37.040
Yeah, it's a thing of beauty.

00:06:37.040 --> 00:06:38.880
I really love the way that it works.

00:06:38.880 --> 00:06:41.960
If you've got JSON data, nested JSON data, right?

00:06:41.960 --> 00:06:47.840
If you go to pydantic.dev/opensource, there's an example of here that we're talking about.

00:06:47.840 --> 00:06:51.480
It's got a tuple, but the tuple contains integers, two of them.

00:06:51.480 --> 00:06:54.880
And so if there's a tuple of three things, it'll give you an error.

00:06:54.880 --> 00:06:58.560
If it's a tuple of a date time and an int, it'll give you an error.

00:06:58.560 --> 00:07:03.160
Like it reaches all the way inside and, you know, things I guess it compares against.

00:07:03.160 --> 00:07:05.340
It's a little bit like data classes.

00:07:05.340 --> 00:07:07.840
Have you done much with data classes and compared them?

00:07:07.840 --> 00:07:09.280
Yeah, that's a great question.

00:07:09.280 --> 00:07:13.480
So we actually offer support for like Pydantic data classes.

00:07:13.480 --> 00:07:18.140
So I think data classes kind of took the first step of, you know, really supporting using

00:07:18.140 --> 00:07:21.320
type hints for model fields and things like that.

00:07:21.320 --> 00:07:27.360
And then Pydantic sort of takes the next jump in terms of like validation and schema support.

00:07:27.360 --> 00:07:32.600
And so I think one like very common use cases, if you're defining like API request and response

00:07:32.600 --> 00:07:36.760
models, you can imagine like the JSON schema capabilities come in handy there.

00:07:36.760 --> 00:07:41.720
And just ensuring like the integrity of your API and the data you're dealing with.

00:07:41.720 --> 00:07:43.400
Very helpful in the validation front.

00:07:43.400 --> 00:07:44.400
Yeah, yeah.

00:07:44.400 --> 00:07:45.400
Very cool.

00:07:45.400 --> 00:07:46.400
Okay.

00:07:46.400 --> 00:07:52.840
So I guess one more thing for people who are not super familiar that Pydantic is, I think

00:07:52.840 --> 00:07:55.040
it's used every now and then.

00:07:55.040 --> 00:07:56.360
Let's check it out on GitHub here.

00:07:56.360 --> 00:07:59.960
I'm just trying to think of, you know, like some of the main places people have heard

00:07:59.960 --> 00:08:00.960
of it.

00:08:00.960 --> 00:08:05.640
Obviously, FastAPI, I think is the thing that really launched its popularity in the early

00:08:05.640 --> 00:08:06.640
days if I had to guess.

00:08:06.640 --> 00:08:13.760
But if we go over to GitHub, GitHub says that for the open source things that Pydantic is

00:08:13.760 --> 00:08:20.000
a foundational dependency for 412,644 different projects.

00:08:20.000 --> 00:08:21.000
Yeah.

00:08:21.000 --> 00:08:22.000
That's unbelievable.

00:08:22.000 --> 00:08:23.840
Yeah, it's very exciting.

00:08:23.840 --> 00:08:30.200
We just got our May download numbers and heard that we have over 200 million downloads in

00:08:30.200 --> 00:08:31.200
May.

00:08:31.200 --> 00:08:33.040
So that's both version one and version two.

00:08:33.040 --> 00:08:38.360
But definitely exciting to see how kind of critical of a tool it's become for so many

00:08:38.360 --> 00:08:40.960
different use cases in Python, which is awesome.

00:08:40.960 --> 00:08:42.120
Yeah, absolutely.

00:08:42.120 --> 00:08:43.120
It's really, really critical.

00:08:43.120 --> 00:08:49.960
And I think we should probably talk a little bit about Pydantic v1, v2 as a way to get

00:08:49.960 --> 00:08:52.120
into the architecture conversation.

00:08:52.120 --> 00:08:53.120
Right.

00:08:53.120 --> 00:08:57.720
That was a big thing I talked to Samuel Colvin maybe a year ago or so, I would imagine.

00:08:57.720 --> 00:08:59.080
Think around PyCon.

00:08:59.080 --> 00:09:01.360
I think we did actually a PyCon last year as well.

00:09:01.360 --> 00:09:02.360
Yeah, for sure.

00:09:02.360 --> 00:09:10.000
So a lot of the benefit of using Pydantic is we promise some great performance.

00:09:10.000 --> 00:09:14.700
And a lot of those performance gains came during our jump from v1 to v2.

00:09:14.700 --> 00:09:17.600
So v1 was written solely in Python.

00:09:17.600 --> 00:09:23.320
We had some compiled options, but really it was mostly Pythonic data validation.

00:09:23.320 --> 00:09:24.720
Or I say Pythonic.

00:09:24.720 --> 00:09:29.040
It's always Pythonic, but data validation done solely in Python.

00:09:29.040 --> 00:09:35.080
And the big difference with v2 is that we rewrote kind of the core of our code in Rust.

00:09:35.080 --> 00:09:36.840
And so Rust is much faster.

00:09:36.840 --> 00:09:42.960
And so depending on what kind of code you're running, v2 can be anywhere from two to 20

00:09:42.960 --> 00:09:45.520
times faster in certain cases.

00:09:45.520 --> 00:09:50.660
So right now we still have this Python wrapper around everything in v2.

00:09:50.660 --> 00:09:55.200
But then, and that's kind of used to define schemas for models and that sort of thing.

00:09:55.200 --> 00:10:02.040
And then the actual validation and serialization logic occurs in Pydantic core in Rust.

00:10:02.040 --> 00:10:03.040
Right.

00:10:03.040 --> 00:10:09.160
So I think the team did a really good job to make this major change, this major rewrite,

00:10:09.160 --> 00:10:14.600
and split the whole monolithic thing into a Pydantic core, Pydantic itself, which is

00:10:14.600 --> 00:10:19.240
Python based in a way that didn't break too many projects, right?

00:10:19.240 --> 00:10:20.720
Yeah, that was the goal.

00:10:20.720 --> 00:10:25.680
You know, every now and then there are breaking changes that I think are generally a good

00:10:25.680 --> 00:10:27.520
thing for the library moving forward, right?

00:10:27.520 --> 00:10:31.960
Like hopefully whenever we make a breaking change, it's because it's leading to a significant

00:10:31.960 --> 00:10:32.960
improvement.

00:10:32.960 --> 00:10:37.840
So we definitely do our best to avoid breaking changes and certainly someday we'll launch

00:10:37.840 --> 00:10:44.680
a v3 and hopefully that'll be an even more seamless transition for v2 users to v3 users.

00:10:44.680 --> 00:10:50.140
Yeah, I would imagine that the switch to Rust probably, that big rewrite, it probably caused

00:10:50.140 --> 00:10:54.760
a lot of ways, thoughts of reconsidering, how are we doing this?

00:10:54.760 --> 00:10:58.440
Or now that it's over in Rust, maybe it doesn't make sense this way or whatever.

00:10:58.440 --> 00:10:59.440
Yeah.

00:10:59.440 --> 00:11:03.680
So we kind of, you know, we got a lot of feedback and usage of Pydantic v1, so tried to do our

00:11:03.680 --> 00:11:08.760
best to incorporate all that feedback into a better v2 version in terms of both APIs

00:11:08.760 --> 00:11:10.640
and performance and that sort of thing.

00:11:10.640 --> 00:11:11.640
Sure, sure.

00:11:11.640 --> 00:11:16.000
John out in the audience asks, how did the team approach thread safety with this?

00:11:16.000 --> 00:11:19.280
So Rust can be multiple threads easy.

00:11:19.280 --> 00:11:24.000
Python, not so much really, although maybe soon with free threaded Python.

00:11:24.000 --> 00:11:26.140
Yeah, that's a good question.

00:11:26.140 --> 00:11:31.520
So our kind of Rust guru on the team is David Hewitt, and he's very in the know about all

00:11:31.520 --> 00:11:35.280
of the multi-threading and things happening on the Rust side of things.

00:11:35.280 --> 00:11:38.880
I myself have some more to learn about that, certainly.

00:11:38.880 --> 00:11:43.880
But I think in general, kind of our approach is that Rust is quite type safe, both performant

00:11:43.880 --> 00:11:48.400
and type safe, which is great and memory safe as well.

00:11:48.400 --> 00:11:54.200
And I think most of our, I'll talk a little bit later about some like parallelization

00:11:54.200 --> 00:11:57.080
and vectorization that we're looking at for performance improvements.

00:11:57.080 --> 00:12:01.280
But in terms of safety, I think if you have any questions, feel free to open an issue

00:12:01.280 --> 00:12:05.200
on the Pydantic core repo and get a conversation going with David Hewitt.

00:12:05.200 --> 00:12:09.800
I would imagine it's not, you guys haven't had to do too much with it, just that Python

00:12:09.800 --> 00:12:16.760
currently, but soon, but currently doesn't really let you do much true multi-threading

00:12:16.760 --> 00:12:17.760
because of the GIL.

00:12:17.760 --> 00:12:23.560
But the whole, I think, you know, yeah, I think Python 3.13 is going to be crazy with

00:12:23.560 --> 00:12:27.440
free threaded Python and it's going to be interesting to see how that evolves.

00:12:27.440 --> 00:12:28.440
Yep.

00:12:28.440 --> 00:12:29.440
Yeah.

00:12:29.440 --> 00:12:32.440
I know we definitely do some jumping through hoops and just, you know, having to be really

00:12:32.440 --> 00:12:36.960
conscious of stuff with the GIL in Pydantic core and Py03.

00:12:36.960 --> 00:12:41.160
And Py03 is kind of the library that bridges Python and Rust.

00:12:41.160 --> 00:12:44.080
And so it's heavily used in Pydantic core, as you can imagine.

00:12:44.080 --> 00:12:46.120
So I'm excited to see what changes might look like there.

00:12:46.120 --> 00:12:47.120
Yeah, same.

00:12:47.120 --> 00:12:48.120
All right.

00:12:48.120 --> 00:12:51.600
Well, let's jump into the performance because you're here to tell us all about Pydantic

00:12:51.600 --> 00:12:52.600
performance tips.

00:12:52.600 --> 00:12:54.000
And you've got a whole bunch of these.

00:12:54.000 --> 00:12:55.600
Did you give this talk at PyCon?

00:12:55.600 --> 00:12:56.720
I did partially.

00:12:56.720 --> 00:12:59.200
It's a little bit different, but some of the tips are the same.

00:12:59.200 --> 00:13:01.140
I don't think the videos are out yet, are they?

00:13:01.140 --> 00:13:03.720
As the time of recording on June 13th.

00:13:03.720 --> 00:13:04.720
Yeah.

00:13:04.720 --> 00:13:06.360
No, I actually checked a couple of minutes ago.

00:13:06.360 --> 00:13:10.020
I was like, I said one thing during my talk that I wanted to double check, but the videos

00:13:10.020 --> 00:13:11.020
are not out yet.

00:13:11.020 --> 00:13:12.020
So.

00:13:12.020 --> 00:13:13.020
No, I'm really excited.

00:13:13.020 --> 00:13:14.020
There's going to be a bunch.

00:13:14.020 --> 00:13:16.760
There was actually a bunch of good talks, including yours and some others I want to

00:13:16.760 --> 00:13:18.600
watch, but they're not out yet.

00:13:18.600 --> 00:13:19.800
All right.

00:13:19.800 --> 00:13:21.680
Let's jump into Pydantic performance.

00:13:21.680 --> 00:13:23.440
Where should we start?

00:13:23.440 --> 00:13:25.560
I can start on the slideshow if we want.

00:13:25.560 --> 00:13:26.920
Yeah, let's do that.

00:13:26.920 --> 00:13:27.920
Awesome.

00:13:27.920 --> 00:13:30.960
So, yeah, I think kind of the categories of performance tips that we're going to talk

00:13:30.960 --> 00:13:37.000
about here kind of have some like fast one liner type performance tips that you can implement

00:13:37.000 --> 00:13:41.800
in your own code and then kind of the meat of the like, how do I improve performance

00:13:41.800 --> 00:13:44.960
in my in my application that uses Pydantic?

00:13:44.960 --> 00:13:49.800
We're going to talk a bit about discriminated unions, also called tagged unions, and then

00:13:49.800 --> 00:13:55.000
kind of finally talk about on our end of the development, how are we continuously improving

00:13:55.000 --> 00:13:56.000
performance?

00:13:56.000 --> 00:13:58.800
You know, Pydantic internals, lies, et cetera.

00:13:58.800 --> 00:13:59.800
Sure.

00:13:59.800 --> 00:14:03.680
Do you have the equivalent of unit test for performance?

00:14:03.680 --> 00:14:05.480
Yeah, we do.

00:14:05.480 --> 00:14:10.080
We use a library called CodSpeed that I'm excited to touch on a bit more later.

00:14:10.080 --> 00:14:11.080
Yeah.

00:14:11.080 --> 00:14:12.080
All right.

00:14:12.080 --> 00:14:13.080
Let's talk about that later.

00:14:13.080 --> 00:14:14.080
Perfect.

00:14:14.080 --> 00:14:15.080
Yeah, sure thing.

00:14:15.080 --> 00:14:18.640
So I have this slide up right now just kind of talking about why people use Pydantic.

00:14:18.640 --> 00:14:22.480
We've already covered some of these, but just kind of as a general recap, it's powered by

00:14:22.480 --> 00:14:23.720
type hints.

00:14:23.720 --> 00:14:26.280
And one of our biggest promises is speed.

00:14:26.280 --> 00:14:31.360
We also have these other great features like JSON schema compatibility and documentation

00:14:31.360 --> 00:14:36.240
comes in particularly handy when we talk about APIs, you know, support for custom validation

00:14:36.240 --> 00:14:38.160
and serialization logic.

00:14:38.160 --> 00:14:44.360
And then as we saw with the GitHub repository observations, a very robust ecosystem of libraries

00:14:44.360 --> 00:14:49.760
and other tools that use and depend on Pydantic that leads to this kind of extensive and large

00:14:49.760 --> 00:14:52.300
community, which is really great.

00:14:52.300 --> 00:14:56.880
But this all kind of lies on the foundation of like Pydantic is easy to use and it's very

00:14:56.880 --> 00:14:57.880
fast.

00:14:57.880 --> 00:14:58.880
So let's talk some more about that.

00:14:58.880 --> 00:15:03.960
And this, yeah, well, the speed is really interesting in the multiplier that you all

00:15:03.960 --> 00:15:08.640
have for basically a huge swath of the Python ecosystem, right?

00:15:08.640 --> 00:15:12.040
We just saw the 412,000 things that depend on Pydantic.

00:15:12.040 --> 00:15:17.200
Well, a lot of those, their performance depends on Pydantic's performance as well.

00:15:17.200 --> 00:15:18.200
Right?

00:15:18.200 --> 00:15:19.200
Yeah, certainly.

00:15:19.200 --> 00:15:24.000
Yeah, it's nice to have such a large ecosystem of folks to also, you know, contribute to

00:15:24.000 --> 00:15:25.120
the library as well, right?

00:15:25.120 --> 00:15:28.920
Like, you know, because other people are dependent on our performance, the community definitely

00:15:28.920 --> 00:15:33.080
becomes invested in it as well, which is great.

00:15:33.080 --> 00:15:38.960
This portion of Talk Python to Me is brought to you by OpenTelemetry support at Sentry.

00:15:38.960 --> 00:15:43.920
In the previous two episodes, you heard how we use Sentry's error monitoring at Talk Python,

00:15:43.920 --> 00:15:48.720
and how distributed tracing connects errors, performance and slowdowns and more across

00:15:48.720 --> 00:15:50.720
services and tiers.

00:15:50.720 --> 00:15:54.140
But you may be thinking our company uses OpenTelemetry.

00:15:54.140 --> 00:15:56.980
So it doesn't make sense for us to switch to Sentry.

00:15:56.980 --> 00:16:01.760
After all, OpenTelemetry is a standard, and you've already adopted it, right?

00:16:01.760 --> 00:16:06.280
Well, did you know, with just a couple of lines of code, you can connect OpenTelemetry's

00:16:06.280 --> 00:16:10.440
monitoring and reporting to Sentry's backend.

00:16:10.440 --> 00:16:13.960
OpenTelemetry does not come with a backend to store your data, analytics on top of that

00:16:13.960 --> 00:16:17.060
data, a UI or error monitoring.

00:16:17.060 --> 00:16:22.540
And that's exactly what you get when you integrate Sentry with your OpenTelemetry setup.

00:16:22.540 --> 00:16:26.840
Don't fly blind, fix and monitor code faster with Sentry.

00:16:26.840 --> 00:16:30.720
Integrate your OpenTelemetry systems with Sentry and see what you've been missing.

00:16:30.720 --> 00:16:35.840
Create your Sentry account at talkpython.fm/sentry-telemetry.

00:16:35.840 --> 00:16:39.920
And when you sign up, use the code TALKPYTHON, all caps, no spaces.

00:16:39.920 --> 00:16:43.960
It's good for two free months of Sentry's business plan, which will give you 20 times

00:16:43.960 --> 00:16:47.360
as many monthly events as well as other features.

00:16:47.360 --> 00:16:50.400
My thanks to Sentry for supporting Talk Python to me.

00:16:50.400 --> 00:16:55.600
But yeah, so kind of as that first category, we can chat about some basic performance tips.

00:16:55.600 --> 00:16:59.600
And I'll do my best here to kind of describe this generally for listeners who maybe aren't

00:16:59.600 --> 00:17:01.480
able to see the screen.

00:17:01.480 --> 00:17:03.200
So when you are...

00:17:03.200 --> 00:17:06.240
Can we share your slideshow later with the audience?

00:17:06.240 --> 00:17:07.560
Can we put it in the show notes?

00:17:07.560 --> 00:17:08.560
Yeah, yeah, absolutely.

00:17:08.560 --> 00:17:10.560
Okay, so people want to go back and check it out.

00:17:10.560 --> 00:17:12.160
But yeah, we'll just, we'll describe it for everyone.

00:17:12.160 --> 00:17:13.160
Go ahead.

00:17:13.160 --> 00:17:14.160
Yeah.

00:17:14.160 --> 00:17:19.720
So when you're validating data in Pydantic, you can either validate Python objects or

00:17:19.720 --> 00:17:24.900
like dictionary type data, or you can validate JSON formatted data.

00:17:24.900 --> 00:17:31.100
And so one of these kind of like one liner tips that we have is to use our built in model

00:17:31.100 --> 00:17:37.020
validate JSON method, instead of calling this our model validate method, and then separately

00:17:37.020 --> 00:17:41.000
loading the JSON data with the standard lib JSON package.

00:17:41.000 --> 00:17:46.100
And the reason that we recommend that is one of the like crux of the general performance

00:17:46.100 --> 00:17:51.120
patterns that we try to follow is not materializing things in Python when we don't have to.

00:17:51.120 --> 00:17:54.660
So we've already mentioned that our core is written in Rust, which is much faster than

00:17:54.660 --> 00:17:55.660
Python.

00:17:55.660 --> 00:18:00.160
And so with our model validate JSON built in method, whenever you pass in that string,

00:18:00.160 --> 00:18:01.860
we send it right to Rust.

00:18:01.860 --> 00:18:06.040
Whereas if you do the JSON loading by yourself, you're going to like materialize Python object

00:18:06.040 --> 00:18:07.540
and then have to send it over.

00:18:07.540 --> 00:18:08.540
Right.

00:18:08.540 --> 00:18:14.240
And so you're going to be using the built in JSON load S, which will then or load or

00:18:14.240 --> 00:18:18.500
whatever, and then it'll pull that in, turn into a Python dictionary, then you take it

00:18:18.500 --> 00:18:23.780
and try to convert that back to a Rust data structure, and then validate it in Rust.

00:18:23.780 --> 00:18:25.700
That's where all the validation lives anyway.

00:18:25.700 --> 00:18:28.060
So just get out of the way, right?

00:18:28.060 --> 00:18:29.060
Exactly.

00:18:29.060 --> 00:18:30.060
Yep.

00:18:30.060 --> 00:18:31.740
It's like skip the Python step if you can, right.

00:18:31.740 --> 00:18:36.760
And I will note there is one exception here, which is I mentioned we support custom validation.

00:18:36.760 --> 00:18:41.720
If you're using what we call like before and wrap validators that do something in Python,

00:18:41.720 --> 00:18:47.540
and then call our internal validation logic, and then maybe even do something after, it's

00:18:47.540 --> 00:18:52.500
okay, you can use model validate and the built in JSON dot load S because you're already

00:18:52.500 --> 00:18:55.940
kind of guaranteed to be materializing Python objects in that case.

00:18:55.940 --> 00:18:59.580
But for the vast majority of cases, it's great to just go with the built in model validate

00:18:59.580 --> 00:19:00.580
JSON.

00:19:00.580 --> 00:19:02.020
Yeah, that's really good advice.

00:19:02.020 --> 00:19:03.700
And they seem kind of equivalent.

00:19:03.700 --> 00:19:07.420
But once you know the internals, right, then it's well, maybe it's not exactly.

00:19:07.420 --> 00:19:08.420
Yeah.

00:19:08.420 --> 00:19:11.900
And I think implementing some of these tips is helpful in that if you understand some

00:19:11.900 --> 00:19:16.820
of the kind of like pedantic architectural context, it can also just help you think more

00:19:16.820 --> 00:19:19.660
about like, how can I write my pedantic code better?

00:19:19.660 --> 00:19:20.660
Absolutely.

00:19:20.660 --> 00:19:26.780
So, the next tip I have here, very easy one liner fix, which is when you're using type

00:19:26.780 --> 00:19:32.060
adapter, which is this structure you can use to basically validate one type.

00:19:32.060 --> 00:19:36.020
So we have base models, which we've chatted about before, which is like if you have a

00:19:36.020 --> 00:19:39.420
model with lots of fields, that's kind of the structure you use to define it.

00:19:39.420 --> 00:19:43.260
Well, type adapter is great if you're like, I just want to validate that this data is

00:19:43.260 --> 00:19:46.060
a list of integers, for example, as we're seeing on the screen.

00:19:46.060 --> 00:19:47.060
Right.

00:19:47.060 --> 00:19:48.780
Because let me give people an idea.

00:19:48.780 --> 00:19:53.700
Like if you accept, if you've got a JSON, well, just JSON data from wherever, but you

00:19:53.700 --> 00:19:57.860
know, a lot of times it's coming over an API or it's provided to you as a file and it's

00:19:57.860 --> 00:19:59.460
not your data you control, right?

00:19:59.460 --> 00:20:00.540
You're trying to validate it.

00:20:00.540 --> 00:20:06.140
You could get a dictionary, a JSON object that's got curly braces with a bunch of stuff,

00:20:06.140 --> 00:20:08.180
in which case that's easy to map to a class.

00:20:08.180 --> 00:20:12.420
But if you just have JSON, which is bracket, thing, thing, thing, thing, close bracket.

00:20:12.420 --> 00:20:15.780
Well, how do you have class that represent the list?

00:20:15.780 --> 00:20:17.980
Like it gets really tricky, right?

00:20:17.980 --> 00:20:21.220
To be able to understand, you can't model that with classes.

00:20:21.220 --> 00:20:24.040
And so you all have this type adapter thing, right?

00:20:24.040 --> 00:20:25.780
That's what this, the role plays generally.

00:20:25.780 --> 00:20:26.780
Is that right?

00:20:26.780 --> 00:20:27.780
Yeah.

00:20:27.780 --> 00:20:30.740
And I think it's also really helpful in a testing context.

00:20:30.740 --> 00:20:35.860
Like you know, when we want to check that our validation behavior is right for one type,

00:20:35.860 --> 00:20:40.660
there's no reason to go like build an entire model if you're really just validating against

00:20:40.660 --> 00:20:44.340
one type or structure, type adapter is great.

00:20:44.340 --> 00:20:50.180
And so kind of the advice here is you only want to initialize your type adapter object

00:20:50.180 --> 00:20:51.180
once.

00:20:51.180 --> 00:20:56.740
And the reason behind that is we build a core schema in Python and then attach that to a

00:20:56.740 --> 00:20:59.300
class or type adapter, et cetera.

00:20:59.300 --> 00:21:03.540
And so if you can, you know, not build that type adapter within your loop, but instead

00:21:03.540 --> 00:21:08.220
of instead do it right before or not build it, you know, in your function, but instead

00:21:08.220 --> 00:21:11.980
outside of it, then you can avoid building the core schema over and over again.

00:21:11.980 --> 00:21:12.980
Yeah.

00:21:12.980 --> 00:21:16.620
So basically what you're saying is that the type adapter that you create might as well

00:21:16.620 --> 00:21:19.300
be a singleton because it's stateless, right?

00:21:19.300 --> 00:21:21.540
Like it doesn't store any data.

00:21:21.540 --> 00:21:24.980
It's kind of slightly expensive to create relatively.

00:21:24.980 --> 00:21:28.420
And so if you had a function that was called over and over again, and that function had

00:21:28.420 --> 00:21:31.960
a loop and inside the loop, you're creating the type adapter, that'd be like worst case

00:21:31.960 --> 00:21:33.500
scenario almost, right?

00:21:33.500 --> 00:21:34.500
Yeah, exactly.

00:21:34.500 --> 00:21:37.760
And I think this kind of goes along with like general best programming tips, right?

00:21:37.760 --> 00:21:42.100
Which is like, if you only need to create something once, do that once.

00:21:42.100 --> 00:21:43.100
Exactly.

00:21:43.100 --> 00:21:48.140
You know, a parallel that maybe goes way, way back in time could be like a compiled

00:21:48.140 --> 00:21:49.140
regular expression.

00:21:49.140 --> 00:21:52.220
You know, you wouldn't do that over and over in a loop.

00:21:52.220 --> 00:21:55.820
You would just create a regular, the compiled regular expression and then use it throughout

00:21:55.820 --> 00:21:57.220
your program, right?

00:21:57.220 --> 00:22:00.980
Because it's kind of expensive to do that, but it's fast once it's created.

00:22:00.980 --> 00:22:01.980
Yeah, exactly.

00:22:01.980 --> 00:22:02.980
And funny that you mentioned that.

00:22:02.980 --> 00:22:08.720
I actually fixed a bug last week where we were compiling regular expressions twice when

00:22:08.720 --> 00:22:11.360
folks like specified that as a constraint on a field.

00:22:11.360 --> 00:22:16.240
So definitely just something to keep in mind and easy to fix or implement with type adapters

00:22:16.240 --> 00:22:17.240
here.

00:22:17.240 --> 00:22:18.240
Yeah, awesome.

00:22:18.240 --> 00:22:19.240
Okay.

00:22:19.240 --> 00:22:20.240
I like this one.

00:22:20.240 --> 00:22:21.240
That's a good one.

00:22:21.240 --> 00:22:22.240
Yeah.

00:22:22.240 --> 00:22:25.560
So this next tip also kind of goes along with like general best practices, but the more

00:22:25.560 --> 00:22:28.680
specific you can be with your type hints, the better.

00:22:28.680 --> 00:22:34.500
And so specifically, if you know that you have a list of integers, it's better and more

00:22:34.500 --> 00:22:39.800
efficient to specify a type hint as a list of integers instead of a sequence of integers,

00:22:39.800 --> 00:22:40.800
for example.

00:22:40.800 --> 00:22:46.080
Or if you know you have a dictionary that maps strings to integers, specify that type

00:22:46.080 --> 00:22:48.200
hint as a dictionary, not a mapping.

00:22:48.200 --> 00:22:49.200
Interesting.

00:22:49.200 --> 00:22:50.200
Yeah.

00:22:50.200 --> 00:22:54.480
So you could import a sequence from the typing module, just the generic way, but I guess

00:22:54.480 --> 00:22:59.360
you probably have specific code that runs that can validate lists more efficiently than

00:22:59.360 --> 00:23:01.760
a general iterable type of thing, right?

00:23:01.760 --> 00:23:02.760
Yeah, exactly.

00:23:02.760 --> 00:23:07.320
So in the case of like a sequence versus a list, it's the like square and rectangle thing,

00:23:07.320 --> 00:23:08.320
right?

00:23:08.320 --> 00:23:11.160
Like a list is a sequence, but there are lots of other types of sequences.

00:23:11.160 --> 00:23:15.520
And so you can imagine for a sequence, we like have to check lots of other things.

00:23:15.520 --> 00:23:20.240
Whereas if you know with certainty, this is going to be a list or it should be a list,

00:23:20.240 --> 00:23:23.720
then you can have things be more efficient with specificity there.

00:23:23.720 --> 00:23:29.960
Does it make any difference at all whether you use the more modern type specifications?

00:23:29.960 --> 00:23:35.600
Like traditionally people would say from typing import capital L list, but now you can just

00:23:35.600 --> 00:23:39.560
say lowercase L list with the built-in and no import statement.

00:23:39.560 --> 00:23:42.600
Are those equivalent or is there some minor difference there?

00:23:42.600 --> 00:23:43.600
Do you know?

00:23:43.600 --> 00:23:44.600
Yeah, that's a good question.

00:23:44.600 --> 00:23:48.440
I wouldn't be surprised if there was a minor difference that was more a consequence of

00:23:48.440 --> 00:23:50.120
like Python version, right?

00:23:50.120 --> 00:23:55.240
Because there's like, I mean, I suppose you could import the old capital L list in a newer

00:23:55.240 --> 00:23:59.960
Python version, but I think the difference is like more related to specificity of a type

00:23:59.960 --> 00:24:03.840
in rather than kind of like versioning.

00:24:03.840 --> 00:24:09.640
If the use of that capital L list made you write an import statement, I mean, it would

00:24:09.640 --> 00:24:14.440
cause the program to start ever so slightly slower because there's another import.

00:24:14.440 --> 00:24:18.080
It's got a run where it already knows it's already imported what list is.

00:24:18.080 --> 00:24:23.420
You wouldn't believe how many times I get messages on YouTube videos I've done or even

00:24:23.420 --> 00:24:28.200
from courses saying, Michael, I don't know what you're doing, but your code is just wrong.

00:24:28.200 --> 00:24:35.040
I wrote lowercase L list bracket something and it said list is not a sub indexable or

00:24:35.040 --> 00:24:36.040
something like that.

00:24:36.040 --> 00:24:37.400
And look, you've just done it wrong.

00:24:37.400 --> 00:24:38.840
You're going to need to fix this.

00:24:38.840 --> 00:24:45.000
Or you're on Python 3.7 or something super old before these new features are added.

00:24:45.000 --> 00:24:49.960
But there's just somewhere in the community we haven't communicated this well.

00:24:49.960 --> 00:24:50.960
I don't know.

00:24:50.960 --> 00:24:52.040
Yeah, for sure.

00:24:52.040 --> 00:24:56.720
I was writing some code earlier today in a meeting and I used the like from typing import

00:24:56.720 --> 00:25:00.400
union and then union X and Y type.

00:25:00.400 --> 00:25:02.760
My coworker was like, Sydney, use the pipe.

00:25:02.760 --> 00:25:04.680
Like what are you doing?

00:25:04.680 --> 00:25:05.960
Use the pipe, exactly.

00:25:05.960 --> 00:25:08.760
But here's the thing that was introduced in 3.10, I believe.

00:25:08.760 --> 00:25:13.720
And if people are in 3.9, that code doesn't run or if they're not familiar with the changes.

00:25:13.720 --> 00:25:15.320
So there's all these tradeoffs.

00:25:15.320 --> 00:25:20.240
I almost feel like it would be amazing to go back for any time there's a security release

00:25:20.240 --> 00:25:25.360
that releases, say another 3.7 or something and change the error message to say this feature

00:25:25.360 --> 00:25:30.520
only works in the future version of Python rather than some arbitrary error of you're

00:25:30.520 --> 00:25:31.520
doing it wrong.

00:25:31.520 --> 00:25:32.520
You know, that would be great.

00:25:32.520 --> 00:25:33.520
Yeah, definitely.

00:25:33.520 --> 00:25:34.520
Yeah.

00:25:34.520 --> 00:25:36.720
Some of those errors can be pretty cryptic with the syntax stuff.

00:25:36.720 --> 00:25:37.720
They can.

00:25:37.720 --> 00:25:38.720
All right.

00:25:38.720 --> 00:25:43.120
So be specific list tuple not sequence if you know it's a list or tuple or whatever.

00:25:43.120 --> 00:25:44.120
Yeah.

00:25:44.120 --> 00:25:49.280
And then kind of my last minor tip, which great that you brought up import statements

00:25:49.280 --> 00:25:54.520
and kind of adding general time to a program is I don't have a slide for this one, but

00:25:54.520 --> 00:25:59.040
if we go back to the type adapter slide, we talked about the fact that initializing this

00:25:59.040 --> 00:26:04.560
type adapter builds a core schema and attaches it to that class.

00:26:04.560 --> 00:26:08.080
And that's kind of done at build time at import time.

00:26:08.080 --> 00:26:10.960
So that's like already done.

00:26:10.960 --> 00:26:17.280
And if you really don't want to have that import or like build time, take a long time,

00:26:17.280 --> 00:26:20.520
you can use the defer build flag.

00:26:20.520 --> 00:26:25.120
And so what that does is defers the core schema build until the first validation call.

00:26:25.120 --> 00:26:28.260
You can also set that on model config and things like that.

00:26:28.260 --> 00:26:32.080
But basically the idea here is like striving to be lazier, right?

00:26:32.080 --> 00:26:36.520
Like I see if we don't need to build this core schema right at import time because we

00:26:36.520 --> 00:26:38.560
want our program to start up quickly.

00:26:38.560 --> 00:26:39.560
That's great.

00:26:39.560 --> 00:26:43.160
There's a little bit of a delay on the first validation, but maybe startup time is more

00:26:43.160 --> 00:26:44.160
important.

00:26:44.160 --> 00:26:48.440
So that's a little bit more of a preferential validation, sorry, preferential performance

00:26:48.440 --> 00:26:50.920
tip, but available for folks who need it.

00:26:50.920 --> 00:26:51.920
Yeah.

00:26:51.920 --> 00:26:52.920
Like, let me give you an example.

00:26:52.920 --> 00:26:55.160
I'll give people an example where I think this might be useful.

00:26:55.160 --> 00:27:00.240
So in the Talk Python Training, the courses site, I think we've got 20,000 lines of Python

00:27:00.240 --> 00:27:02.280
code, which is probably more at this point.

00:27:02.280 --> 00:27:04.560
I checked a long time ago, but a lot.

00:27:04.560 --> 00:27:05.840
And it's a package.

00:27:05.840 --> 00:27:10.960
And so when you import it, it goes and imports all the stuff to like run the whole web app,

00:27:10.960 --> 00:27:14.360
but also little utilities like, oh, I just want to get a quick report.

00:27:14.360 --> 00:27:19.400
I want to just access this model and then use it on something real quick.

00:27:19.400 --> 00:27:20.740
It imports all that stuff.

00:27:20.740 --> 00:27:23.920
So that app startup would be potentially slowed down by this.

00:27:23.920 --> 00:27:28.440
Where if you know, like only sometimes is that type adapter used, you don't want to

00:27:28.440 --> 00:27:31.600
necessarily have it completely created until that function gets called.

00:27:31.600 --> 00:27:34.600
So then the first function call might be a little slow, but there'd be plenty of times

00:27:34.600 --> 00:27:36.200
where maybe it never gets called.

00:27:36.200 --> 00:27:37.200
Right?

00:27:37.200 --> 00:27:38.200
Yep, exactly.

00:27:38.200 --> 00:27:39.200
Awesome.

00:27:39.200 --> 00:27:40.200
Okay.

00:27:40.200 --> 00:27:41.200
All right.

00:27:41.200 --> 00:27:45.280
So kind of a more complex performance optimization is using tagged unions.

00:27:45.280 --> 00:27:46.280
They're still pretty simple.

00:27:46.280 --> 00:27:49.760
It's just like a little bit more than a one line change.

00:27:49.760 --> 00:27:54.360
So kind of talking about tagged unions, we can go through a basic example, why we're

00:27:54.360 --> 00:27:59.500
using tagged unions in the first place, and then some more advanced examples.

00:27:59.500 --> 00:28:03.720
This portion of talk Python to me is brought to you by code comments and original podcast

00:28:03.720 --> 00:28:05.160
from Red Hat.

00:28:05.160 --> 00:28:08.800
You know, when you're working on a project and you leave behind a small comment in the

00:28:08.800 --> 00:28:14.000
code, maybe you're hoping to help others learn what isn't clear at first.

00:28:14.000 --> 00:28:18.280
Sometimes that code comment tells a story of a challenging journey to the current state

00:28:18.280 --> 00:28:19.520
of the project.

00:28:19.520 --> 00:28:25.400
Code comments, the podcast features technologists who've been through tough tech transitions,

00:28:25.400 --> 00:28:28.000
and they share how their teams survived that journey.

00:28:28.000 --> 00:28:32.560
The host Jamie Parker is a Red Hatter and an experienced engineer.

00:28:32.560 --> 00:28:37.200
In each episode, Jamie recounts the stories of technologists from across the industry

00:28:37.200 --> 00:28:40.280
who've been on a journey implementing new technologies.

00:28:40.280 --> 00:28:45.560
I recently listened to an episode about DevOps from the folks at Worldwide Technology.

00:28:45.560 --> 00:28:50.260
The hardest challenge turned out to be getting buy in on the new tech stack rather than using

00:28:50.260 --> 00:28:52.400
that tech stack directly.

00:28:52.400 --> 00:28:54.280
It's a message that we can all relate to.

00:28:54.280 --> 00:28:58.120
And I'm sure you can take some hard one lessons back to your own team.

00:28:58.120 --> 00:29:00.000
Give code comments a listen.

00:29:00.000 --> 00:29:07.200
Search for code comments in your podcast player or just use our link, talkpython.fm/code-comments.

00:29:07.200 --> 00:29:09.880
The link is in your podcast player's show notes.

00:29:09.880 --> 00:29:14.560
Thank you to code comments and Red Hat for supporting Talk Python to Me.

00:29:14.560 --> 00:29:16.760
Let's start with what are tag unions because I honestly have no idea.

00:29:16.760 --> 00:29:19.520
I know what unions are, but tagging them, I don't know.

00:29:19.520 --> 00:29:20.960
Yeah, sure thing.

00:29:20.960 --> 00:29:24.120
So tag unions are a special type of union.

00:29:24.120 --> 00:29:26.880
We also call them discriminated unions.

00:29:26.880 --> 00:29:33.480
And they help you specify a member of a model that you can use for discrimination in your

00:29:33.480 --> 00:29:34.760
validation.

00:29:34.760 --> 00:29:40.320
So what that means is if you have two models that are pretty similar, and your field can

00:29:40.320 --> 00:29:46.800
be either one of those types of models, model X or model Y, but you know that there's one

00:29:46.800 --> 00:29:52.000
tag or like discriminator field that differs, you can specifically validate against that

00:29:52.000 --> 00:29:54.560
field and skip some of the other validation, right?

00:29:54.560 --> 00:30:00.600
So like, I'll move on to an example here in a second, but basically it helps you validate

00:30:00.600 --> 00:30:03.600
more efficiently because you get to skip validation of some fields.

00:30:03.600 --> 00:30:06.800
So it's really helpful if you have models that have like 100 fields, but one of them

00:30:06.800 --> 00:30:09.080
is really indicative of what type it might be.

00:30:09.080 --> 00:30:10.080
I see.

00:30:10.080 --> 00:30:14.480
So instead of trying to figure out like, is it all of this stuff, once you know it has

00:30:14.480 --> 00:30:18.760
this aspect or that aspect, then you can sort of branch it on a path and just treat it as

00:30:18.760 --> 00:30:20.200
one of the elements of the union.

00:30:20.200 --> 00:30:21.200
Is that right?

00:30:21.200 --> 00:30:22.200
Yes, exactly.

00:30:22.200 --> 00:30:23.200
Okay.

00:30:23.200 --> 00:30:28.400
So one other note about discriminated unions is you specify this discriminator and it can

00:30:28.400 --> 00:30:31.880
either be a string, like literal type or callable type.

00:30:31.880 --> 00:30:33.380
And we'll look at some examples of both.

00:30:33.380 --> 00:30:38.180
So here's kind of a more concrete example so we can really better understand this.

00:30:38.180 --> 00:30:41.680
So let's say we have a, this is the classic example, right?

00:30:41.680 --> 00:30:43.640
A cat model and a dog model.

00:30:43.640 --> 00:30:44.640
Yeah.

00:30:44.640 --> 00:30:45.640
Cat people, dog people.

00:30:45.640 --> 00:30:47.600
You're going to start a debate here.

00:30:47.600 --> 00:30:48.600
Exactly, exactly.

00:30:48.600 --> 00:30:52.120
They both have this pet type field.

00:30:52.120 --> 00:30:56.520
So for the cat model, it's a literal that is just the string cat.

00:30:56.520 --> 00:30:59.720
And then for the dog model, it's the literal that's the string dog.

00:30:59.720 --> 00:31:03.880
So it's just kind of a flag on a model to indicate what type it is.

00:31:03.880 --> 00:31:07.480
And you can imagine, you know, in this basic case, we only have a couple of fields attached

00:31:07.480 --> 00:31:13.200
to each model, but maybe this is like data in a like vet database.

00:31:13.200 --> 00:31:16.600
And so you can imagine like there's going to be tons of fields attached to this, right?

00:31:16.600 --> 00:31:20.200
So it'd be pretty helpful to just be able to look at it and say, oh, the pet type is

00:31:20.200 --> 00:31:21.200
dog.

00:31:21.200 --> 00:31:23.560
So this data is valid for a dog type.

00:31:23.560 --> 00:31:26.880
I'll also note we have a lizard in here.

00:31:26.880 --> 00:31:33.720
So what this looks like in terms of validation with Pydantic then is that when we specify

00:31:33.720 --> 00:31:39.320
this pet field, we just add one extra setting, which says that the discriminator is that

00:31:39.320 --> 00:31:40.320
pet type field.

00:31:40.320 --> 00:31:46.000
And so then when we pass in data that corresponds to a dog model, Pydantic is smart enough to

00:31:46.000 --> 00:31:48.580
say, oh, this is a discriminated union field.

00:31:48.580 --> 00:31:54.440
Let me go look for the pet type field on the model and just see what that is and then use

00:31:54.440 --> 00:31:58.560
that to inform my decision for what type I should validate against.

00:31:58.560 --> 00:32:00.000
OK, that's awesome.

00:32:00.000 --> 00:32:07.240
So if we don't set the discriminator keyword value in the field for the union, it'll still

00:32:07.240 --> 00:32:08.240
work, right?

00:32:08.240 --> 00:32:10.680
It just has to be more exhaustive and slow.

00:32:10.680 --> 00:32:11.680
Yeah, exactly.

00:32:11.680 --> 00:32:16.620
So it'll still validate and it'll say, hey, let's take this input data and try to validate

00:32:16.620 --> 00:32:18.240
it against the cat model.

00:32:18.240 --> 00:32:20.840
And then Pydantic will come back and say, oh, that's not a valid cat.

00:32:20.840 --> 00:32:22.720
Like let's try the next one.

00:32:22.720 --> 00:32:27.840
Whereas with this discriminated pattern, we can skip right to the dog, which you can imagine

00:32:27.840 --> 00:32:29.840
helps us skip some of the unnecessary steps.

00:32:29.840 --> 00:32:30.840
Yeah, absolutely.

00:32:30.840 --> 00:32:31.840
OK, that's really cool.

00:32:31.840 --> 00:32:32.840
I had no idea about this.

00:32:32.840 --> 00:32:33.840
Yeah, yeah.

00:32:33.840 --> 00:32:36.880
It's a cool, I'd say like moderate level feature.

00:32:36.880 --> 00:32:40.660
Like I think if you're just starting to use Pydantic, you probably haven't touched discriminated

00:32:40.660 --> 00:32:44.840
unions much, but we hope that it's simple enough to implement that most folks can use

00:32:44.840 --> 00:32:46.160
it if they're using unions.

00:32:46.160 --> 00:32:47.160
Yeah, that's cool.

00:32:47.160 --> 00:32:52.000
I don't use unions very often, which is probably why, other than, you know, symptom pipe none,

00:32:52.000 --> 00:32:53.280
which is, you know, like optional.

00:32:53.280 --> 00:32:57.600
But yeah, if I did, I'll definitely remember this.

00:32:57.600 --> 00:32:58.600
Yeah.

00:32:58.600 --> 00:32:59.600
All righty.

00:32:59.600 --> 00:33:03.000
So as I've mentioned, this helps for more efficient validation.

00:33:03.000 --> 00:33:07.160
And then where this really comes and has a lot of value is when you are dealing with

00:33:07.160 --> 00:33:10.560
lots of nested models or models that have tons of fields.

00:33:10.560 --> 00:33:15.080
So let's say you have a union with like 10 members and each member of the union has 100

00:33:15.080 --> 00:33:16.080
fields.

00:33:16.080 --> 00:33:19.880
If you could just do validation against 100 fields instead of a thousand, that would be

00:33:19.880 --> 00:33:22.760
great in terms of a performance gain.

00:33:22.760 --> 00:33:27.040
And then once again, with nested models, you know, if you can skip lots of those union

00:33:27.040 --> 00:33:29.400
member validations, also going to boost your performance.

00:33:29.400 --> 00:33:30.400
Yeah, for sure.

00:33:30.400 --> 00:33:35.680
You know, an example where this seems very likely would be using it with Beanie or some

00:33:35.680 --> 00:33:40.880
other document database where the modeling structure is very hierarchical.

00:33:40.880 --> 00:33:45.360
You end up with a lot of nested sub-Pydantic models in there.

00:33:45.360 --> 00:33:48.400
Yeah, very much so.

00:33:48.400 --> 00:33:52.240
So as a little bit of an added benefit, we can talk about kind of this improved error

00:33:52.240 --> 00:33:57.060
handling, which is a great way to kind of visualize why the discriminated union pattern

00:33:57.060 --> 00:33:58.580
is more efficient.

00:33:58.580 --> 00:34:03.440
So right now we're looking at an example of validation against a model that doesn't use

00:34:03.440 --> 00:34:05.160
a discriminated union.

00:34:05.160 --> 00:34:07.840
And the errors are not very nice to look at.

00:34:07.840 --> 00:34:13.360
You basically see the errors for every single permutation of the different values.

00:34:13.360 --> 00:34:17.480
And we're using nested models, so it's very hard to interpret.

00:34:17.480 --> 00:34:19.120
So we don't have to look at this for too long.

00:34:19.120 --> 00:34:20.840
It's not very nice.

00:34:20.840 --> 00:34:22.560
But if we look at...

00:34:22.560 --> 00:34:26.360
But basically the error message says, look, there's something wrong with the union.

00:34:26.360 --> 00:34:28.960
If it was a string, it is missing these things.

00:34:28.960 --> 00:34:31.360
If it was this kind of thing, it misses those things.

00:34:31.360 --> 00:34:33.160
Like if it was a dog, it misses this.

00:34:33.160 --> 00:34:35.440
If it's a cat, it misses that.

00:34:35.440 --> 00:34:38.000
And it doesn't specifically tell you.

00:34:38.000 --> 00:34:39.000
Exactly.

00:34:39.000 --> 00:34:43.240
It's a dog, so it's missing like the collar size or whatever, right?

00:34:43.240 --> 00:34:44.240
Exactly.

00:34:44.240 --> 00:34:45.240
But then...

00:34:45.240 --> 00:34:49.400
And I'll go back and kind of explain the discriminated model for this case in a second.

00:34:49.400 --> 00:34:50.600
But if you look at...

00:34:50.600 --> 00:34:54.240
This is the model with the discriminated union instead.

00:34:54.240 --> 00:35:00.360
We have one very nice error that says, okay, you're trying to validate this X field and

00:35:00.360 --> 00:35:03.200
it's the wrong type, right?

00:35:03.200 --> 00:35:05.160
So yeah.

00:35:05.160 --> 00:35:09.040
The first example that we were looking at was using string type discriminators.

00:35:09.040 --> 00:35:13.640
So we just had this pet type thing that said, oh, this is a cat or this is a dog, that sort

00:35:13.640 --> 00:35:14.640
of thing.

00:35:14.640 --> 00:35:19.200
We also offer some more customization in terms of...

00:35:19.200 --> 00:35:21.960
We also allow callable discriminators.

00:35:21.960 --> 00:35:29.360
So in this case, this field can be either a string or this instance of discriminated

00:35:29.360 --> 00:35:30.360
model.

00:35:30.360 --> 00:35:32.120
So it's kind of a recursive pattern, right?

00:35:32.120 --> 00:35:38.060
And that's where you can imagine the nested structures becoming very complex very easily.

00:35:38.060 --> 00:35:44.560
And we use this kind of callable to differentiate between which model we should validate against.

00:35:44.560 --> 00:35:47.320
And then we tag each of the cases.

00:35:47.320 --> 00:35:50.240
So a little bit more of a complex application here.

00:35:50.240 --> 00:35:54.160
But once again, when you kind of see the benefit in terms of errors and interpreting things

00:35:54.160 --> 00:35:57.680
and performance, I think it's generally a worthwhile investment.

00:35:57.680 --> 00:35:58.680
That's cool.

00:35:58.680 --> 00:36:04.400
So if you wanted something like a composite key equivalent of a discriminator, right?

00:36:04.400 --> 00:36:10.600
Like if it has this field and its nested model is of this type, it's one thing versus another.

00:36:10.600 --> 00:36:15.240
Like a free user versus a paying user, you might have to look and see their total lifetime

00:36:15.240 --> 00:36:18.480
value plus that they're a registered user.

00:36:18.480 --> 00:36:19.480
I don't know, something like that.

00:36:19.480 --> 00:36:22.960
You could write code that would pull that information out and then discriminate which

00:36:22.960 --> 00:36:24.920
thing to validate against, right?

00:36:24.920 --> 00:36:25.920
Yeah, exactly.

00:36:25.920 --> 00:36:28.120
Yeah, definitely comes in handy when you have like...

00:36:28.120 --> 00:36:32.560
You're like, okay, well, I still want the performance benefits of a discriminated union,

00:36:32.560 --> 00:36:36.480
but I kind of have three fields on each model that are indicative of which one I should

00:36:36.480 --> 00:36:37.480
validate against, right?

00:36:37.480 --> 00:36:41.880
And it's like, well, you know, taking the time to look at those three fields over the

00:36:41.880 --> 00:36:44.200
hundred is definitely worth it.

00:36:44.200 --> 00:36:48.000
Just a little bit of complexity for the developer.

00:36:48.000 --> 00:36:50.440
One other note here is that discriminated unions are...

00:36:50.440 --> 00:36:52.560
Can we go back really quick on the previous one?

00:36:52.560 --> 00:36:53.600
So I got a quick question.

00:36:53.600 --> 00:36:56.080
So for this, you write a function.

00:36:56.080 --> 00:37:02.520
It's given the value that comes in, which could be a string, it could be a dictionary.

00:37:02.520 --> 00:37:09.720
Could you do a little bit further performance improvements and add like a func tools, LRU

00:37:09.720 --> 00:37:11.640
cache to cache the output?

00:37:11.640 --> 00:37:15.480
So every time it sees the same thing, if there's a repeated data through your validation, it

00:37:15.480 --> 00:37:16.720
goes, I already know what it is.

00:37:16.720 --> 00:37:17.720
What do you think?

00:37:17.720 --> 00:37:19.640
Yeah, I do think that would be possible.

00:37:19.640 --> 00:37:24.200
That's definitely an optimization we should try out and put in our docs for like the advanced,

00:37:24.200 --> 00:37:25.200
advanced performance tips.

00:37:25.200 --> 00:37:31.920
Yeah, because if you've got a thousand strings and then you, you know, that were like it's

00:37:31.920 --> 00:37:35.440
going to be male, female, male, female, male, male, female, like that kind of where the

00:37:35.440 --> 00:37:37.960
data is repeated a bunch.

00:37:37.960 --> 00:37:40.960
Then it could just go, yep, we already know that answer.

00:37:40.960 --> 00:37:41.960
Yeah.

00:37:41.960 --> 00:37:43.640
That'd be potentially, I don't know.

00:37:43.640 --> 00:37:44.720
Yeah, no, definitely.

00:37:44.720 --> 00:37:47.560
And I will say, I don't know if it takes effect.

00:37:47.560 --> 00:37:53.040
I don't think it takes effect with discriminated unions because this logic is kind of in Python,

00:37:53.040 --> 00:37:57.960
but I will say we recently added a like string caching setting because we have kind of our

00:37:57.960 --> 00:38:01.400
own JSON parsing logic that we use in Pydantic Core.

00:38:01.400 --> 00:38:05.720
And so we added a string caching setting so that you don't have to rebuild the exact same

00:38:05.720 --> 00:38:07.560
strings every time.

00:38:07.560 --> 00:38:09.240
So that's a nice performance piece.

00:38:09.240 --> 00:38:10.240
Yeah, nice.

00:38:10.240 --> 00:38:11.240
Caching's awesome.

00:38:11.240 --> 00:38:12.240
Until it's not.

00:38:12.240 --> 00:38:14.160
Yeah, exactly.

00:38:14.160 --> 00:38:19.080
So one quick note here is just that discriminated unions are still JSON schema compatible, which

00:38:19.080 --> 00:38:24.240
is awesome for the case where you're once again, defining like API requests and responses.

00:38:24.240 --> 00:38:27.080
You want to still have valid JSON schema coming out of your models.

00:38:27.080 --> 00:38:28.080
Yeah, very cool.

00:38:28.080 --> 00:38:34.200
And that might show up in things like open API documentation and stuff like that, right?

00:38:34.200 --> 00:38:35.800
Yep, exactly.

00:38:35.800 --> 00:38:37.120
So I'll kind of skip over this.

00:38:37.120 --> 00:38:39.680
We already touched on the callable discriminators.

00:38:39.680 --> 00:38:43.600
And then I'll leave these slides up here as a reference.

00:38:43.600 --> 00:38:48.000
Again, I don't think this is worth touching in too much detail, but just kind of another

00:38:48.000 --> 00:38:53.760
comment about if you've got nested models, that still works well with discriminated unions.

00:38:53.760 --> 00:38:58.840
So we're still on the pet example, but let's say this time you have a white cat and a black

00:38:58.840 --> 00:39:00.400
cat model.

00:39:00.400 --> 00:39:03.640
And then you also have your existing dog model.

00:39:03.640 --> 00:39:09.760
You can still create a union of, you know, your cat union is a union of black cat and

00:39:09.760 --> 00:39:10.760
white cat.

00:39:10.760 --> 00:39:13.640
And then you can union that with the dogs and it still works.

00:39:13.640 --> 00:39:18.760
And once again, you can kind of imagine the exponential blow up that would occur if you

00:39:18.760 --> 00:39:21.160
didn't use some sort of discriminator here in terms of errors.

00:39:21.160 --> 00:39:22.760
Yeah, very interesting.

00:39:22.760 --> 00:39:23.760
OK, cool.

00:39:23.760 --> 00:39:24.760
Yeah.

00:39:24.760 --> 00:39:30.360
So that's kind of all in terms of my recommendations for discriminated union application.

00:39:30.360 --> 00:39:34.480
I would encourage folks who are interested in this to check out our documentation.

00:39:34.480 --> 00:39:35.800
It's pretty thorough in that regard.

00:39:35.800 --> 00:39:38.520
And I think we also have those links attached to the podcast.

00:39:38.520 --> 00:39:39.520
Yeah, definitely.

00:39:39.520 --> 00:39:42.000
And then performance improvements in the pipeline.

00:39:42.000 --> 00:39:44.640
Is this something that we can control from the outside?

00:39:44.640 --> 00:39:47.240
Is this something that you all are just adding for us?

00:39:47.240 --> 00:39:48.640
Yeah, good question.

00:39:48.640 --> 00:39:53.320
This is hopefully maybe not all in the next version, but just kind of things we're keeping

00:39:53.320 --> 00:39:57.800
our eyes on in terms of requested performance improvements and ideas that we have.

00:39:57.800 --> 00:40:00.040
I'll go a little bit out of order here.

00:40:00.040 --> 00:40:04.000
We've been talking a bunch about core schema and kind of, you know, maybe deferring the

00:40:04.000 --> 00:40:07.680
build of that or, you know, just trying to optimize that.

00:40:07.680 --> 00:40:09.740
And that actually happens in Python.

00:40:09.740 --> 00:40:14.000
So one of the biggest things that we're trying to do is effectively speed up the core schema

00:40:14.000 --> 00:40:19.320
building process so that import times are faster and just, you know, Pydantic is more

00:40:19.320 --> 00:40:21.720
performant in general.

00:40:21.720 --> 00:40:28.880
So one thing that I'd like to ask about, kind of back on the Python side a little bit, suppose

00:40:28.880 --> 00:40:32.340
I've got some really large document, right?

00:40:32.340 --> 00:40:33.340
Really nested document.

00:40:33.340 --> 00:40:38.660
Maybe I've converted some terrible XML thing into JSON or I don't know, something.

00:40:38.660 --> 00:40:42.080
And there's a little bit of structured schema that I care about.

00:40:42.080 --> 00:40:47.640
And then there's a whole bunch of other stuff that I could potentially create nested models

00:40:47.640 --> 00:40:49.960
to go to, but I don't really care about validating them.

00:40:49.960 --> 00:40:52.040
It's just whatever it is, it is.

00:40:52.040 --> 00:40:54.000
What if you just said that was a dictionary?

00:40:54.000 --> 00:40:58.120
Would that short circuit a whole bunch of validation and stuff that would make it faster

00:40:58.120 --> 00:40:59.120
potentially?

00:40:59.120 --> 00:41:00.120
Yeah.

00:41:00.120 --> 00:41:05.000
Turn off the validation for a subset of the model if it's really big and deep and you

00:41:05.000 --> 00:41:06.280
don't really care for that part?

00:41:06.280 --> 00:41:07.280
Yeah.

00:41:07.280 --> 00:41:08.280
Good question.

00:41:08.280 --> 00:41:13.320
So there's an annotation called skip validation that you can apply to certain types.

00:41:13.320 --> 00:41:15.000
So that's kind of one approach.

00:41:15.000 --> 00:41:18.800
I think in the future, it could be nice to offer kind of a config setting so that you

00:41:18.800 --> 00:41:23.840
can more easily list features that you want to skip validation for instead of applying

00:41:23.840 --> 00:41:26.320
those on a field by field basis.

00:41:26.320 --> 00:41:30.520
And then the other thing is if you only define your model in terms of the fields that you

00:41:30.520 --> 00:41:36.460
really care about from that very gigantic amount of data, we will just ignore the extra

00:41:36.460 --> 00:41:39.800
data that you pass in and pull out the relevant information.

00:41:39.800 --> 00:41:40.800
Right.

00:41:40.800 --> 00:41:41.800
Okay.

00:41:41.800 --> 00:41:42.800
Yeah.

00:41:42.800 --> 00:41:43.800
Good.

00:41:43.800 --> 00:41:44.800
Back to the pipeline.

00:41:44.800 --> 00:41:45.800
Yeah.

00:41:45.800 --> 00:41:46.800
Back to the pipeline.

00:41:46.800 --> 00:41:51.200
So another improvement, we talked a little bit about potential parallelization of things

00:41:51.200 --> 00:41:52.700
or vectorization.

00:41:52.700 --> 00:41:56.000
One thing that I'm excited to learn more about in the future and that we've started working

00:41:56.000 --> 00:41:59.040
on is this thing called SIMD in Jitter.

00:41:59.040 --> 00:42:02.920
And that's our JSON iterable parser library that I was talking about.

00:42:02.920 --> 00:42:07.100
And so SIMD stands for a single instruction, multiple data.

00:42:07.100 --> 00:42:10.560
Basically means that you can do operations faster.

00:42:10.560 --> 00:42:12.840
And that's with this kind of vectorization approach.

00:42:12.840 --> 00:42:19.120
I certainly don't claim to be an expert in SIMD, but I know that it's improving our validation

00:42:19.120 --> 00:42:22.200
speeds in the department of JSON parsing.

00:42:22.200 --> 00:42:28.080
So that's something that we're hoping to support for a broader set of architectures going forward.

00:42:28.080 --> 00:42:30.020
Yeah, that's really cool.

00:42:30.020 --> 00:42:34.660
Just like what Pandas does for Python, instead of looping over and validation and doing something

00:42:34.660 --> 00:42:38.020
to each piece, you just go this whole column, multiply it by two.

00:42:38.020 --> 00:42:39.020
Yep.

00:42:40.020 --> 00:42:41.020
Exactly.

00:42:41.020 --> 00:42:42.420
I'm sure it's not implemented the same, but like conceptually the same.

00:42:42.420 --> 00:42:43.420
Yep.

00:42:44.420 --> 00:42:45.420
Very much so.

00:42:45.420 --> 00:42:49.060
And then the other two things in the pipeline that I'm going to mention are kind of related

00:42:49.060 --> 00:42:53.860
once again to the avoiding materializing things in Python if we can.

00:42:53.860 --> 00:42:58.620
And we're even kind of extending that to avoiding materializing things in Rust if we don't have

00:42:58.620 --> 00:42:59.620
to.

00:42:59.620 --> 00:43:03.740
So the first thing is when we're parsing JSON in Rust, can we just do the validation as

00:43:03.740 --> 00:43:09.220
we kind of chomp through the JSON instead of like materializing the JSON as a Rust object

00:43:09.220 --> 00:43:10.540
and then doing all the validation?

00:43:10.540 --> 00:43:12.900
It's like, can we just do it in one pass?

00:43:12.900 --> 00:43:13.900
Okay.

00:43:13.900 --> 00:43:19.420
Is that almost like generators and iterables rather than loading all into memory at once

00:43:19.420 --> 00:43:21.780
and then processing it one at a time?

00:43:21.780 --> 00:43:22.780
Yeah, exactly.

00:43:22.780 --> 00:43:28.100
And it's kind of like, do you build the tree and then walk it three times or do you just

00:43:28.100 --> 00:43:32.780
do your operations every time you add something to the tree?

00:43:32.780 --> 00:43:35.740
And then the last performance improvement in the pipeline that I'll mention is this

00:43:35.740 --> 00:43:37.780
thing called fast model.

00:43:37.780 --> 00:43:39.540
Has not been released yet.

00:43:39.540 --> 00:43:44.300
Hasn't really even been significantly developed, but this is cool in that it's really approaching

00:43:44.300 --> 00:43:46.100
that kind of laziness concept again.

00:43:46.100 --> 00:43:51.680
So attributes would remain in Rust after validation until they're requested.

00:43:51.680 --> 00:43:55.180
So this is kind of along the lines of the defer build logic that we were talking about

00:43:55.180 --> 00:43:59.240
in terms of like, we're not going to send you the data or perform the necessary operations

00:43:59.240 --> 00:44:00.980
until they're requested.

00:44:00.980 --> 00:44:01.980
Right.

00:44:01.980 --> 00:44:02.980
Okay.

00:44:02.980 --> 00:44:03.980
Yeah.

00:44:03.980 --> 00:44:05.980
If you don't ever access the field, then why process all that stuff, right?

00:44:05.980 --> 00:44:07.540
And convert it into Python objects.

00:44:07.540 --> 00:44:08.540
Yeah, exactly.

00:44:08.540 --> 00:44:14.300
But yeah, we're kind of just excited in general to be looking at lots of performance improvements

00:44:14.300 --> 00:44:18.460
on our end, even after the big V2 speed up, still have lots of other things to work on

00:44:18.460 --> 00:44:19.460
and improve.

00:44:19.460 --> 00:44:21.540
Yeah, it sure seems like it.

00:44:21.540 --> 00:44:27.940
And if this free threaded Python thing takes off, who knows, maybe there's even more craziness

00:44:27.940 --> 00:44:34.220
with parallel processing of different branches of the model at different, you know, alongside

00:44:34.220 --> 00:44:35.220
each other.

00:44:35.220 --> 00:44:36.220
Yeah.

00:44:36.220 --> 00:44:41.100
So I think this kind of dovetails nicely into like you asked earlier, like, is there a way

00:44:41.100 --> 00:44:45.460
that we kind of monitor the performance improvements that we're making?

00:44:45.460 --> 00:44:51.460
And we're currently using and getting started with two tools that are really helpful.

00:44:51.460 --> 00:44:55.500
And I can share some PRs if that's helpful, send links after.

00:44:55.500 --> 00:45:02.900
But one of them is Codspeed, which integrates super nicely with CI and GitHub.

00:45:02.900 --> 00:45:08.380
And it basically runs tests tagged with this like benchmark tag.

00:45:08.380 --> 00:45:11.980
And then it'll, you know, run them on main compared to on your branch.

00:45:11.980 --> 00:45:16.660
And then you can see like, oh, this made my code, you know, 30% slower, like maybe let's

00:45:16.660 --> 00:45:18.460
not merge that right away.

00:45:18.460 --> 00:45:23.500
Or conversely, if you know there's a 30% improvement on some of your benchmarks, it's really nice

00:45:23.500 --> 00:45:25.180
to kind of track and see that.

00:45:25.180 --> 00:45:26.180
I see.

00:45:26.180 --> 00:45:27.180
So it looks like it sets up.

00:45:27.180 --> 00:45:31.020
So this is a Codspeed.io, right?

00:45:31.020 --> 00:45:36.220
And then it sets up as a GitHub action as part of your CI/CD.

00:45:36.220 --> 00:45:40.620
And you know, probably automatically runs when a PR is open and things along those lines,

00:45:40.620 --> 00:45:41.620
right?

00:45:41.620 --> 00:45:42.620
Yep, exactly.

00:45:42.620 --> 00:45:43.620
All right.

00:45:43.620 --> 00:45:44.620
I've never heard of this.

00:45:44.620 --> 00:45:48.260
But yeah, if it just does the performance testing for yourself automatically, why not?

00:45:48.260 --> 00:45:49.260
Right?

00:45:49.260 --> 00:45:50.260
Let it let it do that.

00:45:50.260 --> 00:45:51.260
Yeah.

00:45:51.260 --> 00:45:57.260
And then I guess another tool that I'll mention while talking about kind of our, you know,

00:45:57.260 --> 00:46:03.300
continuous optimization is a one word for it is this tool kind of similarly named called

00:46:03.300 --> 00:46:05.300
CodeFlash.

00:46:05.300 --> 00:46:12.780
So CodeFlash is a new tool that uses LLMs to kind of read your code and then develop

00:46:12.780 --> 00:46:15.540
potentially more performant versions.

00:46:15.540 --> 00:46:20.940
Kind of analyze those in terms of, you know, is it pass is this new code passing existing

00:46:20.940 --> 00:46:21.940
tests?

00:46:21.940 --> 00:46:24.660
Is it passing additional tests that we write?

00:46:24.660 --> 00:46:28.900
And then another great thing that it does is open PRs for you with those improvements

00:46:28.900 --> 00:46:31.020
and then explain the improvements.

00:46:31.020 --> 00:46:34.900
So I think it's a really pioneering tool in the space.

00:46:34.900 --> 00:46:40.380
And we're excited to kind of experiment with it more on our PRs and in our repository.

00:46:40.380 --> 00:46:41.380
Okay.

00:46:41.380 --> 00:46:42.900
I love it.

00:46:42.900 --> 00:46:44.300
Just tell me why is this?

00:46:44.300 --> 00:46:45.300
Why did this slow down?

00:46:45.300 --> 00:46:46.300
Well, here's why.

00:46:46.300 --> 00:46:47.300
Yeah, exactly.

00:46:47.300 --> 00:46:48.300
Yeah.

00:46:48.300 --> 00:46:54.340
And they offer both like local runs of the tool and also built in CI support.

00:46:54.340 --> 00:46:59.460
So those are just kind of two tools that we use to use and are increasingly using to help

00:46:59.460 --> 00:47:05.060
us kind of check our performance as we continue to develop and really inspire us to, you know,

00:47:05.060 --> 00:47:10.500
get those green check marks with the like performance improved on lots of PRs.

00:47:10.500 --> 00:47:15.700
The more you can have it where if it passes the automated build, it's just ready to go

00:47:15.700 --> 00:47:20.180
and you don't have to worry a little bit and keep testing things and then have uncertainty.

00:47:20.180 --> 00:47:21.180
You know that.

00:47:21.180 --> 00:47:22.180
It's nice, right?

00:47:22.180 --> 00:47:25.660
Because you're allowed to rest and sleep at night.

00:47:25.660 --> 00:47:27.100
Yeah, most certainly.

00:47:27.100 --> 00:47:33.860
I mean, I said it before, but the number of people who are impacted by Pydantic, I don't

00:47:33.860 --> 00:47:37.540
know what that number is, but it has to be tremendous because if there's 400,000 projects

00:47:37.540 --> 00:47:40.420
that use it, like think of the users of those projects, right?

00:47:40.420 --> 00:47:43.780
Like that, that multiple has got to be big for, you know, I'm sure there's some really

00:47:43.780 --> 00:47:45.780
popular ones, for example, FastAPI.

00:47:45.780 --> 00:47:46.780
Yeah.

00:47:48.780 --> 00:47:52.860
And it's just nice to know that there are other companies and tools out there that can

00:47:52.860 --> 00:47:57.620
help us to really boost the performance benefits for all those users, which is great.

00:47:57.620 --> 00:47:58.620
All right.

00:47:58.620 --> 00:47:59.900
Yeah, that is really cool.

00:47:59.900 --> 00:48:04.980
I think, you know, let's talk about one more performance benefit for people and not so

00:48:04.980 --> 00:48:11.820
much in how fast your code runs, but in how fast you go from raw data to Pydantic models.

00:48:11.820 --> 00:48:16.820
So one thing you probably have seen, we may have even spoken about this before, are you

00:48:16.820 --> 00:48:18.860
familiar with JSON to Pydantic?

00:48:18.860 --> 00:48:19.860
The website?

00:48:19.860 --> 00:48:20.860
Yeah, it's a really cool tool.

00:48:20.860 --> 00:48:21.860
Yeah, it's such a cool tool.

00:48:21.860 --> 00:48:26.980
And if you've got some really complicated data, like let's see, I'll pull up some weather

00:48:26.980 --> 00:48:29.740
data that's in JSON format or something, right?

00:48:29.740 --> 00:48:33.700
Like if you just take this and you throw it in here, just don't even have to pretty print

00:48:33.700 --> 00:48:38.620
it, it'll just go, okay, well, it looks like what we've got is, you know, this really complicated

00:48:38.620 --> 00:48:40.460
nested model here.

00:48:40.460 --> 00:48:44.380
And it took, you know, we did this while I was talking, it took 10 seconds for me clicking

00:48:44.380 --> 00:48:49.220
the API to get a response to having like a pretty decent representation here.

00:48:49.220 --> 00:48:53.300
Yeah, it's great in terms of like developer agility, especially, right?

00:48:53.300 --> 00:48:55.980
It's like, oh, I've, you know, heard of this tool called Pydantic.

00:48:55.980 --> 00:48:59.780
I've seen it in places like, I don't really know if I want to manually go build all these

00:48:59.780 --> 00:49:02.260
models for my super complicated JSON data.

00:49:02.260 --> 00:49:05.380
It's like, boom, three seconds done for you, basically.

00:49:05.380 --> 00:49:06.380
Exactly.

00:49:06.380 --> 00:49:07.780
Like, is it really worth it?

00:49:07.780 --> 00:49:11.620
Because I don't want to have to figure this thing out and figure out all the types and

00:49:11.620 --> 00:49:13.820
like, no, just paste it in there and see what you get.

00:49:13.820 --> 00:49:15.780
You're going to be, it won't be perfect, right?

00:49:15.780 --> 00:49:19.340
Some things, if they're null in your data, but they could be something that would make

00:49:19.340 --> 00:49:22.700
them an optional element, like they could be an integer or they could be null.

00:49:22.700 --> 00:49:25.580
It won't know that it's going to be an integer, right?

00:49:25.580 --> 00:49:26.580
Right.

00:49:26.580 --> 00:49:30.900
So you kind of got to patch it up a tiny bit, but in general, I think this is really good.

00:49:30.900 --> 00:49:36.020
And then also, you know, just drop in with your, your favorite LLM, you know, I've been

00:49:36.020 --> 00:49:37.980
using LM studio, which is awesome.

00:49:37.980 --> 00:49:38.980
Nice.

00:49:38.980 --> 00:49:42.500
I heard you talk about that on one of the most recent podcasts, right?

00:49:42.500 --> 00:49:43.500
Yeah.

00:49:44.500 --> 00:49:45.500
It's super cool.

00:49:45.500 --> 00:49:49.140
You can download, just download LLAMA3 and run it locally with like a, I think my, my

00:49:49.140 --> 00:49:53.100
computer can only handle 7 billion parameter models, but you know that you get pretty good

00:49:53.100 --> 00:49:57.300
answers and if you give it a JSON, a piece of JSON data and you say, convert that to

00:49:57.300 --> 00:50:00.220
Pydantic, you'll get really good results.

00:50:00.220 --> 00:50:03.700
You have a little more control over than what you just get with this, this tool.

00:50:03.700 --> 00:50:09.020
But I think those two things, while not about runtime performance, you know, going from

00:50:09.020 --> 00:50:12.660
I have data till I'm working with Pydantic, that's pretty awesome.

00:50:12.660 --> 00:50:13.660
Yeah, definitely.

00:50:13.660 --> 00:50:18.940
And if any, you know, passionate open source contributors are listening and want to create

00:50:18.940 --> 00:50:23.220
like a CLI tool for doing this locally, I'm sure that would be.

00:50:23.220 --> 00:50:29.420
I think this is based on something that I don't use, but I think it's based on this

00:50:29.420 --> 00:50:34.820
data model code generator, which I think might be a CLI tool or a library.

00:50:34.820 --> 00:50:35.820
Let's see.

00:50:35.820 --> 00:50:36.820
Yes.

00:50:36.820 --> 00:50:37.820
Oh yeah.

00:50:37.820 --> 00:50:38.820
Very nice.

00:50:38.820 --> 00:50:40.980
So here, here's the problem that you, you know, you go and define like a YAML file.

00:50:40.980 --> 00:50:45.660
You know, like it's, it's just not as easy as like there's a text field I pasted my stuff,

00:50:45.660 --> 00:50:49.020
but it does technically, technically work, I suppose.

00:50:49.020 --> 00:50:50.020
Yeah.

00:50:50.020 --> 00:50:51.020
I know.

00:50:51.020 --> 00:50:55.420
Definitely the LLM approach or just the basic website approach is very quick, which is nice.

00:50:55.420 --> 00:50:56.420
Yeah.

00:50:56.420 --> 00:50:57.420
Let's talk about LLMs just really quick.

00:50:57.420 --> 00:51:02.460
Like I feel, you know, you get some of the Python newsletters and other places that like,

00:51:02.460 --> 00:51:03.620
here's the cool new packages.

00:51:03.620 --> 00:51:07.420
A lot of them are like nine out of 10 of them are about LLMs these days.

00:51:07.420 --> 00:51:11.180
I was like, that feels a little over the top to me, but I know there's other things going

00:51:11.180 --> 00:51:15.660
on in the world, but you know, just what are your thoughts on LLMs and encoding these days?

00:51:15.660 --> 00:51:19.580
I know you, you write a lot of code and think about it a lot and probably use LLM somewhere

00:51:19.580 --> 00:51:20.580
in there.

00:51:20.580 --> 00:51:21.580
Yeah, no, for sure.

00:51:21.580 --> 00:51:24.980
I, I'm pretty optimistic and excited about it.

00:51:24.980 --> 00:51:29.700
I think there's a lot of good that can be done and a lot of productivity boosting to

00:51:29.700 --> 00:51:34.380
be had from integrating with these tools, both in your like local development environment

00:51:34.380 --> 00:51:36.780
and also just in general.

00:51:36.780 --> 00:51:40.020
I think sometimes, you know, it's also great in the performance department, right?

00:51:40.020 --> 00:51:46.380
Like we can see with CodeFlash using LLMs to help you write for performant code can

00:51:46.380 --> 00:51:47.940
also be really useful.

00:51:47.940 --> 00:51:52.100
And it's been exciting to see some libraries really leverage Pydantic as well in that space

00:51:52.100 --> 00:51:58.700
in terms of like validating LLM outputs or even using LLM calls in Pydantic validators

00:51:58.700 --> 00:52:05.100
to validate, you know, data along constraints that are more like language model friendly.

00:52:05.100 --> 00:52:06.540
So yeah, I'm optimistic about it.

00:52:06.540 --> 00:52:10.740
I still have a lot to learn, but it's cool to see the variety of applications and kind

00:52:10.740 --> 00:52:13.500
of where you can plug in Pydantic in that process for fun.

00:52:13.500 --> 00:52:15.620
Yeah, I totally agree.

00:52:15.620 --> 00:52:20.940
Right now, the context window, like how much you can give it as information than to start

00:52:20.940 --> 00:52:23.220
asking questions is still a little bit small.

00:52:23.220 --> 00:52:27.340
Like you can't give it some huge program and say, you know, find me the bugs where this

00:52:27.340 --> 00:52:28.780
function is called or you know, whatever.

00:52:28.780 --> 00:52:31.500
And it like it doesn't quite understand enough all at once.

00:52:31.500 --> 00:52:33.860
But that thing keeps growing.

00:52:33.860 --> 00:52:36.100
So eventually, someday we'll all see.

00:52:36.100 --> 00:52:37.100
Yep.

00:52:37.100 --> 00:52:38.100
All right.

00:52:38.100 --> 00:52:42.780
Well, let's talk just for a minute, maybe real quick about what you all are doing at

00:52:42.780 --> 00:52:47.340
Pydantic the company rather than Pydantic the open source library.

00:52:47.340 --> 00:52:48.940
Like what do you all got going on there?

00:52:48.940 --> 00:52:49.940
Yeah, sure.

00:52:49.940 --> 00:52:55.380
So Pydantic has the company has released our first commercial tool.

00:52:55.380 --> 00:52:58.740
It's called LogFire and it's in open beta.

00:52:58.740 --> 00:53:01.580
So it's an observability platform.

00:53:01.580 --> 00:53:04.840
And we'd really encourage anyone interested to try it out.

00:53:04.840 --> 00:53:10.340
It's super easy to get started with, you know, just the basic like pip install of the SDK

00:53:10.340 --> 00:53:12.660
and then start using it in your code base.

00:53:12.660 --> 00:53:18.340
And then we have the kind of LogFire dashboard where you're going to see the observability

00:53:18.340 --> 00:53:20.020
and results.

00:53:20.020 --> 00:53:24.340
And so we kind of adopt this like needle in the haystack philosophy where we want this

00:53:24.340 --> 00:53:31.700
to be a very easy to use observability platform that offers very like Python centric insights.

00:53:31.700 --> 00:53:37.020
And it's this kind of opinionated wrapper around open telemetry, if folks are familiar

00:53:37.020 --> 00:53:38.580
with that.

00:53:38.580 --> 00:53:42.620
But in kind of the context of performance, one of the great things about this tool is

00:53:42.620 --> 00:53:47.980
that it offers this like nested logging and profiling structure for code.

00:53:47.980 --> 00:53:51.880
And so it can be really helpful in kind of looking at your code and being like, we don't

00:53:51.880 --> 00:53:54.660
know where this performance slowdown is occurring.

00:53:54.660 --> 00:53:59.100
But if we integrate with LogFire, we can see that like very easily in the dashboard.

00:53:59.100 --> 00:54:06.080
Yeah, you have some interesting approaches, like specifically targeting popular frameworks

00:54:06.080 --> 00:54:09.700
like instrument FastAPI or something like that, right?

00:54:09.700 --> 00:54:10.940
Yeah, definitely.

00:54:10.940 --> 00:54:15.160
Trying to kind of build integrations that work very well with FastAPI, other tools

00:54:15.160 --> 00:54:20.900
like that, and even also offering kind of like custom features in the dashboard, right?

00:54:20.900 --> 00:54:24.020
Like if you're looking at, you know, if you're using an observability tool, you're probably

00:54:24.020 --> 00:54:27.300
advanced enough to want to add some extra things to your dashboard.

00:54:27.300 --> 00:54:30.860
And we're working on supporting that with fast UI, which I know you've chatted with

00:54:30.860 --> 00:54:32.300
Samuel about as well.

00:54:32.300 --> 00:54:33.300
Yeah, absolutely.

00:54:33.300 --> 00:54:38.820
I got a chance to talk to Samuel about LogFire and some of the behind the scenes infrastructure

00:54:38.820 --> 00:54:39.820
was really interesting.

00:54:39.820 --> 00:54:43.780
But also speaking of fast UI, you know, I did speak to him.

00:54:43.780 --> 00:54:44.780
When was that?

00:54:44.780 --> 00:54:45.860
Back in February.

00:54:45.860 --> 00:54:48.580
So this is a really popular project.

00:54:48.580 --> 00:54:54.600
And even on the, I was like, quite a few people decided that they were interested in even

00:54:54.600 --> 00:54:58.520
watching the video on that one, which, yeah.

00:54:58.520 --> 00:54:59.520
Anything with fast UI?

00:54:59.520 --> 00:55:01.920
Sorry, did you say anything with fast UI?

00:55:01.920 --> 00:55:03.000
Yeah, yeah.

00:55:03.000 --> 00:55:04.560
Are you doing anything on the fast UI side?

00:55:04.560 --> 00:55:07.760
Are you on the Pydantic side of things?

00:55:07.760 --> 00:55:08.840
Yeah, good question.

00:55:08.840 --> 00:55:14.300
I've been working mostly on Pydantic, just, you know, larger user base, more feature requests,

00:55:14.300 --> 00:55:18.420
but excited to, I've done a little bit on the fast UI side and excited to kind of brush

00:55:18.420 --> 00:55:22.980
up on my TypeScript and build that out as a more robust and supported tool.

00:55:22.980 --> 00:55:27.300
I think, especially as we grow as a company and have more open source support in general,

00:55:27.300 --> 00:55:30.020
that'll be a priority for us, which is exciting.

00:55:30.020 --> 00:55:31.020
Yeah.

00:55:31.020 --> 00:55:33.140
It's an interesting project.

00:55:33.140 --> 00:55:39.220
Definitely a cool way to do JavaScript front ends and react and then plug those back into

00:55:39.220 --> 00:55:42.740
Python APIs, like FastAPI and those types of things.

00:55:42.740 --> 00:55:43.740
Right.

00:55:43.740 --> 00:55:44.740
So, yeah.

00:55:44.740 --> 00:55:45.740
Yeah.

00:55:45.740 --> 00:55:48.380
And kind of a similarity with fast UI and Logfire, the new tool, is that there's pretty

00:55:48.380 --> 00:55:52.020
seamless integration with Pydantic, which is definitely going to be one of the kind

00:55:52.020 --> 00:55:56.340
of core tenants of any products or open source things that we're producing in the future.

00:55:56.340 --> 00:55:57.340
Yeah.

00:55:57.340 --> 00:56:00.420
I can imagine that's something you want to pay special attention to is like, how well

00:56:00.420 --> 00:56:04.340
do these things fit together as a whole, rather than just, here's something interesting, here's

00:56:04.340 --> 00:56:05.340
something interesting.

00:56:05.340 --> 00:56:06.340
Yeah.

00:56:06.340 --> 00:56:07.340
Awesome.

00:56:07.340 --> 00:56:08.340
All right.

00:56:08.340 --> 00:56:13.180
Well, I think that pretty much wraps it up for the time that we have to talk today.

00:56:13.180 --> 00:56:14.180
Let's close it out.

00:56:14.180 --> 00:56:19.220
Close it out for us with maybe a final call to action for people who are already using

00:56:19.220 --> 00:56:24.020
Pydantic and they want it to go faster, or maybe they could adopt some of these tips.

00:56:24.020 --> 00:56:25.020
What do you tell them?

00:56:25.020 --> 00:56:26.020
Yeah.

00:56:26.020 --> 00:56:31.580
So, you know, inform yourself just a little bit about kind of the Pydantic architecture,

00:56:31.580 --> 00:56:35.940
just in terms of like, what is core schema and why are we using Rust for validation and

00:56:35.940 --> 00:56:36.940
serialization?

00:56:36.940 --> 00:56:41.060
And then that can kind of take you to the next steps of, when do I want to build my

00:56:41.060 --> 00:56:44.100
core schemas based on kind of the nature of my application?

00:56:44.100 --> 00:56:48.380
Is it okay if imports take a little bit longer or do I want to delay that?

00:56:48.380 --> 00:56:51.180
And then take a look at discriminated unions.

00:56:51.180 --> 00:56:54.640
And then maybe if you're really interested in improving performance across your application

00:56:54.640 --> 00:57:00.140
that supports Pydantic and other things, trying out LogFire and just seeing what sort of benefits

00:57:00.140 --> 00:57:01.140
you can get there.

00:57:01.140 --> 00:57:02.140
Yeah.

00:57:02.140 --> 00:57:05.860
See where you're spending your time is one of the very, you know, not just focused on

00:57:05.860 --> 00:57:11.760
Pydantic, but in general, our intuition is often pretty bad for where is your code slow

00:57:11.760 --> 00:57:12.760
and where is it not slow?

00:57:12.760 --> 00:57:14.340
You're like, that looks really complicated.

00:57:14.340 --> 00:57:15.340
That must be slow.

00:57:15.340 --> 00:57:16.340
Like, nope.

00:57:16.340 --> 00:57:19.820
It's that one call to like some sub module that you didn't realize was terrible.

00:57:19.820 --> 00:57:20.820
Yeah.

00:57:21.000 --> 00:57:27.000
And I guess that kind of circles back to the like LLM tools and, you know, integrated performance

00:57:27.000 --> 00:57:31.640
analysis with CodSpeed and CodeFlash and even just other LLM tools, which is like, use the

00:57:31.640 --> 00:57:32.640
tools you have at hand.

00:57:32.640 --> 00:57:37.280
And yeah, sometimes they're better at performance improvements than you might be, or it can

00:57:37.280 --> 00:57:40.800
at least give you good tips that give you, you know, a launching point, which is great.

00:57:40.800 --> 00:57:41.800
Yeah, for sure.

00:57:41.800 --> 00:57:44.360
Or even good old C profile built right in, right?

00:57:44.360 --> 00:57:46.920
If you really, if you want to do it that way.

00:57:46.920 --> 00:57:47.920
Awesome.

00:57:47.920 --> 00:57:48.920
All right.

00:57:49.020 --> 00:57:53.300
Sydney, thank you for being back on the show and sharing all these tips and congratulations

00:57:53.300 --> 00:57:56.140
on all the work you and the team are doing.

00:57:56.140 --> 00:57:58.260
You know, what a, what a success PyTantic is.

00:57:58.260 --> 00:57:59.260
Yeah.

00:57:59.260 --> 00:58:00.260
Thank you so much for having me.

00:58:00.260 --> 00:58:03.340
It was wonderful to get to have this discussion with you and excited that I got to meet you

00:58:03.340 --> 00:58:04.500
in person at PyCon recently.

00:58:04.500 --> 00:58:05.940
Yeah, that was really great.

00:58:05.940 --> 00:58:06.940
Really great.

00:58:06.940 --> 00:58:08.460
Until, until next PyCon.

00:58:08.460 --> 00:58:10.060
See you later.

00:58:10.060 --> 00:58:13.260
This has been another episode of Talk Python to Me.

00:58:13.260 --> 00:58:14.260
Thank you to our sponsors.

00:58:14.260 --> 00:58:15.960
Be sure to check out what they're offering.

00:58:15.960 --> 00:58:18.100
It really helps support the show.

00:58:18.100 --> 00:58:19.840
Take some stress out of your life.

00:58:19.840 --> 00:58:24.580
Get notified immediately about errors and performance issues in your web or mobile applications

00:58:24.580 --> 00:58:25.880
with Sentry.

00:58:25.880 --> 00:58:30.660
Just visit talkpython.fm/sentry and get started for free.

00:58:30.660 --> 00:58:34.360
And be sure to use the promo code talkpython, all one word.

00:58:34.360 --> 00:58:37.340
Code comments and original podcast from Red Hat.

00:58:37.340 --> 00:58:42.140
This podcast covers stories from technologists who've been through tough tech transitions

00:58:42.140 --> 00:58:46.260
and share how their teams survived the journey.

00:58:46.260 --> 00:58:49.820
Those are available everywhere you listen to your podcasts and at talkpython.fm/code-comments.

00:58:49.820 --> 00:58:53.660
Want to level up your Python?

00:58:53.660 --> 00:58:57.740
We have one of the largest catalogs of Python video courses over at Talk Python.

00:58:57.740 --> 00:59:02.860
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:59:02.860 --> 00:59:05.540
And best of all, there's not a subscription in sight.

00:59:05.540 --> 00:59:08.700
Check it out for yourself at training.talkpython.fm.

00:59:08.700 --> 00:59:10.460
Be sure to subscribe to the show.

00:59:10.460 --> 00:59:13.320
Open your favorite podcast app and search for Python.

00:59:13.320 --> 00:59:14.680
We should be right at the top.

00:59:14.680 --> 00:59:20.220
You can also find the iTunes feed at /iTunes, the Google Play feed at /play, and the Direct

00:59:20.220 --> 00:59:24.300
RSS feed at /rss on talkpython.fm.

00:59:24.300 --> 00:59:26.820
We're live streaming most of our recordings these days.

00:59:26.820 --> 00:59:30.420
If you want to be part of the show and have your comments featured on the air, be sure

00:59:30.420 --> 00:59:35.360
to subscribe to our YouTube channel at talkpython.fm/youtube.

00:59:35.360 --> 00:59:36.660
This is your host, Michael Kennedy.

00:59:36.660 --> 00:59:37.780
Thanks so much for listening.

00:59:37.780 --> 00:59:39.020
I really appreciate it.

00:59:39.020 --> 00:59:40.780
Now get out there and write some Python code.

00:59:41.600 --> 00:59:43.600
[MUSIC PLAYING]

00:59:43.600 --> 00:59:45.600
[MUSIC ENDS]

00:59:45.600 --> 00:59:47.600
[MUSIC PLAYING]

00:59:47.600 --> 00:59:49.600
[MUSIC ENDS]

00:59:49.600 --> 00:59:51.600
[MUSIC PLAYING]

00:59:52.600 --> 00:59:54.600
[MUSIC ENDS]

00:59:54.600 --> 00:59:56.600
[MUSIC PLAYING]

00:59:57.600 --> 00:59:59.600
[MUSIC ENDS]

00:59:59.600 --> 01:00:01.600
[MUSIC]

