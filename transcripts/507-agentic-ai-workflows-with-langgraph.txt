00:00:00 If you want to leverage the power of LLMs in your Python apps, you would be wise to consider an Identic framework. Identic empowers the LLMs to use tools and take further actions based on what it's learned at that point. And frameworks provide all the necessary building blocks to weave these into your apps with features like long-term memory and durable resumability. I'm excited to have Sydney Runkle back on the podcast to dive into building Python apps with LangChain and LangGraph.

00:00:27 This is Talk Python To Me, episode 507, recorded Tuesday, May 6th, 2025.

00:00:34 Are you ready for your host, please?

00:00:36 You're listening to Michael Kennedy on Talk Python To Me.

00:00:40 Live from Portland, Oregon, and this segment was made with Python.

00:00:46 Welcome to Talk Python To Me, a weekly podcast on Python.

00:00:50 This is your host, Michael Kennedy.

00:00:52 Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython, both accounts over at Fostadon.org and keep up with the show and listen to over nine years of episodes at talkpython.fm.

00:01:05 If you want to be part of our live episodes, you can find the live streams over on YouTube.

00:01:09 Subscribe to our YouTube channel over at talkpython.fm/youtube and get notified about upcoming shows.

00:01:16 This episode is sponsored by Posit Connect from the makers of Shiny.

00:01:20 Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:24 Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:31 Posit Connect supports all of them. Try Posit Connect for free by going to talkpython.fm/posit, B-O-S-I-T. And it's brought to you by Auth0. Auth0 is an easy to implement adaptable authentication and authorization platform. Think easy user logins, social sign-on, multi-factor authentication and robust role-based access control. With over 30 SDKs and quick starts, Auth0 scales with your product at every stage. Get 25,000 monthly active users for free at talkpython.fm/auth0. Hey all, over at Talk Python we have an exciting new course, Polars for Power Users. If you're into data science or you're just looking for a better way to automate your world than tools like Excel and Google Sheets, this course is for you.

00:02:19 And if you already do data science using older tools like Pandas and NumPy, maybe it's time to add Polars to your toolkit.

00:02:26 Whether you're wrangling CSVs, taming messy Excel files, or joining multi-gigabyte datasets, Polars for Power Users shows you exactly how to translate everyday data tasks into clean Pythonic code that runs 10 to 100 times faster than traditional approaches.

00:02:42 Through a pragmatic mix, short lectures, live REPL sessions, and a capstone case study, You'll master Polars fluent syntax, lazy evaluation engine, and productivity-boosting features such as pivot tables, joins, and Excel-style data accessors.

00:02:57 This excellent and very entertaining course was created by Christopher Trudeau.

00:03:01 His deep experience and connections in the Python world are evident right from the start.

00:03:06 Plus, this course doesn't waste your time.

00:03:08 You'll be up and running with Polars in under three hours.

00:03:11 It's currently available for just $29 or less.

00:03:14 Visit talkpython.fm and click Courses in the nav bar or just click the link in your podcast player's show notes.

00:03:20 Thanks to everyone who's taken one of our courses. It really helps support the show.

00:03:24 Now, let's get on to that interview.

00:03:26 Sydney, welcome back to Talk Python To Me. Fantastic to have you here.

00:03:29 Thanks. Super excited to be back.

00:03:31 I'm excited to have you back.

00:03:33 We always get to talk about cool things.

00:03:35 And for a long time, that's been Pydantic.

00:03:38 And the last time you were on, we talked about Pydantic performance tips.

00:03:42 and now it's the topic du jour really.

00:03:46 Building with LLMs, which I think is really, really different than saying I use an LLM to build my code or I use LLMs to answer questions or kind of an alternative search, but actually using it as a library style in your code, right?

00:04:03 Yeah, definitely.

00:04:04 I think you can kind of turn things inside out, right?

00:04:07 And like thinking about all the things that you can build with LLMs, specifically with LangRaph, And just what we're going to chat about today is really exciting.

00:04:14 Yeah, it is also tricky because as everyone knows who's played with them, LLMs are weirdly not deterministic.

00:04:22 And so programs typically like determinism.

00:04:26 They like, if I call this function, it's going to do a thing.

00:04:29 If I don't call the function, it's not going to do the thing or whatever, right?

00:04:33 So that's a big challenge.

00:04:35 And I think that's part of what your old toolchain is meant to do.

00:04:39 Now, just because you've been on the show a couple of times, there's probably still people out there who don't know who you are, and your role has changed a little bit.

00:04:47 How about a quick introduction into yourself again and what you're doing these days?

00:04:51 I know you made a career transition recently.

00:04:54 My name is Sydney. Nice to meet folks.

00:04:56 I am a passionate open source developer.

00:04:59 And so on previous episodes, I was on talking about Pydantic and doing kind of open source maintenance there.

00:05:05 So Pydantic is both an open source tool, and now there's a company built around that open source tool.

00:05:10 And I recently switched over to LangChain, excited to be working with an open source team in person in Boston.

00:05:18 So that's quite exciting. And I'm mostly working on maintaining LangGraph now.

00:05:22 So many folks are probably familiar with LangChain, the open source package.

00:05:26 We'll probably get into that a little bit more soon.

00:05:29 But LangGraph is kind of our newer agent orchestration framework.

00:05:33 Other than that, yeah, I love just engaging with folks in the open source community, getting excited about building cooler AI applications now. And I don't know, in my free time, I'm quite the podcast addict. So it's always nice to listen to your other podcasts.

00:05:47 Oh, thank you. Well, I know you worked on some cool projects and this certainly is another one of them. I didn't realize they were based in Boston. That's cool.

00:05:56 The main office is actually in San Francisco, but the company's growing pretty fast. So we now have the Boston office as of last week. So got my nice little call booth background here and then a New York office as well.

00:06:08 Is it off that 128 highway there where a lot of the tech companies are? I'm

00:06:12 actually not super familiar with San Francisco geography, but... No, no, I'm taking Boston up by like Woburn. Oh,

00:06:19 oh, gotcha. Yeah, we're actually in Harvard Square. Okay.

00:06:22 Oh, very cool. Yeah, proper Boston.

00:06:24 Yes.

00:06:25 Not Boston suburbs where a lot of those companies are out there. Yeah, really cool. So let's just start by talking about AI a little bit. I know some people are AI accelerators. People believe that AI should be just pushed as fast as it can be. And I suspect a lot of folks like that can be found on a playing chain. Also, people can be very hesitant to it, right? I know some people are like, I'm not using it. I won't use it. I'm not sending my data to the big cloud companies or whatever to train their models to take my job or however people perceive this. I'm certainly pretty, I see a ton of value in it. I think it's really quite incredible. But you know, first, what are your thoughts on using LLMs in general? And then two, what is an agent?

00:07:11 I definitely fall more on the accelerator side of things, but with guardrails and constraints and rules and boundaries, which is sort of what we're trying to do with LandGraph, I think it can be really helpful to use LLMs as a development tool. So I personally do that when I'm writing code. I also think it's really helpful to brainstorm with the help of LLMs. And yeah, so I think they're increasingly valuable. And as long as we're being careful about usage, then it's great to kind of lean into their strengths.

00:07:42 Yeah. Reuven Lerner, I just had him on the show a couple episodes ago, and he says he uses the reverse Socratic method with LLMs where he writes the code, then he asks it to, he sort of interrogates it like, well, what's wrong with my code?

00:07:56 What could be better?

00:07:57 When would I use it?

00:07:58 And what am I overlooking?

00:08:00 And it's, there's so many uses, it's wild.

00:08:02 Yeah, it's crazy.

00:08:03 I think sometimes I'll talk to my parents and be like, oh, I use ChatGPT to help me come up with a recipe.

00:08:08 And they're like, you did what?

00:08:10 Like, I didn't even know you could do that.

00:08:11 Whereas folks at work are having, interacting with AI on the hour.

00:08:16 So yeah, so I'll talk a little bit more about what are agents? Agents are a little bit hard to define. I think it's kind of an overloaded term, but many people are kind of leading into that as the future of AI from a developer perspective. So I think about agents as tools that can reason and make decisions for you, specifically LLMs that are powered with things like tool calling and memory and context and things like that. So like chat based model for an LLM to how can you use an LLM in an application.

00:08:54 Okay. So it can call tools like you could give it a request and maybe it's going to go and call, do like web searches or read web pages or you can tell it, go read the docs and then do this thing or something along those lines.

00:09:07 LLMs are trained on older data. And so if you're not enabling your LLMs to use kind of real world data and information, then their utility is limited. But agents have the power to use tools, which are basically like API calls, or it can even be more simple than that, like running some code in order to incorporate your like real time relevant data. And it can also kind of make decisions about like, which tools do I want to use and that sort of thing.

00:09:35 So interesting. I guess it's related to deep research a little bit, right? Like a lot of the deep research thing seem to be kind of using tools and using modern web and other stuff that they can find rather than just whatever the model was when it was constructed? Definitely.

00:09:52 I think about like perplexity is kind of gaining in popularity and what's really good at you can ask it a question and then it does real-time research against like looking things up on the internet and then provides you back with citations which is a really exciting feature I think for folks who are like LLMs can just make anything up.

00:10:10 Like, how do I know this is being pulled from reasonable sources?

00:10:13 And that's kind of an exciting jump in that space.

00:10:16 It is.

00:10:16 And I think it also goes a little ways, not that far, but a little ways to fill that gap where people said these search engines, they just take our data and they give us no credit.

00:10:27 Right.

00:10:27 Yeah.

00:10:28 Which I'm sympathetic to.

00:10:30 However, I do think it says, here's the four places I found and here's the video you should watch if you want to go deeper.

00:10:36 I think that's actually super valuable.

00:10:38 I just asked perplexity a historical question.

00:10:41 Like, what is the age of these people who did this thing hundreds of years ago?

00:10:47 And it said in their work, and it wrote Python code, and then it gave me the answer.

00:10:51 I think it was doing pandas type stuff, but it was sitting there thinking, thinking, and it shows you what it's doing.

00:10:58 And it just says, writing Python, and then boom, out comes the answer.

00:11:01 I'm like, okay, that's weird.

00:11:02 Oh, man.

00:11:02 Was it correct?

00:11:03 Yeah, it was correct, I think.

00:11:04 Wow.

00:11:05 Wild.

00:11:06 But that's kind of the stuff we're talking about a little bit, right, in this agentic sense.

00:11:11 It's not just like, well, I went to my database.

00:11:13 These are answers I have.

00:11:14 But it's like, well, if I can make this web query and I could write some pandas, then I could format it the way you asked for it, right?

00:11:20 Yeah, there's definitely a lot more kind of reasoning and thinking.

00:11:24 It is a bit of a black box right behind, like, what is the LLM doing?

00:11:27 And so you've got a bit of transparency there with the, like, writing Python code clue.

00:11:32 I wish there was a view source.

00:11:33 You know what I mean?

00:11:34 One of the things that we're trying to do at LinkChain right now with LandGraph development is to kind of bridge the gap between like, what are the parts of your system that you really need to like understand and kind of be guaranteed are reliable and will always run in the same way versus like, where can you afford to introduce non-determinism in favor of like a bit more maybe agency or utility, but also introducing risk like, who knows what your LLM was doing in the research phase.

00:12:00 It's just so powerful, but it's also so, scary as a developer to think, I can't debug this. I can't prove that it's going to do the right thing all the time. Right. And I guess it really depends, right? Like Siri, for example, on the iPhone, sorry if that made anybody's phones go off. It's so bad. It's just so weirdly not capable of doing stuff. And you know that if that were backed by an LLM instead, sure, it might make mistakes periodically, but as a net, it would be so much better that it's probably worth it. You know what I mean, on the other hand, you wouldn't want to say, I'm going to create an agentic workflow to determine if you get a mortgage or things like that would be a little bit too much, I think, right?

00:12:44 It would deny people for weird, random reasons.

00:12:47 Right.

00:12:48 You definitely have to consider the stakes and risk and value of a decision that you're making, right?

00:12:55 And like, I think generally I wouldn't empower LLMs to make like the most important decisions in my life on a day-to-day basis.

00:13:01 Like you said, I do find myself like laughing at series responses more than actually like valuing the response.

00:13:08 It's incredible.

00:13:09 It's setting timers and telling you what the temperature is.

00:13:13 But boy, you're very off very much.

00:13:16 No, no, it doesn't.

00:13:17 It just doesn't do it.

00:13:18 Okay.

00:13:19 So when would you use, I mean, I talked about examples you wouldn't use.

00:13:24 Give us examples of when you might really embrace these things.

00:13:27 We've talked about the non-determinism of LLM behavior, right?

00:13:30 But also kind of the power of an agent is in making decisions for you.

00:13:34 And if you can give your large language model the appropriate context and descriptions of tools so that it can do a good job making decisions for you, then that can save you a lot of time.

00:13:46 So one classic example I'll probably touch on a couple times today is you might build an email agent.

00:13:52 And so the value of that email agent, right, is that it can categorize emails for you.

00:13:56 Maybe some things are spam, some things need immediate response, some things can even be automatically responded to, and then said agent could learn from your preferences over time. So maybe before an automatic reply is sent out, you, the user, get to approve that reply, but you didn't have to do all the work of drafting and that sort of thing.

00:14:19 And so I think the greatest value that I see in developing workflows with agents is if you can come up with systems that we call like ambient workflows, basically, instead of responding to some user prompt, like, hey, what's the weather? They're running to in response to external triggers. So in this example, like the email that you received. And so basically, you're trying to create a system that does work and automates work for you.

00:14:44 Yeah, that's cool. It could determine if it's, is this an emergency? Is this something, a tech support type thing? Is it an accounting thing? And then it could just maybe do a little bit of work through your docs, give a response and then forward it to the right person or something like that, right?

00:14:59 I think we think about like chatbots on like websites that help users as another common example.

00:15:06 And when you're talking with a chatbot, at what point does it decide like, you know what, we need to escalate this and like actually provide them with a phone number to call with a real person or that sort of thing.

00:15:15 I definitely see this as being one of the more powerful, more common ways that allow them to actually interact with people.

00:15:23 It's kind of weird that it's a chat.

00:15:25 You know what I mean?

00:15:26 It is pretty useful, but it's also just weird that it's like, okay, we're going to have this chat with this thing, whereas it could do so much more.

00:15:35 Yeah. You mean with the chatbot example?

00:15:38 Yeah, exactly. Or even ChatGPT itself or something like that, right?

00:15:42 Yeah. I think that's kind of why we're so excited about the ambient or background system pattern is a chat is super helpful if I'm like, I have these five ingredients in my fridge. What should I make for dinner?

00:15:55 That's like a very simplistic pattern.

00:15:57 And we think you should kind of build a system that is only as simple as you need.

00:16:02 But then I think the real value comes when you're responding to those external like real-time triggers.

00:16:08 Can one of them be like a cron job?

00:16:11 Like every hour, check this stock price or every hour, evaluate the sentiment of this community and then do something.

00:16:19 Yeah, definitely.

00:16:20 I think as we get more into discussing how you can build workflows with LandGraph, it'll become pretty evident how you can schedule things.

00:16:27 And that's a very predictable pattern, right?

00:16:29 Maybe as useful for you, I can imagine for the case where you're running something on a schedule.

00:16:33 The end result might be like, okay, you've analyzed sentiment.

00:16:36 Do I need to send an alert to my user or things like that?

00:16:41 This portion of Talk Python To Me is brought to you by the folks at Posit.

00:16:44 Posit has made a huge investment in the Python community lately.

00:16:48 Known originally for RStudio, they've been building out a suite of tools and services for Team Python.

00:16:54 Over the past few years, we've all learned some pretty scary terms.

00:16:58 Hypersquatting, supply chain attack, obfuscated code, and more.

00:17:03 These all orbit around the idea that when you install Python packages, you're effectively running arbitrary code off the internet on your dev machine, and usually even on your servers.

00:17:14 But thought alone makes me shudder.

00:17:15 And this doesn't even touch the reproducibility issues surrounding external packages.

00:17:20 But there are tools to help.

00:17:22 Posit Package Manager can solve both problems for you.

00:17:25 Think of Posit Package Manager as your personal package concierge.

00:17:29 You use it to build your own package repositories within your firewall that keep your project safe.

00:17:33 You can upload your own internal packages to share or import packages directly from PyPI.

00:17:39 Your team members can install from these repos in normal ways using tools like pip, Poetry, and uv.

00:17:45 Posit Package Manager can help you manage updates ensuring you're using the latest, most secure versions of your packages but it also takes point-in-time snapshots of your repos which you can use to rerun your code reproducibly in the future Posit Package Manager reports on packages with known CVEs and other vulnerabilities so you can keep ahead of threats and if you need the highest level of security you can even run Posit Package Manager in air-gapped environments If you work on our data science team where security matters, you owe it to you and your org to check out Posit Package Manager.

00:18:19 Visit talkpython.fm/ppm today and get a three-month free trial to see if it's a good fit.

00:18:25 That's talkpython.fm/ppm.

00:18:28 The link is in your podcast player's show notes.

00:18:30 Thank you to Posit for supporting the show.

00:18:33 Well, let's talk a bit about, I guess, Langchain first.

00:18:37 So there's a lot of things going on here, right?

00:18:39 There's Langchain, the company.

00:18:41 There's LangChain, the open source project.

00:18:45 There's LangGraph.

00:18:46 Tell us about all these things.

00:18:47 Yeah, so happy to give kind of an overview.

00:18:49 So LangChain, the open source tool, is basically a tool for developers to use LLMs and really increase the value of LLMs or kind of augment the power of LLMs with your data.

00:19:04 And so some of the things that we've built in LangChain include abstractions around chat models.

00:19:10 So you can decide you're going to use the 4.1 model and you want to use some different settings, like maybe set the temperature to zero or only send some maximum number of tokens or things like that.

00:19:23 And then specifically, a lot of the value from LinkChain, the open source tool, comes from introducing this model agnostic interface.

00:19:30 So if I want to chain a bunch of model responses together, it's kind of hard to do that if I am separately querying the OpenAI API.

00:19:40 and then the Anthropic API, and then trying to work with Gemini as well.

00:19:43 There are kind of different response formats and features, et cetera.

00:19:47 And so Langchain makes it really easy for developers to use all of those different model providers in a single application.

00:19:53 That's interesting.

00:19:54 So if I wanted, I could bring my own LLM?

00:19:59 Is that possible?

00:20:00 Yes.

00:20:01 Right, like I could use Olama or LM Studio or one of those things rather than the full cloud version?

00:20:06 Definitely, which is nice just from an extensibility point of view.

00:20:10 And then if you want to use that LLM and then start to use some other more commercially available ones as well, you can combine those.

00:20:17 And so the name Langchain comes together when we think about chains of systems.

00:20:21 One common example that we use is RAG, right?

00:20:24 So you have your vector store, some user asks a question and you fetch the relevant data from the vector store and then you kind of feed that into the LLM.

00:20:35 And so that was a very common pattern like folks, LangChain users would implement.

00:20:39 Yeah, very cool.

00:20:40 And then LangGraph.

00:20:41 LangGraph is more about building workflows out of this, right?

00:20:47 LangGraph is kind of the evolution of LangChain and it has two main things that we focus on.

00:20:52 So it's got a low-level system for building graphs.

00:20:56 So you can think of that, the very like computer science.

00:20:59 Folks will be excited to hear the terms like nodes and edges, right?

00:21:02 You're building this low-level system.

00:21:05 You can control the flow of data or the flow of your application.

00:21:10 You can have conditional branches.

00:21:11 You can run nodes in parallel, all of those kind of exciting graph features.

00:21:16 And then we also have, and you can see here, what we call pre-builds, which help you build agents on top of that graph framework.

00:21:24 So the promise of LaneGraph is that it's extensible because we have those low-level building blocks, but then also very easy to get started with an agent

00:21:34 application.

00:21:35 Yeah, like one of the examples you have, the GitHub page is create React agent from the prebuilt graphs.

00:21:41 Is that React as in JavaScript's React framework or just a reactive thing?

00:21:47 Good question.

00:21:47 So that's React is kind of a common term in the agent building space.

00:21:52 So it's reasoning and action agent.

00:21:55 I see.

00:21:55 So it has nothing to do with JavaScript necessarily.

00:21:58 No, it does not.

00:21:58 We actually will be probably changing this name soon to just create agent to be a little bit more clear for folks.

00:22:05 Yeah, super cool.

00:22:06 So I guess give us a sense of maybe, well, I want to, let me circle back to some stuff you talked about that I want to talk about.

00:22:11 Why not just call OpenAI or something like that?

00:22:14 It's API directly.

00:22:16 But you mentioned tokens and, oh gosh, what was the other thing?

00:22:20 I think I mentioned temperature.

00:22:22 Temperature, that was the one.

00:22:23 Yes, thank you.

00:22:24 Temperature.

00:22:24 So LLMs can have a certain amount of creativity is maybe the right word, but not really.

00:22:31 a certain amount of flexibility in, I guess, almost randomness in the amount of the way that it works its way through finding the answers. And the higher the temperature, the more you let it be creative and wonder, whereas the lower the temperature, you're like, no, just give me the closest answer with the least amount of variability. I imagine that that is really an important consideration in building these types of things because it probably significantly influences how deterministic a thing is.

00:22:57 Yeah, I think a great way to think about it is if your temperature is low, let's say we're going on a scale of like zero to one. So if your temperature is like zero to 0.3, it's more deterministic. We can't say like guaranteed to be fully deterministic. But I think when you're building a system that's going to be deployed for users or basically a production ready system, you're certainly going to lean on the side of lower temperature. But, you know, for more creative applications, it's nice to have that setting be pretty configurable just so you can really see what kind of ideas your LLM can help you with.

00:23:29 Right, right.

00:23:30 I want to, you helped me think creatively about doing this thing and what are my options, right?

00:23:34 Like that kind of thing, you probably don't want to set temperature to zero, but when you're building workflows, I imagine it's usually more tending lower.

00:23:42 Definitely.

00:23:42 Sort of a like silly example of maybe when you would set the temperature to higher is I was doing some shopping this weekend and stumbled upon a listing on Facebook Marketplace and the listing had a riddle as the description.

00:23:56 And it was like, if you solve this riddle, you can have this bedside table for free.

00:24:00 And so plugging the riddle into ChatGPT with a higher temperature might be more valuable there.

00:24:05 Obviously more of a like toy example, but kind of shows the utility there.

00:24:09 I've been doing a bunch of stuff on Facebook Marketplace.

00:24:10 That is in a crazy place.

00:24:13 It's the new Craigslist.

00:24:14 It's really weird.

00:24:15 Indeed.

00:24:15 Yeah, that's a wild, wild example.

00:24:17 And the other one that I think is probably important to define would be just tokens.

00:24:22 because a lot of the models, especially the local models, I don't want to send my data off.

00:24:27 I want to run OLAMA.

00:24:28 I want to run LMStudio.

00:24:30 Those are quite limited, right?

00:24:32 Like 8,000 tokens versus half a million for some of the cloud models, right?

00:24:36 So that can be really a significant consideration as well.

00:24:39 What are they?

00:24:41 They're not exactly words, but they're kind of words, but they're not words.

00:24:43 It's basically just a way to quantify the amount of data that you're sending to your LLM.

00:24:49 And so they also can be used to quantify the amount of data or text that your LLM is sending out as well.

00:24:56 So you'll have like input tokens and output tokens.

00:25:00 Generally, you can kind of equate them to characters.

00:25:02 I think there's a little bit of like nuance there, but I think the simple explanation, that's good enough.

00:25:08 And the value of such a wide, what we call like context window, is that the more context and direction your LLM has, the better it's going to perform.

00:25:18 And so if you have those bigger windows, you can write more verbose instructions and, yeah, just write more clear guidelines for your LLM to follow.

00:25:27 You can also put more relevant context for if your, you know, system is answering questions, maybe you need to, like, yeah, provide just relevant context there.

00:25:36 And we'll talk a little bit more down the line about the value of, like, memory and long-term storage in agentic applications.

00:25:42 And so we'll often like feed back in some of the important things logged in memory.

00:25:47 And so if you have that bigger context window, you can send in more of that data as well.

00:25:51 So that might be like user preferences or previous responses or previous messages, that sort of thing.

00:25:57 Yeah, and if you run out of that space, then it's kind of as if the first part of the conversation, which might include important instructions like we are working on this project, here is our goal, would just kind of either drop off or it would be a runtime error or something.

00:26:12 So yeah, it super matters.

00:26:14 I guess one other important note around tokens is that's often how you're charged for LLM use.

00:26:19 Like if you are using more.

00:26:20 Yes, exactly.

00:26:21 More tokens on input and more tokens on output is higher cost.

00:26:24 But that higher cost is often worth the significant performance improvement.

00:26:29 Yeah, so that's for the cloud usage-based ones.

00:26:32 Certainly that's what you get charged.

00:26:34 And that's some of the appeal of the local ones.

00:26:36 But the local ones, they can't answer the questions as well.

00:26:40 They don't have as much data.

00:26:41 Are there local models that do agentic stuff?

00:26:45 Or would I do something like lane graph talking to, I don't know, Mistral or something running, like a 7 billion parameter Mistral running locally?

00:26:52 Would I use lane graph to get that agentic behavior and things like that?

00:26:58 One of the main features that we think about when we think about agentic behavior is that like tool calling ability.

00:27:05 And so I think if a model doesn't have support for that, then its utility is more limited.

00:27:11 But that being said, as long as the model can reason and provide guidance, then you can certainly kind of build an agentic application around it with LaneGraph.

00:27:20 Yeah, very neat.

00:27:21 All right, so my other question before we got distracted on this terminology thing, it was, why not just call the LLM directly?

00:27:31 What's wrong with that?

00:27:32 Which I can think of a couple of things, but, you know, lay it out for us.

00:27:35 The most important thing to think about is controllability and reliability.

00:27:41 So one of the main kind of hallmark features of LaneGraph is this human-in-the-loop support.

00:27:47 So you can send a request to your LLM, and then it's going to return a response.

00:27:52 And maybe before you do anything with that response, you probably want to check that maybe the tool call that it made is okay, or whatever expensive or risky operation that is about to be run.

00:28:04 you want to confirm that or maybe edit the parameters or that sort of thing.

00:28:08 And so I think for very simple chat-based applications, just calling the LLM is okay.

00:28:13 You can use LangChain to specify some of those model setting parameters easily or use different LLMs.

00:28:19 But anytime you want to build something with just more reliability, I think you definitely want more of a framework around it that provides those kind of guardrails.

00:28:28 There's also things like persistence and durability, which if you've had a long, drawn-out conversation with these APIs, that can be a big deal, right?

00:28:40 One of the nice things about Lingrath is that we offer kind of short-term and long-term persistence.

00:28:45 So you can have persistence across just a conversation, so like kind of one thread of discussion or one application run, and then also across runs.

00:28:55 So going back to the assistant example, you probably want your email assistant to learn from your long-term preferences, rather than just your like single human in the loop edit on one email that came in, for example.

00:29:08 You might say, I know you flagged this to be forward over here, but when it looks like this, I need you to take that into account and it means something different.

00:29:16 You want it to know that forever.

00:29:17 Exactly.

00:29:17 At the same time, people get freaked out.

00:29:19 I think ChatGPT started identifying your name and addressing you by name without you saying what your name is, and it freaked people out.

00:29:27 It's like, well, you've been giving it your secrets for six months.

00:29:30 I think my equivalent of being a little freaked out by ChatGPT was I was asking it for some like birthday gift ideas for my partner.

00:29:39 And it was like, oh, I think based on your previous commentary about your hobbies and things you like to do with your partner, then like, here's some ideas.

00:29:48 And I was like, wait a minute.

00:29:48 I didn't tell you that today.

00:29:50 Like, I didn't mention that I like to run and go on hikes, but you know that.

00:29:53 It's spionomic.

00:29:54 No, wait, I told it this over and over and over.

00:29:56 But yeah, it's very interesting.

00:29:58 Yeah.

00:29:58 Mostly useful.

00:29:59 Somewhat weird.

00:30:00 All right, let's maybe talk through, to give people a sense how this might work, let's maybe just talk through like a quick start example.

00:30:06 I know talking about code is a bit troublesome on audio formats, but we'll just keep it like high level.

00:30:12 But give us a sense of what is it like to write some code here.

00:30:15 Maybe we could just talk through the quick start for line graph.

00:30:17 Our quick start is now kind of focused around creating a simple agent.

00:30:22 So you can use that create React agent method that we talked about to create a weather agent.

00:30:29 And so what that looks like is you call the function with your preferred model.

00:30:33 So in this case, we're using Cloud 3.7.

00:30:36 And then we give it a get weather tool or kind of, yeah, it just calls a weather API, maybe with like city and state.

00:30:43 And then you can provide it with a system prompt as well.

00:30:46 So we give it some information about you're a helpful assistant that specializes in weather forecasting and you have access to this get weather tool.

00:30:55 And we're just trying to provide it with helpful context to get it started.

00:30:59 How much do you think that matters that you kind of set the stage, like you're a helpful weather assistant or you're an expert in this field before I ask you questions?

00:31:09 For a really simple application, like just providing one weather tool that has a great description, I think it maybe doesn't matter quite as much.

00:31:19 But I think as you start to build out those like customer facing chat bots or the email agent that we've been discussing, I think the prompt and guidance becomes really important.

00:31:30 And I think updating that with those memory stores like we've talked about helps your system be the most useful that it could be for you.

00:31:38 Yeah, that's true.

00:31:39 Because the long term persistence probably serves a little bit of that role of like setting the context more deeply.

00:31:47 This portion of Talk Python To Me is brought to you by Auth0.

00:31:50 Do you struggle with authentication?

00:31:53 Sure, you can start with usernames and passwords, but what about single sign-on, social auth, integration with AI agents?

00:32:00 It can quickly become a major time sink, and rarely is authentication your core business.

00:32:06 It's just table stakes that you've got to get right before you can move on to building your actual product.

00:32:11 That's why you should consider Auth0.

00:32:13 Auth0 is an easy-to-implement, adaptable authentication and authorization platform.

00:32:18 Think easy user logins, social sign-on, multi-factor authentication, and robust role-based access control.

00:32:25 With over 30 different SDKs and quick starts, Auth0 scales with your product at every stage.

00:32:32 Auth0 lets you implement secure authentication and authorization for your preferred deployment environment.

00:32:38 You can use all of your favorite tools and frameworks, whether it's Flask, Django, FastAPI, or something else, to manage user logins, roles, and permissions.

00:32:47 Leave authentication to Auth0 so that you can start focusing on the features your users will love.

00:32:52 Auth0's latest innovation, Auth4GenAI, which is now available in developer preview.

00:32:57 Secure your agentic apps and integrate with the GenAI ecosystem using features like user authentication for AI agents, token vault, async authorization, and FGA for RAG.

00:33:09 So if you're a Python developer or data scientist looking for an easy and powerful way to secure your applications, get started now with up to 25,000 monthly active users for free at talkpython.fm/auth0.

00:33:23 That's talkpython.fm/auth0.

00:33:25 The link is in your podcast player's show notes.

00:33:27 Thank you to Auth0 for supporting the show.

00:33:30 Just to give kind of an abbreviated example here.

00:33:33 let's say my email assistant drafts me email response, and then I edit that and I make it more concise and maybe a little bit more friendly or something like that. My agent, I can build in logic so that it updates the long-term memory store with that kind of guidance. And then the next time that the agent is called with an email stimulus, the prompt now has like, keep things concise and a bit more friendly. And I didn't necessarily tell it that I wanted it to be shorter and more friendly. I just made that relevant edit and then it summarized that into the prompt. So all that being said, I think my analysis here would be that context and guidance is really, really important. For this toy example, I think it would be okay without.

00:34:17 I do think one of the things that people, I would like to hear your thoughts on this as well and the guidance that you all give. But one of the things I think people who are new to LLMs I think they just, they kind of assume that it has too much knowledge or too much context.

00:34:34 And you'll see like a one sentence, please analyze this document for me.

00:34:40 Whereas if you gave it a two page write-up of the request you want, you might get dramatically better results.

00:34:48 And I also think that that's where a lot of people say, oh, LLMs make mistakes and they do all these crazy things.

00:34:53 It's like, well, you gave it so little information.

00:34:56 What's it supposed to go on?

00:34:57 And I guess in general, my comment is, I think people give way too short of prompts and background information to these things.

00:35:07 What do you guys think?

00:35:07 That's definitely true.

00:35:09 I'll send a link here to OpenAI.

00:35:11 I just released a GPT 4.1 prompting guide.

00:35:14 And if you look at any of the guide, you'll see these huge context blocks.

00:35:21 And so obviously, these guys really know how these models work and are going to give us the best guidance.

00:35:27 Yeah, let me just give people listening a sense.

00:35:28 It says, a sample prompt for a software engineering benchmark verified.

00:35:33 So here's a prompt you might get.

00:35:35 And it says, you'll be tasked to fix an issue in an open source repository.

00:35:39 And then it just, it doesn't even word wrap, but it still goes on both horizontally and vertically, hundreds of lines.

00:35:48 Another thing that I think is super interesting is the use of markdown when you talk to these things because it can it can convey a little bit of like formatting like oh this is a link or this is bolded so it means something different than if it's not bolded

00:36:04 it's really interesting kind of trying to play the game of how can i optimize my context so that i'm optimizing the behavior of the llm i think we talk a lot in when we're talking about link graph about like the structure of your application but then really all that boils down to is like getting your getting your context right so that your agent can do the right thing.

00:36:24 Yeah, well, thanks for the diversion.

00:36:25 I just, I do think to be successful with this stuff, you've really got to have your, you're talking to LLM's game really strong because that's the atomic units of this, right?

00:36:35 Definitely.

00:36:36 Okay, back to the quick start.

00:36:37 Give it a prompt.

00:36:38 Maybe a long, good one.

00:36:39 If you go on our docs, there should be like an agent section.

00:36:43 And I think there's, and yeah, so if you go to lane graph and then up at the, let's see, oh yeah, the agents tab on the top.

00:36:50 That do?

00:36:51 like the top nav if you go to agents.

00:36:52 Yeah.

00:36:53 So we should have a like getting started with agents section that's maybe a little bit more relevant for users.

00:36:59 So what that would look like, you have your create react agent and then you can invoke it with a set of messages.

00:37:05 So maybe I want to say, what's the weather like in San Francisco?

00:37:08 And then it returns a response and then you can invoke it again and say like, what about New York or other questions like that?

00:37:16 And that's kind of the like out of the box.

00:37:18 How do you build just 10 lines of code?

00:37:21 You've got an agent working for you with context and tools, et cetera.

00:37:25 Super neat.

00:37:25 So when is your new Getting Started tutorial walkthrough thing coming out?

00:37:31 We have it coming out, I believe, at the end of the week.

00:37:34 We have our interrupt conference next week.

00:37:37 So we want to have our docs kind of revamped for that.

00:37:40 Interrupt.

00:37:40 Okay.

00:37:40 Is that like, because that's the call for human in the loop callback effectively, right?

00:37:45 Is that the origin of that name?

00:37:47 Yeah, it is.

00:37:48 I think we're like really emphasizing kind of the value of that.

00:37:51 I just sent you the link as well for that.

00:37:54 It should be viewable publicly.

00:37:56 It's kind of our old agent's guide.

00:37:57 Happy to talk more about human in the loop, if that's helpful.

00:38:00 Yeah, yeah, let's talk about that because that sounds pretty interesting, right?

00:38:05 We've got chat, which is obviously human in the loop, although when you press deep research, less in the loop.

00:38:10 Then you've got these Python programs, which maybe just completely run by themselves.

00:38:17 But yeah, what is this human in the loop and how does that work?

00:38:19 The human in the loop, we are trying to basically add human approval or edits for cases that are basically sensitive decisions that are being made.

00:38:31 So very simple example, let's say you have a hotel booking agent and you get a request in that's like, I'd like to book a stay at whatever Hilton in Boston.

00:38:40 You might want a user to just kind of approve that sensitive financial, like significant financial burden before the booking actually goes through. And so we make it really easy with this interrupt function anywhere in a tool or node to say interrupt. I want to get human input here that can review tool calls, validate outputs from an LLM, or like augment existing data or context so that you can make sure your LLM is doing the right thing.

00:39:11 I see. And it's like, well, we found these things, what would you like me to focus on? Or is it okay to make this call to this API? Maybe it's a paid API, like we're accessing this expensive stock data. But I think if I knew this, I could answer your question. You're like, yeah, spend the dollar. Let's see. That kind of thing. Exactly.

00:39:30 Or like with the hotel booking agent, let's say I'm like, I'd like to book the Hilton in Boston. And then it comes up with a proposal for booking not the right hotel.

00:39:41 I can say like actually can you clarify with the user which hotel they'd like to book like maybe provide an address or something and then that like cycles back through and then maybe it gets the proper tool called the second time.

00:39:52 They didn't mind driving so we put them on the opposite end with the maximum traffic. It only looks like at 10 miles but it actually turns out to be two hours to get from here to there when they need to be there. They don't want that right? We

00:40:04 one kind of exciting other open source project we have is called Agent Inbox and so if you have a lot of interrupts going in your application the agent inbox you can hook up to that application and it basically provides you almost looking like this email inbox of all the interrupts for you to

00:40:20 address so maybe if you had like a social media agent or something that was helping you with your posts and it interrupted right before the final post you can go through and like accept all those tool calls or edit posts right before they get sent out just making it easier to kind of deal with multiple runs, things like that.

00:40:39 Yeah, I guess that makes a lot of sense because otherwise we're going to just have a bunch of programs that are executing but just stuck there waiting for people until they go and just start typing back to it.

00:40:48 And how human in the loop ties into this persistence layer is sort of twofold.

00:40:53 One, an application can be suspended for any indefinite amount of time.

00:40:57 So the guarantee with our persistence is that you can just restart back where the interrupt was, whether that's a minute later, five minutes later, 10 days later, a year later, whatever that may be.

00:41:08 And so just making sure that like you're guaranteed to get that human input before you resume, but then you have a kind of resumable state.

00:41:16 The second thing is like we've talked about, you want to learn from that human input.

00:41:20 And so you can kind of analyze that in a separate step and then store that in the long-term memory.

00:41:25 Is that a coding thing that you do or is that just the way you set up the workflow?

00:41:29 Yeah, great question.

00:41:30 So we provide kind of support for the fundamentals in LandGraph.

00:41:35 But we think kind of extensibility and customizability is pretty important.

00:41:38 So we have like data structures for those short term and long term stores.

00:41:43 But we also provide interfaces so that you could customize your store.

00:41:46 And we have like in-memory stores or Postgres stores or things like that.

00:41:51 But if you wanted to use some custom location, you could do that as well.

00:41:54 Yeah, super interesting.

00:41:55 So with this ability to suspend these conversations, does that depend upon the LLM keeping that information around?

00:42:03 Like if you make a call to an API, do you get like a session ID sort of thing for that conversation?

00:42:10 Or does it somehow store it, like you say, in Postgres or whatever, and then provide that back to the LLM to keep talking to it?

00:42:17 Yeah, so it's the latter of those.

00:42:19 You're kind of storing the conversation state and message history and any other relevant state to your application.

00:42:25 And then once you get that signal from the user, you can pick all that up.

00:42:30 It's kind of unique to the thread.

00:42:32 We call it like the thread ID or the run ID.

00:42:35 And yeah, start back from there.

00:42:36 And then you would, if you're going to call the LLM again, just speed in that context.

00:42:41 Yeah, because that's kind of what subsequent chats are, right?

00:42:44 It's see everything again, plus the new information.

00:42:47 Now answer that, right?

00:42:49 It's a little weird.

00:42:50 Yeah.

00:42:50 So that's really helpful for things like local LLMs that might run or restart more frequently, unlike some of the cloud ones where they kind of keep that data.

00:43:00 But I don't know how long they keep it for.

00:43:01 Yeah, and a new kind of exciting feature in the persistence space generally is we're going to very soon introduce caching on the kind of node-by-node level.

00:43:11 So you can imagine if you have a node, which is really just a function running some expensive operation, for simplicity, we can just say it's like a pre-processing step, not even involved with an LLM.

00:43:24 you pass certain inputs to that node and you could enable some sort of cache policy there so that if you're starting up with the same inputs, you get to skip that step. And so really just trying to optimize for how can lots of different types of users use this same low-level system for a variety of agentic workflows.

00:43:42 You have these nodes and graphs and then you put it together in this workflow and you've got this cool persistence of memory. Can some of those operations be just pure Python workflow type things rather than always LLM, right? Like can it be call this LLM, use this tool, call this LLM, now just make an entry in our database or just send an email or whatever?

00:44:03 Yeah, definitely. I think that's the kind of value of that low level framework. Other what we call agent frameworks are really just focusing on the operations involved with LLMs.

00:44:13 Right, or orchestrating multiple LLM calls more or less, yeah?

00:44:16 The OpenAI Agents SDK, for example, helps you query OpenAI LLMs and orchestrate many agents together and maybe have guardrails.

00:44:26 But there's no kind of built-in support for just those standard Python operations, functions, processing, et cetera.

00:44:32 And so Node really just can contain any function.

00:44:35 So calling some API or doing any other thing you might possibly want it to do in just pure Python.

00:44:42 So we talked about using different LLMs like Anthropic or OpenAI or a local one that you might download.

00:44:49 Can I mix and match LLMs within a single workflow?

00:44:52 Can I say this part I want to run in a local model and that part I want to run on O3 Pro or whatever?

00:44:58 I don't know if that's even out on the API.

00:45:00 It's certainly not out in chat, but where's O3 Pro?

00:45:02 Come on.

00:45:02 And they have O4 and 4.0 as well.

00:45:05 Oh my gosh, it's even.

00:45:07 Yeah, absolutely.

00:45:08 You can mix and match as your heart desires.

00:45:12 So LingChain, that first open source tool that we have, makes it really easy to pass messages from one OM provider to another in that kind of model agnostic format.

00:45:23 And so if you're using LingChain's model abstractions from one node to the next, it's quite easy to use.

00:45:30 Yeah, that's really cool.

00:45:31 And you could even do things, I imagine, such as I want to call a certain model that's really good at coding, maybe Cloud3.7 or something like that.

00:45:40 But I want to call, now I need to call another one that's better at tool usage and is more creative now that I have the answer, right?

00:45:46 A little bit like my weirdo perplexity thing went and wrote Python code to answer my history question, right?

00:45:53 Totally.

00:45:53 And it's really interesting to think about the pattern of using a model as a router.

00:45:59 So you can imagine like a user asks a question and you give some model the context that's like, I have three model providers that I can use.

00:46:09 Model provider A is really great at research.

00:46:12 Model provider B is really good at solving coding problems, etc.

00:46:15 And so first, the user question gets routed through that router node, and then that can send and basically delegate to one of the other nodes based on that model's reasoning decision.

00:46:27 So that is kind of a cool multi-agent architecture that you could design with Langrass pretty easily.

00:46:33 One other thing that I wanted to note when you were asking about running Python code in nodes, kind of LM or non-agentic patterns, is that we have this main graph API, which is what most folks use.

00:46:46 But we've also introduced an imperative API that allows you to decorate functions with kind of two key things.

00:46:53 One is an entry point decorator that's like kind of indicative of the start node in your graph.

00:46:59 And then another one is a task decorator.

00:47:01 And so if you already have kind of a workflow-like system or functions already written, you can easily turn that into a LNGraph workflow just with a couple of decorators, which is very nice.

00:47:12 I like it.

00:47:13 I like it a lot.

00:47:14 Let's talk about just what if we look inside LNGraph, surely it's written in Rust, right?

00:47:20 That has to be written in Rust.

00:47:22 Still in Python.

00:47:23 The library itself is written in Python.

00:47:25 So it's easy to understand.

00:47:28 Do you all have external contributors and take pull across and stuff like that?

00:47:32 Yeah, we do.

00:47:33 I think we see a bit more engagement on the LangChain side because LangChain itself is more involved with new features released by model providers or things like that.

00:47:44 We see more activity there.

00:47:46 And LangChain is where all of our integrations lie.

00:47:48 So like the LangChain OpenAI package or LangChain Anthropic.

00:47:52 So that's where most of the community engagement is.

00:47:54 But, you know, like in the other good open source project, we've got open issues.

00:47:58 and discussions and a Slack help channel for LandGraph users as well.

00:48:02 Right, right, a community.

00:48:03 Okay, cool.

00:48:04 Well, I was going to say you had 174 contributors in LandGraph, but I thought that was pretty good in terms of number of people, but you've got 3,600 in LangChain.

00:48:13 So yeah, that's pretty wild.

00:48:15 Used by 237,000 projects.

00:48:18 Yeah, it is really impressive kind of the scope of usage there.

00:48:21 I think it's the biggest like developer community in the AI space.

00:48:26 So it's really nice to have so many eager contributors and get to use that as kind of the foundation for the more model driven operations in LandGraph.

00:48:35 I always like to use the Python web frameworks as measuring sticks or whatever for these things.

00:48:42 So for example, if you look at search for Flask on GitHub, right?

00:48:46 It's, where are you Flask?

00:48:47 Come here.

00:48:47 It's got 70,000 stars, which is pretty awesome.

00:48:50 You guys have 107, like just to give people a sense of like how popular this is.

00:48:55 And I also bring this up because there are people out there go, oh, I can't believe you're doing an AI topic.

00:49:00 I'm so tired of AI.

00:49:01 I can't take any more AI, which I get on one hand.

00:49:04 Like on the other, this is how significant it is.

00:49:08 It's like literally revolutionizing tech and non-tech before our eyes.

00:49:12 It's like history in the making.

00:49:13 It's like the invention of the web a little bit, I think.

00:49:15 What are your thoughts?

00:49:16 I understand kind of the things are so novel and I understand wanting to push back against such big change.

00:49:23 But I think one of the reasons that I like LaneGraph as a tool so much is that it really lets you balance the AI when you need it and not when you don't.

00:49:33 We talk a lot about kind of finding yourself on this workflow versus agents curve.

00:49:38 The more like pure agent is much less predictable and pure workflow is predictable, but maybe not quite as useful.

00:49:46 And I think it lets you pick like wherever you want to be on that curve.

00:49:50 And so hopefully that's also relevant for listeners who are like, man, I'm not.

00:49:53 super interested in AI applications, but like maybe I have this one huge workflow

00:49:58 where one step could really use the help of an LLM. And so I think it's a nice like on-ramp into AI usage for developers and just the customizability is very valuable. But yeah, I mean, I understand like the general hesitation. I think it's kind of revolutionizing our industry and it's unpredictable.

00:50:17 I agree. One other thing I'd like to throw out there is I think rightly so a lot of people are concerned about the environmental impacts of heavy AI usage. On the other hand, I think there's a lot of interesting things you can do with local models and the local models really, they really don't make any difference running them, not necessarily training them. Like for example, I was running a 7 billion parameter model for this Git project that I'm doing and this Git tool. And I think I have a little iStats menu thing for my my computer's energy usage right now it's using between 30 says 13 watts but it bumps around like 13 14 watts when the llm was running it jumped all the way up to 20 which is like one led light bulb for four seconds right so if people who are concerned about those things like you can run these models locally and still get a huge amount of benefit even if they you don't get like the full deep research, massive, massive type of stuff you get from the cloud.

00:51:16 It's still really, really impactful, I think.

00:51:18 Yeah, definitely.

00:51:19 I think that like really leans into the idea of like build simple when you can.

00:51:23 Like a lot of these systems can be relatively simple and context windows are widening.

00:51:29 And I think if you can construct a solution that just meets your needs, but doesn't do anything like crazy outside of it, it's both going to be better environmentally and like more reliable of a system.

00:51:40 Yeah, I was talking to Ines Montani about this whole topic, but mostly about the open source, or at least open weights models and things like that.

00:51:51 And one of the things she really focused on was about task-specific models or models that are really focused on solving a certain problem.

00:51:59 And it sounds to me like combining that idea with Lengraph and sort of bringing in multiple models to the model router, I think you called it, could be really cool.

00:52:09 So instead of running huge models, I run five small ones.

00:52:12 But in coordination, they actually become very powerful.

00:52:16 One of the challenges of using LLMs is reliability if tasks are ambiguous.

00:52:22 It's not going to do a good job if you don't tell it what you want it to do.

00:52:25 And so, yeah, if you have these really specialized tools and you only route things to, or I say tools, what I really mean is models, to clarify when tools is also overloaded.

00:52:35 But yeah, if you have very specialized models and you can kind of properly route queries and questions and tasks and demands to them, I think that's the best way to have a reliable system.

00:52:47 Yeah, it's probably faster too.

00:52:48 And lower environmental footprint.

00:52:50 The one bonus, the one good thing I think here is that the negative environmental impact is directly correlated with cost.

00:52:59 So people's incentives are aligned for trending towards less environmental impact.

00:53:05 even if they don't care about it, right?

00:53:07 They just want to save money.

00:53:09 That's still going to get kind of the same output.

00:53:11 I'm actually really excited.

00:53:12 I won't be able to go to PyCon this year, but I'm excited to watch some of the talks after the fact.

00:53:17 And I helped kind of review the talk submissions this year.

00:53:20 And it seems like there's some really great ones focusing on environmental impacts of your Python code and how to reduce those and, you know, how to think about that on an individual versus like large scale.

00:53:31 And I think it's really great that that's kind of driving more public conversation now.

00:53:36 Yeah, yeah.

00:53:37 Don't tell your LLM things at the end.

00:53:39 Go on.

00:53:39 Yeah.

00:53:42 So let's wrap this up with maybe a bit of a showcase.

00:53:46 Have you got some example apps or things you've seen build or things people are doing that you're like, there's really cool stuff you can do with a link graph and link chain or LLMs in general.

00:53:56 What's some cool stuff you've seen out there people building?

00:53:58 I mentioned the email assistant as a very simple one that I think is satisfying just in that the utility is really high and that's saving folks a lot of time.

00:54:09 I think the social media agent is a cool idea if you're like, I don't want to spend a bunch of time working on social media engagement, but I do want to kind of keep up with the most important updates in my space and then also kind of contribute.

00:54:23 I think hopefully I'll have some better answers in the short term, still kind of onboarding at BlaineChain and trying to better understand customer use cases.

00:54:32 Very cool.

00:54:33 One of the things that I think, just thinking out loud of the examples of things that'd be really amazing is you look at research labs and academia in general, especially the research heavy ones, how much those folks have to read long detailed papers and assess whether they even make any sense.

00:54:52 you could set up some kind of hygienic workflow that just watches for new things being published in your field looks to summarize them, determines the impact and relevance and then brings you like a digest a weekly digest. Well here's what's happened in academia for you and do you have other questions that could be like your interrupt or your inbox sort of thing like well which of these would you like us to dive into right and like maybe really go in and analyze these further and I don't know. It seems like when you're really trying to summarize text or process it or correlate, I don't know. It's just, there's so many possibilities there.

00:55:28 Yeah, definitely. And it's really cool to think about how extensible that is. You could kind of build this like general system for a research agent that's going to provide you with a summary. And then different users can be like, okay, here are the three topics that I'm most interested in, like provide me with the summary for those.

00:55:44 Nice to basically think about like individual users specifying things that they want to narrow in on or like specialties that they want to emphasize.

00:55:52 Super fun.

00:55:53 All right.

00:55:54 How about a last thing here, a roadmap?

00:55:57 Where are things going?

00:55:59 What should people maybe have been asking for that might be showing up they should be on the lookout for?

00:56:04 One thing I mentioned a little bit earlier is that kind of node level cache.

00:56:08 I think that'll just be a nice performance boost for folks, especially folks looking to really scale with their lane graph applications.

00:56:15 The thing that we're focusing on the most now is kind of this happy path for those pre-built. So the like create agent functions or some other frameworks have classes. I think, for example, with human in the loop, I'm working on a feature right now that makes it really easy to use kind of default patterns for human in the loop with those pre-built agents.

00:56:35 So maybe you have like tools A, B, and C, and for all of them, you want default logic such that when the tools run, a human has to accept the tool call before or when the tools are recommended by an LLM before the tool actually runs.

00:56:50 So basically, just emphasizing really making it easier to get started with those like create agent pre-builts, because we think there's going to be increasing demand on the like, how do I in 10 lines of code get started with a really functional agent?

00:57:04 Oh, this is very Pythonic, right? Like it has a lot of, you can put, you can do all the things with it if you want, but then you're down in the details and you're doing advanced programming type stuff, right? But what's the import library? Do the few things have magic happen, right?

00:57:21 I think those like quick start guides are great if they're truly quick. And so I think just kind of shooting for that on our end.

00:57:28 Yeah, that's cool. I would also, this is pure speculation, but maybe informed speculation.

00:57:33 I don't know.

00:57:33 If I were to guess, people coming to do web stuff in Python are pretty CS-like folks, maybe not pure, like they don't necessarily have CS degrees, but they've got that way of thinking.

00:57:46 Like they know what a unit test is, even if they don't do them.

00:57:48 They know about SQL, even if they use an ORM or whatever.

00:57:51 Then we've got the data science folks where before the AI revolution, that was like, well, this is where people who are not really programmers sort of get their first step into Python, and then they kind of get hooked.

00:58:03 But they start by doing these real simple things like the projects you're talking about or the features you're talking about.

00:58:08 And then they realize, oh, well, I can do a little more.

00:58:10 And then they sort of work their way backwards into becoming Python programmers.

00:58:14 I would say that people coming to AI are maybe even less formal than the data science folks, right?

00:58:20 It's a little even further along that spectrum there.

00:58:22 And so really making those people feel welcome until they become a little more programmer-focused is probably really important.

00:58:29 I recall you chatted on your kind of developer trends for 2025 forecast podcast about the value of being able to get started in Python if you've never written a single line of code and it being pretty easy.

00:58:41 And then also folks like the or teams like the folks at Astral developing tools for really advanced users and people who really want to make Python a sophisticated system.

00:58:52 And I think we basically with LangGraph want to provide that same benefit of you can get started with a couple lines of code and then also like you want to deploy tons of parallel instances, running parallel processes and streaming responses with all of these features.

00:59:08 Like you can do that too.

00:59:09 Yeah, that's awesome.

00:59:10 Yeah, you start with one, grow to the other if that's the path you're on, right?

00:59:13 I guess one other thing that I'll mention roadmap wise is both LangChain and LangGraph integrate with LangSmith, which is our commercial product.

00:59:24 And we didn't talk a ton about observability and more of the prompt engineering or evaluation side of things that is often tied into agentic workflows.

00:59:33 But yeah, so if you're building applications with LangGraph, using LangSmith for observability can be super valuable, especially when you're at scale.

00:59:40 Yeah, monitoring for AI app performance, super cool.

00:59:43 I guess maybe one more is LangChain Studio or LangStudio, the studio for debugging.

00:59:49 So if you're developing your lane graph application, you can just run lane graph dev in your terminal.

00:59:56 And then that pops up with kind of a local studio.

00:59:59 You can like step through your graph.

01:00:02 Yeah, that's a great screenshot there.

01:00:03 Or yes, but that makes it really easy to debug things locally and just kind of understand the flow of your system in real time.

01:00:11 And then we also offer a lane graph platform where you can do this kind of thing as well, but deployed locally.

01:00:17 Awesome.

01:00:18 Well, final call to action.

01:00:19 People are interested in getting started with all these ideas.

01:00:22 What do you tell them?

01:00:23 I would say look forward to our new docs drop this week.

01:00:27 I think it's going to really emphasize helping folks get started with those create agent pre-builds.

01:00:33 Can they just go to linkchain.com and click on docs and go from there?

01:00:37 Okay.

01:00:37 Yeah.

01:00:37 So we have our linkchain docs there, our link graph docs there, and it should be quite easy to get started.

01:00:43 And obviously I mentioned our kind of community forums earlier, but we have a community help slack.

01:00:47 open issues and discussions, et cetera. So feel free to ask questions there.

01:00:51 And then this interrupt conference you talked about, is this going to be live streamed or recorded and videos available?

01:00:58 Yes, we should have talk recordings and demo recordings available as well. One other resource that I should mention is that we are kind of trying to grow in the education space. And so we also offer a Langrath course, and we'll be releasing a new course next week, kind of focusing on those ambient agents.

01:01:20 And that's a really great way to get started if you're maybe not quite ready to write code, but just kind of want to learn more about the LandGraph features.

01:01:26 Or if you are ready to write code, it has some awesome resources and notebooks as well.

01:01:32 Well, very interesting.

01:01:33 And it's an exciting time to be working in code.

01:01:37 It's changing fast.

01:01:38 It's great to talk about these cool new systems that we get to use and explore.

01:01:42 Yeah, well, looking forward to seeing what you all keep creating.

01:01:45 Thanks for being back on the show, Sydney.

01:01:47 Yeah, thank you so much for having me.

01:01:48 Yeah, bye.

01:01:50 This has been another episode of Talk Python To Me.

01:01:53 Thank you to our sponsors.

01:01:54 Be sure to check out what they're offering.

01:01:56 It really helps support the show.

01:01:58 This episode is sponsored by Posit Connect from the makers of Shiny.

01:02:02 Publish, share, and deploy all of your data projects that you're creating using Python.

01:02:07 Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

01:02:14 Posit Connect supports all of them.

01:02:16 Try Posit Connect for free by going to talkpython.fm/posit, P-O-S-I-T.

01:02:22 And it's brought to you by Auth0.

01:02:25 Auth0 is an easy-to-implement, adaptable authentication and authorization platform.

01:02:30 Think easy user logins, social sign-on, multi-factor authentication, and robust role-based access control.

01:02:37 With over 30 SDKs and quick starts, Auth0 scales with your product at every stage.

01:02:42 Get 25,000 monthly active users for free at talkpython.fm/auth zero.

01:02:49 Want to level up your Python?

01:02:50 We have one of the largest catalogs of Python video courses over at Talk Python.

01:02:54 Our content ranges from true beginners to deeply advanced topics like memory and async.

01:02:59 And best of all, there's not a subscription in sight.

01:03:02 Check it out for yourself at training.talkpython.fm.

01:03:05 Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:03:10 We should be right at the top.

01:03:11 You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

01:03:21 We're live streaming most of our recordings these days.

01:03:23 If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:03:32 This is your host, Michael Kennedy.

01:03:33 Thanks so much for listening.

01:03:34 I really appreciate it.

01:03:36 Now get out there and write some Python code.

