WEBVTT

00:00:00.001 --> 00:00:02.600
There are many reasons it's a great time to be a developer.

00:00:02.600 --> 00:00:06.380
One of them is because there are so many choices around data access and databases.

00:00:06.380 --> 00:00:10.300
So this week, we take a tour with our guest, Jim Fulton,

00:00:10.300 --> 00:00:15.000
of some of the databases you may not have heard of or haven't given a try yet.

00:00:15.000 --> 00:00:18.540
You'll hear about the pure Python database, Zodb.

00:00:18.540 --> 00:00:22.340
There's Zerodb, an end-to-end encrypted database

00:00:22.340 --> 00:00:25.380
in which the database knows nothing about the data it's even storing.

00:00:25.620 --> 00:00:30.880
And NewtDB, spanning the world of Zodb and JSON-friendly Postgres.

00:00:30.880 --> 00:00:37.120
This is Talk by Thunderby, episode 105, recorded Thursday, March 16, 2017.

00:00:37.120 --> 00:00:40.500
Developers, developers, developers, developers.

00:00:40.500 --> 00:00:43.640
I'm a developer in many senses of the word

00:00:43.640 --> 00:00:48.000
because I make these applications, but I also use these verbs to make this music.

00:00:48.000 --> 00:00:52.540
I construct it line by line, just like when I'm coding another software design.

00:00:52.540 --> 00:00:55.760
In both cases, it's about design patterns.

00:00:55.760 --> 00:00:57.240
Anyone can get the job done.

00:00:57.240 --> 00:00:58.760
It's the execution that matters.

00:00:58.760 --> 00:01:00.220
I have many interests.

00:01:00.220 --> 00:01:00.880
Sometimes...

00:01:00.880 --> 00:01:04.560
Welcome to Talk Python to Me, a weekly podcast on Python,

00:01:04.560 --> 00:01:07.620
the language, the libraries, the ecosystem, and the personalities.

00:01:07.620 --> 00:01:09.740
This is your host, Michael Kennedy.

00:01:09.740 --> 00:01:11.740
Follow me on Twitter, where I'm @mkennedy.

00:01:11.740 --> 00:01:15.620
Keep up with the show and listen to past episodes at talkpython.fm

00:01:15.620 --> 00:01:18.200
and follow the show on Twitter via at Talk Python.

00:01:19.200 --> 00:01:23.280
This episode is brought to you interruption-free by GetStream.

00:01:23.280 --> 00:01:25.840
That's right, GetStream, a new sponsor of the show,

00:01:25.840 --> 00:01:27.560
has a really cool offer for you guys.

00:01:27.560 --> 00:01:31.100
If you're building an application that has some form of activity stream

00:01:31.100 --> 00:01:33.900
like you might see in Slack or Facebook or Instagram and others,

00:01:33.900 --> 00:01:36.900
then you owe it to yourself to have a look at GetStream.

00:01:36.900 --> 00:01:42.280
They provide scalable, reliable, and personalizable hosted API feeds as a service.

00:01:42.280 --> 00:01:46.360
The feed is the most intensive component of these types of applications,

00:01:46.540 --> 00:01:50.040
yet there's no need for you to reinvent the underlying feed technology

00:01:50.040 --> 00:01:54.620
when GetStream has the infrastructure and a Python API already in place.

00:01:54.620 --> 00:01:58.760
Go from zero to scalable feed in hours, not weeks or months.

00:01:58.760 --> 00:02:03.520
They even use advanced machine learning to serve up personalized results to each and every user.

00:02:03.520 --> 00:02:08.980
Stream powers the feeds for over 500 companies, including Makerspace and Fabric,

00:02:09.220 --> 00:02:11.600
with a total of 70 million end users.

00:02:11.600 --> 00:02:18.280
Try the API yourself in a short five-minute interactive tutorial at talkpython.fm/stream.

00:02:18.280 --> 00:02:21.300
Be sure to create an account and try it for yourself.

00:02:21.300 --> 00:02:22.540
It helps support the show.

00:02:22.540 --> 00:02:25.300
Jim, welcome to Talk Python.

00:02:25.300 --> 00:02:26.440
Thank you. It's nice to be here.

00:02:26.440 --> 00:02:27.740
It's great to have you here.

00:02:27.820 --> 00:02:34.160
We have a whole bunch of really cool topics generally around data, but not all data, right?

00:02:34.160 --> 00:02:38.480
So we're going to talk about Zodb, something called ZeroDB,

00:02:38.480 --> 00:02:41.980
which is something I'd never heard of and really interesting, actually.

00:02:41.980 --> 00:02:42.900
NewtDB.

00:02:42.900 --> 00:02:48.720
And then a little bit more process with some agile concepts and continuous integration and so on.

00:02:48.720 --> 00:02:51.660
But of course, before we get to all those, let's start at the beginning.

00:02:51.660 --> 00:02:52.360
What's your story?

00:02:52.360 --> 00:02:53.140
How did you get into programming?

00:02:53.140 --> 00:02:58.660
I was exposed to programming fairly young, although back then it wasn't very common or very accessible.

00:02:58.660 --> 00:03:06.980
I'd say I really got hooked in grad school when I was doing research on rainfall runoff model calibration.

00:03:06.980 --> 00:03:13.580
And I had to hack some alternate statistical techniques, calibration techniques, into a rainfall runoff model.

00:03:13.580 --> 00:03:15.640
And I found that I enjoyed that quite a bit.

00:03:15.640 --> 00:03:20.780
That became, for years, I was a civil engineer slash hydrologist.

00:03:20.780 --> 00:03:27.280
And the software aspect of it kept pulling me and pulling me until it finally extracted me.

00:03:27.280 --> 00:03:30.360
I think that's really interesting.

00:03:30.360 --> 00:03:35.240
A lot of people get into programming that way and somewhat grudgingly like,

00:03:35.240 --> 00:03:39.560
okay, I have to learn this programming thing to make whatever it is I'm doing actually work, right?

00:03:39.560 --> 00:03:42.840
But I sort of went down that path myself to some degree.

00:03:42.840 --> 00:03:47.180
And after a few years, I realized, actually, what am I doing this other stuff for?

00:03:47.180 --> 00:03:48.500
This programming stuff is really great.

00:03:48.580 --> 00:03:49.800
I'm just going to go do more of that.

00:03:49.800 --> 00:03:54.300
And it's funny how life is sort of serendipitous like that.

00:03:54.300 --> 00:03:56.000
But it's also good, right?

00:03:56.000 --> 00:03:57.780
So was that original bit of work?

00:03:57.780 --> 00:03:59.380
Was that in Python or was that in something else?

00:03:59.380 --> 00:04:00.080
Oh, no.

00:04:00.080 --> 00:04:00.920
That was in Fortran.

00:04:00.920 --> 00:04:02.040
Oh, yeah.

00:04:02.040 --> 00:04:02.600
Fortran.

00:04:02.600 --> 00:04:07.000
I mean, I went through a lot of languages over my career.

00:04:07.000 --> 00:04:10.320
That work was in 1981.

00:04:11.760 --> 00:04:12.120
Okay.

00:04:12.120 --> 00:04:14.300
So probably not Python.

00:04:14.300 --> 00:04:16.100
Yeah, definitely not Python.

00:04:16.100 --> 00:04:17.680
Because it was 10 years before it released.

00:04:17.680 --> 00:04:20.960
But, yeah, I've used a lot of different languages.

00:04:20.960 --> 00:04:22.740
I used Fortran for a long time.

00:04:22.740 --> 00:04:24.780
I used PL1 for a little while.

00:04:24.780 --> 00:04:27.260
I used ADA for a little while.

00:04:27.260 --> 00:04:29.300
I really like OO languages.

00:04:29.300 --> 00:04:32.360
I used – I couldn't afford Smalltalk for a long time.

00:04:32.360 --> 00:04:34.880
So I used a language called Actor for a while.

00:04:34.880 --> 00:04:44.380
And then much later, I did an interesting application with GNU Smalltalk, which was an adventure in and of itself because it was fledgling and the garbage collector was broken.

00:04:44.380 --> 00:04:47.160
So I had to use a special branch with a non-broken garbage collector.

00:04:47.160 --> 00:04:50.120
So anyway, I've had lots of fun with different languages over the years.

00:04:50.120 --> 00:04:53.360
Yeah, that sounds like you've really been through a lot of them.

00:04:53.360 --> 00:04:56.220
So are you doing mostly Python these days?

00:04:56.220 --> 00:04:57.040
Yeah.

00:04:57.040 --> 00:05:02.740
Although I did – a couple years ago at Zoap Corporation, we did a bunch of Android development.

00:05:02.740 --> 00:05:05.100
I got to use Scala, which I really enjoyed.

00:05:05.100 --> 00:05:12.440
I like to describe Scala as a beautiful evil language because it just invites so much abuse.

00:05:12.440 --> 00:05:26.660
But it allows you to produce beautiful code within the JVM and just insane, mind-blowing notions of type-based development where you – people do interesting development tasks in the compiler.

00:05:26.660 --> 00:05:27.660
Wow.

00:05:27.660 --> 00:05:30.800
That sounds interesting and evil.

00:05:30.800 --> 00:05:31.700
It was a lot of fun.

00:05:31.780 --> 00:05:32.720
I haven't done any of that.

00:05:32.720 --> 00:05:37.260
I did some Rust lately, which kind of reminded me of a lightweight version of that this last year.

00:05:37.260 --> 00:05:38.180
Sure, sure.

00:05:38.180 --> 00:05:38.540
Okay.

00:05:38.540 --> 00:05:41.680
Yeah, I've been wanting to learn Rust, but I haven't really gotten into it.

00:05:41.680 --> 00:05:44.880
I did look at Go recently this year, but I don't know.

00:05:44.880 --> 00:05:45.940
I'm just not sold on Go.

00:05:45.940 --> 00:05:47.160
I still like Python a lot better.

00:05:47.160 --> 00:05:48.100
We'll see about that.

00:05:48.100 --> 00:05:50.440
I'm actually very anti-Go.

00:05:50.440 --> 00:05:50.840
Yeah.

00:05:50.840 --> 00:05:54.000
I think it's bad on multiple levels, but I like Rust quite a bit.

00:05:54.000 --> 00:05:54.420
Okay.

00:05:54.420 --> 00:05:55.200
Well, that's interesting.

00:05:55.300 --> 00:05:56.640
Maybe I'll be learning Rust eventually.

00:05:56.640 --> 00:05:59.160
But what do you do day-to-day these days?

00:05:59.160 --> 00:06:01.920
You're not still at the Zope Corporation doing Android development, right?

00:06:01.920 --> 00:06:02.240
Nope.

00:06:02.240 --> 00:06:02.800
Nope.

00:06:02.800 --> 00:06:05.860
At Zope, I did a ton of different things.

00:06:05.860 --> 00:06:09.340
But towards the end, we were doing some Android development, among other things.

00:06:09.500 --> 00:06:15.400
But these days, I'm splitting my time between paid work to sort of keep the lights on and

00:06:15.400 --> 00:06:16.440
open source work.

00:06:16.440 --> 00:06:21.200
I got an opportunity to work with a company called ZeroDB about a year ago.

00:06:21.200 --> 00:06:25.360
That and also my sons are grown and they've moved away.

00:06:25.360 --> 00:06:27.100
And so we were sort of downsizing.

00:06:27.100 --> 00:06:33.100
So that was an opportunity to sort of have enough money and reduce my run rate and focus

00:06:33.100 --> 00:06:34.720
on some open source stuff for a while.

00:06:35.040 --> 00:06:40.200
And so that's really what I'm doing right now is paying attention to some open source

00:06:40.200 --> 00:06:44.460
projects that have been neglected for a while, as well as exploring some new ideas.

00:06:44.460 --> 00:06:46.100
That's really, really great.

00:06:46.100 --> 00:06:49.100
And it must feel really good.

00:06:49.100 --> 00:06:54.200
It must just be great to just stop, look at these projects that are pretty mature and say,

00:06:54.200 --> 00:06:55.860
okay, I'm going to work on these things.

00:06:55.860 --> 00:06:57.880
And I don't have to go to meetings.

00:06:57.880 --> 00:07:04.000
I don't have to hit some silly deadline that's not realistic or work on some feature that I

00:07:04.000 --> 00:07:05.020
think adds no value, right?

00:07:05.020 --> 00:07:06.600
Just be able to focus on what you want, right?

00:07:06.600 --> 00:07:06.920
Yep.

00:07:06.920 --> 00:07:07.260
Yeah.

00:07:07.260 --> 00:07:08.140
Excellent.

00:07:08.140 --> 00:07:11.080
So we'll be touching on some of these projects, I'm sure.

00:07:11.080 --> 00:07:14.020
So let's start with one of the older projects, I guess.

00:07:14.020 --> 00:07:16.360
It's been around since 1996 with Zodb.

00:07:16.360 --> 00:07:17.600
What is Zodb?

00:07:17.600 --> 00:07:21.400
So Zodb is an object-oriented database for Python.

00:07:21.400 --> 00:07:26.760
And when I say object-oriented, I contrast that with object-based because lots of people

00:07:26.760 --> 00:07:32.280
refer to databases that are object-based that I don't really consider object-oriented.

00:07:32.280 --> 00:07:37.680
The original goal of object-oriented databases, which were a pretty exciting thing back in

00:07:37.680 --> 00:07:44.380
the, I don't know, late 80s, maybe early 90s, was to try to reduce or eliminate the impedance

00:07:44.380 --> 00:07:47.160
mismatch between programming languages and databases.

00:07:47.160 --> 00:07:53.720
So in databases, you know, you have a very different computational model than you do in a programming

00:07:53.720 --> 00:07:57.980
language, especially some of the, you know, especially object-oriented programming languages.

00:07:57.980 --> 00:07:58.300
Yeah.

00:07:58.300 --> 00:08:04.260
You have hierarchies of object graphs in object-oriented languages, and you have highly

00:08:04.260 --> 00:08:12.260
normalized data that work to minimize duplication and let you approach the data from any angle

00:08:12.260 --> 00:08:12.720
you want.

00:08:12.720 --> 00:08:14.820
But there's always this.

00:08:14.820 --> 00:08:19.980
I pull it into Python and build it into an object graph, and then I tear it back into part

00:08:19.980 --> 00:08:22.160
into all the other tables and put it back again, right?

00:08:22.920 --> 00:08:27.760
So these object databases, they try to just say, let's keep them in the same shape, something

00:08:27.760 --> 00:08:28.120
like that?

00:08:28.120 --> 00:08:34.240
Well, again, I don't think there are many object-oriented, I don't know, I'm not sure I know of any object-oriented

00:08:34.240 --> 00:08:36.520
databases today other than ZDV.

00:08:36.520 --> 00:08:37.880
I mean, I'm sure there are some.

00:08:37.880 --> 00:08:43.120
My sense is that a lot of the object-based languages let you get objects, but they don't necessarily

00:08:43.120 --> 00:08:45.660
avoid having to do queries and doing assembly.

00:08:46.460 --> 00:08:50.780
Like, for example, some databases referred to as object-based seem to be more like graph-based,

00:08:50.780 --> 00:08:58.540
where you have the ability to query graphs, but it's still somewhat of a foreign object.

00:08:58.540 --> 00:08:58.980
I see.

00:08:59.100 --> 00:09:03.860
Like, when you use ZODB, there are some exceptions, but you have to subclass a special

00:09:03.860 --> 00:09:09.160
base class, and you have to identify transaction boundaries, which that latter aspect is usually

00:09:09.160 --> 00:09:12.240
automated, depending on your situation.

00:09:12.240 --> 00:09:17.860
But beyond that, it's literally just as if you were working with objects in memory.

00:09:17.860 --> 00:09:19.600
You don't really query a database.

00:09:19.600 --> 00:09:23.560
You know, the way you query a database is the way you query something in Python.

00:09:23.840 --> 00:09:28.080
You maybe look up a key in a mapping, or maybe you access an object's attribute.

00:09:28.080 --> 00:09:33.280
Accessing an object's attribute might cause data to be loaded from the database, but that's

00:09:33.280 --> 00:09:34.220
transparent to you.

00:09:34.220 --> 00:09:34.580
Okay.

00:09:34.580 --> 00:09:35.480
How interesting.

00:09:35.480 --> 00:09:40.880
So does it use, like, interesting descriptors or something like that for attributes to do

00:09:40.880 --> 00:09:41.040
that?

00:09:41.040 --> 00:09:42.700
That's where the base class comes in.

00:09:42.700 --> 00:09:44.860
So the base class, I can't remember.

00:09:44.860 --> 00:09:45.960
There must be a meta class.

00:09:45.960 --> 00:09:50.260
It's been so long since I've implemented it that I don't remember if there's a meta class

00:09:50.260 --> 00:09:50.640
lurking.

00:09:50.640 --> 00:09:52.200
I wouldn't be surprised if there was.

00:09:53.000 --> 00:09:56.680
But basically, yeah, the base class does a couple of things.

00:09:56.680 --> 00:10:00.700
I've actually had a project that I've wanted to do for some time, which is to get rid of

00:10:00.700 --> 00:10:01.380
the base class.

00:10:01.380 --> 00:10:04.940
I have some hacks in mind involving weak reference data structures.

00:10:04.940 --> 00:10:09.620
But basically, the base class, it watches attribute accesses.

00:10:09.620 --> 00:10:13.100
And so when you modify an attribute, it marks the object as dirty.

00:10:13.100 --> 00:10:17.760
And when you access an attribute, if the object is something we call a ghost.

00:10:18.360 --> 00:10:22.660
So in Zodb, when you first load an object from the database, typically by referencing it from

00:10:22.660 --> 00:10:24.540
some other object, it's loaded as a ghost.

00:10:24.540 --> 00:10:30.700
And then when you actually access an attribute, which includes any method, then the ghost is

00:10:30.700 --> 00:10:33.220
activated and its state is loaded into memory.

00:10:33.220 --> 00:10:33.680
I see.

00:10:33.840 --> 00:10:39.520
There's an in-memory object cache that is effectively an incomplete database replica.

00:10:40.220 --> 00:10:45.500
At transaction boundaries, any changes that have been made in the database by other clients

00:10:45.500 --> 00:10:50.580
are then cause any objects that were affected that are in your cache to be invalidated.

00:10:50.580 --> 00:10:53.980
And so then the next time you access them, they're loaded automatically.

00:10:53.980 --> 00:10:59.780
So the data in memory is always consistent with the committed database as of some point in time.

00:10:59.960 --> 00:11:03.400
Okay. Yeah. So you have transaction support and all those sorts of things as well.

00:11:03.400 --> 00:11:04.160
That's pretty interesting.

00:11:04.160 --> 00:11:07.420
So I can get an object from the database and pass it around.

00:11:07.420 --> 00:11:10.520
And maybe it was passed off to some other module.

00:11:10.520 --> 00:11:15.120
But eventually, that reference will be updated because someone committed a transaction.

00:11:15.120 --> 00:11:15.560
Right.

00:11:15.560 --> 00:11:19.240
The only sort of caveat there is that the data...

00:11:19.240 --> 00:11:21.780
So when you access the database, you open a connection.

00:11:21.780 --> 00:11:23.900
And on that connection is a root object.

00:11:23.900 --> 00:11:30.100
And then all other accesses you make are from that root object, possibly through many steps.

00:11:30.100 --> 00:11:32.960
And then there's an object cache associated with that connection.

00:11:32.960 --> 00:11:36.580
And so that connection, its cache, can only be accessed by one thread at a time.

00:11:36.580 --> 00:11:38.780
So you couldn't hand it off to a different process.

00:11:38.780 --> 00:11:42.400
And you couldn't hand it off to another thread and have both threads operating on it.

00:11:42.400 --> 00:11:45.860
But you can have multiple threads with their own database connections.

00:11:45.860 --> 00:11:50.360
And they're essentially coordinating their activities via transaction commit.

00:11:50.360 --> 00:11:55.140
Very much in the way that software transactional memory either was going to...

00:11:55.140 --> 00:11:57.940
I'm not sure this is the current status, but I should have looked it up.

00:11:57.940 --> 00:12:02.800
Much in the way that software transactional memory is supposed to do that for PyPy.

00:12:02.800 --> 00:12:03.540
Interesting. Okay.

00:12:03.540 --> 00:12:07.400
So I don't think I've talked about software transactional memory previously.

00:12:07.400 --> 00:12:11.380
Maybe you could just give us the quick elevator pitch for what that is.

00:12:11.380 --> 00:12:13.260
Well, it's like ZODB, but not persistent.

00:12:13.260 --> 00:12:15.460
I see.

00:12:15.460 --> 00:12:19.560
You know, there are lots of different sort of models for managing concurrency.

00:12:19.560 --> 00:12:24.140
And so some of the traditional models like locking are very expensive.

00:12:24.140 --> 00:12:31.000
And what a lot of systems have moved towards is something called the actor model, where you

00:12:31.000 --> 00:12:33.960
have different independent actors and message queues.

00:12:33.960 --> 00:12:35.880
And that's a model that works really well.

00:12:35.880 --> 00:12:37.960
But of course, it's fairly invasive.

00:12:37.960 --> 00:12:41.240
You have to architect your model or your application around that.

00:12:41.700 --> 00:12:51.220
I think what the PyPy people were wanting to do was to get rid of the GIL and trying to find some way to get rid of the GIL without being crushed by all the locking overhead of managing concurrency.

00:12:52.080 --> 00:13:00.500
So with transactions, you basically have multiple copies of the object space, possibly with shared and copy and write, etc.

00:13:00.720 --> 00:13:04.240
I'm not really super familiar with either their implementation or their status.

00:13:04.240 --> 00:13:08.280
But the idea is that you have basically different copies of memory.

00:13:09.400 --> 00:13:13.840
Those copies get synchronized when you reach a transaction boundary.

00:13:14.020 --> 00:13:18.320
And that means that at the transaction boundary, that's when you sync everything up.

00:13:18.320 --> 00:13:20.800
And everything else is completely independent.

00:13:20.800 --> 00:13:25.880
So you don't need any locks because you've only got one logical thread of control accessing the data.

00:13:25.880 --> 00:13:26.300
Right.

00:13:26.300 --> 00:13:28.220
And so that sounds really cool.

00:13:28.220 --> 00:13:30.920
Like, basically, it's a very optimistic view of the world, right?

00:13:30.920 --> 00:13:33.580
We're going to grab all this stuff in memory and we're going to try to make a bunch of changes.

00:13:33.580 --> 00:13:34.520
And it's probably fine.

00:13:34.520 --> 00:13:40.380
But if it's not fine, then we're actually going to have to retry that function or whatever that was working at it.

00:13:40.380 --> 00:13:49.940
Right. So there's this instead of taking locks, it'll basically restart parts of your code, which is really quite a different way of thinking about solving this problem, isn't it?

00:13:49.940 --> 00:13:52.220
It's how most modern databases work now.

00:13:52.220 --> 00:13:57.200
I know Postgres uses multiversion concurrency control, which is basically the same idea.

00:13:57.200 --> 00:13:58.800
I think Oracle does as well.

00:13:58.800 --> 00:13:59.440
But yeah.

00:13:59.440 --> 00:14:03.540
And so you sort of have to come to terms with what we call conflict errors.

00:14:03.540 --> 00:14:03.980
Yeah.

00:14:03.980 --> 00:14:04.940
Yeah.

00:14:04.940 --> 00:14:09.500
You have to instead of being blocked, you have to deal with here's how I resolve it when something went wrong.

00:14:09.620 --> 00:14:13.660
I mean, it's fine if it's all within one database or within your memory.

00:14:13.660 --> 00:14:19.620
But if I've called two web services and written a file and then it says, no, no, roll back.

00:14:19.620 --> 00:14:19.860
Right.

00:14:19.860 --> 00:14:20.760
Well, now what, right?

00:14:20.760 --> 00:14:21.100
Yep.

00:14:21.100 --> 00:14:22.280
Already charged your credit card.

00:14:22.280 --> 00:14:22.720
Roll back.

00:14:22.720 --> 00:14:23.520
What are you talking about?

00:14:23.520 --> 00:14:23.840
Yep.

00:14:23.840 --> 00:14:26.080
So it's just a, yeah, it's interesting.

00:14:26.080 --> 00:14:30.220
So would you call Zodb a NoSQL database?

00:14:30.220 --> 00:14:32.760
I mean, was it NoSQL before NoSQL is a thing?

00:14:33.960 --> 00:14:45.120
Well, one of the stories I like to tell about how I learned Python was I was at USGS and we were using this system called RANDRDB, which was based on an earlier system.

00:14:45.120 --> 00:14:49.060
But basically it was based on managing relational data as flat files.

00:14:49.900 --> 00:14:56.400
And since I stopped using that project, it sort of evolved and it called itself NoSQL because it didn't use SQL.

00:14:56.400 --> 00:14:58.280
Right.

00:14:58.280 --> 00:15:00.280
Really, NoSQL is a terrible name.

00:15:00.280 --> 00:15:05.520
To me, in my mind, modern NoSQL databases have nothing to do with not having SQL.

00:15:05.520 --> 00:15:06.260
Yes, I agree.

00:15:06.260 --> 00:15:07.360
Some of them do have SQL.

00:15:07.360 --> 00:15:16.200
You know, really the, the, a better characterization of the, most of the NoSQL databases that I'm familiar with is that they're no transaction.

00:15:16.200 --> 00:15:23.040
And they're no transaction because transactions at some point do limit scalability.

00:15:23.040 --> 00:15:30.260
Although there's, you know, continuing to be work to make databases like Oracle and Postgres scalable even with transactions.

00:15:30.560 --> 00:15:38.460
But the NoSQL databases have much weaker notions of consistency and really are optimized to allow very fast writes.

00:15:38.460 --> 00:15:50.120
And I, the sort of problem domain that I think they're really well suited to is collecting massive amounts of data that you collect and, and analyze, but never really have to update and aren't really part of any business processes.

00:15:50.120 --> 00:15:51.620
Some kind of analytics or something.

00:15:51.620 --> 00:15:52.040
Right.

00:15:52.040 --> 00:15:56.940
And so, so in that sense, ZADB is not a NoSQL database, but it doesn't use SQL.

00:15:56.940 --> 00:16:02.980
Although with Newt, you can, you can now start to leverage SQL in ZADB.

00:16:02.980 --> 00:16:03.220
Yeah.

00:16:03.220 --> 00:16:04.240
We'll talk about Newt as well.

00:16:04.240 --> 00:16:04.740
Yeah.

00:16:04.740 --> 00:16:10.740
I saw a really great quote by somebody who was trying to talk about NoSQL and said something like, my toaster doesn't use SQL.

00:16:10.740 --> 00:16:11.700
Is it NoSQL?

00:16:11.700 --> 00:16:12.100
No.

00:16:12.100 --> 00:16:14.120
I'm a better definition.

00:16:14.120 --> 00:16:20.220
And I really feel like, I feel like, like my definition and your definition are probably quite similar from what you said.

00:16:20.220 --> 00:16:31.800
I feel like NoSQL databases are the ones that give up some relational features in order to be more scalable, possibly more horizontally scalable, things like that.

00:16:31.800 --> 00:16:32.060
Right.

00:16:32.060 --> 00:16:33.940
Like a lot of them give up joins.

00:16:33.940 --> 00:16:37.040
A lot of them give up transactions, but not all of them.

00:16:37.040 --> 00:16:37.300
Right.

00:16:37.300 --> 00:16:40.380
They, they give up different things here and there for different things to optimizing.

00:16:40.860 --> 00:16:57.340
I'm not aware of many, there was a foundation DB, which is no longer a thing that had transactions, but some databases will talk about atomicity, but their notion of atomicity is kind of laughable because, well, we update a single record atomically.

00:16:57.340 --> 00:16:58.740
Yes, exactly.

00:16:58.740 --> 00:17:07.860
But that's not really, I'm sure there's some NoSQL databases out there that are transactional, but if there are, they're probably not scalable the way that some of the other ones are.

00:17:08.780 --> 00:17:12.940
I mean, I think that's, I, to me, in my mind, transactions are the big trade-off.

00:17:12.940 --> 00:17:16.000
And I think it's a trade-off that most people don't really understand.

00:17:16.000 --> 00:17:17.200
Yeah, I think you're probably right.

00:17:17.200 --> 00:17:20.860
If I, if I think of them, the one, the thing they give up first is probably transactions.

00:17:20.860 --> 00:17:22.860
The thing they give up second is probably joins.

00:17:22.860 --> 00:17:23.600
Right.

00:17:23.600 --> 00:17:36.580
I mean, MongoDB does have the isolated operator, which does let you work on multiple documents, but it's, it's not quite the same as, as this just global isolation level serializable that you get in a lot of relational databases.

00:17:36.580 --> 00:17:48.120
Well, and in fact, the giving up joins is really closely related to that because giving up joins means that there are more problems for which only being able to do one operation at a time atomically makes sense.

00:17:48.120 --> 00:17:48.520
Yep.

00:17:48.520 --> 00:17:49.140
Absolutely.

00:17:49.140 --> 00:17:49.880
Nice.

00:17:49.880 --> 00:17:50.100
Okay.

00:17:50.100 --> 00:17:52.480
So if I want to use ZeoDB, how do I get started?

00:17:52.480 --> 00:17:53.620
Can I just pip install it?

00:17:53.620 --> 00:17:53.820
Yep.

00:17:53.820 --> 00:17:54.120
Okay.

00:17:54.120 --> 00:17:55.120
What's it written at?

00:17:55.120 --> 00:17:55.880
Is it written in Python?

00:17:55.880 --> 00:17:56.240
Yep.

00:17:56.240 --> 00:17:57.720
It has some C extensions.

00:17:57.720 --> 00:18:00.560
It has some C extensions, but it also works with PyPy.

00:18:00.700 --> 00:18:03.560
There's all of the C extensions have Python versions.

00:18:03.560 --> 00:18:03.880
Right.

00:18:03.880 --> 00:18:08.180
So if you run it with, if you run it with PyPy, then it'll, it'll use the Python versions.

00:18:08.180 --> 00:18:11.720
And zeoDB.org has some pretty decent documentation.

00:18:11.720 --> 00:18:17.560
I was, I was noticing yesterday that I, some topics that I need to add, but getting started is pretty easy.

00:18:17.560 --> 00:18:21.600
You can run it with an in-memory database if you want, just while you're playing around.

00:18:21.600 --> 00:18:21.940
Okay.

00:18:21.940 --> 00:18:22.240
Yeah.

00:18:22.240 --> 00:18:22.900
That's really nice.

00:18:22.900 --> 00:18:24.240
Nice for testing as well, right?

00:18:24.460 --> 00:18:27.480
Well, it's testing stories is especially strong.

00:18:27.480 --> 00:18:31.100
ZeoDB has a, what I call a pluggable storage architecture.

00:18:31.100 --> 00:18:36.820
So the, there's a defined API or set of APIs that storages can provide.

00:18:36.820 --> 00:18:53.220
And then there are a bunch of different storage implementations ranging from an in-memory implementation to a, a file-based implementation to a client server implementation to, or to an implementation that sits on top of, well, there are a couple of client server implementations actually.

00:18:53.500 --> 00:18:56.920
And then there's a implementation that sits on top of a relational database.

00:18:56.920 --> 00:19:01.960
And then there are also, we sort of follow a pattern of, of layering those with adapters.

00:19:01.960 --> 00:19:06.220
And so one of the interesting adapters for testing is something called the demo storage.

00:19:06.220 --> 00:19:14.240
And with a demo storage, you have a demo storage, wraps two storages, a base storages, a storage and a changing storage.

00:19:14.240 --> 00:19:14.500
Okay.

00:19:14.500 --> 00:19:22.280
And so in testing, what you'll typically do is you'll have for a suite or a set of tests, you'll, you might set up a base database.

00:19:22.360 --> 00:19:26.420
And then each test will use a demo storage on top of that.

00:19:26.420 --> 00:19:29.760
And then, you know, whatever changes are made are made in the changes.

00:19:29.760 --> 00:19:31.720
And then the demo storage is discarded.

00:19:31.720 --> 00:19:33.540
And then next test creates a new one.

00:19:33.540 --> 00:19:39.180
Oh, that's a really cool feature because one of the super painful things of testing is, well, how do I load up the test data?

00:19:39.180 --> 00:19:41.720
How much is enough to be representative, et cetera, et cetera.

00:19:42.160 --> 00:19:46.300
So you can put like, a snapshot on top of the data in a sense, right?

00:19:46.300 --> 00:19:46.900
Basically.

00:19:46.900 --> 00:19:49.480
And you can layer that as many levels deep as you want.

00:19:49.480 --> 00:19:55.820
In fact, we've had, I've written Selenium tests where basically there were sort of push and pop operations on your database.

00:19:55.820 --> 00:20:00.020
So you make some changes and then push another demo storage on top of that.

00:20:00.220 --> 00:20:08.020
And then for, for staging, what, what, what we've often done was to, one of the, one of the layers, one of the layers you can add is something called a before storage.

00:20:08.020 --> 00:20:12.320
And what it does is it wraps a, a, a, a writable storage, like our client server storage.

00:20:12.880 --> 00:20:17.520
But it, it, it says, okay, only show me the data as of this point in time.

00:20:17.520 --> 00:20:20.200
And then that becomes the base for a demo storage.

00:20:20.200 --> 00:20:22.460
And then you have a file storage as your changes.

00:20:22.460 --> 00:20:30.980
And now you can stage a large production database, make substantial changes to it, but it's all in, in, in this sort of layered snapshot.

00:20:30.980 --> 00:20:37.040
So, which you can then discard after staging and it doesn't affect any of the actual production data.

00:20:37.040 --> 00:20:38.420
Yeah, that's really cool.

00:20:38.640 --> 00:20:43.160
Okay. So that sounds like the storage system is, is really robust there.

00:20:43.160 --> 00:20:48.020
And of course that's going to play into zero DB when we get into it.

00:20:48.020 --> 00:20:52.460
But let me ask you two quick questions on zero DB before we move on.

00:20:52.460 --> 00:20:54.900
When is it a good idea to use zero DB?

00:20:54.900 --> 00:20:57.580
Like what's the ideal use case for this?

00:20:57.580 --> 00:21:01.900
I think a really good use time to use it is when you don't want to spend a lot of time writing software.

00:21:01.900 --> 00:21:03.840
Yeah, sure.

00:21:03.840 --> 00:21:08.580
So it makes writing software a lot easier in a lot of ways because you're, you're, again,

00:21:08.580 --> 00:21:11.400
you've, you don't have that database impedance mismatch.

00:21:11.400 --> 00:21:16.200
Does it store things in the basically pickled form or something to that effect?

00:21:16.200 --> 00:21:16.640
Right.

00:21:16.640 --> 00:21:17.500
Okay.

00:21:17.500 --> 00:21:21.060
So you could just say, these are the things I want in the database, put them in the database

00:21:21.060 --> 00:21:22.040
and they're the database, right?

00:21:22.040 --> 00:21:23.780
As long as, as long as they're pickleable.

00:21:23.780 --> 00:21:26.820
And we could or could not have a discussion about pickle.

00:21:26.820 --> 00:21:30.220
Pickle, pickle, pickle has a bit of a bad reputation.

00:21:30.220 --> 00:21:32.500
That's a little bit fudtastic.

00:21:32.500 --> 00:21:34.060
Yeah, sure.

00:21:34.480 --> 00:21:36.980
But, but anyway, yeah, it basically uses pickle.

00:21:36.980 --> 00:21:38.920
So you can store anything that's pickleable.

00:21:38.920 --> 00:21:39.440
All right.

00:21:39.440 --> 00:21:40.120
Nice.

00:21:40.120 --> 00:21:42.380
And you talked about the good testing story as well.

00:21:42.380 --> 00:21:44.400
When should we not use Zodb?

00:21:44.400 --> 00:21:46.880
You shouldn't use Zodb.

00:21:46.880 --> 00:21:49.400
And I think this is changing actually, but.

00:21:49.400 --> 00:21:51.940
Maybe it's being changed by things like NewtDB, right?

00:21:52.100 --> 00:21:57.840
Well, it's being changed by, for example, when, when you, I think Newt, I think Newt can help

00:21:57.840 --> 00:21:58.360
quite a bit.

00:21:58.360 --> 00:21:58.640
Yeah.

00:21:58.640 --> 00:22:06.080
Because Zodb can sit on top of say Postgres or Oracle, it can scale more or less as far

00:22:06.080 --> 00:22:06.860
as they can scale.

00:22:06.860 --> 00:22:07.320
Right.

00:22:07.320 --> 00:22:07.620
Okay.

00:22:08.020 --> 00:22:13.600
Traditionally, Zodb has managed its own, provided its own search facilities on the client side.

00:22:13.600 --> 00:22:19.580
And so you, when you do that aggressively, you end up with lots of extra objects in the

00:22:19.580 --> 00:22:21.100
database to support indexing.

00:22:21.100 --> 00:22:24.800
So, so there are Zodb based implementations of B-trees.

00:22:24.800 --> 00:22:29.960
And then on top of that, various sorts of indexes like inverted indexes and regular B-trees

00:22:29.960 --> 00:22:35.060
indexes and things that are sort of like Postgres GIN indexes a little bit.

00:22:35.060 --> 00:22:39.720
But that tends to bloat the database quite a bit and cause lots of extra rights and lots

00:22:39.720 --> 00:22:41.000
of opportunities for conflicts.

00:22:41.000 --> 00:22:46.860
So I've in the past sort of said, well, don't necessarily use, if your application is very

00:22:46.860 --> 00:22:50.260
search intensive, then maybe you don't want to use Zodb.

00:22:50.260 --> 00:22:55.340
If your application is sort of object intensive and, you know, you're, you're primarily working

00:22:55.340 --> 00:23:00.620
on application objects and traversing application objects, then, then it's a much better fit.

00:23:00.620 --> 00:23:06.940
But I think especially with Newt, by pushing the search back into the relational database,

00:23:06.940 --> 00:23:10.300
it can greatly reduce some of the challenges.

00:23:10.300 --> 00:23:12.920
And plus you just have a much more powerful search engine.

00:23:12.920 --> 00:23:13.280
Sure.

00:23:13.280 --> 00:23:16.500
So let's talk about NewtDB a little bit, then we'll come back to Zodb.

00:23:17.760 --> 00:23:23.200
So Newt is kind of a marriage between Zodb, which we talked about a lot of the features

00:23:23.200 --> 00:23:23.520
there.

00:23:23.520 --> 00:23:28.600
And it's one of its shortcomings, I guess you could say, is it is really hard to query.

00:23:28.600 --> 00:23:34.800
You talked about how your app is search intensive, then maybe you don't want to use it because

00:23:34.800 --> 00:23:36.440
this is not really normalized.

00:23:36.440 --> 00:23:42.340
It's not flat text and integers and stuff in columns, but it's object graphs as binary

00:23:42.340 --> 00:23:42.920
stuff.

00:23:42.920 --> 00:23:49.640
So doing that is challenging, but something like Postgres is really good at storing that

00:23:49.640 --> 00:23:50.380
data and querying it.

00:23:50.380 --> 00:23:55.460
So NewtDB, you called this the amphibious database, which I think is really interesting.

00:23:55.460 --> 00:23:56.060
Right.

00:23:56.060 --> 00:23:56.440
What is it?

00:23:56.440 --> 00:23:56.600
Okay.

00:23:56.600 --> 00:24:00.020
Well, I'd like to argue with your previous assertion, but let's, let's come back to that.

00:24:00.020 --> 00:24:01.940
Which one is that?

00:24:02.240 --> 00:24:07.900
Well, so in terms of searching, it's the issue isn't so much that the search capabilities

00:24:07.900 --> 00:24:13.360
of Zodb catalogs, which is sort of the common pattern for this, are not really that different

00:24:13.360 --> 00:24:17.000
from a lot of the NoSQL database search mechanisms.

00:24:17.000 --> 00:24:22.440
In fact, a lot of the NoSQL mechanisms, even something like SQLAlchemy, to a fault, I think,

00:24:22.440 --> 00:24:25.080
tries to express searches as data.

00:24:25.080 --> 00:24:29.100
And so the catalog is often quite good at that.

00:24:29.100 --> 00:24:36.840
In fact, if you're indexing data fits in memory, the search, the searching in Zodb, I mean, I've

00:24:36.840 --> 00:24:39.120
seen it actually smoke Postgres.

00:24:39.120 --> 00:24:40.320
Wow.

00:24:40.320 --> 00:24:40.600
Okay.

00:24:40.720 --> 00:24:45.700
But for larger databases where it's not all in memory, then, you know, Postgres ends up

00:24:45.700 --> 00:24:46.200
being a win.

00:24:46.200 --> 00:24:50.100
But it's not so much that it's hard to search, other than that you can't use SQL.

00:24:50.100 --> 00:24:52.920
But I think most humans can't use SQL anyway.

00:24:52.920 --> 00:24:53.400
Right.

00:24:53.400 --> 00:25:00.060
But anyway, so the ease of search is debatable, but I think it's reasonable to expect that on

00:25:00.060 --> 00:25:02.080
average, Postgres is going to do a lot better.

00:25:02.080 --> 00:25:09.000
And so the reason I called Newt the amphibious database was that it sort of gives you two views

00:25:09.000 --> 00:25:09.620
on your data.

00:25:09.780 --> 00:25:13.860
It gives you a very Python-centric, object-oriented view on your data via Zodb.

00:25:13.860 --> 00:25:20.300
One of the problems that traditional object-oriented databases have had in terms of what they've

00:25:20.300 --> 00:25:22.380
been criticized for is that they're kind of closed.

00:25:22.380 --> 00:25:23.960
They're limited to a single language.

00:25:23.960 --> 00:25:27.560
And they may even depend very heavily on the classes.

00:25:27.560 --> 00:25:31.280
I mean, that's the whole point is, you know, in Zodb, when you're storing objects, they're

00:25:31.280 --> 00:25:32.960
objects that have specific classes.

00:25:32.960 --> 00:25:37.680
And traditionally in Zodb, if you wanted to access the data, you had to have the class around.

00:25:37.680 --> 00:25:40.820
So it's a little bit more of a restrictive environment.

00:25:40.820 --> 00:25:41.760
Right.

00:25:41.760 --> 00:25:44.140
So if I want to call it from like JavaScript, it's not going to be fun.

00:25:44.140 --> 00:25:44.480
Right.

00:25:44.480 --> 00:25:44.900
Right.

00:25:44.900 --> 00:25:51.320
So what the idea is, is in Newt, you've got your regular OO Python view of your data.

00:25:51.320 --> 00:25:53.320
And then you also have a Postgres view of your data.

00:25:53.320 --> 00:25:55.660
And in Postgres, you can see your data as JSON.

00:25:56.500 --> 00:26:00.900
You can access it from anything that can access JSON in Postgres.

00:26:00.900 --> 00:26:04.900
So you could conceivably write reporting applications that reported against it.

00:26:04.900 --> 00:26:08.780
You can index it and you can search it using PostgresQL.

00:26:08.780 --> 00:26:09.340
Okay.

00:26:09.340 --> 00:26:09.700
Interesting.

00:26:09.700 --> 00:26:13.740
So basically it stores two copies of any given record and it keeps them in sync.

00:26:13.740 --> 00:26:16.440
One pickled version and one JSON version.

00:26:16.440 --> 00:26:21.820
And then you leverage the JSON capabilities of Postgres to work with that thing from other

00:26:21.820 --> 00:26:22.220
languages.

00:26:22.780 --> 00:26:23.260
Okay.

00:26:23.260 --> 00:26:28.240
There's also sort of lurking around there some interesting patterns about synchronizing

00:26:28.240 --> 00:26:28.700
your data.

00:26:28.700 --> 00:26:32.020
So Newt has sort of two modes you can use it in.

00:26:32.020 --> 00:26:37.440
It has the sort of default mode where it writes the JSON data as it's committing the transaction.

00:26:37.440 --> 00:26:43.560
But there's also sort of asynchronous mode where you can run a separate updater process that

00:26:43.560 --> 00:26:47.280
watches the database and generates the JSON asynchronously.

00:26:47.280 --> 00:26:52.820
And one of the things I think that's interesting about that is that you can generalize that.

00:26:52.820 --> 00:26:59.100
So you could, for example, eventually, instead of updating JSON in Postgres, you could update

00:26:59.100 --> 00:27:00.900
an Elasticsearch database.

00:27:01.360 --> 00:27:06.640
Or you could even conceivably asynchronously update a relational representation of the data.

00:27:06.640 --> 00:27:06.920
Right.

00:27:06.920 --> 00:27:07.260
Exactly.

00:27:07.260 --> 00:27:12.480
Right now you're just taking it and turning it into JSON because it's such a close fit.

00:27:12.480 --> 00:27:18.060
But theoretically, you could have a SQLAlchemy type representation as well.

00:27:18.060 --> 00:27:19.220
Something to that effect, right?

00:27:20.500 --> 00:27:27.020
So what flexibility does the Postgres add besides just other clients or other technologies?

00:27:27.020 --> 00:27:28.880
Is there better searching?

00:27:28.880 --> 00:27:31.080
Can I work with more data?

00:27:31.080 --> 00:27:32.200
What's the story?

00:27:32.200 --> 00:27:34.800
Postgres has a large community behind it.

00:27:34.800 --> 00:27:38.060
So there are lots of people working on scaling Postgres in various ways.

00:27:38.060 --> 00:27:45.480
So yes, I'm sure you can work with more data than you can with, say, the built-in client server

00:27:45.480 --> 00:27:47.500
storage in Zodb.

00:27:47.500 --> 00:27:52.380
Although there is a project called Neo where they're doing some interesting things in terms

00:27:52.380 --> 00:27:56.540
of scaling database without Postgres.

00:27:56.540 --> 00:27:59.620
But also, Postgres has this interesting model.

00:27:59.620 --> 00:28:07.460
I don't know if Oracle does this, but in Postgres, when you create an index, you can index expressions

00:28:07.460 --> 00:28:08.820
rather than indexing columns.

00:28:08.820 --> 00:28:09.060
Okay.

00:28:09.060 --> 00:28:11.160
And that gives you a lot of power.

00:28:11.160 --> 00:28:16.500
So for example, if you're building a text index, you can have, instead of saying, I want to

00:28:16.500 --> 00:28:20.940
index this column, you can say, well, here's a Postgres function, which could be written

00:28:20.940 --> 00:28:27.080
in Postgres's stored procedure language, or it could conceivably be written in Python.

00:28:27.080 --> 00:28:32.560
But here's a function that will extract the text from this data record.

00:28:32.900 --> 00:28:37.580
And this function that's extracting the text from the data record could actually make queries

00:28:37.580 --> 00:28:40.040
and get text from related data records.

00:28:40.040 --> 00:28:42.080
We're actually using that in the project.

00:28:42.080 --> 00:28:47.720
And then what happens is then you say, okay, now I want to build an index on this function.

00:28:48.280 --> 00:28:54.260
And what happens is that at index time, it goes through the data and calls that function,

00:28:54.260 --> 00:28:57.780
gets the result of that function, and builds the index based on that.

00:28:57.780 --> 00:29:03.340
And so the function could be doing pretty interesting, possibly expensive things,

00:29:03.340 --> 00:29:06.680
and none of that has to happen at search time.

00:29:06.680 --> 00:29:08.980
It can all happen at index time.

00:29:08.980 --> 00:29:09.640
Right.

00:29:09.640 --> 00:29:10.040
Okay.

00:29:10.040 --> 00:29:10.880
That's really interesting.

00:29:10.880 --> 00:29:15.500
So basically, your inserts might get a little slower and your updates might get a little slower,

00:29:15.500 --> 00:29:19.760
but it could be really worth it if it dramatically improves your query speed.

00:29:19.760 --> 00:29:23.860
Something that came to mind, I was thinking, it's like, well, if you have, say, an email address,

00:29:23.860 --> 00:29:27.300
you could index just the domain part of the email address.

00:29:27.300 --> 00:29:33.020
I want to find everybody in this company, which has this google.com or whatever in there,

00:29:33.020 --> 00:29:34.360
their email address, right?

00:29:34.360 --> 00:29:35.660
Would something like that?

00:29:35.660 --> 00:29:36.440
Absolutely.

00:29:36.440 --> 00:29:37.180
Okay.

00:29:37.180 --> 00:29:37.840
Absolutely.

00:29:37.840 --> 00:29:42.280
Well, for example, I think most people index their, in Postgres, for example,

00:29:42.280 --> 00:29:45.480
when you have a text column, and it's not a free text.

00:29:45.480 --> 00:29:49.940
It's like a person's name or a city name or something like that.

00:29:49.940 --> 00:29:56.740
I think most people tend to index those incorrectly because they index it based on,

00:29:56.740 --> 00:29:59.860
just by creating an index on the column.

00:29:59.860 --> 00:30:06.400
And A, there's a certain way that you build those indexes so that they're usable in like queries.

00:30:06.900 --> 00:30:11.820
But also, if you want it to be able to search a case insensitively,

00:30:11.820 --> 00:30:14.760
what you really need to do is you need to index calling lower on it.

00:30:14.760 --> 00:30:15.680
Exactly.

00:30:15.680 --> 00:30:16.120
Yeah.

00:30:16.120 --> 00:30:17.120
Yeah.

00:30:17.120 --> 00:30:24.120
I find that lowercase, lowercase or case insensitivity in a lot of databases can be really challenging

00:30:24.120 --> 00:30:27.880
if you want to index the thing that has to be case insensitive, right?

00:30:27.880 --> 00:30:30.660
You've got to maybe even change your schema a little bit,

00:30:30.660 --> 00:30:34.580
like store the original and a lowercase version and put the index on the lowercase version

00:30:34.580 --> 00:30:36.140
or something funky like that, right?

00:30:36.140 --> 00:30:37.580
But you don't have to do that.

00:30:37.580 --> 00:30:40.960
See, that's the beauty of this feature of Postgres.

00:30:40.960 --> 00:30:44.740
And I have to be careful to say this feature of Postgres because I don't know that it's not

00:30:44.740 --> 00:30:45.480
in other databases.

00:30:45.480 --> 00:30:50.800
But this pattern of indexing expressions is wildly powerful.

00:30:50.800 --> 00:30:57.680
And it's one of these things that people should zen up on because once you start thinking about

00:30:57.680 --> 00:31:00.620
it that way, then lots of doors open up.

00:31:00.840 --> 00:31:01.060
Yeah.

00:31:01.060 --> 00:31:02.640
It sounds really powerful to me.

00:31:02.640 --> 00:31:07.420
And I can certainly think of some places I would have used it had I had it available,

00:31:07.420 --> 00:31:08.500
but I don't.

00:31:08.500 --> 00:31:13.700
Another interesting example is that in a lot of applications that I work with, the data are

00:31:13.700 --> 00:31:14.400
hierarchical.

00:31:14.400 --> 00:31:19.720
Think of a content management system where the content is arranged hierarchically, possibly

00:31:19.720 --> 00:31:20.560
by organization.

00:31:20.560 --> 00:31:26.100
And there's often interesting security policies about what you can access based both on who

00:31:26.100 --> 00:31:27.700
you are and where you are in the tree.

00:31:27.700 --> 00:31:35.060
And so you can – and the most common – the sort of most common case is to ask, can you view

00:31:35.060 --> 00:31:35.700
this document?

00:31:36.440 --> 00:31:42.860
And so you can write a function that says, okay, for any particular piece of content, which

00:31:42.860 --> 00:31:44.320
principles can view this document?

00:31:44.320 --> 00:31:49.280
And then – and you can write a function that returns an array of principles that indexes that

00:31:49.280 --> 00:31:54.760
document and then create something called the GIN index, which is basically an inverted index

00:31:54.760 --> 00:31:57.620
that allows you to say, okay, here's a set of principles.

00:31:57.620 --> 00:31:59.080
Can any of them view this document?

00:31:59.220 --> 00:32:02.760
Where the set of principles may be the user and the groups that they're in.

00:32:02.760 --> 00:32:03.180
Yeah.

00:32:03.180 --> 00:32:08.660
And you basically can say, okay, can this set of principles access this particular record?

00:32:08.660 --> 00:32:13.700
And that can be an index query, even though in order to make that decision, at some point

00:32:13.700 --> 00:32:17.920
you have to walk the tree to find all the security assertions.

00:32:17.920 --> 00:32:19.760
Excuse me, security assertions.

00:32:19.760 --> 00:32:20.220
Yeah, yeah.

00:32:20.220 --> 00:32:25.680
You can have sort of inherited security stuff that flows down the tree and use your little

00:32:25.680 --> 00:32:29.620
function to build the index without actually putting on every single level.

00:32:29.620 --> 00:32:30.700
Okay.

00:32:30.700 --> 00:32:31.700
That sounds awesome.

00:32:31.700 --> 00:32:32.620
All right.

00:32:32.620 --> 00:32:36.500
So NewtDB is definitely an interesting project.

00:32:36.500 --> 00:32:42.660
What's – how does its, like, ideal use case vary from, say, ZODB?

00:32:42.660 --> 00:32:46.520
Well, it addresses two of the major objections to ZODB.

00:32:46.520 --> 00:32:53.120
I would say the major objections to ZODB would be it's transactional, which I believe limits

00:32:53.120 --> 00:32:56.640
scalability at some point, although, again, that limit is getting higher and higher all

00:32:56.640 --> 00:32:57.060
the time.

00:32:57.060 --> 00:33:01.860
But the other – and I actually think that's a limitation that most people should ignore.

00:33:01.860 --> 00:33:08.440
But then I'd say the two biggest objections are the searchability and the overhead associated

00:33:08.440 --> 00:33:13.120
with trying to support that and the complexity associated with trying to support that and access

00:33:13.120 --> 00:33:13.780
from outside.

00:33:13.780 --> 00:33:19.780
So people with ZODB databases, there's a temptation to feel like their data is imprisoned, especially

00:33:19.780 --> 00:33:22.020
if you're not very familiar with the technology.

00:33:22.920 --> 00:33:28.320
So Newt basically gives you – sort of makes the datable accessible without Python, without

00:33:28.320 --> 00:33:29.420
any special skills.

00:33:29.420 --> 00:33:31.000
It's just sort of sitting there in JSON.

00:33:31.000 --> 00:33:34.720
You can search it using a much more powerful search mechanism.

00:33:34.720 --> 00:33:37.320
Now, you still – you know, there's no free lunch.

00:33:37.320 --> 00:33:43.320
So you can search it using clever tricks like indexing functions against the JSON, but you

00:33:43.320 --> 00:33:44.740
have to learn how to do that.

00:33:44.960 --> 00:33:52.360
And you have to understand how to use Postgres as explained so you can see how the query optimizer

00:33:52.360 --> 00:33:55.240
is analyzing the query.

00:33:55.240 --> 00:33:55.780
Sure.

00:33:55.780 --> 00:33:57.940
That's a good thing to do anyway if you're working with data.

00:33:57.940 --> 00:34:01.220
Know how to ask, are you using an index?

00:34:01.220 --> 00:34:02.260
Which index are you using?

00:34:02.260 --> 00:34:02.960
And so on.

00:34:02.960 --> 00:34:03.360
Right.

00:34:03.360 --> 00:34:05.080
But still, interesting.

00:34:05.080 --> 00:34:05.580
Okay.

00:34:05.580 --> 00:34:11.980
Can you update the JSON and have it update – those updates flow to the ZODB Python side?

00:34:11.980 --> 00:34:16.160
Or is it read-only on the JSON and read-write on the ZODB side?

00:34:16.160 --> 00:34:16.920
The latter.

00:34:16.920 --> 00:34:17.340
Okay.

00:34:17.340 --> 00:34:17.640
Yep.

00:34:17.640 --> 00:34:19.240
The JSON is a read-only representation.

00:34:19.240 --> 00:34:19.920
Gotcha.

00:34:19.920 --> 00:34:20.420
Okay.

00:34:21.080 --> 00:34:22.500
That seems pretty reasonable.

00:34:22.500 --> 00:34:23.020
All right.

00:34:23.020 --> 00:34:24.200
Very, very nice.

00:34:24.200 --> 00:34:27.060
So let's come back and talk about ZODB.

00:34:27.060 --> 00:34:32.380
So the ZODB stuff that you've been doing kind of led you to work with ZODB.

00:34:32.380 --> 00:34:36.680
And they actually were the catalyst for a really cool move for you.

00:34:36.680 --> 00:34:39.380
But let's start with just what is ZODB?

00:34:39.380 --> 00:34:44.340
Well, so ZODB was about trying to have your data be encrypted at rest.

00:34:44.700 --> 00:34:57.480
So the only client – so with ZODB, the goal was that only the database client, the applications would be able to unencrypt the data, would be able to access the data because the encryption would happen on the client.

00:34:57.480 --> 00:34:57.780
Right.

00:34:57.780 --> 00:35:01.100
There's different levels of encrypted at rest.

00:35:01.100 --> 00:35:06.880
But you're talking about even encrypted in the memory of the database, and the database itself can't get it, right?

00:35:06.880 --> 00:35:13.660
That's a different level than I've set up a file system where when I save the data finally to disk, that part is encrypted.

00:35:13.660 --> 00:35:15.440
Like there's more to it than just that, right?

00:35:15.440 --> 00:35:17.180
Well, not much more to it than that.

00:35:17.180 --> 00:35:20.840
I mean, it was certainly encrypted in the memory of the database server.

00:35:20.840 --> 00:35:23.940
So the database server itself couldn't see the data.

00:35:23.940 --> 00:35:28.380
But by the time it reached the application, it was unencrypted in the application's memory.

00:35:28.380 --> 00:35:28.780
Sure.

00:35:28.780 --> 00:35:37.520
So they sell this – they position this as a really great database for the cloud because your data might live in the cloud.

00:35:38.120 --> 00:35:50.420
But even if somebody were to get access to it and, you know, walk away with your virtual machine in some unknown way or even just log into the database server, potentially your data is still safe, right?

00:35:50.420 --> 00:35:51.200
Right.

00:35:51.200 --> 00:35:51.420
Okay.

00:35:51.420 --> 00:35:52.380
That's pretty unique.

00:35:52.380 --> 00:35:55.460
I don't really know a lot of other databases that have that.

00:35:55.460 --> 00:36:11.060
And the fact that, you know, one of ZVDB's – I mean, a decision that I made a long time ago with ZVDB was that the search – basically all the sort of application logic would happen on the client, that the server was really dumb.

00:36:11.620 --> 00:36:15.000
That was partly a reflection of my ability to write a smarter server.

00:36:15.000 --> 00:36:26.520
But that actually, you know, fit ZeroDB's use cases really well because, you know, by doing everything on the client, only the client needs to have unencrypted data.

00:36:26.520 --> 00:36:27.100
I see.

00:36:27.100 --> 00:36:35.300
So basically the client or the application, even if it's like a web app, it has some kind of private key that it can decrypt its data with.

00:36:35.300 --> 00:36:37.640
So how does it do queries and things like that?

00:36:37.640 --> 00:36:52.120
In ZVDB, when you're – in doing a query the sort of the traditional way, you're accessing B-trees and higher-level facilities built on B-trees that are regular database objects just like any other object.

00:36:52.120 --> 00:36:54.720
So they're encrypted.

00:36:54.720 --> 00:36:55.860
They're part of your database.

00:36:55.860 --> 00:36:59.160
So when you – let's say that you want to look up something in a B-tree.

00:36:59.640 --> 00:37:04.440
What happens is you access the top of the B-tree and that gets loaded from the server.

00:37:04.440 --> 00:37:08.560
And then you start walking the nodes of the B-tree to find the value you're looking from.

00:37:08.560 --> 00:37:11.640
And those nodes get loaded from the server as necessary.

00:37:11.640 --> 00:37:13.120
And then they're all cached locally.

00:37:13.120 --> 00:37:13.540
I see.

00:37:13.540 --> 00:37:19.920
Then the execution of the actual way of clause or whatever happens on the client.

00:37:21.000 --> 00:37:29.840
And so you said it was the 0DB guys that made it possible for you to make this transition to sort of being independent, working on these open source projects and so on.

00:37:29.840 --> 00:37:30.540
Yeah.

00:37:30.540 --> 00:37:30.560
Yeah.

00:37:30.560 --> 00:37:31.280
You want to tell us that story?

00:37:31.280 --> 00:37:33.780
Well, I don't know that there's much to tell.

00:37:33.780 --> 00:37:37.780
They needed some scalability help.

00:37:38.240 --> 00:37:40.880
And also they didn't really have a lot of deep knowledge of Zodb.

00:37:40.880 --> 00:37:46.480
So I could sort of provide a lot of help in terms of how they architect their application.

00:37:46.480 --> 00:37:54.680
They funded – the sort of client-server part of Zodb was written a long, long time ago and it used async core.

00:37:54.680 --> 00:38:05.560
And it really needed to be modernized for performance, for maintainability, and also to facilitate adding SSL support.

00:38:05.560 --> 00:38:06.160
Sure.

00:38:06.160 --> 00:38:08.880
And so they funded that along with a bunch of other work.

00:38:08.880 --> 00:38:09.200
Nice.

00:38:09.200 --> 00:38:13.000
And I saw they released 0DB on GitHub not too long ago.

00:38:13.000 --> 00:38:13.740
So that's pretty cool.

00:38:13.740 --> 00:38:15.920
They've really sort of switched gears.

00:38:15.920 --> 00:38:17.720
In fact, I think they've renamed the company.

00:38:17.720 --> 00:38:24.080
So I don't think that the project of 0DB on top of Zodb – I don't think it's actually active at this point.

00:38:24.080 --> 00:38:24.620
Okay.

00:38:24.620 --> 00:38:29.560
Their customers were banks and that sort of financial people.

00:38:29.560 --> 00:38:34.020
And so having a Python database wasn't really all that interesting to them.

00:38:34.020 --> 00:38:34.380
Sure.

00:38:34.580 --> 00:38:38.720
And so they've changed their focus towards dealing with big data.

00:38:39.500 --> 00:38:44.660
And I don't really know all the details, but basically it's the same sort of thing.

00:38:44.660 --> 00:38:52.980
Your data is encrypted at rest, but while you're processing it, then it's encrypted in the processing pipelines.

00:38:52.980 --> 00:38:53.560
Sure.

00:38:53.560 --> 00:38:53.860
Okay.

00:38:53.900 --> 00:39:01.000
I see maybe they've changed the underlying storage engine, but the general idea is still probably more or less the same.

00:39:01.000 --> 00:39:06.080
There's three databases that are probably not super familiar to people.

00:39:06.080 --> 00:39:09.780
Four if you count Postgres, but that one's more familiar to folks.

00:39:10.360 --> 00:39:14.920
I think it's really interesting to look at all these different tradeoffs and study the different databases.

00:39:14.920 --> 00:39:19.140
It gives you a sense for what the value of the tradeoffs are, right?

00:39:19.140 --> 00:39:19.520
Yep.

00:39:19.520 --> 00:39:19.840
Yeah.

00:39:19.840 --> 00:39:20.260
Cool.

00:39:20.260 --> 00:39:21.140
All right.

00:39:21.140 --> 00:39:27.900
So let's switch gears just a little bit towards the process side of things and talk about two projects that you're working on.

00:39:27.900 --> 00:39:35.860
One, a tool for continuous integration like things, and one that's more about Kanban type stuff.

00:39:35.860 --> 00:39:38.520
So first one I want to talk about is Buildout.

00:39:39.000 --> 00:39:43.740
So this is an automation tool written in and extended with Python.

00:39:43.740 --> 00:39:49.020
So is this a continuous integration server, or is this more than that, or what is Buildout?

00:39:49.020 --> 00:39:51.200
It's something different than that.

00:39:51.200 --> 00:39:56.080
So it's really about, let's say you want to work on a Python project.

00:39:56.080 --> 00:40:01.160
So you check out the code, and now you want to actually run stuff.

00:40:01.260 --> 00:40:06.460
And so for a lot of people, what they do is there's a requirements text file sitting around.

00:40:06.460 --> 00:40:11.880
Maybe they create a virtual ENV, and then they run pip against that requirements.txt file.

00:40:11.880 --> 00:40:18.440
Or sadly, what many people will do is they'll just run pip from their machine's system Python

00:40:18.440 --> 00:40:22.520
and install a bunch of things in there, and then they'll have things in there.

00:40:22.520 --> 00:40:25.980
And then they'll run whatever scripts are generated.

00:40:26.120 --> 00:40:30.420
And if the scripts need configuration files, well, maybe they'll write them,

00:40:30.420 --> 00:40:33.120
and they'll check them into version control.

00:40:33.120 --> 00:40:39.300
And if they need extra processes on top of that, it's sort of outside the realm of pip.

00:40:39.300 --> 00:40:42.860
And then the question is, well, what do you do to automate all of that?

00:40:42.860 --> 00:40:49.060
And so Buildout, you know, when we were working on projects many years ago at Zoop Corporation,

00:40:49.060 --> 00:40:52.820
we would, and this was actually before there was even distutils,

00:40:53.340 --> 00:40:57.280
we were in a mode for a while of creating applications for customers.

00:40:57.280 --> 00:41:00.340
And then the customers would run them on their machines,

00:41:00.340 --> 00:41:02.200
and their environments were totally different.

00:41:02.200 --> 00:41:04.620
Their environments were typically completely uncontrolled,

00:41:04.620 --> 00:41:06.980
and usually bad things would happen.

00:41:06.980 --> 00:41:09.280
And so we needed to automate that.

00:41:09.280 --> 00:41:14.000
And in those days, the automation typically involved building Python from source

00:41:14.000 --> 00:41:17.920
because most people's Python environments are in an unpredictable state.

00:41:17.920 --> 00:41:18.280
Okay.

00:41:18.820 --> 00:41:22.920
So you would get like some well-known version and download it and compile it and say,

00:41:22.920 --> 00:41:23.940
we're going to start from here?

00:41:23.940 --> 00:41:27.000
Well, not just, the biggest problem isn't the well-known version,

00:41:27.000 --> 00:41:30.240
although that certainly is part of it, but the contents of site packages.

00:41:30.240 --> 00:41:31.060
Right. Okay.

00:41:31.060 --> 00:41:32.540
Over the years, that evolved.

00:41:32.540 --> 00:41:39.000
And so Buildout was very much geared towards installing exactly the packages you need

00:41:39.000 --> 00:41:41.380
and then generating the artifacts around that.

00:41:41.380 --> 00:41:48.100
So, for example, I have a project related to the Kanban where the JavaScript client is significant,

00:41:48.100 --> 00:41:50.140
and I need to assemble all those artifacts.

00:41:50.140 --> 00:41:55.080
And I, maybe I'm old-fashioned, but it offends me to check them into version control.

00:41:55.080 --> 00:41:55.380
Yeah.

00:41:55.540 --> 00:42:00.540
I have a Buildout configuration that among the things it does is it runs Grunt to,

00:42:00.540 --> 00:42:03.980
what is it Grunt or, I forget what it runs, maybe Grub.

00:42:03.980 --> 00:42:08.360
It runs some JavaScript tools to assemble all the JavaScript requirements.

00:42:08.360 --> 00:42:13.800
And, of course, it uses Buildout's own mechanisms to assemble the Python requirements.

00:42:13.800 --> 00:42:18.800
It generates configuration files that something like PaceScript would need to use.

00:42:18.800 --> 00:42:22.240
It generates daemon configs.

00:42:22.360 --> 00:42:25.920
So, for example, when I run the process, I usually don't run it in the foreground.

00:42:25.920 --> 00:42:28.420
I mean, I may, but I may want to run it in the background.

00:42:28.420 --> 00:42:34.600
And so there's a tool called zdaemon, which is kind of like SupervisorD, but a little bit more.

00:42:34.600 --> 00:42:35.080
Okay.

00:42:35.080 --> 00:42:36.360
A bit simpler.

00:42:36.360 --> 00:42:38.680
And so that has a configuration file.

00:42:38.680 --> 00:42:43.420
Or if you're using Supervisor, you would want to have a Supervisor configuration file.

00:42:43.420 --> 00:42:47.860
And those files may depend on things that are specific to your environment.

00:42:48.020 --> 00:42:53.100
They might depend on, you know, files that are outside the environment that have paths in them.

00:42:53.100 --> 00:42:59.220
I mean, there are all sorts of reasons why you may not be able to have static configurations that are just checked in.

00:42:59.220 --> 00:42:59.580
Right.

00:42:59.580 --> 00:42:59.840
Okay.

00:42:59.840 --> 00:43:07.080
So Buildout will look at the system, look at all the requirements, and put it together in just the way needed for that location, huh?

00:43:07.180 --> 00:43:08.140
That's one way of putting it.

00:43:08.140 --> 00:43:20.840
Basically, with Buildout, you give it a single configuration file that represents all of the parts of what you're trying to deploy, whether you're trying to deploy to production or to CI or staging or to production.

00:43:21.640 --> 00:43:26.160
And it basically says, okay, I've got all these parts that I need to build, and it just basically builds them.

00:43:26.160 --> 00:43:29.600
And it also keeps track of what it's built so that it can unbuild them.

00:43:29.600 --> 00:43:37.300
And, like, if a part specification changes, it knows to uninstall what it did before and then reinstall it.

00:43:37.300 --> 00:43:37.480
Okay.

00:43:37.480 --> 00:43:38.200
That's really cool.

00:43:38.200 --> 00:43:44.680
How much of this is a general software assembly tool and how much of this is for Python projects?

00:43:44.840 --> 00:43:48.400
Like, could I work on a C++ project only with Buildout?

00:43:48.400 --> 00:43:49.080
You could.

00:43:49.080 --> 00:43:54.180
And there are people using Buildout in non-Python environments, but the vast majority is Python.

00:43:54.180 --> 00:43:54.500
Right.

00:43:54.500 --> 00:43:55.440
Because it's written in Python.

00:43:55.440 --> 00:43:59.940
People, Python folks are automatically attracted, you know, disproportionately to it.

00:43:59.940 --> 00:44:00.360
Right.

00:44:00.360 --> 00:44:06.080
And, of course, it has built-in support for assembling Python applications in a particular way that's interesting.

00:44:06.080 --> 00:44:06.420
Right.

00:44:06.420 --> 00:44:07.200
Okay.

00:44:07.200 --> 00:44:14.820
There's a project called SlapOS, which seeks to be a lightweight virtualization environment that's built on top of...

00:44:14.820 --> 00:44:15.320
Buildout.

00:44:15.320 --> 00:44:20.900
And the things that they deploy in that environment, the vast majority of them are not Python.

00:44:20.900 --> 00:44:21.420
All right.

00:44:21.420 --> 00:44:22.840
Yeah, that sounds really interesting.

00:44:22.840 --> 00:44:23.900
Cool.

00:44:23.900 --> 00:44:34.400
One of the comments you made on the page is that software deployment should be highly automated and really should be able to, like, run one or two commands and just you're ready to go.

00:44:34.660 --> 00:44:38.800
And I feel like the more of that that we can do, the better.

00:44:38.800 --> 00:44:45.360
The more frequently we're at least smaller versions because it's not such a challenge for people to get the new version and all sorts of stuff.

00:44:45.360 --> 00:44:47.940
So I think that's a great philosophy there.

00:44:48.100 --> 00:44:54.840
And I think that the sort of DevOps movement has kind of gotten stalled in too much of an ops rut.

00:44:54.840 --> 00:44:59.860
So I see way too little automation in a lot of things that I see.

00:44:59.860 --> 00:45:10.820
At Zone Corporation, we had things to the point where basically we had a representation of our system as a tree that we stored in Zookeeper.

00:45:11.560 --> 00:45:17.980
Each service was, you know, anywhere from two or three to ten lines of very high-level specification.

00:45:17.980 --> 00:45:26.300
And then we had textual models of our entire system for multiple customers and multiple services and multiple applications and how they interconnected.

00:45:26.300 --> 00:45:33.800
And when we wanted to deploy a change, all we did was modify that tree and check it into Git.

00:45:33.800 --> 00:45:35.160
That's really cool.

00:45:35.160 --> 00:45:36.960
And a few minutes later, it would be deployed.

00:45:36.960 --> 00:45:38.540
Yeah, that's the way it should be, right?

00:45:38.540 --> 00:45:41.320
Definitely the way it should be.

00:45:41.960 --> 00:45:42.180
Cool.

00:45:42.180 --> 00:45:47.160
Okay, so let's talk about your final project called Two-Tiered Kanban.

00:45:47.160 --> 00:45:55.200
So I suspect most people know what Kanban is, but maybe you just give us the elevator pitch and then we can talk about the two-tiered version.

00:45:55.200 --> 00:45:55.780
Sure.

00:45:55.780 --> 00:46:00.640
The compelling thing about, well, there's sort of two compelling things about Kanban.

00:46:00.640 --> 00:46:05.960
And one is sort of philosophical, which is that it's very focused on providing value as quickly as possible.

00:46:05.960 --> 00:46:10.940
Whereas in contrast to something like Scrum that I think focuses on doing work.

00:46:10.940 --> 00:46:11.220
Sure.

00:46:11.220 --> 00:46:15.300
So the concept of providing value as quickly as possible.

00:46:15.300 --> 00:46:27.760
We sort of grew this culture at Zove Corporation both as part of trying to be better software developers as well as trying to follow some lean startup kinds of ideas.

00:46:29.380 --> 00:46:38.060
Part of that was related to the fact that we could develop software and check it into Git, but until it was actually in front of customers, it wasn't really providing any value.

00:46:38.060 --> 00:46:52.960
And then the other part of it is really sort of old-fashioned common sense of finish what you start, which Kanban has the highfalutin term of work in progress, limiting work in progress.

00:46:53.080 --> 00:46:57.320
But that's just a fancy-pants way of saying finish what you start before you start something else.

00:46:57.320 --> 00:46:57.420
Right.

00:46:57.420 --> 00:46:58.700
Don't put more stuff on the board.

00:46:58.700 --> 00:46:59.320
Yeah.

00:46:59.320 --> 00:46:59.800
Get it to the end.

00:46:59.800 --> 00:47:00.260
Right.

00:47:00.260 --> 00:47:01.240
Then you put something on the board, right?

00:47:01.240 --> 00:47:04.940
This is kind of like Trello boards if people haven't seen the Kanban boards, right?

00:47:04.940 --> 00:47:05.640
You've got the columns.

00:47:05.640 --> 00:47:11.760
You move the cards from left to right, like from planned to assigned to in-dev and test, whatever.

00:47:12.160 --> 00:47:17.960
But you said that, or the project says, that typical Kanban boards focus on development.

00:47:17.960 --> 00:47:22.580
And products don't, just because they've had development done on them, don't provide value.

00:47:22.580 --> 00:47:28.100
They provide value in features, land, and customers' hands, hopefully through a single button press to deploy them, right?

00:47:28.100 --> 00:47:31.340
And actually, when we started doing this, we were nowhere near a single button press.

00:47:31.340 --> 00:47:35.320
So being able to track things beyond development was actually pretty valuable.

00:47:35.460 --> 00:47:39.500
And often, even with a single button press, there are things that you have to do.

00:47:39.500 --> 00:47:47.520
Like, for example, if your schema changes, you may have to migrate the schema, and you might have to do that before the software is deployed, and there are things.

00:47:47.520 --> 00:47:49.920
But I'd put it a slightly different way.

00:47:49.920 --> 00:47:59.660
So a traditional Trello board or a traditional Kanban board, or even a Scrum board, you have all these trees sitting on the board, but you can't really see the forest.

00:47:59.660 --> 00:48:02.560
Scrum addresses that a little bit through Sprint.

00:48:02.560 --> 00:48:07.900
So perhaps in a Sprint, you're all focused on a single goal, which is good.

00:48:07.900 --> 00:48:18.460
But whereas, you know, the problem with Kanban is it's always been just sort of this sea of separate tasks, and it's hard to know how they relate, and it's hard to know how they relate to value.

00:48:18.460 --> 00:48:30.360
This idea of two-tier Kanban, which, you know, I read about as I was learning about Kanban, but have to this date never really found an implementation of, although I've heard rumors of implementations.

00:48:30.860 --> 00:48:40.140
The basic idea of a two-tier Kanban is that you have a high-level Kanban that represents units of value, typically, you know, features.

00:48:40.140 --> 00:48:41.140
Right.

00:48:41.140 --> 00:48:54.480
Where a feature may require a number of development tasks, and ideally as few as possible, but sometimes, for example, there might be a new feature that requires lots of UI components, and then lots more sort of below the waterline.

00:48:54.480 --> 00:48:54.760
Right.

00:48:54.760 --> 00:49:01.260
Like the designer work, the database work, the APIs to make it go, the data, the backup, the management.

00:49:01.260 --> 00:49:02.760
There can be many things, right?

00:49:02.760 --> 00:49:02.940
Right.

00:49:02.940 --> 00:49:03.440
Of course.

00:49:03.620 --> 00:49:15.320
So the idea is that you want to be able to have – you want to be able to represent the feature as a whole, the value as a whole, and really focus on moving that value to completion and getting the benefit of it.

00:49:15.320 --> 00:49:18.700
But you also need to be able to manage the things that make that up.

00:49:18.700 --> 00:49:28.980
And so you have this high tier, which is the features, and then the low tier, which is, you know, once you've entered development, all the things you need to do to actually, you know, implement that feature.

00:49:29.780 --> 00:49:40.000
And so typically what you have is you have a board where you have features that move across various columns, and then they hit the development column, and then they explode into the various pieces that make up that feature.

00:49:40.000 --> 00:49:40.360
Okay.

00:49:40.360 --> 00:49:48.160
And each – yeah, each one of the things that moves down the board that is a feature, that's basically its own Kanban board as well, right?

00:49:48.160 --> 00:49:48.900
Essentially, yeah.

00:49:48.900 --> 00:49:49.220
Yeah.

00:49:49.220 --> 00:49:50.020
Okay.

00:49:50.020 --> 00:49:50.980
That's the two-tier part.

00:49:50.980 --> 00:49:52.800
Yeah, it sounds really valuable to me.

00:49:52.800 --> 00:50:07.400
I always find these hierarchical things in Scrum or in Kanban really hard to deal with, like, okay, well, this feature costs this much, but the thing I'm working on actually costs this other thing, and someone else has to work on the data part of it, and they need to estimate that.

00:50:07.400 --> 00:50:11.340
And just, you know, it's challenging to represent those.

00:50:11.340 --> 00:50:13.180
So this seems like a nice way to organize it.

00:50:13.180 --> 00:50:15.520
And it provides a little bit of automation around that.

00:50:15.520 --> 00:50:19.620
I mean, you know, most Kanban people will sort of poo-poo estimation.

00:50:20.360 --> 00:50:27.520
And I've been around enough people who needed estimates to know that you can't sort of completely punt on that.

00:50:27.520 --> 00:50:37.760
But I really am a fan of really low-rent estimation and then automation to track the low-rent estimates and basically keeping the process really simple.

00:50:38.660 --> 00:50:49.200
I've been exposed to some environments, some Scrum environments where, and I think this is actually the norm, is that people sort of go through a bunch of motions, and there's a lot of ceremony.

00:50:49.200 --> 00:50:53.160
And a heck of a lot of time gets sucked up in ceremony.

00:50:53.160 --> 00:50:53.520
Right.

00:50:53.520 --> 00:50:54.320
Yep.

00:50:54.320 --> 00:50:55.240
I've seen it as well.

00:50:55.240 --> 00:50:56.740
Okay, cool.

00:50:56.740 --> 00:50:58.140
So we'll definitely include a link.

00:50:58.140 --> 00:51:02.680
And the link goes to a GitHub project that looks like it is executable code.

00:51:02.740 --> 00:51:05.000
What do you actually get when you go to that GitHub repo?

00:51:05.000 --> 00:51:08.580
Well, you get – right now you get a substantial amount of bit rot.

00:51:08.580 --> 00:51:10.600
Okay.

00:51:10.600 --> 00:51:13.920
But that's why I need to – I want to get back to it.

00:51:14.640 --> 00:51:27.560
Some of the bit rot is because initially I punted on authentication and used Persona, Mozilla Persona Project, which actually worked really well, but it relied on Mozilla doing a bunch of work.

00:51:27.560 --> 00:51:29.460
And they finally got tired of doing that work.

00:51:29.460 --> 00:51:33.120
And so they've – they no longer run that service.

00:51:33.120 --> 00:51:34.520
And so I have to go back and –

00:51:34.520 --> 00:51:38.320
That's a challenge for your authentication and identity management.

00:51:38.320 --> 00:51:38.720
Yeah.

00:51:38.720 --> 00:51:39.460
Yeah.

00:51:39.460 --> 00:51:49.660
So my – I need to go back and I want to add hooks to be able to use things like – I don't really want to manage – I don't really particularly want to manage usernames and passwords.

00:51:49.660 --> 00:51:56.280
So I want to be able to work with like Google Auth and various others, you know, Facebook Auth, et cetera, and let people choose that.

00:51:56.280 --> 00:52:05.160
Some other bit rot that I've sort of got is that it was written for Zodb 4 and Zodb 5 changed in ways.

00:52:05.420 --> 00:52:10.220
There's actually discussion on the Zodb list right now about – I don't know if you're familiar with RethinkDB.

00:52:10.220 --> 00:52:10.840
Yeah.

00:52:10.840 --> 00:52:14.220
But so there's this idea of having data pushed to you.

00:52:14.220 --> 00:52:17.660
And that's actually how Zodb works under the hood.

00:52:17.660 --> 00:52:20.240
But that's never really been exposed.

00:52:20.240 --> 00:52:20.780
Right.

00:52:20.780 --> 00:52:25.680
With the transaction commits and sort of refreshing the objects people have memory, right?

00:52:25.680 --> 00:52:25.900
Yeah.

00:52:25.900 --> 00:52:26.260
Right.

00:52:26.260 --> 00:52:36.200
So when you use a number of the Zodb storages, when a transaction commits, then the IDs of all the objects that were modified are pushed to all of the other clients.

00:52:36.200 --> 00:52:38.000
And they're invalidated.

00:52:38.120 --> 00:52:41.400
So there's already interesting information being pushed to clients.

00:52:41.400 --> 00:52:44.740
But that's never really been surfaced at the application level.

00:52:44.740 --> 00:52:49.920
And in Zodb 4, it was really easy with a small monkey patch to get at that.

00:52:49.920 --> 00:52:52.520
And the Kanban relied on that.

00:52:52.520 --> 00:52:55.360
But now in Zodb 5, that's no longer possible.

00:52:55.520 --> 00:53:01.540
So I'm in the process of adding that feature to Zodb 5, adding it as an official feature.

00:53:01.540 --> 00:53:01.820
Yeah.

00:53:01.820 --> 00:53:03.280
That's the way to do it anyway, right?

00:53:03.280 --> 00:53:03.840
Officially?

00:53:03.840 --> 00:53:04.420
Yeah.

00:53:04.420 --> 00:53:04.920
Right.

00:53:04.920 --> 00:53:13.560
Well, the Kanban has been – the original version that we used at Zope Corporation was actually a client server thing on top of the Asana API.

00:53:13.560 --> 00:53:17.720
And so the one that we used there was built on top of Asana.

00:53:17.720 --> 00:53:21.000
And Asana's API became really, really slow.

00:53:21.000 --> 00:53:24.760
They, too, got tired of providing an expensive service for free.

00:53:24.760 --> 00:53:25.760
Yeah.

00:53:25.760 --> 00:53:26.360
Yeah.

00:53:26.360 --> 00:53:28.260
We'll run on this one $10 server over there.

00:53:28.260 --> 00:53:29.280
Exactly.

00:53:29.280 --> 00:53:35.360
So since that, it's been kind of an R&D side project.

00:53:35.360 --> 00:53:42.260
And I'd like to really push it to completion and maybe even try to offer some sort of – offer it as a service.

00:53:42.260 --> 00:53:50.920
Because I wouldn't care so much, especially my last job, which the company was a great company, but they really struggled with process.

00:53:52.020 --> 00:53:56.720
And I think they would have liked to have used the Kanban, but it wasn't quite ready.

00:53:56.720 --> 00:53:59.300
And that was really frustrating for them and for me.

00:53:59.300 --> 00:54:04.400
So I'd like to soon take some time to actually get it much closer to completion.

00:54:04.400 --> 00:54:04.920
Yeah.

00:54:04.920 --> 00:54:07.360
It sounds like a great software-as-a-service type thing.

00:54:07.360 --> 00:54:08.920
So hopefully you can do that.

00:54:08.920 --> 00:54:09.540
All right.

00:54:09.540 --> 00:54:09.920
Very cool.

00:54:09.920 --> 00:54:11.560
Well, it looks like we should probably leave it there.

00:54:11.560 --> 00:54:15.720
We've covered a lot of ground on this episode, but we're pretty much out of time.

00:54:15.720 --> 00:54:18.200
So before we move on, let me ask you two final questions.

00:54:18.200 --> 00:54:23.380
We now have over 100,000 packages on PyPI, so hooray for that.

00:54:23.380 --> 00:54:30.360
And there's many that I'm sure you've come across that are noteworthy, that are not necessarily the most popular, but would be really cool to find out about.

00:54:30.360 --> 00:54:32.380
So what one would you like to recommend people look into?

00:54:32.380 --> 00:54:34.240
Well, it really depends.

00:54:34.240 --> 00:54:35.980
I mean, obviously it depends on what you do.

00:54:36.220 --> 00:54:40.360
But Bodo has delighted me over the years whenever I've had to touch AWS.

00:54:40.360 --> 00:54:42.620
So I'm a big fan of Bodo.

00:54:42.620 --> 00:54:43.800
Yeah, I use Bodo as well.

00:54:43.800 --> 00:54:46.320
I'm also a huge fan of Mach.

00:54:46.320 --> 00:54:46.780
Right.

00:54:46.780 --> 00:54:47.060
Okay.

00:54:47.060 --> 00:54:52.760
I think he did a really nice job of balancing dynamism and functionality.

00:54:52.760 --> 00:54:57.400
I could go on and on, but those are a couple that sort of come to mind.

00:54:57.400 --> 00:54:58.500
And of course, Zodb.

00:54:58.500 --> 00:54:59.240
Of course.

00:54:59.240 --> 00:54:59.800
Yeah.

00:54:59.800 --> 00:55:01.380
And NutDB as well, right?

00:55:01.380 --> 00:55:03.080
Very nice.

00:55:03.080 --> 00:55:03.380
Very nice.

00:55:03.380 --> 00:55:03.940
Okay, cool.

00:55:03.940 --> 00:55:05.280
So thanks for that.

00:55:05.380 --> 00:55:08.520
And finally, when you write some Python code, what editor do you open up?

00:55:08.520 --> 00:55:09.620
Emacs, of course.

00:55:09.620 --> 00:55:10.340
Emacs.

00:55:10.340 --> 00:55:10.840
All right.

00:55:10.840 --> 00:55:12.020
Right on.

00:55:12.020 --> 00:55:14.740
That's definitely a popular one.

00:55:14.740 --> 00:55:16.960
I'm giving a webinar next week on PyCharm.

00:55:16.960 --> 00:55:20.600
And I have to say, I'm actually pretty impressed with PyCharm.

00:55:20.600 --> 00:55:25.440
I like the, you know, as a straight text editor, I still like Emacs a lot.

00:55:25.440 --> 00:55:33.440
But they really assemble a nice package of things along with that, like, you know, database access and REST clients.

00:55:34.320 --> 00:55:37.220
And it's an interesting pile of functionality.

00:55:37.220 --> 00:55:38.220
Yeah, absolutely.

00:55:38.220 --> 00:55:44.340
And when you give that one, maybe if they have it recorded by the time we release this, we can put the link to your webcast in there.

00:55:44.340 --> 00:55:44.820
That'd be cool.

00:55:44.820 --> 00:55:45.920
Okay.

00:55:45.920 --> 00:55:46.720
Awesome.

00:55:46.720 --> 00:55:47.180
All right.

00:55:47.180 --> 00:55:48.940
Well, that all sounds great.

00:55:48.940 --> 00:55:50.500
Any final call to action for the listeners?

00:55:50.500 --> 00:55:52.740
Anything you want them to check out or do?

00:55:53.120 --> 00:55:55.500
Learn about transactions and then check out Newt.

00:55:55.500 --> 00:56:00.520
I'll definitely have Newt, DB, and all the other ones in the show notes so people should be able to get right to them.

00:56:00.520 --> 00:56:01.000
Cool.

00:56:01.000 --> 00:56:01.460
Yeah.

00:56:01.460 --> 00:56:02.600
Jim, thank you for being on the show.

00:56:02.600 --> 00:56:05.060
It's been great to learn about all these different projects with you.

00:56:05.060 --> 00:56:05.980
Thank you for having me.

00:56:05.980 --> 00:56:06.440
You bet.

00:56:06.440 --> 00:56:06.740
Bye.

00:56:09.020 --> 00:56:11.800
This has been another episode of Talk Python to Me.

00:56:11.800 --> 00:56:14.480
Our guest on this episode has been Jim Fulton.

00:56:14.480 --> 00:56:17.220
And this episode is brought to you by GetStream.

00:56:17.920 --> 00:56:23.580
If you're building an app with a feed, make sure to check out GetStream at talkpython.fm/stream.

00:56:23.580 --> 00:56:30.080
They have the intelligent, scalable, and tested feed API you need to be one step closer to launching your app.

00:56:30.080 --> 00:56:32.560
Are you or a colleague trying to learn Python?

00:56:32.560 --> 00:56:37.220
Have you tried books and videos that just left you bored by covering topics point by point?

00:56:37.220 --> 00:56:45.820
Well, check out my online course, Python Jumpstart, by building 10 apps at talkpython.fm/course to experience a more engaging way to learn Python.

00:56:46.320 --> 00:56:53.180
And if you're looking for something a little more advanced, try my WritePythonic code course at talkpython.fm/pythonic.

00:56:53.180 --> 00:56:55.900
Be sure to subscribe to the show.

00:56:55.900 --> 00:56:58.120
Open your favorite podcatcher and search for Python.

00:56:58.120 --> 00:56:59.360
We should be right at the top.

00:56:59.360 --> 00:57:08.660
You can also find the iTunes feed at /itunes, Google Play feed at /play, and direct RSS feed at /rss on talkpython.fm.

00:57:08.660 --> 00:57:13.760
Our theme music is Developers, Developers, Developers by Corey Smith, who goes by Smix.

00:57:14.120 --> 00:57:20.440
Corey just recently started selling his tracks on iTunes, so I recommend you check it out at talkpython.fm/music.

00:57:20.440 --> 00:57:25.800
You can browse his tracks he has for sale on iTunes and listen to the full-length version of the theme song.

00:57:25.800 --> 00:57:27.880
This is your host, Michael Kennedy.

00:57:27.880 --> 00:57:29.160
Thanks so much for listening.

00:57:29.160 --> 00:57:30.340
I really appreciate it.

00:57:30.340 --> 00:57:32.500
Smix, let's get out of here.

00:57:32.500 --> 00:57:32.940
Smix.

00:57:32.940 --> 00:57:42.480
I'll pass the mic back to who rocked it best.

00:57:42.480 --> 00:57:54.740
I'll pass the mic back to who rocked it best.

00:57:54.740 --> 00:57:55.240
you

