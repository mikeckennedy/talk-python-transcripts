WEBVTT

00:00:00.001 --> 00:00:05.520
Even if you got to attend PyCon, there were just too many great talks to go and attend them all.

00:00:05.520 --> 00:00:11.460
Luckily, our friends at the PSF were on top of publishing the videos online for the whole world

00:00:11.460 --> 00:00:17.520
to watch for free. On this episode, we'll meet up with Brett Slacken and replay his path through

00:00:17.520 --> 00:00:24.700
PyCon. We talk about his top 10 favorite sessions from PyCon 2017. This is Talk Python to Me,

00:00:24.700 --> 00:00:28.540
episode 116, recorded May 31, 2017.

00:00:28.540 --> 00:00:57.940
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the

00:00:57.940 --> 00:01:02.540
ecosystem, and the personalities. This is your host, Michael Kennedy. Follow me on Twitter

00:01:02.540 --> 00:01:07.460
where I'm @mkennedy. Keep up with the show and listen to past episodes at talkpython.fm

00:01:07.460 --> 00:01:10.000
and follow the show on Twitter via at Talk Python.

00:01:10.000 --> 00:01:15.360
This episode is brought to you by Rollbar and CodeChip. Be sure to check out what they're

00:01:15.360 --> 00:01:17.900
offering during their segments. It really helps support the show.

00:01:17.900 --> 00:01:21.080
Brett, welcome back to Talk Python.

00:01:21.080 --> 00:01:21.800
Thanks for having me.

00:01:21.880 --> 00:01:27.220
Yeah, it's always a pleasure. We had a really nice time last, almost two years ago on episode

00:01:27.220 --> 00:01:30.340
25. And now we're back to talk about PyCon.

00:01:30.340 --> 00:01:33.760
Yeah, it's been a long time. I can't believe it's been that long. A lot of good episodes

00:01:33.760 --> 00:01:34.140
between.

00:01:34.140 --> 00:01:40.100
Yeah, thanks. It really has been a long time. So we talked a little bit before PyCon about

00:01:40.480 --> 00:01:44.980
another show together. And you had this great idea of like, hey, we're both going to PyCon. Let's kind

00:01:44.980 --> 00:01:50.080
of do a like a PyCon roundup and go through the talks mostly that you went to because I was,

00:01:50.080 --> 00:01:55.020
you know, happily stuck in my booth talking to people. So I didn't get to that many talks. But

00:01:55.020 --> 00:01:59.320
nonetheless, they're all on YouTube. So everyone listening can watch it even if they didn't go

00:01:59.320 --> 00:02:00.180
to PyCon, right?

00:02:00.180 --> 00:02:04.120
Yeah, definitely. And that's, you know, PyCon is a great conference for that reason is that on the

00:02:04.120 --> 00:02:06.820
second day while you're there, they're already uploading talks from the first day.

00:02:07.160 --> 00:02:11.240
So you can even watch some of the talks you missed yesterday. So you can talk to other

00:02:11.240 --> 00:02:15.040
people about those talks while you're still at the conference, which is just really amazing that

00:02:15.040 --> 00:02:21.040
they yeah, yeah, it's really amazing how quickly they come up and the quality, because going there

00:02:21.040 --> 00:02:22.880
really is a bit of a paradox of choice.

00:02:22.880 --> 00:02:26.680
Oh, yeah. And they actually set it up to be that way. Like they'll put all of the best talks,

00:02:26.680 --> 00:02:30.740
quote unquote, best from the speakers that are, you know, most well known for the quality of their

00:02:30.740 --> 00:02:34.640
talks, they put them at the same time. So you can't possibly go to all of the best,

00:02:34.960 --> 00:02:40.440
quote unquote, best talks, you have to go and try different things out and see ones from new

00:02:40.440 --> 00:02:45.080
speakers with different kind of fields of discipline and stuff like that. So it's, that's a big part of

00:02:45.080 --> 00:02:48.540
the fun of being there. And they're able to do that because they know they're all recorded. So people

00:02:48.540 --> 00:02:49.680
don't feel like they're missing out.

00:02:49.680 --> 00:02:55.180
Yeah, they really do a nice job. So I definitely am looking forward to talking about these eight or

00:02:55.180 --> 00:02:59.860
nine talks that we've picked out to discuss. Yeah. But before we do, maybe you know, it's been almost

00:02:59.860 --> 00:03:05.060
two years, since you've been on the show, maybe tell people what you do day to day with Python and

00:03:05.060 --> 00:03:09.980
things like that. Yeah, sounds good. So I'm a software engineer, still working at Google, I work on a

00:03:09.980 --> 00:03:14.960
product called Google surveys. It's a research platform to answer questions, kind of market research and

00:03:14.960 --> 00:03:19.960
survey statistics, we can predict elections and that kind of stuff. And we use a lot of Python to do that.

00:03:19.960 --> 00:03:25.180
So it's hundreds of 1000s lines of Python, everything from Django looking code on the front

00:03:25.180 --> 00:03:31.020
end down to NumPy and statistical functions. And we also use a lot of JavaScript and go and other

00:03:31.020 --> 00:03:35.840
things for other pieces of the system. But overall, it's the majority of our code is in Python. And

00:03:35.840 --> 00:03:39.920
yeah, that sounds like a fun project to work on. Yeah, it's been great. It's I've been working on it for

00:03:39.920 --> 00:03:44.560
many years now. And it just keeps growing. And it's been amazing to see Python grow from you know,

00:03:44.560 --> 00:03:49.600
my first commit was, you know, 2000 lines of Python and to have that grow by 100 or 200

00:03:49.600 --> 00:03:52.780
times. It's been really remarkable that the language kept working.

00:03:52.780 --> 00:03:57.800
It really does grow and stretch pretty well. It's awesome. We'll even talk about some examples

00:03:57.800 --> 00:04:00.320
in some of these talks, like for example, with Instagram, right?

00:04:00.320 --> 00:04:01.080
Yes, exactly.

00:04:01.080 --> 00:04:05.280
So also maybe catch us up on your book. I originally got to know you through

00:04:05.280 --> 00:04:10.740
Effective Python, the book that you wrote a little bit before we had you on the show. And I really liked

00:04:10.740 --> 00:04:14.380
it. So it's still selling. Are you working on new books? Anything like this?

00:04:14.380 --> 00:04:18.720
Yeah, great question. So it's, it ended up getting translated into a bunch of languages. It's doing well.

00:04:19.240 --> 00:04:25.180
translated into Chinese, both traditional and simplified, German, Polish, Korean, Portuguese.

00:04:25.180 --> 00:04:33.700
So it's been crazy to see Japanese also, versions of the book all over the place in the translations

00:04:33.700 --> 00:04:37.600
of the word of, you know, the words Effective Python and all these other languages. So it's been doing

00:04:37.600 --> 00:04:42.640
really well. Weird tweets and other languages that I don't know and translate doesn't really capture

00:04:42.640 --> 00:04:46.880
programming jargon very well. So that's interesting trying to find friends of mine who know these

00:04:46.880 --> 00:04:51.280
languages to help me understand what people are saying. But do they like the book or what?

00:04:51.280 --> 00:04:57.080
Yeah, because it's like dry humor or like a joke about the cover not having a snake on it. You know,

00:04:57.080 --> 00:05:01.080
there's like stuff that it's really hard to get through trans automated translation, right?

00:05:01.080 --> 00:05:01.760
Yeah, absolutely.

00:05:01.760 --> 00:05:06.160
But yeah, so I think I'm looking forward to, you know, everyone's watching the Python death clock of

00:05:06.160 --> 00:05:11.660
Python, two, seven death clock of 2020. And so it'll be interesting to see. I think if you know,

00:05:11.660 --> 00:05:16.060
if there's another if it's good to have another edition of the book in time for that, because so

00:05:16.060 --> 00:05:20.280
much is changing. And I think we'll talk about that today. But no plans yet. I think it's still

00:05:20.280 --> 00:05:22.380
material still really good and is up to date.

00:05:22.380 --> 00:05:26.680
Yeah, excellent. So people want to check that out. That was episode 25 from a couple years ago.

00:05:26.680 --> 00:05:30.120
All right. So yeah, let's let's talk about the talks.

00:05:30.320 --> 00:05:35.000
Yeah, you went to PyCon. I went to PyCon. I didn't get a chance to go to that many talks. And honestly,

00:05:35.000 --> 00:05:41.640
I find the hallway track to be really quite, quite valuable. You make these connections,

00:05:41.640 --> 00:05:46.940
and you can talk to people there that, you know, those aren't recorded. And those won't be,

00:05:46.940 --> 00:05:48.360
you can't relive those, right?

00:05:48.360 --> 00:05:51.740
Yeah, definitely. And I think they're actually are recording the lightning talks now. But that was,

00:05:51.740 --> 00:05:55.000
you know, I think if you went to the conference and just did lightning talks and hallway track,

00:05:55.000 --> 00:05:56.260
you'd probably have a really good time.

00:05:56.260 --> 00:05:58.800
Yeah, the other place that I spent a lot of time was in the open sessions.

00:05:59.000 --> 00:06:01.460
Yeah, that's awesome. Yeah, I didn't get to go to any of those this time.

00:06:01.460 --> 00:06:04.160
Yeah, yeah. And those are still not recorded as far as I know.

00:06:04.160 --> 00:06:04.680
No, they're not.

00:06:04.680 --> 00:06:06.600
It wasn't obvious if they were.

00:06:06.600 --> 00:06:06.780
Yeah.

00:06:06.780 --> 00:06:12.940
All right, cool. But let's focus on the talks that you went to. And I did go to some of them,

00:06:12.940 --> 00:06:18.760
and then also went back and watched the others. All right. So the very, very first talk at PyCon,

00:06:18.760 --> 00:06:22.400
the opening keynote was by Jake Vanderplass.

00:06:22.400 --> 00:06:27.380
Yeah, and he's a longtime PyCon speaker. I mean, he's been there for many years. And I don't know if

00:06:27.380 --> 00:06:32.640
you've seen his other talks before, but he's, you know, he's done tons of them. And he's up at

00:06:32.640 --> 00:06:37.820
University of Washington. He's actually an astronomer. That's his job, which is just crazy

00:06:37.820 --> 00:06:39.840
that that's someone gets to do that professionally.

00:06:39.840 --> 00:06:40.720
So amazing, right?

00:06:40.720 --> 00:06:45.300
Yeah. So yeah, I feel very inadequate whenever I hear him like talking about what he does day to

00:06:45.300 --> 00:06:47.500
day and the science he does. It's like pretty awesome.

00:06:47.760 --> 00:06:54.080
Yeah. A lot of the stuff that they do with Python and astronomy is really fascinating. And what struck

00:06:54.080 --> 00:07:00.040
me about this talk, there were a couple of things. And maybe I'll set the stage before I touch on some

00:07:00.040 --> 00:07:00.720
of the astronomy stuff.

00:07:00.720 --> 00:07:00.880
Sure.

00:07:01.660 --> 00:07:07.580
was basically Jake's theme. I think it was a great way to kick off the conference. It was that

00:07:07.580 --> 00:07:12.680
the people that you are sitting among these 3000 people and everyone else in the community,

00:07:12.680 --> 00:07:20.140
we're all here for Python, but we don't all use Python the same way. And we don't all have the same,

00:07:20.140 --> 00:07:25.940
the same jobs, the same type of challenges and so on. So for example, if I sat down to write like a well

00:07:25.940 --> 00:07:33.840
structured 50 Python file web application that talks to a database, I'll have one way of thinking and

00:07:33.840 --> 00:07:40.580
working with Python. If I have astronomy data, and I want to just explore it dynamically, say in

00:07:40.580 --> 00:07:45.020
IPython notebooks or Jupyter or whatever, that's an entirely different way of working with it. And

00:07:45.020 --> 00:07:50.580
these different ways of working are an opportunity to learn more and catch Python from a different

00:07:50.580 --> 00:07:51.040
perspective.

00:07:51.040 --> 00:07:55.900
Yeah, exactly. And he called it, I think, the mosaic of Python, which I really,

00:07:55.900 --> 00:07:59.860
I really liked the analogy there. And that's a big part of what's great about going to Python,

00:07:59.860 --> 00:08:04.180
or even just watching the talks from it is, you have these people from just very different disciplines

00:08:04.180 --> 00:08:08.900
with very different backgrounds, talking about these subjects. So yeah, he really emphasized that

00:08:08.900 --> 00:08:09.560
very well.

00:08:09.560 --> 00:08:14.300
Yeah, I thought that was a great, great opening message. And it was like, okay, I see that the

00:08:14.300 --> 00:08:20.640
people I'm talking to, maybe they really do have not just a different way of working, but a really good

00:08:20.640 --> 00:08:24.900
reason to not work the same way that I do. And so I think it kind of opened my eyes a little bit to

00:08:24.900 --> 00:08:26.960
appreciating the differences.

00:08:26.960 --> 00:08:32.000
Yeah, definitely. And then he walked us through like all of the tools that he uses, or he knows

00:08:32.000 --> 00:08:37.420
of in the scientific community, kind of went, walked through like, you know, where they came from. And

00:08:37.420 --> 00:08:42.360
it was really interesting to me, because he, the way he actually showed it was in kind of these

00:08:42.360 --> 00:08:47.660
concentric circles of dependencies, you know, where at the core, you know, is Python itself, and then

00:08:47.660 --> 00:08:52.120
something like NumPy, which is really like a fundamental tool for numerical computation and Python.

00:08:52.620 --> 00:08:57.160
But I didn't even realize how many additional layers on top of that there are, you know, in terms

00:08:57.160 --> 00:09:02.940
of machine learning or data processing or things specific to astronomy. And, you know, he basically

00:09:02.940 --> 00:09:06.140
went off the page with how many concentric circles there are.

00:09:06.140 --> 00:09:07.680
Yeah. Yeah.

00:09:07.680 --> 00:09:12.660
Here's Python. Here's a bunch of scientific stuff that you may have heard of. Here's a bunch of,

00:09:12.660 --> 00:09:16.620
you know, higher level scientific stuff that builds on top of that. Here's all the amazing

00:09:16.620 --> 00:09:23.440
things that they're doing at in astronomy on top of that. Oh, and by the way, here's all all of these

00:09:23.440 --> 00:09:30.640
amazing satellites that are coming online, that you basically work with them through Python, which is

00:09:30.640 --> 00:09:31.800
really, really amazing.

00:09:31.800 --> 00:09:35.460
Yeah, that was crazy. Because yeah, like the a bunch of different telescopes he showed,

00:09:35.460 --> 00:09:39.260
and then he like went to the GitHub page where the code is actually completely open source,

00:09:39.260 --> 00:09:44.160
mostly written in Python, and you can actually go in and fix bugs. And that was another thing he was

00:09:44.160 --> 00:09:49.000
basically saying, you know, in there is that and so is I think Katie Huff and her keynote later,

00:09:49.000 --> 00:09:53.240
but, you know, you can go in there and you can you can contribute to these satellites, you know,

00:09:53.240 --> 00:09:57.920
which is crazy. So it's all done in the open, the kind of this open science approach to,

00:09:57.920 --> 00:10:00.860
you know, astronomy that hadn't really been there in the past.

00:10:00.860 --> 00:10:06.640
Yeah, that was another super interesting theme of this talk was how we've seen how successful open

00:10:06.640 --> 00:10:13.140
source has been. And the challenges as science becomes more technology of how do we make science

00:10:13.140 --> 00:10:19.320
reproducible. So let's try to follow a kind of a similar path with open science as we do with open

00:10:19.320 --> 00:10:19.720
source.

00:10:19.720 --> 00:10:23.940
Yeah, definitely. And I think that that's, there's this graph he had, I think he might have tweeted the

00:10:23.940 --> 00:10:27.880
graph last year at some point, but just the graph of like, number of astronomy,

00:10:27.880 --> 00:10:33.040
publications, you know, in academic journals that are using Python, how it's just taking off. And so

00:10:33.040 --> 00:10:38.920
it seems like this is really interesting effect that the open source approach of the Python community

00:10:38.920 --> 00:10:44.620
has had on astronomy in particular, and is starting to have more generally where people are publishing

00:10:44.620 --> 00:10:50.060
their code, their methods, their data, putting them out there so that all the results are reproducible,

00:10:50.060 --> 00:10:55.900
easy to verify, you can't p hack the results so that you're getting fake discoveries and stuff like

00:10:55.900 --> 00:10:56.180
that.

00:10:56.180 --> 00:11:00.560
Yeah, I thought it was really great. And the graph that you're talking about, I mean, it really looked

00:11:00.560 --> 00:11:08.400
like an example of an explosive growth startup out of some sort of growth hack story. But yeah,

00:11:08.400 --> 00:11:11.000
no, this is the number of things using Python now, right?

00:11:11.000 --> 00:11:15.020
Yeah, it makes you think that we just learned how to get into space, or we just invented the telescope,

00:11:15.020 --> 00:11:20.760
because it's just taken off. It's bizarre. So it's really great. And science is very computational

00:11:20.760 --> 00:11:27.420
now, where maybe in the past, it was more about labs or film processing or something like that. It

00:11:27.420 --> 00:11:31.820
seems like data processing is how science is done. And that came across really strongly as well.

00:11:31.820 --> 00:11:36.180
Yeah, it definitely did. One final thing that he covered that I thought was interesting that kind

00:11:36.180 --> 00:11:43.340
of is related to that was, people traditionally had learned in the sciences, some very focused language,

00:11:43.340 --> 00:11:47.340
like there's some language, I don't remember the name of it, that is like, here's how you do astronomy

00:11:47.340 --> 00:11:51.080
programming, you know, IDL or something like that. Yeah, yeah, I believe it was IDL. That's right.

00:11:51.080 --> 00:11:55.720
And he's like, that's really great. You can get astronomy job with that. But if all these people

00:11:55.720 --> 00:12:00.140
now are grad students learning Python, like if for some reason, they don't decide to pursue

00:12:00.140 --> 00:12:05.980
astronomy, they have a super marketable thing that they've learned as part of it, right?

00:12:05.980 --> 00:12:11.140
Yeah, definitely. Yeah, it's much better. And then also people can contribute back to astronomy in a

00:12:11.140 --> 00:12:15.600
way that so it goes both ways. It's two way street, you know, right, like maybe we're programmers,

00:12:15.600 --> 00:12:19.920
we can program really well, but we don't, we're not astronomers, but we might want to like hobbyist

00:12:19.920 --> 00:12:24.360
in it a little bit. And we can actually help out on structuring code or performance or something,

00:12:24.360 --> 00:12:28.100
even if we're not astronomers, right? So you're right, like, I would never go contribute to an

00:12:28.100 --> 00:12:33.240
IDL program. No, no way. Yeah, it's not gonna happen. Yeah. All right. So going from the sciences

00:12:33.240 --> 00:12:39.320
and the sort of mosaic, let's kind of go back to maybe more traditional computer science,

00:12:39.320 --> 00:12:44.620
like large software development house with Dropbox, right? Yeah. This is the talk on

00:12:44.620 --> 00:12:51.020
mypy and static typing with I think Yuka and David from Dropbox, which is also where Guido works.

00:12:51.020 --> 00:12:55.940
Yeah. And this project, mypy is something that's like Guido's main focus right now. He said when I

00:12:55.940 --> 00:13:00.500
interviewed him, what is that like a couple months ago? Oh, great. Yeah. And the things I mean,

00:13:00.500 --> 00:13:03.720
there's a bunch of things I didn't know here and a couple points that I thought were really

00:13:03.720 --> 00:13:07.780
interesting. But the first one is they just, you know, oh, okay, Dropbox has 5 million lines of

00:13:07.780 --> 00:13:13.240
Python. Wow, that's a lot. That's, that's cool. They just tell you that. And then 700,000 lines of that

00:13:13.240 --> 00:13:19.700
are typed now, which is a lot of code. And so they're actually running the type checker at build

00:13:19.700 --> 00:13:24.240
time. They do it as part, almost like part of their continuous integration process where

00:13:24.240 --> 00:13:30.200
you can't commit to upstream until you've run the type checker and verified that it's clean.

00:13:30.860 --> 00:13:36.860
So it's and then they, they actually said that it's helping engineers at Dropbox move faster,

00:13:36.860 --> 00:13:43.640
get more done, do larger scale refactorings. So I think the proof that typing was a good idea,

00:13:43.640 --> 00:13:48.900
Guido is basically helping realize that and kind of test it out and make sure that that this is

00:13:48.900 --> 00:13:53.360
worthwhile. So any naysayers will be like, well, okay, this is not just an academic exercise in

00:13:53.360 --> 00:13:58.460
typing. Like we actually have practical use cases, a very large practical code base. And we've shown it's

00:13:58.460 --> 00:14:03.200
valuable. Yeah, they had a pretty interesting example of just like a three lines of code or

00:14:03.200 --> 00:14:07.640
maybe four lines of code, like really, really simple function. It's like, you have no idea what

00:14:07.640 --> 00:14:13.980
this does. It's entirely simple. And but it's it's kind of similar versions, but not identical versions

00:14:13.980 --> 00:14:18.720
exist in a lot of places in 5 million lines of code, which one is this? And how do you know you're not

00:14:18.720 --> 00:14:24.840
breaking it? Right? Yeah, definitely. I thought that was pretty interesting. And they also went through a lot

00:14:24.840 --> 00:14:32.580
of the ways in which you might approach this problem, right? You might put some sort of like, comment in your

00:14:32.580 --> 00:14:37.160
code, to say, here's what the types are. But then they talked about all the various trade offs on that, right?

00:14:37.160 --> 00:14:42.660
Yeah, definitely. And I think it's also interesting, because right now, you know, in the landscape outside of Python,

00:14:42.660 --> 00:14:47.940
you have things like TypeScript, which is the language from Microsoft, and Google's working on it, related to Angular,

00:14:48.280 --> 00:14:54.720
the the web framework. And then on the Facebook side with react, which is a great framework for for JavaScript

00:14:54.720 --> 00:15:00.600
UIs, they have something called flow, which is also a type checker. So there's a parallel here where

00:15:00.600 --> 00:15:06.400
in flow, you know, you do all the type annotation, a lot of it with comments. And then with TypeScript,

00:15:06.400 --> 00:15:11.360
you do it in line with the special kind of syntax looks a lot like Python, actually. And then Google's

00:15:11.360 --> 00:15:16.420
old closure compiler for JavaScript also had type annotations and comments. And then in Python to seven,

00:15:16.420 --> 00:15:20.700
you can get all of the functionality of mypy and typing also do by doing it through comments. So

00:15:20.700 --> 00:15:24.340
it's kind of like this thing where it's like, well, we didn't plan to have this in the language. So we

00:15:24.340 --> 00:15:30.320
had to figure out a way to shoehorn it in using comments, that it's a common theme. But now Python

00:15:30.320 --> 00:15:35.320
three, six, and even since three, three has all the different parts of support that you really need in

00:15:35.320 --> 00:15:41.640
order to add types everywhere that you'd want. Yeah, and I don't see it being used that often. But I find it,

00:15:42.080 --> 00:15:48.340
I find it really a valuable thing on the boundaries of parts of my program, like, like,

00:15:48.340 --> 00:15:51.560
here's this whole data access layer. And I'm not going to go and like fill out the whole data access

00:15:51.560 --> 00:15:57.440
layer with type hints. But maybe on the external functions that are being used by the rest of the

00:15:57.440 --> 00:16:02.500
app, like just as you cross that boundary, I find it a really helpful thing some of the time.

00:16:02.680 --> 00:16:06.260
Yeah, definitely. And I think like with the code base, I've been working in, you know, this 350,

00:16:06.260 --> 00:16:10.420
400,000 line code base, you know, we've got a bunch of spaghetti in there that we really could,

00:16:10.420 --> 00:16:15.260
it'd be better if we could refactor it out. And I think finding, kind of discovering the common

00:16:15.260 --> 00:16:19.160
components in there and putting a boundary around them with a well defined interface that has typing

00:16:19.160 --> 00:16:24.360
information would make the whole system much more stable and easier to understand, easier to test.

00:16:24.360 --> 00:16:30.340
So I'm not against types. And I think that for core libraries or core functionality that a code base

00:16:30.340 --> 00:16:35.520
relies on, it's really valuable. And I liked that they had a really gradual way of adopting it. It's

00:16:35.520 --> 00:16:41.460
not some big bang thing where you need to go in and start writing types from day one, or you have to

00:16:41.460 --> 00:16:46.740
freeze your whole code base, switch everything to types and then unfreeze it, you can actually go from

00:16:46.740 --> 00:16:51.520
a leaf node up to a root node in terms of the file interdependencies, one file at a time,

00:16:51.520 --> 00:16:55.300
and it all works as expected. It's like a depth first conversion.

00:16:55.300 --> 00:17:00.200
Yeah, yeah, exactly. So, so I think that's really cool that they they've really thought

00:17:00.200 --> 00:17:03.720
through that. And they've actually done it. And they explain the strategies for how they would do

00:17:03.720 --> 00:17:08.540
it. And you're like, okay, run the script this way. Some best practices around checking in the script

00:17:08.540 --> 00:17:12.480
you use to run my pie to make sure that you actually are running it consistently across all

00:17:12.480 --> 00:17:17.160
developers workstations. But it was really cool how much progress they've made, even since the last

00:17:17.160 --> 00:17:21.060
time I saw a talk on this. Yeah, it does really look quite nice.

00:17:21.200 --> 00:17:24.820
There's two things I'm most excited about here. I mean, I think the first one is just structural

00:17:24.820 --> 00:17:31.040
typing in Python. I think if you've used Go or TypeScript recently, the structural typing of the

00:17:31.040 --> 00:17:36.460
interfaces, it's just so nice where you can say, oh, this is looks like a duck, quacks like a duck,

00:17:36.460 --> 00:17:42.080
it's duck. And we can strictly enforce that it's a duck at compile time. It just feels so great. And

00:17:42.080 --> 00:17:46.140
it's interesting because my pie doesn't do this. Like Python, you always think of it that way. You're

00:17:46.140 --> 00:17:49.500
like, oh, if I can call dot open on it, then I can pass it to this function, right?

00:17:49.500 --> 00:17:49.760
Right.

00:17:49.760 --> 00:17:54.100
But the type system so far that they're implementing really looks like the Java type system.

00:17:54.100 --> 00:17:58.320
So it's kind of odd because it's not really Pythonic yet, you know?

00:17:58.320 --> 00:18:02.100
Yeah, that is really interesting because it's not like you're expressing like the thing that comes

00:18:02.100 --> 00:18:05.020
here has to have these two functions in this field.

00:18:05.020 --> 00:18:05.620
Right.

00:18:05.680 --> 00:18:09.140
It's just, it has to literally be in this type hierarchy.

00:18:09.140 --> 00:18:09.680
Exactly.

00:18:09.680 --> 00:18:10.760
Yeah. Interesting.

00:18:10.760 --> 00:18:16.520
Yeah. And so I think that it's not ready for prime time until that's like, I think people will have

00:18:16.520 --> 00:18:21.040
trouble adopting it because they'll feel like it's a little clunky until that's done. But they said

00:18:21.040 --> 00:18:25.680
they plan to do that, which is awesome. Yeah. So that is awesome. Yeah. And there's a pep.

00:18:25.680 --> 00:18:26.400
Oh, what's the pep?

00:18:26.400 --> 00:18:29.940
Oh, I haven't actually found it. They just mentioned there's a PEP for proto. They call it protocols.

00:18:29.940 --> 00:18:30.580
Okay.

00:18:30.580 --> 00:18:33.720
There's a PEP for my pie to support those. I couldn't, I haven't actually dug it up yet,

00:18:33.720 --> 00:18:34.980
but I need to find it.

00:18:34.980 --> 00:18:39.800
Right. Okay, cool. Yeah. If you're working in PyCharm, it will do that sometimes. Like you can

00:18:39.800 --> 00:18:45.340
hit a button when you're at the call side of a function and it'll say there's no type hence here,

00:18:45.340 --> 00:18:49.480
but you're going to need these three properties on whatever you pass. And it'll kind of like pop

00:18:49.480 --> 00:18:54.160
that up. But yeah, it would be really cool if this supported, I didn't really even think about like,

00:18:54.160 --> 00:19:00.340
okay, how, how sort of almost incongruent this way of specifying types is with the way that people

00:19:00.340 --> 00:19:02.920
think of dynamic typing in Python. That's interesting.

00:19:03.220 --> 00:19:07.060
Exactly. And there's one other repercussion of this that I think is extremely interesting,

00:19:07.060 --> 00:19:10.380
which is, you know, in Python right now, like you're writing, let's say you're accessing a

00:19:10.380 --> 00:19:15.180
dictionary and, you know, it's my dictionary, square bracket, the key, and then close square

00:19:15.180 --> 00:19:19.260
bracket. And maybe you'll do that in a try except, and you'll catch the key error because you're

00:19:19.260 --> 00:19:23.480
expecting that there might be a key error. Like the key may not be there. It's a common idiom.

00:19:23.480 --> 00:19:27.520
You see people, oh, I expected this exception to happen. So I'm going to catch it right there.

00:19:27.520 --> 00:19:29.800
Instead of checking if the key's there and then fetching it,

00:19:30.000 --> 00:19:34.040
I'm just going to go for it and then handle the exceptional case. In that way, like exceptions

00:19:34.040 --> 00:19:37.620
are part of the interface for a lot of methods and functions. And you see that all over the place

00:19:37.620 --> 00:19:41.780
in code. And it's not slower in Python. It's about the same speed as a function call. So this is like

00:19:41.780 --> 00:19:47.900
something that people do all the time. In the type system of mypy, you can't specify the types of the

00:19:47.900 --> 00:19:52.280
exceptions that come out of a function. And they have no plans to do it because typed exceptions in Java

00:19:52.280 --> 00:19:54.560
were really a big problem.

00:19:54.560 --> 00:19:56.160
Yeah. Yeah. They are challenging.

00:19:56.160 --> 00:19:59.420
Very challenging. And C# didn't make that mistake, like doesn't have checked exceptions.

00:19:59.420 --> 00:20:05.820
So I think what it means for Python programmers is that once three, six and mypy become more common,

00:20:05.820 --> 00:20:12.040
I think that that idiom of raising an exception and expecting it to be caught is going to go away.

00:20:12.040 --> 00:20:15.720
And I think people are going to do it more like go programming where you return like a tuple of

00:20:15.720 --> 00:20:19.080
it's okay and here's the result or it's not okay and here's the error.

00:20:19.080 --> 00:20:24.260
Yeah, sure, sure. Result comma error in some kind of tuple and you just look at one or the other. Yeah.

00:20:24.260 --> 00:20:29.440
Yeah. And they support optional types in mypy so they can actually enforce typing on the variations,

00:20:29.440 --> 00:20:34.600
which is really cool. Like they have kind of like what Swift can do. They can do that in mypy already.

00:20:34.600 --> 00:20:39.480
So this talk to me was like a sneak peek of what Python will be written like in three years,

00:20:39.480 --> 00:20:40.020
essentially.

00:20:40.020 --> 00:20:41.160
That's a cool analysis.

00:20:41.160 --> 00:20:41.540
Yeah.

00:20:41.680 --> 00:20:47.420
What I was sort of seeing when I was looking at this was part of the overall trend towards Python 3.

00:20:47.420 --> 00:20:48.420
Oh, yeah, definitely.

00:20:48.420 --> 00:20:52.460
Yeah. And, you know, when Guido was on the show, I think he mentioned even that

00:20:52.460 --> 00:20:59.280
this will provide some foundation for helping them move to Python 3 at Dropbox.

00:20:59.280 --> 00:20:59.940
Oh, yeah.

00:20:59.940 --> 00:21:03.620
They can reason more carefully about the code and decide if it's going to be a problem

00:21:03.620 --> 00:21:05.100
at some sort of conversion.

00:21:05.100 --> 00:21:09.060
Yeah, exactly. Yeah, I think that's definitely the case. And there are already 700,000 lines in.

00:21:09.140 --> 00:21:14.780
So I think it was probably the first 100,000 that was the hard part. I'm looking forward to an update

00:21:14.780 --> 00:21:17.520
once they, you know, say that they're totally done or whatever.

00:21:17.520 --> 00:21:18.720
Yeah, it'll be pretty awesome.

00:21:18.720 --> 00:21:19.100
Yeah.

00:21:19.100 --> 00:21:23.880
Hey, everyone. Michael here. Let me take just a moment and thank one of our sponsors who makes

00:21:23.880 --> 00:21:27.840
this show possible. This portion of Talk Python to Me has been brought to you by Rollbar.

00:21:27.840 --> 00:21:31.320
One of the frustrating things about being a developer is dealing with errors.

00:21:31.320 --> 00:21:35.660
Relying on users to report errors, digging through log files, trying to debug them,

00:21:36.020 --> 00:21:38.940
or a million alerts just flooding your inbox and ruining your day.

00:21:38.940 --> 00:21:44.200
With Rollbar's full stack error monitoring, you get the context, insight and control you need to

00:21:44.200 --> 00:21:50.780
find and fix bugs faster. Adding the Rollbar Python SDK is just as easy as pip install Rollbar.

00:21:50.780 --> 00:21:54.500
You can start tracking production errors and deployments in eight minutes or less.

00:21:54.500 --> 00:21:59.600
Rollbar works with all the major languages and frameworks, including the Python ones like Django,

00:21:59.780 --> 00:22:05.780
Flask, Pyramid, as well as Ruby, .NET, Node, iOS, and Android. You can integrate Rollbar into your

00:22:05.780 --> 00:22:10.900
existing workflow. Send error alerts to Slack or HipChat or automatically create new JIRA issues,

00:22:10.900 --> 00:22:15.100
pivotal tracker issues, and a lot more. They have a special offer for Talk Python To Me listeners.

00:22:15.100 --> 00:22:20.660
Visit talkpython.fm/Rollbar, sign up and get the bootstrap plan free for 90 days.

00:22:20.660 --> 00:22:24.880
That's 100,000 errors tracked for free. But you know, just between you and me,

00:22:24.960 --> 00:22:30.660
I hope you don't encounter that many errors. Give Rollbar a try today. Just go to talkpython.fm

00:22:30.660 --> 00:22:37.560
slash Rollbar. So let's talk about the gillectomy. Yeah. So this is Larry Hastings talk,

00:22:37.560 --> 00:22:43.500
and he's been at it for a couple of years. And first of all, let me just like take a step back

00:22:43.500 --> 00:22:47.440
and maybe tell us what the GIL is. And do you think the GIL is actually a problem for Python?

00:22:47.440 --> 00:22:51.880
Wow. Okay. Okay. So the gill, yeah, the global interpreter lock, which is the part of the

00:22:51.880 --> 00:22:57.780
CPython interpreter that locks the state machine state while your program is running so that

00:22:57.780 --> 00:23:03.920
different threads don't trash each other. It's a key part of how CPython works, how CPython's virtual

00:23:03.920 --> 00:23:10.560
machine works. And it has unintended consequences, which are that it prevents your Python program from

00:23:10.560 --> 00:23:16.100
using multiple cores at the same time. So it limits the actual execution speed of Python,

00:23:16.100 --> 00:23:17.160
vanilla Python.

00:23:17.160 --> 00:23:19.680
Right. Basically only for computational stuff.

00:23:19.680 --> 00:23:21.720
Only for computational stuff. Yeah.

00:23:21.720 --> 00:23:26.920
When you are waiting on the OS, like for network or file, it releases the gill, right?

00:23:26.920 --> 00:23:33.040
Yeah, it does. And so for IO bound applications, or memory bound applications, it's not a big deal. But for

00:23:33.040 --> 00:23:38.020
CP bound stuff, especially servers where they're trying to be really high, like highly responsive,

00:23:38.020 --> 00:23:42.020
that can be a problem. So yeah, to answer your question, is it a problem? Well, depends on who you ask.

00:23:42.020 --> 00:23:50.060
Like, in the JavaScript community, v8 is not multi threaded in the same way. It's completely single core for similar reasons.

00:23:50.060 --> 00:23:53.180
Which means node is in a similar situation, right?

00:23:53.180 --> 00:23:53.780
Yeah.

00:23:53.780 --> 00:23:57.920
But you don't really hear people complaining about that with node, because it's really all they can use.

00:23:58.800 --> 00:24:15.420
And then things like Go are, you know, are highly concurrent, super fast. And so I think Python's limiting itself by not being able to use all CPUs out of the box. There are tools like multiprocessing, the multiprocessing module for Python that do let you take advantage of all CPUs. It's just, it's just hard to use if you don't know what you're doing.

00:24:15.620 --> 00:24:28.840
I don't think it's that huge a problem. I think the thing that's sort of relieved the pressure is there, when you really are doing a lot of computation, often there's some library and some bit of it is in C, and it really does take advantage of it, like NumPy or something, right?

00:24:28.840 --> 00:24:35.260
So yeah, the really intense cases seem to have already worked around it, and you just pip install a thing and you're okay.

00:24:35.260 --> 00:25:01.160
Yeah, but even in those cases, like NumPy and other packages like this, it's like, you need to restructure your program to take advantage of it. And I think that's the burden. It's, this was working, why can't I just turn up the speed dial and have it go faster, or increase the concurrency, you know, where you can do that with some other languages or other constructs. So yeah, I think most people, it doesn't matter. But I think certain areas, it does. And so I'm happy that they're spending time on it. And Larry's been diving into it.

00:25:01.160 --> 00:25:03.560
Yeah. Okay, so that brings us to the Gilectomy.

00:25:03.880 --> 00:25:33.060
Yeah. So yeah, he's been talking about it for a couple years now. And he's, he's trying to remove the GIL or at least remove the, the overhead of the GIL. And it's been tried a few times. If you look back at his older talks, I think there's an attempt at it. The original attempt at it was by Greg Stein, who I actually used to work with at Google. And he had added multi course, multi threaded support to Python, I think version, maybe it's version one five or version two, way back when. And it was insanely slow. It was like, awful.

00:25:33.500 --> 00:25:51.020
And so yeah, anyway, so Larry's got a very particular style of presenting, which is, which is funny and very intense. But yeah, he just right off the bat, he's like, yeah, you know, Python without the gill, you can take the GIL out very quickly. It's actually not too hard. The problem is that it's really slow. It's 19 times, the one with the gills 19 times faster than the one without it, right?

00:25:51.260 --> 00:25:58.360
Exactly. So yeah, you can do this. But before you see any advantage, you're going to need like 32 cores and really highly concurrent algorithms.

00:25:58.560 --> 00:26:11.460
Yeah, exactly. You know, Larry is the guy who knows this stuff. So it's been interesting, because he is taking, you know, everything he knows, every trick in the book, essentially, and applying them to this GIL problem.

00:26:12.000 --> 00:26:28.480
Yeah, so he, you know, in this talk, he walked through a lot of those. And, you know, we can talk about a couple of those examples. It started off just seeming hopeless, like he has no chance. And the graphs he was showing was the amount of CPU time that it takes to run a bunch of benchmarks, or maybe the Fibonacci benchmark. And it just looked hopeless. And all of his work was hopeless.

00:26:28.480 --> 00:26:42.740
And so about halfway through the talk, I'm like, Oh, man, this is like, he's like, totally failed on this attempt, you know, but well, I won't give away the end. Okay, because we can talk about the end in just a second. But there's a bunch of techniques, though, that he used. I don't know if you remember any.

00:26:42.740 --> 00:26:58.460
Yeah, well, I think what was interesting about this was he did lay out a lot of the different techniques and things that he had tried over over time, and really pulled out a lot of the challenges and trade offs that you have to make. And so it's like, I want the Gilgon, I want to just like, take advantage of all the CPUs.

00:26:58.460 --> 00:27:14.700
Well, here are the trade offs. And here's where things actually get slower. And so there was stuff around garbage collection and managing reference counting and consistency there, the different types of locking that he had used, and just some of the allocation stuff. And yeah, it was, it was interesting.

00:27:14.700 --> 00:27:36.960
Yeah, and there's a lot of reference. That's exactly right. And there's a lot of references of things that I like need to look up after that, like, some two stage locking stuff, getting rid of like accelerating thread local variables. There's something about, there's a book called the garbage collection handbook that I like, I was like, Oh, wow, I've heard of that has an algorithm called buffered reference counting, which I guess was the was the way that they he was able to make it fast.

00:27:36.960 --> 00:28:02.960
So it's just really interesting to see how much it takes to do it correctly. But how it's actually all very well known algorithms in computer science research, and there's papers on basically everything that he's trying to do. So he's not actually treading new ground, which is really encouraging, because it's just about applying it to the Python space. He's not inventing some new technology that needs to be proven, and might be full of bugs. He's like, Oh, no, this is in the handbook.

00:28:02.960 --> 00:28:12.340
He also invented it independently. But he's like, Oh, no, this is this is actually a known technique that I'm using. So even when he did invent something, it just was like a reinvention of the thing that existed, right?

00:28:12.340 --> 00:28:16.400
Yeah, like from the 1977 or whatever it was. Yeah, that's always how it is.

00:28:16.400 --> 00:28:17.920
It's definitely how it is.

00:28:17.920 --> 00:28:30.140
Yeah. But ultimately, the last graph he showed was that it's really close now. I'm shocked because I did not think it was going to be possible. And you know, he's within, I think, maybe two x or less of slowness.

00:28:30.140 --> 00:29:00.120
Wow.

00:29:00.120 --> 00:29:12.420
You know, you can imagine that Python two seven goes away, because Python three, three has no gill, and it's super fast, or Python three has no GIL and super fast. And people like, wow, why would I use Python two, and I could use Python three, and run a lot faster.

00:29:12.420 --> 00:29:30.100
Yeah, so this is actually an interesting point. I don't believe the galectomy came from these origins. But, you know, the next thing that we're going to talk about, I think, more or less did. And Brett Cannon, and Dino Veland are working on you started working on this thing called pigeon pigeon pigeon pigeon pigeon pigeon pigeon pigeon pigeon.

00:29:30.100 --> 00:29:36.820
Basically, there's a couple of folks in the core developer saying, what can we do to improve adoption of Python three?

00:29:36.820 --> 00:29:37.440
Right.

00:29:37.440 --> 00:29:44.040
What if we made it 50% faster, right? That alone, if nothing else happened, that alone would make a huge difference.

00:29:44.440 --> 00:29:52.460
And I think actually, regardless of whether it's been faster or not, the last two years have made like a huge shift towards Python three.

00:29:52.460 --> 00:29:52.920
Yeah.

00:29:53.100 --> 00:30:03.300
But the next talk that we're going to talk about by Victor Stinner was really highlighting some of the performance improvements that he and some other folks have done on Python three.

00:30:03.300 --> 00:30:03.940
Yeah, definitely.

00:30:03.940 --> 00:30:05.200
I really like this talk.

00:30:05.200 --> 00:30:10.400
And I thought, you know, Victor's a really solid member of the Python core developer community.

00:30:10.400 --> 00:30:14.740
And I really like this talk because it was very scientific in its presentation.

00:30:14.740 --> 00:30:17.580
It was like, okay, here's, here's how we did the measurements.

00:30:17.580 --> 00:30:18.740
It started off just with that.

00:30:18.740 --> 00:30:20.500
You know, this is like, right.

00:30:20.500 --> 00:30:26.080
As you say, it like actually started out with the measurements we've been using are unreliable.

00:30:26.080 --> 00:30:29.800
First thing before we even start this process is we have to fix the measurements, right?

00:30:29.800 --> 00:30:30.380
Yeah.

00:30:30.380 --> 00:30:30.700
Yeah.

00:30:30.700 --> 00:30:33.160
You can't even trust the numbers we used in the past.

00:30:33.160 --> 00:30:40.100
So speed.python.com, which has all the benchmarks on it is like not something we should have been judging ourselves by in the past.

00:30:40.100 --> 00:30:40.720
Yeah.

00:30:40.720 --> 00:30:41.900
So that was, that was great.

00:30:41.900 --> 00:30:42.240
Right.

00:30:42.240 --> 00:30:58.280
And part of that isn't even just like, hey, we were bad at like running this code, but modern CPU architectures have things like turbo boosting and the speed at which your processor might run at could vary by like two or three X depending on how it's trying to save energy at the time and all sorts of stuff.

00:30:58.280 --> 00:30:58.520
Right.

00:30:58.520 --> 00:30:58.880
Yeah.

00:30:58.880 --> 00:31:13.480
And that came up, that actually came up in a few different talks, including the Gilectomy one, another one I went to where people are trying to benchmark things and there's no good way to like disable all of the magic features that are in modern Intel CPUs or even ARM CPUs.

00:31:13.480 --> 00:31:17.040
And so I think that there's actually a module that they're putting together.

00:31:17.040 --> 00:31:22.040
That's like the standard benchmarking module that turns off all of this stuff automatically.

00:31:22.040 --> 00:31:23.700
I actually don't remember what the, what it was called.

00:31:23.700 --> 00:31:25.780
It was like perf or performance or something.

00:31:25.780 --> 00:31:27.460
I think Victor Stenner had worked on it.

00:31:27.460 --> 00:31:27.740
Yeah.

00:31:27.740 --> 00:31:27.840
Yeah.

00:31:28.080 --> 00:31:28.860
So that's great.

00:31:28.860 --> 00:31:34.280
So I think if you're doing any benchmarking of any kind, you know, it's worth picking that module up and using it for your purposes.

00:31:34.280 --> 00:31:37.600
So you can make sure that you're actually comparing stable numbers over time.

00:31:37.600 --> 00:31:37.840
Yeah.

00:31:37.840 --> 00:31:47.660
So then he talked about, I didn't count him exactly, but just something like 10 major, major improvements on Python 3.5 and 3.6 where he focused.

00:31:47.660 --> 00:31:47.960
Yeah.

00:31:47.960 --> 00:31:49.460
And there's, I mean, there's so many of them.

00:31:49.460 --> 00:31:56.500
It's getting into the weeds with some of the stuff, but one of the ones was, one thing is like, it's no longer actually called Python bytecode.

00:31:56.500 --> 00:31:57.740
That was one I liked.

00:31:57.740 --> 00:31:59.380
So Python doesn't have bytecode anymore.

00:31:59.380 --> 00:32:05.780
It has something called word code because bytes only one byte where a word is like 16 bits or, you know, it's multiple bytes.

00:32:05.780 --> 00:32:06.120
Yeah.

00:32:06.280 --> 00:32:13.520
And so there's some inner loop in the CPython runtime that had an if statement, which is like, okay, is this bytecode, does it have any arguments?

00:32:13.520 --> 00:32:15.600
Because if it does, then it's more than one byte.

00:32:16.060 --> 00:32:25.100
And they just said, you know what, let's just get rid of that and just have it be two bytes always because memory performance on, you know, modern machines is good enough that we don't need to actually save space.

00:32:25.100 --> 00:32:25.400
Yeah.

00:32:25.400 --> 00:32:33.380
And they basically removed a conditional check in C eval.c, which is like the switch statement.

00:32:33.520 --> 00:32:33.660
Yeah.

00:32:33.660 --> 00:32:33.740
Yeah.

00:32:33.740 --> 00:32:34.360
The hot loop.

00:32:34.360 --> 00:32:34.840
Yeah.

00:32:34.840 --> 00:32:35.940
That's the super hot loop.

00:32:35.940 --> 00:32:47.040
And so simple things like that, like maybe we'll just throw in like a wasted byte when there's no arguments and that will actually make it a little bit less memory efficient, like tiny, but much faster.

00:32:47.040 --> 00:32:48.040
Yeah.

00:32:48.040 --> 00:32:48.680
Yeah.

00:32:48.680 --> 00:32:48.960
Yeah.

00:32:48.960 --> 00:32:49.320
Exactly.

00:32:49.320 --> 00:32:57.360
And so it ends up like netting, I don't remember what the performance boost, but there's a bunch of these that improve benchmarks by, you know, 5%, 10%, 20%.

00:32:57.360 --> 00:32:58.900
And that stuff really adds up.

00:32:58.900 --> 00:33:01.380
So it's really, they've done a lot.

00:33:01.380 --> 00:33:04.120
And so Python 3.6 is extremely fast compared to others.

00:33:04.120 --> 00:33:06.640
It's amazing to see that that progress.

00:33:06.640 --> 00:33:06.980
Yeah.

00:33:06.980 --> 00:33:11.860
So I would definitely say, especially if you're on Python 2 still and you're like, is it really worth switching?

00:33:11.860 --> 00:33:13.600
You know, I get this language feature.

00:33:13.600 --> 00:33:13.920
Sure.

00:33:13.920 --> 00:33:18.980
I can do double star to create dictionaries out of other dictionaries and whatever, but is that really worth it?

00:33:18.980 --> 00:33:26.940
Like check out this optimization talk because there's a lot of stuff where it's like, and this is 40% faster and this is two times faster and this is 12% faster.

00:33:26.940 --> 00:33:27.800
And it's just like, whoa.

00:33:27.800 --> 00:33:28.420
Yeah, definitely.

00:33:28.420 --> 00:33:33.020
And like the decimal module, for example, that one is actually just rewritten in C, but I think it was 40, 40 times faster.

00:33:33.020 --> 00:33:33.280
Yeah.

00:33:33.280 --> 00:33:34.200
40 times faster.

00:33:34.200 --> 00:33:36.320
Which is like, I've used decimal all the time.

00:33:36.320 --> 00:33:38.380
So that would be helpful for, you know, what I've done.

00:33:38.380 --> 00:33:40.980
He also alluded to something that will be in Python 3.7.

00:33:40.980 --> 00:33:45.740
He didn't really want to go into it yet because he says the results aren't perfect or fully proven.

00:33:45.740 --> 00:33:51.020
But he did say that in Python 3.7 that method calls are going to be faster across the board.

00:33:51.020 --> 00:33:56.820
And, you know, that's my biggest problem I would say with Python is that calling a function is really slow.

00:33:56.820 --> 00:33:57.160
Yeah.

00:33:57.160 --> 00:33:58.120
That's a really good point.

00:33:58.120 --> 00:34:03.500
Like you are at odds with performance with structuring your code well.

00:34:03.720 --> 00:34:03.960
Exactly.

00:34:03.960 --> 00:34:08.140
And so especially with the optimizing code, you're like, well, this is really hard to understand.

00:34:08.140 --> 00:34:10.500
So I'm going to split this into functions so I can like follow it.

00:34:10.500 --> 00:34:15.520
And as soon as you start doing that in Python, like you're slowing your program down every single time.

00:34:15.520 --> 00:34:17.220
And that's not a tradeoff you want to make.

00:34:17.220 --> 00:34:18.200
You know, that's terrible.

00:34:18.200 --> 00:34:23.280
And so anything you can do to make function calls faster, they already, he already talked about a few of those.

00:34:23.280 --> 00:34:24.700
And he said there's more coming in 3.7.

00:34:24.700 --> 00:34:28.740
So I just, I think it's maybe a, the beginning of this performance renaissance in Python.

00:34:28.740 --> 00:34:29.240
Yeah.

00:34:29.240 --> 00:34:32.140
That I'm really looking forward to the Gilectomy being part of that as well.

00:34:32.140 --> 00:34:36.000
But just, you know, meat and potatoes optimization, which is what Victor's doing.

00:34:36.000 --> 00:34:37.720
It's just really great to see.

00:34:37.720 --> 00:34:37.920
Yeah.

00:34:37.920 --> 00:34:39.180
Really, really amazing stuff.

00:34:39.180 --> 00:34:47.980
And some of the stuff that struck me was like how simple the changes were, but how careful you have to be in making them because of the edge cases.

00:34:47.980 --> 00:34:53.080
It's like, here's a simple optimization, but it took us two and a half years because it was incredibly difficult.

00:34:53.080 --> 00:34:54.880
To get every edge case just right.

00:34:54.880 --> 00:34:55.240
Yeah.

00:34:55.240 --> 00:34:55.520
Yeah.

00:34:55.520 --> 00:34:55.880
Totally.

00:34:55.880 --> 00:34:56.280
Yeah.

00:34:56.280 --> 00:35:01.040
And that's, that's why it's like a darker, you know, you really need to know what you're doing to optimize and you need really good tests.

00:35:01.040 --> 00:35:04.800
I think the case you're talking about is they rewrote LRU cache algorithm.

00:35:04.800 --> 00:35:05.620
And yeah, it took them like two.

00:35:05.620 --> 00:35:05.800
Yes.

00:35:05.800 --> 00:35:06.640
That was the one I think.

00:35:06.640 --> 00:35:06.860
Yeah.

00:35:06.860 --> 00:35:07.980
Two and a half years.

00:35:07.980 --> 00:35:08.240
Yeah.

00:35:08.240 --> 00:35:09.460
It's pretty, pretty crazy.

00:35:09.460 --> 00:35:11.420
Yeah.

00:35:11.420 --> 00:35:12.280
That's pretty amazing.

00:35:12.280 --> 00:35:12.600
All right.

00:35:12.600 --> 00:35:16.460
So one that I did not see, but you went to, maybe you can tell us about is the debugger one.

00:35:16.460 --> 00:35:17.060
Yeah.

00:35:17.060 --> 00:35:23.000
So this is by Elizaveta Shashkova from JetBrains, I think in St. Petersburg.

00:35:24.000 --> 00:35:25.620
And this one was really cool.

00:35:25.620 --> 00:35:32.860
So it's cool because there's this PEP called PEP 523 and it's a Python enhancement proposal.

00:35:32.860 --> 00:35:38.680
And it's a, the purpose of the PEP is to give a pigeon, which you were just talking about,

00:35:38.680 --> 00:35:42.980
which is a JIT compiler, a just in time compiler for Python to make Python faster.

00:35:43.560 --> 00:35:44.720
That's what the PEP was for.

00:35:44.720 --> 00:35:51.420
It added a bunch of hooks into the C, CPython runtime that lets you change the way that functions

00:35:51.420 --> 00:35:52.820
and code are evaled.

00:35:52.820 --> 00:35:53.260
Okay.

00:35:53.260 --> 00:35:54.620
So you can plug in new stuff.

00:35:54.620 --> 00:35:54.920
Yeah.

00:35:54.920 --> 00:35:57.860
The big idea is like, let's not keep rewriting new runtimes.

00:35:58.220 --> 00:36:03.180
Let's try to find a way that you can plug into the one that we all have without forcing everyone

00:36:03.180 --> 00:36:04.240
to go, should I do PyPy?

00:36:04.240 --> 00:36:05.080
Should I do JIT?

00:36:05.080 --> 00:36:06.000
Should I do IronPython?

00:36:06.000 --> 00:36:07.700
Like, forget this, right?

00:36:07.700 --> 00:36:08.440
Yeah, exactly.

00:36:08.440 --> 00:36:10.260
And so make it more extensible.

00:36:10.520 --> 00:36:15.440
So that's really cool that that PEP was created and has been plugged into Python.

00:36:15.440 --> 00:36:17.380
I think it might be 3.5 that it landed.

00:36:17.380 --> 00:36:22.480
But what they didn't realize when they developed this PEP is it would enable new use cases.

00:36:22.480 --> 00:36:29.700
And so Eliza, what she went through is how they actually leverage that same interface to

00:36:29.700 --> 00:36:36.100
enable a debugger for Python that is as fast or almost as fast as just vanilla Python.

00:36:36.920 --> 00:36:41.360
And so if you've ever run your Python code under a debugger, it's something like 30 times slower.

00:36:41.360 --> 00:36:42.460
Oh, interesting.

00:36:42.460 --> 00:36:45.820
And so it's really hard to actually simulate a lot of the problems you have.

00:36:45.820 --> 00:36:49.420
Or if you have timing issues, especially where there's races, you just can't even reproduce

00:36:49.420 --> 00:36:50.700
them because it's so slow.

00:36:50.700 --> 00:36:53.980
Everything runs in the right order under the debugger.

00:36:53.980 --> 00:36:57.400
And then once you run it normally, then it goes fast enough.

00:36:57.400 --> 00:36:58.640
And then you get these data races again.

00:36:58.640 --> 00:36:59.700
And then you can't.

00:36:59.700 --> 00:37:00.380
Then you get the bugs.

00:37:00.380 --> 00:37:00.880
Yeah.

00:37:00.880 --> 00:37:01.280
Yeah.

00:37:01.280 --> 00:37:01.840
Heisenbugs.

00:37:01.840 --> 00:37:02.500
Heisenbugs.

00:37:02.500 --> 00:37:02.860
Right.

00:37:02.860 --> 00:37:05.820
And so they created this thing into JetBrains.

00:37:05.820 --> 00:37:12.160
And I think it's I think the core of its open source, where it basically uses the PEP523

00:37:12.160 --> 00:37:14.800
hooks that are meant to be for speedy eval.

00:37:14.800 --> 00:37:20.860
And it'll actually rewrite the Python bytecode or wordcode in as it's coming through and insert

00:37:20.860 --> 00:37:25.480
breakpoints into the bytecode, which makes it, you know, orders of magnitude faster because

00:37:25.480 --> 00:37:31.220
the old Python debugger uses it's a set trace where you get a function call for every single

00:37:31.220 --> 00:37:32.000
line of Python.

00:37:32.000 --> 00:37:33.260
It's almost like a profiler.

00:37:33.260 --> 00:37:34.420
Yeah, exactly.

00:37:34.420 --> 00:37:36.520
And it's the slowest thing imaginable.

00:37:36.520 --> 00:37:39.620
You know, it's first of all, you're calling a function, which is slow.

00:37:39.620 --> 00:37:40.120
Right.

00:37:40.120 --> 00:37:44.180
And then you do it for every single line, whether or not you want you care about that line.

00:37:44.180 --> 00:37:48.700
So I love this talk because she walked through all the how the debuggers work, all the details

00:37:48.700 --> 00:37:51.220
about why they're slow benchmarks are on that.

00:37:51.220 --> 00:37:55.380
Then she explained her approach, how they do it, what it's good at, how it works.

00:37:55.380 --> 00:37:59.700
She even showed the disassembly of the Python bytecode and how they plug into it.

00:37:59.700 --> 00:38:01.000
So it was really awesome.

00:38:01.200 --> 00:38:01.600
Yeah, that's cool.

00:38:01.600 --> 00:38:02.760
I'm definitely going to have to check this one out.

00:38:02.760 --> 00:38:03.540
Yeah, I would.

00:38:03.540 --> 00:38:09.640
And my favorite part about it is just like that PEP defined an interface that is generally

00:38:09.640 --> 00:38:11.000
useful to people.

00:38:11.000 --> 00:38:17.660
So it wasn't intended to be used for this purpose, but it was general enough that it could be.

00:38:17.660 --> 00:38:20.360
And that's good design from my perspective.

00:38:20.820 --> 00:38:25.320
Yeah, it's really nice that, you know, that wasn't even part of the plan, right?

00:38:25.320 --> 00:38:31.480
But just this flexing and growing CPython actually made this other use case really good.

00:38:31.480 --> 00:38:32.060
Yeah, definitely.

00:38:32.060 --> 00:38:33.680
So I'm looking forward to using that debugger.

00:38:33.680 --> 00:38:35.740
And I keep hearing great things about PyCharm.

00:38:35.740 --> 00:38:38.880
And I've never actually used it for anything like day to day.

00:38:38.880 --> 00:38:42.180
I poked around with it, but never built a whole program with it.

00:38:42.180 --> 00:38:43.540
Yeah, I don't know if this is the same thing.

00:38:43.540 --> 00:38:49.000
But when you debug something in PyCharm, if you just do that on like a brand new machine,

00:38:49.000 --> 00:38:52.780
it'll say warning the debugger speedups are not built.

00:38:52.780 --> 00:38:58.660
You basically have to run this compiler statement to like build something into your system.

00:38:58.660 --> 00:38:59.320
Oh, yeah.

00:38:59.320 --> 00:39:00.300
That might be the same thing.

00:39:00.300 --> 00:39:00.560
Yeah.

00:39:00.560 --> 00:39:01.700
I think that might be it actually.

00:39:01.700 --> 00:39:02.020
Yeah.

00:39:02.100 --> 00:39:06.480
So there's like a little output that it says, hey, you can make this much faster if you run this line once.

00:39:06.480 --> 00:39:06.800
Gotcha.

00:39:06.800 --> 00:39:08.040
Yeah, no, I didn't know about that.

00:39:08.040 --> 00:39:12.420
This portion of Talk Python to Me is brought to you by CodeChip.

00:39:12.420 --> 00:39:18.640
Try CodeChip Basic, a free, simple, out-of-the-box, continuous integration service in the cloud.

00:39:18.640 --> 00:39:21.900
Thousands of customers use CodeChip Basic every day.

00:39:21.900 --> 00:39:26.960
Its pre-installed CI dependencies make testing your software and deploying it work out-of-the-box.

00:39:26.960 --> 00:39:31.200
The average setup time for CodeChip Basic is less than three minutes.

00:39:31.740 --> 00:39:38.260
CodeChip Basic comes with a free plan that grants 100 builds per month, unlimited projects, and unlimited users.

00:39:38.260 --> 00:39:40.060
Do you run an open source project?

00:39:40.060 --> 00:39:42.040
Those are always free on CodeChip.

00:39:42.040 --> 00:39:44.880
And they just improved their Python support.

00:39:44.880 --> 00:39:51.540
So give CodeChip a try and visit talkpython.fm/CodeChip to learn more and sign up for free.

00:39:51.540 --> 00:39:54.660
That's talkpython.fm/CodeChip.

00:39:54.660 --> 00:40:00.660
So one of the things that I thought was really neat, you know, I think there's a lot of things touching on this.

00:40:00.740 --> 00:40:03.380
It's like, hey, this Python 3 stuff is becoming really amazing.

00:40:03.380 --> 00:40:08.800
And maybe the pinnacle of that was the Instagram keynote.

00:40:08.800 --> 00:40:09.400
Yeah.

00:40:09.400 --> 00:40:10.720
And this is a great talk.

00:40:10.720 --> 00:40:11.820
It was kind of two parts.

00:40:11.820 --> 00:40:17.000
I think Lisa Guo was the one who talked mostly about the actual transition.

00:40:17.260 --> 00:40:24.400
But it was, yeah, how they moved from Python, you know, Python 2 to Python 3 while not having any downtime.

00:40:24.400 --> 00:40:25.000
Oh, yeah.

00:40:25.000 --> 00:40:29.560
I watched this talk and I thought, okay, there's almost no other company out there.

00:40:29.560 --> 00:40:36.660
I mean, maybe a handful, but almost anyone else that says, well, we can't switch to Python 3 because we have a large code base.

00:40:36.660 --> 00:40:37.700
We have a lot of users.

00:40:37.700 --> 00:40:38.740
We've got to keep shipping.

00:40:38.740 --> 00:40:43.640
Like what Instagram did was really quite incredible.

00:40:44.380 --> 00:40:52.260
The first thing that I sort of thought, okay, this is going to get really interesting is they just have one branch that they develop from, right?

00:40:52.260 --> 00:40:58.180
They don't just like, it's not like they said, well, let's just fork everything and go over there for six months and work on that.

00:40:58.300 --> 00:41:00.960
Yeah, and that's a recipe for disaster, I think.

00:41:00.960 --> 00:41:04.080
And I actually work in a monorepo with a single trunk as well.

00:41:04.080 --> 00:41:08.040
I've been doing that for years, which is kind of odd for many people.

00:41:08.040 --> 00:41:16.720
And it's a great way to develop, but it does make it challenging to do large refactorings like this where you're changing style all over the place.

00:41:16.720 --> 00:41:21.560
I want to do it all at the same time without breaking people or making sure that commits keep flowing through.

00:41:21.940 --> 00:41:29.080
So just in terms of process and collaboration with a large team of people, I don't remember how many engineers they have working there, but it's hard.

00:41:29.080 --> 00:41:30.920
Yeah, but there are many, yeah, quite a few.

00:41:30.920 --> 00:41:33.880
So their goals were, we're not going to branch.

00:41:33.880 --> 00:41:39.900
We're going to take our existing code, which is Python 2.7 running Django 1.3, which is five versions out of date.

00:41:39.900 --> 00:41:40.220
Yeah.

00:41:40.220 --> 00:41:44.180
And we're going to move that to Python 3 and the latest version of Django.

00:41:44.180 --> 00:41:51.060
I suspect that Django switching and Django 2 saying like, we're not going to support Python 2 anymore.

00:41:51.240 --> 00:41:52.300
So we're just done.

00:41:52.300 --> 00:41:56.340
They're like, we're kind of painting ourselves into permanently into a somewhat of an old version.

00:41:56.340 --> 00:41:59.220
Let's see if we can like, you know, get back on track.

00:41:59.220 --> 00:41:59.680
Yeah.

00:41:59.680 --> 00:42:01.080
And that was the incentive there.

00:42:01.080 --> 00:42:01.540
Yeah.

00:42:01.540 --> 00:42:07.960
I thought that was, you know, there's been this push to get all the libraries into Python 3, which has really made a lot of progress over the last, let's say, five years.

00:42:07.960 --> 00:42:10.100
And now it's, you know, it's almost there for all the major ones.

00:42:10.540 --> 00:42:18.240
And this is example, this is an example of the dividends that that's paid off because now Python Django 2 is like, yeah, we're not going to support these older versions.

00:42:18.720 --> 00:42:23.240
And then Instagram's like, well, we really like that open source project and we collaborate, you know, we work on that.

00:42:23.240 --> 00:42:25.720
And so they're incentivized to move.

00:42:25.720 --> 00:42:37.960
And she also mentioned that Python 3.6 is just faster, which is, so those are two proof points that this strategy that Python's had more recently, maybe they should have had earlier, that would have helped the transition to happen faster.

00:42:37.960 --> 00:42:47.140
But this more recent strategy of performance in libraries is starting to actually be enough of a carrot and a stick to get people to start converting at a large scale.

00:42:47.140 --> 00:42:48.240
Yeah, it's really, really interesting.

00:42:48.240 --> 00:42:49.340
I totally agree with you.

00:42:49.340 --> 00:42:53.720
So they said, we're going to try to continue to ship new features.

00:42:53.720 --> 00:42:55.800
We're going to check into this one branch.

00:42:55.800 --> 00:42:56.680
We're not going to branch it.

00:42:56.680 --> 00:43:02.720
We're going to have a very careful rollout of Python 3.

00:43:02.720 --> 00:43:04.840
I thought that was actually really interesting as well.

00:43:05.240 --> 00:43:16.620
Both the test, how they did the testing by saying, we're going to slowly say, these are the tests that pass and we'll like eat our way back into all the tests until they basically all pass again.

00:43:16.620 --> 00:43:20.040
And the way of staging the rollout as well was interesting.

00:43:20.040 --> 00:43:26.480
And they were basically maintaining a Python 2 and 3 code base, like one that could run under either runtime at the same time.

00:43:26.480 --> 00:43:33.620
So that's kind of how they started this and what gave them the ability to make those more tactical moves in production.

00:43:33.940 --> 00:43:41.540
They ran the tests, all the tests under 3 and 2 using a whitelist or an exclusion list, inclusion and exclusion lists.

00:43:41.540 --> 00:43:48.180
And then they basically just started moving test after test across and setting up some best practices and all that kind of stuff.

00:43:48.180 --> 00:43:49.220
And yeah.

00:43:49.220 --> 00:43:51.840
Yeah, I really like this, that it was very prescriptive.

00:43:51.840 --> 00:43:53.480
These are the steps you need to take.

00:43:53.480 --> 00:43:54.460
Do it this way, this way.

00:43:54.460 --> 00:43:58.400
And then like it was really a roadmap, not just a, hey, look, we did it.

00:43:58.960 --> 00:43:59.660
Yeah, definitely.

00:43:59.660 --> 00:44:05.600
Like if you work somewhere and you want to be able to explain to your boss, like, oh, this is, this is what we need to do and how we need to do it.

00:44:05.600 --> 00:44:09.200
Like this is just have them watch this video because it's really, definitely.

00:44:09.200 --> 00:44:10.120
It's really convincing.

00:44:10.780 --> 00:44:13.380
And it has a bunch of best practices for teams.

00:44:13.380 --> 00:44:16.940
And it even has some like nuggets that are really valuable.

00:44:16.940 --> 00:44:21.420
Like one I thought was really cool was they talked about they rely on memcache so heavily.

00:44:22.200 --> 00:44:33.340
And there's this issue between version two and version three of memcache where, oh, sorry, version two and version three of Python where the pickle module becomes, it can poison the other version.

00:44:33.340 --> 00:44:34.440
I don't know if you remember seeing this.

00:44:34.440 --> 00:44:34.620
Right.

00:44:34.620 --> 00:44:39.340
They're basically, yeah, they're basically incompatible with like their serialization format and various things.

00:44:39.340 --> 00:44:39.520
Yeah.

00:44:39.520 --> 00:44:39.860
Yeah.

00:44:39.860 --> 00:44:44.060
So it was really interesting because I've actually had this problem in production many times.

00:44:44.280 --> 00:44:52.940
Even if you don't change the version of Python, you can cause memcache poisoning where you have a pickle version of the object and you've somehow slightly changed the structure of the object.

00:44:52.940 --> 00:45:04.460
And now if you have two different versions of your app accessing memcache at the same time, but they both have different definitions of the object, they'll actually start poisoning each other and you'll cause just total runtime failures.

00:45:04.460 --> 00:45:11.660
And the only solution, even if you flush the cache, it doesn't work because the old version will start writing it stuff into the cache.

00:45:11.660 --> 00:45:13.000
The new version will start writing it stuff.

00:45:13.440 --> 00:45:17.120
So there's, once you get into this loop of death, it's like, there's nothing you can do.

00:45:17.120 --> 00:45:18.440
It's really scary.

00:45:18.440 --> 00:45:18.700
Yeah.

00:45:18.700 --> 00:45:23.800
So they started, they started partitioning their memcache keys to make sure that they wouldn't interact.

00:45:23.800 --> 00:45:29.640
I'm envisioning them putting like PY3 or PY2 in front of every key name or something.

00:45:29.640 --> 00:45:30.140
Exactly.

00:45:30.140 --> 00:45:32.000
And that's really an amazing best practice.

00:45:32.000 --> 00:45:43.280
It seems so obvious when you hear about it, but like, I think that that's something that, you know, even if you're just doing rollouts of deployments or, you know, you have new Docker images that are holding your app in them, that's actually a great strategy.

00:45:43.280 --> 00:45:48.740
Just to reduce the amount of incompatibilities between the runtime, the, you know, runtime versions you have going on.

00:45:48.740 --> 00:45:49.060
Right.

00:45:49.060 --> 00:45:51.560
Maybe even like your app version or something, right?

00:45:51.560 --> 00:45:56.560
It could even be, be that much, but it could be your code change, not Python's internal change.

00:45:56.560 --> 00:45:56.900
Yeah.

00:45:56.900 --> 00:45:57.940
That's, that's what I'm trying to say.

00:45:57.940 --> 00:45:58.120
Yeah.

00:45:58.120 --> 00:46:02.600
Between your own code versions, you know, your commit hash, you could use as a, as a prefix.

00:46:02.600 --> 00:46:04.140
I think that's a really cool best practice.

00:46:04.140 --> 00:46:04.440
Yeah.

00:46:04.440 --> 00:46:04.640
Cool.

00:46:04.640 --> 00:46:05.240
Yeah.

00:46:05.240 --> 00:46:06.460
So I really liked this.

00:46:06.460 --> 00:46:11.120
And in the end, they, I guess I could talk about the rollout really quick.

00:46:11.120 --> 00:46:11.700
That was interesting.

00:46:11.700 --> 00:46:17.340
They said, okay, first thing we're going to do is we're just going to run the tests on Python three as well.

00:46:17.340 --> 00:46:18.860
And we'll start to slowly work that up.

00:46:18.860 --> 00:46:27.060
And then we're going to switch all the dev environments to run Python three, but still ship to do continuous integration and ship to Python two.

00:46:27.060 --> 00:46:34.300
And then once we get all the dev environments working and we stop hitting bugs, we're going to switch to just the employees of Facebook.

00:46:34.680 --> 00:46:37.780
And then 0.1% of the users and then like 20%.

00:46:37.780 --> 00:46:45.860
And then, and so they, they had this really structured rollout and they said, but by the time we got done with the internal use cases, we were like, there's barely anything left to do.

00:46:45.860 --> 00:46:46.680
Yeah, definitely.

00:46:46.680 --> 00:46:48.840
So that's, that's just really conservative.

00:46:48.840 --> 00:46:50.060
Well done.

00:46:50.060 --> 00:46:53.800
And I'd say just, you know, you have to have everyone on board though, that it takes time.

00:46:53.800 --> 00:46:55.540
It's going to take a lot of resources.

00:46:55.540 --> 00:46:57.740
You need to dedicate a team is not doing anything else.

00:46:57.740 --> 00:47:01.640
And yeah, so I, I, I think it's a model that we should all follow.

00:47:01.640 --> 00:47:01.920
Yep.

00:47:02.020 --> 00:47:05.540
And in the end they said, look, there's these different parts of our code.

00:47:05.540 --> 00:47:07.900
We run Python and Django and micro WSGI.

00:47:07.900 --> 00:47:11.060
We run our async stuff like notifications and celery.

00:47:11.060 --> 00:47:16.820
And we got a 40% performance improvement in, in celery, in the async area.

00:47:16.820 --> 00:47:31.820
And we got a 12% performance memory speed improvement in the, the web front end, which there's like something you could take to your, your company, to your executives and say, look how much we're paying for all of these servers we got to maintain.

00:47:31.820 --> 00:47:32.100
Right.

00:47:32.100 --> 00:47:33.120
Look how much better it'll be.

00:47:33.120 --> 00:47:33.500
Yeah.

00:47:33.500 --> 00:47:39.760
I mean, it just, it just translated straight to like a financial savings and number of machine capacity, you know, that you could get out of it.

00:47:39.760 --> 00:47:43.480
And that's, that's another just amazing kind of convincing argument.

00:47:43.480 --> 00:47:48.000
So it's just, you know, you have speed and you have efficiency and then you have the cost savings.

00:47:48.000 --> 00:47:48.780
So it's, it's great.

00:47:48.780 --> 00:47:49.060
Yep.

00:47:49.060 --> 00:47:49.520
It's great.

00:47:49.520 --> 00:47:54.420
So we started this whole discussion of, by thinking of satellites that look out into space.

00:47:54.420 --> 00:47:58.520
But the next one you went to is about satellites looking in towards the world.

00:47:58.520 --> 00:47:59.180
Yeah.

00:47:59.180 --> 00:48:04.180
So this is a, this is by Catherine Scott and she, she wrote the book on open CB for Python.

00:48:04.180 --> 00:48:08.940
She's been in Python community for a while doing a lot of stuff like robots and computer vision.

00:48:09.140 --> 00:48:20.600
And I think she recently joined a company called planet, which is a satellite imagery company that lets you buy satellite imagery and also let you get access to it for free under a bunch of circumstances.

00:48:21.140 --> 00:48:30.700
And that was a big part of the pitch of this talk was kind of showing you that, that API and for academic research and all these other purposes, how you get access to it.

00:48:30.700 --> 00:48:40.060
So it's more accessible than I've ever knew that you could, you know, you can say like, Hey, this lat lawn, like, can you give me every image of it, you know, for the last number of years?

00:48:40.060 --> 00:48:44.100
And they can actually, you can actually pull that up through an API now, which is just totally bonkers.

00:48:44.100 --> 00:48:45.340
You know, that's really cool.

00:48:45.340 --> 00:48:47.340
And you could actually see how it changes over time, maybe.

00:48:47.620 --> 00:48:58.460
Yeah. And, you know, and, and for her, you know, she mentioned it was, it was kind of like an aside, but for her, it was also like something that she thought was politically important or, you know, deforestation of the rainforest and like all these other kinds of things like that.

00:48:58.460 --> 00:49:09.020
She thought it was useful for, but also just like plain old science, understanding ecology and urban analysis, but urban environments from space and just all kinds of GIS kind of use cases.

00:49:09.020 --> 00:49:13.540
So it was really cool to see her work, work through a bunch of those, those examples.

00:49:13.540 --> 00:49:15.460
Oh yeah. That sounds, that sounds really interesting.

00:49:16.360 --> 00:49:21.260
Another one controlling things or even more so was the factory automation one, right?

00:49:21.260 --> 00:49:30.500
Who I think actually they used to work together, Catherine and Jonas, I don't actually know that, but he works at Tempo Automation, which is a pick and place robot company in San Francisco.

00:49:30.500 --> 00:49:32.960
And so they do a lot of crazy things, factories.

00:49:32.960 --> 00:49:34.560
I love this talk.

00:49:34.560 --> 00:49:37.360
It was really fun because he had a live demo for the entire thing.

00:49:37.780 --> 00:49:41.300
And I'm pretty sure that the video captures some of that.

00:49:41.300 --> 00:49:50.220
I don't know if you remember seeing that, but he had this conveyor belt contraption set up there and had a conveyor belt and had two pusher pads and he had some gum, like chewing gum.

00:49:50.820 --> 00:49:58.720
And he's like, we're going to build a robot that will sort this gum into bubble gum and, you know, and spearmint gum based on the color of the package and a barcode.

00:49:58.720 --> 00:49:59.420
Oh, that's cool.

00:49:59.420 --> 00:49:59.920
Yeah.

00:50:00.360 --> 00:50:02.200
And so then he walks you through.

00:50:02.200 --> 00:50:02.560
Okay.

00:50:02.560 --> 00:50:08.760
In Python, there's actually a PI serial library that will interface with a serial port and the serial port is a micro scanner for barcode.

00:50:08.760 --> 00:50:14.620
And, and so he just like walked you through just from the beginning, like, okay, here's how you can scan a barcode.

00:50:14.620 --> 00:50:18.040
Here's how you can actuate a little paddle, like in a pinball machine.

00:50:18.400 --> 00:50:20.860
Here's how you can turn on a conveyor belt.

00:50:20.860 --> 00:50:23.480
There's all this stuff I never, I know it's in there.

00:50:23.480 --> 00:50:31.400
I've seen stuff on TV or whatever about factories and conveyor belts and factories, but he just went through like how it all actually works together.

00:50:31.400 --> 00:50:33.500
And you can do it all from Python.

00:50:33.500 --> 00:50:35.320
There's great libraries for it.

00:50:35.320 --> 00:50:36.760
And it seemed really easy.

00:50:36.760 --> 00:50:40.120
So it's like, that's one of the best talks where you're like, oh, I could totally do this, you know?

00:50:40.120 --> 00:50:40.420
Yeah.

00:50:40.420 --> 00:50:42.280
Made it entirely accessible, right?

00:50:42.280 --> 00:50:42.540
Yeah.

00:50:42.540 --> 00:50:43.280
Totally accessible.

00:50:43.280 --> 00:50:43.880
Excellent.

00:50:43.880 --> 00:50:44.540
Yeah.

00:50:44.540 --> 00:50:44.940
That's great.

00:50:44.940 --> 00:50:45.120
Yeah.

00:50:45.300 --> 00:50:49.420
I really think the internet of things and these little devices, we're just at the beginning.

00:50:49.420 --> 00:50:50.880
There'll be really cool stuff we can do with it.

00:50:50.880 --> 00:50:51.420
Yeah, definitely.

00:50:51.420 --> 00:50:59.260
And I think it also makes you realize that the internet of things, you know, we talk about it mostly for consumers and the little devices in our houses.

00:50:59.260 --> 00:51:03.760
But in the factory, these devices are actually much more impactful.

00:51:03.760 --> 00:51:13.120
And so you have sensors on control, you know, on conveyor belts or factory floors or the actual, like, not the supply chain, but the Henry Ford thing that's escaping me right now.

00:51:13.120 --> 00:51:13.620
Assembly line?

00:51:13.620 --> 00:51:14.400
Assembly line.

00:51:14.400 --> 00:51:14.840
Thank you.

00:51:14.980 --> 00:51:15.120
Yeah.

00:51:15.120 --> 00:51:19.160
And so I think, you know, he just showed all of the things you need in order to do that.

00:51:19.160 --> 00:51:27.880
So it's awesome that it's available over the internet, but it's also really scary because you're like, wow, if someone got access to that thing over the internet, they could, you know, cause a conveyor belt.

00:51:27.880 --> 00:51:30.980
Like, yeah, I love Lucy style to be like running at a million miles an hour.

00:51:30.980 --> 00:51:31.320
Yeah.

00:51:31.320 --> 00:51:35.380
So I thought that was pretty funny just seeing into that as well.

00:51:35.380 --> 00:51:36.240
Yeah.

00:51:36.240 --> 00:51:36.980
That's neat.

00:51:36.980 --> 00:51:37.300
Yeah.

00:51:37.300 --> 00:51:37.700
All right.

00:51:37.700 --> 00:51:41.480
The last one I thought was really pretty inspiring by Marietta.

00:51:41.480 --> 00:51:42.020
Yeah.

00:51:42.020 --> 00:51:43.760
Called Dial M for Mentor.

00:51:43.760 --> 00:51:44.120
Right.

00:51:44.120 --> 00:51:51.340
She's the first female Python core developer who's landed a commit into Python, you know, 20 some odd years after Python started.

00:51:51.580 --> 00:52:02.160
So it's just really great that the Python community has been able to, we had a couple years ago, Hey, we need to really diversify the people who are committing to the core, sent out the call.

00:52:02.160 --> 00:52:03.280
They tried to mentor people.

00:52:03.480 --> 00:52:07.940
And he repeatedly said that we need to have more different types of people committing to Python.

00:52:07.940 --> 00:52:13.580
And so she is, she is the first committer, female committer to Python and to the core.

00:52:14.060 --> 00:52:22.460
To me, this talk was a lot about the kind of journey of mentorship of what it takes to, to, to, to make a contribution like that for someone where it might seem really scary.

00:52:22.460 --> 00:52:23.060
Yeah, absolutely.

00:52:23.220 --> 00:52:28.140
I mean, really the part where she talks about being a core developer, that's not until like the last five minutes.

00:52:28.140 --> 00:52:33.980
It's until then is like, here's all the ways that I was frustrated becoming a developer.

00:52:33.980 --> 00:52:35.320
Here's all the ways I got stuck.

00:52:35.440 --> 00:52:42.640
And I felt inadequate and I felt like this was not for me and how I either kept myself going or I got help from someone.

00:52:42.640 --> 00:52:52.580
And, you know, on the core developer side, I think Guido actually was her mentor to help her make her way through to actually, you know, getting stuff working.

00:52:52.580 --> 00:52:53.100
Yeah.

00:52:53.100 --> 00:52:55.320
At the code level in CPython, which is cool.

00:52:55.320 --> 00:52:55.740
Yeah.

00:52:55.740 --> 00:52:56.140
It's cool.

00:52:56.140 --> 00:53:05.600
And I think that she explained a lot of her fears and the common kind of issues that people have when they're like need mentorship, but are too afraid to ask for it or have a hard time finding it.

00:53:05.600 --> 00:53:16.580
And so it's a good wake up call for, I think people just in general, but in the Python community, especially to realize that we need to structure mentorship better and have a more active approach to how we do it.

00:53:16.680 --> 00:53:28.400
And I've heard, you know, DjangoCon actually has a mentorship program for talks there where they will pair people who have never given a talk, but have thought about it with people who have given many talks to try to help them, you know, work through their slides.

00:53:28.400 --> 00:53:29.360
Practice.

00:53:29.360 --> 00:53:30.000
Yeah.

00:53:30.000 --> 00:53:34.320
And I don't know if they're actually doing this for PyCon itself yet, but they do it for DjangoCon.

00:53:34.320 --> 00:53:35.860
And I think that's an awesome model.

00:53:35.860 --> 00:53:49.220
And I really hope that they, they should just do that for all of the regional PyCons and all of the, you know, all of those kind of meetup groups, just because that's, that's how you build confidence in young people or, or, or people who are approaching Python from different backgrounds.

00:53:49.220 --> 00:53:50.960
And I think that's really critical.

00:53:50.960 --> 00:54:01.560
So I think that her talk is a great way to kind of focus on what this meant, what these mentors should be doing and what, you know, how they need to make people feel comfortable seeking out mentorship.

00:54:01.560 --> 00:54:11.700
Yeah. I think if you're in your first five years of programming, this will be really helpful for you looking for mentorship and finding your way and feeling confident.

00:54:11.700 --> 00:54:20.700
And I think if you've been programmed for a really long time, this will help remind you what it's like for people coming into the modern environment and maybe how you can help.

00:54:20.700 --> 00:54:31.540
Yeah, definitely. And I've been on both sides of that, you know, I remember like needing mentorship way back when, and I also, and now I do mentor people, but I, I would mentor more if I had a better way of connecting to people who need it.

00:54:31.540 --> 00:54:36.420
You know, and there's a couple of ways she calls out that people can do that, which is great for people to volunteer.

00:54:36.420 --> 00:54:46.840
And I hope that more kind of come up in the Python community so that the mentor, the, the people doing the mentoring also more of them volunteer and really make a point of taking the time to do it.

00:54:46.840 --> 00:54:49.720
Yeah. It was a great talk. So let's leave it with that, huh?

00:54:49.720 --> 00:54:50.080
Yeah.

00:54:50.080 --> 00:54:57.080
For the ones that we went to, maybe I can ask you real quick, just, are there some other ones you're like, this is on my to watch list, but I didn't make it to it.

00:54:57.180 --> 00:55:05.860
Yeah. Raymond Hettinger always has a talk, not always, but usually, and it's always great. And so he had one on dictionaries that I didn't get to see, but I heard was awesome.

00:55:05.860 --> 00:55:14.340
Yeah. I don't know if it was this particular talk, but one of his talks was basically sold out. Like they closed the door and said, you can't come in. Like we're at the limit for fire code in this room.

00:55:14.340 --> 00:55:23.540
Yeah. That's usually what happens fire code. Yes. I was like, if people are new to Python, I'm like, well, you should probably go to this talk and get there like early. Yes. I, and I don't go to the, I'll watch that talk later, you know?

00:55:23.540 --> 00:55:33.580
And then Brandon Rhodes, who was the chair of the conference. He also had a talk on dictionaries as well. I think it was different enough from the other ones. I'm looking forward to watching that one. He's a great speaker.

00:55:33.820 --> 00:55:49.200
Yeah. That's, that's really good. And the last one was just Brett Cannon. He had a talk on what's new in Python three, six. It's just like an, a summary. And so you can read that online. If you just Google like what's new in Python three, six, you'll find it. But you know, hearing someone give the talk is a lot more interesting than reading through the notes. So I would definitely check that out.

00:55:49.200 --> 00:56:06.260
I agree with you on that. I've read what it was in there and when it all came out, then I watched his talk and really the, this is here is what you get from reading the peps, but it's like, this is here. And this is the implication of what this being here means and whatnot. I think you just get a lot more appreciation for it.

00:56:06.260 --> 00:56:07.560
Yeah. I agree.

00:56:07.560 --> 00:56:12.240
All right. Excellent. So that was really, you know, it was fun, fun pike on, right?

00:56:12.240 --> 00:56:18.780
Oh, it was great. Yeah. And next year it's in Cleveland. I think the next two years it's in Cleveland, Ohio. So that's going to be totally different. Change the scene.

00:56:18.780 --> 00:56:37.260
Yeah. And I'm looking, looking forward to that and some great talks. So yeah, I'm looking forward to next year. And, and in the meantime, there's a bunch of regional Pycons coming, you know, Python conferences coming up. So that's another thing to just check out. Like if you, if you can't travel to one of these other places, you'd be surprised how many local Pycons there are across the United States and really across the world. So it's, it's worth checking those out.

00:56:37.260 --> 00:56:48.660
Yeah, absolutely. I think they just announced PyCon Canada. And then there's also PyCascades, which is going to be in February. I think these are the PyCascades is brand new. And actually Marietta, the last person we spoke about,

00:56:48.720 --> 00:57:07.020
was part of the organizer for that. Right. Yeah. Yeah. I think, I think it's for all the Pacific Northwest kind of area. Yeah. So definitely get out to one of these Pycons or multiple ones. If you're, if this sounds interesting to you, it's really a great time. Even if you don't go to the talks. Yeah, I agree. All right. Final two questions, Brett. Okay. If you're going to write the Python code, what editor do you use?

00:57:07.020 --> 00:57:17.300
I'm still using Sublime Text. I'm on version three now. Yep. That's, it's still, still my, still my thing. And if I'm in a terminal, I still use Emacs. So that's my, I'm on that side of the debate.

00:57:17.300 --> 00:57:20.420
All right. Very cool. And a notable PyPI package.

00:57:20.760 --> 00:57:40.580
Wow. Recently, it's going to be what I can't live without. Right. I think it's been my go-to still. Yeah. If I'm doing web development, I'm going to install Flask every time, basically. So without a doubt. But I think if I'm actually just trying to do processing, it's, it's NumPy, which it's still the best thing that happened to Python.

00:57:40.580 --> 00:57:47.480
All right. Yeah, for sure. It's very cool. I'll throw one more in there with mypy, just from the static typing talk.

00:57:47.480 --> 00:57:53.280
I haven't used it enough to install it every time, but I think that's a great, that's actually something I should shoot for is that being my go-to.

00:57:53.280 --> 00:57:57.600
Yeah. Yeah. That's very cool. Yeah. All right. So you actually have a playlist of this, right?

00:57:57.600 --> 00:58:00.000
Oh, wow. I do. Yeah. I could share that. That's a good idea.

00:58:00.000 --> 00:58:02.140
Yeah. If it's already, I'll just put it in the show notes. Sounds good.

00:58:02.140 --> 00:58:07.900
And just subscribe to it and just go through. They can basically replay PyCon through your attendance.

00:58:08.480 --> 00:58:14.900
Sounds good. Yeah. I think I'll add a couple more in there too. I think the lightning talks are worth checking out and, but that's great. Yeah, we should do that.

00:58:14.900 --> 00:58:17.600
All right. Awesome. Brett, thanks for being on the show. It was excellent to talk with you.

00:58:17.600 --> 00:58:20.260
Yeah. Thanks so much for having me. I had a really good time.

00:58:20.260 --> 00:58:20.840
You bet. Bye.

00:58:20.840 --> 00:58:25.280
This has been another episode of Talk Python to Me.

00:58:25.280 --> 00:58:31.560
Today's guest has been Brett Slatkin, and this episode has been brought to you by Rollbar and Codeship.

00:58:31.560 --> 00:58:34.460
Rollbar takes the pain out of errors.

00:58:34.460 --> 00:58:42.160
They give you the context and insight you need to quickly locate and fix errors that might have gone unnoticed until your users complain, of course.

00:58:42.160 --> 00:58:49.300
As Talk Python to Me listeners, track a ridiculous number of errors for free at rollbar.com slash Talk Python to Me.

00:58:49.300 --> 00:58:54.360
Do you have software? Would you like to know if it has bugs before you deploy it?

00:58:54.680 --> 00:59:01.620
Then jump over to talkpython.fm/Codeship and set up a free Codeship Basic account, Ship Tested Software.

00:59:01.620 --> 00:59:04.780
Are you or your colleagues trying to learn Python?

00:59:04.780 --> 00:59:07.840
Well, be sure to visit training.talkpython.fm.

00:59:07.840 --> 00:59:13.640
We now have year-long course bundles and a couple of new classes released just this week.

00:59:13.640 --> 00:59:16.080
Have a look around. I'm sure you'll find a class you'll enjoy.

00:59:16.080 --> 00:59:18.500
Be sure to subscribe to the show.

00:59:18.500 --> 00:59:20.700
Open your favorite podcatcher and search for Python.

00:59:20.880 --> 00:59:21.960
We should be right at the top.

00:59:21.960 --> 00:59:31.280
You can also find the iTunes feed at /itunes, Google Play feed at /play, and direct RSS feed at /rss on talkpython.fm.

00:59:31.280 --> 00:59:36.360
Our theme music is Developers, Developers, Developers by Corey Smith, who goes by Smix.

00:59:36.360 --> 00:59:43.040
Corey just recently started selling his tracks on iTunes, so I recommend you check it out at talkpython.fm/music.

00:59:43.040 --> 00:59:48.420
You can browse his tracks he has for sale on iTunes and listen to the full-length version of the theme song.

00:59:48.980 --> 00:59:50.480
This is your host, Michael Kennedy.

00:59:50.480 --> 00:59:52.960
Thanks so much for listening. I really appreciate it.

00:59:52.960 --> 00:59:55.100
Smix, let's get out of here.

00:59:55.100 --> 01:00:16.560
Stay tuned. I'll see you next time.

01:00:16.560 --> 01:00:17.360
Don't believe

01:00:17.360 --> 01:00:47.340
Thank you.

