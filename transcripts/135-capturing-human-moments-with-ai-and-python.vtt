WEBVTT

00:00:00.001 --> 00:00:03.840
We all have smartphones these days, and we take them with us everywhere we go.

00:00:03.840 --> 00:00:08.380
How much could you infer about a person, their stage in life, their driving style,

00:00:08.380 --> 00:00:13.000
their work-life balance, based on just a phone's motion and GPS data?

00:00:13.000 --> 00:00:17.120
With the right mix of analytics and machine learning, it turns out you can learn a lot

00:00:17.120 --> 00:00:23.060
about a person. Are they a dog-owning workaholic or an early rising parent of young children?

00:00:23.060 --> 00:00:28.360
This week you'll meet Vincent Spert, who is the chief data scientist at Sentience,

00:00:28.360 --> 00:00:34.460
a company building an SDK to answer these exact questions. You'll learn how they're using Python

00:00:34.460 --> 00:00:37.740
to make this happen and how they think this data could be used for the greater good.

00:00:37.740 --> 00:00:43.600
This is Talk Python to Me, episode 135, recorded October 25, 2017.

00:00:56.720 --> 00:01:02.760
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the

00:01:02.760 --> 00:01:07.380
ecosystem, and the personalities. This is your host, Michael Kennedy. Follow me on Twitter,

00:01:07.380 --> 00:01:12.300
where I'm @mkennedy. Keep up with the show and listen to past episodes at talkpython.fm,

00:01:12.300 --> 00:01:18.020
and follow the show on Twitter via at Talk Python. This episode is brought to you by Datadog and

00:01:18.020 --> 00:01:21.840
GoCD. Please check out what they're offering during their segments. It really helps support

00:01:21.840 --> 00:01:24.120
the show. Vincent, welcome to Talk Python.

00:01:24.120 --> 00:01:24.660
Thank you.

00:01:24.660 --> 00:01:29.340
It's great to have you here. You guys have a super cool platform. You're doing some seriously

00:01:29.340 --> 00:01:35.760
deep learning and AI and machine learning, and I think everyone's going to get a pretty cool look

00:01:35.760 --> 00:01:39.420
at what you guys are doing and how you're doing it. There's a bunch of cool algorithms going on here.

00:01:39.420 --> 00:01:44.440
But before we get into all that detail, let's talk about how you got into programming and Python,

00:01:44.440 --> 00:01:45.060
things like that.

00:01:45.060 --> 00:01:50.560
Yeah, sure. Cool. It started when I was about 14, and I started hacking around with some web design.

00:01:50.560 --> 00:01:55.900
Remember those days where everyone used those marquee banners? There was no CSS and stuff like

00:01:55.900 --> 00:01:56.060
that.

00:01:56.060 --> 00:01:58.980
Like the blink tag. Yeah, yeah, that was wonderful. Those were good days.

00:01:58.980 --> 00:02:03.120
Exactly. So over the years, I went more into network security and hacking, started a company

00:02:03.120 --> 00:02:09.460
when I was around 18, and converted more to languages like Java and C++ throughout my PhD.

00:02:09.460 --> 00:02:11.200
What was the company you started when you were 18?

00:02:11.400 --> 00:02:14.940
It was a network security company, so quite different from what I'm doing today. It was

00:02:14.940 --> 00:02:20.120
a lot about the... You know, back then, the internet was more or less the Wild West. Everything

00:02:20.120 --> 00:02:22.620
was wide open, so interesting times.

00:02:22.620 --> 00:02:28.820
Yeah, I remember back then that things like Windows XP was the most popular operating system,

00:02:28.820 --> 00:02:31.600
and it had no firewall at all.

00:02:31.600 --> 00:02:32.400
Yeah, yeah, exactly.

00:02:32.400 --> 00:02:32.640
Right?

00:02:32.640 --> 00:02:33.040
Exactly.

00:02:33.040 --> 00:02:33.500
Exactly.

00:02:33.500 --> 00:02:38.260
No, it was right on the internet. It was really bad. Yeah, cool. Okay, so yeah, those were interesting

00:02:38.260 --> 00:02:41.380
Wild West days for sure. And then you said you moved on to...

00:02:41.380 --> 00:02:42.660
C++ and Java?

00:02:42.660 --> 00:02:48.600
Yeah, so during my PhD, I was mostly working on computer vision, machine learning, so that

00:02:48.600 --> 00:02:54.540
was heavily focused on real-time processing, so most of the work was done in C++. And then

00:02:54.540 --> 00:02:59.280
I joined Sentience about three years ago to start out a data science team. So back then, Sentience

00:02:59.280 --> 00:03:04.920
was quite small. I think we were with five people. And we had to choose a main programming language

00:03:04.920 --> 00:03:09.480
for the machine learning stuff, the data science part. And so I guess, coming a bit from an academic

00:03:09.480 --> 00:03:15.100
background, I was looking for a language that both had the ease of use as that MATLAB or

00:03:15.100 --> 00:03:21.540
R has. But on the other hand, also is a language that allows us to go to production and build

00:03:21.540 --> 00:03:25.640
scalable systems. That's how we came up with Python. And so since then, Python has been

00:03:25.640 --> 00:03:26.220
my go-to.

00:03:26.220 --> 00:03:30.780
Yeah, that's really great. Three years ago, I think it was probably on the border of whether

00:03:30.780 --> 00:03:37.780
Python was going to be one of the really dominant machine learning languages. I mean, now it's

00:03:37.780 --> 00:03:42.380
like really a clear choice. But three years ago, it was just starting to be a clear choice,

00:03:42.380 --> 00:03:46.360
right? What other things did you consider? And why, in the end, did you choose Python?

00:03:46.500 --> 00:03:53.560
The thing is that obviously you don't want to use MATLAB in a production system. So then I guess the

00:03:53.560 --> 00:03:59.920
choice was whether or not we would want to use a programming language like Java for the data science

00:03:59.920 --> 00:04:04.560
work. And there has been some discussion around that because the data engineering team here at

00:04:04.560 --> 00:04:09.540
Sentience does most of the stuff in Java, you know, making sure everything is scalable, all the

00:04:09.540 --> 00:04:15.920
infrastructure stuff is Java. But for us, we noticed that although we love Java, doing rapid prototyping,

00:04:16.120 --> 00:04:20.920
quickly coming up and testing your models, it's just much easier in Python. And actually,

00:04:20.920 --> 00:04:25.080
although there is a lot of discussion on whether or not Python is a production-friendly language,

00:04:25.080 --> 00:04:30.720
if you look at, for example, YouTube, they also use mainly Python for their whole platform. So

00:04:30.720 --> 00:04:31.720
it's quite powerful.

00:04:31.720 --> 00:04:36.060
Yeah, it's incredibly powerful. You look at some of the people or some of the companies doing

00:04:36.060 --> 00:04:41.120
really interesting things. YouTube is a great example. YouTube handles like a million requests per

00:04:41.120 --> 00:04:48.060
second. So that's a pretty insane level of web traffic right there. And yeah, there's some other

00:04:48.060 --> 00:04:55.000
really cool use cases like that as well. So I guess the main takeaway is sort of the combination of

00:04:55.000 --> 00:05:01.840
it's quick and easy, but also you can go fully to production, like all the way to like real scalable

00:05:01.840 --> 00:05:04.180
levels of running and production, right?

00:05:04.300 --> 00:05:09.540
Yeah, indeed. And of course, the machine learning communities is, these days is growing. And I mean,

00:05:09.540 --> 00:05:14.700
the amount of libraries and support you have for machine learning in Python is just huge compared to

00:05:14.700 --> 00:05:15.960
almost any other language.

00:05:15.960 --> 00:05:18.680
Yeah, absolutely. So what do you do at Sentience now?

00:05:18.860 --> 00:05:24.080
So I'm the chief data scientist at Sentience. So basically, my job is mostly focused on the research

00:05:24.080 --> 00:05:30.480
part and on building the algorithms together with the team, of course. So Sentience is an AI company

00:05:30.480 --> 00:05:36.700
first. So we are currently with about 50 people, and about 40 of them are actually technical, half of

00:05:36.700 --> 00:05:41.960
them data engineering, and half of them data science. And with data science, we mostly mean, you know,

00:05:41.960 --> 00:05:45.840
machine learning, signal processing, building the actual algorithms there.

00:05:45.840 --> 00:05:50.980
Okay, that sounds, that sounds pretty awesome, like a pretty fun job to be part of, I'm sure.

00:05:50.980 --> 00:05:55.980
So I guess, you know, probably a lot of the listeners don't know about Sentience, maybe give us

00:05:55.980 --> 00:06:03.860
like a high level idea of what you guys do. I mean, you have this specific SDK that people can plug into

00:06:03.860 --> 00:06:10.180
their mobile apps. And then you look at the behaviors and stuff. Tell us what the big idea is.

00:06:10.180 --> 00:06:15.340
Well, the idea is that these days, I mean, everyone has a smartphone, to that extent that the

00:06:15.340 --> 00:06:20.100
smartphone is almost like an extension of your body, you continuously use it. And every smartphone

00:06:20.100 --> 00:06:24.660
is packed with sensors, you have accelerometer sensors measuring every small vibration of the

00:06:24.660 --> 00:06:29.160
phone, you have the gyroscope, of course, you have the location subsystem. So what we do is we have an

00:06:29.160 --> 00:06:34.000
SDK that plugs in into the app of our customers, which are companies. And once the SDK is in the app,

00:06:34.000 --> 00:06:38.320
we start logging all that sensor data, accelerometer, gyroscope, location, we send that to our backend,

00:06:38.320 --> 00:06:43.320
running on Amazon Cloud. And there we have a bunch of machine learning algorithms that extract behavioral

00:06:43.320 --> 00:06:46.680
intelligence from it. So we learn about your behavior. What is your home? What is your work

00:06:46.680 --> 00:06:50.860
location? What do you do every day? Why do you do it? Can we predict your future behavior, etc?

00:06:50.860 --> 00:06:59.120
Wow. Okay. So I totally agree that, you know, it's a crazy world where we always have our phones with us.

00:06:59.120 --> 00:07:04.620
Like I would rather accidentally leave my keys at home and leave my house unlocked and leave my house

00:07:04.620 --> 00:07:05.980
without my phone. You know what I mean?

00:07:06.180 --> 00:07:12.840
So if you can take this information about what people are doing just ambiently, I do more with it. That sounds

00:07:12.840 --> 00:07:19.200
pretty cool. So you take all the sensor data, orientation, accelerometer, location, things like

00:07:19.200 --> 00:07:25.400
that. And you say you extract intelligence from it. So I watched there's a video on your homepage,

00:07:25.400 --> 00:07:31.380
I'll link to it in the show notes where you have these different layers, right? Like one layer comes in and

00:07:31.380 --> 00:07:39.400
just takes in this ambient deformation. One tries to understand what you're doing. And then the other,

00:07:39.400 --> 00:07:43.820
what's the final one to try to create like these moments or something? Tell us about that.

00:07:43.820 --> 00:07:49.880
We start with a low level sensor data. And based on that, we do what we call event detection. So we

00:07:49.880 --> 00:07:55.200
have a whole bunch of classifiers that take in the sensor data and for example, try to classify your mode

00:07:55.200 --> 00:07:59.160
of transport. Based on the vibrations of the phone, you can figure out is this person walking,

00:07:59.360 --> 00:08:05.600
biking in a train, on a subway, in a car, or for example, given your location, your current location,

00:08:05.600 --> 00:08:10.420
we want to figure out where are you? I mean, are you visiting the bus stop that is five meters from

00:08:10.420 --> 00:08:14.120
your location? Or maybe if you're there in the middle of the night for five hours in a row,

00:08:14.120 --> 00:08:18.240
you're not visiting the bus stop, you're actually in the bar that is like 50 meters further, right?

00:08:18.240 --> 00:08:22.880
And so we end up with this whole timeline of human behavior. But of course, then you know what the

00:08:22.880 --> 00:08:28.140
user is doing, but not why he's doing it. So we feed this event timeline into our deep learning

00:08:28.140 --> 00:08:32.360
based prediction model, we can predict what you're going to do next. And that allows us to explain why

00:08:32.360 --> 00:08:36.400
you're doing something, you know, is this are you in a car because it's your commute or because it's

00:08:36.400 --> 00:08:41.660
your shopping routine? Is this a business trip? Is it a leisure trip, etc. And then finally, indeed, we

00:08:41.660 --> 00:08:47.240
aggregate all that data, all those timelines over weeks. So we can come up with with more like a profile.

00:08:47.240 --> 00:08:52.140
Are you a shopaholic, a workaholic? Are you an aggressive driver? Do you have children? And that data we then

00:08:52.140 --> 00:08:53.320
expose back to our customers.

00:08:53.760 --> 00:08:58.840
That's pretty wild. It sounds really challenging, because like you said, there could be a bar and

00:08:58.840 --> 00:09:03.400
then right outside the bar could be, you could be sitting like right in the front, you know, with

00:09:03.400 --> 00:09:07.960
like maybe on a beautiful day, like the windows are open or something. And then right next to that is a

00:09:07.960 --> 00:09:13.080
bus stop. And so determining whether you're trying to go on the bus, or you're trying to relax after

00:09:13.080 --> 00:09:15.440
work. That sounds like a real interesting challenge.

00:09:15.440 --> 00:09:20.360
Yeah, exactly. Even more, I mean, you can be in a bar because you work there, you can be in a bar because

00:09:20.360 --> 00:09:24.540
you just like to go for a drink, you can be there because you live in the apartment on top of it. So

00:09:24.540 --> 00:09:28.320
trying to figure out why a user is doing something is pretty cool.

00:09:28.320 --> 00:09:36.020
Yeah, that's definitely taking it to another level. So what is your day to day look like? Do you do a

00:09:36.020 --> 00:09:40.800
lot of research? What kind of tools do you do to come up with some of these models? Do you write

00:09:40.800 --> 00:09:41.880
production code? What are you doing?

00:09:42.000 --> 00:09:47.180
It's a mix of both research and actually writing production code indeed. So most, most of the time when we start

00:09:47.180 --> 00:09:52.420
on a project, there is a research phase. I mean, there's a lot of reading papers, experimenting, usually just in

00:09:52.420 --> 00:09:58.180
iPad and notebooks, you create your models, you validate them. But then at some point, indeed, we have to convert

00:09:58.180 --> 00:10:04.640
this code into something that is production ready. So then it actually comes or boils down to cleaning up the code,

00:10:04.640 --> 00:10:10.180
creating a nice object oriented framework. Do you need testing, regression testing, you know, performance profiling,

00:10:10.180 --> 00:10:16.940
make sure that everything is scalable, and then encapsulate it into an API so that we can deploy

00:10:16.940 --> 00:10:22.260
this as a microservice. And finally, try to get a microservice running in a Docker image. And that is

00:10:22.260 --> 00:10:26.400
actually then when the data engineering team comes in. So the data engineers take this Docker image,

00:10:26.400 --> 00:10:31.440
refine it, basically, they built a base Docker image. So we just customize it a little bit for our specific

00:10:31.440 --> 00:10:35.320
projects. And they help us to make sure that we can deploy it in a scalable manner.

00:10:35.320 --> 00:10:38.340
That's cool. And do you guys deploy it to your own system? Or do you deploy,

00:10:38.340 --> 00:10:44.440
I forgot what AWS is container service is called? But do you deploy it to the container service? Or do

00:10:44.440 --> 00:10:46.980
you have more control over where it lives and runs?

00:10:46.980 --> 00:10:53.320
It's our own system. So we try, I mean, we love AWS, but we try to be not too dependent on their

00:10:53.320 --> 00:10:58.060
specific services, mainly because we need to be able to move to different cloud infrastructures if needed.

00:10:58.100 --> 00:11:05.340
Isn't that an interesting struggle? Like, there's so many features and AWS and Azure, those are the two that

00:11:05.340 --> 00:11:12.780
have like, a ridiculous number of things that the cloud can do. But the more that you like, put those

00:11:12.780 --> 00:11:18.880
hooks into your system and those dependencies, like the more you're locked in, I mean, people used to talk

00:11:18.880 --> 00:11:23.900
about lock in like with Windows or with Mac or with iOS or whatever. But like, the cloud lock in is a whole

00:11:23.900 --> 00:11:27.900
another level if you go all in, right? Yeah, exactly. And of course, that's their business model. I mean,

00:11:27.900 --> 00:11:31.040
they try to get you to use those specific services.

00:11:31.040 --> 00:11:37.300
Yeah. Yeah, that's cool. Okay, so go with your own container service. That makes a lot of sense.

00:11:37.300 --> 00:11:45.420
And for the tooling for R&D stuff, this is like IPv3 notebooks. And what are the notable packages and

00:11:45.420 --> 00:11:50.940
libraries using there? It depends on the project, I guess. Obviously, we just use a lot of typical

00:11:50.940 --> 00:11:54.860
libraries like scikit-learn for most of the modeling. When we talk about deep learning,

00:11:54.860 --> 00:12:00.220
it's usually TensorFlow and some Keras. For performance and memory profiling, we create

00:12:00.220 --> 00:12:05.880
things like flame graphs. For unit testing, we use a pytest or nosetest. Yeah, nice. Are you using

00:12:05.880 --> 00:12:13.320
like GPU clusters in AWS or is this pure CPU-based? For deployment at inference time, it's usually CPU-based.

00:12:13.320 --> 00:12:18.660
For research, I mean, like training the models, we indeed use GPU machines because it can take a few

00:12:18.660 --> 00:12:23.180
weeks before a model is trained. So that really speeds it up. Yeah. And how fast is it if you use

00:12:23.180 --> 00:12:28.700
GPUs? Also weeks. And if it's not GPUs, it's even worse. Yeah, exactly. So the last model I trained a

00:12:28.700 --> 00:12:35.420
few weeks ago, I started using, I started out using an AWS machine that was just a CPU machine with 36

00:12:35.420 --> 00:12:42.000
cores. And eventually, I moved to a GPU machine where I trained about two weeks. And the training there,

00:12:42.000 --> 00:12:46.440
I mean, the loss went down about 10 times as fast as when I was using the CPU machines.

00:12:46.440 --> 00:12:51.560
Wow, that's really awesome. Yeah. And for performance and stuff, you just get that

00:12:51.560 --> 00:12:56.560
basically dialed in, I guess. There's two parts, right? There's training and then there's answering

00:12:56.560 --> 00:13:00.960
the question, the inference bits. How do you sort of balance those things? Like obviously,

00:13:00.960 --> 00:13:06.460
you're just going to train as much data as you need. But then what do you do for performance at

00:13:06.460 --> 00:13:10.200
that point? I mean, once you have the model built and you kind of have the library, you're using

00:13:10.200 --> 00:13:14.420
TensorFlow or whatever, you kind of like how much flexibility do you have to make it go faster?

00:13:14.420 --> 00:13:20.380
Well, that's a good question. And usually, it's really just trying to balance performance and

00:13:20.380 --> 00:13:26.100
cost, I guess. I mean, you can have a model with 3 million parameters and have a gain of 1% in

00:13:26.100 --> 00:13:31.660
accuracy compared to a model with 300,000 parameters, right? While the latter, of course, is much cheaper

00:13:31.660 --> 00:13:36.420
to be used in production. So a lot of the time, it's just balancing out those two.

00:13:36.420 --> 00:13:42.320
Okay, that's interesting. Do you sometimes build like super detailed models in the research phase and go,

00:13:42.320 --> 00:13:49.020
I think we can take it down to 100,000 or whatever levels and then run that in production and get good

00:13:49.020 --> 00:13:54.660
enough answers? Yeah, we do. Especially, of course, if you, some of our models started out on the cloud,

00:13:54.660 --> 00:13:59.360
and then at some point, we realized, you know, we could actually deploy those on the mobile phone

00:13:59.360 --> 00:14:03.900
itself. So then it's very important to reduce the number of parameters as much as possible without

00:14:03.900 --> 00:14:09.000
losing too much accuracy. So yeah, that's really cool. And that's definitely a trend in the space to

00:14:09.000 --> 00:14:14.120
not have these tremendously powerful cloud infrastructures, but to push it to the edge, right?

00:14:14.120 --> 00:14:15.700
To the devices.

00:14:15.700 --> 00:14:23.520
Yeah, indeed, indeed. It's especially with, you know, Apple in the new iPhone has this X11 chip that is like a

00:14:23.520 --> 00:14:28.740
dedicated coprocessor for these kind of things. And at the same time, Google with the Pixel 2, they have this

00:14:28.740 --> 00:14:34.280
separate chip specifically for like image processing, computer vision. So more and more phones will have

00:14:34.280 --> 00:14:38.400
coprocessors that allow us to do edge computing without draining the battery too much.

00:14:38.400 --> 00:14:44.300
Yeah, that's more or less like running on GPUs, right? Like these specialized hardware are way more efficient and

00:14:44.300 --> 00:14:47.220
quick. So more reasonable to run it on these wimpy devices.

00:14:47.220 --> 00:14:47.740
Exactly.

00:14:47.740 --> 00:14:54.440
Yeah, yeah. Cool. So you said that you guys were about 50 people. What is the and if I remember the breakdown, right?

00:14:54.440 --> 00:15:00.180
20 or so data scientists, 20 or so sort of data software website of things.

00:15:01.100 --> 00:15:05.400
What's the team structure? Like how do you guys work together and things like that?

00:15:05.400 --> 00:15:10.580
We have a model that is that is like loosely based on the Spotify model. They work with a or we work in a kind of a

00:15:10.580 --> 00:15:15.820
matrix structure where horizontally, we have a set of functional teams. So there is a data science team, there is a data

00:15:15.820 --> 00:15:21.860
engineering team, then there is a mobile SDK team, and then there is a solutions team. But we quickly realized as those

00:15:21.860 --> 00:15:27.900
teams grow bigger and bigger, that it's very difficult to isolate. You don't want to want to be isolated in your team, you want

00:15:27.900 --> 00:15:32.880
to work together with people from different backgrounds. So that's why vertically over those

00:15:32.880 --> 00:15:37.960
teams, we define cross functional teams that we call squads. So cross functional team has a quite a

00:15:37.960 --> 00:15:43.360
specific focus, it's kind of a of a mini startup. And it consists of a few data scientists, few data

00:15:43.360 --> 00:15:48.740
engineers, few mobile guys, they build stuff from from concept to actually build, bringing it into

00:15:48.740 --> 00:15:49.160
production.

00:15:49.160 --> 00:15:56.120
That sounds really like a cool way to work, actually. So there's some new major feature or new

00:15:56.120 --> 00:16:00.100
library you guys want to build and you put together these cross functional teams to build it, huh?

00:16:00.100 --> 00:16:05.120
Yeah, and usually cross those cross functional teams or those squads are long lift. So it's not like they

00:16:05.120 --> 00:16:11.100
are created and then and then disbanded quickly, because of course, we continuously try to improve

00:16:11.100 --> 00:16:15.240
our products. So we have like a mob sense, what we call a mob sense squad, the squad that focuses on

00:16:15.240 --> 00:16:19.220
everything around signal processing, and you know, the deep learning directly on the sensor data,

00:16:19.220 --> 00:16:23.740
then we have like a lifestyle squad that focuses more on the moments in the segments. So there we use more

00:16:23.740 --> 00:16:29.040
like NLP related techniques. And of course, we try to move people around. I mean, you don't stay in a

00:16:29.040 --> 00:16:29.860
single squad forever.

00:16:29.860 --> 00:16:36.920
Of course. That sounds really cool. So let's dig into the three layers of your SDK, the event

00:16:36.920 --> 00:16:42.080
acquisition, the moments and segments, you call them, right? So there's some pretty interesting

00:16:42.080 --> 00:16:50.060
algorithms and libraries you're using. So the first level is this idea of events. And the basic

00:16:50.060 --> 00:16:55.060
question you're trying to answer is what is the user doing? So maybe we could talk about some of the

00:16:55.060 --> 00:17:00.360
some of the algorithms and techniques you're using to determine like, are they driving? Are they walking?

00:17:00.360 --> 00:17:02.620
Are they at a bar? Whatever.

00:17:02.620 --> 00:17:08.200
Yeah, yeah, cool. Well, so transport mode detection itself is a is a cool problem. You know, both both

00:17:08.200 --> 00:17:13.720
iOS and Android already have what what they call motion activities. So they give you an idea already about

00:17:13.720 --> 00:17:19.260
transport mode, but it's quite limited. I think they support walking, biking, vehicle and idle,

00:17:19.360 --> 00:17:23.720
something like that. Also, the occurrences are quite low, usually. So indeed, we had to build our

00:17:23.720 --> 00:17:28.320
own model to get better occurrences, and especially to extend the number of transports we support like

00:17:28.320 --> 00:17:31.500
bus and subway and running and stuff like that.

00:17:31.500 --> 00:17:37.160
Sure. Can you still leverage these like motion chips at a lower level and not just ask like,

00:17:37.160 --> 00:17:41.800
what are they doing? But you know, give me the actual measurements that you were going to use to

00:17:41.800 --> 00:17:42.540
make that assessment?

00:17:42.540 --> 00:17:47.740
Currently, we get 25 hertz accelerometer and gyroscope data from the phone. And based on that data,

00:17:47.860 --> 00:17:50.960
well, first, of course, there is some pre processing, some signal processing, you have

00:17:50.960 --> 00:17:56.080
to interpolate the samples because they don't come in on a regular on a regular grid, let's say,

00:17:56.080 --> 00:18:01.220
you have to do some bandpass filtering to remove the high frequency components that usually contain

00:18:01.220 --> 00:18:05.120
a lot of noise. And then after that, when you have like a signal that is more or less clean,

00:18:05.120 --> 00:18:09.660
what we do then is a lot of data augmentation, we add some noise, you know, additive noise,

00:18:09.660 --> 00:18:14.600
multiplicative noise. And that is mainly because every phone has different noise characteristics. And we

00:18:14.600 --> 00:18:20.780
don't want our machine learning models to learn to recognize specific phones. So to undo those noise

00:18:20.780 --> 00:18:25.480
characteristics, we basically deliberately add noise to our data, so that the classifiers learn to

00:18:25.480 --> 00:18:31.060
generalize. And what we then do is we feed that sensor data. Well, maybe it's interesting to have a look at

00:18:31.060 --> 00:18:35.640
the evolution. So today we use a neural net, a conf net, but we started out in a completely different

00:18:35.640 --> 00:18:41.860
way. In the beginning, we actually chopped our sensor stream into pieces of several seconds. Those pieces for

00:18:41.860 --> 00:18:46.620
those pieces of or segments of sensor data, we did a lot of manual feature engineering, like some Fourier

00:18:46.620 --> 00:18:52.140
coefficients, like frequency domain features, time domain features. Those were fed into a random forest

00:18:52.140 --> 00:18:54.840
back then. And the random forest then outputs class probabilities.

00:18:54.840 --> 00:18:57.760
Maybe quickly define what a random forest is for people.

00:18:57.760 --> 00:19:02.000
Yeah, yeah. So random forest is basically an ensemble of decision trees. So you can,

00:19:02.000 --> 00:19:07.320
one of the most simple classifiers is a decision tree where it's just like a binary search tree where

00:19:07.320 --> 00:19:12.520
you say, okay, if this feature is higher than a certain value, go to the left node, otherwise go

00:19:12.520 --> 00:19:16.100
to the right node, and you go through the whole tree until you have a decision on what is the transport

00:19:16.100 --> 00:19:21.900
mode. Problem is that decision tree is not very powerful. It quickly overfits to your data. So what

00:19:21.900 --> 00:19:26.960
you can do is just build, you know, a thousand decision trees, all a little bit different, all on

00:19:26.960 --> 00:19:31.380
different subsets of your data and your features, and then you end up with a random forest. So it's kind of

00:19:31.380 --> 00:19:33.440
averaging out all those predictions.

00:19:33.440 --> 00:19:37.820
Right. So it kind of somewhat combats against the overfitting problem you would run into.

00:19:37.820 --> 00:19:38.920
Exactly. Exactly.

00:19:38.920 --> 00:19:39.280
Okay.

00:19:39.280 --> 00:19:43.600
The thing, of course, is by chopping up the sensor stream into pieces of several seconds,

00:19:43.600 --> 00:19:48.760
you completely lose the temporal dependencies. It could be that one piece is correctly classified

00:19:48.760 --> 00:19:53.960
as car, and the next piece maybe is incorrectly classified as walking. So you still want to do some

00:19:53.960 --> 00:19:57.380
temporal smoothing. So what we did back then is we fed that information, those segments,

00:19:57.380 --> 00:20:01.160
or actually the class probabilities, into a hidden Markov model. And a hidden Markov model,

00:20:01.160 --> 00:20:06.280
is able to learn short-term temporal dependencies and kind of smooth out the end results. So that

00:20:06.280 --> 00:20:11.540
was our first version of the transport classifier. And then over the past three years, we went through

00:20:11.540 --> 00:20:16.900
several iterations. So the Renov Forest was replaced by boosted trees, XGBoost, which is used a lot,

00:20:16.900 --> 00:20:22.680
for example, these days in the Kaggle competitions you read about. And now recently, we figured out that

00:20:22.680 --> 00:20:28.400
actually just using a convolutional neural net with one-dimensional convolutions, because of course you don't have

00:20:28.400 --> 00:20:34.240
images. It allows us to not only get an improved accuracy, but also come up with much smaller models

00:20:34.240 --> 00:20:37.620
that more easily feed in memory compared to this huge random forest.

00:20:37.620 --> 00:20:42.640
Okay. Yeah, that sounds really interesting. Thanks for sharing the evolution. I think that's pretty cool.

00:20:42.640 --> 00:20:54.200
And so you've got all these events. Okay. Users driving, users at work, users walking, users at restaurant, users walking, users at work, things like that.

00:20:54.580 --> 00:21:05.500
And then you try to create what you guys call moments, which is why are they doing this? Like, why are they walking? Oh, they're walking to lunch, things like that, right? So maybe talk about the analysis that you guys do there.

00:21:05.500 --> 00:21:21.620
Well, similarly, there was an evolution on that level too. So the main idea is that if you can predict what users will be doing next, you can use that indeed to explain why he's doing what he's doing. So if, for example, the user is predicted to go to work, then the fact that he's in a car means he's in a commute.

00:21:21.860 --> 00:21:26.540
While if he's predicted to go to a shop, the fact that he's in a car means he's probably in a shopping routine, right?

00:21:26.540 --> 00:21:33.960
So the first step is to teach a model to be able to predict your next event. And there we started out with a Markov Chain-like approach.

00:21:33.960 --> 00:21:47.540
Markov Chain basically just tries to learn transition probabilities. It just learns a distribution over, learns to predict the probability of your next event being event A, given your previous events.

00:21:47.540 --> 00:21:55.760
So it learns very short-term dependencies. We quickly saw, though, that those short-term dependencies were not able to model complex human behavior.

00:21:55.760 --> 00:22:03.280
So it worked in simple cases, like, especially if you include features like time and day, it worked in simple cases like going to work and going back home.

00:22:03.280 --> 00:22:09.300
But what if suddenly, you know, you wake up an hour later than normally and your whole day shifts a little bit,

00:22:09.680 --> 00:22:12.780
then suddenly the Markov Chain model completely kind of blacks out.

00:22:12.780 --> 00:22:17.520
Hey, everyone. This is Michael. Let me tell you about Datadog. They're sponsoring this episode.

00:22:17.520 --> 00:22:21.500
Performance and bottlenecks don't exist just in your application code.

00:22:21.500 --> 00:22:24.320
Modern applications are systems built upon systems.

00:22:24.320 --> 00:22:27.520
And Datadog lets you view the system as a whole.

00:22:27.780 --> 00:22:29.900
Let's say you have a Python web app running Flask.

00:22:29.900 --> 00:22:35.160
It's built upon MongoDB and hosted and scaled out on a set of Ubuntu servers running Nginx and Microwisgi.

00:22:35.160 --> 00:22:40.200
Add Datadog and you can view and monitor and even get alerts across all of these systems.

00:22:40.200 --> 00:22:44.140
Datadog has a great getting started tutorial that takes just a few moments.

00:22:44.140 --> 00:22:47.620
And if you complete it, they'll send you a sweet Datadog t-shirt for free.

00:22:47.620 --> 00:22:52.700
Don't hesitate. Visit talkpython.fm/Datadog and see what you've been missing.

00:22:52.700 --> 00:22:55.320
That's talkpython.fm/Datadog.

00:22:56.120 --> 00:22:59.260
What we use today there is, again, deep learning.

00:22:59.260 --> 00:23:00.440
We use an LSTM.

00:23:00.440 --> 00:23:03.600
What's an LSTM? Long, short-term memory?

00:23:03.600 --> 00:23:04.720
Yeah, exactly. Exactly.

00:23:04.720 --> 00:23:08.960
So an LSTM is a recurrent neural network that is able to...

00:23:08.960 --> 00:23:13.360
So when you think about deep learning, convolutional neural nets, for example,

00:23:13.360 --> 00:23:15.460
they are deep because you have a lot of layers.

00:23:15.460 --> 00:23:21.080
LSTMs, or recurrent neural networks, they are deep not because you have, per se, a lot of layers,

00:23:21.080 --> 00:23:24.320
but because they learn deep in the time dimension.

00:23:24.460 --> 00:23:25.980
They learn a lot of temporal dependencies.

00:23:25.980 --> 00:23:30.160
As opposed to a Markov chain where you only have a dependency on the previous event,

00:23:30.160 --> 00:23:35.660
an LSTM can depend on 20, 30, 50 events back in the past, right?

00:23:35.660 --> 00:23:40.720
It can say, okay, you know, 50 events ago, the user was in a car, and 20 events ago, he was at a shop.

00:23:40.720 --> 00:23:44.380
And given all that behavior, the user is probably going to do this next.

00:23:44.380 --> 00:23:49.880
That's cool, yeah. The longer you go without shopping, the more likely you are to shop.

00:23:49.880 --> 00:23:51.520
And things like that for groceries, right?

00:23:51.520 --> 00:23:52.420
Yeah, indeed, indeed.

00:23:52.420 --> 00:23:56.480
And the cool thing is also that the Markov chain model, by nature,

00:23:56.480 --> 00:24:00.800
had to be trained specifically for each user, separately, on the user's data.

00:24:00.800 --> 00:24:02.900
While the LSTM, we trained differently.

00:24:02.900 --> 00:24:08.880
We trained one global LSTM, feeding it thousands and thousands of different timelines of different users.

00:24:08.880 --> 00:24:13.180
The LSTM thereby kind of learned about general human behavior,

00:24:13.180 --> 00:24:19.540
and it learned what events from the past it has to pay attention to to predict something in the future.

00:24:20.060 --> 00:24:24.020
And then, for a specific user that was never seen in a training set before,

00:24:24.020 --> 00:24:26.580
we don't have to fine-tune or retrain the LSTM.

00:24:26.580 --> 00:24:30.660
We just feed the past three weeks of events into the LSTM,

00:24:30.660 --> 00:24:36.200
and the LSTM already learned during the training phase how it should use that pass to predict the next event.

00:24:36.200 --> 00:24:37.600
So the nice thing is that you don't...

00:24:37.600 --> 00:24:39.480
I mean, if you have a million users on your platform,

00:24:39.480 --> 00:24:43.540
you cannot have a million deep learning models, right, that you have to retrain every second.

00:24:43.540 --> 00:24:44.280
Yeah, of course.

00:24:44.280 --> 00:24:46.960
And how do you mark them, right?

00:24:47.020 --> 00:24:51.300
Like, all this stuff is happening without necessarily going,

00:24:51.300 --> 00:24:53.060
yes, I'm shopping now.

00:24:53.060 --> 00:24:54.160
Yes, I'm doing this.

00:24:54.160 --> 00:24:57.540
And then eventually it learns, okay, you're shopping, so I know what that means, right?

00:24:57.540 --> 00:24:59.540
This is sort of all inference-based.

00:24:59.540 --> 00:25:00.320
It's a combination.

00:25:00.320 --> 00:25:04.500
So on the event level, on the lowest level, we do have a lot of labeled data.

00:25:04.500 --> 00:25:08.940
So we spend a lot of time with customers or even, I mean,

00:25:08.940 --> 00:25:13.100
we paid a lot of students to go out on the road, take trains and trams and bus,

00:25:13.100 --> 00:25:15.320
label the data.

00:25:15.500 --> 00:25:19.540
And then internally we build some tools to clean up the data and make labels more accurate.

00:25:19.540 --> 00:25:21.260
So we do have labeled data on that level.

00:25:21.260 --> 00:25:24.000
Of course, when we go more to moments and segments,

00:25:24.000 --> 00:25:27.140
it becomes very difficult to get your hand on labeled data indeed.

00:25:27.140 --> 00:25:32.040
So there we focus a lot on semi-supervised learning and things like transfer learning.

00:25:32.040 --> 00:25:34.940
For example, using triplet loss function,

00:25:34.940 --> 00:25:38.260
we can learn this kind of high-dimensional feature space

00:25:38.260 --> 00:25:41.640
in which two users with similar behavior are close to each other

00:25:41.640 --> 00:25:44.500
and two users with different behavior are far from each other.

00:25:44.680 --> 00:25:49.160
And then in that feature space, you can build very simple classifiers using limited labeled data

00:25:49.160 --> 00:25:51.260
to actually come up with user segments.

00:25:51.260 --> 00:25:56.180
So that's kind of a transfer learning approach that allows us to cope with limited amounts of labeled data.

00:25:56.180 --> 00:25:56.580
Sure.

00:25:56.580 --> 00:25:57.180
Oh, okay.

00:25:57.180 --> 00:25:58.860
That sounds like it's working out really well.

00:25:58.860 --> 00:26:01.900
I've definitely been part of projects where it's like,

00:26:01.900 --> 00:26:05.380
all right, we're going to hire 100 students to do this for an hour.

00:26:05.380 --> 00:26:06.360
Yeah.

00:26:06.500 --> 00:26:09.360
And, you know, sometimes that's just what you got to do, right?

00:26:09.360 --> 00:26:09.900
Yeah, exactly.

00:26:09.900 --> 00:26:10.840
That's how we got started.

00:26:10.840 --> 00:26:12.960
Yep.

00:26:12.960 --> 00:26:14.580
But you can't pay a million students.

00:26:14.580 --> 00:26:15.840
Well, not much anyway.

00:26:15.840 --> 00:26:17.160
So, all right.

00:26:17.160 --> 00:26:18.280
So, that's moments.

00:26:18.280 --> 00:26:21.040
And you have your LSTM deep learning model there.

00:26:21.040 --> 00:26:26.340
And then the final, like, the real end goal is to, I guess moments is already probably an end goal.

00:26:26.340 --> 00:26:31.260
Like, they're at this store because also you want to classify people into groups, right?

00:26:31.260 --> 00:26:32.720
What type of driver are they?

00:26:32.720 --> 00:26:33.680
Do they work a lot?

00:26:33.680 --> 00:26:34.600
Are they parents?

00:26:34.600 --> 00:26:35.360
Are they teachers?

00:26:36.060 --> 00:26:37.160
Why are they at the school?

00:26:37.160 --> 00:26:37.940
Are they at the school?

00:26:37.940 --> 00:26:39.060
Because they're teaching there?

00:26:39.060 --> 00:26:39.740
Because they're a student?

00:26:39.740 --> 00:26:41.340
Because they're a parent dropping off a kid?

00:26:41.340 --> 00:26:42.220
Things like that, right?

00:26:42.220 --> 00:26:45.500
So, tell us about the algorithms and stuff and segments.

00:26:45.500 --> 00:26:47.480
That's a bit of what I was talking about earlier.

00:26:47.480 --> 00:26:48.280
So, this feature space.

00:26:48.280 --> 00:26:53.020
I think with segments is you, of course, some segments can be business rules, right?

00:26:53.020 --> 00:26:56.920
I mean, you're a workaholic if you work more than a specific number of hours, right?

00:26:56.920 --> 00:26:57.480
Right.

00:26:57.480 --> 00:26:59.840
But some segments, like, are you a parent, for example?

00:26:59.840 --> 00:27:00.980
That is less obvious.

00:27:00.980 --> 00:27:04.180
Being a parent definitely influences your behavior.

00:27:04.280 --> 00:27:06.920
I became a parent six months ago, and I'm a completely different person.

00:27:06.920 --> 00:27:10.920
But how do you capture that behavior?

00:27:10.920 --> 00:27:13.420
I mean, you cannot put that in a business rule, right?

00:27:13.420 --> 00:27:13.660
Yeah.

00:27:13.660 --> 00:27:17.000
So, tell us how you can determine someone is a parent, for example.

00:27:17.000 --> 00:27:17.700
That's pretty interesting.

00:27:17.700 --> 00:27:27.780
So, what we did there is we used deep learning to analyze, to compare, actually, the behavior of different people and to learn a feature representation,

00:27:27.780 --> 00:27:36.820
like a feature vector consisting of 50 floating point numbers, where each dimension, each floating point number, encodes a different characteristic of the person.

00:27:36.820 --> 00:27:39.680
Maybe the first number encodes your demographics.

00:27:39.680 --> 00:27:44.180
Maybe the second number encodes how many times you go to sport.

00:27:44.560 --> 00:27:52.180
The difference with traditional machine learning is that, in this case, we didn't manually define the meaning, semantic meaning of each of those 50 numbers.

00:27:52.180 --> 00:28:00.580
Instead, we let our neural network figure out on itself which dimensions it should learn to capture human behavior.

00:28:00.720 --> 00:28:08.740
And once you have that, you can actually take this timeline of events and code the whole event timeline into 50 floating points.

00:28:08.740 --> 00:28:18.500
And then you have a rather small feature space with only 50 features on which you can easily build, you know, even linear classifiers, very simple classifiers,

00:28:18.500 --> 00:28:23.280
using limited amounts of labeled data, people, for example, from which we know they are parents.

00:28:23.380 --> 00:28:30.740
And it generalizes extremely well because your feature space is so expressive and because the feature space was learned using unsupervised learning.

00:28:30.740 --> 00:28:34.580
So we can use all the data we gathered in the past to learn that representation.

00:28:34.580 --> 00:28:35.000
Okay.

00:28:35.000 --> 00:28:42.720
So you have these 50 classifiers or points that are sort of grouping people together.

00:28:42.720 --> 00:28:46.800
How did you determine, like, this grouping means it's a parent?

00:28:46.800 --> 00:28:51.100
Did you find some people you knew were parents and say, oh, they also have this feature that must mean they're a parent?

00:28:51.100 --> 00:28:53.680
Or how did you, like, assign values to that?

00:28:53.680 --> 00:28:54.280
Yeah, exactly.

00:28:54.280 --> 00:28:58.300
So it's kind of the feature space just allows us to do user similarity modeling.

00:28:58.300 --> 00:29:02.080
And then, indeed, we do still need labeled data, just not a whole lot of it.

00:29:02.080 --> 00:29:11.800
We can find, we can ask 100 users to install our demo app, walk around with the data for a few weeks, with a SDK for a few weeks, tell us whether or not they are a parent.

00:29:11.800 --> 00:29:18.360
And then in this feature space, if we look at those people, well, other parents will be very close to them.

00:29:18.360 --> 00:29:22.140
And that's how we can then build a classifier to detect parents.

00:29:22.140 --> 00:29:23.560
That's pretty awesome.

00:29:23.560 --> 00:29:26.840
Do you feel like there are pieces that are missing?

00:29:26.840 --> 00:29:31.120
Like, there's dimensions of human behavior that are not captured?

00:29:31.120 --> 00:29:31.740
Probably.

00:29:31.740 --> 00:29:33.240
Up till now, it works.

00:29:33.640 --> 00:29:40.440
It's also all very, very new to us, because we started out also here with mostly business rules on top of our event sequences.

00:29:40.440 --> 00:29:43.800
So most of the machine learning in the past was on the bottom layer, on the event layer.

00:29:43.800 --> 00:29:50.580
It's only since recent times that we're also doing this unsupervised and semi-supervised learning on the segments and the moments.

00:29:51.120 --> 00:30:00.960
But yeah, probably the difficulty, indeed, if you use representation learning, is that it's very difficult to control which dimensions the deep learning thinks are important to capture human behavior.

00:30:00.960 --> 00:30:05.360
So I can imagine that not everything is captured there.

00:30:05.360 --> 00:30:17.000
But in the end, you can easily solve that by fixing some of the bottom layers of the pre-trained network and then training it a little bit more on a smaller set of labeled data, fine-tuning the upper layers.

00:30:17.400 --> 00:30:20.360
And that way, it still is able to learn those things.

00:30:20.360 --> 00:30:20.700
Yeah.

00:30:20.700 --> 00:30:21.140
Okay.

00:30:21.140 --> 00:30:21.980
Very interesting.

00:30:21.980 --> 00:30:25.660
The dependency that you're talking about here sounds like it could be really tricky.

00:30:25.660 --> 00:30:32.740
Like, suppose you guys redesign your transportation mode detection.

00:30:32.740 --> 00:30:40.360
And it turns out, some of the time you thought people were walking, they're just in traffic, but really slow traffic, or something like this, right?

00:30:40.360 --> 00:30:46.480
Instead of every day taking a walk down I-5, the interstate highway, they're actually just driving in really bad traffic.

00:30:47.160 --> 00:30:51.340
And that probably has knock-on effects for moments, which has knock-on effects for segments.

00:30:51.340 --> 00:30:59.760
So how much of, like, if this training of networks takes weeks, potentially, how bad is it if, you know, you change the bottom layer?

00:30:59.760 --> 00:31:02.620
That's indeed a very actual problem we encountered.

00:31:02.620 --> 00:31:09.420
Especially now that we are more and more using, you know, representation learning to learn these feature spaces on the bottom layer.

00:31:09.540 --> 00:31:19.180
Indeed, if you retrain one of the models, the resulting feature space could have a completely different meaning, which means that all the consuming models that follow in the cascade would have to be retrained.

00:31:19.180 --> 00:31:20.560
And, of course, you don't want that.

00:31:20.560 --> 00:31:22.660
We solve this, I guess, in different ways.

00:31:22.720 --> 00:31:39.480
On the one hand, there is a decision you have to make between deploying a trained model as a microservice that is then consumed by other models in the cascade, versus actually just using the pre-trained model and fine-tuning it in a model that consumes that information.

00:31:39.900 --> 00:31:45.120
If you do it the first way, if you put it in a microservice, then, indeed, if you retrain the first model, you have to retrain the second.

00:31:45.120 --> 00:31:53.580
But if you do it in the other way, if you just combine both machine learning models eventually into one model, then, of course, you don't have this dependency.

00:31:53.580 --> 00:32:06.260
So in this sense, we actually try to just use pre-trained models and fine-tune them and embed them into the next model as much as possible, and only go to a microservice if there is good reason for it.

00:32:06.260 --> 00:32:15.880
If your model, for some reason, needs, for example, huge amounts of memories or a large amount of SQL queries to a database or something like that, then that is a good reason to actually put it in a microservice.

00:32:15.880 --> 00:32:17.940
That's one way we try to solve it.

00:32:17.940 --> 00:32:33.140
Another way, that's something we're still working on, we don't have it today, is that we're trying to create a model that basically learns a locally linear mapping from your previous feature space to the new feature space after retraining, or actually the other way around.

00:32:33.140 --> 00:32:44.860
So if you retrain a model, but you put a mapping layer after it, then that mapping layer can actually make sure that even if the model is retrained, the new feature space is mapped to the same semantics as the old feature space.

00:32:44.860 --> 00:32:45.200
I see.

00:32:45.200 --> 00:32:52.580
So the inputs to the next level model basically are literally transformed to look the same as they would have before.

00:32:52.580 --> 00:32:53.600
Exactly, exactly.

00:32:53.820 --> 00:32:54.020
Okay.

00:32:54.020 --> 00:32:58.980
Yeah, that sounds like a pretty interesting set of challenges and some good solutions.

00:32:58.980 --> 00:33:04.640
But yeah, definitely it seems like that's something that's always going to be a bit of a tension.

00:33:04.640 --> 00:33:05.360
Yeah, exactly.

00:33:05.360 --> 00:33:08.580
And we're also, I mean, we're continuously trying to figure it out ourselves.

00:33:08.580 --> 00:33:17.840
I mean, there is also, of course, versioning, because if you deploy a new model, there is at least some period in which you're going to have to run both the old model and the new model in parallel,

00:33:17.840 --> 00:33:20.760
because not all the consumers will be updated at the same time.

00:33:20.760 --> 00:33:27.720
It's getting complicated quickly, but luckily we have an awesome data engineering team there to help us solve all that.

00:33:27.720 --> 00:33:28.400
Yeah, that's cool.

00:33:28.500 --> 00:33:37.120
So one of the things I was wondering as I was looking through all this, like there's a lot of statistics and statistical inference and understanding these models.

00:33:37.120 --> 00:33:42.620
So somebody who works on your team as a data scientist, like what's their general skill set?

00:33:42.620 --> 00:33:48.260
Like how much programmer versus how much statistician versus some other skill I'm not thinking of?

00:33:48.260 --> 00:33:49.140
It's a bit mixed.

00:33:49.300 --> 00:33:52.840
So in general, we say that everyone at Sentience is a software engineer.

00:33:52.840 --> 00:34:01.000
So that means that every data scientist has to have good software engineering skills, not just some, you know, some MATLAB scripting experience or something.

00:34:01.000 --> 00:34:02.120
You have to be a software engineer.

00:34:02.120 --> 00:34:02.840
That's for sure.

00:34:02.840 --> 00:34:07.340
And then, of course, most people, we put a lot of emphasis on the machine learning background.

00:34:07.500 --> 00:34:16.600
So most people in the data science team, they either have a, you know, PhD in machine learning or computer vision or something, or they have a background in physics or mathematics.

00:34:16.600 --> 00:34:19.120
They need an analytical mindset, let's say.

00:34:19.120 --> 00:34:24.000
And then finally, there is the signal processing, which is kind of a specific field.

00:34:24.000 --> 00:34:30.780
So people coming from robotics or from speech recognition or also image processing often have a good signal processing background.

00:34:30.780 --> 00:34:35.300
Yeah, it's quite challenging to find people that combine all three of them.

00:34:35.480 --> 00:34:36.500
Yeah, I'm sure.

00:34:36.500 --> 00:34:39.980
Definitely sounds fun in terms of projects you get to work on.

00:34:39.980 --> 00:34:41.940
You guys don't build apps, right?

00:34:41.940 --> 00:34:48.960
You basically provide this SDK or this API to customers who themselves build apps, right?

00:34:48.960 --> 00:34:56.180
Well, actually, we just hired a designer, but ourselves, we're not the best in creating very fancy apps or something.

00:34:56.180 --> 00:34:58.320
We are really a tech company.

00:34:58.320 --> 00:35:03.280
And indeed, we have an API through which we expose all this information back to our customers.

00:35:03.640 --> 00:35:05.920
But the customer still needs a tech team.

00:35:05.920 --> 00:35:10.260
They need data scientists or developers to be able to do stuff with it.

00:35:11.260 --> 00:35:14.800
This portion of Talk Python is brought to you by GoCD.

00:35:14.800 --> 00:35:23.540
GoCD is an on-premise, open-source, continuous delivery tool to help you get better visibility into and control of your team's deployments.

00:35:23.540 --> 00:35:30.100
With GoCD's comprehensive pipeline modeling, you can model complex workflows for multiple teams with ease.

00:35:30.100 --> 00:35:35.720
And GoCD's value stream map lets you track changes from commit to deploy at a glance.

00:35:36.000 --> 00:35:39.840
Say goodbye to deployment panic and hello to consistent, predictable deliveries.

00:35:39.840 --> 00:35:44.240
We all know that continuous integration is super important to the code quality of your applications.

00:35:44.240 --> 00:35:47.860
Choose the open-source local CI server, GoCD.

00:35:47.860 --> 00:35:51.780
Learn more at talkpython.fm/gocd.

00:35:51.780 --> 00:35:54.580
That's talkpython.fm/gocd.

00:35:55.340 --> 00:36:00.060
All this sounds so cool and powerful and useful.

00:36:00.060 --> 00:36:07.220
But at the same time, it also feels like it could be a little bit invasive into people's lives and into their privacy.

00:36:07.220 --> 00:36:10.400
So what's the story around trying to strike that balance?

00:36:10.540 --> 00:36:11.620
That's a question we get a lot.

00:36:11.620 --> 00:36:14.520
And indeed, it is a balance we have to maintain.

00:36:14.520 --> 00:36:18.900
There is a lot of information you can extract from the sensor data.

00:36:18.900 --> 00:36:25.720
I mean, even your personality and your mood at something that's on our roadmap, something we're looking into, not something we per se have today completely.

00:36:25.720 --> 00:36:31.260
But your personality influences how you behave and how you behave influences the motion of your phone.

00:36:31.260 --> 00:36:33.800
So there is a lot of stuff you can do with it.

00:36:33.960 --> 00:36:37.520
And indeed, then privacy becomes an important question for us.

00:36:37.520 --> 00:36:42.880
On the one hand, there is a GDPR, so like the recent European privacy legislation.

00:36:42.880 --> 00:36:47.360
If you look at the GDPR, Sentience is a data processor, not a data owner.

00:36:47.360 --> 00:36:54.320
What actually means that compared to, let's say, Facebook or Google or something, we never claim that the data is ours.

00:36:54.320 --> 00:36:59.040
The data is still owned by the customer, which means we cannot combine the data with other data.

00:36:59.040 --> 00:37:00.300
We cannot sell the data.

00:37:00.300 --> 00:37:01.440
And the data is siloed.

00:37:01.440 --> 00:37:02.060
That's one thing.

00:37:02.060 --> 00:37:10.660
On the other hand, and probably much more important, is that we explicitly force our customers to ask consent to their users.

00:37:10.660 --> 00:37:17.180
So it cannot be that they use our SDK and put something in a small privacy statement, you know, hidden in the app or something.

00:37:17.180 --> 00:37:23.120
Our customers really need to be very upfront with their end users, tell them what kind of data they gather, why they do it.

00:37:23.120 --> 00:37:27.320
And as long as those customers provide enough value to the end users, that works.

00:37:27.320 --> 00:37:30.320
I mean, it won't work for, let's say, advertising solutions.

00:37:30.320 --> 00:37:34.560
Nobody wants to give consent to gather all this data to have better advertisements.

00:37:34.560 --> 00:37:37.640
But it does work for, let's say, health and lifestyle coaching.

00:37:37.640 --> 00:37:46.680
I mean, if we can help you live a healthier life, if we can contextualize your heart problems, or maybe even for insurance, if we can model your driving behavior.

00:37:46.680 --> 00:37:51.300
And by that, by doing so, reducing the amount of money you have to pay to an insurance company.

00:37:51.420 --> 00:37:55.300
Well, there is enough added value for most users to actually give that consent.

00:37:55.300 --> 00:37:56.200
Yeah, that's a good point.

00:37:56.200 --> 00:38:01.680
Yeah, I guess it's all about the trade-off for the benefit, right?

00:38:01.680 --> 00:38:08.980
Like you said, no one's going to go, I would love to see better banner ads in my, like, Candy Crush app or whatever.

00:38:08.980 --> 00:38:09.520
Yeah, indeed.

00:38:09.520 --> 00:38:17.320
The tagline of Sentence, or at least what our CEO often says is, we want to make sure that AI improves people's life.

00:38:17.320 --> 00:38:24.840
And it might sound a bit cheesy, but imagine indeed a world where you don't have to adapt to all your surroundings.

00:38:24.840 --> 00:38:28.520
But instead, you know, your phone knows who you are, knows what you feel, knows what you want.

00:38:28.720 --> 00:38:36.440
And the whole world adapts to you, not to spam you or manipulate you, but just to make your life easier and healthier and improve your quality.

00:38:36.440 --> 00:38:37.520
That's the promise, right?

00:38:37.520 --> 00:38:38.000
Exactly.

00:38:38.000 --> 00:38:41.760
So, you talked about being an SDK.

00:38:41.760 --> 00:38:45.560
Can you give us some examples of some of the apps that are using you guys as a service?

00:38:45.560 --> 00:38:46.080
Yeah, sure.

00:38:46.080 --> 00:38:48.340
There are different components, of course, in what we do.

00:38:48.340 --> 00:38:58.700
One of the components I quickly mentioned before is driving behavior, where we, in a detailed manner, model, you know, how aggressively you drive, how do you take your turns, what is your driver DNA?

00:38:58.700 --> 00:39:08.580
And that is currently being used by, I'm not allowed to name them, but let's say by the biggest ride-hailing company in the world to actually model the safety of their drivers.

00:39:08.580 --> 00:39:16.960
So, not the passengers, but the drivers themselves, so that they can coach them and make sure that the riders are safe when they take the gap.

00:39:16.960 --> 00:39:21.760
Another example is, for example, one of the biggest brand loyalty companies in the UK.

00:39:21.760 --> 00:39:30.180
So, they have a huge user base of users that installed their app because they want to get the latest coupons and that kind of stuff.

00:39:30.180 --> 00:39:40.340
And so, there they use our SDK to just personalize their communication with their users and to make sure that, you know, the user is not spammed with information that they don't care about.

00:39:40.340 --> 00:39:44.680
But instead, it's a very personalized communication and increases engagement.

00:39:44.680 --> 00:39:54.440
Right. So, maybe if you could tell them, like, this person is a parent versus this person is a workaholic, or if they're both, you know, that they might treat them differently, right?

00:39:54.440 --> 00:39:55.520
Yeah, exactly. Exactly.

00:39:55.520 --> 00:40:03.060
I mean, if you know that someone is sportive, you can propose more interesting stuff than if you know, okay, this person never sports and indeed is a workaholic or something like that.

00:40:03.060 --> 00:40:08.540
And I guess maybe the most interesting use cases, to me at least, are in health and insurance.

00:40:08.540 --> 00:40:14.440
So, in health, for example, we work with Samsung, who is also one of our main investors, on detection of heart arythemia.

00:40:14.440 --> 00:40:23.260
So, problems with, I mean, if you have heart fibrillations and you want to contextualize that, you want to know why it happens, when it happens, and you want to expose that to your doctor.

00:40:23.260 --> 00:40:33.920
So, your doctor can say, okay, we see that if you work late, and I see that you're a workaholic in general, and if you eat a lot of fast food that week, that is a time when you usually have your heart problems.

00:40:33.920 --> 00:40:35.280
So, that's one of the use cases.

00:40:35.280 --> 00:40:36.260
How does it know?

00:40:36.260 --> 00:40:44.160
Do you have to, like, do you have a different device that detects the arrhythmia and, like, flags it in time, and then you can overlay it on your timeline or something like that?

00:40:44.160 --> 00:40:44.960
Yeah, exactly. Exactly.

00:40:44.960 --> 00:40:45.400
Okay.

00:40:45.400 --> 00:40:48.320
Yeah, and you said you're also working with another company doing something similar?

00:40:48.480 --> 00:40:54.860
Yeah, so there is, in the health space, we work with some smaller companies also from Europe and Belgium and the Netherlands more specifically.

00:40:54.860 --> 00:40:57.000
So, there is FibriCheck, for example.

00:40:57.000 --> 00:41:08.220
FibriCheck, they have a mobile app where you can put your finger on your camera, and the app will use the camera and the flashlight to extract your heart rhythm from the blood flow to your fingertip.

00:41:08.220 --> 00:41:18.580
And so, there also, they use our SDK to contextualize that, to predict when you're probably going to have heart problems, why it's happening, and to expose this to a doctor.

00:41:18.580 --> 00:41:20.260
And then there is another example, Medup.

00:41:20.260 --> 00:41:22.220
Medup is a company in the Netherlands.

00:41:22.220 --> 00:41:25.760
They have an app for care adherence, medical adherence.

00:41:26.240 --> 00:41:30.860
So, a lot of people have to take a lot of pills, and a lot of people actually forget to take their pills.

00:41:30.860 --> 00:41:32.380
And that's a huge problem.

00:41:32.380 --> 00:41:37.080
So, what they did is they developed an app that reminds users to take their pills on time.

00:41:37.080 --> 00:41:45.740
But, of course, if you just get such a reminder, you know, an alarm on your phone right before you have to go to work, or maybe even when you're in the car,

00:41:45.740 --> 00:41:49.480
then you just snooze the alarm or dismiss it, and you forget about it altogether.

00:41:49.480 --> 00:41:56.820
So, they use our SDK, again, to tailor those alarms to make them contextual aware and remind users at the right time.

00:41:56.820 --> 00:41:57.060
Right.

00:41:57.060 --> 00:42:00.300
Like, if you're driving, it makes no sense to remind you, so wait until you get to work.

00:42:00.300 --> 00:42:00.720
Exactly.

00:42:00.720 --> 00:42:03.380
Or wait until you return home if it knows you're coming home or something like that.

00:42:03.380 --> 00:42:03.800
Yeah, indeed.

00:42:03.800 --> 00:42:10.160
Or if we predict you will probably be leaving for work in 10 minutes, then this is the time to remind you, and don't wait 10 minutes.

00:42:10.160 --> 00:42:11.140
Yeah, that'd be even better.

00:42:11.140 --> 00:42:12.020
Cool.

00:42:12.020 --> 00:42:13.740
So, those sound all really interesting.

00:42:13.740 --> 00:42:19.460
We talked a lot about your architecture already, actually, but there's a few things that we haven't touched on that I think are worth covering.

00:42:19.460 --> 00:42:23.460
One of the things you guys use is something called DevPy.

00:42:23.460 --> 00:42:26.920
It's sort of an alternative local PyPI.

00:42:26.920 --> 00:42:29.560
Tell people what DevPy is, and how is it helping you guys?

00:42:29.560 --> 00:42:37.520
The problem we had with Python and PyPy as a package server is that you quickly end up in kind of a dependency hell.

00:42:37.700 --> 00:42:54.620
You develop your project, put it in a repo, you have a setup.py to easily install it, and as a requirement, you list, let's say, NumPy version X, but also you list package Y as a dependency, but package Y actually depends on NumPy version Z.

00:42:54.760 --> 00:43:01.040
So, you have this whole conflicting set of dependencies which quickly becomes very difficult to manage.

00:43:01.400 --> 00:43:14.620
And how we actually did versioning of our own packages, so our repositories, is in the past we specified a version attribute in the setup.py and used git tags on BitBucket, so on our git repositories.

00:43:15.140 --> 00:43:24.580
And those tags also contain a version number, and that kind of allowed us to pull the correct version and try to get everything installed as it should be.

00:43:24.580 --> 00:43:27.840
But then you have to make sure that you maintain a setup.py.

00:43:27.840 --> 00:43:30.300
Don't forget to increase the version number there.

00:43:30.300 --> 00:43:33.480
Make sure the tags are in sync, and it really becomes messy quickly.

00:43:33.480 --> 00:43:36.460
So, how we solve this is, indeed, we use DevPy these days.

00:43:36.520 --> 00:43:39.520
We have our own package server, our Jenkins server.

00:43:39.520 --> 00:43:41.300
So, Jenkins basically is our build server.

00:43:41.300 --> 00:43:44.740
Everything gets built into packages automatically there.

00:43:44.740 --> 00:43:53.300
Jenkins builds wheels from our internal repositories, builds those wheels both for Mac, for the developers, and for Linux, for actual production.

00:43:53.300 --> 00:43:55.120
And it stores that with a version number.

00:43:55.120 --> 00:44:00.360
And then if we do pip install something, then first our DevPy is consulted.

00:44:00.360 --> 00:44:04.300
It fetches the correct version, the package with the correct version and correct dependencies.

00:44:04.780 --> 00:44:08.260
And only if it cannot find it there, it goes further to PyPy.

00:44:08.260 --> 00:44:11.140
Yeah, that's really cool to be able to control it like that.

00:44:11.140 --> 00:44:18.360
Do you distribute your own packages for use on other projects within your own DevPy?

00:44:18.360 --> 00:44:24.300
Everything we build is contained in like a functional repo, let's say, with an API.

00:44:24.300 --> 00:44:31.440
And then we always have a microservice wrapper repo that just uses that functional repo as a dependency.

00:44:31.820 --> 00:44:39.040
So, the functional part is always built by Jenkins, put into DevPy, and can then be used by different other projects as a dependency.

00:44:39.040 --> 00:44:39.580
Yeah, okay.

00:44:39.580 --> 00:44:42.360
That sounds like a really good setup you guys have going there.

00:44:42.360 --> 00:44:48.120
Another thing that you talked about is pragmatic use of deep learning.

00:44:48.460 --> 00:44:51.660
Tell us what do you mean by pragmatic use.

00:44:51.660 --> 00:44:53.080
What are some of your recommendations?

00:44:53.080 --> 00:44:54.240
Deep learning is cool.

00:44:54.240 --> 00:44:59.460
And especially if we hire new people and they hear that we do deep learning, we use it a lot actually.

00:44:59.460 --> 00:45:03.180
They are eager to also start using it for the problems they start working on.

00:45:03.180 --> 00:45:08.680
But of course, we have to be pragmatic indeed in the sense that a lot of problems just don't need deep learning.

00:45:09.000 --> 00:45:17.340
For example, if I talked earlier about detecting what is your home location and what is your work location, you can solve that without deep learning.

00:45:17.340 --> 00:45:24.820
You just do some feature engineering, gather a little training data, and train a linear support vector machine on top of it or something.

00:45:24.820 --> 00:45:31.060
It's important, I think, to use deep learning if it really solves your problem, if it makes your product better.

00:45:31.060 --> 00:45:32.900
But indeed, don't just follow the hype.

00:45:32.900 --> 00:45:34.900
Don't just do it because it's a buzzword.

00:45:34.900 --> 00:45:35.380
Yeah, exactly.

00:45:35.380 --> 00:45:37.240
More VC money because of it.

00:45:37.680 --> 00:45:38.080
Indeed.

00:45:38.080 --> 00:45:39.800
Yeah, yeah, that's really cool.

00:45:39.800 --> 00:45:47.600
Like sometimes just standard algorithms and, you know, if cases effectively, right, are all you really need sometimes.

00:45:47.600 --> 00:45:59.360
It is true that these days with VCs and even for customers, for some reason, it sometimes almost sounds embarrassing if you have to tell them that for a part of your product, you use traditional machine learning.

00:45:59.360 --> 00:46:00.880
It's like, why don't you use deep learning?

00:46:00.880 --> 00:46:02.940
But it's a matter of cost.

00:46:02.940 --> 00:46:05.720
It's a matter of accuracy and also maintainability.

00:46:05.880 --> 00:46:11.040
I mean, if you have a very simple  actually, I think it goes even further than the simplest example I gave.

00:46:11.040 --> 00:46:14.940
If you can solve a problem by a simple business rule, then that's the way you should go.

00:46:14.940 --> 00:46:15.260
Right.

00:46:15.260 --> 00:46:15.660
Absolutely.

00:46:16.280 --> 00:46:28.140
Let's take just a moment and, like, take a step sort of up this higher level, not anything that you guys are doing in general, not referring to your product or your mission, but just in general.

00:46:28.140 --> 00:46:38.020
Like there's some people like Elon Musk, who I'm a big admirer of in general and others saying, like, we should be really worried about AI and machine learning.

00:46:38.020 --> 00:46:40.420
And other people saying, no, this will make things lots better.

00:46:40.420 --> 00:46:47.440
And you've given us some definite examples where it is going to be better for people, right, with, like, health, for example.

00:46:47.880 --> 00:46:49.360
But where do you land in this debate?

00:46:49.360 --> 00:46:50.800
And do we live in a simulation?

00:46:51.160 --> 00:46:58.920
First, the extreme example or the extreme case that you sometimes read about, about, you know, AI taking over the world and stuff like that.

00:46:58.920 --> 00:47:00.460
Well, an interesting quote there.

00:47:00.460 --> 00:47:07.040
I think it's from Andrew NG, so one of the big deep learning guys who used to be head of AI at Baidu.

00:47:07.100 --> 00:47:09.040
And I think today he's still head of AI at Stanford.

00:47:09.040 --> 00:47:16.500
He said at some point, you know, that the fact or talking about AI taking over the world is a little bit like talking about overpopulation on Mars.

00:47:16.500 --> 00:47:18.060
It might happen at some point.

00:47:18.060 --> 00:47:18.720
It probably will.

00:47:18.720 --> 00:47:21.980
But there is still no clear path to it, right?

00:47:21.980 --> 00:47:24.660
So that's one thing.

00:47:24.660 --> 00:47:32.480
Of course, it is true that AI or machine learning, which I like more as a term, actually, is becoming very powerful.

00:47:32.480 --> 00:47:36.840
And in that sense, like any powerful tool, it can be used for the good and the bad.

00:47:36.980 --> 00:47:40.000
So I do agree that we need politics.

00:47:40.000 --> 00:47:42.420
We need legislation to be ready for this.

00:47:42.420 --> 00:47:54.500
We need to make sure that governments are limited in what they can do, you know, that they cannot force you to install an app that tracks your every movement so that they can then control your future or something like that.

00:47:54.500 --> 00:48:02.920
So I do agree with Elon Musk on that point that it's time for government officials to take this serious and to work on the legal aspect there.

00:48:02.920 --> 00:48:03.240
Sure.

00:48:03.240 --> 00:48:04.160
I totally agree.

00:48:04.160 --> 00:48:06.280
And there's other interesting knock-ons.

00:48:06.860 --> 00:48:08.800
I think the EU is working on this.

00:48:08.800 --> 00:48:20.300
You know, when we get to things like driverless cars, if the driverless car is in an accident and it turns out the driverless car was at fault, who is responsible and how do you address that?

00:48:20.340 --> 00:48:34.220
And if it's pure, totally unsupervised learning that made the car drive, like how do you know why it crashed?

00:48:34.220 --> 00:48:36.160
We're going to be able to do that.

00:48:36.160 --> 00:48:56.960
So first, a whole transformation in the mobility sector, in the insurance sector has to happen so that cars are actually seen as a service where you insure a service.

00:48:57.160 --> 00:48:58.160
It's a different mindset.

00:48:58.160 --> 00:49:06.380
Yeah, and I think we're going to have to get used to pushing the benefits in an aggregated way instead of a specific individual's responsibility way.

00:49:06.380 --> 00:49:11.220
For example, yeah, the self-driver car did something really bad and it crashed into some people on the sidewalk.

00:49:11.600 --> 00:49:17.160
But if you look at it as a whole, half a million fewer people were killed in car accidents this year.

00:49:17.160 --> 00:49:20.940
So this is a horrible news story and we're really, you know, it's really bad.

00:49:20.940 --> 00:49:24.520
But taken as a whole, self-driving cars are doing better for people.

00:49:24.520 --> 00:49:26.740
That's like a theory I'm imagining, right?

00:49:26.740 --> 00:49:29.900
But I can see the world struggling with those sort of ethical trade-offs.

00:49:30.040 --> 00:49:30.400
Yeah, indeed.

00:49:30.400 --> 00:49:44.820
You know, it's a little bit, I know maybe it's not a very good comparison, but if you think about the Industrial Revolution, there was a lot of people that were so scared about all the millions of jobs that would be lost if cars would not be made by hand anymore, but if machines would be used, you know.

00:49:44.820 --> 00:49:51.580
But in the end, when we look back, I do think that most people agree that the Industrial Revolution made our life healthier.

00:49:51.580 --> 00:49:54.360
We live longer, made it easier, we're happier.

00:49:54.360 --> 00:49:57.240
And the same thing is going to happen with the AI revolution.

00:49:57.380 --> 00:50:00.240
Yeah, I think that in the long term that that's definitely true.

00:50:00.240 --> 00:50:03.520
Like I definitely wouldn't want to live pre-Industrial Revolution myself.

00:50:03.520 --> 00:50:05.560
I wouldn't trade my spot in it now.

00:50:05.560 --> 00:50:06.960
All right.

00:50:06.960 --> 00:50:10.860
Well, Vincent, I think we're going to have to probably leave it there for our topics.

00:50:10.860 --> 00:50:15.980
But that was a super interesting look inside what you guys are doing with machine learning and things like that.

00:50:15.980 --> 00:50:19.420
So let's get to the two questions.

00:50:19.420 --> 00:50:21.960
First one, favorite Python editor.

00:50:21.960 --> 00:50:23.900
What do you open up if you're going to write some Python code?

00:50:23.900 --> 00:50:25.160
By charm, for sure.

00:50:25.620 --> 00:50:27.620
I love the JetBrains product in general.

00:50:27.620 --> 00:50:31.720
You know, DataGrip for database stuff, IntelliJ for Java, PyTron for Python, yeah.

00:50:31.720 --> 00:50:32.180
Yeah, awesome.

00:50:32.180 --> 00:50:33.160
Yeah, me as well.

00:50:33.160 --> 00:50:33.660
That's my favorite.

00:50:33.660 --> 00:50:34.600
All right.

00:50:34.600 --> 00:50:36.620
And notable PyPI package?

00:50:36.620 --> 00:50:38.220
I've been thinking about this for a long time.

00:50:38.220 --> 00:50:48.380
I think it would be Python Flame Graph just because it's a very cool way to do memory and performance profiling, create Flame Graph, see which methods in your code are the bottlenecks, and optimize them.

00:50:48.380 --> 00:50:49.940
Yeah, I looked at that just a little bit.

00:50:49.940 --> 00:50:55.460
And it looks like a very powerful way to quickly visualize where your performance problems are.

00:50:55.460 --> 00:50:56.040
Yeah, exactly.

00:50:56.040 --> 00:50:56.380
Exactly.

00:50:56.380 --> 00:51:00.900
And to actually dig deeper into the stack of method calls and figure out what's happening.

00:51:00.900 --> 00:51:01.460
Yeah, that's cool.

00:51:01.460 --> 00:51:05.880
So I'll put a link to the GitHub repo for Python Flame Graph, which has a bunch of nice pictures.

00:51:05.880 --> 00:51:06.240
Awesome.

00:51:06.240 --> 00:51:06.600
Awesome.

00:51:06.600 --> 00:51:07.320
Yeah, yeah.

00:51:07.560 --> 00:51:09.580
So, all right, final call to action.

00:51:09.580 --> 00:51:11.840
People are excited about deep learning.

00:51:11.840 --> 00:51:13.100
They're excited about what you guys are doing.

00:51:13.100 --> 00:51:14.520
What do they do to get started?

00:51:14.520 --> 00:51:15.280
We're expanding.

00:51:15.280 --> 00:51:16.320
We're continuously expanding.

00:51:16.320 --> 00:51:19.280
This year, or coming year, we should grow from 50 to 80 people.

00:51:19.280 --> 00:51:23.480
So we're always looking for passionate Python developers, machine learning guys.

00:51:23.480 --> 00:51:26.760
Can they just reach out to you, like, on Twitter or something like that if they want to get more information?

00:51:26.760 --> 00:51:27.640
Or how do they find out?

00:51:27.640 --> 00:51:28.380
Yeah, yeah, definitely.

00:51:28.380 --> 00:51:33.380
Just, you know, ping me on Twitter or LinkedIn or go through our website where there is a more official channel.

00:51:34.220 --> 00:51:38.220
Maybe you can refer to podcast so we have an idea where you're coming from.

00:51:38.220 --> 00:51:40.580
Don't focus too much on the machine learning part either.

00:51:40.580 --> 00:51:45.440
If you're very good at Python or very good at machine learning or signal processing, we should talk.

00:51:45.440 --> 00:51:46.280
Okay, awesome.

00:51:46.280 --> 00:51:47.940
And then you guys have an app.

00:51:47.940 --> 00:51:49.880
Even though you said you don't build apps, you have an app.

00:51:49.880 --> 00:51:52.380
What's the story with this app?

00:51:52.380 --> 00:51:55.140
Yeah, it's a demo app because our product is quite technical.

00:51:55.140 --> 00:51:58.260
And so, of course, customers ask, like, okay, how does it look like?

00:51:58.260 --> 00:51:59.060
What can I do with it?

00:51:59.060 --> 00:52:00.920
So, indeed, we built a small demo app.

00:52:00.920 --> 00:52:01.860
It's called Journeys.

00:52:01.860 --> 00:52:03.800
You can find it on our website or on the App Store.

00:52:03.800 --> 00:52:04.720
Our Play Store.

00:52:04.720 --> 00:52:08.840
And Journeys, basically, when you install it, after a while, it will learn about your behavior.

00:52:08.840 --> 00:52:12.920
After one week or two weeks, you will see pop up a whole set of segments that we assign to you.

00:52:12.920 --> 00:52:14.860
Your moments, your home and work detections.

00:52:14.860 --> 00:52:16.020
So, yeah, check it out.

00:52:16.020 --> 00:52:16.460
Download it.

00:52:16.460 --> 00:52:17.560
It's pretty cool.

00:52:17.560 --> 00:52:19.140
And there is also a way to give feedback.

00:52:19.140 --> 00:52:24.000
So, if something is wrong and you decide to give feedback, well, that helps us to retrain our models.

00:52:24.000 --> 00:52:24.600
Oh, beautiful.

00:52:24.600 --> 00:52:25.100
All right.

00:52:25.100 --> 00:52:26.820
Well, thanks for sharing your story and what you guys have to.

00:52:26.820 --> 00:52:27.620
It was great to chat with you.

00:52:27.620 --> 00:52:28.300
Thanks a lot, Michael.

00:52:28.800 --> 00:52:32.060
This has been another episode of Talk Python to Me.

00:52:32.060 --> 00:52:34.120
Our guest has been Vincent Spurt.

00:52:34.120 --> 00:52:37.620
And this episode has been brought to you by Datadog and GoCD.

00:52:37.620 --> 00:52:41.720
Datadog gives you visibility into the whole system running your code.

00:52:41.720 --> 00:52:46.060
Visit talkpython.fm/datadog and see what you've been missing.

00:52:46.060 --> 00:52:48.240
Don't even throw in a free t-shirt for doing the tutorial.

00:52:49.080 --> 00:52:52.880
GoCD is the on-premise, open-source, continuous delivery server.

00:52:52.880 --> 00:52:57.040
Want to improve your deployment workflow but keep your code and builds in-house?

00:52:57.040 --> 00:53:03.380
Check out GoCD at talkpython.fm/gocd and take control over your process.

00:53:03.380 --> 00:53:05.780
Are you or a colleague trying to learn Python?

00:53:05.780 --> 00:53:10.440
Have you tried books and videos that just left you bored by covering topics point by point?

00:53:10.540 --> 00:53:16.460
Well, check out my online course, Python Jumpstart, by building 10 apps at talkpython.fm/course

00:53:16.460 --> 00:53:19.040
to experience a more engaging way to learn Python.

00:53:19.040 --> 00:53:23.860
And if you're looking for something a little more advanced, try my Write Pythonic Code course

00:53:23.860 --> 00:53:26.400
at talkpython.fm/pythonic.

00:53:26.400 --> 00:53:29.120
Be sure to subscribe to the show.

00:53:29.120 --> 00:53:31.340
Open your favorite podcatcher and search for Python.

00:53:31.340 --> 00:53:32.580
We should be right at the top.

00:53:32.580 --> 00:53:37.980
You can also find the iTunes feed at /itunes, Google Play feed at /play,

00:53:37.980 --> 00:53:41.900
and direct RSS feed at /rss on talkpython.fm.

00:53:41.900 --> 00:53:43.760
This is your host, Michael Kennedy.

00:53:43.760 --> 00:53:45.140
Thanks so much for listening.

00:53:45.140 --> 00:53:46.200
I really appreciate it.

00:53:46.200 --> 00:53:48.140
Now get out there and write some Python code.

00:53:48.140 --> 00:54:08.600
I'll see you next time.

