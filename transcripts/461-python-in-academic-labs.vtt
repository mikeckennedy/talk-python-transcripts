WEBVTT

00:00:00.001 --> 00:00:01.960
Do you use Python in an academic setting?

00:00:01.960 --> 00:00:05.160
Maybe you run a research lab or teach courses using Python.

00:00:05.160 --> 00:00:08.000
Maybe you're even a student using Python.

00:00:08.000 --> 00:00:11.400
Whichever it is, you'll find a ton of great advice in this episode.

00:00:11.400 --> 00:00:16.780
I talked with Keelan Cooper about how he's using Python in his neuroscience lab at the

00:00:16.780 --> 00:00:18.300
University of California, Irvine.

00:00:18.300 --> 00:00:22.960
And Keelan wanted me to let you know that if any developers who are not themselves scientists

00:00:22.960 --> 00:00:27.480
are interested in learning more about scientific research and ways you might be able to contribute,

00:00:27.480 --> 00:00:29.600
please don't hesitate to reach out to him.

00:00:30.160 --> 00:00:35.440
This is Talk Python to Me, episode 461, recorded March 14th, 2024.

00:00:35.440 --> 00:00:37.700
Are you ready for your host?

00:00:37.700 --> 00:00:38.560
There he is.

00:00:38.560 --> 00:00:42.000
You're listening to Michael Kennedy on Talk Python to Me.

00:00:42.000 --> 00:00:45.680
Live from Portland, Oregon, and this segment was made with Python.

00:00:45.680 --> 00:00:53.560
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:53.560 --> 00:00:55.300
This is your host, Michael Kennedy.

00:00:55.300 --> 00:00:59.420
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using

00:00:59.420 --> 00:01:02.800
at Talk Python, both on fosstodon.org.

00:01:02.800 --> 00:01:07.880
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:01:08.100 --> 00:01:11.680
We've started streaming most of our episodes live on YouTube.

00:01:11.680 --> 00:01:17.380
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming

00:01:17.380 --> 00:01:19.200
shows and be part of that episode.

00:01:19.480 --> 00:01:22.020
This episode is sponsored by Neo4j.

00:01:22.020 --> 00:01:27.940
It's time to stop asking relational databases to do more than they were made for and simplify

00:01:27.940 --> 00:01:30.180
complex data models with graphs.

00:01:30.180 --> 00:01:37.000
Check out the sample FastAPI project and see what Neo4j, a native graph database, can do for you.

00:01:37.000 --> 00:01:41.420
Find out more at talkpython.fm/Neo4j.

00:01:41.820 --> 00:01:45.580
And it's brought to you by Posit Connect from the makers of Shiny.

00:01:45.580 --> 00:01:50.100
Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:50.100 --> 00:01:56.780
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:56.780 --> 00:01:59.160
Posit Connect supports all of them.

00:01:59.160 --> 00:02:04.840
Try Posit Connect for free by going to talkpython.fm/Posit, P-O-S-I-T.

00:02:04.840 --> 00:02:06.860
Hello, how are you?

00:02:06.860 --> 00:02:07.720
I'm doing well.

00:02:07.720 --> 00:02:12.460
So awesome to have you here on Talk Python and talking academics.

00:02:12.460 --> 00:02:18.440
I didn't tell you before we hit record, but I spent a long time at universities and I just love them.

00:02:18.440 --> 00:02:23.020
They're such cool places and it's going to be really fun to get a look inside how Python's

00:02:23.020 --> 00:02:23.900
being used there.

00:02:23.900 --> 00:02:25.800
Yeah, well, thank you so much for having me.

00:02:25.800 --> 00:02:27.920
And yes, I too love universities.

00:02:27.920 --> 00:02:33.460
It's kind of like all the coolest parts of humanity just kind of intermixing in one place.

00:02:33.460 --> 00:02:37.060
So yeah, I'd love to kind of peel back the curtain on how things are going by.

00:02:37.060 --> 00:02:37.640
Yeah, yeah.

00:02:37.640 --> 00:02:43.700
Well, we're talking about how you and your colleagues use Python and data science inside of your

00:02:43.700 --> 00:02:45.580
neurology research lab.

00:02:45.580 --> 00:02:49.140
But before we dive into that, let's just get a bit of background on yourself.

00:02:49.140 --> 00:02:49.840
Who are you?

00:02:49.840 --> 00:02:51.180
How do you get into Python?

00:02:51.180 --> 00:02:52.060
All those things.

00:02:52.060 --> 00:02:52.940
So I'm Keelan Cooper.

00:02:52.940 --> 00:02:56.580
I'm a neuroscientist at the University of California, Irvine.

00:02:56.580 --> 00:03:00.880
So Southern California, 15 minutes from the beach and an hour from the mountains.

00:03:00.880 --> 00:03:04.340
But I'm originally from the middle of nowhere, Indiana.

00:03:04.340 --> 00:03:08.900
And I started playing with computers and code when I was young.

00:03:08.900 --> 00:03:14.020
So like middle school ish, just ripping apart computers and seeing what was in them and then

00:03:14.020 --> 00:03:17.880
trying to put them back together and feeling bad when they didn't work right after.

00:03:18.260 --> 00:03:22.080
And then the typical, you know, tweaking the software when you don't like what it does

00:03:22.080 --> 00:03:23.000
until you make it work.

00:03:23.000 --> 00:03:28.720
And then probably my senior year of high school is when I started teaching myself Python.

00:03:28.720 --> 00:03:32.060
And it was because we had to do some for some government class, actually.

00:03:32.060 --> 00:03:32.600
Oh, wow.

00:03:32.600 --> 00:03:32.900
Okay.

00:03:33.060 --> 00:03:34.020
And we had to learn.

00:03:34.020 --> 00:03:35.920
We were learning about the stock market.

00:03:35.920 --> 00:03:40.920
And every day you'd have to spend like 15 minutes going to like some stock website and like filling

00:03:40.920 --> 00:03:42.120
out your fake stocks.

00:03:42.120 --> 00:03:46.820
And so I wrote a really small Python script that would just pull the data from the website

00:03:46.820 --> 00:03:49.240
and populate like an Excel spreadsheet.

00:03:49.240 --> 00:03:53.480
And so every day the kids in the class were just like going through and like spending 15,

00:03:53.480 --> 00:03:55.200
20 minutes by handwriting it down.

00:03:55.200 --> 00:03:56.180
And I would just sit there.

00:03:56.180 --> 00:03:56.880
That's awesome.

00:03:56.880 --> 00:04:00.860
And so that was kind of the first time I was like, wow, this whole automation thing is pretty

00:04:00.860 --> 00:04:02.260
sweet from there.

00:04:02.260 --> 00:04:04.920
I thought I just kind of caught the bug pretty early.

00:04:04.920 --> 00:04:06.800
Python was definitely the way to go.

00:04:06.800 --> 00:04:09.080
Was Python your first programming language?

00:04:09.080 --> 00:04:14.600
First programming language was the Windows registry and trying to undo all of the mistakes

00:04:14.600 --> 00:04:15.880
of the operating system.

00:04:15.880 --> 00:04:20.140
It's been a while since I've been in the Windows registry, but good old reg edit.

00:04:20.140 --> 00:04:21.580
I switched to Linux pretty quick.

00:04:21.580 --> 00:04:23.020
Linux and Unix.

00:04:23.020 --> 00:04:23.780
Are you still on Linux?

00:04:23.780 --> 00:04:24.320
Mostly.

00:04:24.320 --> 00:04:25.560
My desktops are all Linux.

00:04:25.560 --> 00:04:27.240
My servers are obviously all Linux.

00:04:27.240 --> 00:04:32.460
I like Mac for a laptop just because, you know, Linux has this thing where you tinker

00:04:32.460 --> 00:04:32.980
with it.

00:04:32.980 --> 00:04:37.700
And so then any small task you want to do, you end up like rewriting some deep script in

00:04:37.700 --> 00:04:38.540
the operating system.

00:04:38.540 --> 00:04:41.640
And like two hours later, you're like, what was that small thing I was trying to do again?

00:04:41.640 --> 00:04:42.280
Yeah, exactly.

00:04:42.280 --> 00:04:43.620
I got distracted.

00:04:43.620 --> 00:04:45.940
I was rewriting something in there and off we go.

00:04:45.940 --> 00:04:46.280
Yeah.

00:04:46.280 --> 00:04:46.720
Yeah.

00:04:46.720 --> 00:04:51.640
So Macs are nice because you still have all the same Unix like properties that are great,

00:04:51.640 --> 00:04:53.540
but you pay a price for reliability.

00:04:53.880 --> 00:04:58.040
You just sell a bit of your soul out, but boy, is that UI nice and those little menu

00:04:58.040 --> 00:04:59.240
bar apps are handy.

00:04:59.240 --> 00:05:00.540
You know, I was...

00:05:00.540 --> 00:05:00.660
It's a little.

00:05:00.660 --> 00:05:02.060
That's right.

00:05:02.060 --> 00:05:02.940
I was...

00:05:02.940 --> 00:05:10.960
I've been playing with running Ubuntu on my Mac M2 Pro, which it runs great, but it's

00:05:10.960 --> 00:05:13.920
an ARM version of Mac, of Linux rather.

00:05:13.920 --> 00:05:14.860
Well, both really.

00:05:14.860 --> 00:05:21.180
But boy, is there a limited supply of applications for an ARM Linux distribution.

00:05:21.180 --> 00:05:21.640
Linux.

00:05:22.320 --> 00:05:25.400
Let me tell you, they're like, just download the Debian package.

00:05:25.400 --> 00:05:27.100
I imagine that'll change pretty quick though.

00:05:27.100 --> 00:05:27.320
Yeah.

00:05:27.320 --> 00:05:28.760
They're like, just download the Debian package.

00:05:28.760 --> 00:05:29.640
You just install it.

00:05:29.640 --> 00:05:30.800
Like wrong platform.

00:05:30.800 --> 00:05:33.200
Like again, over half.

00:05:33.200 --> 00:05:37.420
But yeah, I think it will change as I think ARM's going to start to take over Windows a little

00:05:37.420 --> 00:05:38.220
bit as well.

00:05:38.220 --> 00:05:41.240
And obviously the Mac world is basically transitioning.

00:05:41.240 --> 00:05:43.080
So anyone who has a Mac.

00:05:43.080 --> 00:05:43.360
Yeah.

00:05:43.480 --> 00:05:48.640
I think it's Qualcomm that just kind of started hinting that they were going to try and really

00:05:48.640 --> 00:05:52.720
heavily compete with the M line of processors and have some pretty good specs.

00:05:52.720 --> 00:05:53.760
So it'll be good.

00:05:53.760 --> 00:05:56.440
I have an M3 and it's pretty nice.

00:05:56.600 --> 00:05:57.420
It is really nice.

00:05:57.420 --> 00:06:02.980
Like I said, I like to run more stuff on it, but it's still kind of Intel or x86 stuff

00:06:02.980 --> 00:06:04.540
for Linux and Windows.

00:06:04.540 --> 00:06:07.920
So it's a little hard to work with that, but still super fun.

00:06:07.920 --> 00:06:11.320
That's a long way to say it's a very long time since I've been in a reg edit.

00:06:11.320 --> 00:06:16.520
Personally, it sounds like you as well being not naming Windows too much.

00:06:16.600 --> 00:06:20.760
I'm so bad at Windows now, like when I'm helping people with Python or something else and they

00:06:20.760 --> 00:06:25.320
show me their computer, there's always that like 10 minute learning curve of like, okay,

00:06:25.320 --> 00:06:29.100
how do I, how do I do anything basic on this machine?

00:06:29.100 --> 00:06:33.380
Or even like the keyboard shortcuts you get so accustomed to when people don't have any of

00:06:33.380 --> 00:06:37.460
those little things that you're just like, how do I, how do I select everything?

00:06:37.460 --> 00:06:38.160
And that is it.

00:06:38.160 --> 00:06:41.640
Like I did professional software development on Windows for a long, long time.

00:06:41.640 --> 00:06:43.180
I even wrote a bunch of Windows apps.

00:06:43.180 --> 00:06:44.060
It was, it was great.

00:06:44.400 --> 00:06:49.080
But going back and forth too quickly, that or Linux, like just the hotkeys, I just get

00:06:49.080 --> 00:06:49.400
broken.

00:06:49.400 --> 00:06:51.040
Not just on Windows.

00:06:51.040 --> 00:06:54.480
Also, when I come back to Mac, like I'm just completely out of sorts.

00:06:54.480 --> 00:06:56.960
So yeah, it's fun.

00:06:56.960 --> 00:06:57.440
All right.

00:06:57.440 --> 00:07:05.100
Well, let's talk academics and Python from a, probably a OS, mostly agnostic perspective.

00:07:05.100 --> 00:07:08.880
But yeah, just, you know, give us a sense of the kind of research you do.

00:07:08.880 --> 00:07:09.960
You know, what is your field?

00:07:09.960 --> 00:07:10.700
What do you study?

00:07:10.700 --> 00:07:11.640
Those kinds of things.

00:07:11.640 --> 00:07:14.340
So people get a sense of like, why am I talking?

00:07:14.340 --> 00:07:16.740
Where are you coming from as you talk about doing all these things?

00:07:16.740 --> 00:07:19.960
The core of my work is pure neuroscience.

00:07:19.960 --> 00:07:21.660
So, so basic science.

00:07:21.660 --> 00:07:25.940
What we do mainly in the lab is we take really tiny wires.

00:07:25.940 --> 00:07:28.140
So they're like a fifth of the size of the human hair.

00:07:28.140 --> 00:07:31.920
And now we're using something called silicon probes, which are, they're manufactured the

00:07:31.920 --> 00:07:37.100
same way that computer chips are manufactured on silicon wafers using photolithography.

00:07:37.100 --> 00:07:38.620
Do you get a higher density that way?

00:07:38.620 --> 00:07:42.120
Do you get like a bunch of little sensors on one point or something?

00:07:42.420 --> 00:07:42.560
Okay.

00:07:42.560 --> 00:07:44.340
So we used to build these little drives.

00:07:44.340 --> 00:07:46.100
I used to have one here, but I got rid of it.

00:07:46.100 --> 00:07:47.240
Little drives by hand.

00:07:47.240 --> 00:07:51.180
So you would just feed the wires in with, with forceps.

00:07:51.180 --> 00:07:57.000
And so you'd get maybe 64 or 128 at most, depending on how much time you want to sit there and

00:07:57.000 --> 00:07:58.000
feed the wires in.

00:07:58.000 --> 00:07:58.240
Yeah.

00:07:58.240 --> 00:07:59.940
But now you can just get the manufactured.

00:07:59.940 --> 00:08:03.520
You pay a lot more, but you get twice, three times the sites.

00:08:03.520 --> 00:08:08.480
And the whole point is the more sites you have, the more neurons you can actually record

00:08:08.480 --> 00:08:09.740
from in the brain.

00:08:09.740 --> 00:08:10.020
Yeah.

00:08:10.020 --> 00:08:14.480
You're not just saying this part of the brain lit up, but you can have a much better picture,

00:08:14.480 --> 00:08:14.720
right?

00:08:14.720 --> 00:08:17.080
The constituent part of your brain is the neuron.

00:08:17.080 --> 00:08:22.820
And so of the millions and billions of neurons, depending on the species you're recording from,

00:08:22.820 --> 00:08:25.420
we can record maybe a few hundred of them.

00:08:25.420 --> 00:08:30.100
But that's usually sufficient to actually, in the specific region you study, and I can talk

00:08:30.100 --> 00:08:33.640
about that more, to discern some sort of information from it.

00:08:33.680 --> 00:08:37.900
And so really the data type we really care about is this tiny little electrical voltages

00:08:37.900 --> 00:08:41.560
that tell you what different neurons in the brain are talking about.

00:08:41.560 --> 00:08:46.400
And so you put the wires in, you record the conversations of a bunch of neurons.

00:08:46.400 --> 00:08:51.780
And then particularly we're interested in two brain regions that are critical for memory,

00:08:51.780 --> 00:08:53.680
learning, and decision-making.

00:08:53.680 --> 00:08:58.040
And this is the hippocampus, which in humans is about the size of your pinky and a few

00:08:58.040 --> 00:08:59.480
inches in from your ear.

00:08:59.480 --> 00:09:03.580
And the prefrontal cortex, which most people know about right behind your forehead, important

00:09:03.580 --> 00:09:06.520
for learning, decision-making, and all those sorts of things.

00:09:06.520 --> 00:09:06.800
Yeah.

00:09:06.880 --> 00:09:11.600
So that's the core of my work is I'm in the lab doing the actual data collection and building

00:09:11.600 --> 00:09:13.140
equipment to actually do that.

00:09:13.140 --> 00:09:17.860
But once you have all of that data and the data keeps growing, like most other fields, you

00:09:17.860 --> 00:09:20.780
got to do a lot of pre-processing, which takes Python.

00:09:20.780 --> 00:09:23.980
You got to do a lot of post-processing, which takes a lot of Python.

00:09:23.980 --> 00:09:26.860
And also we do something called neural decoding.

00:09:26.860 --> 00:09:31.680
So not only do we just like say descriptively, what are these neurons doing?

00:09:31.720 --> 00:09:37.940
But we can go one step further and say, what actual information are these cells representing?

00:09:37.940 --> 00:09:44.600
So in the brain, we can kind of say, this is kind of the fundamental kind of information

00:09:44.600 --> 00:09:49.900
transfer and how information is manipulated in the brain and how it ships information from

00:09:49.900 --> 00:09:53.300
the environment into memory and how it uses that to make a decision.

00:09:53.300 --> 00:09:59.000
All of those kinds of things we can use through fancy modeling and statistics and more recently,

00:09:59.000 --> 00:10:00.720
deep learning and those sorts of things.

00:10:00.920 --> 00:10:02.240
We'll have to come back to deep learning later.

00:10:02.240 --> 00:10:03.200
That'll be fun.

00:10:03.200 --> 00:10:05.580
Given your background.

00:10:05.580 --> 00:10:11.740
So for this hardware, do you write the software that actually talks directly to the hardware

00:10:11.740 --> 00:10:16.600
or is there something that just records it and you grab some sort of custom file format and

00:10:16.600 --> 00:10:17.040
run with it?

00:10:17.040 --> 00:10:17.360
Yeah.

00:10:17.360 --> 00:10:21.060
More recently, it kind of depends on the lab.

00:10:21.060 --> 00:10:26.100
So as time goes on, there's more and more companies that you can just buy off the shelf and

00:10:26.100 --> 00:10:30.020
recording platforms, mostly for the electrical engineering people.

00:10:30.120 --> 00:10:33.940
It's kind of like an audio amplifier because you're recording at millivolts in the brain.

00:10:33.940 --> 00:10:38.200
So you have to amplify it, write it to, if you're plugged in with a wire, write it to the

00:10:38.200 --> 00:10:38.620
computer.

00:10:38.620 --> 00:10:41.660
So all that takes software in various forms.

00:10:41.660 --> 00:10:44.400
And then we do a lot of animal research.

00:10:44.780 --> 00:10:49.260
So the tasks that the animals do are pretty much all automated.

00:10:49.260 --> 00:10:55.240
But recently in the lab, we've kind of had this resurgence of developing kind of novel hardware

00:10:55.240 --> 00:10:56.900
and a lot of automation of behavior.

00:10:56.900 --> 00:11:03.240
So I've kind of rewritten most of our entire behavioral stacks, which is a lot of just some

00:11:03.240 --> 00:11:06.300
microcontroller programming, which not a lot of that's in Python.

00:11:06.300 --> 00:11:09.060
A lot of that's just kind of like C++ and those sorts of things.

00:11:09.460 --> 00:11:11.500
But we have cameras all over.

00:11:11.500 --> 00:11:16.220
So I wrote this kind of like camera server that streams all of the camera footage from

00:11:16.220 --> 00:11:20.740
a bunch of automated boxes to some like central server that just collects all of that data.

00:11:20.740 --> 00:11:26.360
So yeah, a lot of the behavioral stuff nowadays, we're just building in-house to collect all

00:11:26.360 --> 00:11:27.220
of the behavior data.

00:11:27.540 --> 00:11:32.420
The EFIS stuff is now, especially because we're doing something called wireless recording.

00:11:32.420 --> 00:11:36.520
So instead of just having a wire plugged into the head, it just writes it to like an SD card

00:11:36.520 --> 00:11:37.480
or Bluetooth.

00:11:37.480 --> 00:11:39.740
That's just kind of all on chip.

00:11:39.740 --> 00:11:44.120
So it's just whatever the microcontroller language of the chip needs.

00:11:44.120 --> 00:11:49.300
This portion of Talk Python to Me is brought to you by Neo4j.

00:11:49.300 --> 00:11:51.240
Do you know Neo4j?

00:11:51.240 --> 00:11:54.000
Neo4j is a native graph database.

00:11:54.220 --> 00:11:58.840
And if the slowest part of your data access patterns involves computing relationships,

00:11:58.840 --> 00:12:05.340
why not use a database that stores those relationships directly in the database, unlike your typical

00:12:05.340 --> 00:12:06.080
relational one?

00:12:06.080 --> 00:12:10.840
A graph database lets you model the data the way it looks in the real world, instead of forcing

00:12:10.840 --> 00:12:12.780
it into rows and columns.

00:12:12.780 --> 00:12:18.160
It's time to stop asking a relational database to do more than they were made for and simplify

00:12:18.160 --> 00:12:20.400
complex data models with graphs.

00:12:20.400 --> 00:12:24.060
If you haven't used a graph database before, you might be wondering.

00:12:24.060 --> 00:12:25.460
About common use cases.

00:12:25.460 --> 00:12:26.340
What's it for?

00:12:26.340 --> 00:12:27.740
Here are just a few.

00:12:27.740 --> 00:12:28.880
Detecting fraud.

00:12:28.880 --> 00:12:30.380
Enhancing AI.

00:12:30.380 --> 00:12:32.200
Managing supply chains.

00:12:32.200 --> 00:12:35.060
Gaining a 360 degree view of your data.

00:12:35.060 --> 00:12:38.420
And anywhere else you have highly connected data.

00:12:38.420 --> 00:12:43.880
To use Neo4j from Python, it's a simple pip install Neo4j.

00:12:44.580 --> 00:12:48.900
And to help you get started, their docs include a sample web app demonstrating how to use it

00:12:48.900 --> 00:12:51.020
both from Flask and FastAPI.

00:12:51.020 --> 00:12:56.020
Find it in their docs or search GitHub for Neo4j Movies Application Quick Start.

00:12:56.020 --> 00:13:00.200
Developers are solving some of the world's biggest problems with graphs.

00:13:00.200 --> 00:13:01.400
Now it's your turn.

00:13:01.400 --> 00:13:05.700
Visit talkpython.fm/Neo4j to get started.

00:13:06.140 --> 00:13:09.540
That's talkpython.fm/Neo4j.

00:13:09.540 --> 00:13:10.680
And the letter J.

00:13:10.680 --> 00:13:13.740
Thank you to Neo4j for supporting Talk Python To Me.

00:13:15.080 --> 00:13:22.140
I think it's surprising how much software and even hardware, but definitely software is involved

00:13:22.140 --> 00:13:25.140
for something that doesn't sound like a software discipline.

00:13:25.140 --> 00:13:25.640
Yeah.

00:13:25.640 --> 00:13:30.080
You wouldn't think of what you guys are doing as inherently almost like a software team,

00:13:30.080 --> 00:13:31.480
but there's a lot of software there.

00:13:31.480 --> 00:13:32.000
Absolutely.

00:13:32.000 --> 00:13:32.820
And it's growing.

00:13:32.820 --> 00:13:38.400
So it used to be 10, 20 years ago, more biology, I'd say, like more wet lab stuff.

00:13:38.400 --> 00:13:45.140
But 90% of what I do as kind of a neurobiologist is really just engineering style things.

00:13:45.140 --> 00:13:51.080
Like I'm more recently designing PCBs and I'm in the shop a lot, just like with saws and

00:13:51.080 --> 00:13:54.200
hammers and drills and like actually physically building things.

00:13:54.200 --> 00:13:55.660
And obviously a lot of code.

00:13:55.660 --> 00:14:00.960
And the coding part is becoming bigger and bigger to the point where in the field, I always say

00:14:00.960 --> 00:14:05.020
that the neuroscience is like about three decades behind astrophysics.

00:14:05.020 --> 00:14:09.340
Because all the problems that like neuroscientists, like say we're facing now as a field, they

00:14:09.340 --> 00:14:14.300
have like three decades prior where in astrophysics, they're like, well, or neuroscience, we're

00:14:14.300 --> 00:14:15.860
like, what do we do with all this data?

00:14:15.860 --> 00:14:21.280
This is, I mean, I'm collecting a hundred gigabytes an hour, if not more, like what do we do?

00:14:21.280 --> 00:14:21.800
That is a lot.

00:14:21.800 --> 00:14:22.980
Yeah.

00:14:22.980 --> 00:14:28.360
But relative to like some of those big telescopes that are collecting like almost petabyte scale.

00:14:28.360 --> 00:14:32.200
I would say both ends of physics, like the very, very extreme ends of physics.

00:14:32.360 --> 00:14:36.180
So astrophysics, the very large and then particle physics, right?

00:14:36.180 --> 00:14:39.020
At CERN as well, they've got insane amounts of data.

00:14:39.020 --> 00:14:39.300
Yeah.

00:14:39.300 --> 00:14:40.520
And that's what we're starting to see.

00:14:40.520 --> 00:14:45.100
I think in neuroscience too, is that kind of division of like, because the scale of data

00:14:45.100 --> 00:14:49.180
collection is so big, you're starting to need not just a single lab, but teams.

00:14:49.180 --> 00:14:53.960
So we have a few institutes now that are just pumping out terabytes of data.

00:14:53.960 --> 00:14:59.280
And so you start to see that division between the neuroscientists who are really in the lab,

00:14:59.280 --> 00:15:04.540
hands-on with actual neural tissue or the recording device, and the neuroscientists who

00:15:04.540 --> 00:15:09.100
are just take the data and analyze it and develop new models and statistical models.

00:15:09.100 --> 00:15:14.840
And also theory, there's always a dearth of theory in neuroscience, but the computational

00:15:14.840 --> 00:15:20.360
modeling is certainly getting a lot bigger within the last few decades as well, where people's

00:15:20.360 --> 00:15:24.240
entire job is just how do we model some of these things in code?

00:15:24.240 --> 00:15:29.780
You probably run into different research groups, different teams that have different levels

00:15:29.780 --> 00:15:32.080
of sophistication from a software side.

00:15:32.080 --> 00:15:37.900
And do you see like a productivity or a quality difference jump out from like the kind of work

00:15:37.900 --> 00:15:39.660
or the velocity of work that people are doing there?

00:15:39.900 --> 00:15:40.300
Absolutely.

00:15:40.300 --> 00:15:44.420
It makes me almost like a, it's a huge range.

00:15:44.420 --> 00:15:46.700
There are like very sophisticated labs.

00:15:46.700 --> 00:15:51.180
And usually those are the labs that have kind of just a pure software person on the team or

00:15:51.180 --> 00:15:56.140
people who are very inclined towards software all the way to, and it makes me so sad when people

00:15:56.140 --> 00:16:00.220
are spending like weeks in a spreadsheet, just manually doing things by hand.

00:16:00.220 --> 00:16:00.940
Yeah, I know.

00:16:00.940 --> 00:16:03.280
You could do this in five minutes and by a minute.

00:16:03.280 --> 00:16:07.280
And not only could you do it faster, you could do it without any errors.

00:16:07.540 --> 00:16:08.440
Yeah, more reliable.

00:16:08.440 --> 00:16:15.380
None of those like, oh, I misread it and I shifted off by a cell or I typed in, I missed

00:16:15.380 --> 00:16:16.120
something, right?

00:16:16.120 --> 00:16:17.840
Because it just reads what's there.

00:16:17.840 --> 00:16:18.040
Yeah.

00:16:18.040 --> 00:16:23.660
A lot of like graduate programs are starting to wake up to this fact that it's going to

00:16:23.660 --> 00:16:28.280
be almost impossible to do any science without some degree of proficiency in coding.

00:16:28.520 --> 00:16:33.740
And I think a lot of, a lot of say grad students and postdocs and so on, when they actually sit

00:16:33.740 --> 00:16:38.420
down and try and analyze their data, whether they're just in Excel or they need to write

00:16:38.420 --> 00:16:42.520
a little Python script, that's kind of their first introduction is, oh, I have this data.

00:16:42.520 --> 00:16:43.920
I need to do something with it.

00:16:43.920 --> 00:16:49.360
I'm going to Google exactly how do I read in this data or how do I do a t-test in Python

00:16:49.360 --> 00:16:51.600
or how do I plot something in matplotlib?

00:16:51.860 --> 00:16:54.940
And that's kind of the level that they start getting into out of necessity.

00:16:54.940 --> 00:16:59.920
But the sophistication and the speed, because that's, they're usually just teaching themselves.

00:16:59.920 --> 00:17:01.100
That's most of academia.

00:17:01.100 --> 00:17:06.220
It's just, you have a problem, spend a few days Googling and reading books until you find

00:17:06.220 --> 00:17:06.360
it.

00:17:06.500 --> 00:17:08.500
And once it works, you can kind of just leave it.

00:17:08.500 --> 00:17:10.600
You don't have to clean it up or anything, right?

00:17:10.600 --> 00:17:11.000
Yeah.

00:17:11.000 --> 00:17:11.260
Okay.

00:17:11.260 --> 00:17:17.500
Which results in a lot of, I mean, the progress of science doesn't go away, but the code is,

00:17:17.500 --> 00:17:18.820
you know, not robust.

00:17:18.820 --> 00:17:22.660
And so that's why you see things, especially in other fields of like psychology and such

00:17:22.660 --> 00:17:23.980
like replication crises.

00:17:23.980 --> 00:17:29.460
And people have done meta analysis of running the same software stack on like 12 different

00:17:29.460 --> 00:17:31.300
data sets and you get different results.

00:17:31.300 --> 00:17:37.580
And so you start to kind of see that shaky foundation is starting to bleed into the, like

00:17:37.580 --> 00:17:39.680
you said, the reliability results.

00:17:39.680 --> 00:17:42.960
And starting to have consequences, not just it's more work or something.

00:17:42.960 --> 00:17:43.520
Exactly.

00:17:43.520 --> 00:17:48.320
Maybe we could start a bit by just talking about maybe the history, you know, diving into this

00:17:48.320 --> 00:17:51.800
a little bit more, just the history of programming in neuroscience.

00:17:51.800 --> 00:17:58.260
I wasn't in neuroscience in any way, but I worked with a bunch of cognitive scientists studying,

00:17:58.260 --> 00:18:03.460
you know, how people solve problems and thought about things at a lab for one of my first jobs.

00:18:03.460 --> 00:18:04.860
And we studied all through eye tracking.

00:18:04.860 --> 00:18:05.420
Yeah.

00:18:05.420 --> 00:18:07.080
Not the iPhone, but actual eyes.

00:18:07.080 --> 00:18:08.140
It was fascinating.

00:18:08.140 --> 00:18:08.920
It was tons of data.

00:18:08.920 --> 00:18:09.500
It was really cool.

00:18:09.500 --> 00:18:13.000
And there were like, you described a lot of people who would do sort of Excel stuff and

00:18:13.000 --> 00:18:14.900
they would take the data and they process it.

00:18:14.900 --> 00:18:17.380
And over time, we just started to automate these things.

00:18:17.380 --> 00:18:20.600
And their first thought was, you're programming me out of a job.

00:18:20.600 --> 00:18:22.040
I'm like, no, no, no.

00:18:22.040 --> 00:18:24.140
This is the crappy part of your job.

00:18:24.140 --> 00:18:27.800
Like you're supposed to analyze the results and think about it and plan new stuff.

00:18:27.800 --> 00:18:29.800
And now you can just focus on that.

00:18:29.800 --> 00:18:30.260
Right.

00:18:30.260 --> 00:18:34.120
And as the software got better, you know, we just tackled bigger problems.

00:18:34.120 --> 00:18:37.840
So, you know, maybe give us a bit of a history of on your side.

00:18:37.840 --> 00:18:39.380
So I love the cognitive science.

00:18:39.380 --> 00:18:42.760
That's my more background is cognitive science.

00:18:42.760 --> 00:18:47.000
I was my undergrad and grew up in science in a cognitive science department while also

00:18:47.000 --> 00:18:49.000
doing some wet lab neuroscience stuff.

00:18:49.000 --> 00:18:50.280
So it's fun.

00:18:50.620 --> 00:18:51.640
Yeah, absolutely.

00:18:51.640 --> 00:18:54.340
Did you start out with like MATLAB and that kind of stuff?

00:18:54.340 --> 00:18:56.200
Is that where they told you you need to be?

00:18:56.200 --> 00:19:02.040
Neuroscience has certainly had at least our branch of neuroscience just because by the nature

00:19:02.040 --> 00:19:05.560
of recording voltages and you need to write to a computer.

00:19:05.560 --> 00:19:11.000
So there has been kind of a long history of for as long as there's been even like punch

00:19:11.000 --> 00:19:11.680
card computers.

00:19:11.680 --> 00:19:17.100
People have kind of read in the data into the computer and done, you know, their statistics

00:19:17.100 --> 00:19:18.800
on that rather than something else.

00:19:19.360 --> 00:19:24.140
I'm just I'm actually recently writing a kind of a review article on kind of the history

00:19:24.140 --> 00:19:25.560
of data science and neuroscience.

00:19:25.560 --> 00:19:28.000
And I loved this paper.

00:19:28.000 --> 00:19:30.200
It was from 1938.

00:19:30.200 --> 00:19:33.080
And they took an EEG spectrum.

00:19:33.080 --> 00:19:38.200
And so EEG is just the continuous time series of brain voltage.

00:19:38.200 --> 00:19:39.880
So you're not in the brain recording.

00:19:39.880 --> 00:19:41.320
And this is, I think, from humans.

00:19:41.320 --> 00:19:45.720
And they took something called the Fourier transform, which I'll be as up to speed with that is you

00:19:45.720 --> 00:19:51.040
basically just take some oscillating signal and you break it down into its constituent parts.

00:19:51.040 --> 00:19:52.380
And most of you have seen it before.

00:19:52.380 --> 00:19:58.060
If you've ever seen like an audio spectrogram, that's kind of the most notable visualization

00:19:58.060 --> 00:20:00.540
where you can kind of see the high frequencies and the low frequencies.

00:20:00.540 --> 00:20:03.880
Basically, it pulls the frequencies out of the signal, right?

00:20:04.060 --> 00:20:04.260
Yeah.

00:20:04.260 --> 00:20:07.000
But the way they did this, this is 1938.

00:20:07.000 --> 00:20:07.840
There's no computers.

00:20:07.840 --> 00:20:13.920
So they actually had mechanical device where they would just take this EEG trace that was

00:20:13.920 --> 00:20:17.380
on tape and they would feed it into this like mechanical machine.

00:20:17.380 --> 00:20:20.960
And it would basically read kind of this black line on the tape.

00:20:20.960 --> 00:20:27.420
And so as it would crank the tape around this machine, depending on kind of the frequency that

00:20:27.420 --> 00:20:30.460
the line went up and down, that would read out the Fourier transform.

00:20:30.580 --> 00:20:35.520
So it was mechanical, like a lot of those cool devices back in the older days.

00:20:35.520 --> 00:20:36.120
That's impressive.

00:20:36.120 --> 00:20:39.260
Now you can get that same thing with in MATLAB.

00:20:39.260 --> 00:20:43.720
You just type FFT, parentheses, parentheses, put your data in the middle and you get the

00:20:43.720 --> 00:20:45.100
same thing in microseconds.

00:20:45.100 --> 00:20:51.000
But neuroscience, at least my field, has kind of always had this kind of serendipitous relationship

00:20:51.000 --> 00:20:53.760
with computing generally, coding generally.

00:20:53.760 --> 00:20:58.920
And a lot of the code, I think earlier on was kind of was Fortran-ish and then it moved

00:20:58.920 --> 00:21:03.140
towards MATLAB and MATLAB's kind of had its stake in the ground for a long time.

00:21:03.140 --> 00:21:08.040
Just because that was the first kind of software that you could really do array manipulations

00:21:08.040 --> 00:21:08.700
on well.

00:21:08.700 --> 00:21:11.660
And it was kind of a higher level than some of the lower level programming.

00:21:11.660 --> 00:21:18.440
So a lot of the older labs have their entire code base and stack and analysis software in

00:21:18.440 --> 00:21:19.040
MATLAB.

00:21:19.520 --> 00:21:24.720
And so it's only been within maybe five to six, seven years, it'll be a bit longer,

00:21:24.720 --> 00:21:29.600
10 years that you've really seen Python start to supplant MATLAB as kind of the de facto

00:21:29.600 --> 00:21:35.260
programming language in labs, just because of the cost of trying to transfer everything over.

00:21:35.260 --> 00:21:40.580
And despite the fact that MATLAB isn't open source and it's extremely expensive, most universities

00:21:40.580 --> 00:21:41.320
have licenses.

00:21:41.640 --> 00:21:43.440
And so that kind of facilitates...

00:21:43.440 --> 00:21:44.020
It's prepaid.

00:21:44.020 --> 00:21:44.860
Yeah.

00:21:44.860 --> 00:21:45.440
In a sense.

00:21:45.440 --> 00:21:45.780
Yeah.

00:21:45.780 --> 00:21:47.640
But it is still pretty expensive.

00:21:47.640 --> 00:21:52.340
Especially if you get those little toolboxes, like wavelet decomposition toolbox, 2,000 bucks

00:21:52.340 --> 00:21:54.020
instead of a pip install, you know?

00:21:54.020 --> 00:21:55.900
And again, we do a lot of signal processing.

00:21:55.900 --> 00:21:58.620
And so that's exactly the place you want to be.

00:21:58.620 --> 00:22:03.920
And like MATLAB usually controls, because it has pretty good control over like external hardware,

00:22:03.920 --> 00:22:07.880
you can run like your behavior, your task kind of in MATLAB codes.

00:22:07.880 --> 00:22:11.840
You can kind of do everything in one language as you would like to do in Python.

00:22:11.840 --> 00:22:14.620
But it's starting to kind of go away.

00:22:14.620 --> 00:22:19.380
And I think a lot of that is just because the allure of Python, which is so many tools,

00:22:19.380 --> 00:22:23.700
and because it's probably a lot easier to learn for most people than MATLAB.

00:22:23.700 --> 00:22:28.540
We're kind of starting to see that switch now that there's kind of more to offer, I'd say,

00:22:28.540 --> 00:22:31.160
a lot of scientists than MATLAB.

00:22:31.160 --> 00:22:32.620
Yeah, you said 10, 12 years ago.

00:22:32.620 --> 00:22:33.380
At least in our film.

00:22:33.380 --> 00:22:37.880
Yeah, the difference in the external packages on PyPI you can get,

00:22:37.880 --> 00:22:43.100
and especially the ones for data science have just exploded.

00:22:43.100 --> 00:22:46.620
The choices and the stuff that's out there, it's pretty diverse.

00:22:46.620 --> 00:22:47.320
It's pretty crazy.

00:22:47.320 --> 00:22:50.860
The only other one that I think is still in pretty strong competition with Python

00:22:50.860 --> 00:22:55.420
from the perspective of, we collaborate a lot with like mathematicians and statisticians,

00:22:55.420 --> 00:22:59.760
and R is their usual favorite, just because statistics,

00:22:59.760 --> 00:23:03.240
like all the best statistical packages are still pretty much in R.

00:23:03.320 --> 00:23:05.560
And so that's where a lot of people live.

00:23:05.560 --> 00:23:07.480
TG Plot's pretty good.

00:23:07.480 --> 00:23:08.720
Pretty mixed plots.

00:23:08.720 --> 00:23:10.380
Yeah, that's interesting.

00:23:10.380 --> 00:23:13.240
It's really focused, and it's really good at what it does.

00:23:13.240 --> 00:23:16.320
And one of the things that I think is worth just considering,

00:23:16.720 --> 00:23:22.020
if somebody comes, let's say a brand new first year grad student comes into the lab,

00:23:22.020 --> 00:23:24.340
and you're like, all right, what's your programming experience?

00:23:24.340 --> 00:23:27.500
Like, well, program the clock on the VCR.

00:23:27.500 --> 00:23:30.000
Like, okay, we're going to have to start you somewhere or something, right?

00:23:30.060 --> 00:23:36.140
And you could teach them something really specific, like MATLAB, or something along those lines.

00:23:36.140 --> 00:23:45.400
But if they learn something like Julia, not like Julia, like Python, not Julia, maybe even not really R, but R is closer somewhat,

00:23:45.400 --> 00:23:52.920
is they learn not just a skill for the lab, but it's kind of almost any software job is potentially within reach,

00:23:53.080 --> 00:23:55.820
with a little bit of learning about that area, right?

00:23:55.820 --> 00:23:59.880
Like, if you know Python, you say, I want a job, there's a massive set of options out there.

00:23:59.880 --> 00:24:09.320
If you say, I know MATLAB, or even Julia, it's like, okay, well, here's the few labs and the few research areas and the real,

00:24:09.320 --> 00:24:11.080
I just think it's something that-

00:24:11.080 --> 00:24:12.160
A lot of engineering firms.

00:24:12.160 --> 00:24:13.100
Yeah, yeah.

00:24:13.100 --> 00:24:20.580
I'm just thinking that, like, a lot of academic folks should consider what happens if the student doesn't necessarily become a professor.

00:24:20.800 --> 00:24:21.740
You know what I mean?

00:24:21.740 --> 00:24:23.540
Which actually is a lot of the time, right?

00:24:23.540 --> 00:24:25.640
Or a professional researcher of some sort.

00:24:25.640 --> 00:24:29.220
And that's a really awesome skill to have on top of your degree.

00:24:29.220 --> 00:24:31.360
So I think that's just a big win for it.

00:24:31.360 --> 00:24:32.380
I'm happy to see that.

00:24:32.380 --> 00:24:38.500
And that literal situation just happened where a statistician that we were collaborating pretty closely with graduated,

00:24:38.500 --> 00:24:42.100
brilliant guy, and got a job at Microsoft.

00:24:42.100 --> 00:24:46.300
And so we were in a meeting after he was there, and they were like,

00:24:46.300 --> 00:24:50.340
what's some advice that you have now that you've been, you know, in industry for a while?

00:24:50.600 --> 00:24:51.960
And he's like, stop using R.

00:24:51.960 --> 00:24:54.860
Learn Python, because everyone here uses Python.

00:24:54.860 --> 00:25:00.220
And it took me a few months to kind of switch from the R worldview of, you know,

00:25:00.220 --> 00:25:07.320
caret hyphen to equal sign to actually to work and collaborate with everyone, because everyone's just using Python.

00:25:07.320 --> 00:25:07.560
Yeah.

00:25:07.560 --> 00:25:10.140
From his perspective, and I'm sure it's not unique.

00:25:10.140 --> 00:25:11.600
No, I'm sure that it's not either.

00:25:12.040 --> 00:25:15.220
I think, yeah, I just think it's, it's not like a religious war.

00:25:15.220 --> 00:25:17.720
It's not like, oh, I think Python is absolutely better.

00:25:17.720 --> 00:25:18.900
You should just not use other stuff.

00:25:18.900 --> 00:25:22.320
I just think it's preparing people for stuff beyond school.

00:25:22.320 --> 00:25:24.220
It's a pretty interesting angle to take.

00:25:24.300 --> 00:25:25.680
And it's not like you can't learn other things.

00:25:25.680 --> 00:25:35.620
I think it's really good to learn other things, especially ones that are complementary, where R can be complementary, especially now that they have a lot of the, like, subsystem packages.

00:25:35.620 --> 00:25:39.260
Or when I get R code, I usually just write, like, a subprocess.

00:25:39.580 --> 00:25:45.440
I did this recently, just wrote, like, a subprocess line to call the R script, because I was too lazy to rewrite it.

00:25:45.440 --> 00:25:45.920
Yeah, sure.

00:25:45.920 --> 00:25:50.120
But there's other, like, I don't know, like, Rust is probably a good one to probably try and branch out.

00:25:50.120 --> 00:25:52.300
Or, like, lower level languages, like C++.

00:25:52.300 --> 00:25:52.940
Yeah.

00:25:52.940 --> 00:25:54.460
If you need for what you're doing.

00:25:54.460 --> 00:25:57.820
Yeah, and it sounds like you guys do for talking to hardware and stuff like that.

00:25:57.820 --> 00:25:58.640
Yeah, occasionally.

00:25:58.640 --> 00:26:01.240
Boy, there's not a lot of things Python can't do.

00:26:01.240 --> 00:26:04.320
Break out some MicroPython when you got to get your microcontrollers and stuff.

00:26:04.320 --> 00:26:08.720
This portion of Talk Python to Me is brought to you by Posit,

00:26:08.720 --> 00:26:14.020
the makers of Shiny, formerly RStudio, and especially Shiny for Python.

00:26:14.020 --> 00:26:15.920
Let me ask you a question.

00:26:15.920 --> 00:26:17.620
Are you building awesome things?

00:26:17.620 --> 00:26:18.680
Of course you are.

00:26:18.680 --> 00:26:20.260
You're a developer or a data scientist.

00:26:20.260 --> 00:26:21.160
That's what we do.

00:26:21.160 --> 00:26:23.200
And you should check out Posit Connect.

00:26:23.200 --> 00:26:30.180
Posit Connect is a way for you to publish, share, and deploy all the data products that you're building using Python.

00:26:30.180 --> 00:26:33.360
People ask me the same question all the time.

00:26:33.360 --> 00:26:36.520
Michael, I have some cool data science project or notebook that I built.

00:26:37.020 --> 00:26:39.800
How do I share it with my users, stakeholders, teammates?

00:26:39.800 --> 00:26:44.640
Do I need to learn FastAPI or Flask or maybe Vue or React.js?

00:26:45.140 --> 00:26:45.860
Hold on now.

00:26:45.860 --> 00:26:50.640
Those are cool technologies, and I'm sure you'd benefit from them, but maybe stay focused on the data project.

00:26:50.640 --> 00:26:53.120
Let Posit Connect handle that side of things.

00:26:53.120 --> 00:26:57.840
With Posit Connect, you can rapidly and securely deploy the things you build in Python.

00:26:57.840 --> 00:27:04.300
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, ports, dashboards, and APIs.

00:27:04.880 --> 00:27:06.580
Posit Connect supports all of them.

00:27:06.580 --> 00:27:12.440
And Posit Connect comes with all the bells and whistles to satisfy IT and other enterprise requirements.

00:27:12.440 --> 00:27:16.720
Make deployment the easiest step in your workflow with Posit Connect.

00:27:16.720 --> 00:27:22.920
For a limited time, you can try Posit Connect for free for three months by going to talkpython.fm/posit.

00:27:22.920 --> 00:27:26.580
That's talkpython.fm/P-O-S-I-T.

00:27:26.780 --> 00:27:28.460
The link is in your podcast player show notes.

00:27:28.460 --> 00:27:31.720
Thank you to the team at Posit for supporting Talk Python.

00:27:31.720 --> 00:27:36.600
So another thing that's, I don't know how it's received.

00:27:36.600 --> 00:27:39.760
I know it took a while to kind of really catch on.

00:27:39.760 --> 00:27:49.220
And I think the thing that just broke the final barriers for open source being adopted, at least in business, was the AI stuff and the data science stuff.

00:27:49.220 --> 00:27:51.160
People were like, oh, we can't use this open source stuff.

00:27:51.160 --> 00:27:56.440
We've got to have a SLA and some company we can sue if our code doesn't work right or, you know, whatever, right?

00:27:56.440 --> 00:27:57.440
Something crazy like that.

00:27:57.440 --> 00:28:02.000
And they're like, but you understand all the AI and all the data science.

00:28:02.000 --> 00:28:03.880
We have to use this open source stuff.

00:28:03.880 --> 00:28:04.980
Like, all right, fine.

00:28:04.980 --> 00:28:07.620
What's the open source story for you guys?

00:28:07.620 --> 00:28:19.720
Academia is probably championed open source for a really long time just because, I mean, open source back, I mean, even when I first started, it was just if you read a paper and someone has some new fancy analysis.

00:28:20.320 --> 00:28:26.380
Before it became a bigger push by, like, funding agencies to, like, actually post it to GitHub or some repository.

00:28:26.380 --> 00:28:29.320
I mean, you could just email people and be like, hey, I saw your paper.

00:28:29.320 --> 00:28:30.520
I want that script.

00:28:30.520 --> 00:28:32.200
And they would just send you a MATLAB file.

00:28:32.200 --> 00:28:35.120
And it would be, you know, just whatever they had written.

00:28:35.160 --> 00:28:38.380
But it was in MATLAB and you'd have to kind of tear it apart yourself.

00:28:38.380 --> 00:28:39.780
And there was little to no documentation.

00:28:39.780 --> 00:28:43.020
You'd be lucky if there's comments and it's, you know, spaghetti code.

00:28:43.020 --> 00:28:45.180
But, you know, you figure that out.

00:28:45.180 --> 00:28:47.660
You kind of work backwards and deconstruct it.

00:28:47.660 --> 00:28:49.100
And eventually you kind of have their code.

00:28:49.620 --> 00:28:57.400
So that kind of ethos of just, you know, scientists are really good, by and large, of just sharing information and helping people out.

00:28:57.400 --> 00:28:58.880
If you have a question, just ask.

00:28:58.880 --> 00:29:01.120
It's kind of always been there.

00:29:01.120 --> 00:29:08.180
At least in our field, it's not as competitive as some other ones where you're just kind of like racing to get the next project out.

00:29:08.180 --> 00:29:09.560
It happens, but rarely.

00:29:09.620 --> 00:29:18.660
But now a lot of funding agencies and just in general, people are just excited about when you publish a paper, you put a GitHub link in the bottom of the paper.

00:29:18.660 --> 00:29:20.240
And then that links to the repository.

00:29:20.240 --> 00:29:25.760
And, yeah, maybe it's not been updated in a while, but the code's there and you can just take it and grab it.

00:29:25.760 --> 00:29:26.680
For the reproducibility.

00:29:26.680 --> 00:29:28.380
How about using other things?

00:29:28.380 --> 00:29:29.960
Is there SciPy?

00:29:29.960 --> 00:29:31.840
I know for astronomy, there's AstroPy.

00:29:31.840 --> 00:29:33.580
Is there Neuropy?

00:29:33.580 --> 00:29:38.500
It's really still more analysis-dependent and pre-process-dependent.

00:29:38.500 --> 00:29:46.140
So there's kind of this, it's still the early days where there's probably too many formats just because no one can agree on what's the best one.

00:29:46.140 --> 00:29:53.080
So like even a lot of the data formats are written kind of in Python to take whatever data you have and reformat it to something shareable.

00:29:53.080 --> 00:29:55.240
And there's five or six of them floating around.

00:29:55.240 --> 00:29:59.400
There's probably two that are still duking it out to see which one will be the best.

00:29:59.400 --> 00:30:02.060
And probably five years from now, there's going to be a better one.

00:30:02.060 --> 00:30:06.760
So data formats, certainly there's kind of this, there's a few that are neck and neck.

00:30:07.060 --> 00:30:13.240
Analysis pipelines, a lot of those are still done in-house, but they're starting to be a lot more toolkits and frameworks and packages.

00:30:13.240 --> 00:30:17.480
There's some really good ones that have more documentation written.

00:30:17.480 --> 00:30:19.740
They're on the PyPy repositories.

00:30:19.740 --> 00:30:21.820
So you can just pip install them and you have them.

00:30:21.820 --> 00:30:24.620
The computational neuroscience people are great at this.

00:30:24.620 --> 00:30:30.220
So all the like neural simulation software, that is all really well documented, really well written.

00:30:30.460 --> 00:30:34.220
A lot of good like example code and tutorials and so on.

00:30:34.220 --> 00:30:41.480
So yeah, we're starting to see kind of this more robust kind of ecosystem where you can just kind of pull things.

00:30:41.480 --> 00:30:42.980
It still just kind of varies.

00:30:42.980 --> 00:30:48.640
There's probably still not one go-to place other than the standard data science toolkits.

00:30:48.640 --> 00:30:49.520
Right, right.

00:30:49.520 --> 00:30:50.980
The pandas and so on.

00:30:51.100 --> 00:31:00.200
Yeah, NumPy, Matplotlib, pandas, scikit-learn, if you're doing deep learning, PyTorch or TensorFlow, all of those still apply to any data site stack.

00:31:00.200 --> 00:31:00.900
Yeah, of course.

00:31:00.900 --> 00:31:05.100
What's your day-to-day stack look like if you're sitting down to do some analysis?

00:31:05.440 --> 00:31:13.040
I have a VS Code and like autocomplete where I just write import in and it just NumPy, Matplotlib, pandas.

00:31:13.040 --> 00:31:17.420
Then I usually delete pandas because unless I have a CSV file, I'm not using it.

00:31:17.420 --> 00:31:22.100
So NumPy, Matplotlib, I can probably do 75% of the things I want to do.

00:31:22.100 --> 00:31:28.360
scikit-learn and SciPy, obviously, if I'm doing any stats with those things, those libraries I might go to.

00:31:28.720 --> 00:31:36.160
And then over the last few years, I kind of just have my own, just because you catch yourself writing the same functions over and over and over again.

00:31:36.160 --> 00:31:40.680
And so I just started building my kind of internal framework of just things I know I need.

00:31:40.680 --> 00:31:44.040
So if I'm working with LFP data, I have all my filters there.

00:31:44.040 --> 00:31:46.400
If I have spike data, I have all my spikes there.

00:31:46.400 --> 00:31:52.100
We do a lot of decoding, so developing deep learning algorithms to decode neural data.

00:31:52.100 --> 00:31:54.040
All of those are kind of listed there.

00:31:54.040 --> 00:32:06.340
Yeah, and then I started realizing, dude, internal tools make the difference between solving a problem in 10 minutes or solving it in an hour, where I can just sit down and have everything automated to come up.

00:32:06.340 --> 00:32:09.580
So yeah, the standard data science stack I use pretty frequently.

00:32:09.580 --> 00:32:17.320
Hardware stack, I mean, so VS Code, I just recently switched to just because everyone was talking about it from Sublime.

00:32:17.320 --> 00:32:19.760
I usually just edit it in a terminal.

00:32:19.760 --> 00:32:21.020
And I was like, oh, I'll try it out.

00:32:21.020 --> 00:32:21.980
Everyone's talking about it.

00:32:21.980 --> 00:32:24.180
It's one of the good things Microsoft has done.

00:32:24.180 --> 00:32:25.660
It's pretty sweet.

00:32:25.660 --> 00:32:26.640
Yeah, it is pretty sweet.

00:32:26.640 --> 00:32:27.460
That's pretty nice.

00:32:27.460 --> 00:32:34.240
And when you do the VS Code stuff, are you just writing straight Python scripts or are you doing VS Code on top of notebooks?

00:32:34.240 --> 00:32:34.900
Yeah.

00:32:34.900 --> 00:32:38.260
Because it has that kind of text view of a notebook type of thing, I think.

00:32:38.260 --> 00:32:42.220
I used to use exclusively Python scripts, so just the .py.

00:32:42.220 --> 00:32:44.840
Started seeing how great Jupyter was.

00:32:44.840 --> 00:32:51.200
And so then you start doing everything in Jupyter, and then you start to have all these convoluted notebooks and notebook V1 through 7.

00:32:51.200 --> 00:32:58.160
So then you realize that you've got to find a balance between, you know, notebooks are great for presentation and for quickly testing.

00:32:58.420 --> 00:33:02.300
But the sooner you can get it into, like, a class structure or a package or something.

00:33:02.300 --> 00:33:08.060
The sort of productized version of it, you wanted to get it down into Python code a lot of times, probably.

00:33:08.060 --> 00:33:08.520
Exactly.

00:33:08.520 --> 00:33:10.180
Like your internal tools you talked about.

00:33:10.180 --> 00:33:12.840
You're like, all right, this is the library you just call stuff, right?

00:33:12.840 --> 00:33:15.200
That just belongs more as a package and not a...

00:33:15.200 --> 00:33:22.960
The sooner you can kind of condense, pull the code out of the notebook and just leave notebooks for presentation, it's probably the best.

00:33:22.960 --> 00:33:23.240
Yeah.

00:33:23.240 --> 00:33:24.060
It's a lot of pipelines.

00:33:24.060 --> 00:33:25.840
So it's a lot of preprocessing pipelines.

00:33:25.840 --> 00:33:29.520
So you don't want, you know, 50 cells of just moving data.

00:33:29.520 --> 00:33:30.400
Preparing, yeah.

00:33:30.400 --> 00:33:34.780
You talked about having quite a bit of data, some of that being image-based.

00:33:34.780 --> 00:33:36.100
Sounds like a lot of work.

00:33:36.100 --> 00:33:37.980
Do you have, like, a big compute cluster?

00:33:37.980 --> 00:33:42.460
Do you just have, like, an ultra, an M3 ultra or whatever?

00:33:42.460 --> 00:33:43.420
That's not even not yet.

00:33:43.420 --> 00:33:44.280
It's M2s.

00:33:44.280 --> 00:33:47.120
But do you have just a big machine or do you guys do cloud stuff?

00:33:47.120 --> 00:33:48.400
What's compute look like?

00:33:48.400 --> 00:33:50.440
Depends on what I'm doing, what I need.

00:33:50.440 --> 00:33:56.520
Most things, let's be honest, I could probably just use my desktop computers, really a super micro server.

00:33:56.520 --> 00:33:57.760
It just runs Linux.

00:33:57.760 --> 00:34:00.960
But then for doing deep learning, you need GPUs.

00:34:00.960 --> 00:34:04.800
And so we have a nice set of GPUs we can pull, too.

00:34:04.800 --> 00:34:05.060
Yeah.

00:34:05.060 --> 00:34:08.380
Do you do your own training on LLMs and other deep learning things?

00:34:08.380 --> 00:34:10.780
The only LLM training I did was just for fun.

00:34:10.780 --> 00:34:13.720
But it's all the deep learning stuff we have to train.

00:34:13.720 --> 00:34:15.680
And it's on R, particularly.

00:34:15.680 --> 00:34:17.840
So that's all GPUs for that.

00:34:17.840 --> 00:34:20.960
A lot of the statistics we do are, like, permutations.

00:34:20.960 --> 00:34:24.160
So you need to kind of, like, parallelize them out into CPUs.

00:34:24.160 --> 00:34:27.100
So then I'll pull, like, a CPU cluster we have if I need it.

00:34:27.100 --> 00:34:31.360
Do you see Irvine have, like, a big compute resource sort of thing you can grab?

00:34:31.500 --> 00:34:33.720
They have a campus-wide one that you can get on.

00:34:33.720 --> 00:34:37.300
And there's a few independent ones that I have access to.

00:34:37.300 --> 00:34:40.920
So GPU is kind of in a different place than CPUs are.

00:34:40.920 --> 00:34:42.740
So I can just kind of pick and choose.

00:34:42.740 --> 00:34:46.200
And then I have a few servers in the lab that I've just kind of put together.

00:34:46.460 --> 00:34:51.160
All my camera stuff, all my behavior, I kind of wrote it so it's cloud-based.

00:34:51.160 --> 00:34:55.620
So I can kind of just pull up my phone and look at the videos of what animals are doing and stuff.

00:34:55.620 --> 00:34:58.280
All that runs on just a server in the lab.

00:34:58.280 --> 00:35:01.020
So, yeah, it's the compute is there when you need it.

00:35:01.140 --> 00:35:09.840
And I think as I've matured, I've kind of learned when to use what compute when and when it's worth taking the extra time to use it when you don't need to.

00:35:09.840 --> 00:35:12.580
And also when a lot of the times you don't even need it.

00:35:12.580 --> 00:35:17.380
So I know a lot of people when I see their code and they complain that it takes like an hour to run.

00:35:17.380 --> 00:35:25.380
I mean, just using multiprocessing in Python, that in and of itself is enough to not need to use a cluster.

00:35:25.380 --> 00:35:28.020
They're just using a single thread for their analysis.

00:35:28.020 --> 00:35:28.620
For sure.

00:35:28.620 --> 00:35:30.960
Or just a bad programming patterns.

00:35:30.960 --> 00:35:31.760
design patterns.

00:35:31.760 --> 00:35:38.380
Like you're looping over the thing in the Pandas data frame instead of doing vector operations in the Pandas data frame.

00:35:38.380 --> 00:35:39.400
Like that kind of stuff, right?

00:35:39.400 --> 00:35:40.500
A hundred percent.

00:35:40.500 --> 00:35:41.060
Yeah.

00:35:41.060 --> 00:35:44.320
I mean, that was one of the first things that I usually teach.

00:35:44.320 --> 00:35:50.920
I have this little example script that shows that like, why is it better to pre-allocate array rather than to just append to the bottom?

00:35:50.920 --> 00:35:55.800
And it's like these things that we kind of take for granted now, but it's not intuitive unless you actually see it.

00:35:55.800 --> 00:35:59.960
No, you learn it the hard way, but it sticks in your mind once you learn it.

00:36:00.020 --> 00:36:01.580
Well, yeah, I think that's the issue.

00:36:01.580 --> 00:36:03.180
It's like people just take it for granted.

00:36:03.180 --> 00:36:03.900
Yeah, for sure.

00:36:03.900 --> 00:36:05.060
Like, why didn't you know that?

00:36:05.060 --> 00:36:08.820
How do you onboard new people?

00:36:08.820 --> 00:36:14.000
It just kind of depends on the lab.

00:36:14.000 --> 00:36:26.940
Every lab kind of has their own structure of just kind of this hierarchy of expertise where like I started as an undergrad and I just volunteered in a lab at a different university and just volunteered my time.

00:36:26.940 --> 00:36:28.040
Eventually could get paid.

00:36:28.240 --> 00:36:35.880
Just wanted to spend time in the lab and you could all the way up to grad students who are there to get a PhD and have more kind of autonomy over their projects.

00:36:35.880 --> 00:36:41.000
A postdoc who has a PhD and five to eight years of experience.

00:36:41.000 --> 00:36:42.780
And so it can pretty work well.

00:36:42.780 --> 00:36:48.560
Then there's like staff scientists or even a lot of labs now are hiring just pure engineers or pure software people.

00:36:48.560 --> 00:36:48.960
Okay.

00:36:48.960 --> 00:36:50.660
Because there's such a need for that.

00:36:50.660 --> 00:36:56.480
And so, yeah, it really just depends on the lab specific situation and what their focus is on and what they need.

00:36:56.480 --> 00:36:56.720
Cool.

00:36:56.720 --> 00:37:03.940
I guess if you have a good NSF grant and you got some extra money, it might be money well spent to hire some student who has good programming skills, right?

00:37:03.940 --> 00:37:04.460
Absolutely.

00:37:04.460 --> 00:37:05.020
Yeah.

00:37:05.020 --> 00:37:08.680
You talked about the video stuff that you're doing, the streaming video.

00:37:08.680 --> 00:37:12.640
Do you actually do analysis on that or is it just for you to go back and look at?

00:37:12.640 --> 00:37:13.000
Oh, yeah.

00:37:13.000 --> 00:37:13.400
Yeah.

00:37:13.400 --> 00:37:14.860
We do analysis on that.

00:37:14.860 --> 00:37:17.680
There's actually a pretty cool deep learning package out now.

00:37:17.680 --> 00:37:18.500
We didn't write it.

00:37:18.500 --> 00:37:24.240
Another lab did where you just give it the video frame and it can automatically segment kind of it's an animal.

00:37:24.240 --> 00:37:30.940
So, like where their paws are or where their like nose is looking or in some cases people have like you're talking about eye tracking.

00:37:30.940 --> 00:37:32.900
They do eye tracking in like mice now.

00:37:32.900 --> 00:37:34.260
They do eye tracking on mice.

00:37:34.260 --> 00:37:36.040
That was hard on humans in the 90s.

00:37:36.040 --> 00:37:36.580
Yeah.

00:37:36.580 --> 00:37:37.500
There's a lot of VR.

00:37:37.500 --> 00:37:40.980
So, they put kind of mice in this like VR system.

00:37:40.980 --> 00:37:41.520
Oh, wow.

00:37:41.520 --> 00:37:45.460
And they can like see where their little mouse pupil is looking on like the VR screen.

00:37:45.460 --> 00:37:45.820
Yeah.

00:37:45.820 --> 00:37:49.140
And do they show them different scenarios and they can detect that and they react to it?

00:37:49.140 --> 00:37:49.660
Oh, absolutely.

00:37:49.660 --> 00:37:50.380
Incredible.

00:37:50.380 --> 00:37:50.920
So, yeah.

00:37:50.920 --> 00:38:00.120
And a lot of stuff, at least in our field, the Nobel Prize was awarded for you stick some electrodes in the hippocampus part of your brain that's important for learning and memory.

00:38:00.120 --> 00:38:03.740
And then you have the animal kind of run around some environment.

00:38:03.740 --> 00:38:07.400
And then you take some video data of kind of where they were running the environment.

00:38:07.720 --> 00:38:15.400
And if you were only looking at the brain data, you can predict to like 90 some percent accuracy the location of the animal.

00:38:15.400 --> 00:38:20.480
So, you can show this kind of this correspondence that inside the brain is a map of kind of the environment.

00:38:20.480 --> 00:38:25.740
Our stuff, we're taking that a little one step further that says this map is not just for space.

00:38:25.740 --> 00:38:28.080
It's for non-spatial and other things too.

00:38:28.480 --> 00:38:36.920
There's this kind of network of information in the brain that the animal can kind of like navigate through, even if they're just standing still but thinking about some sort of problem.

00:38:36.920 --> 00:38:42.860
But we use video data to validate what the animal's doing or check what kind of tasks they're doing and so on.

00:38:42.860 --> 00:38:48.600
So, yeah, a lot of multimodal heterogeneous data that each needs its own funky pre-processing.

00:38:48.600 --> 00:38:53.540
And depending on the task at hand, you're writing something new to ask that question.

00:38:53.540 --> 00:38:54.660
So, is that OpenCV?

00:38:54.860 --> 00:39:00.540
Yeah, my stuff is OpenCV and streamed over sockets and some Django webpage.

00:39:00.540 --> 00:39:01.340
It's fun.

00:39:01.340 --> 00:39:02.880
It's cool to build.

00:39:02.880 --> 00:39:03.680
That sounds really cool.

00:39:03.680 --> 00:39:04.400
Yeah, absolutely.

00:39:04.400 --> 00:39:07.040
So, what kind of questions are you answering with the video?

00:39:07.040 --> 00:39:07.580
Yeah.

00:39:07.580 --> 00:39:11.620
Or is it just to correlate back with the time series of what you're measuring in the brain?

00:39:11.620 --> 00:39:14.820
So, like I said, the Nobel Prize was for this spatial map.

00:39:14.820 --> 00:39:16.840
We're doing this non-spatial stuff.

00:39:16.840 --> 00:39:23.320
And so, we kind of do both in the lab where we have an animal kind of run around and then we have an animal just kind of sit still

00:39:23.320 --> 00:39:25.160
and do some sort of mental task.

00:39:25.160 --> 00:39:31.480
In our case, it's a – they have to memorize a sequence of odors and if the sequence gets shuffled, they make a different choice.

00:39:31.480 --> 00:39:37.260
And so, we're basically showing how does the brain work for the spatial part versus the non-spatial part?

00:39:37.260 --> 00:39:39.060
What's similar about these two things?

00:39:39.060 --> 00:39:40.560
What's different about these things?

00:39:40.560 --> 00:39:50.140
And we show that the – one of our recent papers was that the brain uses a lot of the similar mechanisms to navigate space as it does to navigate this kind of non-spatial odor task.

00:39:50.140 --> 00:39:58.260
But we also showed that there's this mechanism that the brain uses to take kind of discrete memories and link them together into some kind of mirror hole.

00:39:58.500 --> 00:40:03.000
Best case being like this talk we've been talking back and forth for 30-some minutes now.

00:40:03.000 --> 00:40:05.460
Inside, there's kind of chunks of the conversation.

00:40:05.460 --> 00:40:10.920
So, if tomorrow someone was to ask you, what did you and that neuroscience guy talk about on your podcast?

00:40:10.920 --> 00:40:17.600
You would kind of rattle off this story of, oh, we talked about history of Python and this and this and this, right?

00:40:17.600 --> 00:40:24.520
This, this, and this are each kind of discrete memories that in your brain you kind of lock together and store them.

00:40:24.520 --> 00:40:28.380
So, you could use them, make decisions about them and so on and so on.

00:40:28.380 --> 00:40:33.860
Think about it as a whole, not just the little ideas, every little idea, but like just the big concept of it, right?

00:40:33.860 --> 00:40:34.680
Exactly, yeah.

00:40:34.680 --> 00:40:37.160
And it's a fundamental thing that the brain does.

00:40:37.160 --> 00:40:42.680
Like people say humans are storytellers and your life is kind of the sequence of events of stories.

00:40:42.680 --> 00:40:44.820
And so, you use that every single day.

00:40:44.820 --> 00:40:52.700
And across a bunch of diseases, that's one of the first things to actually be impaired, whether it's addiction or schizophrenia or Alzheimer's.

00:40:52.700 --> 00:40:59.200
That kind of ability to link things in time and link them well and make decisions about them starts to get impaired.

00:40:59.200 --> 00:41:01.460
That's not great when that happens, but that is what happens, right?

00:41:01.460 --> 00:41:02.540
Absolutely, yeah.

00:41:02.540 --> 00:41:15.520
But as with the software engineering practices, for lack of a better word, that you would recommend that maybe other grad students, professors who are feeling like they're not, they don't have their software game fully together, pay attention to it.

00:41:15.520 --> 00:41:17.040
And maybe what should they ignore, right?

00:41:17.120 --> 00:41:19.720
Like, should they pay attention to like source control and get up?

00:41:19.720 --> 00:41:23.240
Should they have unit tests or, you know, what should they pay attention to or not?

00:41:23.240 --> 00:41:24.620
First off, no one writes tests.

00:41:24.620 --> 00:41:28.500
That is just only the very few, very well put together.

00:41:28.500 --> 00:41:31.360
And usually people who just came from industry write tests.

00:41:31.360 --> 00:41:31.700
Sure.

00:41:31.700 --> 00:41:32.480
Which is an issue.

00:41:32.480 --> 00:41:35.060
But yeah, first off, just learn Python.

00:41:35.060 --> 00:41:39.360
I've said that hundreds of times and I'm preaching to the choir in this audience.

00:41:39.360 --> 00:41:40.660
You are, for sure.

00:41:41.000 --> 00:41:45.320
Learn Python is honestly, there's not much better you could learn.

00:41:45.320 --> 00:41:49.040
And two, it's, you know, it's quintessential automation stuff.

00:41:49.040 --> 00:41:54.200
So it's really just think about the things that you're doing, the spreadsheets or, you know, the simple things.

00:41:54.200 --> 00:41:59.020
And really just ask yourself, if you find yourself doing any repetitive tasks, that's a software problem.

00:41:59.020 --> 00:42:01.360
Those are the things to kind of look at first.

00:42:01.500 --> 00:42:06.780
So you have your text editor in one window, Google in the other, and stack overflow your way to learning.

00:42:06.780 --> 00:42:12.460
And so the way people, I think, really do kind of teach themselves Python is probably the best way to learn.

00:42:12.460 --> 00:42:18.840
But nevertheless, I think there is a real need for, and again, we're starting to see more of it, just formal education.

00:42:18.840 --> 00:42:28.720
Even if it's just a course, our program is really great that they started to teach a Python course just because the students requested it because they knew how important it was.

00:42:28.720 --> 00:42:31.260
Like a Python for neuroscience?

00:42:31.260 --> 00:42:32.180
Exactly.

00:42:32.180 --> 00:42:32.620
Okay.

00:42:32.620 --> 00:42:33.080
Yeah.

00:42:33.080 --> 00:42:37.080
I mean, you just work your way through if statements for loops, data types.

00:42:37.080 --> 00:42:44.240
You probably also, I'm just guessing you get a chance to work with some of these external libraries that are relevant to studies they're doing, right?

00:42:44.240 --> 00:42:46.660
Rather than, here's an example of stock market data.

00:42:46.660 --> 00:42:47.920
You're like, great, not a trader.

00:42:47.920 --> 00:42:49.820
I don't want to be a programmer.

00:42:49.820 --> 00:42:50.800
Why am I here, you know?

00:42:50.800 --> 00:42:52.000
Yeah, it's really relevant.

00:42:52.000 --> 00:42:58.140
And I think it's just kind of seeing like, oh, yeah, I would do that this way, but this is so much easier if I use Python.

00:42:58.460 --> 00:42:59.940
And I can use it in Python.

00:42:59.940 --> 00:43:05.260
And just seeing that, oh, it's not as bad as the mountain looks a lot higher when you're at the base than the summit.

00:43:05.260 --> 00:43:06.060
So it does.

00:43:06.060 --> 00:43:11.980
Seeing it done once is usually enough to kind of tell people it's not as bad as you originally think.

00:43:11.980 --> 00:43:12.240
Yeah.

00:43:12.240 --> 00:43:14.040
I feel like maybe I saw it this way.

00:43:14.040 --> 00:43:16.020
I certainly know a lot of other people see it this way.

00:43:16.020 --> 00:43:17.040
I mean, when I was younger.

00:43:17.040 --> 00:43:18.860
But a lot of people see it this way as well.

00:43:18.860 --> 00:43:22.340
Is it like you got to be crazy smart to do programming.

00:43:22.340 --> 00:43:23.500
It's really challenging.

00:43:24.380 --> 00:43:27.720
It's kind of one of those things that only a few people can do.

00:43:27.720 --> 00:43:33.460
And then you get into it and you're like, oh, it's not a few really huge steps and things you've got to solve.

00:43:33.460 --> 00:43:35.200
It's like a thousand small steps.

00:43:35.200 --> 00:43:38.460
And each one of the little small steps, you're like, that was actually easy.

00:43:38.460 --> 00:43:39.140
That's no big deal.

00:43:39.140 --> 00:43:40.120
What's the next step?

00:43:40.260 --> 00:43:42.300
And you get to the end, you're like, where was the big step?

00:43:42.300 --> 00:43:43.520
Where was it really hard, right?

00:43:43.520 --> 00:43:44.360
Yeah, absolutely.

00:43:44.360 --> 00:43:44.860
Yeah.

00:43:44.860 --> 00:43:51.160
Do you have some experience where people in the department or people that worked with you are like, oh, I'm not a programmer.

00:43:51.160 --> 00:43:51.960
I don't want to do this stuff.

00:43:51.960 --> 00:43:56.760
Then they kind of got into it and really found out that programming was something they really liked.

00:43:56.760 --> 00:43:58.360
Any converts out there?

00:43:58.360 --> 00:43:59.800
Yeah, I would say so.

00:43:59.800 --> 00:44:01.700
I mean, I think there's kind of two kinds of people.

00:44:01.700 --> 00:44:04.020
There's people who program just because, what is it?

00:44:04.020 --> 00:44:06.000
The programming is an art book or whatever.

00:44:06.000 --> 00:44:08.560
They love it just for the sake of loving.

00:44:08.900 --> 00:44:11.640
And I'm probably closer to those kind of people, right?

00:44:11.640 --> 00:44:14.200
I just think it's the coolest thing, like academic.

00:44:14.200 --> 00:44:18.240
But then there's the people who just kind of see it as like it's a tool like anything else.

00:44:18.240 --> 00:44:23.000
And so you could be an expert in a drill or you could just know to pick up a drill.

00:44:23.000 --> 00:44:32.240
That's kind of the majority of people is that it's just another tool in their toolkit, especially for a scientist, just to answer the question that you're trying to answer.

00:44:32.240 --> 00:44:38.460
And I would even flip the reverse where there's been some times where I've maybe even used Python too much.

00:44:38.540 --> 00:44:43.460
In the sense that like I made a problem more because it's like the automation dilemma, right?

00:44:43.460 --> 00:44:46.820
It's like, do I spend an hour automating this when I could do it in 10 minutes?

00:44:46.820 --> 00:44:49.440
You got to do it a lot of times and all of a sudden the hour is worth it.

00:44:49.440 --> 00:44:50.560
But if it turns out you don't.

00:44:50.560 --> 00:44:52.460
It's like I might need this a year from now.

00:44:52.460 --> 00:44:54.100
So I might as well just write the script.

00:44:54.100 --> 00:44:56.220
Whereas I could just do it in Excel.

00:44:56.220 --> 00:44:57.020
That's pretty standard.

00:44:57.020 --> 00:44:59.940
Standard problems we all run into in programming.

00:44:59.940 --> 00:45:01.620
It's like, write some code to do that.

00:45:01.620 --> 00:45:04.440
Or I could just be done with it for sure.

00:45:04.440 --> 00:45:05.060
All right.

00:45:05.060 --> 00:45:07.240
I think we've got time for a couple more topics.

00:45:07.240 --> 00:45:12.720
One thing that I think might be fun to talk about is publishing papers, right?

00:45:12.720 --> 00:45:16.060
Obviously, if you're in academics, especially in labs, you got to publish papers.

00:45:16.060 --> 00:45:19.340
Do you use notebooks and stuff like that for your papers?

00:45:19.340 --> 00:45:21.840
Or is that just kind of separate?

00:45:21.840 --> 00:45:22.480
What's...

00:45:22.480 --> 00:45:24.840
Yeah, like I said, notebooks are great for presentation.

00:45:24.840 --> 00:45:31.100
So yeah, I use notebooks kind of for development just because you can quickly run code and go

00:45:31.100 --> 00:45:32.540
back up and move things around.

00:45:32.540 --> 00:45:37.340
And so I kind of like that ability to kind of just a stream of consciousness, write code

00:45:37.340 --> 00:45:41.120
until you kind of like see how it's kind of working the prototype and then refactor out

00:45:41.120 --> 00:45:44.700
into an actual .py document or a package or something.

00:45:44.700 --> 00:45:47.000
So that's kind of been my workflow and it works pretty well.

00:45:47.000 --> 00:45:51.240
But then when you actually have the code and it works and it's robust, you actually want

00:45:51.240 --> 00:45:51.840
to put...

00:45:51.840 --> 00:45:52.600
There's a lot of figures.

00:45:52.600 --> 00:45:53.980
That's usually the main thing.

00:45:53.980 --> 00:45:55.180
So you kind of put all of that.

00:45:55.180 --> 00:45:56.300
Here's the data.

00:45:56.300 --> 00:45:57.640
Here's the pre-processing.

00:45:57.640 --> 00:45:58.780
Here's the figure one.

00:45:58.780 --> 00:46:03.320
Here's figure two, figure three in the notebook just so it's reproducible and other people

00:46:03.320 --> 00:46:06.560
can download it and rerun your code and that sort of thing.

00:46:06.560 --> 00:46:11.860
So I think that's slowly becoming kind of the standard approach for those labs that use

00:46:11.860 --> 00:46:14.280
Python and they share their code openly.

00:46:14.280 --> 00:46:15.680
That's kind of how they do it.

00:46:15.680 --> 00:46:20.880
Anything like executable books or any of those things that kind of produce printable?

00:46:20.880 --> 00:46:22.260
Output out of the notebooks?

00:46:22.260 --> 00:46:24.480
Like publishable output out of the notebooks?

00:46:24.480 --> 00:46:25.360
Not a lot.

00:46:25.360 --> 00:46:28.760
But there's one of the journals, it's called eLife.

00:46:28.760 --> 00:46:29.800
It's kind of...

00:46:29.800 --> 00:46:33.860
It's trying to like push the boundaries of what it means to publish a scientific paper.

00:46:33.860 --> 00:46:35.480
And so they kind of have...

00:46:35.480 --> 00:46:38.680
Because most papers are really just on the web nowadays.

00:46:38.680 --> 00:46:41.620
The journals aren't really physical journals as much anymore.

00:46:41.620 --> 00:46:47.320
They kind of have like papers as executable code where you can like plot the figure in

00:46:47.320 --> 00:46:50.840
the browser and kind of run through the notebook and just as an experiment.

00:46:50.840 --> 00:46:57.040
But it's pretty cool to kind of see these like new alternative ways to still convey the same

00:46:57.040 --> 00:46:57.840
findings.

00:46:57.840 --> 00:46:59.340
But you can play with it.

00:46:59.340 --> 00:47:00.400
You can come to CA out.

00:47:00.400 --> 00:47:02.600
So the methods are kind of implicit in the...

00:47:02.600 --> 00:47:03.800
What's the name of the journal?

00:47:03.800 --> 00:47:04.680
That's eLife.

00:47:04.680 --> 00:47:05.100
eLife.

00:47:05.100 --> 00:47:05.980
Okay, cool.

00:47:06.060 --> 00:47:11.000
Yeah, you probably, I suppose, need some way to capture the data output because you

00:47:11.000 --> 00:47:14.540
might not have access to the compute to recompute it.

00:47:14.540 --> 00:47:17.600
You know, somehow it's got to sort of be a static version.

00:47:17.600 --> 00:47:18.540
But that sounds really cool.

00:47:18.540 --> 00:47:19.020
Yeah.

00:47:19.020 --> 00:47:24.100
And especially for like most recently, some of our like trained models, it's becoming more

00:47:24.100 --> 00:47:27.960
important to just share the weights and share those sorts of things too.

00:47:27.960 --> 00:47:32.300
You can't just share the code to train the thing if people don't have the compute to actually

00:47:32.300 --> 00:47:33.540
train them themselves.

00:47:33.760 --> 00:47:37.320
It's kind of growing to not just sharing your data, not just sharing your code, but

00:47:37.320 --> 00:47:41.460
you need to share like the key derivatives of the preprocessing and those sorts of things.

00:47:41.460 --> 00:47:46.400
Or even just sharing the version numbers because there's been psychology or fMRI literature.

00:47:46.400 --> 00:47:50.620
There's like a bug in some version that like made a lot of the results null.

00:47:50.620 --> 00:47:56.060
And so, you know, one person could use version 3.7 of a package, but that had a bug, but people

00:47:56.060 --> 00:47:56.740
don't know that.

00:47:56.740 --> 00:48:00.600
So they claim it's not reproducible, but it's really just not the same algorithms.

00:48:00.600 --> 00:48:01.680
Yeah, yeah, yeah.

00:48:01.680 --> 00:48:06.960
Or like across languages, like if you rerun the same analysis in MATLAB versus Python versus

00:48:06.960 --> 00:48:12.220
R, especially complex ones, there's a lot of little design decisions under the hood that

00:48:12.220 --> 00:48:17.240
might tweak exactly how that regression fits or exactly how that, if you're statistically

00:48:17.240 --> 00:48:20.180
sampling, how the sampling works under the hood of those sorts of things.

00:48:20.180 --> 00:48:20.440
Awesome.

00:48:20.440 --> 00:48:22.680
Are you familiar with the Journal of Open Source Software?

00:48:22.680 --> 00:48:23.480
Yeah.

00:48:23.640 --> 00:48:25.080
I had the folks on from there.

00:48:25.080 --> 00:48:25.780
Yeah.

00:48:25.780 --> 00:48:27.640
I had them on quite a while ago.

00:48:27.640 --> 00:48:32.160
And I think they're trying to solve the interesting problem of if you take the time to create a

00:48:32.160 --> 00:48:37.100
really nice package for your area, you might have not taken your time writing the paper.

00:48:37.100 --> 00:48:40.660
And so you wouldn't get credit because you don't have as many papers to publish.

00:48:40.660 --> 00:48:44.700
So they let you publish like your open source work there, which I think is pretty cool.

00:48:44.700 --> 00:48:45.600
What do you think about that?

00:48:45.660 --> 00:48:46.980
We kind of had that same problem.

00:48:46.980 --> 00:48:51.620
One of the, I run a nonprofit called Continual AI.

00:48:51.620 --> 00:48:56.820
It does artificial intelligence and outreach and research, and we have conferences and all

00:48:56.820 --> 00:48:57.400
sorts of events.

00:48:57.400 --> 00:49:02.100
But one of the main things we've done is we built a deep learning library on top of PyTorch

00:49:02.100 --> 00:49:03.140
called Avalanche.

00:49:03.140 --> 00:49:08.580
And so like we had a really great community of mostly volunteers who just saw the need

00:49:08.580 --> 00:49:10.160
in the field and put it together.

00:49:10.160 --> 00:49:12.480
But then again, it's like a lot of us are academics.

00:49:12.480 --> 00:49:13.840
How do you present this?

00:49:13.840 --> 00:49:18.200
And so you write wrapper papers around kind of the framework.

00:49:18.200 --> 00:49:23.660
So that's kind of been the de facto way of like, it's not really a paper, but you still

00:49:23.660 --> 00:49:27.600
need to like, you know, share it and get credit for it and put your name on it.

00:49:27.600 --> 00:49:28.720
It's certainly an issue.

00:49:28.720 --> 00:49:32.500
I'm starting to see it not even just with software, but even with hardware, because hardware

00:49:32.500 --> 00:49:34.600
is becoming more open source in our field.

00:49:34.600 --> 00:49:39.260
And so you just kind of write like a paper about the hardware solution to some problem.

00:49:39.260 --> 00:49:39.680
That's cool.

00:49:39.680 --> 00:49:40.480
It's better than a patent.

00:49:40.480 --> 00:49:42.080
Yeah, it's definitely better than a patent.

00:49:42.080 --> 00:49:45.100
Patents, while they serve a purpose, are pretty evil.

00:49:45.100 --> 00:49:50.020
Let's wrap things up with maybe just, you know, you mentioned Continual AI.

00:49:50.020 --> 00:49:51.260
Tell people a bit about that.

00:49:51.260 --> 00:49:54.180
It's the largest nonprofit for continual learning.

00:49:54.180 --> 00:49:59.540
Continual learning in a nutshell is, say I have a neural network and I train my neural network

00:49:59.540 --> 00:50:01.220
to classify cats.

00:50:01.600 --> 00:50:03.620
And I classify cats to 90% accuracy.

00:50:03.620 --> 00:50:05.660
And we're like, yeah, this is why neural networks are great.

00:50:05.660 --> 00:50:09.680
I take that same trained neural network on cats and I train it on say dogs.

00:50:09.680 --> 00:50:10.740
It does really well.

00:50:10.740 --> 00:50:12.260
90% accuracy on dogs.

00:50:12.260 --> 00:50:14.600
We're really excited why neural networks are so great.

00:50:14.600 --> 00:50:18.660
But the issue is if I take that, again, the same network, I just trained it on dogs and

00:50:18.660 --> 00:50:19.940
previously trained it on cats.

00:50:19.940 --> 00:50:22.640
I try and test it on cats again.

00:50:22.640 --> 00:50:26.020
It's going to forget pretty much everything it learned about cats.

00:50:26.080 --> 00:50:27.620
And this is an old, old problem.

00:50:27.620 --> 00:50:31.820
Back in like, you know, the good old days when neural networks were connectionist models and

00:50:31.820 --> 00:50:34.840
it was computer scientists, it was the cognitive scientists.

00:50:34.840 --> 00:50:35.760
They noticed.

00:50:35.760 --> 00:50:37.540
Overtraining or something like that, right?

00:50:37.540 --> 00:50:38.480
Kind of overfitting.

00:50:38.480 --> 00:50:39.560
It's neurorelated.

00:50:39.560 --> 00:50:40.540
Yeah, it's very similar.

00:50:40.540 --> 00:50:41.620
Catastrophe forgetting.

00:50:42.140 --> 00:50:45.440
They call it the sequential learning problem, which is why I'm really interested in it because

00:50:45.440 --> 00:50:48.400
I'm really interested in, you know, continual learning and sequential memory.

00:50:48.400 --> 00:50:51.660
Or in neuroscience, it's called the stability plasticity problem.

00:50:51.660 --> 00:50:52.820
So when do you learn?

00:50:52.820 --> 00:50:53.720
When do you remember?

00:50:53.720 --> 00:51:01.260
And so over the last, since we started the organization 2018, the field has kind of exploded

00:51:01.260 --> 00:51:06.600
just because there's such a need for overcoming this across a lot of use cases.

00:51:06.600 --> 00:51:09.380
So like a lot of times you can only see the data once.

00:51:09.380 --> 00:51:14.020
So the way you solve the problem generally is you just shuffle in cats and dogs into the

00:51:14.020 --> 00:51:15.900
same data set and retrain your model.

00:51:15.900 --> 00:51:18.420
But now the neural networks are getting bigger and bigger and bigger.

00:51:18.420 --> 00:51:20.620
Retraining is getting costlier and costlier.

00:51:20.620 --> 00:51:24.500
You can't just have, you can't train a network on petabytes every time you want to update it.

00:51:24.500 --> 00:51:29.940
That's even if you have access to the data and the storage to save it and so on and so forth.

00:51:29.940 --> 00:51:31.860
So clever ways to solve the problem.

00:51:31.860 --> 00:51:33.660
And so we're kind of around that.

00:51:33.660 --> 00:51:38.540
We have neuroscientists, we have computer scientists, AI researchers across academia,

00:51:38.940 --> 00:51:42.980
industry, all that are just a bunch of people really interested in this problem to just come

00:51:42.980 --> 00:51:45.400
together and share papers, share ideas.

00:51:45.400 --> 00:51:46.760
We just had a conference.

00:51:46.760 --> 00:51:52.220
We sponsor a lot of competitions for people to kind of put forward an idea to some problem

00:51:52.220 --> 00:51:53.840
that we kind of put out every year.

00:51:53.840 --> 00:51:58.080
So it's been really, really exciting to kind of see the community grow over the years and

00:51:58.080 --> 00:52:00.300
all the tools and fun things that's kind of come out.

00:52:00.300 --> 00:52:02.300
Well, it's definitely a hot topic right now.

00:52:02.300 --> 00:52:02.800
Absolutely.

00:52:02.800 --> 00:52:06.940
The cognitive scientists and neuroscientists studied neural networks and stuff.

00:52:06.940 --> 00:52:08.920
And it was kind of like, well, maybe this model stuff.

00:52:08.920 --> 00:52:12.780
And then now we're in the time of LLMs and the world has gone crazy.

00:52:12.780 --> 00:52:13.360
Absolutely.

00:52:13.900 --> 00:52:18.560
I said we were going to close out with a continual AI, but let me just ask, what are your thoughts

00:52:18.560 --> 00:52:19.520
on LLMs?

00:52:19.520 --> 00:52:20.660
Where the stuff's going?

00:52:20.660 --> 00:52:26.960
I mean, we all have exposure to it in different ways, but you've got this understanding of what

00:52:26.960 --> 00:52:28.660
they're trying to model it on quite a bit.

00:52:28.660 --> 00:52:31.360
So what do you guys in your space think of it?

00:52:31.360 --> 00:52:36.380
So the first lab I joined was, well, the first real lab I joined was a neuroscience lab where

00:52:36.380 --> 00:52:39.840
we were sticking wires in brains and actually doing real neuroscience.

00:52:39.840 --> 00:52:46.240
But I also started kind of simultaneously working with a cognitive scientist where we were working

00:52:46.240 --> 00:52:48.440
on the original word to them.

00:52:48.440 --> 00:52:51.960
So this is, in my mind, like the grandfather of the LLM.

00:52:51.960 --> 00:52:56.820
So this is the model that like overnight took Google Translate from being meh to pretty good.

00:52:56.820 --> 00:52:59.900
And it's just really at the heart of it, just an autoencoder.

00:53:00.220 --> 00:53:06.700
But we were really excited then doing kind of semantic modeling of how much further kind

00:53:06.700 --> 00:53:08.600
of deep learning could take language modeling.

00:53:08.600 --> 00:53:11.500
And then we were actually using it to study catastrophic forgetting.

00:53:11.500 --> 00:53:13.580
So does word to that catastrophically forget?

00:53:13.580 --> 00:53:15.420
And the punchline is it does.

00:53:15.420 --> 00:53:19.880
And that kind of got me jumped into really excited about continual learning and so on.

00:53:19.880 --> 00:53:25.740
So I saw kind of that trajectory then, and then kind of stepped out of it for a few years

00:53:25.740 --> 00:53:31.580
dug more deep into, you know, pure neuroscience and artificial intelligence from other angles.

00:53:32.220 --> 00:53:37.400
But I'd always been just so fascinated by this idea of like, say you take an AI and it could

00:53:37.400 --> 00:53:39.560
read every book or it could read the internet.

00:53:39.560 --> 00:53:41.760
Like, what would you be able to get?

00:53:41.760 --> 00:53:46.100
And that was kind of, you know, in my mind, like, well, seeing Word2Vec try and do the same

00:53:46.100 --> 00:53:50.220
thing and training it on my laptop, like, well, you know, it's going to take, it's going to take a

00:53:50.220 --> 00:53:51.420
minute till we get there.

00:53:51.420 --> 00:53:54.840
And I underestimated that drastically.

00:53:55.100 --> 00:53:57.440
It was like, almost no progress, almost no progress.

00:53:57.440 --> 00:53:58.880
Wow, what just happened?

00:53:58.880 --> 00:53:59.720
Right?

00:53:59.720 --> 00:54:05.320
It's a testament to statistical learning more than anything, which is just how much information

00:54:05.320 --> 00:54:10.080
can you just soak up and put together in a fancy new way and regurgitate back.

00:54:10.080 --> 00:54:15.520
I think the next big leap is going to be adding more cognition to that progress.

00:54:15.520 --> 00:54:21.100
So adding when an agent has a goal, when an agent kind of has to break down a series of

00:54:21.100 --> 00:54:25.820
steps to get to that goal, those kinds of things we don't see as much of.

00:54:25.820 --> 00:54:28.680
And that will kind of be the next big push.

00:54:28.680 --> 00:54:33.500
I think that'll kind of take all the cool things that LLMs can do now and kind of blow everyone

00:54:33.500 --> 00:54:38.760
away of just, if you can take the internet and put it on a seven gigabyte file, what can

00:54:38.760 --> 00:54:39.400
that get you?

00:54:39.400 --> 00:54:42.940
But what if you can take the internet, put it on a seven gigabyte file, but actually have

00:54:42.940 --> 00:54:48.140
some sort of logic and direction and the agent itself can actually navigate through its

00:54:48.140 --> 00:54:48.860
own thoughts?

00:54:49.280 --> 00:54:53.180
That's going to take us, I think, right to the borderline of-

00:54:53.180 --> 00:54:53.300
Terminator?

00:54:53.300 --> 00:54:53.840
Yeah.

00:54:53.840 --> 00:54:54.440
Not Terminator.

00:54:54.440 --> 00:54:55.080
I'm just kidding.

00:54:55.080 --> 00:54:55.900
It won't be Terminator.

00:54:55.900 --> 00:54:56.320
No.

00:54:56.320 --> 00:54:57.180
It won't be Terminator.

00:54:57.180 --> 00:54:59.680
But it'll be really an intelligent system.

00:54:59.680 --> 00:55:00.700
It's going to be super interesting.

00:55:00.700 --> 00:55:06.760
You know, you've got all this prompt engineering and these clever ways to kind of get the current

00:55:06.760 --> 00:55:10.980
LLMs in the right mindset, which is probably a personification.

00:55:10.980 --> 00:55:14.660
But you can tell it things like, here, I want you to tell me how to do this.

00:55:14.660 --> 00:55:15.640
And I'll come up with some answer.

00:55:15.640 --> 00:55:18.020
You can say, I want you to think step by step.

00:55:18.200 --> 00:55:22.280
And then all of a sudden you get a real different type of answer where it pulls out the pieces

00:55:22.280 --> 00:55:23.660
and it thinks about how it does it.

00:55:23.660 --> 00:55:24.920
And it's going to be interesting.

00:55:24.920 --> 00:55:29.180
You know, it's kind of like kind of stuff, but it just, it already knows how to think.

00:55:29.180 --> 00:55:31.060
You don't have to give it little weird clues.

00:55:31.060 --> 00:55:33.480
Like you're an expert in this and you're really good at it.

00:55:33.480 --> 00:55:35.740
Now I want to ask you a question about, oh, I'm good at it.

00:55:35.740 --> 00:55:35.920
Okay.

00:55:35.920 --> 00:55:36.700
I'll answer better.

00:55:37.000 --> 00:55:40.420
My favorite definition of AI is it's whatever computers can't do yet.

00:55:40.420 --> 00:55:40.700
Yeah.

00:55:40.700 --> 00:55:44.760
Because like, you know, 30 years ago, if we had this conversation, it'd be like, so what

00:55:44.760 --> 00:55:45.780
do you think of Deep Blue?

00:55:45.780 --> 00:55:51.540
Do you think Deep Blue, the AI that becomes probably chess, can, you know, think and is

00:55:51.540 --> 00:55:52.620
it going to take all our jobs?

00:55:52.620 --> 00:55:54.200
Or it's going to be, what can Watson do?

00:55:54.200 --> 00:55:55.940
Can it think and take all our jobs?

00:55:56.200 --> 00:56:01.140
And, you know, that was solved with tree search, which, you know, undergraduates in

00:56:01.140 --> 00:56:02.860
their second year CS class are learning.

00:56:02.860 --> 00:56:04.980
It's just a standard, it's search.

00:56:04.980 --> 00:56:06.520
People don't even think of search as AI.

00:56:06.520 --> 00:56:11.480
What if we just loaded every possible outcome into the chess thing and the steps and we just

00:56:11.480 --> 00:56:14.380
try to take, you know, traverse each step and see where it takes us, right?

00:56:14.380 --> 00:56:18.800
There's always going to be a room to grow, but, you know, from a cognitive science perspective,

00:56:18.800 --> 00:56:22.840
I think something far more interesting rather, you know, I think it's cool to see what computers

00:56:22.840 --> 00:56:23.460
can actually do.

00:56:23.460 --> 00:56:24.920
And I think they can do a hell of a lot more.

00:56:25.240 --> 00:56:29.040
But I think it's more interesting to kind of ask the more philosophical question of what

00:56:29.040 --> 00:56:30.680
does that actually mean for us?

00:56:30.680 --> 00:56:34.980
Because at every step of the way, when we develop something new in artificial intelligence, it

00:56:34.980 --> 00:56:39.600
tells us something a lot deeper about our own intelligence too, where back in the 50s and

00:56:39.600 --> 00:56:41.840
60s, they thought the chess meant intelligence.

00:56:41.840 --> 00:56:46.720
And so now we're kind of seeing with LLMs, if someone just reads a bunch of books and can

00:56:46.720 --> 00:56:49.120
memorize a bunch of books, does that mean they're intelligent?

00:56:49.120 --> 00:56:51.700
Because that's effectively what an LLM can do.

00:56:51.700 --> 00:56:53.920
It comes across as intelligent, right?

00:56:53.920 --> 00:56:57.560
It comes across that way to people like, oh, you have all the answers, but it doesn't

00:56:57.560 --> 00:56:59.320
mean you're good at problem solving necessarily.

00:56:59.360 --> 00:57:03.980
We're kind of peeling at this onion and we're kind of segmenting intelligence into its different

00:57:03.980 --> 00:57:10.040
categories to really kind of break it apart just from this vague word of intelligence into

00:57:10.040 --> 00:57:12.900
actually what are the parts that make something intelligent?

00:57:12.900 --> 00:57:14.080
What does it really mean?

00:57:14.080 --> 00:57:18.580
And what are still the things that like we thought were hard and are really easy or the

00:57:18.580 --> 00:57:20.240
things that we thought were easy and really hard?

00:57:20.320 --> 00:57:25.980
Because any LLM you have now can't chew gum and walk to the store and buy you something

00:57:25.980 --> 00:57:28.140
to eat and then play you in chess.

00:57:28.140 --> 00:57:34.080
And so the general and general AI isn't just there for to make it sound grander.

00:57:34.080 --> 00:57:38.720
It's there because that's actually something that makes humans very, very unique is that I can

00:57:38.720 --> 00:57:44.400
have this conversation with you, write code, prepare an omelet, walk a dog and do all of these

00:57:44.400 --> 00:57:45.460
things all at once.

00:57:45.620 --> 00:57:46.900
And I started as a babe.

00:57:46.900 --> 00:57:50.140
And have feelings and thoughts and introspection about it and all that.

00:57:50.140 --> 00:57:53.860
Hopes, dreams, like ketchup and not tomatoes and all sorts of other.

00:57:53.860 --> 00:57:54.100
Yeah.

00:57:54.100 --> 00:57:54.860
Super interesting.

00:57:54.860 --> 00:57:58.300
So are you, are you pretty positive on, on where stuff's going?

00:57:58.300 --> 00:58:03.200
I'm less concerned about the AI itself and I'm more concerned about just how we react to it.

00:58:03.200 --> 00:58:06.000
And if we act, react intelligent, we react well.

00:58:06.000 --> 00:58:08.140
We went through the industrial revolution.

00:58:08.140 --> 00:58:10.100
We've went through the steel age.

00:58:10.100 --> 00:58:14.960
We're starting to go through the cognitive revolution or whatever people are going to call this a hundred

00:58:14.960 --> 00:58:15.580
years ago.

00:58:15.580 --> 00:58:17.680
I think by and large, people are going to be okay.

00:58:17.680 --> 00:58:22.100
I think we just need to, you know, have good policies, make sure that people do it responsibly,

00:58:22.100 --> 00:58:23.000
people do it well.

00:58:23.000 --> 00:58:26.660
And that's going to be the hard part is just how do we manage the transition?

00:58:26.660 --> 00:58:31.980
Well, how do we take a whole labor force whose jobs will be gone?

00:58:31.980 --> 00:58:37.280
Like there's no economic incentive to keep their jobs and retrain them in a really smart and sensible

00:58:37.280 --> 00:58:37.720
way.

00:58:37.720 --> 00:58:41.840
So people's livelihoods don't just go away to, to maximize the dollar.

00:58:42.300 --> 00:58:48.080
Those are kind of problems that are going to need good policy and clever solutions and a

00:58:48.080 --> 00:58:51.000
lot of research to actually sit down and handle well.

00:58:51.000 --> 00:58:52.500
But AI isn't going to go anywhere.

00:58:52.500 --> 00:58:56.840
Just like computers haven't went anywhere, but it's not Terminator that we should worry about.

00:58:56.840 --> 00:58:57.480
No, absolutely.

00:58:57.480 --> 00:58:58.480
It's certainly not.

00:58:58.480 --> 00:58:59.040
I was joking.

00:58:59.040 --> 00:59:05.160
We should worry about disinformation and politics and news and all that stuff.

00:59:05.160 --> 00:59:08.020
I think people get so hung up on all the negatives that we kind of forget.

00:59:08.020 --> 00:59:10.420
Like we're developing these tools for a reason.

00:59:10.420 --> 00:59:13.560
Scientists are spending so much time and we're excited about them for a reason.

00:59:13.560 --> 00:59:17.900
One being that I used to work on proteins, trying to find the structure of proteins.

00:59:17.900 --> 00:59:20.100
And that was one protein a year.

00:59:20.100 --> 00:59:22.260
It would take one year to find the structure of protein.

00:59:22.260 --> 00:59:23.340
And now I can run this.

00:59:23.340 --> 00:59:27.580
I took the same sequence that we found and ran it through AlphaFold, which is DeepMind's

00:59:27.580 --> 00:59:29.020
protein folding software.

00:59:29.020 --> 00:59:30.740
And I could do it in five minutes.

00:59:30.740 --> 00:59:35.880
I mean, those are the things that will really like catalyze science and technology and healthcare

00:59:35.880 --> 00:59:38.720
and actually solve the problems we want to solve.

00:59:38.720 --> 00:59:40.320
So that's what I think we should do.

00:59:40.320 --> 00:59:44.580
I think I heard even some AI stuff coming up with some new battery chemistry, potentially.

00:59:44.580 --> 00:59:45.720
Everything.

00:59:45.720 --> 00:59:53.000
How do you appropriately kind of harness like a fusion ring and like a tokamak reactor or something

00:59:53.000 --> 00:59:53.540
like that?

00:59:53.540 --> 00:59:54.220
Everything.

00:59:54.220 --> 01:00:00.680
Even to how do you route a PCB with like millions of traces affected?

01:00:00.860 --> 01:00:05.320
So it's a tool for the mind and it's not going to put our minds out of work.

01:00:05.320 --> 01:00:07.400
Like you said a long time ago when you were in your eye track.

01:00:07.400 --> 01:00:07.860
Yeah, exactly.

01:00:07.860 --> 01:00:09.600
It's like a different view of that thing.

01:00:09.600 --> 01:00:14.140
The same reason that none of us want to sit around and churn butter and go till the fields

01:00:14.140 --> 01:00:16.620
and walk to work.

01:00:16.620 --> 01:00:19.680
I don't dislike my clothes washer.

01:00:19.680 --> 01:00:20.460
Not at all.

01:00:20.460 --> 01:00:21.280
Yeah.

01:00:21.280 --> 01:00:21.860
Awesome.

01:00:21.860 --> 01:00:22.260
All right.

01:00:22.260 --> 01:00:27.100
Well, thanks for giving us a look inside your lab, inside your research and the field.

01:00:27.100 --> 01:00:29.260
And then just, you know, share what you're about and up to.

01:00:29.260 --> 01:00:29.700
It's been great.

01:00:29.700 --> 01:00:30.640
Yeah, yeah, yeah.

01:00:30.840 --> 01:00:31.720
Thanks for having me.

01:00:31.720 --> 01:00:36.460
Yeah, it's been really great to, at least for the years that I've been in research, seeing

01:00:36.460 --> 01:00:38.220
how pivotal Python has been.

01:00:38.220 --> 01:00:43.140
And I think that's one of the big things that probably goes unnoticed by a lot of developers

01:00:43.140 --> 01:00:46.600
when they're actually writing their code to solve whatever problem they're solving is

01:00:46.600 --> 01:00:52.520
that someone who's wrote the NumPy library or the scikit-learn library or, you know, Jupyter

01:00:52.520 --> 01:00:56.940
Notebooks has actively played a part in curing diseases and making people's lives better.

01:00:57.300 --> 01:01:00.180
And those stories usually don't kind of come to the forefront.

01:01:00.180 --> 01:01:01.960
It's not a direct line, right?

01:01:01.960 --> 01:01:06.940
But the research was done and facilitated by these open source tools and then discoveries

01:01:06.940 --> 01:01:07.380
were made.

01:01:07.380 --> 01:01:10.660
Like you said, that's the difference between people getting cured in 10 years or getting

01:01:10.660 --> 01:01:11.420
cured in a year.

01:01:11.420 --> 01:01:13.220
And that's thousands of lives.

01:01:13.640 --> 01:01:17.140
And so you might not think about it when you're sitting behind your desk, you know,

01:01:17.140 --> 01:01:18.600
making something usable.

01:01:18.600 --> 01:01:23.200
But for every day a PhD student doesn't have to like pull their hair out and debug some software

01:01:23.200 --> 01:01:24.840
when it's well-written and it works well.

01:01:24.840 --> 01:01:27.160
That's a day that they can find something new.

01:01:27.160 --> 01:01:27.660
That's awesome.

01:01:27.660 --> 01:01:28.080
Yeah.

01:01:28.080 --> 01:01:28.940
Very inspiring.

01:01:28.940 --> 01:01:30.340
Let's leave it there, Keelan.

01:01:30.340 --> 01:01:31.640
Thank you for being on the show.

01:01:31.640 --> 01:01:32.220
Absolutely.

01:01:32.220 --> 01:01:32.680
Yeah.

01:01:32.680 --> 01:01:33.480
It's been great to talk to you.

01:01:33.480 --> 01:01:34.100
Thank you so much.

01:01:34.160 --> 01:01:34.320
Yeah.

01:01:34.320 --> 01:01:34.840
Thanks for coming.

01:01:34.840 --> 01:01:38.340
This has been another episode of Talk Python to Me.

01:01:38.340 --> 01:01:40.160
Thank you to our sponsors.

01:01:40.160 --> 01:01:41.760
Be sure to check out what they're offering.

01:01:41.760 --> 01:01:43.180
It really helps support the show.

01:01:43.180 --> 01:01:49.380
It's time to stop asking relational databases to do more than they were made for and simplify

01:01:49.380 --> 01:01:51.620
complex data models with graphs.

01:01:51.620 --> 01:01:58.060
Check out the sample FastAPI project and see what Neo4j, a native graph database, can do

01:01:58.060 --> 01:01:58.460
for you.

01:01:58.460 --> 01:02:02.880
Find out more at talkpython.fm/Neo4j.

01:02:03.400 --> 01:02:07.140
This episode is sponsored by Posit Connect from the makers of Shiny.

01:02:07.140 --> 01:02:11.660
Publish, share, and deploy all of your data projects that you're creating using Python.

01:02:11.660 --> 01:02:18.240
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

01:02:18.240 --> 01:02:20.620
Posit Connect supports all of them.

01:02:20.620 --> 01:02:26.300
Try Posit Connect for free by going to talkpython.fm/Posit, P-O-S-I-T.

01:02:26.300 --> 01:02:28.160
Want to level up your Python?

01:02:28.160 --> 01:02:32.220
We have one of the largest catalogs of Python video courses over at Talk Python.

01:02:32.660 --> 01:02:37.380
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:02:37.380 --> 01:02:40.060
And best of all, there's not a subscription in sight.

01:02:40.060 --> 01:02:42.960
Check it out for yourself at training.talkpython.fm.

01:02:42.960 --> 01:02:45.080
Be sure to subscribe to the show.

01:02:45.080 --> 01:02:47.840
Open your favorite podcast app and search for Python.

01:02:47.840 --> 01:02:49.160
We should be right at the top.

01:02:49.160 --> 01:02:54.320
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:02:54.500 --> 01:02:58.520
and the direct RSS feed at /rss on talkpython.fm.

01:02:58.520 --> 01:03:01.500
We're live streaming most of our recordings these days.

01:03:01.500 --> 01:03:04.900
If you want to be part of the show and have your comments featured on the air,

01:03:04.900 --> 01:03:09.320
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:03:10.020 --> 01:03:11.380
This is your host, Michael Kennedy.

01:03:11.380 --> 01:03:12.680
Thanks so much for listening.

01:03:12.680 --> 01:03:13.840
I really appreciate it.

01:03:13.840 --> 01:03:15.740
Now get out there and write some Python code.

01:03:15.740 --> 01:03:16.740
Bye.

01:03:16.740 --> 01:03:17.740
Bye.

01:03:17.740 --> 01:03:18.740
Bye.

01:03:18.740 --> 01:03:19.740
Bye.

01:03:19.740 --> 01:03:20.740
Bye.

01:03:20.740 --> 01:03:21.740
Bye.

01:03:21.740 --> 01:03:22.740
Bye.

01:03:22.740 --> 01:03:23.740
Bye.

01:03:23.740 --> 01:03:24.740
Bye.

01:03:24.740 --> 01:03:25.740
Bye.

01:03:25.740 --> 01:03:26.740
Bye.

01:03:26.740 --> 01:03:27.740
Bye.

01:03:27.740 --> 01:03:28.740
Bye.

01:03:28.740 --> 01:03:29.740
Bye.

01:03:29.740 --> 01:03:30.740
Bye.

01:03:30.740 --> 01:03:31.740
Bye.

01:03:31.740 --> 01:03:32.740
Bye.

01:03:32.740 --> 01:03:33.240
you

01:03:33.240 --> 01:03:35.240
Thank you.

01:03:35.240 --> 01:03:36.640
Thank you.

