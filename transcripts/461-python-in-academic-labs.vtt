WEBVTT

00:00:00.000 --> 00:00:02.480
Do you use Python in an academic setting?

00:00:02.480 --> 00:00:05.860
Maybe you run a research lab or teach courses using Python.

00:00:05.860 --> 00:00:08.760
Maybe you're even a student using Python.

00:00:08.760 --> 00:00:11.600
Whichever it is, you'll find a ton of great advice in this episode.

00:00:11.600 --> 00:00:16.680
I talked with Keelen Cooper about how he's using Python in his neuroscience lab at the

00:00:16.680 --> 00:00:19.120
University of California, Irvine.

00:00:19.120 --> 00:00:23.400
And Keelen wanted me to let you know that if any developers who are not themselves scientists

00:00:23.400 --> 00:00:28.160
are interested in learning more about scientific research and ways you might be able to contribute,

00:00:28.160 --> 00:00:30.440
please don't hesitate to reach out to him.

00:00:30.440 --> 00:00:35.160
This is Talk Python to Me, episode 461, recorded March 14th, 2024.

00:00:35.160 --> 00:00:39.280
Are you ready for your host, please?

00:00:39.280 --> 00:00:42.200
You're listening to Michael Kennedy on Talk Python to Me.

00:00:42.200 --> 00:00:50.600
Live from Portland, Oregon, and this segment was made with Python.

00:00:50.600 --> 00:00:54.040
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:54.040 --> 00:00:55.880
This is your host, Michael Kennedy.

00:00:55.880 --> 00:01:00.800
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:01:00.800 --> 00:01:03.440
both on fosstodon.org.

00:01:03.440 --> 00:01:08.680
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:01:08.680 --> 00:01:12.160
We've started streaming most of our episodes live on YouTube.

00:01:12.160 --> 00:01:18.280
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be

00:01:18.280 --> 00:01:20.060
part of that episode.

00:01:20.060 --> 00:01:22.840
This episode is sponsored by Neo4j.

00:01:22.840 --> 00:01:28.160
It's time to stop asking relational databases to do more than they were made for and simplify

00:01:28.160 --> 00:01:31.000
complex data models with graphs.

00:01:31.000 --> 00:01:36.540
Check out the sample FastAPI project and see what Neo4j, a native graph database, can do

00:01:36.540 --> 00:01:37.540
for you.

00:01:37.540 --> 00:01:42.320
Find out more at talkpython.fm/neo4j.

00:01:42.320 --> 00:01:46.360
And it's brought to you by Posit Connect from the makers of Shiny.

00:01:46.360 --> 00:01:50.600
Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:50.600 --> 00:01:57.560
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:57.560 --> 00:01:59.480
Posit Connect supports all of them.

00:01:59.480 --> 00:02:03.920
Try Posit Connect for free by going to talkpython.fm/posit.

00:02:03.920 --> 00:02:04.920
P-O-S-I-T.

00:02:04.920 --> 00:02:06.960
- Hello, how are you?

00:02:06.960 --> 00:02:07.960
- I'm doing well.

00:02:07.960 --> 00:02:13.040
So awesome to have you here on Talk Python and talking academics.

00:02:13.040 --> 00:02:17.840
I didn't tell you before we hit record, but I spent a long time at universities and I

00:02:17.840 --> 00:02:18.840
just love them.

00:02:18.840 --> 00:02:23.320
They're such cool places and it's gonna be really fun to get a look inside how Python's

00:02:23.320 --> 00:02:24.320
being used there.

00:02:24.320 --> 00:02:25.320
- Yeah, well, yeah.

00:02:25.320 --> 00:02:26.320
Thank you so much for having me.

00:02:26.320 --> 00:02:28.200
And yes, I too love universities.

00:02:28.200 --> 00:02:33.280
It's kind of like all the coolest parts of humanity just kind of intermixing in one place.

00:02:33.280 --> 00:02:37.000
So yeah, I'd love to kind of peel back the curtain on how things are going.

00:02:37.000 --> 00:02:38.000
- Yeah, yeah.

00:02:38.000 --> 00:02:43.960
Well, we talked about how you and your colleagues use Python and data science inside of your

00:02:43.960 --> 00:02:46.040
neurology research lab.

00:02:46.040 --> 00:02:49.280
But before we dive into that, let's just get a bit of background on yourself.

00:02:49.280 --> 00:02:50.280
Who are you?

00:02:50.280 --> 00:02:51.280
How do you get into Python?

00:02:51.280 --> 00:02:52.280
All those things.

00:02:52.280 --> 00:02:53.280
- So I'm Keelen Cooper.

00:02:53.280 --> 00:02:56.840
I'm a neuroscientist at the University of California, Irvine.

00:02:56.840 --> 00:03:01.520
So Southern California, 15 minutes from the beach and an hour from the mountains.

00:03:01.520 --> 00:03:05.280
But I'm originally from the middle of nowhere, Indiana.

00:03:05.280 --> 00:03:09.000
And I started playing with computers and code when I was young.

00:03:09.000 --> 00:03:13.840
So like middle school-ish, just ripping apart computers and seeing what was in them and

00:03:13.840 --> 00:03:18.320
then trying to put them back together and feeling bad when they didn't work right after.

00:03:18.320 --> 00:03:22.040
And then the typical, you know, tweaking the software when you don't like what it does

00:03:22.040 --> 00:03:23.360
until you make it work.

00:03:23.360 --> 00:03:29.080
And then probably my senior year of high school is when I started teaching myself Python.

00:03:29.080 --> 00:03:32.040
And it was because we had to do some for some government class actually.

00:03:32.040 --> 00:03:33.040
- Oh, wow.

00:03:33.040 --> 00:03:34.040
Okay.

00:03:34.040 --> 00:03:36.300
- And we had to learn, we were learning about the stock market.

00:03:36.300 --> 00:03:40.480
And every day you'd have to spend like 15 minutes going to like some stock website and

00:03:40.480 --> 00:03:42.560
like filling out your fake stocks.

00:03:42.560 --> 00:03:47.200
And so I wrote a really small Python script that would just pull the data from the website

00:03:47.200 --> 00:03:49.720
and populate like an Excel spreadsheet.

00:03:49.720 --> 00:03:52.880
And so every day the kids in the class were just like going through and like spending

00:03:52.880 --> 00:03:55.200
15, 20 minutes by hand writing it down.

00:03:55.200 --> 00:03:56.200
And I would just sit there.

00:03:56.200 --> 00:03:57.200
- That's awesome.

00:03:57.200 --> 00:04:00.120
- And so that was kind of the first time I was like, wow, this whole automation thing

00:04:00.120 --> 00:04:01.960
is pretty sweet.

00:04:01.960 --> 00:04:05.620
From there, Python just kind of, I caught the bug pretty early.

00:04:05.620 --> 00:04:07.040
Python was definitely the way to go.

00:04:07.040 --> 00:04:08.040
- Yeah.

00:04:08.040 --> 00:04:09.480
Was Python your first programming language?

00:04:09.480 --> 00:04:14.600
- My first programming language was the Windows registry and trying to undo all of the mistakes

00:04:14.600 --> 00:04:15.600
of the operating system.

00:04:15.600 --> 00:04:20.320
- It's been a while since I've been in the Windows registry, but good old regedit.

00:04:20.320 --> 00:04:22.200
- I switched to Linux pretty quick.

00:04:22.200 --> 00:04:23.200
In Linux and Unix.

00:04:23.200 --> 00:04:24.200
- Are you still on the Linux?

00:04:24.200 --> 00:04:25.200
- Mostly.

00:04:25.200 --> 00:04:26.200
My desktops are all Linux.

00:04:26.200 --> 00:04:27.560
My servers are obviously all Linux.

00:04:27.560 --> 00:04:32.440
I like Mac for a laptop just because, you know, Linux has this thing where you tinker

00:04:32.440 --> 00:04:33.440
with it.

00:04:33.440 --> 00:04:37.560
And so then any small task you want to do, you end up like rewriting some deep script

00:04:37.560 --> 00:04:40.760
in the operating system and like two hours later, you're like, what was that small thing

00:04:40.760 --> 00:04:41.760
I was trying to do again?

00:04:41.760 --> 00:04:42.760
- Yeah, exactly.

00:04:42.760 --> 00:04:43.760
I got distracted.

00:04:43.760 --> 00:04:46.160
I was rewriting something in there and off we go.

00:04:46.160 --> 00:04:47.160
Yeah.

00:04:47.160 --> 00:04:48.160
- Yeah.

00:04:48.160 --> 00:04:51.840
So Macs are nice because you still have all the same Unix like properties that are great,

00:04:51.840 --> 00:04:53.920
but you pay a price for reliability.

00:04:53.920 --> 00:04:56.760
- You just sell a bit of your soul out, but boy, is that UI nice.

00:04:56.760 --> 00:04:59.880
And those little menu bar apps are handy.

00:04:59.880 --> 00:05:02.080
You know, I was, that's right.

00:05:02.080 --> 00:05:10.880
I was been playing with running Ubuntu on my Mac M2 Pro, which it runs great, but it's

00:05:10.880 --> 00:05:14.080
an ARM version of Mac or of Linux rather.

00:05:14.080 --> 00:05:21.440
Well, both really, but boy, is there a limited supply of applications for an ARM Linux distribution?

00:05:21.440 --> 00:05:25.560
Let me tell you, they're like, just download the Debian package.

00:05:25.560 --> 00:05:27.120
- I imagine that'll change pretty quick though.

00:05:27.120 --> 00:05:28.880
- Yeah, they're like, just download the Debian package.

00:05:28.880 --> 00:05:29.880
You just install it.

00:05:29.880 --> 00:05:30.880
Like wrong platform.

00:05:30.880 --> 00:05:33.320
I'm like, again, over half.

00:05:33.320 --> 00:05:37.160
But yeah, I think it will change as I think ARM's going to start to take over Windows

00:05:37.160 --> 00:05:38.400
a little bit as well.

00:05:38.400 --> 00:05:41.600
And obviously the Mac world is basically transitioning.

00:05:41.600 --> 00:05:43.520
So anyone who has a Mac, yeah.

00:05:43.520 --> 00:05:48.280
- I think it's Qualcomm that just kind of started hinting that they were going to try

00:05:48.280 --> 00:05:52.760
and really heavily compete with the M line of processors and have some pretty good specs.

00:05:52.760 --> 00:05:53.760
So it'll be good.

00:05:53.760 --> 00:05:56.440
I have an M3 and it's pretty nice.

00:05:56.440 --> 00:05:57.440
- It is really nice.

00:05:58.000 --> 00:06:02.920
Like I said, I'd like to run more stuff on it, but it's still kind of Intel or x86 stuff

00:06:02.920 --> 00:06:04.800
for Linux and Windows.

00:06:04.800 --> 00:06:08.440
So it's a little hard to work with that, but still super fun.

00:06:08.440 --> 00:06:12.280
That's a long way to say it's a very long time since I've been a reg at it.

00:06:12.280 --> 00:06:16.560
Personally, it sounds like you as well being not naming Windows too much.

00:06:16.560 --> 00:06:18.120
- I'm so bad at Windows now.

00:06:18.120 --> 00:06:21.840
Like when I'm helping people with Python or something else and they show me their computer,

00:06:21.840 --> 00:06:27.640
there's always that like 10 minute learning curve of like, okay, how do I do anything

00:06:27.640 --> 00:06:29.080
basic on this machine?

00:06:29.080 --> 00:06:33.200
Or even like the keyboard shortcuts you get so accustomed to when people don't have any

00:06:33.200 --> 00:06:37.880
of those little things that you're just like, how do I select everything?

00:06:37.880 --> 00:06:38.880
- That is it.

00:06:38.880 --> 00:06:41.680
Like I did professional software development on Windows for a long, long time.

00:06:41.680 --> 00:06:43.280
I even wrote a bunch of Windows apps.

00:06:43.280 --> 00:06:44.720
It was great.

00:06:44.720 --> 00:06:49.200
But going back and forth too quickly that or Linux, like just the hotkeys, I just get

00:06:49.200 --> 00:06:50.200
broken.

00:06:50.200 --> 00:06:54.680
So I'm just on Windows also when I come back to Mac, like I'm just completely out of sorts.

00:06:54.680 --> 00:06:55.680
So yeah, it's fun.

00:06:55.680 --> 00:07:04.400
All right, well, let's talk academics and Python from a probably a OS, mostly agnostic

00:07:04.400 --> 00:07:05.800
perspective.

00:07:05.800 --> 00:07:09.120
But yeah, just give us a sense of the kind of research you do.

00:07:09.120 --> 00:07:10.120
You know, what is your field?

00:07:10.120 --> 00:07:11.120
What do you study?

00:07:11.120 --> 00:07:12.120
Those kinds of things.

00:07:12.120 --> 00:07:14.880
So people get a sense of like, why am I talking about this?

00:07:14.880 --> 00:07:16.920
Where are you coming from as you talk about doing all these things?

00:07:16.920 --> 00:07:20.600
- The core of my work is pure neuroscience.

00:07:20.600 --> 00:07:26.160
So basic science, what we do mainly in the lab is we take really tiny wires.

00:07:26.160 --> 00:07:28.280
So they're like a fifth of the size of the human hair.

00:07:28.280 --> 00:07:31.840
And now we're using something called silicon probes, which are, they're manufactured the

00:07:31.840 --> 00:07:37.360
same way that computer chips are manufactured on silicon wafers using photolithography.

00:07:37.360 --> 00:07:38.600
- Do you get a higher density that way?

00:07:38.600 --> 00:07:42.440
Do you get like a bunch of little sensors on one point or something?

00:07:42.440 --> 00:07:43.440
Okay.

00:07:43.440 --> 00:07:44.440
- So we used to build these little drives.

00:07:44.440 --> 00:07:46.400
I used to have one here, but I got rid of it.

00:07:46.400 --> 00:07:47.440
Little drives by hand.

00:07:47.440 --> 00:07:51.680
So you would just feed the wires in with forceps.

00:07:51.680 --> 00:07:56.600
And so you'd get maybe 64 or 128 at most, depending on how much time you want to sit

00:07:56.600 --> 00:07:58.040
there and feed the wires in.

00:07:58.040 --> 00:08:02.520
But now you can just get the manufactured, you pay a lot more, but you get twice, three

00:08:02.520 --> 00:08:04.320
times the sites.

00:08:04.320 --> 00:08:08.520
And the whole point is the more sites you have, the more neurons you can actually record

00:08:08.520 --> 00:08:09.880
from in the brain.

00:08:09.880 --> 00:08:10.880
- Yeah.

00:08:10.880 --> 00:08:14.640
You're not just saying this part of the brain lit up, but you can have a much better picture,

00:08:14.640 --> 00:08:15.640
right?

00:08:15.640 --> 00:08:16.640
- Yeah.

00:08:16.640 --> 00:08:17.640
So a big part of your brain is the neuron.

00:08:17.640 --> 00:08:22.520
And so of the millions and billions of neurons, depending on the species you're recording

00:08:22.520 --> 00:08:27.840
from, we can record maybe a few hundred of them, but that's usually sufficient to actually,

00:08:27.840 --> 00:08:32.520
in the specific region you study, and I can talk about that more, to discern some sort

00:08:32.520 --> 00:08:33.760
of information from it.

00:08:33.760 --> 00:08:38.840
So really the data type we really care about is this tiny little electrical voltages that

00:08:38.840 --> 00:08:41.920
tell you what different neurons in the brain are talking about.

00:08:41.920 --> 00:08:46.960
And so you put the wires in, you record the conversations of a bunch of neurons.

00:08:46.960 --> 00:08:52.960
And particularly we're interested in two brain regions that are critical for memory, learning,

00:08:52.960 --> 00:08:53.960
and decision-making.

00:08:53.960 --> 00:08:58.000
And this is the hippocampus, which in humans is about the size of your pinky and a few

00:08:58.000 --> 00:09:02.280
inches in from your ear, and the prefrontal cortex, which most people know about right

00:09:02.280 --> 00:09:07.000
behind your forehead, important for learning, decision-making, and all those sorts of things.

00:09:07.000 --> 00:09:11.640
So that's the core of my work is I'm in the lab doing the actual data collection and building

00:09:11.640 --> 00:09:13.320
equipment to actually do that.

00:09:13.320 --> 00:09:17.800
But once you have all of that data and the data keeps growing, like most other fields,

00:09:17.800 --> 00:09:21.000
you got to do a lot of pre-processing, which takes Python.

00:09:21.000 --> 00:09:24.440
You got to do a lot of post-processing, which takes a lot of Python.

00:09:24.440 --> 00:09:27.180
And also we do something called neural decoding.

00:09:27.180 --> 00:09:32.080
So not only do we just like say descriptively, what are these neurons doing, but we can go

00:09:32.080 --> 00:09:38.460
one step further and say, what actual information are these cells representing?

00:09:38.460 --> 00:09:44.680
So in the brain, we can kind of say, this is kind of the fundamental kind of information

00:09:44.680 --> 00:09:49.640
transfer and how information is manipulated in the brain and how it ships information

00:09:49.640 --> 00:09:53.760
from the environment into memory and how it uses that to make a decision.

00:09:53.760 --> 00:09:59.240
All of those kinds of things we can use through fancy modeling and statistics and more recently,

00:09:59.240 --> 00:10:00.560
deep learning and those sorts of things.

00:10:00.560 --> 00:10:02.400
- We'll have to come back to deep learning later.

00:10:02.400 --> 00:10:03.400
That'll be fun.

00:10:03.400 --> 00:10:06.080
Well, given your background.

00:10:06.080 --> 00:10:11.860
So for this hardware, do you write the software that actually talks directly to the hardware

00:10:11.860 --> 00:10:16.460
or is there something that just records it and you grab some sort of custom file format

00:10:16.460 --> 00:10:17.460
and run with it?

00:10:17.460 --> 00:10:21.300
- Yeah, more recently, it kind of depends on the lab.

00:10:21.300 --> 00:10:25.860
So as time goes on, there's more and more companies that you can just buy off the shelf

00:10:25.860 --> 00:10:30.100
and recording platforms, mostly for the electrical engineering people.

00:10:30.100 --> 00:10:33.620
It's kind of like an audio like amplifier, 'cause you're recording at millivolts in the

00:10:33.620 --> 00:10:37.780
brain so you have to amplify it, write it to, if you're plugged in with a wire, write

00:10:37.780 --> 00:10:39.380
it to the computer.

00:10:39.380 --> 00:10:42.240
So all that takes software in various forms.

00:10:42.240 --> 00:10:44.780
And then we do a lot of animal research.

00:10:44.780 --> 00:10:49.700
So the tasks that the animals do are pretty much all automated.

00:10:49.700 --> 00:10:54.460
But recently in the lab, we've kind of had this resurgence of like developing kind of

00:10:54.460 --> 00:10:57.380
novel hardware and a lot of automation of behavior.

00:10:57.380 --> 00:11:03.180
So I've kind of rewritten most of our entire behavioral stacks, which is a lot of just,

00:11:03.180 --> 00:11:06.860
so microcontroller programming, which not a lot of that's in Python, a lot of that's

00:11:06.860 --> 00:11:09.740
just kind of like C++ and those sorts of things.

00:11:09.740 --> 00:11:14.500
But we have cameras all over, so I wrote this kind of like camera server that streams all

00:11:14.500 --> 00:11:19.700
of the camera footage from a bunch of automated boxes to some like central server that just

00:11:19.700 --> 00:11:21.140
collects all of that data.

00:11:21.140 --> 00:11:26.300
So yeah, a lot of the behavioral stuff nowadays, we're just building in house to collect all

00:11:26.300 --> 00:11:27.860
of the behavior data.

00:11:27.860 --> 00:11:32.620
The EFIS stuff is now, especially because we're doing something called wireless recording.

00:11:32.620 --> 00:11:36.540
So instead of just having a wire plugged into the head, it just writes it to like an SD

00:11:36.540 --> 00:11:38.660
card or Bluetooth.

00:11:38.660 --> 00:11:40.340
That's just kind of all on chip.

00:11:40.340 --> 00:11:46.260
So it's just whatever the microcontroller language of the chip needs.

00:11:46.260 --> 00:11:50.260
- This portion of Talk Python to Me is brought to you by Neo4j.

00:11:50.260 --> 00:11:51.580
Do you know Neo4j?

00:11:51.580 --> 00:11:54.720
Neo4j is a native graph database.

00:11:54.720 --> 00:11:59.620
And if the slowest part of your data access patterns involves computing relationships,

00:11:59.620 --> 00:12:05.340
why not use a database that stores those relationships directly in the database, unlike your typical

00:12:05.340 --> 00:12:06.340
relational one?

00:12:06.340 --> 00:12:10.460
A graph database lets you model the data the way it looks in the real world, instead of

00:12:10.460 --> 00:12:13.620
forcing it into rows and columns.

00:12:13.620 --> 00:12:18.140
It's time to stop asking a relational database to do more than they were made for and simplify

00:12:18.140 --> 00:12:21.480
complex data models with graphs.

00:12:21.480 --> 00:12:25.460
If you haven't used a graph database before, you might be wondering about common use cases.

00:12:25.460 --> 00:12:27.020
What's it for?

00:12:27.020 --> 00:12:34.060
Here are just a few, detecting fraud, enhancing AI, managing supply chains, gaining a 360

00:12:34.060 --> 00:12:38.940
degree view of your data, and anywhere else you have highly connected data.

00:12:38.940 --> 00:12:44.860
To use Neo4j from Python, it's a simple pip install Neo4j.

00:12:44.860 --> 00:12:48.720
And to help you get started, their docs include a sample web app demonstrating how to use

00:12:48.720 --> 00:12:51.940
it both from Flask and FastAPI.

00:12:51.940 --> 00:12:56.980
Find it in their docs or search GitHub for Neo4j movies application quick start.

00:12:56.980 --> 00:13:00.700
Developers are solving some of the world's biggest problems with graphs.

00:13:00.700 --> 00:13:01.700
Now it's your turn.

00:13:01.700 --> 00:13:06.380
Visit talkpython.fm/neo4j to get started.

00:13:06.380 --> 00:13:11.060
That's talkpython.fm/neo, the number four and the letter J.

00:13:11.060 --> 00:13:15.500
Thank you to Neo4j for supporting Talk Python to me.

00:13:15.500 --> 00:13:21.500
- I think it's surprising how much software and even hardware, but definitely software

00:13:21.500 --> 00:13:25.940
is involved for something that doesn't sound like a software discipline.

00:13:25.940 --> 00:13:30.340
You wouldn't think of what you guys are doing as inherently almost like a software team,

00:13:30.340 --> 00:13:31.820
but there's a lot of software there.

00:13:31.820 --> 00:13:33.220
- Absolutely, and it's growing.

00:13:33.220 --> 00:13:38.620
So it used to be 10, 20 years ago, more biology, I'd say, like more wet lab stuff.

00:13:38.620 --> 00:13:45.260
But 90% of what I do as kind of a neurobiologist is really just engineering style things.

00:13:45.260 --> 00:13:50.780
Like I'm more recently designing PCBs and I'm in the shop a lot, just like with saws

00:13:50.780 --> 00:13:54.740
and hammers and drills and like actually physically building things.

00:13:54.740 --> 00:13:56.060
And obviously a lot of code.

00:13:56.060 --> 00:14:00.620
And the coding part is becoming bigger and bigger to the point where in the field, I

00:14:00.620 --> 00:14:05.500
always say that the neuroscience is like about three decades behind astrophysics.

00:14:05.500 --> 00:14:09.460
'Cause all the problems that like neuroscientists like say we're facing now as a field, they

00:14:09.460 --> 00:14:14.060
had like three decades prior where in astrophysics, they're like, well, or in neuroscience, we're

00:14:14.060 --> 00:14:16.060
like, what do we do with all this data?

00:14:16.060 --> 00:14:20.980
This is, I mean, I'm collecting a hundred gigabytes an hour, if not more, like what

00:14:20.980 --> 00:14:21.980
do we do with all this data?

00:14:21.980 --> 00:14:22.980
- That is a lot.

00:14:22.980 --> 00:14:27.380
- Yeah, but relative to like some of those big telescopes that are collecting like almost

00:14:27.380 --> 00:14:28.380
petabyte scale.

00:14:28.380 --> 00:14:32.340
- I would say both ends of physics, like the very, very extreme ends of physics.

00:14:32.340 --> 00:14:36.380
So astrophysics, the very large and then particle physics, right?

00:14:36.380 --> 00:14:39.100
At CERN as well, they've got insane amounts of data.

00:14:39.100 --> 00:14:40.100
Yeah.

00:14:40.100 --> 00:14:42.140
- And that's what we're starting to see, I think, in neuroscience too, is that kind of

00:14:42.140 --> 00:14:47.260
division of like, because the scale of data collection is so big, you're starting to need

00:14:47.260 --> 00:14:49.740
not just a single lab, but teams.

00:14:49.740 --> 00:14:54.180
So we have a few institutes now that are just pumping out terabytes of data.

00:14:54.180 --> 00:14:58.900
And so you start to see that division between the neuroscientists who are really in the

00:14:58.900 --> 00:15:04.300
lab hands-on with actual neural tissue or the recording device, and the neuroscientists

00:15:04.300 --> 00:15:09.700
who are just take the data and analyze it and develop new models and statistical models.

00:15:09.700 --> 00:15:14.960
And also theory, there's always a dearth of theory in neuroscience, but the computational

00:15:14.960 --> 00:15:19.980
modeling is certainly getting a lot bigger within the last few decades as well, where

00:15:19.980 --> 00:15:24.300
people's entire job is just how do we model some of these things in code?

00:15:24.300 --> 00:15:29.420
- You probably run into different research groups, different teams that have different

00:15:29.420 --> 00:15:32.540
levels of sophistication from a software side.

00:15:32.540 --> 00:15:37.620
And do you see like a productivity or a quality difference jump out from like the kind of

00:15:37.620 --> 00:15:40.380
work or the velocity of work that people are doing there?

00:15:40.380 --> 00:15:41.380
- Absolutely.

00:15:41.380 --> 00:15:44.740
It makes me almost like a, it's a huge range.

00:15:44.740 --> 00:15:46.820
There are like very sophisticated labs.

00:15:46.820 --> 00:15:51.000
And usually those are the labs that have kind of just a pure software person on the team

00:15:51.000 --> 00:15:55.860
or people who are very inclined towards software all the way to, and it makes me so sad when

00:15:55.860 --> 00:16:00.220
people are spending like weeks in a spreadsheet, just manually doing things by hand.

00:16:00.220 --> 00:16:01.220
- Yeah, I know.

00:16:01.220 --> 00:16:03.940
- You could do this in five minutes in Python.

00:16:03.940 --> 00:16:07.340
- And not only could you do it faster, you could do it without any errors.

00:16:07.340 --> 00:16:08.340
- Yeah, more reliable.

00:16:08.340 --> 00:16:14.500
- None of those like, oh, I misread it and I shifted off by a cell or I typed in.

00:16:14.500 --> 00:16:16.300
- I missed something, right?

00:16:16.300 --> 00:16:18.180
'Cause it just reads what's there, yeah.

00:16:18.180 --> 00:16:23.700
- A lot of like graduate programs are starting to wake up to this fact that it's gonna be

00:16:23.700 --> 00:16:28.860
almost impossible to do any science without some degree of proficiency in coding.

00:16:28.860 --> 00:16:33.660
And I think a lot of, say grad students and postdocs and so on, when they actually sit

00:16:33.660 --> 00:16:38.340
down and try and analyze their data, whether there's just an Excel or they need to write

00:16:38.340 --> 00:16:42.500
a little Python script, that's kind of their first introduction is, oh, I have this data,

00:16:42.500 --> 00:16:44.120
I need to do something with it.

00:16:44.120 --> 00:16:49.500
I'm gonna Google exactly how do I read in this data or how do I do a T-test in Python

00:16:49.500 --> 00:16:51.980
or how do I plot something in Matplotlib?

00:16:51.980 --> 00:16:55.460
And that's kind of the level that they start getting into out of necessity.

00:16:55.460 --> 00:17:00.180
But the sophistication and the speed, because they're usually just teaching themselves,

00:17:00.180 --> 00:17:01.180
that's most of academia.

00:17:01.180 --> 00:17:05.900
It's just, you have a problem, spend a few days Googling and reading books until you

00:17:05.900 --> 00:17:06.900
find it.

00:17:06.900 --> 00:17:08.740
- And once it works, you can kind of just leave it.

00:17:08.740 --> 00:17:10.900
You don't have to clean it up or anything, right?

00:17:10.900 --> 00:17:11.900
Yeah, okay.

00:17:11.900 --> 00:17:16.360
- And it results in a lot of, I mean, the progress of science doesn't go away, but the

00:17:16.360 --> 00:17:19.000
code is not robust.

00:17:19.000 --> 00:17:22.920
And so that's why you see things, especially in other fields of psychology and such, like

00:17:22.920 --> 00:17:29.480
replication crises and people have done meta-analysis of running the same software stack on 12 different

00:17:29.480 --> 00:17:31.280
data sets and you get different results.

00:17:31.280 --> 00:17:37.400
And so you start to kind of see the shaky foundation starting to bleed into the, like

00:17:37.400 --> 00:17:40.240
you said, the reliability results.

00:17:40.240 --> 00:17:43.280
- And you'd have consequences, not just it's more work or something.

00:17:43.280 --> 00:17:44.280
- Exactly.

00:17:44.280 --> 00:17:48.240
- Maybe we could start a bit by just talking about maybe the history, diving into this

00:17:48.240 --> 00:17:52.480
a little bit more, just the history of programming in neuroscience.

00:17:52.480 --> 00:17:57.720
I wasn't in neuroscience in any way, but I worked with a bunch of cognitive scientists

00:17:57.720 --> 00:18:03.160
studying how people solve problems and thought about things at a lab for one of my first

00:18:03.160 --> 00:18:05.720
jobs and we studied all through eye tracking.

00:18:05.720 --> 00:18:07.600
Not the iPhone, but actual eyes.

00:18:07.600 --> 00:18:08.600
It was fascinating.

00:18:08.600 --> 00:18:09.600
It was tons of data.

00:18:09.600 --> 00:18:12.880
And there were, like you described, a lot of people who would do sort of Excel stuff

00:18:12.880 --> 00:18:15.520
and they would take the data and they process it.

00:18:15.520 --> 00:18:19.680
Over time, we just started to automate these things and their first thought was, "You're

00:18:19.680 --> 00:18:20.680
programming me out of a job."

00:18:20.680 --> 00:18:22.540
I'm like, "No, no, no.

00:18:22.540 --> 00:18:24.320
This is the crappy part of your job.

00:18:24.320 --> 00:18:28.480
Like you're supposed to analyze the results and think about it and plan new stuff and

00:18:28.480 --> 00:18:30.840
now you can just focus on that."

00:18:30.840 --> 00:18:34.700
And as the software got better, we just tackled bigger problems.

00:18:34.700 --> 00:18:37.920
So maybe give us a bit of a history of on your side.

00:18:37.920 --> 00:18:39.840
So I love the cognitive science.

00:18:39.840 --> 00:18:42.680
That's my more background is cognitive science.

00:18:42.680 --> 00:18:47.080
I was an undergrad and grew up in science in a cognitive science department while also

00:18:47.080 --> 00:18:49.160
doing some wet lab neuroscience stuff.

00:18:49.160 --> 00:18:50.160
So it's fun.

00:18:50.160 --> 00:18:51.160
Yeah, absolutely.

00:18:51.160 --> 00:18:54.440
Did you start out with like MATLAB and that kind of stuff?

00:18:54.440 --> 00:18:56.840
Is that where they told you you need to be?

00:18:56.840 --> 00:19:01.560
Neuroscience has certainly had, at least our branch of neuroscience, just because by the

00:19:01.560 --> 00:19:05.800
nature of recording voltages and you need to write to a computer.

00:19:05.800 --> 00:19:11.320
So there has been kind of a long history of, for as long as there's been even like punchcard

00:19:11.320 --> 00:19:17.200
computers, people have kind of read in the data into the computer and done their statistics

00:19:17.200 --> 00:19:20.000
on that rather than something else.

00:19:20.000 --> 00:19:24.880
I'm actually recently writing a kind of a review article on the history of data science

00:19:24.880 --> 00:19:26.400
and neuroscience.

00:19:26.400 --> 00:19:27.880
And I loved this paper.

00:19:27.880 --> 00:19:31.120
It was from 1938.

00:19:31.120 --> 00:19:37.760
And they took an EEG spectrum, and so EEG is just the continuous time series of brain

00:19:37.760 --> 00:19:38.760
voltage.

00:19:38.760 --> 00:19:39.760
So you're not in the brain recording.

00:19:39.760 --> 00:19:41.760
And this is, I think, from humans.

00:19:41.760 --> 00:19:45.080
And they took something called the Fourier transform, which I'll be as up to speed with

00:19:45.080 --> 00:19:50.600
that is you basically just take some oscillating signal and you break it down into its constituent

00:19:50.600 --> 00:19:51.600
parts.

00:19:51.600 --> 00:19:54.720
And most of you have seen it before if you've ever seen like an audio spectrogram, that's

00:19:54.720 --> 00:19:59.920
kind of the most notable visualization where you can kind of see the high frequencies and

00:19:59.920 --> 00:20:00.920
the low frequencies.

00:20:00.920 --> 00:20:04.120
So basically it pulls the frequencies out of the signal, right?

00:20:04.120 --> 00:20:05.120
Yeah.

00:20:05.120 --> 00:20:08.480
But the way they did this, and this is 1938, there's no computers.

00:20:08.480 --> 00:20:13.920
So they actually had mechanical device where they would just take this EEG trace that was

00:20:13.920 --> 00:20:17.960
on tape and they would feed it into this like mechanical machine.

00:20:17.960 --> 00:20:21.400
And it would basically read kind of this black line on the tape.

00:20:21.400 --> 00:20:27.120
And so as it would crank the tape around this machine, depending on kind of the frequency

00:20:27.120 --> 00:20:30.640
that the line went up and down, that would read out the Fourier transform.

00:20:30.640 --> 00:20:31.640
So it was mechanical.

00:20:31.640 --> 00:20:32.640
Wow.

00:20:32.640 --> 00:20:35.760
Like a lot of those cool devices back in the older days.

00:20:35.760 --> 00:20:36.760
That's impressive.

00:20:36.760 --> 00:20:39.320
Now you can get that same thing with in MATLAB.

00:20:39.320 --> 00:20:43.680
You just type FFT, parenthesis, parenthesis, put your data in the middle and you get the

00:20:43.680 --> 00:20:45.760
same thing in microseconds.

00:20:45.760 --> 00:20:51.240
But neuroscience, at least my field has kind of always had this kind of serendipitous relationship

00:20:51.240 --> 00:20:53.920
with computing generally, coding generally.

00:20:53.920 --> 00:20:59.200
And a lot of the code I think earlier on was kind of Fortran-ish and then it moved towards

00:20:59.200 --> 00:21:00.200
MATLAB.

00:21:00.200 --> 00:21:03.880
And MATLAB's kind of had its stake in the ground for a long time, just because that

00:21:03.880 --> 00:21:08.960
was the first kind of software that you could really do array manipulations on well.

00:21:08.960 --> 00:21:12.240
And it was kind of a higher level than some of the lower level programming.

00:21:12.240 --> 00:21:18.240
So a lot of the older labs have their entire code base and stack and analysis software

00:21:18.240 --> 00:21:19.240
in MATLAB.

00:21:19.240 --> 00:21:25.280
And so it's only been within maybe five to six, seven years, maybe a bit longer, 10 years

00:21:25.280 --> 00:21:30.720
that you've really seen Python start to supplant MATLAB as kind of the de facto programming

00:21:30.720 --> 00:21:35.320
language in labs, just because of the cost of trying to transfer everything over.

00:21:35.320 --> 00:21:40.160
And despite the fact that MATLAB isn't open source and it's extremely expensive, most

00:21:40.160 --> 00:21:41.600
universities have licenses.

00:21:41.600 --> 00:21:43.400
And so that kind of facilitates.

00:21:43.400 --> 00:21:44.400
It's prepaid in a sense.

00:21:44.400 --> 00:21:45.400
Yeah.

00:21:45.400 --> 00:21:46.400
But it is still pretty expensive.

00:21:46.400 --> 00:21:52.240
Especially if you get those little toolboxes like Wavelet Decomposition Toolbox, 2000

00:21:52.240 --> 00:21:54.280
bucks instead of a pip install, you know.

00:21:54.280 --> 00:21:56.160
And again, we do a lot of signal processing.

00:21:56.160 --> 00:21:59.120
And so that's exactly the place you want to be.

00:21:59.120 --> 00:22:03.560
And like MATLAB usually controls because it has pretty good control over like external

00:22:03.560 --> 00:22:04.560
hardware.

00:22:04.560 --> 00:22:07.800
You can run like your behavior, your task kind of in MATLAB mode.

00:22:07.800 --> 00:22:12.400
So you can kind of do everything in one language as you would like to do in Python.

00:22:12.400 --> 00:22:14.560
But it's starting to kind of go away.

00:22:14.560 --> 00:22:19.400
And I think a lot of that is just because the allure of Python, which is so many tools

00:22:19.400 --> 00:22:24.080
and because it's probably a lot easier to learn for most people than MATLAB.

00:22:24.080 --> 00:22:28.200
We're kind of starting to see that switch now that there's kind of more to offer, I'd

00:22:28.200 --> 00:22:30.880
say a lot of scientists than MATLAB.

00:22:30.880 --> 00:22:31.880
Yeah.

00:22:31.880 --> 00:22:32.880
You said 10, 12 years ago.

00:22:32.880 --> 00:22:33.880
At least in our field.

00:22:33.880 --> 00:22:34.880
Yeah.

00:22:34.880 --> 00:22:39.960
The difference in the external packages on PyPI you can get, and especially the ones

00:22:39.960 --> 00:22:43.600
for data science have just exploded.

00:22:43.600 --> 00:22:46.640
The choices and the stuff that's out there is, it's pretty diverse.

00:22:46.640 --> 00:22:47.640
It's pretty crazy.

00:22:47.640 --> 00:22:51.200
The only other one that I think is still in pretty strong competition with Python from

00:22:51.200 --> 00:22:55.800
the perspective of, we collaborate a lot with like mathematicians and statisticians and

00:22:55.800 --> 00:23:02.000
R is their usual favorite, just because statistics, like all the best statistical packages are

00:23:02.000 --> 00:23:05.520
still pretty much in R. And so that's where a lot of people live.

00:23:05.520 --> 00:23:06.520
ggplot is pretty good.

00:23:06.520 --> 00:23:07.520
Pretty makes pretty good plots.

00:23:07.520 --> 00:23:08.520
Yeah, that's interesting.

00:23:08.520 --> 00:23:13.400
It's really focused and it's really good at what it does.

00:23:13.400 --> 00:23:18.760
And one of the things that I think is worth just considering, if somebody comes, let's

00:23:18.760 --> 00:23:23.440
say a brand new first year grad student comes into the lab and you're like, all right, what's

00:23:23.440 --> 00:23:24.440
your programming experience?

00:23:24.440 --> 00:23:27.560
Like, well, programmed the clock on the VCR.

00:23:27.560 --> 00:23:30.400
Like, okay, we're going to have to start you somewhere or something.

00:23:30.400 --> 00:23:35.720
And you could teach them something really specific like MATLAB or something along those

00:23:35.720 --> 00:23:36.720
lines.

00:23:36.720 --> 00:23:41.920
But if they learn something like Julia, not like Julia, like Python, not Julia, maybe

00:23:41.920 --> 00:23:48.720
even not really R, but R is closer somewhat, is they learn not just a skill for the lab,

00:23:48.720 --> 00:23:53.760
but it's kind of almost any software job is potentially within reach with a little bit

00:23:53.760 --> 00:23:55.720
of learning about that area.

00:23:55.720 --> 00:23:56.720
Right.

00:23:56.720 --> 00:23:58.320
Like if you know Python, you say, I want a job.

00:23:58.320 --> 00:24:00.420
There's a massive set of options out there.

00:24:00.420 --> 00:24:07.720
If you say, I know MATLAB or even Julia, it's like, okay, well, here's the few labs and

00:24:07.720 --> 00:24:11.120
the few research areas and the real, I just think it's something that.

00:24:11.120 --> 00:24:12.120
A lot of engineering firms.

00:24:12.120 --> 00:24:13.120
Yeah.

00:24:14.120 --> 00:24:19.680
A lot of academic folks should consider what happens if the student doesn't necessarily

00:24:19.680 --> 00:24:20.680
become a professor.

00:24:20.680 --> 00:24:21.840
You know what I mean?

00:24:21.840 --> 00:24:24.000
Which actually is a lot of the time, right?

00:24:24.000 --> 00:24:26.240
Or a professional researcher of some sort.

00:24:26.240 --> 00:24:29.700
And that's a really awesome skill to have on top of your degree.

00:24:29.700 --> 00:24:31.480
So I think that's just a big win for it.

00:24:31.480 --> 00:24:32.480
I'm happy to see that.

00:24:32.480 --> 00:24:36.920
And that literal situation just happened where a statistician that we were collaborating

00:24:36.920 --> 00:24:42.760
pretty closely with graduated, brilliant guy, and got a job at Microsoft.

00:24:42.760 --> 00:24:47.080
And so we were in a meeting after he was there and they were like, what's some advice that

00:24:47.080 --> 00:24:50.400
you have now that you've been in industry for a while?

00:24:50.400 --> 00:24:55.080
And he's like, stop using R, learn Python because everyone here uses Python.

00:24:55.080 --> 00:25:01.560
And it took me a few months to kind of switch from the R worldview of, you know, caret hyphen

00:25:01.560 --> 00:25:07.040
to equal sign to actually to work and collaborate with everyone because everyone's just using

00:25:07.040 --> 00:25:08.040
Python.

00:25:08.040 --> 00:25:09.040
Yeah.

00:25:09.040 --> 00:25:10.040
From his perspective.

00:25:10.040 --> 00:25:11.040
And I'm sure it's not unique.

00:25:11.040 --> 00:25:12.040
No, I'm sure that it's not either.

00:25:12.040 --> 00:25:15.320
I think, yeah, I just think it's not like a religious war.

00:25:15.320 --> 00:25:17.800
It's not like, oh, I think Python is absolutely better.

00:25:17.800 --> 00:25:18.960
You should just not use other stuff.

00:25:18.960 --> 00:25:22.520
I just think it's preparing people for stuff beyond school.

00:25:22.520 --> 00:25:24.240
It's a pretty interesting angle to take.

00:25:24.240 --> 00:25:25.720
And it's not like you can't learn other things.

00:25:25.720 --> 00:25:30.040
I think it's really good to learn other things, especially ones that are complimentary, where

00:25:30.040 --> 00:25:34.920
R can be complimentary, especially now that they have a lot of the subsystem packages.

00:25:34.920 --> 00:25:39.600
When I get R code, I usually just write like a sub process.

00:25:39.600 --> 00:25:40.600
I did this recently.

00:25:40.600 --> 00:25:45.400
I just wrote like a sub process line to call the R script because I was too lazy to rewrite

00:25:45.400 --> 00:25:46.400
it.

00:25:46.400 --> 00:25:47.400
Yeah, sure.

00:25:47.400 --> 00:25:49.600
But there's other like, I don't know, like Rust is probably a good one to probably try

00:25:49.600 --> 00:25:50.600
and brainchallenge.

00:25:50.600 --> 00:25:53.040
Or like lower level languages like C++.

00:25:53.040 --> 00:25:54.600
If you need for what you're doing.

00:25:54.600 --> 00:25:55.600
Yeah.

00:25:55.600 --> 00:25:58.080
It sounds like you guys do for talking to hardware and stuff like that.

00:25:58.080 --> 00:25:59.080
Yeah.

00:25:59.080 --> 00:26:00.080
Occasionally.

00:26:00.080 --> 00:26:01.320
Boy, there's not a lot of things Python can't do.

00:26:01.320 --> 00:26:06.520
Break out some MicroPython when you got to get your microcontrollers and stuff.

00:26:06.520 --> 00:26:10.360
This portion of Talk Python to Me is brought to you by Posit, the makers of Shiny.

00:26:10.360 --> 00:26:11.360
Formerly RStudio.

00:26:11.360 --> 00:26:15.040
And especially Shiny for Python.

00:26:15.040 --> 00:26:16.040
Let me ask you a question.

00:26:16.040 --> 00:26:18.040
Are you building awesome things?

00:26:18.040 --> 00:26:19.040
Of course you are.

00:26:19.040 --> 00:26:20.520
You're a developer or data scientist.

00:26:20.520 --> 00:26:21.560
That's what we do.

00:26:21.560 --> 00:26:24.040
And you should check out Posit Connect.

00:26:24.040 --> 00:26:28.640
Posit Connect is a way for you to publish, share and deploy all the data products that

00:26:28.640 --> 00:26:31.300
you're building using Python.

00:26:31.300 --> 00:26:33.560
People ask me the same question all the time.

00:26:33.560 --> 00:26:37.160
Michael, I have some cool data science project or notebook that I built.

00:26:37.160 --> 00:26:39.960
How do I share it with my users, stakeholders, teammates?

00:26:39.960 --> 00:26:45.480
Do I need to learn FastAPI or Flask or maybe Vue or ReactJS?

00:26:45.480 --> 00:26:46.480
Hold on now.

00:26:46.480 --> 00:26:49.880
Those are cool technologies and I'm sure you'd benefit from them, but maybe stay focused

00:26:49.880 --> 00:26:51.320
on the data project.

00:26:51.320 --> 00:26:53.760
Let Posit Connect handle that side of things.

00:26:53.760 --> 00:26:58.200
With Posit Connect, you can rapidly and securely deploy the things you build in Python.

00:26:58.200 --> 00:27:04.880
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Ports, Dashboards and APIs.

00:27:04.880 --> 00:27:07.120
Posit Connect supports all of them.

00:27:07.120 --> 00:27:11.920
And Posit Connect comes with all the bells and whistles to satisfy IT and other enterprise

00:27:11.920 --> 00:27:12.920
requirements.

00:27:12.920 --> 00:27:17.160
Make deployment the easiest step in your workflow with Posit Connect.

00:27:17.160 --> 00:27:23.560
For a limited time, you can try Posit Connect for free for three months by going to talkpython.fm/posit.

00:27:23.560 --> 00:27:26.840
That's talkpython.fm/POSIT.

00:27:26.840 --> 00:27:29.240
The link is in your podcast player show notes.

00:27:29.240 --> 00:27:33.720
Thank you to the team at Posit for supporting Talk Python.

00:27:33.720 --> 00:27:36.680
So another thing is, I don't know how it's received.

00:27:36.680 --> 00:27:39.920
I know it took a while to kind of really catch on.

00:27:39.920 --> 00:27:45.280
And I think the thing that just broke the final barriers for open source being adopted

00:27:45.280 --> 00:27:49.520
in at least in business was the AI stuff and the data science stuff.

00:27:49.520 --> 00:27:51.280
People are like, "Oh, we can't use this open source stuff.

00:27:51.280 --> 00:27:55.560
We got to have a SLA and some company we can sue if our code doesn't work right."

00:27:55.560 --> 00:27:56.680
Or, you know, whatever, right?

00:27:56.680 --> 00:27:58.240
Something crazy like that.

00:27:58.240 --> 00:28:02.140
And they're like, "But you understand all the AI and all the data science.

00:28:02.140 --> 00:28:04.040
We have to use this open source stuff."

00:28:04.040 --> 00:28:05.320
Like, "All right, fine."

00:28:05.320 --> 00:28:07.880
What's the open source story for you guys?

00:28:07.880 --> 00:28:13.720
Academia has probably championed open source for a really long time just because, I mean,

00:28:13.720 --> 00:28:17.800
open source back, I mean, even when I first started, was just if you read a paper and

00:28:17.800 --> 00:28:23.680
someone has some new fancy analysis, before it became a bigger push by like funding agencies

00:28:23.680 --> 00:28:26.240
to like actually post it to GitHub or some repository.

00:28:26.240 --> 00:28:29.480
I mean, you could just email people and be like, "Hey, I saw your paper.

00:28:29.480 --> 00:28:30.640
I want that script."

00:28:30.640 --> 00:28:32.640
And they would just send you a MATLAB file.

00:28:32.640 --> 00:28:37.000
And it would be just whatever they had written, but it was in MATLAB and you'd have to kind

00:28:37.000 --> 00:28:38.320
of tear it apart yourself.

00:28:38.320 --> 00:28:40.360
And there was little to no documentation.

00:28:40.360 --> 00:28:43.640
You'd be lucky if there's comments and it's spaghetti code.

00:28:43.640 --> 00:28:47.760
But you figured that out and you kind of work backwards and deconstruct it.

00:28:47.760 --> 00:28:49.720
And eventually you kind of have their code.

00:28:49.720 --> 00:28:56.400
So that kind of ethos of just scientists are really good by and large of just sharing information

00:28:56.400 --> 00:28:57.400
and helping people out.

00:28:57.400 --> 00:28:59.200
And if you have a question, just ask.

00:28:59.200 --> 00:29:01.240
It's kind of always been there.

00:29:01.240 --> 00:29:05.400
At least in our field, it's not as competitive as some other ones where you're just kind

00:29:05.400 --> 00:29:08.520
of like racing to get the next project out.

00:29:08.520 --> 00:29:10.040
It happens, but rarely.

00:29:10.040 --> 00:29:15.080
But now a lot of funding agencies and just in general, people are just excited about

00:29:15.080 --> 00:29:19.200
when you publish a paper, you put a GitHub link in the bottom of the paper and then that

00:29:19.200 --> 00:29:20.640
links to the repository.

00:29:20.640 --> 00:29:24.880
And yeah, maybe it's not been updated in a while, but the code's there and you can just

00:29:24.880 --> 00:29:25.880
take it, grab it.

00:29:25.880 --> 00:29:27.080
For the reproducibility.

00:29:27.080 --> 00:29:28.640
How about using other things?

00:29:28.640 --> 00:29:29.640
Is there SciPy?

00:29:29.640 --> 00:29:32.200
I know for astronomy there's Astropy.

00:29:32.200 --> 00:29:33.960
Is there a NeuroPy?

00:29:33.960 --> 00:29:38.920
It's really still more analysis dependent and pre-process dependent.

00:29:38.920 --> 00:29:43.800
So there's kind of this, it's still the early days where there's probably too many formats

00:29:43.800 --> 00:29:46.560
just because no one can agree on what's the best one.

00:29:46.560 --> 00:29:50.440
So like even a lot of the data formats are written kind of in Python to take whatever

00:29:50.440 --> 00:29:53.560
data you have and reformat it to something shareable.

00:29:53.560 --> 00:29:55.520
There's five or six of them floating around.

00:29:55.520 --> 00:29:59.560
There's probably two that are still duking it out to see which one will be the best.

00:29:59.560 --> 00:30:02.400
And probably five years from now, there's going to be a better one.

00:30:02.400 --> 00:30:07.520
So data formats, certainly there's kind of this, there's a few that are neck and neck.

00:30:07.520 --> 00:30:10.520
Analysis pipelines, a lot of those are still done in house, but there's starting to be

00:30:10.520 --> 00:30:13.840
a lot more toolkits and frameworks and packages.

00:30:13.840 --> 00:30:17.760
There's some really good ones that have more documentation written.

00:30:17.760 --> 00:30:18.760
They're on the PyPy repositories.

00:30:18.760 --> 00:30:22.280
So you can just pip install them and you have them.

00:30:22.280 --> 00:30:24.720
The computational neuroscience people are great at this.

00:30:24.720 --> 00:30:29.800
So all the neural simulation software, that is all really well documented, really well

00:30:29.800 --> 00:30:30.800
written.

00:30:30.800 --> 00:30:34.560
A lot of good example code and tutorials and so on.

00:30:34.560 --> 00:30:40.480
So yeah, we're starting to see kind of this more robust kind of ecosystem where you can

00:30:40.480 --> 00:30:41.920
just kind of pull things.

00:30:41.920 --> 00:30:43.200
It still just kind of varies.

00:30:43.200 --> 00:30:48.840
There's probably still not one go-to place other than the standard data science toolkits.

00:30:48.840 --> 00:30:49.840
Right, right.

00:30:49.840 --> 00:30:51.120
The pandas and so on.

00:30:51.120 --> 00:30:52.120
Yeah.

00:30:52.120 --> 00:30:55.960
So NumPy, Matplotlib, pandas, scikit-learn, if you're doing deep learning, PyTorch or

00:30:55.960 --> 00:31:00.280
TensorFlow, all of those still apply to any data science stack.

00:31:00.280 --> 00:31:01.560
Yeah, of course.

00:31:01.560 --> 00:31:05.440
What's your day-to-day stack look like if you're sitting down to do some analysis?

00:31:05.440 --> 00:31:11.800
I have a VS Code and a like autocomplete where I just write import in and it just NumPy,

00:31:11.800 --> 00:31:12.800
Matplotlib, pandas.

00:31:12.800 --> 00:31:17.760
Then I usually delete pandas because unless I have a CSV file, I'm not using it.

00:31:17.760 --> 00:31:22.800
So NumPy, Matplotlib, I can probably do 75% of the things I want to do.

00:31:22.800 --> 00:31:27.640
Scikit-learn and SciPy, obviously, if I'm doing any stats with those things, those libraries

00:31:27.640 --> 00:31:28.640
I might go to.

00:31:28.640 --> 00:31:33.600
And then over the last few years, I kind of just have my own, just because you catch yourself

00:31:33.600 --> 00:31:36.400
writing the same functions over and over and over again.

00:31:36.400 --> 00:31:40.880
So I just started building my kind of internal framework of just things I know I need.

00:31:40.880 --> 00:31:44.040
So if I'm working with LFP data, I have all my filters there.

00:31:44.040 --> 00:31:47.560
If I have spike data, I have all my spikes there.

00:31:47.560 --> 00:31:52.560
We do a lot of decoding, so developing deep learning algorithms to decode neural data.

00:31:52.560 --> 00:31:54.720
All of those are kind of listed there.

00:31:54.720 --> 00:32:00.080
And then I started realizing, dude, internal tools make the difference between solving

00:32:00.080 --> 00:32:04.580
a problem in 10 minutes or solving it in an hour where I can just sit down and have everything

00:32:04.580 --> 00:32:06.640
automated to come up.

00:32:06.640 --> 00:32:10.280
So yeah, the standard data science stack I use pretty frequently.

00:32:10.280 --> 00:32:15.440
Hardware stack, I mean, so VS Code, I just recently switched to just because everyone

00:32:15.440 --> 00:32:20.120
was talking about it from like Sublime or I usually just edit it in a terminal.

00:32:20.120 --> 00:32:21.120
And I was like, yeah, I'll try it out.

00:32:21.120 --> 00:32:22.120
Everyone's talking about it.

00:32:22.120 --> 00:32:24.600
And it's one of the good things Microsoft has done.

00:32:24.600 --> 00:32:25.600
It's pretty sweet.

00:32:25.600 --> 00:32:26.920
Yeah, that's pretty sweet.

00:32:26.920 --> 00:32:27.920
That's pretty nice.

00:32:27.920 --> 00:32:31.640
And when you do the VS Code stuff, are you just writing straight Python scripts or are

00:32:31.640 --> 00:32:34.480
you doing like VS Code on top of notebooks?

00:32:34.480 --> 00:32:35.480
Yeah.

00:32:35.480 --> 00:32:38.360
You know, it has like that kind of like text view of a notebook type of thing, I think.

00:32:38.360 --> 00:32:43.960
I used to use exclusively Python scripts, so just the .py, started seeing how great

00:32:43.960 --> 00:32:47.880
Jupyter was and so then you start doing everything in Jupyter and then you start to have all

00:32:47.880 --> 00:32:51.640
these like convoluted notebooks and like notebook V1 through 7.

00:32:51.640 --> 00:32:55.320
So then you realize that you've got to like find a balance between like, you know, notebooks

00:32:55.320 --> 00:32:58.520
are great for presentation and for like quickly testing.

00:32:58.520 --> 00:33:02.600
But the sooner you can get it into like a class structure or a package or something.

00:33:02.600 --> 00:33:07.360
The sort of productized version of it, you wanted to get it down into Python code a lot

00:33:07.360 --> 00:33:08.360
of times probably.

00:33:08.360 --> 00:33:09.360
Exactly.

00:33:09.360 --> 00:33:11.800
Like your internal tools you talked about, you're like, all right, this is the library

00:33:11.800 --> 00:33:13.080
you just call stuff, right?

00:33:13.080 --> 00:33:15.280
That just belongs more as a package and not a...

00:33:15.280 --> 00:33:19.960
The sooner you can kind of condense, pull the code out of the notebook and just leave

00:33:19.960 --> 00:33:21.720
notebooks for presentation.

00:33:21.720 --> 00:33:22.720
It's probably the best.

00:33:22.720 --> 00:33:23.720
Yeah.

00:33:23.720 --> 00:33:24.720
It's a lot of pipelines.

00:33:24.720 --> 00:33:26.200
So it's a lot of pre-processing pipelines.

00:33:26.200 --> 00:33:29.920
So you don't want, you know, 50 cells of just moving data.

00:33:29.920 --> 00:33:30.980
Preparing, yeah.

00:33:30.980 --> 00:33:35.360
You talked about having quite a bit of data, some of that being image based.

00:33:35.360 --> 00:33:36.520
Sounds like a lot of work.

00:33:36.520 --> 00:33:38.200
Do you have like a big compute cluster?

00:33:38.200 --> 00:33:42.880
Do you just have like an ultra, an M3 ultra or whatever?

00:33:42.880 --> 00:33:44.440
That's not even out yet, it's M2s.

00:33:44.440 --> 00:33:47.680
But do you just have a big machine or do you guys do cloud stuff?

00:33:47.680 --> 00:33:48.680
What's compute look like?

00:33:48.680 --> 00:33:50.960
It depends on what I'm doing, what I need.

00:33:50.960 --> 00:33:55.440
Most things, let's be honest, I could probably just use my desktop computer is really a super

00:33:55.440 --> 00:33:58.240
micro server, just runs Linux.

00:33:58.240 --> 00:34:01.040
But then for doing deep learning, you need GPUs.

00:34:01.040 --> 00:34:04.880
And so we have a nice set of GPUs we can pull to.

00:34:04.880 --> 00:34:08.440
Do you do your own training on LLMs and other deep learning things?

00:34:08.440 --> 00:34:13.000
The only LLM training I did was just for fun, but yeah, it's all the deep learning stuff

00:34:13.000 --> 00:34:15.960
we have to train and else on, on our particular.

00:34:15.960 --> 00:34:18.080
So that's all GPUs for that.

00:34:18.080 --> 00:34:21.420
A lot of the statistics we do are like permutations.

00:34:21.420 --> 00:34:24.240
So you need to kind of like parallelize them out into CPUs.

00:34:24.240 --> 00:34:27.160
And then I'll pull like a CPU cluster we have if I need it.

00:34:27.160 --> 00:34:31.440
Do you see Irvine have like a big compute resource sort of thing you can grab?

00:34:31.440 --> 00:34:36.440
They have a campus wide one that you can get on and there's a few independent ones that

00:34:36.440 --> 00:34:37.640
I have access to.

00:34:37.640 --> 00:34:41.580
So GPU is kind of in a different place than CPUs are.

00:34:41.580 --> 00:34:42.760
So I can just kind of pick and choose.

00:34:42.760 --> 00:34:47.520
And I have a few servers in the lab that I've just kind of put together that all my camera

00:34:47.520 --> 00:34:49.980
stuff, all my behavior, I kind of wrote it.

00:34:49.980 --> 00:34:51.280
So it's cloud based.

00:34:51.280 --> 00:34:55.840
I can kind of just pull up my phone and look at the videos of what animals are doing and

00:34:55.840 --> 00:34:56.840
stuff.

00:34:56.840 --> 00:34:58.700
All that runs just a server in the lab.

00:34:58.700 --> 00:35:01.200
So yeah, the compute is there when you need it.

00:35:01.200 --> 00:35:05.960
And I think as I've matured, I've kind of learned when to use what compute when and

00:35:05.960 --> 00:35:10.280
when it's worth taking the extra time to use it when you don't need to.

00:35:10.280 --> 00:35:12.760
And also when a lot of the times you don't even need it.

00:35:12.760 --> 00:35:16.440
So I know a lot of people when I see their code and they complain that it takes like

00:35:16.440 --> 00:35:17.440
an hour to run.

00:35:17.440 --> 00:35:24.400
I mean, just using multiprocessing in Python, that in and of itself is enough to not need

00:35:24.400 --> 00:35:25.800
to use a cluster.

00:35:25.800 --> 00:35:28.360
They're just using a single thread for their analysis.

00:35:28.360 --> 00:35:29.360
For sure.

00:35:29.360 --> 00:35:33.660
Or just a bad programming patterns, design patterns, like you're looping over the thing

00:35:33.660 --> 00:35:38.520
in the pandas data frame instead of doing vector operations in the pandas data frame,

00:35:38.520 --> 00:35:39.520
like that kind of stuff.

00:35:39.520 --> 00:35:40.520
Right?

00:35:40.520 --> 00:35:41.520
A hundred percent.

00:35:41.520 --> 00:35:42.520
Yeah.

00:35:42.520 --> 00:35:44.040
I mean, that was one of the first things that I usually teach.

00:35:44.040 --> 00:35:48.200
I have this little example script that shows that like, why is it better to preallocate

00:35:48.200 --> 00:35:50.920
array rather than to just append to the bottom?

00:35:50.920 --> 00:35:54.680
And it's like these things that we kind of take for granted now, but it's not intuitive

00:35:54.680 --> 00:35:55.920
unless you actually see it.

00:35:55.920 --> 00:36:00.120
No, you learn it the hard way, but it sticks in your mind once you learn it.

00:36:00.120 --> 00:36:01.560
I think that's the issue.

00:36:01.560 --> 00:36:03.320
It's like people just take it for granted.

00:36:03.320 --> 00:36:04.320
Yeah, for sure.

00:36:04.320 --> 00:36:05.400
Like, why didn't you know that?

00:36:05.400 --> 00:36:07.200
How do you, how do you onboard new people?

00:36:07.200 --> 00:36:11.360
If you, you know, get new grad students or people contribute, other contributors.

00:36:11.360 --> 00:36:14.280
It just kind of depends on the lab.

00:36:14.280 --> 00:36:19.320
Every lab kind of has their own structure of just kind of this hierarchy of expertise

00:36:19.320 --> 00:36:25.240
where like I started as an undergrad and I just volunteered in a lab at a different university

00:36:25.240 --> 00:36:28.720
and just volunteered my time, eventually could get paid.

00:36:28.720 --> 00:36:32.200
Just wanted to spend time in the lab and you could all the way up to grad students who

00:36:32.200 --> 00:36:35.960
were there to get a PhD and have more kind of autonomy over their projects.

00:36:35.960 --> 00:36:42.440
A postdoc who has a PhD and five to eight years of experience and so can pretty work

00:36:42.440 --> 00:36:43.440
well.

00:36:43.440 --> 00:36:47.320
Then there's like staff scientists or even a lot of labs now are hiring just pure engineers

00:36:47.320 --> 00:36:50.720
or pure software people because there's such a need for that.

00:36:50.720 --> 00:36:55.240
And so yeah, it really just depends on the lab specific situation and what their focus

00:36:55.240 --> 00:36:56.600
is on and what they need.

00:36:56.600 --> 00:36:57.600
Cool.

00:36:57.600 --> 00:37:01.000
I guess if you have a good NSF grant and you got some extra money, it might be money well

00:37:01.000 --> 00:37:04.560
spent to hire some student who has good programming skills, right?

00:37:04.560 --> 00:37:05.560
Absolutely.

00:37:05.560 --> 00:37:06.560
Yeah.

00:37:06.560 --> 00:37:09.360
You talked about the video stuff that you're doing in the streaming video.

00:37:09.360 --> 00:37:12.840
Do you actually do analysis on that or is it just for you to go back and look at?

00:37:12.840 --> 00:37:13.840
Oh yeah.

00:37:13.840 --> 00:37:14.840
Yeah.

00:37:14.840 --> 00:37:15.840
We do analysis on that.

00:37:15.840 --> 00:37:17.840
There's actually a pretty cool deep learning package out now.

00:37:17.840 --> 00:37:18.840
We didn't write it.

00:37:18.840 --> 00:37:21.520
It's something that another lab did where you just give it the video frame and it can

00:37:21.520 --> 00:37:24.680
automatically segment kind of it's an animal.

00:37:24.680 --> 00:37:29.400
So like where their paws are or where their like nose is looking or some cases people

00:37:29.400 --> 00:37:31.080
have like you were talking about eye tracking.

00:37:31.080 --> 00:37:32.840
They do eye tracking in like mice now.

00:37:32.840 --> 00:37:34.440
They do eye tracking on mice?

00:37:34.440 --> 00:37:36.080
That was hard on humans in the nineties.

00:37:36.080 --> 00:37:37.080
Yeah.

00:37:37.080 --> 00:37:38.080
There's a lot of VR.

00:37:38.080 --> 00:37:43.280
So they put kind of mice in this like VR system and they can like see where their little mouse

00:37:43.280 --> 00:37:45.640
pupil is looking on like the VR screen.

00:37:45.640 --> 00:37:46.640
Yeah.

00:37:46.640 --> 00:37:49.440
So you can do some different scenarios and they can detect that and they react to it?

00:37:49.440 --> 00:37:50.440
Oh, absolutely.

00:37:50.440 --> 00:37:51.440
Incredible.

00:37:51.440 --> 00:37:55.560
So yeah, I know a lot of stuff, at least in our field, the Nobel prize was awarded for

00:37:55.560 --> 00:37:58.920
you stick some electrodes in the hippocampus part of your brain.

00:37:58.920 --> 00:38:00.400
That's important for learning and memory.

00:38:00.400 --> 00:38:05.080
And then you have the animal kind of run around some environment and then you take some video

00:38:05.080 --> 00:38:07.840
data of kind of where they were running the environment.

00:38:07.840 --> 00:38:13.040
And if you were only looking at the brain data, you can predict to like 90 some percent

00:38:13.040 --> 00:38:15.600
accuracy the location of the animal.

00:38:15.600 --> 00:38:19.880
So you can show this kind of this correspondence that inside the brain is a map of kind of

00:38:19.880 --> 00:38:20.880
the environment.

00:38:20.880 --> 00:38:25.120
Our stuff, we're taking that a little one step further that says this map is not just

00:38:25.120 --> 00:38:28.640
for space, it's for non-spatial and other things too.

00:38:28.640 --> 00:38:32.740
There's this kind of network of information in the brain that the animal can kind of like

00:38:32.740 --> 00:38:37.320
navigate through, even if they're just standing still, but thinking about some sort of problem.

00:38:37.320 --> 00:38:41.960
But we use video data to validate what the animal's doing or check what kind of tasks

00:38:41.960 --> 00:38:42.960
they're doing.

00:38:42.960 --> 00:38:48.400
So yeah, a lot of multimodal heterogeneous data that each needs its own funky pre-processing

00:38:48.400 --> 00:38:53.480
and depending on the task at hand, you're writing something new to ask that question.

00:38:53.480 --> 00:38:54.840
So is that OpenCV?

00:38:54.840 --> 00:38:57.280
Yeah, my stuff is OpenCV.

00:38:57.280 --> 00:39:00.080
Streamed over sockets and some Django webpage.

00:39:00.080 --> 00:39:01.080
It's fun.

00:39:01.080 --> 00:39:03.080
It's cool to build.

00:39:03.080 --> 00:39:04.080
That sounds really cool.

00:39:04.080 --> 00:39:05.080
Yeah, absolutely.

00:39:05.080 --> 00:39:06.840
So what kind of questions are you answering with the video?

00:39:06.840 --> 00:39:07.840
Yeah.

00:39:07.840 --> 00:39:11.960
Or is it just to correlate back with the time series of what you're measuring in the brain?

00:39:11.960 --> 00:39:15.000
So like I said, the Nobel Prize was for the spatial map.

00:39:15.000 --> 00:39:17.040
We're doing this non-spatial stuff.

00:39:17.040 --> 00:39:21.640
And so we kind of do both in the lab where we have an animal kind of run around and then

00:39:21.640 --> 00:39:25.280
we have an animal just kind of sit still and do some sort of mental task.

00:39:25.280 --> 00:39:28.520
In our case, they have to memorize a sequence of odors.

00:39:28.520 --> 00:39:31.960
And if the sequence gets shuffled, they make a different choice.

00:39:31.960 --> 00:39:36.360
And so we're basically showing how does the brain work for the spatial part versus the

00:39:36.360 --> 00:39:37.560
non-spatial part?

00:39:37.560 --> 00:39:39.320
What's similar about these two things?

00:39:39.320 --> 00:39:40.960
What's different about these things?

00:39:40.960 --> 00:39:45.360
And we show that one of our recent papers was that the brain uses a lot of the similar

00:39:45.360 --> 00:39:50.560
mechanisms to navigate space as it does to navigate this kind of non-spatial odor task.

00:39:50.560 --> 00:39:55.160
But we also showed that there's this mechanism that the brain uses to take kind of discrete

00:39:55.160 --> 00:39:58.840
memories and link them together into some kind of miracle.

00:39:58.840 --> 00:40:03.760
Best case being like this talk, we've been talking back for 30 some minutes now.

00:40:03.760 --> 00:40:05.760
Inside there's kind of chunks of the conversation.

00:40:05.760 --> 00:40:10.040
So if tomorrow someone was to ask you, what did you and that neuroscience guy talk about

00:40:10.040 --> 00:40:11.560
on your podcast?

00:40:11.560 --> 00:40:16.200
You would kind of rattle off this story of, oh, we talked about history of Python and

00:40:16.200 --> 00:40:18.080
this and this and this, right?

00:40:18.080 --> 00:40:22.840
This, this and this are each kind of discrete memories that in your brain you kind of lock

00:40:22.840 --> 00:40:28.000
together and store them so that you could use them, make decisions about them and so

00:40:28.000 --> 00:40:29.000
on.

00:40:29.000 --> 00:40:32.760
Think about it as a whole, not just the little ideas, every little idea, but like just the

00:40:32.760 --> 00:40:34.160
big concept of it, right?

00:40:34.160 --> 00:40:35.160
Exactly.

00:40:35.160 --> 00:40:36.160
Yeah.

00:40:36.160 --> 00:40:37.160
And it's a fundamental thing that the brain does.

00:40:37.160 --> 00:40:42.040
Like people say humans are storytellers and your life is kind of the sequence of events

00:40:42.040 --> 00:40:43.040
of stories.

00:40:43.040 --> 00:40:47.200
And so you use that every single day and across a bunch of diseases, that's one of the first

00:40:47.200 --> 00:40:53.160
things to actually be impaired, whether it's addiction or schizophrenia or Alzheimer's,

00:40:53.160 --> 00:40:57.440
that kind of ability to link things in time and link them well and make decisions about

00:40:57.440 --> 00:40:59.480
them starts to get impaired.

00:40:59.480 --> 00:41:01.840
That's not great when that happens, but that is what happens, right?

00:41:01.840 --> 00:41:02.840
Absolutely.

00:41:02.840 --> 00:41:07.320
And I guess with the software engineering practices, for lack of a better word, that

00:41:07.320 --> 00:41:12.000
you would recommend that maybe other grad students, professors who are feeling like

00:41:12.000 --> 00:41:15.640
they're not, they don't have their software game fully together, pay attention to it.

00:41:15.640 --> 00:41:17.280
And maybe what should they ignore, right?

00:41:17.280 --> 00:41:20.120
Like should they pay attention to like source control and get up?

00:41:20.120 --> 00:41:23.400
Should they have unit tests or, you know, what should they pay attention to or not?

00:41:23.400 --> 00:41:24.920
First off, no one writes tests.

00:41:24.920 --> 00:41:28.720
That is just only the very few, very well put together.

00:41:28.720 --> 00:41:31.240
And usually people who just came from industry write tests.

00:41:31.240 --> 00:41:32.240
Sure.

00:41:32.240 --> 00:41:33.240
That's not an issue.

00:41:33.240 --> 00:41:35.240
But yeah, first off, just learn Python.

00:41:35.240 --> 00:41:39.440
I've said that hundreds of times and I'm preaching to the choir in this audience.

00:41:39.440 --> 00:41:41.360
You are, for sure.

00:41:41.360 --> 00:41:42.360
Learn Python.

00:41:42.360 --> 00:41:45.760
It's honestly, there's not much better you could learn.

00:41:45.760 --> 00:41:49.160
And two, it's, you know, it's quintessential automation stuff.

00:41:49.160 --> 00:41:53.120
So it's really just think about the things that you're doing, the spreadsheets or, you

00:41:53.120 --> 00:41:57.680
know, the simple things and really just ask yourself, if you find yourself doing any repetitive

00:41:57.680 --> 00:41:59.560
tasks, that's a software problem.

00:41:59.560 --> 00:42:01.880
Those are the things to kind of look at first.

00:42:01.880 --> 00:42:06.120
So you have your text editor in one window, Google in the other and stack overflow your

00:42:06.120 --> 00:42:07.120
way to learning.

00:42:07.120 --> 00:42:10.920
And so the way people, I think, really do kind of teach themselves Python is probably

00:42:10.920 --> 00:42:12.880
the best way to learn.

00:42:12.880 --> 00:42:17.360
But nevertheless, I think there is a real need for, and again, we're starting to see

00:42:17.360 --> 00:42:20.280
more of it, just formal education, even if it's just a course.

00:42:20.280 --> 00:42:25.080
Our program is really great that they started to teach a Python course just because the

00:42:25.080 --> 00:42:28.840
students requested it because they knew how important it was.

00:42:28.840 --> 00:42:30.800
We have Python for neuroscience.

00:42:30.800 --> 00:42:31.800
Exactly.

00:42:31.800 --> 00:42:32.800
Okay.

00:42:32.800 --> 00:42:33.800
Yeah.

00:42:33.800 --> 00:42:37.360
I mean, you just work your way through if statements for loops, data types.

00:42:37.360 --> 00:42:40.900
You probably also, I'm just guessing you get a chance to work with some of these external

00:42:40.900 --> 00:42:44.520
libraries that are relevant to studies they're doing, right?

00:42:44.520 --> 00:42:46.800
Rather than here's an example of stock market data.

00:42:46.800 --> 00:42:49.040
You're like, great, not a trader.

00:42:49.040 --> 00:42:50.040
I don't want to be a programmer.

00:42:50.040 --> 00:42:51.040
Why am I here?

00:42:51.040 --> 00:42:52.040
You know?

00:42:52.040 --> 00:42:53.040
Yeah, it's really relevant.

00:42:53.040 --> 00:42:56.320
And I think it's just kind of seeing like, oh yeah, I would do that this way, but this

00:42:56.320 --> 00:42:58.720
is so much easier if I use Python.

00:42:58.720 --> 00:43:03.120
And I can use it in Python and just seeing that, oh, it's not as bad as the mountain

00:43:03.120 --> 00:43:05.480
looks a lot higher when you're at the base than the summit.

00:43:05.480 --> 00:43:06.560
So it does.

00:43:06.560 --> 00:43:11.680
Seeing it done once is usually enough to kind of tell people it's not as bad as you originally

00:43:11.680 --> 00:43:12.680
think.

00:43:12.680 --> 00:43:13.680
Yeah.

00:43:13.680 --> 00:43:14.680
I feel like maybe I saw it this way.

00:43:14.680 --> 00:43:16.040
I certainly know a lot of other people see it this way.

00:43:16.040 --> 00:43:19.640
I mean, when I was younger, but a lot of people see it this way as well, is that like, you

00:43:19.640 --> 00:43:22.820
got to be crazy smart to do programming.

00:43:22.820 --> 00:43:24.320
It's really challenging.

00:43:24.320 --> 00:43:27.880
It's kind of one of those things that only few people can do.

00:43:27.880 --> 00:43:32.360
And then you get into it and you're like, oh, it's, it's not a few really huge steps

00:43:32.360 --> 00:43:33.680
and things you've got to solve.

00:43:33.680 --> 00:43:37.840
It's like a thousand small steps and each one of the little small steps, you're like,

00:43:37.840 --> 00:43:38.840
that was actually easy.

00:43:38.840 --> 00:43:39.840
That's no big deal.

00:43:39.840 --> 00:43:40.840
What's the next step?

00:43:40.840 --> 00:43:42.520
And you get to the end, you're like, where was the big step?

00:43:42.520 --> 00:43:43.520
Where was it really hard?

00:43:43.520 --> 00:43:44.520
Right?

00:43:44.520 --> 00:43:45.520
Yeah, absolutely.

00:43:45.520 --> 00:43:46.520
Yeah.

00:43:46.520 --> 00:43:49.720
Do you have some experience where people in the department or people that worked with

00:43:49.720 --> 00:43:51.280
you are like, ah, I'm not a programmer.

00:43:51.280 --> 00:43:52.280
I don't want to do this stuff.

00:43:52.280 --> 00:43:56.680
Then they kind of got into it and really found out that programming was something they really

00:43:56.680 --> 00:43:57.680
liked.

00:43:57.680 --> 00:43:58.680
Are there any converts out there?

00:43:58.680 --> 00:43:59.680
Yeah, I would say so.

00:43:59.680 --> 00:44:01.880
I mean, I think there's kind of two kinds of people.

00:44:01.880 --> 00:44:04.080
There's people who program just because what is it?

00:44:04.080 --> 00:44:06.120
The programming is an art book or whatever.

00:44:06.120 --> 00:44:09.000
Like, like they, they love it just for the sake of like loving.

00:44:09.000 --> 00:44:11.640
And I'm probably closer to those kinds of people, right?

00:44:11.640 --> 00:44:15.240
Like, I just think it's the coolest thing, like academic, but then there's the people

00:44:15.240 --> 00:44:18.720
who just kind of see it as like, it's a tool like anything else.

00:44:18.720 --> 00:44:23.680
And so like you could be an expert in a drill or you could just know to pick up a drill.

00:44:23.680 --> 00:44:28.560
That's kind of the majority of people is that it's just another tool in their toolkit to,

00:44:28.560 --> 00:44:32.800
especially for a scientist, just to answer the question that you're trying to answer.

00:44:32.800 --> 00:44:37.200
And I would even flip the reverse where there's been some times where I've maybe even used

00:44:37.200 --> 00:44:43.000
Python too much in the sense that like I made a problem more because it's like the automation

00:44:43.000 --> 00:44:44.000
dilemma, right?

00:44:44.000 --> 00:44:47.160
It's like, do I spend an hour automating this when I could do it in 10 minutes?

00:44:47.160 --> 00:44:49.600
You got to do it a lot of times and all of a sudden the hour is worth it.

00:44:49.600 --> 00:44:50.600
But if it turns out you don't.

00:44:50.600 --> 00:44:54.360
It's like, I might need this a year from now, so I might as well just write the script.

00:44:54.360 --> 00:44:56.400
Whereas I could just do it in Excel.

00:44:56.400 --> 00:44:59.880
That's pretty standard, standard problems we all run into in programming.

00:44:59.880 --> 00:45:04.600
It's like, I'll write some code to do that or I could just be done with it for sure.

00:45:04.600 --> 00:45:05.600
All right.

00:45:05.600 --> 00:45:07.940
I think we've got time for a couple more topics.

00:45:07.940 --> 00:45:13.160
One thing that I think might be fun to talk about is publishing papers, right?

00:45:13.160 --> 00:45:16.440
Obviously if you're in academics, especially in labs, you got to publish papers.

00:45:16.440 --> 00:45:22.080
Do you use notebooks and stuff like that for your papers or is that just kind of separate?

00:45:22.080 --> 00:45:25.520
Yeah, like I said, notebooks are great for presentation.

00:45:25.520 --> 00:45:31.000
So yeah, I use notebooks kind of for development just because you can quickly run code and

00:45:31.000 --> 00:45:32.760
go back up and move things around.

00:45:32.760 --> 00:45:37.360
And so I kind of like that ability to kind of just a stream of consciousness, write code

00:45:37.360 --> 00:45:40.800
until you kind of like see how it's kind of working, the prototype, and then refactor

00:45:40.800 --> 00:45:45.020
out into an actual .py document or a package or something.

00:45:45.020 --> 00:45:47.160
So that's kind of been my workflow and it works pretty well.

00:45:47.160 --> 00:45:51.240
But then when you actually have the code and it works and it's robust, you actually want

00:45:51.240 --> 00:45:53.960
to put, there's a lot of figures, that's usually the main thing.

00:45:53.960 --> 00:45:55.800
So you kind of put all of that.

00:45:55.800 --> 00:45:59.720
Here's the data, here's the pre-processing, here's the figure one, here's figure two,

00:45:59.720 --> 00:46:04.320
figure three in the notebook just so it's reproducible and other people can download

00:46:04.320 --> 00:46:06.720
it and rerun your code and that sort of thing.

00:46:06.720 --> 00:46:11.720
So I think that's slowly becoming kind of the standard approach for those labs that

00:46:11.720 --> 00:46:14.820
use Python and they share their code openly.

00:46:14.820 --> 00:46:16.040
That's kind of how they do it.

00:46:16.040 --> 00:46:21.620
Anything like executable books or any of those things that kind of produce printable output

00:46:21.620 --> 00:46:24.920
out of the notebooks, like publishable output out of the notebooks?

00:46:24.920 --> 00:46:29.000
Not a lot, but there's one of the journals, it's called eLife.

00:46:29.000 --> 00:46:33.480
It's kind of, it's trying to like push the boundaries of what it means to publish a scientific

00:46:33.480 --> 00:46:34.480
paper.

00:46:34.480 --> 00:46:39.640
And so they kind of have, because most papers are really just on the web nowadays, the journals

00:46:39.640 --> 00:46:42.120
aren't really physical journals as much anymore.

00:46:42.120 --> 00:46:47.340
They kind of have like papers as executable code where you can like plot the figure in

00:46:47.340 --> 00:46:51.140
the browser and kind of run through the notebook and just as an experiment.

00:46:51.140 --> 00:46:56.340
But it's pretty cool to kind of see these like new alternative ways to still convey

00:46:56.340 --> 00:47:01.260
the same findings, but you can play with it, you can kind of see how some of the methods

00:47:01.260 --> 00:47:02.740
are kind of implicit in the...

00:47:02.740 --> 00:47:03.740
What's the name of the journal?

00:47:03.740 --> 00:47:04.740
That's eLife.

00:47:04.740 --> 00:47:05.740
eLife.

00:47:05.740 --> 00:47:06.740
Okay, cool.

00:47:06.740 --> 00:47:11.160
Yeah, you probably, I suppose, need some way to capture the data output because you might

00:47:11.160 --> 00:47:15.300
not have access to the compute to recompute it.

00:47:15.300 --> 00:47:18.820
Somehow it's got to sort of be a static version, but that sounds really cool.

00:47:18.820 --> 00:47:19.820
Yeah.

00:47:19.820 --> 00:47:23.900
And especially for like most recently, some of our like trained models, it's becoming

00:47:23.900 --> 00:47:28.180
more important to just share the weights and share those sorts of things too.

00:47:28.180 --> 00:47:31.700
You can't just share the code to train the thing if people don't have the compute to

00:47:31.700 --> 00:47:34.140
actually train them themselves.

00:47:34.140 --> 00:47:37.420
It's kind of growing to not just sharing your data, not just sharing your code, but you

00:47:37.420 --> 00:47:42.020
need to share like the key derivatives of the pre-processing and those sorts of things.

00:47:42.020 --> 00:47:47.060
Or even just sharing the version numbers, because there's been psychology or fMRI literature,

00:47:47.060 --> 00:47:51.060
there's like a bug in some version that made a lot of the results null.

00:47:51.060 --> 00:47:56.100
And so, one person could use version 3.7 of a package, but that had a bug, but people

00:47:56.100 --> 00:47:57.100
don't know that.

00:47:57.100 --> 00:48:00.460
So they claim it's not reproducible, but it's really just not the same algorithms.

00:48:00.460 --> 00:48:02.140
Yeah, yeah, yeah.

00:48:02.140 --> 00:48:06.660
Or like across languages, like if you rerun the same analysis in MATLAB versus Python

00:48:06.660 --> 00:48:11.380
versus R, especially complex ones, there's a lot of little design decisions under the

00:48:11.380 --> 00:48:17.340
hood that might tweak exactly how that regression fits or exactly how that, if you're statistically

00:48:17.340 --> 00:48:20.340
sampling how the sampling works under the hood or those sorts of things.

00:48:20.340 --> 00:48:21.340
Awesome.

00:48:21.340 --> 00:48:23.140
Are you familiar with the Journal of Open Source Software?

00:48:23.140 --> 00:48:24.140
Yeah.

00:48:24.140 --> 00:48:25.420
I had the folks on from there.

00:48:25.420 --> 00:48:29.540
Yeah, I had them on quite a while ago and I think they're trying to solve the interesting

00:48:29.540 --> 00:48:35.220
problem of if you take the time to create a really nice package for your area, you might

00:48:35.220 --> 00:48:37.460
have not taken your time writing the paper.

00:48:37.460 --> 00:48:40.820
And so you wouldn't get credit because you don't have as many papers to publish.

00:48:40.820 --> 00:48:44.540
So they let you publish like your open source work there, which I think is pretty cool.

00:48:44.540 --> 00:48:45.540
What do you think about that?

00:48:45.540 --> 00:48:47.540
We kind of have that same problem.

00:48:47.540 --> 00:48:51.780
One of the, I run a nonprofit called Continual AI.

00:48:51.780 --> 00:48:56.660
It does artificial intelligence and outreach and research, and we have conferences and

00:48:56.660 --> 00:48:57.660
all sorts of events.

00:48:57.660 --> 00:49:02.020
But one of the main things we've done is we built a deep learning library on top of PyTorch

00:49:02.020 --> 00:49:03.020
called Avalanche.

00:49:03.020 --> 00:49:08.700
And so we had a really great community of mostly volunteers who just saw the need in

00:49:08.700 --> 00:49:10.580
the field and put it together.

00:49:10.580 --> 00:49:12.700
But then again, it's like a lot of us are academics.

00:49:12.700 --> 00:49:13.980
How do you present this?

00:49:13.980 --> 00:49:18.680
And so you write wrapper papers around kind of the framework.

00:49:18.680 --> 00:49:23.700
So that's kind of been the de facto way of like, it's not really a paper, but you still

00:49:23.700 --> 00:49:28.020
need to share it and get credit for it and put your name on it.

00:49:28.020 --> 00:49:29.020
It's certainly an issue.

00:49:29.020 --> 00:49:32.100
I'm starting to see it not even just with software, but even with hardware, because

00:49:32.100 --> 00:49:34.940
hardware is becoming more open source in our field.

00:49:34.940 --> 00:49:39.460
And so you just kind of write like a paper about the hardware solution to some problem.

00:49:39.460 --> 00:49:40.460
That's cool.

00:49:40.460 --> 00:49:41.460
It's better than a patent.

00:49:41.460 --> 00:49:42.460
Yeah, it's definitely better than a patent.

00:49:42.460 --> 00:49:45.780
Patents, while they serve a purpose, are pretty evil.

00:49:45.780 --> 00:49:50.420
Let's wrap things up with maybe just, you mentioned Continual AI.

00:49:50.420 --> 00:49:51.500
Tell people a bit about that.

00:49:51.500 --> 00:49:54.900
It's the largest nonprofit for continual learning.

00:49:54.900 --> 00:49:59.180
Continual learning in a nutshell is, say I have a neural network and I train my neural

00:49:59.180 --> 00:50:01.660
network to classify cats.

00:50:01.660 --> 00:50:05.580
I classify cats to 90% accuracy and we're like, yeah, this is why neural networks are

00:50:05.580 --> 00:50:06.580
great.

00:50:06.580 --> 00:50:10.140
I take that same trained neural network on cats and I trained it on say dogs.

00:50:10.140 --> 00:50:12.380
It does really well, 90% accuracy on dogs.

00:50:12.380 --> 00:50:14.700
We're really excited why neural networks are so great.

00:50:14.700 --> 00:50:18.700
But the issue is if I take that, again, the same network, I just trained it on dogs and

00:50:18.700 --> 00:50:20.220
previously trained it on cats.

00:50:20.220 --> 00:50:25.460
I try and test it on cats again, it's going to forget pretty much everything it learned

00:50:25.460 --> 00:50:26.460
about cats.

00:50:26.460 --> 00:50:30.580
And this is an old, old problem back in like, you know, the good old days when neural networks

00:50:30.580 --> 00:50:35.260
were connectionist models and it was computer scientists, it was the cognitive scientists.

00:50:35.260 --> 00:50:36.260
They noticed-

00:50:36.260 --> 00:50:37.900
Overtraining or something like that, right?

00:50:37.900 --> 00:50:38.900
Kind of overfitting.

00:50:38.900 --> 00:50:39.900
It's neural related.

00:50:39.900 --> 00:50:40.900
Yeah, it's very similar.

00:50:40.900 --> 00:50:44.300
Catastrophic forgetting, they call it the sequential learning problem, which is why

00:50:44.300 --> 00:50:48.060
I'm really interested in it because I'm really interested in continual learning and sequential

00:50:48.060 --> 00:50:51.940
memory or in neuroscience, it's called the stability plasticity problem.

00:50:51.940 --> 00:50:52.940
So when do you learn?

00:50:52.940 --> 00:50:53.940
When do you remember?

00:50:53.940 --> 00:51:00.460
And so over the last, since we started the organization in 2018, the field has kind of

00:51:00.460 --> 00:51:06.860
exploded just because there's such a need for overcoming this across a lot of use cases.

00:51:06.860 --> 00:51:09.500
So like a lot of times you could only see the data once.

00:51:09.500 --> 00:51:13.820
So the way you solve the problem generally is you just shuffle in cats and dogs into

00:51:13.820 --> 00:51:15.980
the same data set and retrain your model.

00:51:15.980 --> 00:51:19.020
But now the neural networks are getting bigger and bigger and bigger.

00:51:19.020 --> 00:51:20.740
Retraining is getting costlier and costlier.

00:51:20.740 --> 00:51:24.300
You can't just have, can't train a network on petabytes every time you want to update

00:51:24.300 --> 00:51:25.300
it.

00:51:25.300 --> 00:51:29.620
That's even if you have access to the data and the storage to save it and so on and so

00:51:29.620 --> 00:51:30.620
forth.

00:51:30.620 --> 00:51:33.740
So clever ways to solve the problem is, so we're kind of around that.

00:51:33.740 --> 00:51:38.900
We have neuroscientists, we have computer scientists, AI researchers across academia,

00:51:38.900 --> 00:51:42.780
industry, all that are just a bunch of people really interested in this problem to just

00:51:42.780 --> 00:51:45.900
come together and share papers, share ideas.

00:51:45.900 --> 00:51:50.740
We just had a conference, we sponsor a lot of competitions for people to kind of put

00:51:50.740 --> 00:51:54.140
forward an idea to some problem that we kind of put out every year.

00:51:54.140 --> 00:51:58.460
So it's been really, really exciting to kind of see the community grow over the years and

00:51:58.460 --> 00:52:00.580
all the tools and fun things that's kind of come out.

00:52:00.580 --> 00:52:02.540
Well, it's definitely a hot topic right now.

00:52:02.540 --> 00:52:03.540
Absolutely.

00:52:03.540 --> 00:52:07.300
The cognitive scientists and neuroscientists studied neural networks and stuff and it was

00:52:07.300 --> 00:52:09.060
kind of like, well, maybe this model stuff.

00:52:09.060 --> 00:52:13.100
And then now we're in the time of LLMs and the world has gone crazy.

00:52:13.100 --> 00:52:14.100
Absolutely.

00:52:14.100 --> 00:52:18.580
I said we were going to close out with a continual AI, but let me just ask, what are your thoughts

00:52:18.580 --> 00:52:20.940
on LLMs, where this stuff's going?

00:52:20.940 --> 00:52:26.660
I mean, we all have exposure to it in different ways, but you've got this understanding of

00:52:26.660 --> 00:52:28.780
what they're trying to model it on quite a bit.

00:52:28.780 --> 00:52:31.500
So what do you guys in your space think of it?

00:52:31.500 --> 00:52:36.460
So the first lab I joined was, well, the first real lab I joined was a neuroscience lab where

00:52:36.460 --> 00:52:40.500
we were sticking wires in brains and actually doing real neuroscience.

00:52:40.500 --> 00:52:45.620
But I also started kind of simultaneously working with a cognitive scientist where we

00:52:45.620 --> 00:52:48.780
were working on the original word to them.

00:52:48.780 --> 00:52:52.140
So this is in my mind, like the grandfather of the LLM.

00:52:52.140 --> 00:52:56.460
So this is the model that like overnight took Google Translate from being meh to pretty

00:52:56.460 --> 00:52:57.460
good.

00:52:57.460 --> 00:53:00.020
And it's just really at the heart of it, just an auto encoder.

00:53:00.020 --> 00:53:06.700
But we were really excited then doing kind of semantic modeling of how much further kind

00:53:06.700 --> 00:53:09.180
of deep learning could take language modeling.

00:53:09.180 --> 00:53:11.700
And then we were actually using it to study catastrophic forgetting.

00:53:11.700 --> 00:53:14.420
So does word to that catastrophically forget?

00:53:14.420 --> 00:53:15.420
The punchline is it does.

00:53:15.420 --> 00:53:20.260
And that kind of got me jumped into really excited about continual learning and so on.

00:53:20.260 --> 00:53:25.720
So I saw kind of that trajectory then, and then kind of stepped out of it for a few years

00:53:25.720 --> 00:53:32.280
and dug more deep into pure neuroscience and artificial intelligence from other angles.

00:53:32.280 --> 00:53:37.140
But I'd always been just so fascinated by this idea of like, say you take an AI and

00:53:37.140 --> 00:53:39.980
it could read every book or it could read the Internet.

00:53:39.980 --> 00:53:42.060
Like what would you be able to get?

00:53:42.060 --> 00:53:45.780
And that was kind of, you know, in my mind, like, well, seeing word to that, try and do

00:53:45.780 --> 00:53:49.660
the same thing and training it on my laptop, like, well, you know, it's going to take,

00:53:49.660 --> 00:53:51.820
it's going to take a minute till we get there.

00:53:51.820 --> 00:53:55.140
And I underestimated that drastically.

00:53:55.140 --> 00:53:57.700
It was like almost no progress, almost no progress.

00:53:57.700 --> 00:53:58.700
Wow.

00:53:58.700 --> 00:53:59.700
What just happened?

00:53:59.700 --> 00:54:00.700
Right.

00:54:00.700 --> 00:54:05.400
It's a testament to statistical learning more than anything, which is just how much information

00:54:05.400 --> 00:54:10.320
can you just soak up and put together in a fancy new way and regurgitate back.

00:54:10.320 --> 00:54:15.720
I think the next big leap is going to be adding more cognition to that progress.

00:54:15.720 --> 00:54:20.880
So adding, when an agent has a goal, when an agent kind of has to break down a series

00:54:20.880 --> 00:54:26.200
of steps to get to that goal, those kinds of things we don't see as much of.

00:54:26.200 --> 00:54:28.740
And that will kind of be the next big push.

00:54:28.740 --> 00:54:33.060
I think that'll kind of take all the cool things that LLMs can do now and kind of blow

00:54:33.060 --> 00:54:38.580
everyone away of just, if you can take the internet and put it on a seven gigabyte file,

00:54:38.580 --> 00:54:39.580
what can that get you?

00:54:39.580 --> 00:54:42.640
But what if you can take the internet, put it on a seven gigabyte file, but actually

00:54:42.640 --> 00:54:47.960
have some sort of logic and direction and the agent itself can actually navigate through

00:54:47.960 --> 00:54:49.620
its own thoughts.

00:54:49.620 --> 00:54:52.760
That's going to take us, I think, right to the borderline of.

00:54:52.760 --> 00:54:53.760
Terminator?

00:54:53.760 --> 00:54:54.760
Yeah.

00:54:54.760 --> 00:54:55.760
Not Terminator.

00:54:55.760 --> 00:54:56.760
It won't be Terminator.

00:54:56.760 --> 00:54:59.800
No, it won't be Terminator, but it'll be a really an intelligence.

00:54:59.800 --> 00:55:00.800
It's going to be super interesting.

00:55:00.800 --> 00:55:06.800
You know, you've got all this prompt engineering and these clever ways to kind of get the current

00:55:06.800 --> 00:55:12.520
LLMs in the right mindset, which is probably a personification, but you can tell it things

00:55:12.520 --> 00:55:14.720
like here, I want you to tell me how to do this.

00:55:14.720 --> 00:55:15.720
And I'll come up with some answer.

00:55:15.720 --> 00:55:18.480
You can say, I want you to think step by step.

00:55:18.480 --> 00:55:22.360
And then all of a sudden you get a real different type of answer where it pulls out the pieces

00:55:22.360 --> 00:55:23.760
and it thinks about how it does it.

00:55:23.760 --> 00:55:24.760
And it's going to be interesting.

00:55:24.760 --> 00:55:29.280
You know, it's kind of like kind of stuff, but it just, it already knows how to think.

00:55:29.280 --> 00:55:31.320
You don't have to give it little weird clues.

00:55:31.320 --> 00:55:33.600
Like you're an expert in this and you're really good at it.

00:55:33.600 --> 00:55:35.920
Now I want to ask you a question about, Oh, I'm good at it.

00:55:35.920 --> 00:55:36.920
Okay.

00:55:36.920 --> 00:55:37.920
I'll answer better.

00:55:37.920 --> 00:55:40.600
My favorite definition of AI is it's whatever computers can't do yet.

00:55:40.600 --> 00:55:41.600
Yeah.

00:55:41.600 --> 00:55:44.760
Because like, you know, 30 years ago, if we had this conversation, it'd be like, so what

00:55:44.760 --> 00:55:45.760
do you think of deep blue?

00:55:45.760 --> 00:55:51.520
Do you think deep blue, the AI that has to roll the chess can, you know, think, and is

00:55:51.520 --> 00:55:54.320
it going to take all our jobs or it's going to be, what can Watson do?

00:55:54.320 --> 00:55:56.440
Can it think and take all our jobs?

00:55:56.440 --> 00:56:01.600
And you know, that was solved with tree search, which, you know, undergraduates in their second

00:56:01.600 --> 00:56:03.080
year CS class are learning.

00:56:03.080 --> 00:56:05.320
It's just a standard it's search.

00:56:05.320 --> 00:56:06.320
People don't even think of searches.

00:56:06.320 --> 00:56:11.120
What if we just loaded every possible outcome into the chest thing and the steps.

00:56:11.120 --> 00:56:14.400
And we just try to take the traverse each step and see where it takes us.

00:56:14.400 --> 00:56:15.400
Right.

00:56:15.400 --> 00:56:18.920
There's always going to be a room to grow, but you know, from a cognitive science perspective,

00:56:18.920 --> 00:56:22.840
I think something far more interesting rather, you know, I think it's cool to see what computers

00:56:22.840 --> 00:56:23.840
can actually do.

00:56:23.840 --> 00:56:25.320
And I think they can do a hell of a lot more.

00:56:25.320 --> 00:56:28.880
But I think it's more interesting to kind of ask the more philosophical question of

00:56:28.880 --> 00:56:30.720
what does that actually mean for us?

00:56:30.720 --> 00:56:34.920
Because every step of the way, when we develop something new in artificial intelligence,

00:56:34.920 --> 00:56:39.440
it tells us something a lot deeper about our own intelligence too, where back in the fifties

00:56:39.440 --> 00:56:42.480
and sixties, they thought the chess meant intelligence.

00:56:42.480 --> 00:56:46.560
And so now we're kind of seeing with LLMs, if someone just reads a bunch of books and

00:56:46.560 --> 00:56:49.400
can memorize a bunch of books, does that mean they're intelligent?

00:56:49.400 --> 00:56:51.880
Because that's effectively what a, what an LLM can do.

00:56:51.880 --> 00:56:54.160
It comes across as intelligent, right?

00:56:54.160 --> 00:56:57.680
It comes across that way to people like, oh, you have all the answers, but it doesn't mean

00:56:57.680 --> 00:56:59.720
you were good at problem solving necessarily.

00:56:59.720 --> 00:57:04.040
We're kind of peeling at this onion and we're kind of segmenting intelligence into its different

00:57:04.040 --> 00:57:07.120
categories to really kind of break it apart.

00:57:07.120 --> 00:57:12.040
Just from this vague word of intelligence into actually what are the parts that make

00:57:12.040 --> 00:57:13.040
something intelligent?

00:57:13.040 --> 00:57:14.040
What does it really mean?

00:57:14.040 --> 00:57:18.440
And what, what are still the things that like we thought were hard and are really easy or

00:57:18.440 --> 00:57:20.280
the things that we thought were easy and really hard.

00:57:20.280 --> 00:57:26.040
Because any LLM you have now can't chew gum and walk to the store and buy you something

00:57:26.040 --> 00:57:28.760
to eat and then play you in chess.

00:57:28.760 --> 00:57:34.200
And so the general and general AI isn't just there for, to make it sound grander.

00:57:34.200 --> 00:57:38.480
It's there because that's actually something that makes humans very, very unique is that

00:57:38.480 --> 00:57:43.880
I can have this conversation with you, write code, prepare an omelet, walk a dog and do

00:57:43.880 --> 00:57:45.960
all of these things all at once.

00:57:45.960 --> 00:57:47.160
And I started as a baby.

00:57:47.160 --> 00:57:50.440
And have feelings and thoughts and introspection about it and all that.

00:57:50.440 --> 00:57:54.040
- Hopes, dreams, like ketchup and not tomatoes and all sorts of other.

00:57:54.040 --> 00:57:55.240
- Yeah, super interesting.

00:57:55.240 --> 00:57:58.440
So are you, are you pretty positive on where stuff's going?

00:57:58.440 --> 00:58:02.760
- I'm less concerned about the AI itself and I'm more concerned about just how we react

00:58:02.760 --> 00:58:03.760
to it.

00:58:03.760 --> 00:58:06.540
And if we act, react intelligent, we react well.

00:58:06.540 --> 00:58:08.480
We went through the industrial revolution.

00:58:08.480 --> 00:58:10.440
We've went through the steel age.

00:58:10.440 --> 00:58:14.280
We're starting to go through the cognitive revolution or whatever people are going to

00:58:14.280 --> 00:58:15.880
call this a hundred years ago.

00:58:15.880 --> 00:58:18.100
I think by and large, people are going to be okay.

00:58:18.100 --> 00:58:22.560
I think we just need to have good policies, make sure that people do it responsibly, people

00:58:22.560 --> 00:58:23.560
do it well.

00:58:23.560 --> 00:58:26.760
And that's going to be the hard part is just how do we manage the transition?

00:58:26.760 --> 00:58:31.840
Well, how do we take a whole labor force whose jobs will be gone?

00:58:31.840 --> 00:58:36.760
Like there's no economic incentive to keep their jobs and retrain them in a really smart

00:58:36.760 --> 00:58:38.380
and sensible way.

00:58:38.380 --> 00:58:42.560
So people's livelihoods don't just go away to maximize the dollar.

00:58:42.560 --> 00:58:47.920
Those are kind of problems that are going to need good policy and clever solutions and

00:58:47.920 --> 00:58:50.880
a lot of research to actually sit down and handle well.

00:58:50.880 --> 00:58:55.200
But AI isn't going to go anywhere just like computers haven't went anywhere, but it's

00:58:55.200 --> 00:58:57.000
not terminated that we should worry about.

00:58:57.000 --> 00:58:58.000
- No, absolutely.

00:58:58.000 --> 00:58:59.000
It's certainly not.

00:58:59.000 --> 00:59:00.000
I was joking.

00:59:00.000 --> 00:59:05.120
We should worry about disinformation and politics and news and all that stuff.

00:59:05.120 --> 00:59:08.680
- I think people get so hung up on all the negatives that we kind of forget, like we're

00:59:08.680 --> 00:59:11.160
developing these tools for a reason.

00:59:11.160 --> 00:59:13.800
Scientists are spending so much time and we're excited about them for a reason.

00:59:13.800 --> 00:59:18.600
One being that I used to work on proteins, trying to find the structure of proteins.

00:59:18.600 --> 00:59:20.440
And that was one protein a year.

00:59:20.440 --> 00:59:22.440
It would take one year to find the structure of protein.

00:59:22.440 --> 00:59:23.440
And now I can run this.

00:59:23.440 --> 00:59:27.760
I took the same sequence that we found and ran it through AlphaFold, which is DeepMind's

00:59:27.760 --> 00:59:29.040
protein folding software.

00:59:29.040 --> 00:59:31.120
They could do it in five minutes.

00:59:31.120 --> 00:59:36.040
I mean, those are the things that are really like catalyze science and technology and healthcare

00:59:36.040 --> 00:59:39.140
and actually solve the problems we want to solve.

00:59:39.140 --> 00:59:40.320
So that's what I think we should do.

00:59:40.320 --> 00:59:44.640
- I think I heard even some AI stuff coming up with some new battery chemistry, potentially.

00:59:44.640 --> 00:59:45.640
- Everything.

00:59:45.640 --> 00:59:52.680
How do you appropriately kind of harness like a fusion ring and like a tokamak reactor or

00:59:52.680 --> 00:59:54.320
something like that.

00:59:54.320 --> 01:00:01.080
Everything even to, how do you route a PCB, like millions of traces effect.

01:00:01.080 --> 01:00:05.480
So it's a tool for the mind and it's not going to put our minds out of work.

01:00:05.480 --> 01:00:07.600
Like you said a long time ago when you were in your eye track.

01:00:07.600 --> 01:00:08.600
- Yeah, exactly.

01:00:08.600 --> 01:00:09.600
It's like a different view of that thing.

01:00:09.600 --> 01:00:13.160
It's like the same reason that none of us want to sit around and churn butter and go

01:00:13.160 --> 01:00:17.760
till the fields and walk to work.

01:00:17.760 --> 01:00:20.200
- I don't dislike my clothes washer.

01:00:20.200 --> 01:00:21.200
Not at all.

01:00:21.200 --> 01:00:22.200
Yeah.

01:00:22.200 --> 01:00:23.200
Awesome.

01:00:23.200 --> 01:00:24.200
All right.

01:00:24.200 --> 01:00:27.400
Well, thanks for giving us a look inside your lab, inside your research and the field, and

01:00:27.400 --> 01:00:29.400
then just, you know, share what you've gotten up to.

01:00:29.400 --> 01:00:30.400
It's been great.

01:00:30.400 --> 01:00:31.400
- Yeah, yeah, yeah.

01:00:31.400 --> 01:00:32.400
Thanks for having me.

01:00:32.400 --> 01:00:33.400
Yeah.

01:00:33.400 --> 01:00:37.080
It's been really great to, at least for the years that I've been in research, seeing how

01:00:37.080 --> 01:00:38.360
pivotal Python has been.

01:00:38.360 --> 01:00:43.240
And I think that's one of the big things that probably goes unnoticed by a lot of developers

01:00:43.240 --> 01:00:46.520
when they're actually writing their code to solve whatever problem they're solving is

01:00:46.520 --> 01:00:52.160
that someone who's wrote the NumPy library or the scikit-learn library, or, you know,

01:00:52.160 --> 01:00:56.760
Jupyter notebooks has actively played a part in curing diseases and making people's lives

01:00:56.760 --> 01:00:57.760
better.

01:00:57.760 --> 01:01:00.480
And those stories usually don't kind of come to the forefront.

01:01:00.480 --> 01:01:02.280
- It's not a direct line, right?

01:01:02.280 --> 01:01:06.980
But the research was done and facilitated by these open source tools and then discoveries

01:01:06.980 --> 01:01:07.980
were made.

01:01:07.980 --> 01:01:11.520
And that's the difference between people getting cured in 10 years or getting cured in a year.

01:01:11.520 --> 01:01:13.680
And that's thousands of lives.

01:01:13.680 --> 01:01:17.680
And so you might not think about it when you're sitting behind your desk, you know, making

01:01:17.680 --> 01:01:18.680
something usable.

01:01:18.680 --> 01:01:22.480
And, but for every day, a PhD student doesn't have to like pull their hair out and debug

01:01:22.480 --> 01:01:25.040
some software when it's well-written and it works well.

01:01:25.040 --> 01:01:27.360
That's a day that they can find something new.

01:01:27.360 --> 01:01:28.360
- That's awesome.

01:01:28.360 --> 01:01:29.360
Yeah.

01:01:29.360 --> 01:01:30.360
Very inspiring.

01:01:30.360 --> 01:01:31.360
Let's leave it there, Keelen.

01:01:31.360 --> 01:01:32.360
Thank you for being on the show.

01:01:32.360 --> 01:01:33.360
- Absolutely.

01:01:33.360 --> 01:01:34.360
- Yeah.

01:01:34.360 --> 01:01:35.360
It's been great to talk to you.

01:01:35.360 --> 01:01:36.360
- Thank you so much.

01:01:36.360 --> 01:01:37.360
- Yeah.

01:01:37.360 --> 01:01:39.260
- And thanks for joining Talk Python To Me.

01:01:39.260 --> 01:01:40.600
Thank you to our sponsors.

01:01:40.600 --> 01:01:41.960
Be sure to check out what they're offering.

01:01:41.960 --> 01:01:44.280
It really helps support the show.

01:01:44.280 --> 01:01:49.620
It's time to stop asking relational databases to do more than they were made for and simplify

01:01:49.620 --> 01:01:52.460
complex data models with graphs.

01:01:52.460 --> 01:01:57.900
Check out the sample FastAPI project and see what Neo4j, a native graph database can

01:01:57.900 --> 01:01:58.900
do for you.

01:01:58.900 --> 01:02:03.580
Find out more at talkpython.fm/neo4j.

01:02:03.580 --> 01:02:07.940
This episode is sponsored by Posit Connect from the makers of Shiny.

01:02:07.940 --> 01:02:12.220
Publish, share, and deploy all of your data projects that you're creating using Python.

01:02:12.220 --> 01:02:19.260
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

01:02:19.260 --> 01:02:20.980
Posit Connect supports all of them.

01:02:20.980 --> 01:02:23.820
Try Posit Connect for free by going to talkpython.fm/posit.

01:02:23.820 --> 01:02:24.820
P-O-S-I-T.

01:02:24.820 --> 01:02:28.700
Want to level up your Python?

01:02:28.700 --> 01:02:32.780
We have one of the largest catalogs of Python video courses over at Talk Python.

01:02:32.780 --> 01:02:37.900
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:02:37.900 --> 01:02:40.580
And best of all, there's not a subscription in sight.

01:02:40.580 --> 01:02:43.740
Check it out for yourself at training.talkpython.fm.

01:02:43.740 --> 01:02:48.360
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:02:48.360 --> 01:02:49.720
We should be right at the top.

01:02:49.720 --> 01:02:55.260
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the Direct

01:02:55.260 --> 01:02:59.340
RSS feed at /rss on talkpython.fm.

01:02:59.340 --> 01:03:01.860
We're live streaming most of our recordings these days.

01:03:01.860 --> 01:03:05.460
If you want to be part of the show and have your comments featured on the air, be sure

01:03:05.460 --> 01:03:10.380
to subscribe to our YouTube channel at talkpython.fm/youtube.

01:03:10.380 --> 01:03:11.700
This is your host, Michael Kennedy.

01:03:11.700 --> 01:03:12.820
Thanks so much for listening.

01:03:12.820 --> 01:03:14.060
I really appreciate it.

01:03:14.060 --> 01:03:15.820
Now get out there and write some Python code.

01:03:16.820 --> 01:03:19.820
[MUSIC PLAYING]

01:03:19.820 --> 01:03:22.820
[MUSIC ENDS]

01:03:22.820 --> 01:03:25.820
[MUSIC PLAYING]

01:03:25.820 --> 01:03:28.820
[MUSIC ENDS]

01:03:28.820 --> 01:03:31.820
[MUSIC PLAYING]

01:03:31.820 --> 01:03:34.820
[MUSIC ENDS]

01:03:34.820 --> 01:03:36.540


