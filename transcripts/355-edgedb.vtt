WEBVTT

00:00:00.001 --> 00:00:02.540
What database are you using for your apps these days?

00:00:02.540 --> 00:00:05.940
If you're like most Python people, it's probably Postgres SQL.

00:00:05.940 --> 00:00:09.100
If you roll with no SQL like me, you're probably using MongoDB.

00:00:09.100 --> 00:00:13.220
Maybe you're even using a graph database focused more on relationships.

00:00:13.220 --> 00:00:18.260
But there's a new Python database in town, and as you'll learn during this episode,

00:00:18.260 --> 00:00:22.380
many critical Python libraries have come into existence because of it.

00:00:22.380 --> 00:00:24.680
This database is called EdgeDB.

00:00:24.680 --> 00:00:29.280
EdgeDB is built upon Postgres and implemented mostly in Python.

00:00:29.440 --> 00:00:33.800
It's something of a marriage between traditional relational databases and an ORM.

00:00:33.800 --> 00:00:39.080
Python's async and await keywords, UV loop, the high-performance asyncio event loop,

00:00:39.080 --> 00:00:43.000
and async PG all have ties back to the creation of EdgeDB.

00:00:43.000 --> 00:00:49.120
Yuri Selvanov, the co-founder and CEO of EdgeDB, PSF fellow, and Python core developers

00:00:49.120 --> 00:00:53.800
here to tell us all about EdgeDB along with the history of many of these impactful

00:00:53.800 --> 00:00:55.520
language features and packages.

00:00:55.800 --> 00:01:01.540
This is Talk Python to Me, episode 355, recorded February 16th, 2022.

00:01:14.660 --> 00:01:17.740
Welcome to Talk Python to Me, a weekly podcast on Python.

00:01:17.740 --> 00:01:19.460
This is your host, Michael Kennedy.

00:01:19.460 --> 00:01:23.680
Follow me on Twitter where I'm @mkennedy, and keep up with the show and listen to past

00:01:23.680 --> 00:01:25.640
episodes at talkpython.fm.

00:01:25.640 --> 00:01:28.720
And follow the show on Twitter via at Talk Python.

00:01:28.720 --> 00:01:32.280
We've started streaming most of our episodes live on YouTube.

00:01:32.280 --> 00:01:38.060
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming

00:01:38.060 --> 00:01:39.900
shows and be part of that episode.

00:01:40.300 --> 00:01:43.180
This episode is brought to you by Sentry and SignalWire.

00:01:43.180 --> 00:01:49.760
Use Sentry to find out about and fix errors when they happen and build real-time next-generation

00:01:49.760 --> 00:01:52.500
video meeting rooms with SignalWire's API.

00:01:52.500 --> 00:01:56.800
Transcripts for this and all of our episodes are brought to you by Assembly AI.

00:01:56.800 --> 00:01:59.460
Do you need a great automatic speech-to-text API?

00:01:59.460 --> 00:02:02.000
Get human-level accuracy in just a few lines of code.

00:02:02.000 --> 00:02:04.860
Visit talkpython.fm/Assembly AI.

00:02:04.860 --> 00:02:07.000
Yuri, welcome to Talk Python to Me.

00:02:07.000 --> 00:02:07.300
Yeah.

00:02:07.340 --> 00:02:08.200
It's great to have you here.

00:02:08.200 --> 00:02:11.220
We just met recently at Pi Bay down there.

00:02:11.220 --> 00:02:14.080
So in honor of that, I wore my Pi Bay shirt today.

00:02:14.080 --> 00:02:17.000
Oh my God, I forgot about that episode.

00:02:17.000 --> 00:02:18.840
I probably should have worn my t-shirt.

00:02:18.840 --> 00:02:20.240
Yeah, where's your Pi Bay shirt?

00:02:20.240 --> 00:02:21.360
Yeah, yeah, yeah, yeah.

00:02:21.360 --> 00:02:23.520
What a cool conference, huh?

00:02:23.520 --> 00:02:23.920
It is.

00:02:24.000 --> 00:02:25.140
I love small conferences.

00:02:25.140 --> 00:02:26.360
I like small conferences.

00:02:26.360 --> 00:02:34.080
And in the time of COVID and all of this madness, having a winter conference outside in California

00:02:34.080 --> 00:02:36.880
at a beautiful food cart area where it's warm.

00:02:36.880 --> 00:02:39.320
Oh, there were just so many things to like about that.

00:02:39.320 --> 00:02:40.300
I got to tell you, it was great.

00:02:40.300 --> 00:02:40.980
It was amazing.

00:02:40.980 --> 00:02:44.140
It was the best day of the year for me, essentially.

00:02:44.280 --> 00:02:48.900
Just being able to talk to people finally and see many friends was amazing.

00:02:49.440 --> 00:02:50.760
We both gave talks there.

00:02:50.760 --> 00:02:52.660
I talked about Flask and HTMX.

00:02:52.660 --> 00:02:57.700
And you spoke about building a database engine, a whole database with Python.

00:02:57.700 --> 00:02:59.540
And that was interesting.

00:02:59.540 --> 00:03:04.880
So then I watched a little more and I just thought, wow, there are a lot of interesting pieces of

00:03:04.880 --> 00:03:08.640
technology in and around this thing you built called Edge TV.

00:03:08.760 --> 00:03:10.400
So I'm super excited to dive into that with you.

00:03:10.400 --> 00:03:12.980
But before we do, let's just hear your story real quick.

00:03:12.980 --> 00:03:14.400
How do you get into programming in Python?

00:03:14.400 --> 00:03:19.840
So my co-founder, Elvis, and I met many years ago, probably 14 years ago or something like that,

00:03:19.840 --> 00:03:25.360
working in a small Canadian company, building big enterprise software for companies like Walmart.

00:03:25.360 --> 00:03:31.080
Back then, we were actually like the system that we were working on was written in PHP.

00:03:31.080 --> 00:03:36.720
And I mean, we pushed PHP to the limits, but we always knew that, hey, when we start our own thing,

00:03:36.720 --> 00:03:40.300
we will be looking for something new and fresh for us to tinker with.

00:03:40.300 --> 00:03:44.880
And we looked around and we just like Python.

00:03:44.880 --> 00:03:46.060
Liked it a lot.

00:03:46.060 --> 00:03:46.980
Great syntax.

00:03:46.980 --> 00:03:47.440
Fantastic.

00:03:47.440 --> 00:03:48.220
Was that Django?

00:03:48.220 --> 00:03:52.320
I mean, that's right around the time of the Django growth or was it something else that brought you in?

00:03:52.320 --> 00:03:54.660
We started with Django.

00:03:54.660 --> 00:04:01.440
We played with it a little, but actually like we just started building our own thing pretty much

00:04:01.440 --> 00:04:06.080
immediately without looking like too deeply at existing frameworks or anything.

00:04:06.080 --> 00:04:06.340
Yeah.

00:04:06.340 --> 00:04:09.220
I get the sense that you and your co-founder are framework builders.

00:04:09.220 --> 00:04:10.280
Yes.

00:04:10.280 --> 00:04:11.120
Yes, we are.

00:04:11.120 --> 00:04:13.900
Somebody asked me, maybe it was Guido, I don't remember anymore.

00:04:13.900 --> 00:04:17.080
What was your first thing that you wrote on Python?

00:04:17.080 --> 00:04:18.680
And I said, the function decorator.

00:04:18.680 --> 00:04:20.540
I could just...

00:04:20.540 --> 00:04:21.460
John Trayden.

00:04:21.460 --> 00:04:22.580
Exactly.

00:04:22.580 --> 00:04:23.080
Awesome.

00:04:23.460 --> 00:04:24.500
So how about now?

00:04:24.500 --> 00:04:25.360
What are you doing these days?

00:04:25.360 --> 00:04:27.600
Working on EdgeDB full-time?

00:04:27.600 --> 00:04:28.180
EdgeDB.

00:04:28.180 --> 00:04:31.220
EdgeDB full-time exclusively.

00:04:31.220 --> 00:04:31.900
Yeah.

00:04:31.900 --> 00:04:33.580
We're building a great company here.

00:04:33.580 --> 00:04:36.540
So that requires 100% of my attention.

00:04:36.720 --> 00:04:36.940
Yeah.

00:04:36.940 --> 00:04:37.760
I bet it does.

00:04:37.760 --> 00:04:38.180
It's...

00:04:38.180 --> 00:04:42.740
You can build a business on the side, but it's a hard time.

00:04:42.740 --> 00:04:48.140
And you have this great article that talks about how you're going to build your favorite new database in a month,

00:04:48.140 --> 00:04:49.660
but that it actually takes 10 years.

00:04:49.660 --> 00:04:50.940
Do you like that, right?

00:04:51.240 --> 00:04:52.080
Yeah, pretty much.

00:04:52.080 --> 00:04:52.400
Yeah.

00:04:52.400 --> 00:04:55.260
It was a long, sometimes painful journey.

00:04:55.260 --> 00:05:01.420
And we didn't realize, like, right off the bat that we will be building a database, right?

00:05:01.420 --> 00:05:02.700
We were building a Python framework.

00:05:02.700 --> 00:05:04.540
And the Python ORM, essentially.

00:05:04.540 --> 00:05:06.000
And granted, that ORM was...

00:05:06.000 --> 00:05:06.160
Right.

00:05:06.160 --> 00:05:09.940
A better way to talk to databases in Python was your idea, right?

00:05:09.940 --> 00:05:10.380
Yeah.

00:05:10.380 --> 00:05:11.320
Yeah, exactly.

00:05:11.320 --> 00:05:14.260
But I guess you didn't have in mind that you would also build the database.

00:05:14.260 --> 00:05:16.020
No idea.

00:05:16.020 --> 00:05:16.480
Yeah.

00:05:16.480 --> 00:05:17.820
Very cool.

00:05:17.820 --> 00:05:19.880
Well, I think what you built is pretty interesting,

00:05:20.080 --> 00:05:22.240
and people are going to enjoy checking it out.

00:05:22.240 --> 00:05:30.400
But more so, I think what is pretty interesting is there's a lot of things in the Python space that we enjoy and we appreciate,

00:05:30.400 --> 00:05:35.560
especially what I would consider to be the advantages of modern Python.

00:05:35.560 --> 00:05:37.040
I don't know how you feel about it.

00:05:37.040 --> 00:05:38.480
I know you've been deep in this world.

00:05:38.480 --> 00:05:47.000
But to me, it seems like just two or three years ago, people building frameworks, you know, think FastAPI or Pydantic or stuff like that,

00:05:47.000 --> 00:05:50.380
have really embraced the...

00:05:50.380 --> 00:05:52.400
They've taken full advantage of Python 3, right?

00:05:52.400 --> 00:05:55.100
They said, oh, look, we have these typing, we have typing, we have ASIC and away.

00:05:55.100 --> 00:05:56.540
We have all these things that we can bring together.

00:05:56.540 --> 00:06:00.860
And it really feels like that stuff is all starting to come together in a big way.

00:06:00.860 --> 00:06:02.160
Is that over the last couple of years?

00:06:02.160 --> 00:06:02.560
What do you think?

00:06:02.560 --> 00:06:02.980
Yeah.

00:06:03.100 --> 00:06:09.660
I also have this feeling that the ecosystem becomes more and more robust, that people build amazing systems with Python.

00:06:09.660 --> 00:06:14.300
I think that asynchronous IO played a part in it for sure.

00:06:14.300 --> 00:06:19.960
But I think that the other big thing that is happening to Python right now is strict typing.

00:06:19.960 --> 00:06:23.500
mypy and the other similar tools.

00:06:23.500 --> 00:06:27.140
This is what actually allows you to manage your code base at scale.

00:06:27.140 --> 00:06:30.360
And this is just incredibly important.

00:06:30.360 --> 00:06:33.020
So yeah, those two things I would say.

00:06:33.280 --> 00:06:33.500
Absolutely.

00:06:33.500 --> 00:06:40.320
And you talk, we're going to get into it when we get into the architecture and stuff, but you talk about using Cython for making parts of your Python code faster.

00:06:40.320 --> 00:06:43.260
And of course, that relies heavily on typing.

00:06:43.260 --> 00:06:44.940
Because you want to say, here's an int 64.

00:06:44.940 --> 00:06:49.240
Don't turn it to a pi, you know, pi long object pointer.

00:06:49.240 --> 00:06:52.640
We just want an int 64 that works on the stack really quickly, right?

00:06:52.740 --> 00:06:53.560
Yeah, yeah, absolutely.

00:06:53.560 --> 00:06:55.120
I mean, it's an open question.

00:06:55.120 --> 00:07:04.240
Will Python ever enjoy strict typing that the Python interpreter actually takes care of to make things run faster or not?

00:07:04.240 --> 00:07:06.760
But for Cython, it's absolutely critical.

00:07:06.760 --> 00:07:13.840
And actually, I had this, sometimes I had this feeling that writing code in Cython is easier than in Python because, hey, I have a compiler.

00:07:13.840 --> 00:07:15.220
Something mismatches.

00:07:15.220 --> 00:07:17.540
I know it at the compile time, not the run time.

00:07:17.540 --> 00:07:17.880
Yeah.

00:07:17.880 --> 00:07:20.280
I suspect myPy is a little like that as well, right?

00:07:20.380 --> 00:07:21.220
Exactly, exactly.

00:07:21.220 --> 00:07:30.700
So when myPy started happening, because I was experimenting heavily with Cython before myPy became popular, when myPy finally became like this common thing to use.

00:07:30.700 --> 00:07:34.740
Yeah, it was almost a revelation that we finally have this beautiful workflow with Python.

00:07:34.740 --> 00:07:41.780
Well, I want to talk about some of the technologies that are sort of surrounding this larger project that you've been working on.

00:07:41.780 --> 00:07:45.460
So over on GitHub, github.com slash magic stack.

00:07:45.460 --> 00:07:48.420
This is for, this is your company.

00:07:48.860 --> 00:07:53.180
And one of the, you know, where sort of EdgeDB and all that is coming out of.

00:07:53.180 --> 00:08:02.620
But there's a lot of interesting things happening here that I think people who see modern Python doing its thing are going to appreciate.

00:08:02.620 --> 00:08:05.440
We talked about the async stuff and so on.

00:08:05.440 --> 00:08:12.380
And so I wanted to kind of dive into some of those first that are sort of orbiting your projects that you all have created here.

00:08:12.380 --> 00:08:14.400
So let's start with Magic Python.

00:08:14.400 --> 00:08:16.260
Tell us what this Magic Python is about.

00:08:16.260 --> 00:08:18.360
So Magic Python is a syntax highlighter.

00:08:18.360 --> 00:08:21.600
It's actually used in VS Code by default.

00:08:21.600 --> 00:08:27.420
So if you use VS Code and you edit Python in VS Code, this is the stuff that VS Code uses under the hood.

00:08:27.420 --> 00:08:32.180
It was used by GitHub for years to highlight all Python code.

00:08:32.680 --> 00:08:37.860
And recently I think GitHub switched to this tree sitter other Python highlighter.

00:08:37.860 --> 00:08:42.700
But yeah, Magic Python was, and I guess is, incredibly popular.

00:08:42.700 --> 00:08:47.460
It was born out of frustration actually because we were big fans of metaprogramming.

00:08:47.460 --> 00:08:49.860
We abused Python a lot in interesting ways.

00:08:50.100 --> 00:08:55.820
And one of the ways to abuse it was to push some meta information to function annotations.

00:08:55.820 --> 00:08:58.780
It was before mypy and before typing.

00:08:58.780 --> 00:09:02.220
So yeah, we just were like adding stuff to those annotations.

00:09:02.220 --> 00:09:06.960
So we quickly discovered that built-in syntax highlighters in TextMate back then.

00:09:06.960 --> 00:09:08.520
Back then I was using TextMate heavily.

00:09:08.520 --> 00:09:10.720
They just couldn't highlight annotations.

00:09:10.720 --> 00:09:17.880
So my goal was to basically, hey, can we create our own syntax highlighter for Python that would just take care of annotations?

00:09:17.880 --> 00:09:22.540
And by the way, highlight all of the newer stuff that is available in Python 3.

00:09:22.540 --> 00:09:25.740
Because back then Python 2 was still the king.

00:09:25.740 --> 00:09:28.160
And Python 3 was kind of barely supported.

00:09:28.160 --> 00:09:28.660
Interesting.

00:09:28.660 --> 00:09:35.680
So a lot of the highlighters and editors and stuff really would highlight kind of based on Python 2 type syntax.

00:09:35.680 --> 00:09:36.180
Exactly.

00:09:36.180 --> 00:09:36.360
Exactly.

00:09:36.360 --> 00:09:37.720
But I guess.

00:09:37.720 --> 00:09:41.740
No, it's 20, whatever this was, in 2015 or something.

00:09:41.740 --> 00:09:42.000
2015.

00:09:42.000 --> 00:09:42.820
Yeah, yeah.

00:09:42.820 --> 00:09:44.800
It was clear to me that Python 3 is the future.

00:09:44.800 --> 00:09:48.280
But yeah, the industry was still kind of moving slowly towards it.

00:09:48.280 --> 00:09:56.100
But the key innovation of Magic Python, and I think this is why I think it's a high quality thing, is unit tests.

00:09:56.380 --> 00:10:02.080
So I'm a big fan of writing tests and having this test-driven development.

00:10:02.080 --> 00:10:12.440
And the first thing after highlighting Hello World in TextMate, first thing for me was to figure out, can I actually build a unit test engine?

00:10:12.440 --> 00:10:17.740
Because if you think of those syntax highlighters, it's essentially, it's a huge reg exp.

00:10:17.740 --> 00:10:21.620
It's just mind-bogglingly, like huge, huge, huge reg exp.

00:10:21.620 --> 00:10:23.900
And writing reg exp is hard.

00:10:23.900 --> 00:10:24.980
Yeah.

00:10:25.700 --> 00:10:28.440
But modifying them is much harder.

00:10:28.440 --> 00:10:28.500
I was thinking about that.

00:10:28.500 --> 00:10:36.540
Well, I was thinking down the road, you have a really interesting query syntax that's pretty rich and powerful for EdgeDB.

00:10:36.540 --> 00:10:37.020
Yeah.

00:10:37.020 --> 00:10:46.100
Did your experience writing Magic Python give you the ability to go like, oh, yeah, we can write this thing that parses this insane sort of complex language?

00:10:46.320 --> 00:10:50.060
How much did this play into your ability to go beyond SQL?

00:10:50.060 --> 00:10:51.300
I wouldn't say much.

00:10:51.300 --> 00:10:55.400
I mean, we have syntax highlighters for our schema files and the EdgeQL.

00:10:55.400 --> 00:10:56.860
They're pretty basic right now.

00:10:56.860 --> 00:10:59.240
We just highlight keywords and literals.

00:10:59.240 --> 00:11:01.800
We have some interesting plans about that.

00:11:01.800 --> 00:11:02.980
And we can talk about that later.

00:11:02.980 --> 00:11:07.980
I guess we'll be talking about it to be like implementing language server protocol for EdgeQL.

00:11:07.980 --> 00:11:10.980
But the highlighter itself is pretty simple.

00:11:10.980 --> 00:11:15.660
But I used this unit testing framework in those highlighters.

00:11:15.660 --> 00:11:17.720
And this is what gives me peace of mind.

00:11:17.720 --> 00:11:22.960
I know that EdgeQL highlight is just working when I'm adding like a new operator or a new keyword.

00:11:22.960 --> 00:11:27.440
I don't have to just test it manually on some big file.

00:11:27.440 --> 00:11:28.080
Yeah, absolutely.

00:11:28.080 --> 00:11:31.940
Sort of speaking to that thing that I talked about, a lot of interesting stuff coming out of your work.

00:11:31.940 --> 00:11:35.820
Adrian out there says, didn't know you also made HTTP tools as well.

00:11:35.820 --> 00:11:38.400
Indeed, yeah, there's a lot of cool stuff that you've done.

00:11:38.400 --> 00:11:40.400
So final thing on Magic Python.

00:11:40.400 --> 00:11:44.420
Can I use it for other purposes than just VS Code, Sublime, and Atom?

00:11:44.760 --> 00:11:52.340
Like if I wanted to build my own thing that, you know, printed out like terminal stuff or like even some other kind of UI app.

00:11:52.340 --> 00:11:54.760
Could I use this more generally than the editors?

00:11:54.760 --> 00:11:56.360
I haven't tried it myself.

00:11:56.360 --> 00:12:10.100
But given that GitHub was using it to highlight the code, I believe that there must be some libraries and packages that just can consume this text-made inspired syntax and just highlight, I don't know, stuff you print into terminal.

00:12:10.100 --> 00:12:10.480
I see.

00:12:10.480 --> 00:12:14.740
So it comes out as text-made and then it just happens to these three editors with their...

00:12:14.740 --> 00:12:15.240
Yeah, I think...

00:12:15.240 --> 00:12:16.720
Sort of common heritage, understand that.

00:12:16.720 --> 00:12:17.100
Yeah, yeah.

00:12:17.100 --> 00:12:24.360
I think text-made started the revolution originally, then Sublime Text just inherited the format and then VS Code just decided, hey, we should just use it.

00:12:24.360 --> 00:12:25.640
Yeah.

00:12:25.640 --> 00:12:26.040
Cool.

00:12:26.040 --> 00:12:27.800
Yeah, very cool.

00:12:27.800 --> 00:12:28.160
All right.

00:12:28.160 --> 00:12:41.520
So when you spoke about your journey towards creating this product in this business, you talked about how central having asynchronous IO and server work is going to be.

00:12:41.620 --> 00:12:43.340
And of course that is true, right?

00:12:43.340 --> 00:12:52.380
Not all databases, but most databases are able to be a point of extreme concurrency to the point that they can handle the processing, right?

00:12:52.380 --> 00:12:55.280
So if you've got a web app, you can scale your web app out.

00:12:55.280 --> 00:13:00.280
And if it's got two connections or 200 connections to the database, generally, that's fine.

00:13:00.280 --> 00:13:03.820
The database is meant to sort of scale that vertically, I guess.

00:13:04.020 --> 00:13:10.300
So you really talked about, well, if you're going to do this in Python, that probably means leveraging asyncio pretty strongly, right?

00:13:10.300 --> 00:13:10.960
Yeah, yeah.

00:13:10.960 --> 00:13:13.680
It was pretty clear that we need asynchronous IO.

00:13:13.680 --> 00:13:16.360
As you said, databases have to handle lots of connections.

00:13:16.360 --> 00:13:23.580
And also it's important to understand that most databases like Postgres, for example, the cost of establishing a new connection is pretty high.

00:13:23.580 --> 00:13:26.000
So we wanted Edge.

00:13:26.000 --> 00:13:28.480
And I mean, there are tools to mitigate that.

00:13:28.480 --> 00:13:29.780
Like PG Bouncer, for example.

00:13:29.780 --> 00:13:33.100
It's like middleware you put in front of PostgresQL to make connections cheaper.

00:13:33.480 --> 00:13:38.480
And we just didn't want to have any of such tools as a requirement for Edge.

00:13:38.480 --> 00:13:42.700
We just wanted it to work like natively out of the box without any configuration.

00:13:42.700 --> 00:13:47.900
So yeah, we had to have cheap connections in terms of like how fast you can connect.

00:13:47.900 --> 00:13:52.780
And also, I mean, if your connection is just hanging out there, we wanted to allow that essentially.

00:13:52.780 --> 00:14:01.760
So we had to have a way to handle thousands, maybe hundreds of thousands, just concurrent connections that maybe are not super active, but just, I mean, open.

00:14:02.160 --> 00:14:07.720
And asynchronous core is the only way how you would be able to do this.

00:14:07.720 --> 00:14:14.880
Like not even like even if Python didn't have GIL, for example, you would still use asynchronous IO to tackle this problem.

00:14:14.880 --> 00:14:19.920
This portion of Talk Python to me is brought to you by Sentry.

00:14:19.920 --> 00:14:22.800
How would you like to remove a little stress from your life?

00:14:22.800 --> 00:14:28.780
Do you worry that users may be encountering errors, slowdowns or crashes with your app right now?

00:14:28.780 --> 00:14:31.840
Would you even know it until they sent you that support email?

00:14:31.840 --> 00:14:42.240
How much better would it be to have the error or performance details immediately sent to you, including the call stack and values of local variables and the active user recorded in the report?

00:14:42.240 --> 00:14:45.660
With Sentry, this is not only possible, it's simple.

00:14:45.660 --> 00:14:49.220
In fact, we use Sentry on all the Talk Python web properties.

00:14:49.400 --> 00:14:55.780
We've actually fixed a bug triggered by a user and had the upgrade ready to roll out as we got the support email.

00:14:55.780 --> 00:14:57.760
That was a great email to write back.

00:14:57.760 --> 00:15:01.140
Hey, we already saw your error and have already rolled out the fix.

00:15:01.140 --> 00:15:02.580
Imagine their surprise.

00:15:02.580 --> 00:15:04.780
Surprise and delight your users.

00:15:04.780 --> 00:15:08.840
Create your Sentry account at talkpython.fm/Sentry.

00:15:09.040 --> 00:15:20.520
And if you sign up with the code talkpython, all one word, it's good for two free months of Sentry's business plan, which will give you up to 20 times as many monthly events as well as other features.

00:15:20.520 --> 00:15:22.080
Create better software.

00:15:22.080 --> 00:15:24.920
Delight your users and support the podcast.

00:15:24.920 --> 00:15:29.880
Visit talkpython.fm/Sentry and use the coupon code talkpython.

00:15:32.280 --> 00:15:38.260
There's an overhead for threads and the context switching between the OS trying to figure out if that thread still needs to do stuff.

00:15:38.260 --> 00:15:41.980
Yeah, you can't have hundreds of thousands of threads and be in a good place.

00:15:41.980 --> 00:15:44.920
Yeah, but my concern wasn't even that.

00:15:44.920 --> 00:15:49.280
Maybe we would be smart and implement some sort of M2 and scheduling or something like that.

00:15:49.280 --> 00:15:50.240
I don't know.

00:15:50.240 --> 00:15:54.060
It's just I don't believe that humans are good at writing threaded code.

00:15:54.060 --> 00:16:02.140
Async await gives you this luxury of essentially seeing where you can actually give up control.

00:16:02.140 --> 00:16:06.100
of the current code when it can await things and potentially switch the context, right?

00:16:06.100 --> 00:16:10.320
So you can be smart about locking access to shared resources and things like that.

00:16:10.320 --> 00:16:13.880
With threads, it's way, way harder.

00:16:13.880 --> 00:16:19.580
Maybe with Rust, it's easier because, I mean, there is some compile time magic that can help you.

00:16:19.580 --> 00:16:25.500
But with pretty much every other language, thread-based programming is very hard.

00:16:25.500 --> 00:16:26.060
It is hard.

00:16:26.500 --> 00:16:38.640
Well, I suspect many people, but not everyone out there listening knows that when you use the asyncio tasks and so on, at least by default, they run on a single thread.

00:16:38.640 --> 00:16:40.320
There's not actual threading happening.

00:16:40.320 --> 00:16:43.760
When you use threads or multiprocessing, you can get that true concurrency.

00:16:43.760 --> 00:16:45.680
But this is different.

00:16:45.680 --> 00:16:46.700
It's not really threads.

00:16:46.700 --> 00:16:47.640
Yeah, it's different.

00:16:47.880 --> 00:16:53.460
Basically, the idea for async await is to use it for IO bound code.

00:16:53.460 --> 00:16:59.720
So if your code is doing like lots of IO, pushing data from multiple connections here and there, this is an ideal thing.

00:16:59.720 --> 00:17:11.500
But if you're computing something like, I don't know, doing something, scientific computation or just use blocking IO or disk IO, it's best to offset that computation into a separate process.

00:17:12.500 --> 00:17:18.480
But yeah, if you just want to handle a lot of IO in Python concurrently, asyncio is the way.

00:17:18.480 --> 00:17:25.860
Yeah, the way that I like to think of asyncio and async and await is what you're scaling is you're scaling the waiting.

00:17:25.860 --> 00:17:38.300
If you're waiting on anything, if I'm waiting on a database or waiting in the database version for the client to talk to me or not to talk to me, then you can basically take that period where you'd be waiting and turn that into predictive computational time.

00:17:38.300 --> 00:17:39.000
I love it.

00:17:39.000 --> 00:17:41.520
I think we should put this like straight into the ducks.

00:17:41.520 --> 00:17:44.160
I've never thought about this this week.

00:17:44.160 --> 00:17:53.440
Because people tell me, I'll see these benchmarks and stuff said, oh, well, I did this thing where I overwhelmed the database and then it didn't go very fast when I did asyncio.

00:17:53.440 --> 00:17:56.040
It's like, well, because there's no period in which you're waiting.

00:17:56.040 --> 00:18:00.100
Like you're like constraining the resource beyond what it can take.

00:18:00.100 --> 00:18:03.100
But if there was some sort of, oh, I'm waiting for this thing to get back to me.

00:18:03.100 --> 00:18:05.660
Well, then all of a sudden there's your performance.

00:18:05.660 --> 00:18:06.720
Okay.

00:18:06.900 --> 00:18:09.280
So when I saw this come out, I was super excited.

00:18:09.280 --> 00:18:10.800
I think this was 3.4.

00:18:10.800 --> 00:18:14.500
My history reminds me correctly when this came out.

00:18:14.500 --> 00:18:15.360
Is that, do you remember?

00:18:15.360 --> 00:18:19.260
I think it was around 3.4 because the most important prerequisite.

00:18:19.260 --> 00:18:20.120
I think so.

00:18:20.120 --> 00:18:21.140
Because 3.5.

00:18:21.140 --> 00:18:21.780
Yeah, go ahead.

00:18:21.780 --> 00:18:22.040
Sorry.

00:18:22.040 --> 00:18:26.460
Yeah, the most important prerequisite for asyncio to happen was actually the yield from syntax.

00:18:26.460 --> 00:18:28.500
Probably not a lot of people remember about it.

00:18:28.500 --> 00:18:35.940
But back then, asyncio required this like add-corting decorator and you would use yield from instead of await in your code.

00:18:35.940 --> 00:18:42.120
So that PAP, so basically Python 3.3, I think, was a moratorium on modifying Python language.

00:18:42.120 --> 00:18:46.260
So we had to wait for Python 3.4 to add yield from and then asyncio happened.

00:18:46.260 --> 00:18:47.320
We made it happen.

00:18:47.320 --> 00:18:47.560
Right.

00:18:47.560 --> 00:18:48.580
That enabled it.

00:18:48.820 --> 00:18:51.580
But when I remember when it came out, I was like super excited about this.

00:18:51.580 --> 00:18:54.800
And I said like, oh, this is a harsh programming model.

00:18:54.800 --> 00:18:59.040
This is really like direct and juggling those sorts of things.

00:18:59.040 --> 00:19:05.100
And I had experience with C Sharp, which had async and await keywords as well.

00:19:05.100 --> 00:19:07.420
I'm like, gosh, I wish this language had async and await.

00:19:07.420 --> 00:19:15.320
And then I didn't know you then, but I thank you because you authored PEP492 coroutines with async and await.

00:19:15.320 --> 00:19:18.460
Basically, we have async and await in Python because of you, right?

00:19:18.640 --> 00:19:19.260
Well, somewhat.

00:19:19.260 --> 00:19:19.900
Yes.

00:19:19.900 --> 00:19:21.360
I don't want to give you too much credit.

00:19:21.360 --> 00:19:21.720
I did.

00:19:21.720 --> 00:19:28.420
You created the PEP that said like, let's stop using yield from and continue and all these other things that you do.

00:19:28.420 --> 00:19:30.380
I can tell you the entire backstory.

00:19:30.380 --> 00:19:31.520
It's relatively short.

00:19:31.520 --> 00:19:31.980
Yeah.

00:19:31.980 --> 00:19:32.200
Yeah.

00:19:32.300 --> 00:19:41.600
So basically we were trying to figure out like the future API for HDB, Python client back then when HDB wasn't doing a thing.

00:19:41.600 --> 00:19:46.840
And we knew that we want to support asyncio in our future client.

00:19:47.360 --> 00:19:49.620
But how do you actually have like a migration block?

00:19:49.620 --> 00:19:53.580
Like you would have to say like try, finally accept, back, commit.

00:19:53.580 --> 00:19:54.680
It's like a lot of code.

00:19:54.680 --> 00:19:56.440
And we have context managers in Python, right?

00:19:56.440 --> 00:20:02.620
So with the context manager, you would just say with transaction and just do all this magic behind the scenes.

00:20:02.620 --> 00:20:05.660
But we didn't have an asynchronous version of with.

00:20:05.660 --> 00:20:07.240
We had yield from.

00:20:07.240 --> 00:20:12.100
But how do you kind of mush together yield from and with wasn't clear.

00:20:12.100 --> 00:20:16.440
So I thought, hey, if we have like async keyword, we could have async with.

00:20:16.440 --> 00:20:17.900
Then it was natural case.

00:20:18.000 --> 00:20:22.260
We just should replace yield from with await because it was also familiar with C#.

00:20:22.260 --> 00:20:26.060
And I also liked the short and neat syntax of async await.

00:20:26.060 --> 00:20:34.560
And then the next thought was that, hey, what if you have a cursor to the database and just want to iterate over the rows and make it like prefetch those rows.

00:20:34.560 --> 00:20:36.080
And this is how async four was born.

00:20:36.080 --> 00:20:39.000
And then in about a couple of weeks, language summit happened.

00:20:39.000 --> 00:20:40.480
I think it was in Montreal.

00:20:40.480 --> 00:20:43.720
That was back on US in Montreal.

00:20:43.720 --> 00:20:44.900
And I met with Guido.

00:20:45.160 --> 00:20:48.520
I showed him like rough sketch and he said, yeah, let's do it.

00:20:48.520 --> 00:20:54.860
I think I implemented the first prototype of this thing in the interpreter over a couple of nights.

00:20:54.860 --> 00:20:57.380
Like I just called it like straight 48 hours.

00:20:57.380 --> 00:20:59.000
I wanted to impress Guido.

00:20:59.000 --> 00:21:03.440
And yeah, I just had this like rough implementation.

00:21:03.440 --> 00:21:08.760
And then just over the course of like months and a half, I was refining it and writing this path.

00:21:08.760 --> 00:21:09.960
And this is how it happened.

00:21:09.960 --> 00:21:11.300
I think it all happened because of Guido.

00:21:11.420 --> 00:21:16.480
Because first of all, he saw like clearly like this is an improvement to Yulthrom, like a big improvement.

00:21:16.480 --> 00:21:17.460
It's a huge improvement.

00:21:17.460 --> 00:21:19.440
It makes it incredibly approachable.

00:21:19.440 --> 00:21:22.860
It's like you do what you normally do, but sometimes you might have to put the word await there.

00:21:22.860 --> 00:21:23.320
Exactly.

00:21:23.320 --> 00:21:27.980
But your mental model isn't about callbacks and weird stuff like that.

00:21:27.980 --> 00:21:31.660
It's just like you write the regular code, but you sometimes need to await a thing.

00:21:31.740 --> 00:21:32.540
And it's beautiful.

00:21:32.540 --> 00:21:33.380
Yeah, exactly.

00:21:33.380 --> 00:21:33.700
Exactly.

00:21:33.700 --> 00:21:38.860
And yeah, I'm grateful to Guido because first of all, he recognized this thing and encouraged me.

00:21:38.860 --> 00:21:43.700
And second of all, he actually like inspired lots and lots of refinements in this proposal.

00:21:43.700 --> 00:21:46.740
And I was like working with him essentially all this time.

00:21:46.740 --> 00:21:49.520
Like a discussion happened in Python, in Python dev.

00:21:49.620 --> 00:21:53.960
And sometimes he and I exchanged emails and he proposed some ideas and I would just tweak the path.

00:21:53.960 --> 00:21:57.480
Yeah, Guido was actually also behind this proposal to a big extent.

00:21:57.480 --> 00:22:02.820
There's some mind-blowing stuff here, like the async with, for example, as you point out, right?

00:22:02.820 --> 00:22:04.540
These are wild ideas, right?

00:22:04.540 --> 00:22:06.960
Instead of just calling, just saying here, there can be a function.

00:22:06.960 --> 00:22:08.740
You have async for, async with.

00:22:08.740 --> 00:22:10.180
There's really neat things in here.

00:22:10.180 --> 00:22:15.000
Actually, yeah, I think that still async with is pretty unique.

00:22:15.000 --> 00:22:21.660
Like JavaScript, for example, is lucky because they have this nice syntax for declaring anonymous functions, right?

00:22:21.660 --> 00:22:26.700
And so you can just say await transaction and pass a function.

00:22:26.700 --> 00:22:28.440
And it's like a multi-line function.

00:22:28.440 --> 00:22:29.480
You can do whatever you need.

00:22:29.480 --> 00:22:34.180
You don't actually have to have something like async with in TypeScript or JavaScript.

00:22:34.180 --> 00:22:38.900
But in many other languages, you would need something like this.

00:22:38.900 --> 00:22:43.240
And pretty much, I think, we pioneered this idea in Python.

00:22:43.240 --> 00:22:49.580
I think I saw a proposal to make using async in C Sharp, but I'm not actively engaged with C Sharp community.

00:22:49.580 --> 00:22:50.080
So I'm not.

00:22:50.080 --> 00:22:51.160
Maybe it was implemented.

00:22:51.160 --> 00:22:51.660
Maybe not.

00:22:51.660 --> 00:22:52.240
I don't know.

00:22:52.240 --> 00:22:55.500
That would be the parallel, but I'm also not tracking it.

00:22:55.500 --> 00:22:55.820
Yeah.

00:22:55.820 --> 00:22:56.140
Okay.

00:22:56.140 --> 00:22:57.620
This is really cool.

00:22:57.620 --> 00:23:00.900
So awesome, awesome work on this PEP and getting this language.

00:23:00.900 --> 00:23:01.160
Thank you.

00:23:01.160 --> 00:23:01.480
Thank you.

00:23:01.480 --> 00:23:02.400
Yeah.

00:23:02.400 --> 00:23:05.980
So let's talk two more async I think real quick here before we get to EdgeDB.

00:23:05.980 --> 00:23:08.220
Or actually, three.

00:23:08.560 --> 00:23:10.340
One jumped the list just yesterday.

00:23:10.340 --> 00:23:11.020
Absolutely.

00:23:11.020 --> 00:23:11.440
Okay.

00:23:11.440 --> 00:23:20.860
So when you're doing asyncio, there's this background event loop that looks at all the things that could be done and says, are any of them waiting?

00:23:20.860 --> 00:23:25.160
Can we take that while it's waiting and put it aside and go do something else, right?

00:23:25.160 --> 00:23:27.020
That way I scale the waiting story.

00:23:27.240 --> 00:23:29.940
And there's an implementation for that in CPython.

00:23:29.940 --> 00:23:41.300
But you all decided, you and Elvis, your co-founder, decided it would be nice if there was a faster, more optimized version of that part that does the checking and execution.

00:23:41.800 --> 00:23:45.500
So you created this thing called UV loop, an ultra fast asyncio event loop.

00:23:45.500 --> 00:23:47.100
It's incredibly easy to use, right?

00:23:47.100 --> 00:23:47.980
Like to install it.

00:23:47.980 --> 00:23:48.340
Two lines.

00:23:48.340 --> 00:23:50.600
It's two lines, right?

00:23:50.600 --> 00:23:54.760
You import and then you run install and you're good to go, which is fantastic.

00:23:55.500 --> 00:24:03.340
Tell people about UV loop and how broadly, should this just be standard stuff we do in all of our code that uses async and await?

00:24:03.340 --> 00:24:04.760
That's an interesting question.

00:24:04.760 --> 00:24:05.840
Okay, let's jump in.

00:24:05.840 --> 00:24:08.800
So UV loop wasn't the first thing that I created.

00:24:08.800 --> 00:24:10.680
The first thing was actually HTTP tools.

00:24:11.100 --> 00:24:13.520
Someone asked you about it like a few minutes ago.

00:24:13.520 --> 00:24:16.720
So I just wanted to experiment with Cython.

00:24:16.720 --> 00:24:18.000
I discovered Cython.

00:24:18.000 --> 00:24:26.340
I thought, hey, this might actually be a useful tool and allow us to speed up Python a lot for some things like parsing HTTP, for example.

00:24:26.340 --> 00:24:26.620
Right.

00:24:26.620 --> 00:24:27.560
The tight loops.

00:24:27.560 --> 00:24:28.000
Yeah.

00:24:28.000 --> 00:24:28.500
Exactly.

00:24:28.500 --> 00:24:28.800
Exactly.

00:24:28.800 --> 00:24:33.560
So I look at Node.js and they used a C HTTP parser.

00:24:33.560 --> 00:24:36.820
I think that parser was actually extracted from Nginx.

00:24:36.820 --> 00:24:40.500
And yeah, just wrapped it in HTTP tools.

00:24:40.620 --> 00:24:43.740
Just literally like 100 lines of code, maybe even less, maybe 50.

00:24:43.740 --> 00:24:47.260
Just like a small wrapper over the C library.

00:24:47.260 --> 00:24:48.480
And it worked.

00:24:48.480 --> 00:24:49.480
And it worked great.

00:24:49.480 --> 00:24:52.440
Then I, oh my God, I now have this superpower.

00:24:52.440 --> 00:24:54.140
I can quickly.

00:24:54.140 --> 00:24:56.220
What other things can I grab and wrap up and put it into PHP?

00:24:56.220 --> 00:24:56.600
Exactly.

00:24:56.600 --> 00:24:56.620
Exactly.

00:24:56.620 --> 00:25:04.360
Because, I mean, you could do the same, but just like using Python C API, but you would end up writing like 3x, maybe 5x amount of code.

00:25:04.360 --> 00:25:06.640
And using Cython just feels like magic.

00:25:06.640 --> 00:25:08.520
So, yeah, it worked.

00:25:08.520 --> 00:25:10.340
And then I was like, hmm.

00:25:10.340 --> 00:25:11.080
Interesting.

00:25:11.080 --> 00:25:11.180
Interesting.

00:25:11.180 --> 00:25:16.400
So there is this libuv library that actually powers Node.js and it's cross-platform.

00:25:16.400 --> 00:25:19.560
And it's super fast and Node.js is fast.

00:25:19.560 --> 00:25:23.120
Maybe, just maybe, I can do the same.

00:25:23.120 --> 00:25:26.720
I can just wrap it into Python and make a drop-in replacement for it eventually.

00:25:27.080 --> 00:25:29.500
So I prototyped something relatively quickly.

00:25:29.500 --> 00:25:31.100
Maybe in a few days.

00:25:31.100 --> 00:25:34.640
Basically, I just implemented like a loop object and call soon.

00:25:34.640 --> 00:25:37.360
Like, basically the staple of ACKIO.

00:25:37.780 --> 00:25:39.320
The most basic thing.

00:25:39.320 --> 00:25:40.160
And it worked.

00:25:40.160 --> 00:25:41.000
It worked just fine.

00:25:41.000 --> 00:25:42.420
I was able to implement call later.

00:25:42.420 --> 00:25:47.600
And then I was able to run a coroutine like, await sleep one, print hello world.

00:25:47.600 --> 00:25:48.480
And it worked.

00:25:48.480 --> 00:25:54.160
And then I just, over the course of next several months, I think three, maybe four, maybe five months.

00:25:54.160 --> 00:25:57.700
I was gradually implementing AsyncIO API.

00:25:57.700 --> 00:26:01.220
I swearing a lot because I discovered that this API surface is just huge.

00:26:01.220 --> 00:26:04.180
AsyncIO event loop is just, it's an enormous API actually.

00:26:04.180 --> 00:26:11.240
And yeah, then we, we posted benchmarks and I think it went somewhat viral.

00:26:11.240 --> 00:26:13.360
It was in HN.

00:26:13.360 --> 00:26:17.600
I think it was like post number one on HN for a long time.

00:26:17.600 --> 00:26:17.740
Yeah.

00:26:17.740 --> 00:26:22.740
I think Brian and I covered it over on the Python Bytes podcast when it came out because it was, it was big news.

00:26:22.740 --> 00:26:23.240
Yeah.

00:26:23.240 --> 00:26:23.580
Yeah.

00:26:23.580 --> 00:26:23.580
Yeah.

00:26:23.580 --> 00:26:23.960
Yeah.

00:26:23.960 --> 00:26:33.900
People are excited specifically because basically we showed that you can write some Python code, like a simple protocol parser, and it would be almost as fast as Go.

00:26:33.900 --> 00:26:38.300
And sometimes it's on faster than the Node.js, which was surprising.

00:26:38.300 --> 00:26:41.180
So yeah, I think a lot of people were excited about it.

00:26:41.180 --> 00:26:41.980
Yeah, that's fantastic.

00:26:41.980 --> 00:26:47.380
So the, the quick takeaway here is UV loop makes AsyncIO two to four times faster.

00:26:47.380 --> 00:26:52.660
You've got some benchmarks for different situations and amount of data and so on with regard to sockets.

00:26:52.660 --> 00:26:57.720
So let's wrap this one up with, is that a universal statement that you would recommend there?

00:26:57.720 --> 00:26:59.700
UV loop.install?

00:26:59.700 --> 00:27:00.460
It depends.

00:27:00.560 --> 00:27:07.280
I think for production, it makes a lot of sense to use UV loop or you should try it because I mean, there are still some minor incompatibilities in UV loop.

00:27:07.280 --> 00:27:09.360
That are really hard to track.

00:27:09.360 --> 00:27:15.900
Maybe there is some behavior difference, or maybe there is a box simply using something that a lot of people are not using with UV loop.

00:27:15.900 --> 00:27:18.140
And it's still a possibility.

00:27:18.280 --> 00:27:21.080
So yeah, use it, use it with care in production.

00:27:21.080 --> 00:27:23.000
In local development, I don't think you need it.

00:27:23.000 --> 00:27:25.240
Like vanilla AsyncIO should be, should be plenty.

00:27:25.240 --> 00:27:28.440
There is one more interesting thing about UV loop.

00:27:28.440 --> 00:27:29.660
It's a package.

00:27:29.660 --> 00:27:31.240
It's a package on PyPI.

00:27:31.680 --> 00:27:35.520
So if we find the bug, we fix it and we publish a package.

00:27:35.520 --> 00:27:40.560
You don't have to wait until Python 3.11.7 to get your bugs fixed.

00:27:40.560 --> 00:27:41.600
Or improvements made.

00:27:41.600 --> 00:27:41.840
Yeah.

00:27:41.840 --> 00:27:42.800
Or improvements made.

00:27:42.800 --> 00:27:43.440
Exactly.

00:27:43.440 --> 00:27:47.920
So this kind of suggests that it's a great idea to use UV loop.

00:27:47.920 --> 00:27:52.560
But on the other hand, we really haven't had like any emergency releases or anything in a long time.

00:27:52.560 --> 00:27:57.520
We basically release almost like every year just to catch up with the latest Python version.

00:27:57.520 --> 00:28:00.800
I would say that UV loop is pretty stable at this point.

00:28:00.800 --> 00:28:01.040
Yeah.

00:28:01.040 --> 00:28:01.500
Very cool.

00:28:01.500 --> 00:28:02.420
Yeah.

00:28:02.420 --> 00:28:03.240
It definitely seems neat.

00:28:03.240 --> 00:28:06.980
I think also it's probably a context of when does it make sense, right?

00:28:06.980 --> 00:28:12.600
If you're running three tasks and that's your whole program, who cares how fast the event loop is?

00:28:12.600 --> 00:28:12.960
All right.

00:28:12.960 --> 00:28:13.580
It's three tasks.

00:28:13.580 --> 00:28:20.420
But if you have many, many fine grain, tons of little tasks and there's lots of, like how complex and how many tasks,

00:28:20.420 --> 00:28:24.700
like basically how complex is the task coordination job of asyncio, right?

00:28:24.700 --> 00:28:28.020
The more complicated it is, probably the better benefit you'll get from UV loop.

00:28:28.020 --> 00:28:28.720
What do you think?

00:28:28.720 --> 00:28:34.400
If you go deep in the details, I would say it's not so much about juggling tasks around.

00:28:34.400 --> 00:28:38.000
It is more about performing IO in the most optimal way.

00:28:38.000 --> 00:28:38.820
Okay.

00:28:38.820 --> 00:28:41.600
And LibUV is just because it's so low level.

00:28:41.600 --> 00:28:46.180
It just uses lots and lots of tricks under the hood to just do IO faster.

00:28:46.180 --> 00:28:50.260
And the entire loop of like calling callbacks in the loop is just,

00:28:50.260 --> 00:28:52.220
it's a tight loop in C essentially.

00:28:52.220 --> 00:28:55.260
So it's much faster than a loop in Python.

00:28:55.260 --> 00:28:57.580
So that actually, yeah, those two points.

00:28:57.580 --> 00:29:01.240
But yeah, the performance improvement is noticeable usually.

00:29:01.240 --> 00:29:03.200
Very noticeable with the UV loop.

00:29:03.200 --> 00:29:03.480
Cool.

00:29:03.480 --> 00:29:07.320
The benefit is if it's literally import UV loop, UV loop dot install.

00:29:07.320 --> 00:29:07.800
Yeah.

00:29:07.800 --> 00:29:09.000
Run your benchmarks.

00:29:09.000 --> 00:29:10.420
Comment that line out.

00:29:10.420 --> 00:29:11.480
Run your benchmarks again.

00:29:11.480 --> 00:29:12.000
Exactly.

00:29:12.000 --> 00:29:12.500
Exactly.

00:29:12.860 --> 00:29:14.860
It's so easy to, you don't have to commit to it.

00:29:14.860 --> 00:29:17.160
It's not like, oh, we're going to swap ORMs and try it again.

00:29:17.160 --> 00:29:17.640
Exactly.

00:29:17.640 --> 00:29:17.940
Yeah.

00:29:17.940 --> 00:29:21.500
But I just love packages in Python that do this magic.

00:29:21.500 --> 00:29:26.640
Like if you remember, there was this package called psycho created by Armin Grigo, creator

00:29:26.640 --> 00:29:27.180
of PyPy.

00:29:27.180 --> 00:29:30.240
You just import psycho, psycho install or something like that.

00:29:30.240 --> 00:29:34.160
And boom, you have like an alternative CPython eval loop.

00:29:34.160 --> 00:29:37.360
Your program just magically becomes five, ten times faster.

00:29:37.360 --> 00:29:38.460
It's just magic.

00:29:38.900 --> 00:29:41.880
So yeah, it's great when we can do something like this.

00:29:41.880 --> 00:29:42.740
Yeah, that's fantastic.

00:29:42.740 --> 00:29:44.460
Adrian has an interesting question.

00:29:44.460 --> 00:29:47.380
I know this came up around requests a couple years ago.

00:29:47.380 --> 00:29:51.600
He asks, could you give your thoughts on having things as part of the standard library?

00:29:51.600 --> 00:29:58.460
Basically having UV loop in this case be part, you know, be the replacement for asyncio loop

00:29:58.460 --> 00:30:01.100
rather than having an external package updated independently.

00:30:01.100 --> 00:30:02.360
Yeah, it's an interesting question.

00:30:02.360 --> 00:30:04.800
And I'm not super involved in conversations like this.

00:30:04.800 --> 00:30:08.400
I know that Python core developers consider it actually separating standard library

00:30:08.400 --> 00:30:12.240
and shipping of them aside so that it can have like its own release schedule.

00:30:12.240 --> 00:30:17.640
I think it's sort of mitigated with Lukasz Lang actually speeding up the release cycle for

00:30:17.640 --> 00:30:18.240
Python now.

00:30:18.240 --> 00:30:21.340
It's being released like every year, which is amazing.

00:30:21.340 --> 00:30:24.800
And I think the pressure is lower now to separating standard library.

00:30:24.800 --> 00:30:29.860
As far as including UV loop as part of standard library, I'm not sure it's a good idea.

00:30:29.860 --> 00:30:32.000
First of all, it's entirely in Cython.

00:30:32.000 --> 00:30:34.480
It's like 50,000 lines of Cython or something like that.

00:30:34.480 --> 00:30:41.560
We will have to either adopt Cython as like an official standard library tool or rewrite it in C.

00:30:41.560 --> 00:30:45.260
And if you rewrite it in C, it's going to be 100,000 lines in C or something like that.

00:30:45.260 --> 00:30:46.020
It will be huge.

00:30:46.020 --> 00:30:49.140
So probably not going to happen anytime soon.

00:30:49.140 --> 00:30:54.520
Maybe with things like mypyC, we can make it happen eventually.

00:30:54.720 --> 00:30:55.320
Yeah, that's interesting.

00:30:55.320 --> 00:30:56.560
But mypyC is still pretty early.

00:30:56.560 --> 00:30:56.800
Right.

00:30:56.800 --> 00:30:57.300
Okay.

00:30:57.300 --> 00:31:02.480
Yeah, the conversation was had around that with regard to requests as well.

00:31:02.480 --> 00:31:04.680
Maybe you're even part of it since you're a core developer.

00:31:05.480 --> 00:31:13.480
But they decided not to make requests the new HTTP library of CPython because it would hobble requests.

00:31:13.480 --> 00:31:19.260
Like it would mean requests could only be changed, you know, once every 12 months or something like that.

00:31:19.260 --> 00:31:19.420
Right?

00:31:19.420 --> 00:31:25.380
Yeah, I think one of the concerns with requests specifically, and I wasn't actively involved in those conversations at all.

00:31:25.600 --> 00:31:36.440
But I think the concern that I heard was that HTTP is pretty wild and you often need to fix some security issues and bugs and you need to act quickly.

00:31:36.440 --> 00:31:49.120
And if something as huge as requests and so fundamental as requests was part of standard library, we would just have to be like way more flexible about making bug releases for CPython.

00:31:49.520 --> 00:31:53.760
But Python is just, it's such a huge thing, right?

00:31:53.760 --> 00:31:59.660
Like operating systems bundle it, like multiple different workflows are centered around it.

00:31:59.660 --> 00:32:00.720
It's just...

00:32:00.720 --> 00:32:02.440
It runs on helicopters in Mars.

00:32:02.440 --> 00:32:03.060
I mean, come on.

00:32:03.060 --> 00:32:03.560
Exactly.

00:32:03.560 --> 00:32:05.200
There's a lot of edge cases.

00:32:05.200 --> 00:32:06.100
People are not thinking about it.

00:32:06.100 --> 00:32:06.520
Exactly.

00:32:06.520 --> 00:32:11.720
Just upgrading a separate library is so much easier than upgrading the entire Python thing.

00:32:11.720 --> 00:32:17.020
So, yeah, I think this is why packages like requests for sure will stay out of standard library.

00:32:17.020 --> 00:32:17.360
Yeah.

00:32:17.360 --> 00:32:18.180
All right.

00:32:18.180 --> 00:32:23.160
Final question before we move on from UV loop, because it's not even our main topic, but it is very interesting.

00:32:23.160 --> 00:32:30.940
Teddy asks, are there any trade-offs of using UV loop as opposed to the native built-in one?

00:32:30.940 --> 00:32:41.680
I think this is time for me to make a shout out because we still haven't implemented a couple of APIs that are in AsyncIO, like API balls protocol.

00:32:41.680 --> 00:32:43.160
Maybe there is something else.

00:32:43.160 --> 00:32:45.840
I just haven't got time to do it myself.

00:32:45.840 --> 00:32:47.340
We are busy with SGB.

00:32:47.500 --> 00:32:50.500
So if anyone wants to join the project and help, that would be great.

00:32:50.500 --> 00:32:52.480
And that basically answers the question.

00:32:52.480 --> 00:32:55.360
The fundamental APIs are already all there.

00:32:55.360 --> 00:32:58.460
It's almost 100% compatible with UV loop.

00:32:58.460 --> 00:32:58.880
No...

00:32:58.880 --> 00:33:00.260
With vanilla AsyncIO.

00:33:00.260 --> 00:33:11.440
No trade-offs except there are a couple of relatively new APIs, I think path 3.9 and path 3.10 that are still missing from UV loop and that we still should implement them.

00:33:11.440 --> 00:33:11.820
Yeah.

00:33:11.820 --> 00:33:13.440
To be a true replacement, right?

00:33:13.440 --> 00:33:13.700
Yeah.

00:33:13.700 --> 00:33:17.360
I think it's sent file and API balls and maybe something else.

00:33:17.360 --> 00:33:17.740
Okay.

00:33:17.740 --> 00:33:20.860
UV loop is running inside EdgeDB?

00:33:20.860 --> 00:33:21.360
Yeah.

00:33:21.360 --> 00:33:24.700
It powers the IO server.

00:33:24.700 --> 00:33:28.720
Basically we use multi-processing architecture in EdgeDB.

00:33:28.720 --> 00:33:36.080
We have a pool of compiler processes because this is like computation CPU heavy thing to compile your query.

00:33:36.080 --> 00:33:45.740
And then there is a core IO process that just runs UV loop and quickly, quickly, quickly goes through your connections and pushing data between clients, posts, etc.

00:33:48.000 --> 00:33:51.000
This portion of Talk Python to me is brought to you by SignalWire.

00:33:51.000 --> 00:33:52.880
Let's kick this off with a question.

00:33:52.880 --> 00:33:56.480
Do you need to add multi-party video calls to your website or app?

00:33:56.480 --> 00:34:09.040
I'm talking about live video conference rooms that host 500 active participants, run in the browser and work within your existing stack, and even support 1080p without devouring the bandwidth and CPU on your users' devices.

00:34:09.040 --> 00:34:17.040
SignalWire offers the APIs, the SDKs, and Edge networks around the world for building the realest of real-time voice and video communication apps,

00:34:17.040 --> 00:34:20.000
apps with less than 50 milliseconds of latency.

00:34:20.000 --> 00:34:30.040
Their core products use WebSockets to deliver 300% lower latency than APIs built on REST, making them ideal for apps where every millisecond of responsiveness makes a difference.

00:34:30.040 --> 00:34:34.040
Now, you may wonder how they get 500 active participants in a browser-based app.

00:34:34.040 --> 00:34:40.040
Most current approaches use a limited but more economical approach called SFU, or Selective Forwarding Units,

00:34:40.040 --> 00:34:46.040
which leaves the work of mixing and decoding all those video and audio streams of every participant to each user's device.

00:34:46.040 --> 00:34:52.040
Browser-based apps built on SFU struggle to support more than 20 interactive participants.

00:34:52.040 --> 00:34:59.040
So SignalWire mixes all the video and audio feeds on the server and distributes a single unified stream back to every participant.

00:34:59.040 --> 00:35:05.040
So you can build things like live streaming fitness studios where instructors demonstrate every move from multiple angles,

00:35:05.040 --> 00:35:12.040
or even live shopping apps that highlight the charisma of the presenter and the charisma of the products they're pitching at the same time.

00:35:12.040 --> 00:35:22.040
SignalWire comes from the team behind FreeSwitch, the open-source telecom infrastructure toolkit used by Amazon, Zoom, and tens of thousands of more to build mass-scale telecom products.

00:35:22.040 --> 00:35:31.040
So sign up for your free account at talkpython.fm/signalwire, and be sure to mention Talk Python to me to receive an extra 5,000 video minutes.

00:35:31.040 --> 00:35:38.040
That's talkpython.fm/signalwire and mention Talk Python to me for all those credits.

00:35:38.040 --> 00:35:51.040
So another thing that came out just today, I know this is, I don't want to spend too much time on it, but there's a big new feature for tasks and async.io in Python 3.11 coming very soon.

00:35:51.040 --> 00:36:00.040
And you just gave a shout out on Twitter yesterday saying that task groups is coming to async.io.

00:36:00.040 --> 00:36:07.040
This is a way, because right now if you start two tasks, there's no way to say, well, if this one fails, don't even bother running that one, right?

00:36:07.040 --> 00:36:08.040
They're fully independent.

00:36:08.040 --> 00:36:12.040
This is a way to sort of create a dependency and control them as a set, right?

00:36:12.040 --> 00:36:14.040
Tell us real quick about this.

00:36:14.040 --> 00:36:17.040
I have an API for spawning tasks concurrently.

00:36:17.040 --> 00:36:22.040
It's called async.io gatherer, but it's just a suboptimal API in many ways.

00:36:22.040 --> 00:36:25.040
And this API is like way superior.

00:36:25.040 --> 00:36:31.040
We have to credit Nathaniel J. Smith for his work on Trio and Trio Nursery specifically.

00:36:31.040 --> 00:36:36.040
And Trio is, I mean, we can run an entirely different podcast episode just about Trio and async.

00:36:36.040 --> 00:36:41.040
I actually had Nathaniel on, yeah, we talked about Trio on the show quite a while ago when it was fairly new.

00:36:41.040 --> 00:36:44.040
It's an amazing thing and there are lots and lots of great ideas in Trio.

00:36:44.040 --> 00:36:53.040
One of them is having this thing, it's called nursery in Trio and the async and the task groups,

00:36:53.040 --> 00:36:56.040
async.io task groups, essentially, they just replicate this nursery idea.

00:36:56.040 --> 00:36:59.040
They port it from Trio to async.io.

00:36:59.040 --> 00:37:04.040
Like the bigger points about how this API works are all similar to Trio.

00:37:04.040 --> 00:37:10.040
There are some details about how constellation works, et cetera, but most people probably won't really care about that one.

00:37:10.040 --> 00:37:11.040
Yeah.

00:37:11.040 --> 00:37:12.040
Okay.

00:37:12.040 --> 00:37:13.040
Very cool.

00:37:13.040 --> 00:37:14.040
It's great to see more innovation.

00:37:14.040 --> 00:37:15.040
Yeah.

00:37:15.040 --> 00:37:16.040
And the async.io.

00:37:16.040 --> 00:37:17.040
Yeah.

00:37:17.040 --> 00:37:19.040
But task groups, I'll just talk for a couple more minutes about task groups.

00:37:19.040 --> 00:37:22.040
So task groups was like a more requested thing.

00:37:22.040 --> 00:37:25.040
A lot of people wanted task groups in async.io.

00:37:25.040 --> 00:37:29.040
And I was DMed like, sometimes I was DMed like on a daily basis entirely.

00:37:29.040 --> 00:37:31.040
Like we promised us task groups.

00:37:31.040 --> 00:37:32.040
When can we have our task groups?

00:37:32.040 --> 00:37:37.040
So the big like elephant in the room with task groups is how do we handle exceptions?

00:37:37.040 --> 00:37:43.040
Because multiple things can fail at the same time and the essential will propagate out of this async with task group.

00:37:43.040 --> 00:37:47.040
You'll end up with a hierarchical tree of exceptions.

00:37:47.040 --> 00:37:48.040
Exactly.

00:37:48.040 --> 00:37:49.040
And we just had to figure it out.

00:37:49.040 --> 00:38:02.040
And we had to figure it out in the core because if it was just some, I don't know, some exception class defined in async.io, then what would happen when you, when your async.io program crashed?

00:38:02.040 --> 00:38:03.040
Right.

00:38:03.040 --> 00:38:06.040
You wouldn't have like a correct state, a trace back in your terminal.

00:38:06.040 --> 00:38:09.040
You wouldn't be able to understand what actually happened.

00:38:09.040 --> 00:38:13.040
So we had to integrate this into trace backs and like a debug.

00:38:13.040 --> 00:38:23.040
We needed to make sure that it's like a standard thing that tools like Sentry, for example, can take advantage of it and provide you like great visibility into what happens in your async application.

00:38:23.040 --> 00:38:26.040
So we had to work in this exception group thing.

00:38:26.040 --> 00:38:42.040
And there's this amazing new core developer, you read CatRiel and she spearheaded this effort of just implementing this and drafting a proposal and just doing it to completion essentially.

00:38:42.040 --> 00:38:49.040
And it's because of her work, actually, task groups are finally a thing because task groups themselves, it's like 100 lines of code.

00:38:49.040 --> 00:38:52.040
There is with comments, there is not much to them.

00:38:52.040 --> 00:38:55.040
The huge thing is getting exception groups in.

00:38:55.040 --> 00:39:03.040
And I believe Python is the first language that has this feature, like right in the syntax, right in the runtime model.

00:39:03.040 --> 00:39:10.040
And this is also huge because I actually believe that Python now can be like one of the best languages to do concurrent programming.

00:39:10.040 --> 00:39:16.040
And I don't know, maybe when we have JIT or something like that, it might actually match a goal in performance somewhat.

00:39:16.040 --> 00:39:17.040
Yeah.

00:39:17.040 --> 00:39:18.040
Would be ideal thing.

00:39:18.040 --> 00:39:24.040
So while I'm looking at this syntax here, which I'll try to quickly simply communicate to people listening on audio.

00:39:24.040 --> 00:39:25.040
It's an async with block.

00:39:25.040 --> 00:39:35.040
So what you do is you'd say async with asyncio dot task group, and you create this task group and then you can create tasks within there that are all grouped together.

00:39:35.040 --> 00:39:39.040
And then you also can do things like await stuff while you're in there.

00:39:39.040 --> 00:39:46.040
It looks to me like one of the things that often I don't see possible in Python's async.

00:39:46.040 --> 00:39:55.040
Previously, it's the ability to just fire off a task and have it sort of just run in the background to completion.

00:39:55.040 --> 00:40:00.040
So you don't have to do like async or like run all or gather or any of those types of things.

00:40:00.040 --> 00:40:07.040
Basically, the width block, we won't exit the width block until all the tasks are finished or until it fails.

00:40:07.040 --> 00:40:08.040
One of those two, right?

00:40:08.040 --> 00:40:09.040
Yeah.

00:40:09.040 --> 00:40:15.040
That's a cool feature of it alone to just kind of say like, I don't need to kind of store up all the tasks and then make sure I'm waiting on them forever.

00:40:15.040 --> 00:40:22.040
Like I can just kick them off and then like if they happen to start in this place, then they're going to finish when this width block finishes.

00:40:22.040 --> 00:40:24.040
I'm even more excited about this than I was before.

00:40:24.040 --> 00:40:25.040
Right, right, right.

00:40:25.040 --> 00:40:28.040
It's a nice API to compose things in asyncio.

00:40:28.040 --> 00:40:34.040
And I believe it's one of the bigger deals in the recent years.

00:40:34.040 --> 00:40:35.040
So I'm super excited about this.

00:40:35.040 --> 00:40:37.040
3.11 is out soon.

00:40:37.040 --> 00:40:38.040
Exactly sure the release date.

00:40:38.040 --> 00:40:40.040
I know it's in alpha stuff right now.

00:40:40.040 --> 00:40:41.040
So it's getting real near.

00:40:41.040 --> 00:40:43.040
Yeah, yeah, it should be should be close.

00:40:43.040 --> 00:40:44.040
Yeah, for sure.

00:40:44.040 --> 00:40:45.040
Awesome.

00:40:45.040 --> 00:40:46.040
All right.

00:40:46.040 --> 00:40:49.040
Last thing before we get to EdgeDB proper people.

00:40:49.040 --> 00:40:56.040
I would say that Postgres is the most popular database for Python people doing database things, possibly with the exception of SQLite.

00:40:56.040 --> 00:41:03.040
But that really counts for just like, oh, I'm doing testing or oh, I use this for this incredibly small, but like production level stuff.

00:41:03.040 --> 00:41:04.040
Got to be Postgres, right?

00:41:04.040 --> 00:41:05.040
Yeah, yeah.

00:41:05.040 --> 00:41:06.040
It's fair to say.

00:41:06.040 --> 00:41:11.040
Yeah, maybe throw in some MySQL and then like a little bit down, maybe some MongoDB, something like that.

00:41:11.040 --> 00:41:16.040
But like, clearly, it seems like Postgres has a lot of interest for folks.

00:41:16.040 --> 00:41:24.040
If you want to talk to it through async and await, which is exactly how you want to scale your database stuff.

00:41:24.040 --> 00:41:27.040
A pretty popular library is this one called async PG, right?

00:41:27.040 --> 00:41:28.040
Yep.

00:41:28.040 --> 00:41:29.040
Yep.

00:41:29.040 --> 00:41:30.040
Yeah, you and Elvis created that, huh?

00:41:30.040 --> 00:41:31.040
Yeah.

00:41:31.040 --> 00:41:33.040
So yeah, it was an interesting experience.

00:41:33.040 --> 00:41:37.040
Basically, we knew that the EdgeDB will be based on Postgres.

00:41:37.040 --> 00:41:38.040
That was clear.

00:41:38.040 --> 00:41:39.040
They won.

00:41:39.040 --> 00:41:48.040
And we also knew that we have to have like this very high performance bridge, essentially, between Python and Postgres.

00:41:48.040 --> 00:41:50.040
And it had to be asynchronous.

00:41:50.040 --> 00:41:56.040
So there was no good asynchronous client for Postgres back at the time.

00:41:56.040 --> 00:42:03.040
And we couldn't just use PsycAPG, the most popular Postgres driver, because it uses text encoding for data.

00:42:03.040 --> 00:42:08.040
Maybe not anymore, but it used to have text encoding.

00:42:08.040 --> 00:42:11.040
And we actually had to use binary for something.

00:42:11.040 --> 00:42:15.040
So we just knew that, okay, we have to just jump in and explore Postgres protocol.

00:42:15.040 --> 00:42:18.040
And we decided, okay, let's write the driver.

00:42:18.040 --> 00:42:20.040
Yeah, this is how Async PG was born.

00:42:20.040 --> 00:42:27.040
And I think what makes Async PG different, just besides that it implements binary protocol and it's asynchronous, it's API.

00:42:27.040 --> 00:42:32.040
Because we were not basing it on the common Python DB API.

00:42:32.040 --> 00:42:39.040
We basically designed an API to be as low level as possible, as close to Postgres semantics as possible.

00:42:39.040 --> 00:42:44.040
So in DB API, there is this thing called cursor, which has nothing to do with the actual database cursors.

00:42:44.040 --> 00:42:46.040
So we didn't want to replicate that.

00:42:46.040 --> 00:42:53.040
So yeah, we just built like what we thought were proper primitives, working with Postgres as efficiently as possible.

00:42:53.040 --> 00:42:57.040
We used binary protocol plus Async I/O.

00:42:57.040 --> 00:43:01.040
And we of course use Cython to speed up like all the bottlenecks in it.

00:43:01.040 --> 00:43:03.040
It's pretty much entirely in Cython actually.

00:43:03.040 --> 00:43:07.040
And yeah, the result is just amazing to this day.

00:43:07.040 --> 00:43:13.040
Async PG is like one of the fastest Postgres clients on the planet across all languages.

00:43:13.040 --> 00:43:14.040
That's fascinating.

00:43:14.040 --> 00:43:18.040
You can see that it beats Node.js and go pretty handily there.

00:43:18.040 --> 00:43:20.040
Yeah, we should probably update this chart actually.

00:43:20.040 --> 00:43:23.040
I'm pretty sure that they updated PG library for Node.js.

00:43:23.040 --> 00:43:24.040
So this is outdated.

00:43:24.040 --> 00:43:30.040
I think it's closer in performance to Async PG, but I think Async PG is still the fastest.

00:43:30.040 --> 00:43:31.040
Yeah.

00:43:31.040 --> 00:43:32.040
Cool.

00:43:32.040 --> 00:43:33.040
Awesome.

00:43:33.040 --> 00:43:43.040
So taking all these together, UV loop, Async and await in the language, Async PG, all of these are building up your skills to sort of almost build a database.

00:43:43.040 --> 00:43:46.040
And so then you went on and actually did build a database, right?

00:43:46.040 --> 00:43:47.040
Yeah, pretty much.

00:43:47.040 --> 00:43:51.040
So we had this framework, which was like almost an arm in Python for many years.

00:43:51.040 --> 00:43:54.040
And we built multiple different production applications with that.

00:43:54.040 --> 00:43:58.040
We shipped applications that were deployed to GE, Cisco companies like that.

00:43:58.040 --> 00:44:07.040
And we knew it's something interesting, but we also knew that it has to be bigger than just a Python or like it has to be a database.

00:44:07.040 --> 00:44:15.040
It's a surprisingly long road to make something to go this path essentially, because you have to define a query link.

00:44:15.040 --> 00:44:24.040
You have to define type system, you have to define standard library, you have to define protocols, how it works, how migrations work, all the different syntaxes for schema modeling.

00:44:24.040 --> 00:44:25.040
It's a huge thing.

00:44:25.040 --> 00:44:36.040
And yeah, with like all the right primitives in Python itself, we knew that we can start like morphing our code base into like this separate service essentially.

00:44:36.040 --> 00:44:41.040
And yeah, that was the necessary and required groundwork to make HDB happen.

00:44:41.040 --> 00:44:44.040
Without it, we would probably not succeed.

00:44:44.040 --> 00:44:45.040
Cool.

00:44:45.040 --> 00:44:47.040
So HDB really written in Python?

00:44:47.040 --> 00:44:48.040
It is.

00:44:48.040 --> 00:44:49.040
Mostly.

00:44:49.040 --> 00:44:50.040
Yeah.

00:44:50.040 --> 00:44:51.040
Mostly.

00:44:51.040 --> 00:44:54.040
Entire like IO service server is essentially a Cython thing.

00:44:54.040 --> 00:45:02.040
So it's in C and this is why if you look at benchmarks of HDB, it's actually pretty close to Postgres, to vanilla Postgres.

00:45:02.040 --> 00:45:04.040
Like the overhead of HDB is super low.

00:45:04.040 --> 00:45:13.040
That is only possible because of Cython and like all low level tips and tricks that we learned when we were working on UV loop and the asyncPG.

00:45:13.040 --> 00:45:15.040
So we really optimize it a lot.

00:45:15.040 --> 00:45:16.040
Yeah.

00:45:16.040 --> 00:45:24.040
The compiler part, the thing that actually takes an HQL query and compiles it to SQL, that thing is pure Python and that runs in a separate process.

00:45:24.040 --> 00:45:27.040
But we do some also tricks to make it fast.

00:45:27.040 --> 00:45:29.040
Like we cache things aggressively.

00:45:29.040 --> 00:45:32.040
I mean, in most applications, you don't have thousands of queries.

00:45:32.040 --> 00:45:35.040
You only have like 10, 50, 100.

00:45:35.040 --> 00:45:36.040
Yeah.

00:45:36.040 --> 00:45:40.040
So they get cached pretty quickly and then you don't even run Python anymore.

00:45:40.040 --> 00:45:41.040
From that point on, it's just C.

00:45:41.040 --> 00:45:42.040
Oh, interesting.

00:45:42.040 --> 00:45:42.040
Yeah.

00:45:42.040 --> 00:45:52.040
You don't need to incredibly optimize the understanding of the query because like you said, it's not ad hoc stuff happening that happens at scale.

00:45:52.040 --> 00:45:53.040
Exactly.

00:45:53.040 --> 00:45:54.040
Exactly.

00:45:54.040 --> 00:46:06.040
I mean, it's great when your compiler is exceptionally fast, but for a database and especially if it's smart around extracting constants, let's say you send a select one and then your next query is select two.

00:46:06.040 --> 00:46:07.040
Essentially it's the same query.

00:46:07.040 --> 00:46:09.040
Substitute the same query, just different constants.

00:46:09.040 --> 00:46:17.040
So if you extract it and you cache the file query as if this wasn't the constant, but the argument the query, then yeah, you don't need to compile it for the second time.

00:46:17.040 --> 00:46:18.040
So yeah.

00:46:18.040 --> 00:46:19.040
Yeah.

00:46:19.040 --> 00:46:28.040
I don't know Postgres super, super well, but I know some databases, they at their level, when they see a query, they're like, oh, I've seen this query before.

00:46:28.040 --> 00:46:34.040
They can cache the query plan and those types of, so that's like another level of performance and speed up as well.

00:46:34.040 --> 00:46:35.040
Right.

00:46:35.040 --> 00:46:36.040
We do that as well.

00:46:36.040 --> 00:46:43.040
Um, I mean, we did it even in async Pg, for example, async Pg automatically prepare statements for you to enjoy this optimization.

00:46:43.040 --> 00:46:48.040
So that Postgres doesn't have to reparse or SQL query can just execute the precast plan.

00:46:48.040 --> 00:46:51.040
We do the same in HDB and many other things.

00:46:51.040 --> 00:47:00.040
This is why HDB is kind of, it's based on Postgres, but it fully envelops Postgres because we want to be in like full control on the underlying Postgres instance.

00:47:00.040 --> 00:47:01.040
Right.

00:47:01.040 --> 00:47:05.040
So in some sense, this is a brand new database that's got some really cool features that I'm going to ask you about.

00:47:05.040 --> 00:47:06.040
very soon.

00:47:06.040 --> 00:47:06.040
Absolutely.

00:47:06.040 --> 00:47:15.040
But in the other sense, it's got a lot of stability because it's kind of a database level API rethinking of a well known core that people already trust.

00:47:15.040 --> 00:47:16.040
This is an interesting thing.

00:47:16.040 --> 00:47:22.040
Actually, a lot of people are not 100% satisfied with relational databases for a variety of reasons.

00:47:22.040 --> 00:47:23.040
Somebody.

00:47:23.040 --> 00:47:24.040
Yeah.

00:47:24.040 --> 00:47:28.040
Somebody is not satisfied with scaling.

00:47:28.040 --> 00:47:38.040
Some are not satisfied with SQL and some not satisfied with migrations and how rigid the schema is and how inconvenient it is to deal with the relational database.

00:47:38.040 --> 00:47:40.040
And so it's a huge problem.

00:47:40.040 --> 00:47:46.040
You have a part of it, which is just language design and by standard library and type system, how that part works.

00:47:46.040 --> 00:47:48.040
The second is workflows around your database.

00:47:48.040 --> 00:47:52.040
The third is the engine of your database, like how it actually works.

00:47:52.040 --> 00:47:59.040
EdgeDB wants to challenge everything, but we also not dumb enough to challenge everything.

00:47:59.040 --> 00:48:05.040
At the same time, we understand that just writing this whole thing from scratch is impossible.

00:48:05.040 --> 00:48:07.040
No company in the world would be able to pull it off.

00:48:07.040 --> 00:48:11.040
Well, maybe some companies would be able to, but they're definitely not a startup.

00:48:11.040 --> 00:48:13.040
But they have many, many employees.

00:48:13.040 --> 00:48:14.040
Exactly.

00:48:14.040 --> 00:48:15.040
And they're probably public.

00:48:15.040 --> 00:48:16.040
Giant tech companies.

00:48:16.040 --> 00:48:17.040
Exactly.

00:48:17.040 --> 00:48:28.040
So for us, the only viable strategy was to pick a database that is already trusted, that is already fast and universally loved, which is Postgres.

00:48:28.040 --> 00:48:32.040
And it's also incredibly capable and just build on top of it.

00:48:32.040 --> 00:48:34.040
And it's not actually a new approach in databases.

00:48:34.040 --> 00:48:41.040
Like lots of databases actually are built on like primitive key value databases, like level DB or something like that.

00:48:41.040 --> 00:48:43.040
It's a popular approach.

00:48:43.040 --> 00:48:44.040
We're just taking it further.

00:48:44.040 --> 00:48:49.040
We are saying that, hey, using a key value storage won't buy us much.

00:48:49.040 --> 00:48:57.040
We are like high level programming language requires a lot of code to be written to properly be executed in good time.

00:48:57.040 --> 00:49:01.040
But SQL looks like this nice compile target.

00:49:01.040 --> 00:49:02.040
So this is why we use Postgres.

00:49:02.040 --> 00:49:03.040
Yeah.

00:49:03.040 --> 00:49:04.040
Very cool.

00:49:04.040 --> 00:49:08.040
Kind of the TypeScript to JavaScript equivalent of the database query language in a sense.

00:49:08.040 --> 00:49:09.040
Yeah, pretty much.

00:49:09.040 --> 00:49:11.040
I mean, sometimes I explain HDB as LLVM.

00:49:11.040 --> 00:49:17.040
Like imagine LLVM, it compiles your high level code to low level code and then it, et cetera.

00:49:17.040 --> 00:49:19.040
And the same about HDB.

00:49:19.040 --> 00:49:24.040
We compile your, like high level schema to like a proper normalized table layout.

00:49:24.040 --> 00:49:28.040
We compile our HQL, high level query language down to SQL.

00:49:28.040 --> 00:49:31.040
SQL and that SQL can actually be jittered by Postgres.

00:49:31.040 --> 00:49:38.040
So essentially, ultimately your HQL might be executing with like at native code speed, not now, but in the future.

00:49:38.040 --> 00:49:42.040
So what's the elevator pitch for people who are out there?

00:49:42.040 --> 00:49:47.040
They're slightly, you know, not super thrilled about the database they're necessarily using, whatever that is.

00:49:47.040 --> 00:49:49.040
And they're kind of exploring.

00:49:49.040 --> 00:49:54.040
I picked up a few things that I think make it unique, but I want to ask you, it's your baby.

00:49:54.040 --> 00:49:55.040
All right.

00:49:55.040 --> 00:49:56.040
I guess I'll give two pitches.

00:49:56.040 --> 00:50:01.040
One is super high level and one is slightly more low level.

00:50:01.040 --> 00:50:08.040
A super high level pitch is that imagine you have a tool and when it's a great tool, it becomes an extension of your hand.

00:50:08.040 --> 00:50:10.040
Essentially, you just don't notice it.

00:50:10.040 --> 00:50:11.040
You just do things, right?

00:50:11.040 --> 00:50:13.040
Current databases are not like that.

00:50:13.040 --> 00:50:18.040
They require lots and lots of mental overhead to work with them.

00:50:18.040 --> 00:50:21.040
Like what one library do you use in this language?

00:50:21.040 --> 00:50:22.040
Right.

00:50:22.040 --> 00:50:26.040
Is there lazy loading and N+1 stuff I got to consider or is it not and all those kinds of things?

00:50:26.040 --> 00:50:27.040
Exactly.

00:50:27.040 --> 00:50:33.040
And then you have to learn their API and then you have to learn SQL and understand how those things interact with each other.

00:50:33.040 --> 00:50:36.040
And then you have to care about deployment and migrations.

00:50:36.040 --> 00:50:38.040
It's just so much headache.

00:50:38.040 --> 00:50:45.040
This alone explains why MongoDB was so popular and is so popular because a lot of people just decided, okay, to hell with that.

00:50:45.040 --> 00:50:46.040
I don't want to deal with this.

00:50:46.040 --> 00:50:49.040
I believe in the relational space altogether.

00:50:49.040 --> 00:50:50.040
Yeah, exactly.

00:50:50.040 --> 00:50:53.040
Just abandoning this train.

00:50:53.040 --> 00:50:57.040
Yeah, and we want to fix all of that in HDB.

00:50:57.040 --> 00:50:59.040
We want to give you a tool that you just don't notice.

00:50:59.040 --> 00:51:06.040
We want to give you a data model that just feels native to Python or TypeScript or Go or any other language.

00:51:06.040 --> 00:51:08.040
You don't have to think in tables anymore.

00:51:08.040 --> 00:51:16.040
I want to give you a query language that is super easy to use and learn and compose and build query builders around.

00:51:16.040 --> 00:51:21.040
And essentially we want to essentially kill the entire concept of ORM.

00:51:21.040 --> 00:51:23.040
We don't need it anymore.

00:51:23.040 --> 00:51:28.040
We are almost sorry that ORMs have to exist in a way.

00:51:28.040 --> 00:51:29.040
I was going to ask you about that.

00:51:29.040 --> 00:51:31.040
There are so many incredibly difficult problems.

00:51:31.040 --> 00:51:33.040
This problem is called object impedance mismatch there.

00:51:33.040 --> 00:51:34.040
Yeah.

00:51:34.040 --> 00:51:35.040
And tables to like objects.

00:51:35.040 --> 00:51:37.040
It's a super hard problem.

00:51:37.040 --> 00:51:39.040
I feel sorry that they have to go through this.

00:51:39.040 --> 00:51:47.040
But we just looked at this problem and decided, hey, can we actually just solve this object impedance problem in a different way?

00:51:47.040 --> 00:51:49.040
Can we just avoid solving it entirely?

00:51:49.040 --> 00:51:54.040
Can we just give you a database with the proper high level data model that doesn't have this problem at all?

00:51:54.040 --> 00:51:55.040
Sure.

00:51:55.040 --> 00:51:56.040
And then suddenly you don't need ORMs.

00:51:56.040 --> 00:52:08.040
Let's talk real quick about the actual way you define what would be the equivalent, I guess, of a DDL table create script or somewhat related to that maybe closer is like an ORM class.

00:52:08.040 --> 00:52:09.040
Like it's kind of the...

00:52:09.040 --> 00:52:10.040
Okay.

00:52:10.040 --> 00:52:11.040
Can I start a little from afar?

00:52:11.040 --> 00:52:12.040
Yeah, yeah.

00:52:12.040 --> 00:52:13.040
Let's start back.

00:52:13.040 --> 00:52:14.040
Okay.

00:52:14.040 --> 00:52:17.040
Now it's going to be the second pitch, which is slightly more detailed.

00:52:17.040 --> 00:52:20.040
So we say that HDB is a new kind of database.

00:52:20.040 --> 00:52:22.040
It's not just relational.

00:52:22.040 --> 00:52:25.040
We call it a graph relational database.

00:52:25.040 --> 00:52:30.040
Essentially, we are saying that we created an extension to the relational model.

00:52:30.040 --> 00:52:33.040
So what actually constitutes the graph relational model?

00:52:33.040 --> 00:52:43.040
It's first of all, in all of your like rows, all of your tuples in your relational algebra, they essentially have a globally unique key.

00:52:43.040 --> 00:52:44.040
Now, this is a requirement.

00:52:44.040 --> 00:52:47.040
So data independent is just UID essentially.

00:52:47.040 --> 00:52:50.040
Every row in your database will have it.

00:52:50.040 --> 00:52:52.040
This is the first requirement, first modification.

00:52:52.040 --> 00:52:55.040
The second extension is links.

00:52:55.040 --> 00:53:00.040
The idea that links between data is like a first class citizen of the model.

00:53:00.040 --> 00:53:02.040
You don't need join, you don't need foreign key.

00:53:02.040 --> 00:53:09.040
You just know that, hey, if this type links to another type, it's just going to be like a relationship between the unique IDs.

00:53:09.040 --> 00:53:11.040
This is what unique IDs gives you.

00:53:11.040 --> 00:53:15.040
And the second thing is the third thing is that everything is a set.

00:53:15.040 --> 00:53:25.040
This, like if you have an object that is connected to multiple other objects, this is a set of objects.

00:53:25.040 --> 00:53:29.040
If you have an object that has a bunch of properties, then a set of properties.

00:53:29.040 --> 00:53:31.040
Even a single thing is a set as well.

00:53:31.040 --> 00:53:35.040
And this later enables HQL to be super composable.

00:53:35.040 --> 00:53:40.040
But these are just like three simple kind of axioms that are in the core of the model.

00:53:40.040 --> 00:53:54.040
So if you, if we talk about like this schema snippet where we have an object type, a block post with required property content, which is text and required link author, which is another type called user.

00:53:54.040 --> 00:54:05.040
It's going to be compiled to a table in SQL with a column called content with a column ID, which is going to be a unique UUID for every blog post that will have it automatically.

00:54:05.040 --> 00:54:06.040
It's immutable.

00:54:06.040 --> 00:54:07.040
It's read only.

00:54:07.040 --> 00:54:08.040
You don't have to create them manually.

00:54:08.040 --> 00:54:13.040
And a user will also be a table and also have IDs.

00:54:13.040 --> 00:54:19.040
And then we'll have a separate column, which is going to be called author, which you will have IDs of users.

00:54:19.040 --> 00:54:25.040
So ultimately, ultimately like deep beneath what you see in edge DB is like this high level schema.

00:54:25.040 --> 00:54:28.040
It's all compiled properly for the relational model.

00:54:28.040 --> 00:54:30.040
It's all normalized there.

00:54:30.040 --> 00:54:31.040
We are still relational.

00:54:31.040 --> 00:54:37.040
We still like exhibit like the same, the same characteristics as just, we're hiding a lot of this like low level things.

00:54:37.040 --> 00:54:44.040
that you had to bother with with this high level model, just abstracting away the low level stuff.

00:54:44.040 --> 00:54:48.040
Is there a way to directly connect to that relational view?

00:54:48.040 --> 00:54:50.040
You mean Postgres, the underlying Postgres other ways?

00:54:50.040 --> 00:54:51.040
Yeah.

00:54:51.040 --> 00:54:52.040
Yeah.

00:54:52.040 --> 00:54:53.040
Like the underlying.

00:54:53.040 --> 00:55:01.040
I'm not sure even that's necessarily a good idea, but you know, like in SQLAlchemy, there's a way to go like, I just need to get out of here and send raw SQL for a moment.

00:55:01.040 --> 00:55:02.040
Right?

00:55:02.040 --> 00:55:04.040
Like that feels like that's kind of the same.

00:55:04.040 --> 00:55:05.040
I just need to go to the guts for a minute.

00:55:05.040 --> 00:55:06.040
Yeah.

00:55:06.040 --> 00:55:06.040
Yeah.

00:55:06.040 --> 00:55:06.040
Yeah.

00:55:06.040 --> 00:55:07.040
Yeah.

00:55:07.040 --> 00:55:07.040
Yeah.

00:55:07.040 --> 00:55:10.040
So with edge DB, the goal is for you to never actually need that.

00:55:10.040 --> 00:55:12.040
There is just one exception to this.

00:55:12.040 --> 00:55:13.040
Just one exception.

00:55:13.040 --> 00:55:13.040
Ideally.

00:55:13.040 --> 00:55:14.040
Yeah.

00:55:14.040 --> 00:55:14.040
Okay.

00:55:14.040 --> 00:55:21.040
But basically our goal with edge QL, like we knew that first of all, we have to elevate the data and make it more high level.

00:55:21.040 --> 00:55:28.040
And second of all, we knew that, Hey, order for a relational database to be successful, it just has to have query language.

00:55:28.040 --> 00:55:29.040
Right.

00:55:29.040 --> 00:55:31.040
And because our data was different.

00:55:31.040 --> 00:55:32.040
We have to come up with our own.

00:55:32.040 --> 00:55:34.040
This is how which kill was born.

00:55:34.040 --> 00:55:34.040
Yeah.

00:55:34.040 --> 00:55:37.040
And we spent years designing edge QL.

00:55:37.040 --> 00:55:44.040
And the reason why is because we wanted it to be actually more powerful than SQL in many ways.

00:55:44.040 --> 00:55:51.040
Basically, if you have something that is expressible in SQL, but isn't expressible in SQL, we treat it as a bug immediately.

00:55:51.040 --> 00:55:53.040
If something is easier to do in SQL, it's a bug.

00:55:53.040 --> 00:55:59.040
And this is why we spent so many years kind of refining this thing to make it to be capable of thing.

00:55:59.040 --> 00:56:02.040
So basically you never need to use SQL.

00:56:02.040 --> 00:56:05.040
You don't need to know about SQL or know about its existence.

00:56:05.040 --> 00:56:10.040
And this is a powerful thing because when you use a norm library, you have to know about SQL.

00:56:10.040 --> 00:56:12.040
With SGP, no, you just learn one language.

00:56:12.040 --> 00:56:14.040
You're good to go for the rest of your life.

00:56:14.040 --> 00:56:15.040
Essentially.

00:56:15.040 --> 00:56:18.040
There's just one use case when you might need SQL.

00:56:18.040 --> 00:56:26.040
It's when, let's say you're a big company and you're using some BI tools like Tableau or something like that.

00:56:26.040 --> 00:56:29.040
Graph analysts that already know SQL.

00:56:29.040 --> 00:56:30.040
And we're going to do something about it.

00:56:30.040 --> 00:56:34.040
We're going to open like a special adapter.

00:56:34.040 --> 00:56:35.040
Adapter.

00:56:35.040 --> 00:56:36.040
Exactly.

00:56:36.040 --> 00:56:39.040
We'll allow you to just run SQL against the database in read-only mode.

00:56:39.040 --> 00:56:40.040
That makes a lot of sense.

00:56:40.040 --> 00:56:42.040
Because there are these tools, these big BI tools.

00:56:42.040 --> 00:56:49.040
And you're like, if your data is here, do you really want to like have some job to move it to another Postgres just to run an analysis on it?

00:56:49.040 --> 00:56:50.040
Yeah.

00:56:50.040 --> 00:56:51.040
Exactly.

00:56:51.040 --> 00:56:56.040
I mean, just like with us not attacking this problem all at once and implementing the engine and the language and everything.

00:56:56.040 --> 00:57:03.040
else here, we also understand that we are not going to replace all the business intelligence infrastructure overnight.

00:57:03.040 --> 00:57:04.040
Yeah.

00:57:04.040 --> 00:57:05.040
And yeah, we have to make it be compatible.

00:57:05.040 --> 00:57:06.040
It's not there yet.

00:57:06.040 --> 00:57:09.040
We'll be a part of a future release.

00:57:09.040 --> 00:57:10.040
Eventually.

00:57:10.040 --> 00:57:12.040
You'll have a nice roadmap, which we'll cover in a minute.

00:57:12.040 --> 00:57:13.040
But like, I really love that.

00:57:13.040 --> 00:57:14.040
Oh my God.

00:57:14.040 --> 00:57:15.040
Don't do it.

00:57:15.040 --> 00:57:16.040
Don't do it.

00:57:16.040 --> 00:57:17.040
Don't do it.

00:57:17.040 --> 00:57:18.040
I can just say it out loud.

00:57:18.040 --> 00:57:19.040
Like the ideas that we have.

00:57:19.040 --> 00:57:26.040
But let me, like just for people who want to see if they go there, just visually, the way that you've laid this out of like where you are and where you're going.

00:57:26.040 --> 00:57:33.040
Like so many libraries and products should model this because so often, you know, you'll reach out to the companies.

00:57:33.040 --> 00:57:34.040
Hey, it'd be great if you could do this.

00:57:34.040 --> 00:57:35.040
Oh yeah.

00:57:35.040 --> 00:57:35.040
It's on our roadmap.

00:57:35.040 --> 00:57:36.040
Like, oh yeah.

00:57:36.040 --> 00:57:37.040
Well, what is that?

00:57:37.040 --> 00:57:38.040
Like some, where do you even have this?

00:57:38.040 --> 00:57:41.040
Anyway, I think your roadmap is great, but give us the update.

00:57:41.040 --> 00:57:44.040
It is, it is beautiful and I encourage everybody to go and check it out.

00:57:44.040 --> 00:57:46.040
It's hdp.com/roadmap.

00:57:46.040 --> 00:57:47.040
It's, it is slightly outdated.

00:57:47.040 --> 00:57:50.040
Well, lots of things that are in progress were already done.

00:57:50.040 --> 00:57:51.040
Yeah.

00:57:51.040 --> 00:57:53.040
This formula car here, this is a 2021 series.

00:57:53.040 --> 00:57:56.040
They just redid the Formula One cars for 2022.

00:57:56.040 --> 00:57:58.040
So yeah, that's probably not what you're talking about.

00:57:58.040 --> 00:57:59.040
Yeah.

00:57:59.040 --> 00:58:00.040
All right.

00:58:00.040 --> 00:58:01.040
So tell us what's coming for this.

00:58:01.040 --> 00:58:02.040
What's coming.

00:58:02.040 --> 00:58:04.040
It took us years for building HDB 1.0.

00:58:04.040 --> 00:58:10.040
And during this time, we were almost encouraging people not to use HDB because it's a relational database.

00:58:10.040 --> 00:58:16.040
If you build a business on an alpha version of relational database and goes down, your business will go down with it most likely.

00:58:16.040 --> 00:58:18.040
And people should know you just released 1.0, right?

00:58:18.040 --> 00:58:19.040
Yes.

00:58:19.040 --> 00:58:20.040
That's a huge, huge thing.

00:58:20.040 --> 00:58:21.040
Congratulations.

00:58:21.040 --> 00:58:22.040
We launched 1.0 a week ago.

00:58:22.040 --> 00:58:27.040
It was on Hacker News, number one for like 13, maybe 14 hours.

00:58:27.040 --> 00:58:28.040
Wow.

00:58:28.040 --> 00:58:29.040
It was a pretty, pretty interesting event.

00:58:29.040 --> 00:58:36.040
We also had a live stream, us launching it, talking about architecture of HDB, of the query language, comparing it to SQL.

00:58:36.040 --> 00:58:39.040
It's a great event and I encourage you to check it out if you have a live stream.

00:58:39.040 --> 00:58:42.040
If you're interested, it's YouTube/HDB.

00:58:42.040 --> 00:58:43.040
Check it out.

00:58:43.040 --> 00:58:44.040
You'll find it there.

00:58:44.040 --> 00:58:45.040
But yeah.

00:58:45.040 --> 00:58:47.040
So it took us years to do 1.0 just right.

00:58:47.040 --> 00:58:56.040
To make sure that SQL is right, that its design is sound and that the schema is right and the workflows and CLI and the cloud APIs.

00:58:56.040 --> 00:59:00.040
Everything is just right and that we are confident that, hey, we're not going to be changing it.

00:59:00.040 --> 00:59:02.040
We're not going to be retroactively fixing things.

00:59:02.040 --> 00:59:05.040
Took us a long year, many years, but now it's out.

00:59:05.040 --> 00:59:09.040
And now we don't want to spend many years on HDB 2.0.

00:59:09.040 --> 00:59:11.040
We actually want to make it way quicker.

00:59:11.040 --> 00:59:12.040
We have the solid foundation.

00:59:12.040 --> 00:59:14.040
We can iterate much faster now.

00:59:14.040 --> 00:59:16.040
And this is what we're going to do.

00:59:16.040 --> 00:59:22.040
So our current target, internal target, is to release 2.0 sometime in May 2022.

00:59:22.040 --> 00:59:24.040
So relatively soon.

00:59:24.040 --> 00:59:27.040
2.0 will have a few features.

00:59:27.040 --> 00:59:29.040
One is almost implemented.

00:59:29.040 --> 00:59:31.040
It's a group by statement.

00:59:31.040 --> 00:59:37.040
As I said, the idea of HQL is to actually surpass SQL in capabilities.

00:59:37.040 --> 00:59:41.040
And right now with HQL, it's already incredibly powerful.

00:59:41.040 --> 00:59:43.040
You can fetch that data hierarchies.

00:59:43.040 --> 00:59:44.040
You can compute things.

00:59:44.040 --> 00:59:46.040
You can use aggregate functions.

00:59:46.040 --> 00:59:47.040
You have sub queries.

00:59:47.040 --> 00:59:48.040
You have JSON.

00:59:48.040 --> 00:59:56.040
Like it's an incredibly powerful language right now, but a proper group by statements will give it like proper analytical flavor.

00:59:56.040 --> 01:00:00.040
Now you will be able to actually create reports and we have a great group by design.

01:00:00.040 --> 01:00:04.040
By the way, we try to make HQL design process as open as possible.

01:00:04.040 --> 01:00:05.040
We have RFCs.

01:00:05.040 --> 01:00:08.040
It's a GitHub slash HDB slash RFCs.

01:00:08.040 --> 01:00:18.040
So if you're interested to look at how our group by is different from SQL group by and why it's better than SQL group by, you can just go ahead and read an RFC about our group by.

01:00:18.040 --> 01:00:20.040
So group by is going to be one thing.

01:00:20.040 --> 01:00:23.040
The second thing is going to be a proper explain for your queries.

01:00:23.040 --> 01:00:25.040
Like why is my query slow?

01:00:25.040 --> 01:00:31.040
We have some ideas on how to make it less critic than the default explain output that you get most databases.

01:00:31.040 --> 01:00:33.040
Then there is an exciting thing.

01:00:33.040 --> 01:00:38.040
And I hope that we'll have enough time to implement it, which is access control.

01:00:38.040 --> 01:00:41.040
So HDB is this like vertically integrated thing.

01:00:41.040 --> 01:00:49.040
So you define your schema and in your schema you can define aliases, which is basically a view in your relational database.

01:00:49.040 --> 01:00:54.040
You can define fields or object types that are computed dynamically with that scale.

01:00:54.040 --> 01:00:58.040
So schema depends on SQL and SQL depends on schema in HDB.

01:00:58.040 --> 01:01:00.040
They are intertwined.

01:01:00.040 --> 01:01:01.040
So we have this idea.

01:01:01.040 --> 01:01:06.040
It's not that it's like super new, but in HDB it's going to be super powerful.

01:01:06.040 --> 01:01:11.040
Is that you'll be able to specify different policies on your schema type.

01:01:11.040 --> 01:01:16.040
Like allow reading something or allow mutating something or disallow, etc.

01:01:16.040 --> 01:01:17.040
Right.

01:01:17.040 --> 01:01:19.040
And we don't want to hard code that.

01:01:19.040 --> 01:01:23.040
So essentially we are introducing this concept of context in a database.

01:01:23.040 --> 01:01:33.040
You'll be able to define sort of like global variables, like context variables in your schema, say a user ID in 64 and something else.

01:01:33.040 --> 01:01:43.040
And then when you just get your connection in your Python code, you say with context plus user ID that is automatically passed to the database.

01:01:43.040 --> 01:01:49.040
In your schema, you can implement arbitrarily access logic on your schema type.

01:01:49.040 --> 01:01:52.040
And this logic will be automatically enforced in order of queries.

01:01:52.040 --> 01:01:53.040
So fantastic.

01:01:53.040 --> 01:01:54.040
Yeah, that's really cool.

01:01:54.040 --> 01:01:55.040
Fetching data for the home page is filtered.

01:01:55.040 --> 01:02:02.040
You are fetching data for report and it only includes the data that your business logic allow it to be there.

01:02:02.040 --> 01:02:13.040
So basically with HDB, you will have schema and that schema not only will define just the data layout of your application, but also the access patterns and many other things in the future.

01:02:13.040 --> 01:02:14.040
Yeah.

01:02:14.040 --> 01:02:17.040
I really want to ask you about the query syntax.

01:02:17.040 --> 01:02:18.040
Yeah.

01:02:18.040 --> 01:02:24.040
I find it super interesting, especially also how it relates to like ORMs and so on.

01:02:24.040 --> 01:02:29.040
But Michael out in the audience has a pretty neat question that sort of follows on to the roadmap first.

01:02:29.040 --> 01:02:40.040
So since HDB is fundamentally Python, it'd be great to have a way to run user defined functions in Python, I guess, still like stored procedures, but Python.

01:02:40.040 --> 01:02:40.040
Yeah.

01:02:40.040 --> 01:02:41.040
Not SQL.

01:02:41.040 --> 01:02:42.040
Yeah.

01:02:42.040 --> 01:02:42.040
Yeah.

01:02:42.040 --> 01:02:43.040
Yeah.

01:02:43.040 --> 01:02:44.040
It's an interesting question.

01:02:44.040 --> 01:02:45.040
I mean, user defined functions.

01:02:45.040 --> 01:02:54.040
Well, first of all, there are like a couple of different planes, I would say, of user defined functions in the context of HDB because HDB has this notion of extensions.

01:02:54.040 --> 01:02:59.040
The API isn't public yet, but HDB, for example, supports GraphQL natively.

01:02:59.040 --> 01:03:02.040
You can just run HDB, let's say on port 555.

01:03:02.040 --> 01:03:07.040
This is the localhost:555/db/mydb/graphql.

01:03:07.040 --> 01:03:24.040
We want you to be able to also define potentially, eventually, like user defined API handlers there so that with HDB, you would not need a backup at all if your business logic is relatively simple and you don't need like a full blown application.

01:03:24.040 --> 01:03:25.040
Oh, interesting.

01:03:25.040 --> 01:03:36.040
So if I've got like something on Netlify where it's pure static code, I just write a little JavaScript, some view or whatever, and it could theoretically do read only stuff maybe to an HDB.

01:03:36.040 --> 01:03:38.040
To an HDB instance or something like that.

01:03:38.040 --> 01:03:39.040
Or even write only.

01:03:39.040 --> 01:03:40.040
Yeah, absolutely.

01:03:40.040 --> 01:03:46.040
We just want to kind of push this idea of backendless development as far as we can.

01:03:46.040 --> 01:03:53.040
And because HDB has this incredibly powerful schema and will soon have access control, that already allows you to eliminate a lot of code, right?

01:03:53.040 --> 01:03:58.040
If only you could define some simple server side, database side functions.

01:03:58.040 --> 01:04:00.040
A little bit of Python in there.

01:04:00.040 --> 01:04:01.040
I'm starting to come around.

01:04:01.040 --> 01:04:02.040
Yeah.

01:04:02.040 --> 01:04:05.040
A little bit of Python or JavaScript or maybe a Rust or something.

01:04:05.040 --> 01:04:10.040
that you can just make that request to Stripe API, do something and then glue things together.

01:04:10.040 --> 01:04:10.040
Yeah.

01:04:10.040 --> 01:04:12.040
Then maybe you don't need the backend at all.

01:04:12.040 --> 01:04:16.040
So this is our vision eventually to allow things like this.

01:04:16.040 --> 01:04:20.040
And second plane is user defined functions within the database.

01:04:20.040 --> 01:04:23.040
And because there is in Postgres, those functions are going to be running like inside Postgres.

01:04:23.040 --> 01:04:25.040
You will be able to call them from the query language.

01:04:25.040 --> 01:04:29.040
Like, hey, use NumPy to crunch this data for me.

01:04:29.040 --> 01:04:30.040
Like write in SQL.

01:04:30.040 --> 01:04:31.040
This is also possible.

01:04:31.040 --> 01:04:34.040
There are extensions for Postgres that allow you to do that.

01:04:34.040 --> 01:04:38.040
It's possible to define user defined functions in Postgres.

01:04:38.040 --> 01:04:41.040
Multiple different extensions for that are there.

01:04:41.040 --> 01:04:45.040
So yeah, it's an interesting thing for us to think about.

01:04:45.040 --> 01:04:48.040
And we are thinking about it, but probably not for 2.0.

01:04:48.040 --> 01:04:49.040
Yeah.

01:04:49.040 --> 01:04:50.040
Okay.

01:04:50.040 --> 01:04:51.040
Very cool.

01:04:51.040 --> 01:04:52.040
So let's take this statement here for a minute.

01:04:52.040 --> 01:04:53.040
Yeah.

01:04:53.040 --> 01:05:00.040
This query syntax highlights a lot of probably what makes EdgeDB unique and some of your motives

01:05:00.040 --> 01:05:01.040
here.

01:05:01.040 --> 01:05:07.040
So this, if you wanted to go and get say a movie, which has a relationship to an actor's

01:05:07.040 --> 01:05:13.040
table and you want to do some sort of filter type thing, you would say select movie curly

01:05:13.040 --> 01:05:15.040
brace, look at that title.

01:05:15.040 --> 01:05:16.040
That's the select projection.

01:05:16.040 --> 01:05:18.040
So a movie.title basically.

01:05:18.040 --> 01:05:22.040
And then actors, curly brace, name and email.

01:05:22.040 --> 01:05:27.040
So is that, is this part right here, this, the sub actors, is that traversing the relationship,

01:05:27.040 --> 01:05:28.040
that graph relationship?

01:05:28.040 --> 01:05:29.040
Exactly.

01:05:29.040 --> 01:05:30.040
You're basically traversing the graph.

01:05:30.040 --> 01:05:34.040
And then inside the select statement, you say order by.name and you have this cool convention

01:05:34.040 --> 01:05:41.040
of dot, which if you're in one of these scopes, like curly bracket actors, then you can say

01:05:41.040 --> 01:05:44.040
dot and it means dot name applies back to actors that, right?

01:05:44.040 --> 01:05:45.040
Actors.

01:05:45.040 --> 01:05:46.040
Yes.

01:05:46.040 --> 01:05:47.040
And basically this is just syntax sugar.

01:05:47.040 --> 01:05:49.040
Nothing prevents you from spelling it out completely.

01:05:49.040 --> 01:05:52.040
Like you say, you can say order by movie.actors.name.

01:05:52.040 --> 01:05:53.040
Yeah.

01:05:53.040 --> 01:05:57.040
But because you're already in inside the actors, essentially, we're just like giving you this.

01:05:57.040 --> 01:05:58.040
Yeah.

01:05:58.040 --> 01:05:59.040
Fantastic.

01:05:59.040 --> 01:06:03.040
Then another thing that stands out for the query syntax is you can define inline variables

01:06:03.040 --> 01:06:05.040
using the walrus operator, by the way.

01:06:05.040 --> 01:06:06.040
Yeah.

01:06:06.040 --> 01:06:13.040
So you can say average review equals math mean dot reviews of the movie, then dot rating.

01:06:13.040 --> 01:06:15.040
And is this also traversing?

01:06:15.040 --> 01:06:16.040
Exactly.

01:06:16.040 --> 01:06:17.040
What is this?

01:06:17.040 --> 01:06:18.040
Yeah.

01:06:18.040 --> 01:06:23.040
a movie type has a multi-linked reviews.

01:06:23.040 --> 01:06:28.040
So multiple reviews can be attached to movies and every review has, let's say five star rating,

01:06:28.040 --> 01:06:30.040
an integer one to five.

01:06:30.040 --> 01:06:36.040
And this is how you quickly can say, hey, just calculate the mean number of all linked reviews

01:06:36.040 --> 01:06:38.040
and all their ratings.

01:06:38.040 --> 01:06:43.040
So somebody on Hacker News years ago aptly called HGL as a child of SQL and GraphQL.

01:06:43.040 --> 01:06:50.040
And I mean, it's funny, but there is truth to it because GraphQL made it extremely obvious

01:06:50.040 --> 01:06:55.040
to people that working with object hierarchies this way, when you can just have a query that

01:06:55.040 --> 01:06:58.040
just select something deep, right, is extremely important.

01:06:58.040 --> 01:07:00.040
People suddenly realize this is cool.

01:07:00.040 --> 01:07:05.040
Some companies have been trying to make GraphQL work for relational databases such as Hasura.

01:07:05.040 --> 01:07:06.040
And they have an amazing product.

01:07:06.040 --> 01:07:11.040
The only problem is that GraphQL isn't actually, it wasn't, it wasn't designed for creating databases.

01:07:11.040 --> 01:07:14.040
It's an API language, it's a REST replacement.

01:07:14.040 --> 01:07:18.040
So while it works for some things, good luck computing something in GraphQL.

01:07:18.040 --> 01:07:22.040
You just can't, you can fetch things, but you cannot compute like your average review is,

01:07:22.040 --> 01:07:24.040
is not possible to do in GraphQL.

01:07:24.040 --> 01:07:31.040
SQL on the other hand is, is very stubborn when you have to select anything nested, like

01:07:31.040 --> 01:07:35.040
things in tables, you have to think in tables, you either like select super wide tables,

01:07:35.040 --> 01:07:40.040
and then you have to write some Python code to kind of combine it back to your shape or use

01:07:40.040 --> 01:07:45.040
a norm, or if you use an advanced database, you can things like, you can use things like

01:07:45.040 --> 01:07:49.040
a Reag, but SQL isn't, isn't, it doesn't shine for things like this.

01:07:49.040 --> 01:07:53.040
So with, HQL, we're kind of marrying those both worlds.

01:07:53.040 --> 01:08:00.040
You have this, deep fetch syntax and, you have an ability to drop computation in any,

01:08:00.040 --> 01:08:02.040
at any point of your query.

01:08:02.040 --> 01:08:06.040
Now a couple of other like super important things about HQL.

01:08:06.040 --> 01:08:08.040
If you want, I can go into them.

01:08:08.040 --> 01:08:09.040
Yeah.

01:08:09.040 --> 01:08:10.040
We're getting short on time, but yeah, go ahead.

01:08:10.040 --> 01:08:11.040
Sure.

01:08:11.040 --> 01:08:14.040
As I said before, sometimes the pitch HDB is like this LVM thing, like,

01:08:14.040 --> 01:08:15.040
compiler.

01:08:15.040 --> 01:08:19.040
When we compile HQL query to a SQL, we have one important thing.

01:08:19.040 --> 01:08:25.040
Every HQL query, no matter how complex it is, it's always compiled to just one SQL query.

01:08:25.040 --> 01:08:29.040
And this is very important in the context of relational databases, because when you have

01:08:29.040 --> 01:08:31.040
just one single query, it's atomic.

01:08:31.040 --> 01:08:33.040
So you don't need like an explicit transaction.

01:08:33.040 --> 01:08:35.040
You're already like working.

01:08:35.040 --> 01:08:37.040
You always work with the same snapshot of the essentially.

01:08:37.040 --> 01:08:38.040
Interesting.

01:08:38.040 --> 01:08:42.040
So you're not in this case, like going, doing a query for the movies and then doing a query

01:08:42.040 --> 01:08:48.040
for the actors and then doing a query for the reviews as three steps.

01:08:48.040 --> 01:08:50.040
You're just, it's basically a three way join.

01:08:50.040 --> 01:08:51.040
And then you're getting the data back out.

01:08:51.040 --> 01:08:52.040
Something like that.

01:08:52.040 --> 01:08:55.040
It's slightly more complicated than three way join.

01:08:55.040 --> 01:08:56.040
Yeah, sure it is.

01:08:56.040 --> 01:08:59.040
But yeah, basically, basically, yeah, that's, that's the idea.

01:08:59.040 --> 01:09:01.040
We wouldn't, for one HQL query, it's always one SQL query.

01:09:01.040 --> 01:09:02.040
It's very important.

01:09:02.040 --> 01:09:04.040
We use lots of interesting tricks to make it happen.

01:09:04.040 --> 01:09:08.040
And if you're interested about those tricks, YouTube slash HDBs and watch our live event,

01:09:08.040 --> 01:09:10.040
we explain this all actually.

01:09:10.040 --> 01:09:11.040
But it's an important thing.

01:09:11.040 --> 01:09:15.040
And then HQL is actually, it's very composable.

01:09:15.040 --> 01:09:18.040
So you can pack multiple different queries into one query.

01:09:18.040 --> 01:09:24.040
So you can have a query that reads data, insert data, mutates data, and introspects the schema.

01:09:24.040 --> 01:09:26.040
All in one huge thing.

01:09:26.040 --> 01:09:32.040
And it will execute quickly for you and return your data like in proper way, ready for you to be consumed.

01:09:32.040 --> 01:09:34.040
So HQL is extremely powerful in that regard.

01:09:34.040 --> 01:09:39.040
This is what separates it from ORPs because your OR, be it SQLAlchemy or Pre-Ur,

01:09:39.040 --> 01:09:41.040
or Prisma or something like that.

01:09:41.040 --> 01:09:47.040
They might have a high level API for some operations, but they also don't really restrict themselves

01:09:47.040 --> 01:09:50.040
on how many queries it will take to implement that API.

01:09:50.040 --> 01:09:51.040
Right.

01:09:51.040 --> 01:09:52.040
And sometimes N plus one.

01:09:52.040 --> 01:09:53.040
Yeah.

01:09:53.040 --> 01:09:54.040
Right.

01:09:54.040 --> 01:09:57.040
And if you benchmark it on localhost, for example, databases on your laptop and your code

01:09:57.040 --> 01:10:00.040
executes on laptop, it appears to be fast.

01:10:00.040 --> 01:10:02.040
So you have three queries instead of one.

01:10:02.040 --> 01:10:03.040
So what?

01:10:03.040 --> 01:10:05.040
Like there is zero latency between your database and your code.

01:10:05.040 --> 01:10:08.040
And probably not full production levels of data.

01:10:08.040 --> 01:10:09.040
Sure.

01:10:09.040 --> 01:10:13.040
But when you move it to the dot data center, you will have latency between your code and

01:10:13.040 --> 01:10:14.040
the database.

01:10:14.040 --> 01:10:19.040
And even if you have like one millisecond latency between your queries, suddenly you just start

01:10:19.040 --> 01:10:26.040
losing performance a lot because your Python that uses or JavaScript that uses a norm operation,

01:10:26.040 --> 01:10:28.040
you can actually fire like 10 queries.

01:10:28.040 --> 01:10:29.040
This is easy.

01:10:29.040 --> 01:10:30.040
Like 10 queries is fine.

01:10:30.040 --> 01:10:34.040
And imagine it just spend 10 milliseconds on just doing that.

01:10:34.040 --> 01:10:35.040
Yeah.

01:10:35.040 --> 01:10:36.040
Just latency.

01:10:36.040 --> 01:10:37.040
Nothing else.

01:10:37.040 --> 01:10:38.040
Yeah.

01:10:38.040 --> 01:10:39.040
Just losing performance.

01:10:39.040 --> 01:10:40.040
So with SGP, it's not a thing.

01:10:40.040 --> 01:10:41.040
All right.

01:10:41.040 --> 01:10:42.040
So final question here.

01:10:42.040 --> 01:10:45.040
When I run this, what do I get back in Python?

01:10:45.040 --> 01:10:50.040
Obviously there's a nice async and synchronous Python API to talk to this.

01:10:50.040 --> 01:10:51.040
Yeah.

01:10:51.040 --> 01:10:54.040
But when I run this query in Python, what do I get?

01:10:54.040 --> 01:10:56.040
It depends on how you run it.

01:10:56.040 --> 01:10:57.040
Yeah.

01:10:57.040 --> 01:11:00.040
We offer you two modes, essentially two output modes.

01:11:00.040 --> 01:11:02.040
Any HQ query can be compiled as JSON.

01:11:02.040 --> 01:11:05.040
In our Python client, you just say query JSON.

01:11:05.040 --> 01:11:09.040
And it will return your JSON data, like ready to be pumped to your front end.

01:11:09.040 --> 01:11:10.040
Or you can just say query.

01:11:10.040 --> 01:11:14.040
And when you say query, it will return you rich Python objects.

01:11:14.040 --> 01:11:19.040
So you'll have movie Python object, which with a title, a string attribute with an actors list,

01:11:19.040 --> 01:11:22.040
which will have factors, objects within it, et cetera.

01:11:22.040 --> 01:11:25.040
It's also very compact, like on the IO level.

01:11:25.040 --> 01:11:29.040
So we are not sending like super fat tables or anything.

01:11:29.040 --> 01:11:31.040
The data is neatly serialized.

01:11:31.040 --> 01:11:33.040
So no need for any duplication.

01:11:33.040 --> 01:11:34.040
Yeah, that matters.

01:11:34.040 --> 01:11:35.040
Anything.

01:11:35.040 --> 01:11:39.040
It's just like you have your native object data model in the database.

01:11:39.040 --> 01:11:43.040
You query it and you get objects out of it.

01:11:43.040 --> 01:11:46.040
So you never have to think about like any tables or anything.

01:11:46.040 --> 01:11:47.040
It's always high level.

01:11:47.040 --> 01:11:48.040
Nice.

01:11:48.040 --> 01:11:48.040
All right.

01:11:48.040 --> 01:11:49.040
Final question.

01:11:49.040 --> 01:11:50.040
Then we really do have to wrap it up.

01:11:50.040 --> 01:11:56.040
One of the things that's really nice about ORMs is I can say my thing dot, and I get a list

01:11:56.040 --> 01:11:59.040
in my editor of what I should be getting back from the database.

01:11:59.040 --> 01:12:02.040
Can I do that with this?

01:12:02.040 --> 01:12:08.040
I know like the movie is basically defined in the GraphQL schema definition.

01:12:08.040 --> 01:12:10.040
Is there a way to do like a type shed type thing?

01:12:10.040 --> 01:12:11.040
Yeah.

01:12:11.040 --> 01:12:12.040
EdgeDB.

01:12:12.040 --> 01:12:13.040
Sorry.

01:12:13.040 --> 01:12:14.040
I don't know.

01:12:14.040 --> 01:12:17.040
Maybe it's not a DB schema language, but is there a way to do like a type shed thing to say,

01:12:17.040 --> 01:12:19.040
well, that thing you get back looks like this.

01:12:19.040 --> 01:12:20.040
Yes.

01:12:20.040 --> 01:12:22.040
Unfortunately not in Python yet.

01:12:22.040 --> 01:12:27.040
In TypeScript, we just released our query builder and it's insane because the API of the

01:12:27.040 --> 01:12:34.040
query builder super closely replicates the layout of the SQL query.

01:12:34.040 --> 01:12:36.040
It's basically like one to one correspondence.

01:12:36.040 --> 01:12:38.040
It's like almost like same thing.

01:12:38.040 --> 01:12:42.040
And in TypeScript, we just focused on TypeScript first, then Python is next.

01:12:42.040 --> 01:12:47.040
But for TypeScript, yes, you reflect your schema with just one command line command.

01:12:47.040 --> 01:12:50.040
And in VS Code, you now have full autocomplete.

01:12:50.040 --> 01:12:53.040
You can express your queries in TypeScript no matter how nested they are, no matter what

01:12:53.040 --> 01:12:55.040
kind of computation you do.

01:12:55.040 --> 01:12:56.040
It's still the same idea.

01:12:56.040 --> 01:13:00.040
Whatever query you build in your TypeScript is going to be just single SQL query, just single

01:13:00.040 --> 01:13:01.040
SQL query.

01:13:01.040 --> 01:13:02.040
It's going to be fast.

01:13:02.040 --> 01:13:05.040
And you have full autocompletion and more.

01:13:05.040 --> 01:13:08.040
You actually have full return type inference.

01:13:08.040 --> 01:13:09.040
So you don't have to type anything.

01:13:09.040 --> 01:13:15.040
You have a query, your VS Code and TypeScript, they will know the type of the data that's going

01:13:15.040 --> 01:13:16.040
to be returned.

01:13:16.040 --> 01:13:17.040
Interesting.

01:13:17.040 --> 01:13:18.040
Okay.

01:13:18.040 --> 01:13:19.040
It works like magic.

01:13:19.040 --> 01:13:24.040
We're going to see if we can replicate this experience with Python and mypy.

01:13:24.040 --> 01:13:27.040
This is going to be our goal to make something like this happen.

01:13:27.040 --> 01:13:31.040
Right now, we just have this low level, well, relatively low level client API for Python.

01:13:31.040 --> 01:13:32.040
You can run any SQL query.

01:13:32.040 --> 01:13:34.040
You can get data for it.

01:13:34.040 --> 01:13:36.040
You can do it in async or sync.

01:13:36.040 --> 01:13:37.040
Entirely up to you.

01:13:37.040 --> 01:13:40.040
But the typing integration specifically isn't there.

01:13:40.040 --> 01:13:47.040
And second part of this question is that we are looking in future implementing a language

01:13:47.040 --> 01:13:48.040
server protocol for EdgeDB.

01:13:48.040 --> 01:13:52.040
So installs it locally and then VS Code would just connect to it.

01:13:52.040 --> 01:13:56.040
And then you would have your autocomplete for EdgeQL queries, for schema files.

01:13:56.040 --> 01:14:00.040
This is going to be great, but I'm just not sure like what kind of ETA we can put in it.

01:14:00.040 --> 01:14:01.040
Probably not for 2.0.

01:14:01.040 --> 01:14:02.040
Right.

01:14:02.040 --> 01:14:03.040
Okay.

01:14:03.040 --> 01:14:03.040
Yeah.

01:14:03.040 --> 01:14:04.040
Looking forward to it.

01:14:04.040 --> 01:14:07.040
Very neat work on EdgeDB and obviously all the building blocks that we talked about

01:14:07.040 --> 01:14:08.040
at the beginning.

01:14:08.040 --> 01:14:09.040
Congratulations.

01:14:09.040 --> 01:14:10.040
Thank you, Michael.

01:14:10.040 --> 01:14:11.040
Yeah.

01:14:11.040 --> 01:14:12.040
You bet.

01:14:12.040 --> 01:14:13.040
All right.

01:14:13.040 --> 01:14:14.040
I'll list my Pi as well.

01:14:14.040 --> 01:14:14.040
My Pi is a great thing.

01:14:14.040 --> 01:14:14.040
Use my Pi.

01:14:14.040 --> 01:14:15.040
Cool.

01:14:15.040 --> 01:14:16.040
Right on.

01:14:16.040 --> 01:14:17.040
All right.

01:14:17.040 --> 01:14:18.040
Final call to action.

01:14:18.040 --> 01:14:19.040
People are interested in any of your projects.

01:14:19.040 --> 01:14:19.040
Probably primarily EdgeDB.

01:14:19.040 --> 01:14:19.040
What do you say?

01:14:19.040 --> 01:14:20.040
How to get started?

01:14:20.040 --> 01:14:21.040
Yeah, absolutely.

01:14:21.040 --> 01:14:22.040
It's ready for you.

01:14:22.040 --> 01:14:23.040
It's a 1.0.

01:14:23.040 --> 01:14:24.040
It's a stable.

01:14:24.040 --> 01:14:25.040
Follow us on Twitter.

01:14:25.040 --> 01:14:25.040
It's Twitter edge database without any underscores or dashes.

01:14:25.040 --> 01:14:26.040
Just edge database.

01:14:26.040 --> 01:14:26.040
Follow us on Twitter.

01:14:26.040 --> 01:14:26.040
You will find the discord link right in the Twitter description.

01:14:26.040 --> 01:14:26.040
So join our discord.

01:14:26.040 --> 01:14:26.040
We try to grow community.

01:14:26.040 --> 01:14:27.040
And yeah, build something amazing.

01:14:27.040 --> 01:14:27.040
EdgeDB.

01:14:27.040 --> 01:14:28.040
I can't really do it.

01:14:28.040 --> 01:14:29.040
I can't really do it.

01:14:29.040 --> 01:14:30.040
You can't really do it.

01:14:30.040 --> 01:14:31.040
I can't really do it.

01:14:31.040 --> 01:14:32.040
I can't really do it.

01:14:32.040 --> 01:14:33.040
If you want to do it.

01:14:33.040 --> 01:14:34.040
If you want to do it, you can't really do it.

01:14:34.040 --> 01:14:35.040
And then you can't really do it.

01:14:35.040 --> 01:14:36.040
If you want to do it, you can't really do it.

01:14:36.040 --> 01:14:37.040
You can't really do it.

01:14:37.040 --> 01:14:38.040
If you want to do it.

01:14:38.040 --> 01:14:39.040
You can't really do it.

01:14:39.040 --> 01:14:41.040
So if you want to do it, you can't really do it.

01:14:41.040 --> 01:14:42.040
If you want to do it, you can't really do it.

01:14:42.040 --> 01:14:43.040
If you want to do it.

01:14:43.040 --> 01:14:44.040
If you want to do it, you can't really do it.

01:14:44.040 --> 01:14:45.040
You can't really do it.

01:14:45.040 --> 01:14:46.040
If you want to do it.

01:14:46.040 --> 01:14:49.040
Find the discord link right in the Twitter description.

01:14:49.040 --> 01:14:51.040
So join our discord.

01:14:51.040 --> 01:14:55.040
We try to grow community and yeah, build something amazing.

01:14:55.040 --> 01:14:56.040
EdgeDB.

01:14:56.040 --> 01:14:58.040
I can say it like with full confidence.

01:14:58.040 --> 01:15:03.040
EdgeDB is the most amazing things that thing that ever happened to relational databases.

01:15:03.040 --> 01:15:04.040
So take a look at it.

01:15:04.040 --> 01:15:07.040
This is the beginning of hopefully a big movement.

01:15:07.040 --> 01:15:08.040
Yeah, fantastic.

01:15:08.040 --> 01:15:11.040
Let me put in one final postscript question.

01:15:11.040 --> 01:15:12.040
Sorry.

01:15:12.040 --> 01:15:15.040
I really wanted to ask you this and I think it matters for people considering adopting it.

01:15:15.040 --> 01:15:17.040
But do keep it super quick.

01:15:17.040 --> 01:15:18.040
What's the business model?

01:15:18.040 --> 01:15:21.040
Like when you guys released this thing, is it how do people get it?

01:15:21.040 --> 01:15:23.040
Will there be a free version?

01:15:23.040 --> 01:15:24.040
What's the story?

01:15:24.040 --> 01:15:26.040
So EdgeDB is fully open source.

01:15:26.040 --> 01:15:27.040
It's Apache two licenses.

01:15:27.040 --> 01:15:28.040
It's extremely permissive.

01:15:28.040 --> 01:15:29.040
No strings attached.

01:15:29.040 --> 01:15:31.040
We'll make money by running EdgeDB for you.

01:15:31.040 --> 01:15:34.040
Essentially, we will have a hosted version of EdgeDB.

01:15:34.040 --> 01:15:35.040
EdgeDB as a service.

01:15:35.040 --> 01:15:36.040
Yeah, absolutely.

01:15:36.040 --> 01:15:38.040
And this is how most other these companies make money these days.

01:15:38.040 --> 01:15:42.040
It's not anymore about enterprise version of your database so much.

01:15:42.040 --> 01:15:44.040
It is about, hey, can you run this?

01:15:44.040 --> 01:15:46.040
It's a database for us in the private cloud.

01:15:46.040 --> 01:15:47.040
Right.

01:15:47.040 --> 01:15:48.040
This is what businesses want.

01:15:48.040 --> 01:15:49.040
Back it up, scale it.

01:15:49.040 --> 01:15:50.040
Give us all that kind of back.

01:15:50.040 --> 01:15:51.040
Exactly.

01:15:51.040 --> 01:15:52.040
Okay.

01:15:52.040 --> 01:15:53.040
We're actively working on that.

01:15:53.040 --> 01:15:58.040
Although you can run EdgeDB right now on top of Aurora Postgres, RDS Postgres, Google Cloud.

01:15:58.040 --> 01:15:59.040
We have guides for that.

01:15:59.040 --> 01:16:02.040
So if you need to deploy your HDB application, we have your back.

01:16:02.040 --> 01:16:13.040
But we will have this native, proper cloud version of HDB with which you will be able to just, with one terminal command, you will be able to bootstrap a cloud database for yourself.

01:16:13.040 --> 01:16:14.040
It's going to be amazing.

01:16:14.040 --> 01:16:15.040
All right.

01:16:15.040 --> 01:16:15.040
Fantastic.

01:16:15.040 --> 01:16:16.040
Thanks, Gary.

01:16:16.040 --> 01:16:17.040
Thank you.

01:16:17.040 --> 01:16:18.040
Yeah.

01:16:18.040 --> 01:16:19.040
Bye.

01:16:19.040 --> 01:16:20.040
Bye.

01:16:20.040 --> 01:16:21.040
Bye.

01:16:21.040 --> 01:16:22.040
Bye.

01:16:22.040 --> 01:16:23.040
Bye.

01:16:23.040 --> 01:16:24.040
Bye.

01:16:24.040 --> 01:16:28.000
to check out what they're offering. It really helps support the show. Take some stress out of

01:16:28.000 --> 01:16:33.140
your life. Get notified immediately about errors and performance issues in your web or mobile

01:16:33.140 --> 01:16:40.020
applications with Sentry. Just visit talkpython.fm/Sentry and get started for free. And be sure

01:16:40.020 --> 01:16:45.940
to use the promo code talkpython, all one word. Add high performance, multi-party video calls to

01:16:45.940 --> 01:16:51.480
any app or website with SignalWire. Visit talkpython.fm/SignalWire and mention

01:16:51.480 --> 01:16:54.800
that you came from Talk Python to me to get started and grab those free credits.

01:16:54.800 --> 01:17:00.100
Want to level up your Python? We have one of the largest catalogs of Python video courses over at

01:17:00.100 --> 01:17:05.680
Talk Python. Our content ranges from true beginners to deeply advanced topics like memory and async.

01:17:05.680 --> 01:17:09.700
And best of all, there's not a subscription in sight. Check it out for yourself at

01:17:09.700 --> 01:17:14.900
training.talkpython.fm. Be sure to subscribe to the show, open your favorite podcast app,

01:17:14.900 --> 01:17:19.500
and search for Python. We should be right at the top. You can also find the iTunes feed at

01:17:19.500 --> 01:17:26.600
/itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

01:17:26.600 --> 01:17:31.760
We're live streaming most of our recordings these days. If you want to be part of the show and have

01:17:31.760 --> 01:17:36.920
your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm

01:17:36.920 --> 01:17:42.180
slash YouTube. This is your host, Michael Kennedy. Thanks so much for listening. I really appreciate it.

01:17:42.180 --> 01:17:44.100
Now get out there and write some Python code.

01:17:44.100 --> 01:17:44.740
Bye.

01:17:44.740 --> 01:17:44.940
Bye.

01:17:44.940 --> 01:17:45.940
Bye.

01:17:45.940 --> 01:17:46.940
Bye.

01:17:46.940 --> 01:17:47.580
Bye.

01:17:47.580 --> 01:17:47.940
Bye.

01:17:47.940 --> 01:17:48.940
Bye.

01:17:48.940 --> 01:17:48.940
Bye.

01:17:48.940 --> 01:17:48.940
Bye.

01:17:48.940 --> 01:17:48.940
Bye.

01:17:48.940 --> 01:17:49.940
Bye.

01:17:49.940 --> 01:18:05.000
Thank you.

