WEBVTT

00:00:00.001 --> 00:00:06.800
On this episode, you'll meet Francesca Lazeri and hear her story how she went from research fellow in economics at the Harvard Business School

00:00:06.800 --> 00:00:11.440
to working on the AI and data science stack on the Azure team at Microsoft.

00:00:11.440 --> 00:00:16.680
This is Talk Python To Me, episode 220, recorded June 20th, 2019.

00:00:29.720 --> 00:00:35.900
Welcome to Talk Python To Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:00:35.900 --> 00:00:39.960
This is your host, Michael Kennedy. Follow me on Twitter where I'm @mkennedy.

00:00:39.960 --> 00:00:46.140
Keep up with the show and listen to past episodes at talkpython.fm and follow the show on Twitter via at Talk Python.

00:00:46.140 --> 00:00:49.920
This episode is brought to you by Linode and Talk Python Training.

00:00:49.920 --> 00:00:55.080
Be sure to check out what the offers are for both of these segments. It really helps support the show.

00:00:55.940 --> 00:01:00.700
Hey, everyone. Before we get to the interview, I want to quickly tell you about a new course we just launched.

00:01:00.700 --> 00:01:06.420
It's our first major Flask course, and it's called Building Data-Driven Web Apps in Flask and SQLAlchemy.

00:01:06.420 --> 00:01:14.080
This one's a deep dive into Flask. We cover things like routing models, templates, databases, and migrations, and even deployment and security.

00:01:14.600 --> 00:01:19.780
And we do all of this in the context of building a clone of the pypi.org website.

00:01:19.780 --> 00:01:22.800
Check it out over at training.talkpython.fm.

00:01:22.800 --> 00:01:29.180
If you're not sure if you want to choose Flask just yet for your web app, then give our 100 Days of Web course a look.

00:01:29.180 --> 00:01:37.580
We cover many frameworks and programming models in 25 four-day projects, so you get a super wide view of what's out there.

00:01:37.580 --> 00:01:41.320
Then you could pick Flask or Django or Pyramid or something else.

00:01:41.320 --> 00:01:43.520
Thanks for checking it out. Now let's get to the interview.

00:01:43.520 --> 00:01:46.400
Francesca, welcome to Talk Python To Me.

00:01:46.400 --> 00:01:48.140
Hi, thank you. Thank you for having me.

00:01:48.140 --> 00:01:49.920
It's really great to have you on the show.

00:01:49.920 --> 00:01:54.820
We got a chance to meet at Microsoft Build where I was walking around the expo hall floor,

00:01:54.820 --> 00:02:00.340
and you're doing really cool stuff with AI and Python, and I'm just happy to have you here.

00:02:00.340 --> 00:02:03.380
Thank you so much. I'm very excited for being here.

00:02:03.380 --> 00:02:08.400
Yeah, so we're going to dig into this whole machine learning thing that you're working on,

00:02:08.400 --> 00:02:12.240
and just the industry in general, and machine learning at Microsoft as well.

00:02:12.320 --> 00:02:15.080
And that's going to be a lot of fun, but before we get to all those things, you know,

00:02:15.080 --> 00:02:18.020
let's get started with your story. How did you get into programming and Python?

00:02:18.020 --> 00:02:21.920
Yeah, that's a great question. I ask myself this question all the time.

00:02:21.920 --> 00:02:27.740
I have to say, before joining Microsoft as a data scientist, I was a research fellow in business

00:02:27.740 --> 00:02:33.260
economics at Harvard Business School, and over there was in charge of performing statistical

00:02:33.260 --> 00:02:38.500
and econometrics analysis within the technology operation management unit.

00:02:38.500 --> 00:02:44.960
So at that time, really, my title wasn't a data scientist, but it wasn't, as I said, a research fellow.

00:02:44.960 --> 00:02:54.960
But I had to work with a massive amount of data from different data sources, such as patent, publication data, social network data.

00:02:54.960 --> 00:03:02.280
The goal of my research was to investigate and measure the impact of external knowledge networks.

00:03:02.280 --> 00:03:07.480
And that's why we were using that specific type of data on companies' innovation.

00:03:07.480 --> 00:03:12.220
Is that like social media or what's an external source of data that you might be looking at?

00:03:12.220 --> 00:03:16.060
Patent data, publication data, and social network data.

00:03:16.440 --> 00:03:19.920
These three were the main three sources of data.

00:03:19.920 --> 00:03:27.300
And we were trying to understand if these knowledge networks were also localized from a geographical point of view,

00:03:27.300 --> 00:03:32.240
or they were more like global networks of knowledge.

00:03:32.240 --> 00:03:39.300
And how these networks, both local and global, could affect a company's innovation.

00:03:39.300 --> 00:03:45.120
As you might know, like, for example, Cambridge, Massachusetts, that is where I'm working from,

00:03:45.460 --> 00:03:48.340
and where my office is at Microsoft Cambridge.

00:03:48.340 --> 00:03:53.300
It's a very powerful tech cluster and also pharma cluster.

00:03:53.300 --> 00:03:55.780
Okay, well, that sounds like a really cool thing to study there.

00:03:55.780 --> 00:04:00.140
So you're studying this data, you're studying these projects at Harvard Business School.

00:04:00.140 --> 00:04:06.820
And of course, this is probably not a challenge that can easily be solved with Excel, and definitely not manually, right?

00:04:06.820 --> 00:04:07.360
Exactly.

00:04:07.360 --> 00:04:13.520
So at that time, Python was emerging as a leader in data science programming.

00:04:13.520 --> 00:04:20.980
And while there are still many people in academia who use R, SPSS for their analysis,

00:04:20.980 --> 00:04:26.800
Python, I think, was getting very, very popular because there were a lot of data science libraries.

00:04:26.800 --> 00:04:32.020
I remember that one of the most popular and still very popular is Pandas.

00:04:32.020 --> 00:04:38.400
So it has many in-build features, such as the ability to read the data from many sources.

00:04:38.400 --> 00:04:44.580
You can create large data frames from these sources and also compute aggregate analytics.

00:04:44.840 --> 00:04:52.600
And this was exactly what I needed as a research fellow and also for doing all the data analysis that I needed to do.

00:04:52.600 --> 00:04:53.820
Yeah, that's really interesting.

00:04:53.820 --> 00:04:54.960
What year was this?

00:04:54.960 --> 00:04:55.660
Like, about?

00:04:55.800 --> 00:05:00.920
It was about 2012, 2013, 2014.

00:05:00.920 --> 00:05:06.120
Because then I started to work at Microsoft as a data scientist exactly in 2014.

00:05:06.120 --> 00:05:15.360
And at that time, I remember that R was still very, very strong for both academics and also data scientists.

00:05:15.360 --> 00:05:17.800
But Python was already there, of course.

00:05:17.800 --> 00:05:35.040
Of course, and the reason I ask is I have this theory that there's a big change at an inflection point around 2012 where a couple of things happened that just made Python in the data science space really start to accelerate out ahead of the other options like R.

00:05:35.040 --> 00:05:39.380
And it's just, it's super interesting that it's this time as well that you're, you sort of picked it up.

00:05:39.380 --> 00:05:40.260
Yeah, totally agree.

00:05:40.260 --> 00:05:40.640
Yeah.

00:05:40.640 --> 00:05:46.200
And so did you know other programming languages before or did you have to teach yourself Python to get into this?

00:05:46.200 --> 00:05:47.960
I had to teach myself Python.

00:05:47.960 --> 00:05:52.580
Of course, at university, I took a couple of classes, just introduction to Python.

00:05:52.580 --> 00:05:55.220
And those classes were very helpful.

00:05:55.220 --> 00:05:58.240
Before that, I was already coding a lot in R.

00:05:58.240 --> 00:06:05.660
SQL was another very powerful language that I'm still using sometimes to just ingest the data.

00:06:05.660 --> 00:06:10.580
You know, sometimes you need to prepare your data, some tables, and you need just to ingest them.

00:06:10.580 --> 00:06:16.040
And from there, you can start using the tools that you prefer to build a machine learning solution.

00:06:16.040 --> 00:06:18.900
And it's Python, the main tool that I use.

00:06:18.900 --> 00:06:28.340
But I have to say, beside these two languages, then the third language is, for me, it's Python, because it's very, very powerful for data science.

00:06:28.340 --> 00:06:31.500
And I would say data analysis in general.

00:06:31.500 --> 00:06:39.980
So also for people who need to do a lot of statistics, econometrics type of analysis, Python is a very, very good choice.

00:06:39.980 --> 00:06:40.440
Absolutely.

00:06:40.440 --> 00:06:47.240
Did you come up with any really interesting results from your research at your time there that you can talk about briefly or anything like that?

00:06:47.320 --> 00:06:48.080
Yeah, absolutely.

00:06:48.080 --> 00:06:51.080
I mean, I love my time there at Harvard.

00:06:51.080 --> 00:06:55.960
I was working with a great professor and a great research unit.

00:06:55.960 --> 00:06:59.140
And so the results were very interesting.

00:06:59.140 --> 00:07:10.140
So we noticed that for the most important innovations, and we were targeting the biotech industry, the localization was very, very important.

00:07:10.140 --> 00:07:25.120
And like we noticed that data scientists who were located in the same, sorry, not data scientists, scientists in the biotech industry, and also some data scientists, but we were looking just at the general category of scientists who were located in the same geographical cluster.

00:07:25.120 --> 00:07:30.020
They were actually able to innovate more often and much faster.

00:07:30.020 --> 00:07:37.340
So, and of course, we were seeing these in terms of publication, in terms of how they were citing each other.

00:07:37.480 --> 00:07:48.460
And most importantly, in terms of patents, because the only way to really measure knowledge and how the knowledge can be clustered is through patents, unfortunately.

00:07:48.460 --> 00:07:52.740
I mean, I say unfortunately, because it's a sort of extra step.

00:07:52.740 --> 00:07:58.080
You have to make a few assumptions to make this correlation between knowledge and patents.

00:07:58.080 --> 00:08:02.160
But still, it's a good indicator for innovation.

00:08:02.160 --> 00:08:03.740
So we noticed this.

00:08:04.060 --> 00:08:17.780
However, we noticed that for long-term innovation, like if you look at the company and you look at the number of patents that the company and the research unit have filed, you can see that geographical barriers are actually not an issue.

00:08:17.780 --> 00:08:28.300
And right now, especially with the use of technology, innovation and the knowledge do not need to be linked from a geographical point of view.

00:08:28.500 --> 00:08:31.140
So this is what we noticed with our research.

00:08:31.140 --> 00:08:32.540
Yeah, that sounds really interesting.

00:08:32.540 --> 00:08:38.700
So the short term is more important to be around fellow scientists, but long term, the knowledge gets out there.

00:08:38.700 --> 00:08:39.780
Cool.

00:08:39.780 --> 00:08:40.440
All right.

00:08:40.440 --> 00:08:41.920
So you're no longer working.

00:08:41.920 --> 00:08:43.740
You're no longer doing that research at Harvard.

00:08:43.740 --> 00:08:46.200
You're still near Harvard, but you're working at Microsoft.

00:08:46.200 --> 00:08:47.480
What do you do day to day there?

00:08:47.600 --> 00:08:51.580
Right now, I'm a machine learning scientist on the cloud advocacy team.

00:08:51.580 --> 00:09:00.540
And what I do, I work with a lot of external customers and the Azure machine learning community in general.

00:09:00.540 --> 00:09:10.980
Specifically, I work a lot with universities and research institutions from students, professors to researchers on machine learning projects.

00:09:11.120 --> 00:09:12.240
Oh, that sounds really interesting.

00:09:12.240 --> 00:09:14.640
And there's something special about universities.

00:09:14.640 --> 00:09:16.320
I mean, you were at Harvard for a while.

00:09:16.320 --> 00:09:20.820
Just being on campus and being in those environments is really nice.

00:09:20.820 --> 00:09:25.180
So it must be fun to work with those research groups just on a day-to-day basis.

00:09:25.180 --> 00:09:25.760
Absolutely.

00:09:25.760 --> 00:09:38.740
And I think, again, talking about innovation, I think that the real innovation starts most of the time from university, from research units, from what we call a spin-off.

00:09:38.740 --> 00:09:42.980
There are a specific type of startups coming from academia.

00:09:42.980 --> 00:09:49.960
So I really think that having these close relations with university is a key for innovation.

00:09:49.960 --> 00:09:53.600
And when I say innovation, I mean also in terms of machine learning solutions.

00:09:53.600 --> 00:10:01.020
So it's nice because most of the time I leverage their knowledge in terms of AI and machine learning.

00:10:01.020 --> 00:10:10.200
But I'm the one that is more like expert, even if it's hard to use this word, because I think that every time we learn from each other.

00:10:10.200 --> 00:10:14.160
But more or less, I have more experience with the technology that they can use.

00:10:14.340 --> 00:10:27.200
And so that their innovation, their research is not just on paper, but they can actually translate these, transform their research into a product, into a service, into a feature that other people can consume.

00:10:27.200 --> 00:10:32.080
So that's why it's so interesting to work with these type of customers.

00:10:32.080 --> 00:10:33.520
I feel very lucky.

00:10:33.520 --> 00:10:34.320
Yeah, for sure.

00:10:34.320 --> 00:10:35.060
They're so interesting.

00:10:35.320 --> 00:10:43.880
And especially in science and biology and pharmaceuticals, those are not the kind of startups that people often can just go start on their own.

00:10:43.880 --> 00:10:46.200
They often spin out of these labs.

00:10:46.200 --> 00:10:47.940
And that's like a pretty cool area, right?

00:10:47.940 --> 00:10:48.540
Absolutely.

00:10:49.120 --> 00:10:55.480
And again, this is a topic that is similar to my Harvard University research.

00:10:55.480 --> 00:11:00.740
What we call it, economists call it a spillover type of effect.

00:11:00.740 --> 00:11:07.160
Like when you build the knowledge and then you decide to transfer this knowledge outside.

00:11:07.380 --> 00:11:09.960
And when I say outside, it can be to a different industry.

00:11:09.960 --> 00:11:12.680
Like from academia, you go to the real industry.

00:11:12.680 --> 00:11:15.540
It could be biotech, tech, or any other industry.

00:11:15.540 --> 00:11:17.120
Or you change.

00:11:17.120 --> 00:11:19.200
You change completely your area.

00:11:19.200 --> 00:11:22.640
Like from economics, you go to machine learning.

00:11:22.640 --> 00:11:30.620
As you said, it's something, it's a real nice phenomenon that you can notice when you are like in a cluster, in a tech and knowledge cluster.

00:11:30.620 --> 00:11:33.480
And yeah, it's a very interesting phenomenon.

00:11:33.480 --> 00:11:34.900
Yeah, I'm sure that it is.

00:11:35.280 --> 00:11:40.380
How interchangeable is the knowledge between the different projects that you're working on?

00:11:40.380 --> 00:11:43.900
Like how much do you have to try to study what they're doing?

00:11:43.900 --> 00:11:48.340
Or how interchangeable is like this machine learning, data science world?

00:11:48.340 --> 00:11:50.200
That is a great question.

00:11:50.200 --> 00:12:01.460
So I think that the difference is in the data and in the business problem, or I would say research problem in this case, that you are trying to solve.

00:12:01.860 --> 00:12:11.660
Everything that is in the middle is actually very similar in the sense that the approach can change or the type of technique that you are using.

00:12:11.660 --> 00:12:20.480
If you have like economics background or a biotech background or a machine learning background can be like a little bit different.

00:12:20.480 --> 00:12:35.620
But more or less, you have this scientific mindset that you know that there are a few techniques, some very powerful techniques that you can apply on your data to an answer that is going to be able to solve your problem.

00:12:35.700 --> 00:12:38.880
Again, if you are talking to a company, of course, it's a business problem.

00:12:38.880 --> 00:12:45.380
In this case, since my customers most of the time are university research institutes, the problem is more like a research problem.

00:12:45.640 --> 00:12:47.420
So it's a very, very interesting.

00:12:47.420 --> 00:12:55.260
Of course, those people, as you said, they have most of the time very different backgrounds, but they are experts of the data.

00:12:55.260 --> 00:13:00.660
And they know very well what the output from their research needs to be like.

00:13:00.660 --> 00:13:02.040
What is the type of answer?

00:13:02.040 --> 00:13:04.600
What is the type of problem that they want to solve?

00:13:04.980 --> 00:13:08.320
So my role is really between these two points.

00:13:08.320 --> 00:13:20.960
Like I really help them understand how they can use the machine learning and the cloud to build the hand-to-hand AI solutions and apps most of the time to solve their own specific research problems.

00:13:20.960 --> 00:13:25.460
And also to sometimes can be just an optimization of a specific process, for example.

00:13:25.920 --> 00:13:35.960
And what is interesting in my role is that I don't just help them understanding what are the potentials with using machine learning, but it's also about collecting feedback.

00:13:35.960 --> 00:13:41.400
Because when I work with them, of course, I always have some type of feedback that I can collect.

00:13:41.400 --> 00:13:53.460
And then I support our machine learning product teams, our AI product teams, to build a new feature, to optimize our services for both machine learning scientists and data scientists.

00:13:55.520 --> 00:13:58.640
This portion of Talk Python To Me is brought to you by Linode.

00:13:58.640 --> 00:14:02.380
Are you looking for hosting that's fast, simple, and incredibly affordable?

00:14:02.380 --> 00:14:07.480
Well, look past that bookstore and check out Linode at talkpython.fm/Linode.

00:14:07.480 --> 00:14:09.380
That's L-I-N-O-D-E.

00:14:09.380 --> 00:14:13.800
Plans start at just $5 a month for a dedicated server with a gig of RAM.

00:14:13.800 --> 00:14:16.020
They have 10 data centers across the globe.

00:14:16.020 --> 00:14:19.840
So no matter where you are or where your users are, there's a data center for you.

00:14:19.840 --> 00:14:24.320
Whether you want to run a Python web app, host a private Git server, or just a file server,

00:14:24.540 --> 00:14:31.500
you'll get native SSDs on all the machines, a newly upgraded 200 gigabit network, 24-7 friendly support,

00:14:31.500 --> 00:14:34.300
even on holidays, and a seven-day money-back guarantee.

00:14:34.300 --> 00:14:35.880
Need a little help with your infrastructure?

00:14:35.880 --> 00:14:40.620
They even offer professional services to help you with architecture, migrations, and more.

00:14:40.620 --> 00:14:43.560
Do you want a dedicated server for free for the next four months?

00:14:43.560 --> 00:14:46.640
Just visit talkpython.fm/Linode.

00:14:48.200 --> 00:14:56.900
Artificial intelligence was something, when I was in college, it was like a small research side of computer science.

00:14:56.900 --> 00:14:58.620
And there were some people working on it.

00:14:58.620 --> 00:15:04.040
But it was always, it felt like one of those technologies that's 30 years away, if ever.

00:15:04.040 --> 00:15:08.300
The type of problems they were trying to solve is, well, let's build a little chat bot.

00:15:08.660 --> 00:15:15.740
And then if a person can chat with the chat bot in IRC, and they don't know that it's a machine, it's artificial intelligence,

00:15:15.740 --> 00:15:17.620
that we're very close, right?

00:15:17.620 --> 00:15:22.820
And that seemed like an interesting research project, but not really practical.

00:15:23.300 --> 00:15:29.380
And now we have machine learning taking stuff just so far along, right?

00:15:29.380 --> 00:15:30.920
We've got self-driving cars.

00:15:30.920 --> 00:15:35.240
We have computer algorithms determining whether folks have cancer.

00:15:35.240 --> 00:15:38.120
All sorts of, like, mind-blowing stuff.

00:15:38.120 --> 00:15:42.680
So I feel like AI has really become real, right?

00:15:42.680 --> 00:15:43.980
It's actually become a thing.

00:15:44.540 --> 00:15:49.440
But also, I think it's a little bit misunderstood in some interesting ways.

00:15:49.440 --> 00:15:56.360
Like, how would you describe artificial intelligence to non-technical people or machine learning even?

00:15:56.360 --> 00:15:58.540
Yeah, that's another great question.

00:15:58.540 --> 00:16:06.500
I think that simply speaking, AI is just about programming computers to make decisions.

00:16:06.500 --> 00:16:12.980
And machine learning, of course, focuses more on making predictions about the future.

00:16:13.520 --> 00:16:16.980
So I always like to explain AI with an example.

00:16:16.980 --> 00:16:24.580
Like, there is a very nice app that I have been using here at Microsoft, and it's called Seeing AI.

00:16:24.580 --> 00:16:33.580
It's a Microsoft research project that really brings together the power of the cloud and AI to deliver this intelligent app

00:16:33.580 --> 00:16:40.240
that is designed to help people that are blind or that they are, like, low vision.

00:16:40.880 --> 00:16:45.340
And they help them, like, to go through their everyday life.

00:16:45.460 --> 00:16:49.760
It's very nice because with this app, you can just point to your phone's camera.

00:16:49.760 --> 00:16:56.180
You can select a channel, and you can hear a description of what the app has recognized around you.

00:16:56.180 --> 00:17:08.380
So, again, this is a very, very good example of AI and how AI can help us also to improve some of our everyday actions, I would say.

00:17:08.700 --> 00:17:13.720
As I said at the beginning, it's really about programming computers to do something, to make some decisions.

00:17:13.720 --> 00:17:18.240
That's really incredible, this Seeing AI app here.

00:17:18.240 --> 00:17:19.580
I'll put a link in the show notes.

00:17:19.960 --> 00:17:26.980
So, you just hold it up and it just says, hey, I see there's a car over there and there's a table with two people sitting at it, something like this?

00:17:26.980 --> 00:17:27.420
Exactly.

00:17:27.420 --> 00:17:27.860
Wow.

00:17:27.860 --> 00:17:32.700
Yeah, it's very, very nice because, again, it's with your phone camera.

00:17:32.700 --> 00:17:39.520
You can select a channel and here, again, a description of what has been recognized around you.

00:17:39.520 --> 00:17:43.660
So, it's really designed to help you navigate your day.

00:17:43.780 --> 00:17:44.160
That's amazing.

00:17:44.160 --> 00:17:48.040
I'll tell you a real quick story that's kind of wild that happened to me about 10 or 15 years ago.

00:17:48.040 --> 00:17:50.100
And this person could have really used this app.

00:17:50.100 --> 00:17:53.000
I was walking to the grocery store where I lived.

00:17:53.000 --> 00:17:55.700
It was maybe three blocks, four blocks away.

00:17:55.700 --> 00:18:01.860
And I was walking along and this guy comes over or is standing next to me at this light and says, hey, could you help me?

00:18:01.860 --> 00:18:03.240
I said, sure, no problem.

00:18:03.240 --> 00:18:03.880
What do you need?

00:18:03.880 --> 00:18:06.100
He says, could you tell me where the grocery store is?

00:18:06.100 --> 00:18:09.980
And it was clearly visible just across, diagonal across the intersection.

00:18:09.980 --> 00:18:11.040
I said, yeah, it's right there.

00:18:11.040 --> 00:18:12.520
He goes, don't point, man.

00:18:12.520 --> 00:18:13.100
I'm blind.

00:18:13.240 --> 00:18:14.140
I'm like, wait, what?

00:18:14.140 --> 00:18:16.640
You know, it was not at all obvious.

00:18:16.640 --> 00:18:17.740
He's like, could you just help me?

00:18:17.740 --> 00:18:18.900
I just got disoriented.

00:18:18.900 --> 00:18:20.380
Could you just help me walk over there?

00:18:20.380 --> 00:18:22.160
And I took him by the arm.

00:18:22.160 --> 00:18:24.100
We walked over there and he said, thank you very much.

00:18:24.100 --> 00:18:26.700
When we got to the store, he just went off on his own and went shopping.

00:18:26.700 --> 00:18:29.500
I was just amazed how well he could function.

00:18:29.500 --> 00:18:33.900
But it seems like just something like this, he could just hold it up and go, there's a store across the street.

00:18:33.900 --> 00:18:34.760
Oh, there it is.

00:18:34.760 --> 00:18:35.120
I see.

00:18:35.120 --> 00:18:36.440
You know, it would be just amazing.

00:18:36.440 --> 00:18:38.340
And it could really change people's lives.

00:18:38.340 --> 00:18:38.840
That's awesome.

00:18:38.840 --> 00:18:39.440
Absolutely.

00:18:39.440 --> 00:18:40.520
Yeah, I totally agree.

00:18:40.520 --> 00:18:42.700
And there are many, many other examples.

00:18:42.700 --> 00:18:53.320
I really like to talk about this app, the seeing an AI app, because I think that it can be a very good impact on people's lives.

00:18:53.320 --> 00:18:54.960
But I totally agree with you.

00:18:54.960 --> 00:18:58.300
There are so many other examples that they're just around you.

00:18:58.300 --> 00:19:00.520
And probably we don't even notice at this time.

00:19:00.900 --> 00:19:08.140
But they are there of the AI apps that just help us with our everyday tasks that we have to perform.

00:19:08.140 --> 00:19:08.780
So, yeah.

00:19:08.780 --> 00:19:09.600
Nice story.

00:19:09.600 --> 00:19:10.480
Very nice story.

00:19:10.480 --> 00:19:11.220
Yeah, thanks.

00:19:11.480 --> 00:19:14.720
So, you're describing artificial intelligence and machine learning.

00:19:14.720 --> 00:19:20.820
I saw a funny joke that said, how can you tell the difference between artificial intelligence and machine learning?

00:19:20.820 --> 00:19:25.280
And it said, if it's written in Python, it's probably machine learning.

00:19:25.280 --> 00:19:29.240
If it's written in PowerPoint as a concept, it's probably AI.

00:19:30.440 --> 00:19:33.980
I saw that joke, of course, as well.

00:19:33.980 --> 00:19:34.540
It's a good one.

00:19:34.540 --> 00:19:36.460
And it's a very, very good one.

00:19:36.460 --> 00:19:39.060
And I have to say, probably it's also true.

00:19:39.060 --> 00:19:40.980
There is some truth there.

00:19:41.560 --> 00:19:47.220
I mean, AI is something that, as we said, in some cases is already around us.

00:19:47.220 --> 00:19:51.740
In some other cases, it's not there yet or it needs to be improved.

00:19:51.740 --> 00:19:58.240
But I still think that it depends a lot on how you define AI and what are your expectations from AI.

00:19:58.240 --> 00:20:00.780
But, yes, that joke, it's very popular.

00:20:00.780 --> 00:20:03.020
And I saw that as well.

00:20:03.020 --> 00:20:03.540
That's a good one.

00:20:03.540 --> 00:20:03.860
Yep.

00:20:03.860 --> 00:20:04.220
Nice.

00:20:04.220 --> 00:20:04.940
All right.

00:20:04.940 --> 00:20:09.080
So, let's talk a little bit about the AI stuff you guys have going on at Microsoft.

00:20:09.360 --> 00:20:12.960
And you work on the machine learning cloud advocacy team.

00:20:12.960 --> 00:20:24.420
So, it seems like a lot of stuff these days that Microsoft is doing, especially in the developer space, is something at Azure or something on the cloud or something like that, right?

00:20:24.420 --> 00:20:28.960
It feels to me like Azure has really become the super big focus.

00:20:28.960 --> 00:20:39.920
And once again, developers have kind of really become a big focus at Microsoft, as opposed to, say, just Windows and Office, for example, as the two key pillars of the company or whatever, right?

00:20:39.920 --> 00:20:40.360
What do you think?

00:20:40.360 --> 00:20:41.360
What's your impression?

00:20:41.360 --> 00:20:42.760
That's totally right.

00:20:42.760 --> 00:20:48.200
And we can feel this both from an external and internal point of view.

00:20:48.200 --> 00:20:58.180
I think that everything probably started with Satya Nadella's first emails to us, to Microsoft employees, because it's very interesting.

00:20:58.180 --> 00:21:08.100
Instead of focusing on the past, he wrote about the future and, in particular, the importance of cloud for Microsoft's growth.

00:21:08.440 --> 00:21:13.920
He's also saying that our industry does not respect the tradition, but only respect innovation.

00:21:13.920 --> 00:21:22.440
So, this means that there was, at that time, and still, there is a strong focus on the cloud, on machine learning, and on AI.

00:21:22.440 --> 00:21:35.700
For example, also from an internal point of view, we noticed that in 2017, Microsoft launched an AI division with more than 5,000 computer scientists.

00:21:36.140 --> 00:21:38.720
That was, of course, that was a huge change.

00:21:38.720 --> 00:21:43.780
And also, of course, there was, like, computer scientists, software engineers, AI developers.

00:21:43.780 --> 00:21:52.460
And at that time, we also launched an intelligent cloud division, which included products such as Server and Azure.

00:21:52.460 --> 00:21:58.400
This was, again, a big change that we noticed both from an internal point of view, but also externally.

00:21:59.080 --> 00:22:08.520
And then, another, I think, big change that we noticed is that Microsoft has done a series of, I would say, smart acquisitions.

00:22:08.520 --> 00:22:11.580
For example, GitHub and LinkedIn.

00:22:12.140 --> 00:22:22.100
And I think that he did that because we really wanted to make AI accessible to developers and to our communities in general.

00:22:22.100 --> 00:22:24.240
So, yes, it's a big change.

00:22:24.240 --> 00:22:26.720
Of course, it didn't start this year.

00:22:26.720 --> 00:22:29.420
It has been going on for a while at Microsoft.

00:22:29.420 --> 00:22:32.900
And I think that we are seeing the results right now.

00:22:32.900 --> 00:22:37.840
There is a big focus on cloud, AI, and machine learning.

00:22:37.880 --> 00:22:41.320
Yeah, it definitely seems like a big shift, but in a positive way.

00:22:41.320 --> 00:22:43.180
I think it's a good move.

00:22:43.180 --> 00:22:48.400
So, maybe tell us about some of the AI stuff that you have going on at Azure.

00:22:48.400 --> 00:22:53.360
I know there's a lot of cool things that you have going on there.

00:22:53.360 --> 00:22:57.580
I know you have some stuff around ML DevOps, for example, right?

00:22:57.580 --> 00:23:02.240
Machine learning DevOps and just doing things like productizing machine learning models

00:23:02.240 --> 00:23:06.740
or turning them into production systems like REST endpoints and so on.

00:23:06.740 --> 00:23:09.760
So, maybe we could talk a little bit about all the stuff you got going on there.

00:23:09.760 --> 00:23:10.460
Yeah, absolutely.

00:23:10.460 --> 00:23:16.140
So, right now we have MLOps or DevOps for machine learning capabilities.

00:23:16.140 --> 00:23:18.760
And this includes Azure DevOps.

00:23:18.760 --> 00:23:24.460
This enables Azure DevOps to be used to manage the entire machine learning lifecycle,

00:23:24.460 --> 00:23:32.340
including, for example, model reproducibility, validation, the deployment part, the retraining.

00:23:33.220 --> 00:23:48.880
And it's very interesting as a data scientist to see this because I have to say the DevOps for machine learning includes a lot of the steps that the data scientists need to perform when they are building an end-to-end machine learning solution,

00:23:48.880 --> 00:23:55.880
model training model management, model management, deployment, and monitoring.

00:23:55.880 --> 00:23:57.280
I can go on and on.

00:23:57.280 --> 00:24:08.920
So, those pipelines allow for what we call the modularization of these different steps or different phases into smaller steps.

00:24:09.400 --> 00:24:17.020
And also, it provides a mechanism for automating, sharing, and most importantly, reproducing the models for models.

00:24:17.020 --> 00:24:20.820
And not only models, also the different machine learning assets that you need.

00:24:20.820 --> 00:24:30.520
Again, thanks to these, all the machine learning workflow becomes like much, much easier to perform and to reproduce and to automate.

00:24:30.680 --> 00:24:31.880
So, it's great to see this.

00:24:31.880 --> 00:24:35.560
It sounds like it solves a lot of good problems or problems that need solving.

00:24:35.560 --> 00:24:35.880
Yeah.

00:24:35.880 --> 00:24:39.200
So, what does machine learning in production look like, right?

00:24:39.200 --> 00:24:44.320
Is that like TensorFlow behind a RESTful, some like Flask REST service?

00:24:44.320 --> 00:24:50.480
Or what does it look like for folks who are like just web developers or not doing, you know, data science day-to-day?

00:24:50.480 --> 00:24:58.280
Yeah, that is very interesting because I think that data scientists, they love to focus a lot on the machine learning piece.

00:24:58.280 --> 00:25:07.400
But then, once you decided what is the best model or the best models, because it can be, of course, multiple models that you want to push into production,

00:25:07.400 --> 00:25:14.660
it's also very important to understand how you can deploy the solution and how other people can eventually consume the solution.

00:25:14.660 --> 00:25:16.200
Back to your questions.

00:25:16.200 --> 00:25:19.060
Into production, it's a web service.

00:25:19.060 --> 00:25:29.560
It can be, I have to say that the first format that it takes is a pickle file because this training run, that is the model training,

00:25:29.560 --> 00:25:34.920
this training run produces a Python serialized object that we call it, again, a pickle file.

00:25:34.920 --> 00:25:38.780
And this contains the model and the data preprocessing.

00:25:38.780 --> 00:25:47.160
So, this is very, very important because then at this time, there is actually the following step is to make this web service.

00:25:47.160 --> 00:25:56.420
And the web service is really, there is a REST API that, again, you can call to just consume the service from whatever environment you prefer.

00:25:56.420 --> 00:26:02.280
Like, it can be, again, an app or it can be like just another platform that your company is already using.

00:26:02.440 --> 00:26:07.660
And you want to use that to consume the results from your machine learning model.

00:26:07.660 --> 00:26:08.780
Yeah, that sounds pretty cool.

00:26:08.780 --> 00:26:13.960
So, maybe I have a REST endpoint and I just upload a picture, like a PNG or something.

00:26:13.960 --> 00:26:14.300
Exactly.

00:26:14.300 --> 00:26:18.480
And it takes it, understands it, feeds it through the pre-trained model.

00:26:18.620 --> 00:26:28.160
So, there's the training side of things, which can be super computational, but then maybe the evaluation decision-making process is really quick, right?

00:26:28.340 --> 00:26:33.600
So, what response times people typically look for, but I suspect it's much, much, much faster, right?

00:26:33.600 --> 00:26:36.700
It's a question that doesn't really have an answer.

00:26:36.700 --> 00:26:39.860
Like, it really depends on the type of solution that you are building.

00:26:39.860 --> 00:26:46.680
And most importantly, it depends on the type of data, the amount of data that you are using.

00:26:46.680 --> 00:26:50.960
So, there is not a clear answer to that.

00:26:50.960 --> 00:27:05.140
But it's interesting how to see that right now there are many different solutions that you can use, actually, to accelerate, I would say, not only the deployment and the consumption process, but also the training process.

00:27:05.700 --> 00:27:09.480
Like, for example, we have right now a new feature.

00:27:09.480 --> 00:27:14.780
It's actually not really new because it was launched last September, September 2018.

00:27:14.780 --> 00:27:17.540
And it's called Automated Machine Learning.

00:27:17.540 --> 00:27:20.720
And it's a feature within Azure Machine Learning Service.

00:27:20.720 --> 00:27:32.080
For those who are not familiar with Automated Machine Learning, this is a process of automating the time-consuming, very iterative, I would say, task of machine learning model development.

00:27:32.080 --> 00:27:42.080
And allows data scientists and also analysts and developers to build machine learning models with, you know, high-scale efficiency and also productivity.

00:27:42.080 --> 00:27:48.340
Because you don't need, actually, to manually create all these different models by yourself.

00:27:48.340 --> 00:27:53.040
But Automated Machine Learning actually runs many different models for you.

00:27:53.040 --> 00:27:59.860
And it suggests you the best model and also all the hyperparameter tuning is, again, done for you.

00:27:59.860 --> 00:28:04.620
So, it's a new feature that can somehow optimize the machine learning flow.

00:28:04.620 --> 00:28:12.820
But, again, going back to your question about time, when you are in a machine learning context, saying, like, a specific time, it's very hard.

00:28:12.820 --> 00:28:14.460
Super hard, yeah.

00:28:14.460 --> 00:28:14.820
I see.

00:28:15.340 --> 00:28:20.640
So, that's pretty meta to have machine learning teaching your machine learning algorithm, right?

00:28:20.640 --> 00:28:21.620
Yeah, yeah, yeah.

00:28:21.620 --> 00:28:28.700
Automated Machine Learning, it's very interesting because it's actually, again, was developed by Microsoft Research.

00:28:28.700 --> 00:28:31.180
It's like Seeing AI, the app.

00:28:31.180 --> 00:28:38.340
And then our products team was able, actually, to translate these research pieces into a real feature.

00:28:38.840 --> 00:28:44.780
So, again, it's a sort of a big recommender system for your machine learning pipelines.

00:28:44.780 --> 00:28:50.420
And I've been using these now for a while as a data scientist for the past few months.

00:28:50.420 --> 00:28:58.900
And I have to say that, really, it's not just about saving you some time as a data scientist, but it's also a sort of check.

00:28:59.120 --> 00:29:10.680
Like, sometimes when you prepare your data or, like, you pick a specific type of models to try on your training data set, you somehow are exposed to biases.

00:29:10.680 --> 00:29:14.760
Because, again, it's a selection process that you, as a human, you have to do.

00:29:14.760 --> 00:29:26.280
While if you have also an external voice somehow, an external suggestion that just gives you a different perspective or different suggestions, again, I think that is a sort of sanity check.

00:29:26.760 --> 00:29:36.000
So, again, it's not just about saving time, but I think it's also about making your process more objective and less subjective.

00:29:36.000 --> 00:29:38.240
Yeah, it sounds like it would be really helpful.

00:29:38.240 --> 00:29:42.480
So, normally, when you're doing training, you have to pick some kind of model.

00:29:42.480 --> 00:29:47.720
You say, I think this kind of model with this many nodes and this type of thing, we're going to set it up.

00:29:48.000 --> 00:29:52.500
And here goes the training data where you know what the outcome should be.

00:29:52.500 --> 00:29:54.700
Like, let's say, housing prices, right?

00:29:54.700 --> 00:30:02.940
Like, one of the interesting problems people tried was, given just the description of a house and a neighborhood, predict the price that it should sell for.

00:30:02.940 --> 00:30:05.740
Like, you could feed all that and say the actual price was this.

00:30:05.740 --> 00:30:08.180
And it corrects itself, right?

00:30:08.220 --> 00:30:15.040
But there's still a lot of decisions on the actual model that you feed it to or the setup you feed it to on top of the training data, right?

00:30:15.040 --> 00:30:16.600
That's totally correct.

00:30:17.140 --> 00:30:25.320
And, again, this is something that most data scientists do it manually in the sense that you start with your raw feature.

00:30:25.320 --> 00:30:31.460
Actually, you start with your raw data, and then you do some data cleaning, data preparation.

00:30:31.460 --> 00:30:34.440
And then it starts what we call the feature engineering.

00:30:34.440 --> 00:30:41.360
But, again, the feature engineering is something that you do based on some assumptions that you have in your mind.

00:30:41.360 --> 00:30:48.240
Because feature engineering is really about creating additional features based on the raw data that you have.

00:30:48.240 --> 00:30:52.100
And some of these additional features, let me give you a real example.

00:30:52.100 --> 00:30:57.300
Like, for example, if we are in a time series forecasting scenario, you have the timestamped column,

00:30:57.300 --> 00:31:02.640
and you can build additional features such as is the holiday or is not holidays?

00:31:02.640 --> 00:31:04.620
This is afternoon or no?

00:31:04.620 --> 00:31:05.820
Is the weekend or no?

00:31:05.820 --> 00:31:09.740
And this can help you making your model more accurate in some cases.

00:31:09.740 --> 00:31:12.440
This is not the case sometimes, but they can help.

00:31:12.440 --> 00:31:19.480
But, again, also the feature engineering is something that you do before you even know what is going to be the output of your model.

00:31:19.480 --> 00:31:25.800
And then after the feature engineering, of course, you start manually selecting and trying a few approaches that,

00:31:25.800 --> 00:31:31.260
based on your experience and knowledge as a data scientist, have worked pretty well in similar scenarios.

00:31:31.260 --> 00:31:37.000
And after that, of course, usually you need like one single machine learning model.

00:31:37.060 --> 00:31:43.620
And, of course, you have been doing a lot of iteration for the hyperparameter tuning part.

00:31:43.620 --> 00:31:45.540
And then you push everything into production.

00:31:45.540 --> 00:31:50.300
But as you said, it's something that you have to try out manually.

00:31:50.300 --> 00:31:57.160
And there are now some new features like automated machine learning that can help you somehow saving some time.

00:31:57.160 --> 00:32:05.100
Because, of course, they do all the training, not only the training, but they do all the experimentation with different machine learning models for you.

00:32:05.100 --> 00:32:08.580
And also, most importantly, the hyperparameter tuning part.

00:32:08.580 --> 00:32:10.720
Yeah, that sounds like a pretty cool service.

00:32:10.720 --> 00:32:17.600
So if I'm going to go work with like the machine learning SDK over on Azure for what you guys are doing,

00:32:17.840 --> 00:32:23.560
like what libraries are supported, you know, are the standard Python libraries the ones we get to use?

00:32:23.560 --> 00:32:26.860
Or do you have to use like a Microsoft ML one or something like that?

00:32:26.920 --> 00:32:30.420
All the standard Python libraries are supported.

00:32:30.420 --> 00:32:37.700
And then, of course, we have the library for the Azure Machine Learning SDK for Python.

00:32:38.220 --> 00:32:44.640
And this is, again, you have to think about it as a sort of a library, Python library.

00:32:44.640 --> 00:32:51.540
And the most important part of this is that the deployment part is going to be much, much easier.

00:32:51.540 --> 00:32:52.320
Why?

00:32:52.320 --> 00:32:58.260
Because, of course, when you prepare your data and you do all the feature engineering part,

00:32:58.260 --> 00:33:02.740
and then you go to the modeling phase, that part, basically, it's Python.

00:33:02.740 --> 00:33:03.680
It's Python.

00:33:03.680 --> 00:33:07.760
And you can, of course, just use the classical Python libraries.

00:33:08.140 --> 00:33:14.260
But then when you go into the deployment part, I have to say that Azure Machine Learning SDK for Python,

00:33:14.260 --> 00:33:19.580
at least I find it very powerful because you just need to write a couple of functions,

00:33:19.580 --> 00:33:22.720
like what we call the init and run functions.

00:33:22.720 --> 00:33:28.800
And those two functions are going basically to define the model and how the data needs to be,

00:33:28.800 --> 00:33:30.560
the data that you use to feed the model.

00:33:30.560 --> 00:33:36.300
And as soon as you have defined these two functions, then it's very easy just to register your model

00:33:36.300 --> 00:33:40.540
and then create that pickle file that I was mentioning before.

00:33:40.680 --> 00:33:44.400
So, yeah, going back to your question, is Python-based.

00:33:44.400 --> 00:33:51.280
And it's very nice to build and run machine learning workflow with what we call the Azure Machine Learning Service.

00:33:51.280 --> 00:33:55.260
Another thing I saw you all talking about is model interoperability.

00:33:55.260 --> 00:33:56.260
What does that mean?

00:33:56.620 --> 00:34:01.440
Yeah, that's, I would say, is one of my favorite topics.

00:34:01.440 --> 00:34:13.000
Because I think that model interpretability is another topic that is very close to what we call the ethics in AI or biases in AI.

00:34:13.000 --> 00:34:16.980
So, first of all, it's a package.

00:34:16.980 --> 00:34:21.060
So, first of all, it's a package, Python-based package within the Azure Machine Learning Python SDK.

00:34:21.060 --> 00:34:29.860
And what it does for you is really make the machine learning models not black boxes anymore for you.

00:34:30.240 --> 00:34:36.420
So, like, for example, you can use classes and methods that are in the SDK.

00:34:36.420 --> 00:34:44.920
And you can get, with this model interpretability package, you can get feature importance values for both raw and engineer feature.

00:34:44.920 --> 00:34:52.320
You can get interpretability on real-world data set, both during training and inference deployment.

00:34:52.320 --> 00:34:53.700
So, it's very nice.

00:34:53.840 --> 00:35:01.420
And then the most interesting part is that you can also get interacting visualization to help you understand your data.

00:35:01.420 --> 00:35:08.100
So, like, for example, let's say that we are in a use case where you want to predict the price of a car.

00:35:08.100 --> 00:35:18.360
You create some additional features, and then you try out a couple of machine learning models, and then you deploy those models or just pick one model and you deploy it.

00:35:18.640 --> 00:35:27.720
But then, most of the time, data scientists, they want really to understand what are the different features that actually affect the accuracy of the model, the performance of your model.

00:35:27.720 --> 00:35:34.540
And this is something that, right now, you can get through the model interpretability package within Azure Machine Learning.

00:35:34.540 --> 00:35:37.060
So, I think it's something very, very important.

00:35:37.060 --> 00:35:43.820
Yeah, it's really interesting because one of the big problems with machine learning is it's really good at making decisions,

00:35:43.820 --> 00:35:51.240
but there are certain circumstances where you need to know real concretely why a decision was made, right?

00:35:51.240 --> 00:35:55.240
Like, sometimes it's just to improve the system.

00:35:55.240 --> 00:36:02.680
Like, if a car crashes, like a Tesla self-driving car turns the wrong way and crashes, like they need that to not happen again.

00:36:02.680 --> 00:36:04.560
So, understanding how to fix it is important.

00:36:04.560 --> 00:36:06.840
But other times, it's like legal even, right?

00:36:06.900 --> 00:36:13.520
Like, if you get rejected for a mortgage for your house and you apply for a loan, you get rejected.

00:36:13.520 --> 00:36:21.780
A lot of times, there's laws that say you have to be told why you were rejected or there has to be some visibility into that, right?

00:36:21.780 --> 00:36:22.680
To avoid bias.

00:36:22.680 --> 00:36:23.220
Absolutely.

00:36:23.400 --> 00:36:26.240
That's why I mentioned ethics in AI.

00:36:26.240 --> 00:36:29.220
That is a big topic right now.

00:36:29.220 --> 00:36:31.040
And biases.

00:36:31.040 --> 00:36:37.180
Because, as you said, the first place where biases create is the data set that you are using.

00:36:37.180 --> 00:36:43.080
So, all the training data that you use most of the time can create biases in your model.

00:36:43.440 --> 00:36:52.160
And, as a result, also in the different outputs that your model is giving you in the final results that, you know, you are looking at.

00:36:52.360 --> 00:37:04.260
And, as you said, having, like, sort of visibility, transparency on why the model gave you that specific output is something that we all need to have.

00:37:04.260 --> 00:37:05.860
At least, we have to have this option.

00:37:05.860 --> 00:37:12.020
It's not, I really believe that it's something that, for sure, is going to be interesting for data scientists.

00:37:12.020 --> 00:37:17.480
Because data scientists, I think, they don't want to use machine learning models as a black box at all.

00:37:17.480 --> 00:37:24.420
They really want to understand why specific processes were done and why we had specific results.

00:37:24.420 --> 00:37:29.100
But it's also, as you said, it's also a topic that should be interesting for everybody.

00:37:29.100 --> 00:37:39.840
Because, again, some of the decisions that are made based on the machine learning models that we build can really affect personal life in a good or negative way.

00:37:39.840 --> 00:37:43.060
Yeah, and you definitely want to have visibility around those things, right?

00:37:43.060 --> 00:37:43.580
Absolutely.

00:37:43.580 --> 00:37:49.500
Human biases can get into the algorithms and then the machines just make biased decisions faster.

00:37:49.500 --> 00:37:50.720
Yeah, yeah, absolutely.

00:37:50.720 --> 00:37:53.800
More systematically, which is not so good.

00:37:53.800 --> 00:37:54.220
No.

00:37:54.220 --> 00:37:59.220
So, if people want to play around with some of this stuff, you guys have the Azure Machine Learning Notebooks, right?

00:37:59.220 --> 00:38:00.920
Is that something that's easy to go play with?

00:38:00.920 --> 00:38:03.260
Yeah, and we have Azure Machine Learning Notebooks.

00:38:03.260 --> 00:38:08.080
This is something new that was actually announced at the build where we met.

00:38:08.080 --> 00:38:12.620
And these are integrated with Azure Machine Learning Service.

00:38:12.620 --> 00:38:16.820
And they provide a code-first experience for Python developers.

00:38:16.820 --> 00:38:22.240
And so, as a Python developer, you can build and deploy your models in a workspace.

00:38:22.240 --> 00:38:30.560
And also, developer and data scientists can then perform every operation that are supported by the Azure Machine Learning Python SDK.

00:38:30.760 --> 00:38:35.020
So, you don't need to install anything else, anything additional.

00:38:35.020 --> 00:38:36.780
You can just connect with this.

00:38:36.780 --> 00:38:41.540
And it's nice because you also have a pretty good computer target, the virtual machine.

00:38:41.540 --> 00:38:51.360
It's a very easy environment to use if you are a data scientist or a developer and you want to use Python with Azure Machine Learning Service.

00:38:51.680 --> 00:38:52.820
Okay, that sounds really cool.

00:38:52.820 --> 00:38:57.680
Another challenge working with machine learning is you have to feed it a lot of data.

00:38:57.680 --> 00:39:01.520
And you have to have, like, the data somewhat cleaned up, right?

00:39:01.520 --> 00:39:04.180
Hence, Pandas is pretty powerful and interesting there.

00:39:04.180 --> 00:39:04.380
Yeah.

00:39:04.380 --> 00:39:04.960
And so on.

00:39:04.960 --> 00:39:07.940
But you have some open data sets as well.

00:39:07.940 --> 00:39:10.140
You want to tell folks what kind of data they get there?

00:39:10.140 --> 00:39:11.160
That sounds pretty helpful.

00:39:11.340 --> 00:39:11.620
Yeah.

00:39:11.620 --> 00:39:20.040
So, this is a part of some of the new open source capabilities that Azure Machine Learning has.

00:39:20.040 --> 00:39:35.700
And Azure Open Data Set, I would say it's one of my favorites because it's really a sort of repo for a public data set that you can use to add scenario-specific features to your machine learning solution to get more accurate models.

00:39:35.700 --> 00:39:46.640
Like, for example, I was building an energy demand forecasting solution and I already added the load data, load historical data from a public data set.

00:39:46.640 --> 00:39:56.660
But I really wanted to include weather data because, as you know, energy consumption can be strongly dependent on weather.

00:39:56.660 --> 00:40:02.680
And specifically, I wanted to use temperature data.

00:40:02.680 --> 00:40:09.380
So, thanks to Azure Open Data Set, I was able to get this public data set for weather.

00:40:09.380 --> 00:40:14.700
But we have also holidays, public safety data, and also location data.

00:40:14.700 --> 00:40:23.200
So, all these external and public data can really enrich your original data set and can help you to build more accurate models.

00:40:23.200 --> 00:40:37.260
The last thing that I think is very important for these open Azure Open Data Set is that they are on the cloud and they are available to, for example, Azure Databricks, Machine Learning Service, and Machine Learning Studio.

00:40:37.260 --> 00:40:41.080
So, you can really consume them from different tools.

00:40:41.220 --> 00:40:51.920
And you can also access them through APIs and use them in other products like visualization products like Power BI or Azure Data Factory.

00:40:51.920 --> 00:40:55.060
Yeah, it's pretty cool that it's already uploaded and accessible there.

00:40:55.060 --> 00:41:00.900
Because, like, one of the data sets is you have the New York City taxi and limousine trip records.

00:41:00.900 --> 00:41:01.140
Yeah.

00:41:01.140 --> 00:41:04.840
But that's 500 million rows and it's five gigs of data.

00:41:04.840 --> 00:41:09.900
So, it would be better if you didn't have to upload that and try to move that around and whatever, right?

00:41:09.900 --> 00:41:13.420
Just download it or just ingest it and process it.

00:41:13.420 --> 00:41:14.200
Yeah, absolutely.

00:41:14.820 --> 00:41:18.300
And again, I did this for the Energy Demand Forecasting Solution.

00:41:18.300 --> 00:41:26.900
And the pain points for me as a data scientist was really not only to look for a public weather data source,

00:41:26.900 --> 00:41:32.360
but because I found that there are around several weather data that you can use.

00:41:32.360 --> 00:41:39.660
But the problem was, like, really to download them and, most importantly, make the hand-to-hand solution working.

00:41:39.800 --> 00:41:43.360
Because once you download them, you want to consume them over time.

00:41:43.360 --> 00:41:50.960
And having them, like, on the cloud and the fact that you can consume new data and also forecast data,

00:41:50.960 --> 00:41:53.500
because it was, again, a time series forecasting data.

00:41:53.500 --> 00:41:57.260
So, as an input, I needed the forecast weather data.

00:41:57.260 --> 00:42:03.440
It's something that really, really helped me and made my work as a data scientist much, much easier.

00:42:03.440 --> 00:42:04.340
Yeah, that's really cool.

00:42:04.340 --> 00:42:07.900
So, I know that a lot of the stuff that you all are doing is on the cloud.

00:42:08.440 --> 00:42:14.300
And, right, you have, like, virtual machines and ones with GPUs that you can leverage and services and so on.

00:42:14.300 --> 00:42:21.640
But I'm sure that a lot of data scientists, even who use the cloud, also work locally on their computers, right?

00:42:21.640 --> 00:42:22.520
Absolutely, yep.

00:42:22.520 --> 00:42:22.760
Yeah.

00:42:22.760 --> 00:42:29.160
So, what does a proper data science, machine learning computer look like these days?

00:42:29.160 --> 00:42:32.180
You know, like, you have to get some fancy GPU.

00:42:32.180 --> 00:42:33.980
Like, what do you do for a setup?

00:42:33.980 --> 00:42:36.980
What do you see people using for setups in your interactions with them?

00:42:37.080 --> 00:42:37.300
Yeah.

00:42:37.300 --> 00:42:43.500
So, I have to say, most of the researchers, students, and also big corporations I work with,

00:42:43.500 --> 00:42:51.400
they all use right now data science virtual machines, especially when I talk and I work with other data scientists.

00:42:51.400 --> 00:42:58.160
Because those data science virtual machines, and some of them are also called deep learning virtual machines,

00:42:58.160 --> 00:43:06.140
they come with all the different tools that you need as a data scientist, different cluster, GPUs, as you said, the right size.

00:43:06.140 --> 00:43:10.660
And they are already there, and you can just start working with these.

00:43:10.860 --> 00:43:17.060
And it's true that you mentioned that most of the time, or I would say not most of the time, probably sometimes data scientists,

00:43:17.060 --> 00:43:22.700
they still want to use their local machine, especially probably at the beginning of machine learning projects.

00:43:23.080 --> 00:43:34.880
So, some of the editors that I have been seeing using a lot are like Visual Studio Code, that of course there is a local app that they can just download.

00:43:35.020 --> 00:43:40.320
But other very, very popular editors are like JupyterLab, PyCharm.

00:43:40.320 --> 00:43:43.080
So, there are many options out there.

00:43:43.500 --> 00:43:47.580
And I have to say the most popular ones, again, are virtual machines.

00:43:47.580 --> 00:43:56.680
And then when you have to work on your local machine, you probably use editors such as Visual Studio Code and other tools, again, like PyCharm.

00:43:56.680 --> 00:44:02.860
How often do you see data privacy being a problem or a challenge that people run into?

00:44:02.860 --> 00:44:08.780
Just stuff they don't want to put on the cloud, or they're not allowed to leave the building as it is?

00:44:08.780 --> 00:44:10.220
I see it very often.

00:44:10.220 --> 00:44:13.000
I think that is all about the trust, really.

00:44:13.000 --> 00:44:21.780
Because when you start a new data science project or like a new machine learning project, it's all about getting to know each other.

00:44:21.780 --> 00:44:25.680
So, you work as a data scientist, you work with an external entity.

00:44:25.680 --> 00:44:28.360
Again, it can be a big corporation, it can be a university.

00:44:28.360 --> 00:44:32.140
And of course, at the beginning, when you are what we call the scoping phase,

00:44:32.140 --> 00:44:36.860
so you are defining what is the research problem or the business problem that you want to solve,

00:44:36.860 --> 00:44:38.900
what is the data that you're going to use.

00:44:38.900 --> 00:44:42.340
Of course, over there, you are building trust.

00:44:42.460 --> 00:44:44.100
It's the moment that you are building trust.

00:44:44.100 --> 00:44:58.500
And probably you don't use, they just share with you a sample of the data, and you just share with them like a general demo to show like the potential of different machine learning tools and the cloud.

00:44:58.920 --> 00:45:03.920
But then I think it's the real moment where you are building trust between each other.

00:45:03.920 --> 00:45:10.400
And of course, security in the data space, it's a concern that everybody needs to have.

00:45:10.400 --> 00:45:16.740
I mean, we have to be concerned about data because this means that we are aware of what are the different options out there.

00:45:17.160 --> 00:45:27.560
And that's why I think that VM, virtual machines, most of the time are the best choice when you work also with external customers and with external data scientists,

00:45:27.560 --> 00:45:37.680
because it's a sort of common place where you can just connect using and, of course, performing all the security steps that your customers or, you know,

00:45:37.720 --> 00:45:40.760
your research peers wants you to perform, of course.

00:45:40.760 --> 00:45:48.140
But it's like a sort of common place where you can share all your experiments or data and so on.

00:45:48.140 --> 00:45:50.040
Like a safe, safe middle ground.

00:45:50.040 --> 00:45:50.960
Yes, exactly.

00:45:50.960 --> 00:45:51.860
This is exactly what it means.

00:45:51.860 --> 00:45:55.500
Inside anybody's firewalls and things like that.

00:45:55.500 --> 00:45:56.060
Interesting.

00:45:56.060 --> 00:45:57.180
That's pretty cool.

00:45:57.180 --> 00:45:59.400
So we're getting sort of close to the end of our time.

00:45:59.400 --> 00:46:07.720
And I did want to ask you to do a little bit of a prediction for us because you are seeing so many different projects that are coming along,

00:46:07.720 --> 00:46:09.120
what people are doing and researching.

00:46:09.120 --> 00:46:16.460
So what do you think that machine learning is going to create or do for society or how is it going to change society?

00:46:17.100 --> 00:46:22.780
And like, say, five or 10 years that maybe normal people who don't follow this see coming.

00:46:22.780 --> 00:46:24.660
I'm a very optimistic person.

00:46:24.660 --> 00:46:34.020
So I don't really think that, you know, AI is going to impact our everyday life or our world in a negative way.

00:46:34.020 --> 00:46:44.260
I really think that if we are able to just take advantage of what AI and when I say AI, I mean, also all the machine learning algorithms that are behind AI.

00:46:44.680 --> 00:46:55.320
If we are able to really take advantage of this, we can really see some improvements in the different processes and different industries such as healthcare.

00:46:55.320 --> 00:46:58.180
Yeah, healthcare is the first one that I was thinking of as well.

00:46:58.180 --> 00:47:08.220
Healthcare is something because they are, I think, after the finance industry, they are the industry that actually produce the biggest amount of data.

00:47:08.760 --> 00:47:16.020
And of course, the more data you have, better your models and objective the results are going to be.

00:47:16.020 --> 00:47:23.320
So for sure, if I have to mention a few industries where I see AI being successful in the next few years,

00:47:23.320 --> 00:47:25.660
one, as I mentioned, is healthcare.

00:47:25.660 --> 00:47:28.540
The second is transportations.

00:47:28.680 --> 00:47:37.500
I really think that not only driverless cars are going to improve our everyday life, but also what we call the predictive maintenance,

00:47:37.500 --> 00:47:46.180
that is, you know, predicting when a machine is going to fail, is something that is going to have a huge impact in the transportation to field.

00:47:46.740 --> 00:47:56.100
And the third one is, I would say, probably is less interesting, but still it's an industry that we all need to interact with.

00:47:56.100 --> 00:47:57.500
That is the finance industry.

00:47:57.500 --> 00:48:01.420
So the finance industry, why I see the biggest impact there?

00:48:01.420 --> 00:48:06.480
Because actually, they are the ones who have been using machine learning for longer time.

00:48:06.480 --> 00:48:14.100
But I have to say that this interaction between AI and machine learning is something new to them as well.

00:48:14.100 --> 00:48:18.640
So I think that we are going to see interesting solution there as well.

00:48:18.640 --> 00:48:29.980
And probably is going to democratize what sometimes looks and sounds inaccessible to many people who are not experts in economics or trading.

00:48:29.980 --> 00:48:39.080
So I think these are the three main industries where we will see a lot of changes and impact from the AI world.

00:48:39.080 --> 00:48:42.480
Yeah, those are all definitely, I think healthcare for sure.

00:48:42.480 --> 00:48:47.620
There's just so much data and it has the opportunity to be just so transformative, right?

00:48:47.620 --> 00:48:53.460
You think of the cancer diagnosis and the other things or, and, you know, probably pharmaceuticals as well.

00:48:53.460 --> 00:48:54.820
It's kind of tied into that, right?

00:48:54.820 --> 00:48:56.980
Like creating new drugs in a much quicker way.

00:48:56.980 --> 00:48:57.420
Absolutely.

00:48:57.420 --> 00:49:07.640
And if you think about healthcare, beside the two excellent examples that you just made, also there is all the insurance word for healthcare.

00:49:07.640 --> 00:49:14.080
Also that can really help facilitate some of the processes that sometimes patients have to go through.

00:49:14.080 --> 00:49:19.980
And if we can optimize time and make these processes better for, you know, people who need healthcare.

00:49:19.980 --> 00:49:23.260
I think that also is a very, very good improvement.

00:49:23.260 --> 00:49:23.740
Yeah.

00:49:23.740 --> 00:49:28.260
One other I'd love to see is the energy sector around renewable energy and stuff like that.

00:49:28.260 --> 00:49:30.940
There's, it seems like that a lot of good stuff could happen there.

00:49:30.940 --> 00:49:31.440
Totally agree.

00:49:31.440 --> 00:49:31.820
All right.

00:49:31.820 --> 00:49:36.420
So I guess before we call it a show, I'm going to ask you the two final questions I always ask.

00:49:36.420 --> 00:49:40.360
The first one is if you're going to write some Python code, what editor do you use?

00:49:40.360 --> 00:49:43.280
I already mentioned this editor is a Visual Studio Code.

00:49:43.640 --> 00:49:50.240
I have to say that I really like right now the Python extension and the Azure Machine Learning extension.

00:49:50.240 --> 00:50:04.020
The Azure Machine Learning for Visual Studio Code that previously was called Visual Studio Code Tools for AI is an extension that you can use as data scientists to build, train, and also deploy your machine learning models, of course, on the cloud.

00:50:04.440 --> 00:50:10.800
Also on the edge, you can leverage the power of Azure Machine Learning service.

00:50:11.200 --> 00:50:15.840
Other editors that I really like is our Jupyter Lab.

00:50:15.840 --> 00:50:23.540
I think I really like it because it provides a high level of integration between notebooks, documents, and different activities.

00:50:23.540 --> 00:50:29.280
And then the other one that I mentioned, and I think that data scientists should also consider, is a pie chart.

00:50:29.280 --> 00:50:43.120
Because I think that it's similar to Visual Studio Code that they both have interesting features such as a code editor, errors highlighting, and also a powerful debugger with a nice graphical interface.

00:50:43.120 --> 00:50:48.340
They seem to have a slightly different philosophy, Visual Studio Code and PyCharm, but they're both really good.

00:50:48.340 --> 00:50:48.640
Excellent.

00:50:48.640 --> 00:50:53.280
And then, of course, the Jupyter stuff is like standard data scientists.

00:50:53.280 --> 00:50:55.840
You've got to fit that into the workflow somewhere, right?

00:50:55.840 --> 00:50:56.300
Absolutely.

00:50:56.300 --> 00:50:57.000
Awesome.

00:50:57.000 --> 00:51:00.740
All right, and then finally, a notable PyPI package.

00:51:00.740 --> 00:51:05.800
Not necessarily the most popular, but something that folks maybe haven't heard of, but it's really cool that you want to share.

00:51:05.800 --> 00:51:08.840
Again, I'm very passionate about time series forecasting.

00:51:08.840 --> 00:51:15.200
And the package that I have been using a lot lately is the forecasting package with AutoML.

00:51:15.200 --> 00:51:24.540
So for forecasting tasks, automated machine learning uses these preprocessing and estimation steps that are specific to time series data.

00:51:24.540 --> 00:51:33.180
So the preprocessing steps will, for example, detect time series samples frequency, if it is hourly, daily, or weekly.

00:51:33.180 --> 00:51:42.820
And they create new records for missing data for missing time stamps to make the series continuous.

00:51:42.820 --> 00:51:46.620
And then they can also input missing values in the target and feature columns.

00:51:46.620 --> 00:51:52.420
And they can create grain-based features to enable fixed effects across different series.

00:51:52.420 --> 00:52:03.120
So this is, again, it's a very nice forecasting package that you can use with the AutoML config object within Azure Machine Learning Service.

00:52:03.120 --> 00:52:06.100
And I have to say, I have been using this a lot.

00:52:06.440 --> 00:52:07.040
Yeah, that's cool.

00:52:07.040 --> 00:52:07.360
Yeah.

00:52:07.360 --> 00:52:08.240
Yeah, that's really cool.

00:52:08.240 --> 00:52:12.340
Their example on the PyPI page is like eight lines of code.

00:52:12.340 --> 00:52:12.840
Yeah.

00:52:12.840 --> 00:52:13.860
It's pretty incredible.

00:52:13.860 --> 00:52:14.200
Yeah.

00:52:14.200 --> 00:52:14.520
Yeah.

00:52:14.520 --> 00:52:15.120
Super cool.

00:52:15.120 --> 00:52:15.680
Okay.

00:52:15.680 --> 00:52:16.840
Well, that's a good one.

00:52:16.840 --> 00:52:17.760
And I hadn't heard of it either.

00:52:17.760 --> 00:52:18.620
So quite nice.

00:52:18.620 --> 00:52:19.100
Yeah, yeah.

00:52:19.100 --> 00:52:20.060
You should try it out.

00:52:20.060 --> 00:52:21.540
Yeah, definitely.

00:52:21.540 --> 00:52:22.140
All right.

00:52:22.140 --> 00:52:29.240
Well, thank you for sharing what you've been up to and all of your experience working with all these other groups, universities and companies and so on.

00:52:29.900 --> 00:52:30.840
It's been great to chat with you.

00:52:30.840 --> 00:52:31.320
Thank you.

00:52:31.320 --> 00:52:31.680
Yeah.

00:52:31.680 --> 00:52:34.940
And people want to get started with some of these things you talked about.

00:52:34.940 --> 00:52:36.620
You know, what's Final Call to Action?

00:52:36.620 --> 00:52:37.880
Where should they go check out?

00:52:37.880 --> 00:52:38.820
Where should they go?

00:52:38.820 --> 00:52:41.520
There are a few links that I would like to share.

00:52:41.520 --> 00:52:46.600
The first one is aka.ms slash Azure ML service.

00:52:46.600 --> 00:52:48.280
So it's very easy to remember.

00:52:48.280 --> 00:52:54.220
And the other one is aka.ms slash Azure ML for VS Code.

00:52:54.800 --> 00:53:00.620
And if you want to get started, the last link is aka.ms get started Azure ML.

00:53:00.620 --> 00:53:09.780
So these are some of the links that you can look at if you want to learn more about Azure Machine Learning service, Azure Machine Learning for Visual Studio Code.

00:53:09.780 --> 00:53:13.980
And if you want just to get started with Azure in general.

00:53:13.980 --> 00:53:15.000
Yeah, that sounds great.

00:53:15.000 --> 00:53:15.820
Those are good links.

00:53:15.820 --> 00:53:18.260
And I'll be sure to put them in the show notes so people can check them out.

00:53:18.260 --> 00:53:18.660
That's great.

00:53:18.660 --> 00:53:19.140
Thank you.

00:53:19.140 --> 00:53:19.700
Yeah, you bet.

00:53:19.700 --> 00:53:20.480
Thanks for being on the show.

00:53:20.480 --> 00:53:20.940
Thank you.

00:53:20.940 --> 00:53:21.520
Bye-bye.

00:53:22.580 --> 00:53:25.280
This has been another episode of Talk Python To Me.

00:53:25.280 --> 00:53:28.200
Our guest on this episode was Francesca Lazeri.

00:53:28.200 --> 00:53:31.080
And it's been brought to you by Linode and Talk Python Training.

00:53:31.080 --> 00:53:35.100
Linode is your go-to hosting for whatever you're building with Python.

00:53:35.100 --> 00:53:38.640
Get four months free at talkpython.fm/Linode.

00:53:38.640 --> 00:53:40.520
That's L-I-N-O-D-E.

00:53:40.520 --> 00:53:42.880
Want to level up your Python?

00:53:42.880 --> 00:53:47.740
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

00:53:48.000 --> 00:53:55.880
Or if you're looking for something more advanced, check out our new async course that digs into all the different types of async programming you can do in Python.

00:53:55.880 --> 00:54:00.560
And of course, if you're interested in more than one of these, be sure to check out our Everything Bundle.

00:54:00.560 --> 00:54:02.440
It's like a subscription that never expires.

00:54:02.440 --> 00:54:04.740
Be sure to subscribe to the show.

00:54:04.740 --> 00:54:07.160
Open your favorite podcatcher and search for Python.

00:54:07.160 --> 00:54:08.380
We should be right at the top.

00:54:08.380 --> 00:54:19.480
This is your host, Michael Kennedy.

00:54:19.480 --> 00:54:20.980
Thanks so much for listening.

00:54:20.980 --> 00:54:22.040
I really appreciate it.

00:54:22.040 --> 00:54:23.780
Now get out there and write some Python code.

00:54:36.260 --> 00:54:44.160
I really appreciate it.

