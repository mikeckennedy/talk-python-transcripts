WEBVTT

00:00:00.001 --> 00:00:02.820
There have been a lot of changes in the low-level Python space these days.

00:00:02.820 --> 00:00:07.740
The biggest has to be how many projects have rewritten core performance-sensitive

00:00:07.740 --> 00:00:14.760
sections in Rust, or even the wholesale adoption of Rust for newer projects such as UV and Ruff.

00:00:14.760 --> 00:00:19.880
On this episode, we dive into the tools and workflow needed to build these portions of

00:00:19.880 --> 00:00:24.900
Python apps in Rust with David Seddon and Samuel Colvin. This is Talk Python to Me,

00:00:24.900 --> 00:00:28.900
episode 487, recorded November 21st, 2024.

00:00:29.900 --> 00:00:30.900
Are you ready for your host?

00:00:30.900 --> 00:00:31.720
Here he is.

00:00:31.720 --> 00:00:35.180
You're listening to Michael Kennedy on Talk Python to Me.

00:00:35.180 --> 00:00:38.860
Live from Portland, Oregon, and this segment was made with Python.

00:00:38.860 --> 00:00:44.940
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:44.940 --> 00:00:47.160
This is your host, Michael Kennedy.

00:00:47.160 --> 00:00:52.520
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:00:52.520 --> 00:00:58.480
both accounts over at fosstodon.org, and keep up with the show and listen to over nine years of

00:00:58.480 --> 00:01:03.880
episodes at talkpython.fm. If you want to be part of our live episodes, you can find the live

00:01:03.880 --> 00:01:09.580
streams over on YouTube. Subscribe to our YouTube channel over at talkpython.fm/youtube and get

00:01:09.580 --> 00:01:11.240
notified about upcoming shows.

00:01:11.240 --> 00:01:20.500
This episode is sponsored by Posit Connect from the makers of Shiny. Publish, share, and deploy all of your data projects that you're creating using Python.

00:01:20.500 --> 00:01:27.180
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

00:01:27.180 --> 00:01:29.580
Posit Connect supports all of them.

00:01:29.580 --> 00:01:33.940
Try Posit Connect for free by going to talkpython.fm/Posit.

00:01:34.300 --> 00:01:39.580
P-O-S-I-T. And it's brought to you by the Data Citizens Dialogues podcast from Colibra.

00:01:39.580 --> 00:01:46.460
If you're ready for a deeper dive into the latest hot topics and data, listen to an episode at talkpython.fm/citizens.

00:01:46.460 --> 00:01:51.200
Hey everyone, it's the week of Thanksgiving in the United States. You know what that means.

00:01:51.200 --> 00:01:53.400
Black Friday sales galore.

00:01:53.700 --> 00:01:57.000
Of course, we're having Black Friday sales at Talk Python as well.

00:01:57.000 --> 00:02:02.480
All of our courses are on sale from between 18 to 50% off through our Everything Bundle.

00:02:02.480 --> 00:02:09.660
Get huge discounts on the Everything Bundle by visiting talkpython.fm/Black Friday.

00:02:09.660 --> 00:02:14.020
But be sure to hurry. This deal ends next week after Monday.

00:02:14.020 --> 00:02:17.920
So act now if you've been looking at taking a couple of our courses.

00:02:17.920 --> 00:02:20.580
The price is about two courses for the entire library.

00:02:20.580 --> 00:02:22.260
So you probably want to jump on that.

00:02:22.260 --> 00:02:25.160
And thank you to everyone who's taken some of our courses.

00:02:25.160 --> 00:02:26.600
It really helps support the show.

00:02:26.600 --> 00:02:28.200
Let's jump into that interview.

00:02:28.200 --> 00:02:31.000
David, Samuel, welcome to talkpython.fm.

00:02:31.000 --> 00:02:32.380
Thank you very much for having me.

00:02:32.380 --> 00:02:33.320
Thank you for having me.

00:02:33.320 --> 00:02:34.760
Yeah. Good to have you, David.

00:02:34.760 --> 00:02:37.000
And Samuel, it's always good to have you back on the show.

00:02:37.000 --> 00:02:40.360
So we're going to talk about Rust.

00:02:40.360 --> 00:02:49.960
Some really cool experiences that David had building a linter that works on a ridiculous number of different projects and packages.

00:02:50.560 --> 00:02:54.120
And Samuel, Rust is obviously core to Pydantic.

00:02:54.120 --> 00:02:57.560
And I want to talk a bit about Pydantic and how you guys have used Rust as well.

00:02:57.560 --> 00:02:58.360
Should be a good time.

00:02:58.360 --> 00:02:59.660
Yeah. Looking forward to it.

00:02:59.660 --> 00:03:00.660
And thanks for having me on.

00:03:00.660 --> 00:03:02.540
I've been listening to this podcast for years.

00:03:02.540 --> 00:03:05.300
So it's very nice finally to be talking.

00:03:05.300 --> 00:03:06.360
It's a little like open source.

00:03:06.360 --> 00:03:07.600
You get to help create it, you know?

00:03:07.600 --> 00:03:08.140
Exactly.

00:03:09.340 --> 00:03:09.860
All right.

00:03:09.860 --> 00:03:10.980
Let's do quick introductions.

00:03:10.980 --> 00:03:13.960
I know, Samuel, you almost don't need introductions.

00:03:13.960 --> 00:03:15.300
Pydantic is so popular.

00:03:15.300 --> 00:03:18.040
However, I'm sure there's a couple people out there.

00:03:18.040 --> 00:03:21.900
Before I let you introduce yourself and stuff just a tiny, just quickly.

00:03:21.900 --> 00:03:30.760
You have the honor, distinguished or maybe otherwise, of actually participating in the loudest Talk Python episode ever.

00:03:31.120 --> 00:03:35.200
Do you remember that forklift that was driving around behind us?

00:03:35.200 --> 00:03:36.500
It was dystopian, wasn't it?

00:03:36.500 --> 00:03:39.120
It was the end of PyCon two years ago.

00:03:39.120 --> 00:03:40.360
And we started doing the podcast.

00:03:40.360 --> 00:03:43.260
And then they started taking down the PyCon around us.

00:03:43.260 --> 00:03:44.120
And there was this forklift.

00:03:44.120 --> 00:03:47.200
It felt like slight jeopardy, but it was good.

00:03:47.320 --> 00:03:53.740
It certainly was a concentration test to have the forklift driving right behind us, beeping as loud as I could.

00:03:53.740 --> 00:03:54.080
It was amazing.

00:03:54.080 --> 00:03:54.360
All right.

00:03:54.360 --> 00:03:57.780
Tell people about yourself and Pydantic and stuff.

00:03:57.780 --> 00:04:01.600
So I started Pydantic back in 2017 as a side project.

00:04:01.600 --> 00:04:02.800
And I toodled along.

00:04:02.800 --> 00:04:05.940
And then 2021, it somehow, something happened.

00:04:05.940 --> 00:04:08.380
And the rate of downloads just started to increase a lot.

00:04:08.380 --> 00:04:10.440
Started working on it full time in 2022.

00:04:10.440 --> 00:04:13.180
Decided to do this rebuild of the core in Rust.

00:04:13.180 --> 00:04:18.040
Because while I was really proud of how much people were using Pydantic, I wasn't particularly proud of its internals.

00:04:18.040 --> 00:04:26.800
I had done a bit of Rust, a bit of a couple of other projects that wrapped Rust to produce Python packages, but nothing on the scale of Pydantic.

00:04:26.800 --> 00:04:30.620
And then eight months into this three-month project, I was halfway through.

00:04:30.620 --> 00:04:34.200
And Sequoia very kindly got in touch and offered to invest.

00:04:34.200 --> 00:04:36.220
And so I started a company around Pydantic.

00:04:36.220 --> 00:04:40.820
And so, yeah, we released Pydantic V2, the rewrite, middle of last year.

00:04:41.640 --> 00:04:46.040
And, yeah, adoption of Pydantic, as I'm pleased to say, continued to grow.

00:04:46.040 --> 00:04:49.180
We had, I think, 307 million downloads in October.

00:04:49.180 --> 00:04:52.800
And now we're obviously building commercial stuff, Logfire in particular.

00:04:52.800 --> 00:04:55.220
But we also do a bit more Rust in Python.

00:04:55.220 --> 00:05:00.540
So we have Jitter, which is our very fast Rust-based JSON parser, which is available both.

00:05:00.540 --> 00:05:02.700
It's used in Pydantic and is a separate package.

00:05:02.700 --> 00:05:07.980
So, yeah, that's a kind of summary of my interaction with Rust and Python over the last kind of five, six years.

00:05:08.380 --> 00:05:08.780
Amazing.

00:05:08.780 --> 00:05:17.720
Yeah, and it was that move, that pending move or partial move to Rust that actually was the basis of that forklift episode.

00:05:17.720 --> 00:05:20.880
David, hello.

00:05:20.880 --> 00:05:21.600
Hi.

00:05:21.600 --> 00:05:24.800
Yeah, so I am based in London, like Samuel.

00:05:25.080 --> 00:05:30.980
I work on a product called Kraken that is not anything to do with cryptocurrency or gin.

00:05:30.980 --> 00:05:32.220
I think there's a gin.

00:05:32.220 --> 00:05:34.100
Or Git clients.

00:05:34.100 --> 00:05:37.440
It's actually, it came out of a company called Octopus Energy.

00:05:37.440 --> 00:05:41.120
And it's, Octopus Energy is a renewable energy company.

00:05:41.620 --> 00:05:47.460
And Kraken is basically a big Django monolith that we used at Octopus Energy.

00:05:47.460 --> 00:05:49.500
And it worked really well.

00:05:49.500 --> 00:05:55.380
And Octopus Energy over the last eight years has grown to be the second biggest energy company in the UK.

00:05:55.380 --> 00:06:04.360
And so what we've been doing is using Kraken throughout the world in lots of different countries and lots of different energy companies.

00:06:04.360 --> 00:06:07.480
I think the interesting thing about it is it's absolutely massive.

00:06:07.480 --> 00:06:13.200
It's, I just counted it today, eight and a half million lines of code for one Django packet.

00:06:13.200 --> 00:06:13.960
That is nuts.

00:06:13.960 --> 00:06:18.240
I was going to have you elaborate because you said I work on a large Django monolith.

00:06:18.240 --> 00:06:20.240
Like, it's really large.

00:06:20.240 --> 00:06:21.080
That's amazing.

00:06:21.080 --> 00:06:24.100
Sometimes I wonder, has there ever been a bigger one?

00:06:24.100 --> 00:06:25.120
I don't know.

00:06:25.120 --> 00:06:27.320
I should probably ask on Hacker News or something.

00:06:27.320 --> 00:06:27.740
Yeah.

00:06:27.740 --> 00:06:28.500
On the GitHub Notes.

00:06:28.700 --> 00:06:32.540
It's big and it's also, there's quite a lot of people working on it at once.

00:06:32.540 --> 00:06:42.320
There's, like I just looked at last week, there were over 400 authors of pull requests in one week, all merging stuff together onto the same Python packet.

00:06:42.320 --> 00:06:44.460
And you'd think it wouldn't work.

00:06:44.460 --> 00:06:45.820
I would have said it wouldn't work.

00:06:45.820 --> 00:06:49.760
It turns out, actually, you can run an energy company on that basis.

00:06:49.760 --> 00:06:51.120
You're a huge energy company.

00:06:51.120 --> 00:06:52.540
You must have a ton of repositories.

00:06:52.540 --> 00:06:53.360
Yeah, we got one.

00:06:53.360 --> 00:06:57.440
There are some others, to be honest, but mostly it's one big one.

00:06:57.440 --> 00:06:58.440
Can I ask a question?

00:06:58.440 --> 00:07:03.320
Is that continuously deployed or how is that managed in terms of deploys?

00:07:03.320 --> 00:07:07.340
Actually, each energy company, there are nearly 30 energy companies.

00:07:07.340 --> 00:07:10.940
Each energy company gets their own separate installation.

00:07:10.940 --> 00:07:16.960
And every time anyone merges, pretty much, we push it out to all of the energy companies.

00:07:16.960 --> 00:07:22.780
You know, it's on the basis that really, if we break something, then we can fix it quickly as well.

00:07:22.780 --> 00:07:29.120
And also, in the domain of energy, how often do you actually log in to your energy account?

00:07:29.120 --> 00:07:32.260
You know, are you going to be on the phone saying, where's my bill?

00:07:32.260 --> 00:07:33.180
Do you know what I mean?

00:07:33.180 --> 00:07:39.740
We can get away with that kind of thing, which maybe we couldn't do that if it was, I don't know, a payments gateway or something like that.

00:07:39.740 --> 00:07:45.080
Or if you built a package that shipped over PyPI to hundreds of millions of people.

00:07:45.320 --> 00:07:45.600
Yeah.

00:07:45.760 --> 00:07:51.660
We released Pydantic 2.10 yesterday, and we've definitely got quite a few issues back.

00:07:51.660 --> 00:07:53.420
So we definitely break stuff too.

00:07:53.420 --> 00:07:55.240
Don't, for a second thing, we don't break anything.

00:07:55.240 --> 00:07:58.840
We don't mind the things that are unintentionally broken because we can go and fix them.

00:07:58.840 --> 00:08:00.240
It's when we change an API.

00:08:00.500 --> 00:08:08.460
That's the painful thing for us rather than actually, weirdly, bugs are in some sense, like, less severe than, like, getting the wrong API.

00:08:08.460 --> 00:08:13.780
Yeah, that's got to be really tricky to say, you know, we need to add, we need to add a parameter to this function.

00:08:13.780 --> 00:08:19.200
Or, you know, the whole one to two switch, you deprecated quite a few methods and stuff as well.

00:08:19.200 --> 00:08:25.460
In some sense, deprecated methods and parameters are relatively easy because someone's, you know, it's relatively clear to see what's happened.

00:08:25.460 --> 00:08:27.920
It's when it's, like, subtle changes in behavior.

00:08:27.920 --> 00:08:35.460
Like, do you apply an, like, integer constraint before or after a function that wraps the integer validation?

00:08:35.460 --> 00:08:40.120
Like, things like that, if you decide to change it because you're like, well, this is marginally more correct.

00:08:40.120 --> 00:08:43.580
Is it worth making it marginally more correct for a lot of people spending a lot of time?

00:08:43.580 --> 00:08:44.860
Very, very confused.

00:08:44.860 --> 00:08:48.780
That can definitely generate some open issues on the issue tracker.

00:08:49.120 --> 00:08:50.140
Also, the parsing.

00:08:50.140 --> 00:08:52.720
I think you all changed the rules about the parsing, right?

00:08:52.720 --> 00:08:59.780
One of the pieces of magic of Pydantic is you had a list and you said it was a list of integers, but it happened to be strings that could be converted to integers.

00:08:59.780 --> 00:09:01.100
It would just become a list of integers.

00:09:01.100 --> 00:09:06.080
But I feel like you changed the strictness or looseness of that behavior at one point, right?

00:09:06.080 --> 00:09:08.340
Yeah, we made it a little bit more strict in places.

00:09:08.340 --> 00:09:17.940
We said things like you can't coerce an integer to a string because basically the original semantics of Pydantic was like, we'll just call integer on the thing and see if it's an int.

00:09:18.320 --> 00:09:19.880
And that mostly worked.

00:09:19.880 --> 00:09:21.460
We'll call list on something and see if it's a list.

00:09:21.460 --> 00:09:25.880
Problem is with string, you can call string on everything and then you'll get back a string, right?

00:09:25.880 --> 00:09:28.920
So it's no longer a valid test of is it a string to call string on it.

00:09:28.920 --> 00:09:29.840
What time did this happen?

00:09:29.840 --> 00:09:33.160
It happened at angle bracket class datetime dot datetime dot.

00:09:34.160 --> 00:09:38.460
And that's another thing because no one writes their unit tests for the weird edge cases of what's valid.

00:09:38.460 --> 00:09:45.220
But then if you're a bank and one bank is sending you strings for a number or numbers for a string and you change it, like we change how it works.

00:09:45.220 --> 00:09:46.460
That is that's problematic.

00:09:46.460 --> 00:09:48.820
But luckily the banks don't pay us anything in sponsorship.

00:09:48.820 --> 00:09:50.900
So I don't mind breaking it for banks as a rule.

00:09:50.900 --> 00:09:54.820
These are the bootstrapped struggling small businesses.

00:09:54.820 --> 00:09:55.740
They're not ready.

00:09:55.740 --> 00:09:58.940
These banks to have enough money to, you know, support open source.

00:09:58.940 --> 00:10:00.840
We're just trying to persuade them to use LogFire right now.

00:10:00.840 --> 00:10:02.040
So I'll stop being rude about banks.

00:10:02.040 --> 00:10:02.620
Yes.

00:10:02.620 --> 00:10:03.400
No, of course.

00:10:03.400 --> 00:10:06.200
It's well, it's a really tricky balance, right?

00:10:06.200 --> 00:10:09.500
To get those folks to open their checkbooks and pay for it.

00:10:09.540 --> 00:10:15.700
Right. They they don't have charity usually in their bylines or whatever they're supposed to be doing, right?

00:10:15.700 --> 00:10:20.880
Like they but with something like LogFire, they can say, well, here's a service that we can use.

00:10:20.880 --> 00:10:25.980
And by using it, we might be able to support Pydantic and the other things that are important to us.

00:10:25.980 --> 00:10:27.400
So I think that's great.

00:10:27.400 --> 00:10:30.480
You know, tell people just real quickly about LogFire out there.

00:10:30.480 --> 00:10:31.220
Yeah, absolutely.

00:10:31.220 --> 00:10:36.420
So LogFire is an observability platform built, obviously, by the team behind Pydantic.

00:10:36.900 --> 00:10:45.020
And if you go to LogFire along the along the top, the I suppose the two things that make it different from some of the stuff that's come before is LogFire is built on open telemetry.

00:10:45.020 --> 00:10:50.380
So on open standards that mean that, yeah, the rails of that where the data is being transferred are on an open standard.

00:10:50.380 --> 00:10:56.960
And if you decide you didn't want to use the LogFire platform anymore, you can send that data to anything else that supports open telemetry.

00:10:56.960 --> 00:11:10.380
But unlike lots of other companies in our space, instead of using open telemetry as an excuse to abandon the SDK space and just say use the horrible open telemetry SDK directly, we have the LogFire package, which tries to make that super nice and easy to use.

00:11:10.380 --> 00:11:15.160
And then the other big change we have, I think there'll be an example maybe further on down the page.

00:11:15.340 --> 00:11:20.680
Like we maybe maybe there isn't one right there, but we allow you to write SQL directly against your data.

00:11:20.680 --> 00:11:25.320
So instead of having to use kind of ClickOps to go around and do surveys.

00:11:25.320 --> 00:11:29.200
So if you look here, right, you can go and like write SQL to query your data.

00:11:29.200 --> 00:11:38.900
And so there are although we're still early, there are things you can do in LogFire that you can't you cannot and never been able to do in like one of the big incumbents like Datadog because it's just SQL.

00:11:38.900 --> 00:11:43.120
And it's obviously much easier to learn for you, much easier for LLMs to write.

00:11:43.120 --> 00:11:49.520
So we have the like plausible chance in the future that you could basically chat with LogFire and say, what's wrong with my app?

00:11:49.520 --> 00:11:56.120
And the agent can go off and run SQL to investigate things in a way that is much harder if you have your own dialect.

00:11:56.120 --> 00:12:01.220
But allowing people to write SQL against data of the scale is a monumentally difficult challenge.

00:12:01.220 --> 00:12:07.380
And one of the things we struggle with a lot, but we think it's useful enough for developers that we like put the time in.

00:12:07.380 --> 00:12:11.180
So you can write any SQL you want, except for please only do the ones that have indexes.

00:12:11.180 --> 00:12:13.320
So our new database is data fusion.

00:12:13.320 --> 00:12:14.480
So there are no indexes.

00:12:14.600 --> 00:12:21.180
But yeah, if you do, there are queries you can do now that just like eat memory and we have to find ways around them.

00:12:21.180 --> 00:12:29.480
And that's actually the hardest bit is like whether intentionally or not, there are people, you know, there are SQL you can write, which is enormously like heavy to go and compute.

00:12:29.480 --> 00:12:35.620
And so we have to be able to find ways to like process that without taking down other customers, I suppose, is the point.

00:12:35.620 --> 00:12:37.840
You don't want to do a denial of service on yourself.

00:12:38.060 --> 00:12:45.360
Right. I mean, the definition of DOS is that like the effort required to DOS is significantly lower than the effort required to process it.

00:12:45.360 --> 00:12:47.940
Right. And writing SQL is the ultimate example of that.

00:12:47.940 --> 00:12:50.000
Yeah, it absolutely is.

00:12:50.000 --> 00:12:58.500
OK, well, that's a really interesting idea to have SQL there rather than like, let's just click around our UI until we get an answer and those sorts of things.

00:12:58.500 --> 00:12:59.960
Or you've got some dashboards on that page.

00:12:59.960 --> 00:13:05.860
But the idea is like, sure, we'll go and give you a nice dashboard for HTTP traffic and like response codes.

00:13:05.860 --> 00:13:07.100
I think it's the next one down.

00:13:07.100 --> 00:13:12.560
But if you want to go and edit that, like the point is that you can basically next one after that.

00:13:12.560 --> 00:13:17.400
It's the point is you can go and customize that however you like by just editing the SQL if you so wish.

00:13:17.400 --> 00:13:19.360
So it's like it's trying to same with alert.

00:13:19.360 --> 00:13:21.880
So we have, I guess you would say century style alerting.

00:13:21.880 --> 00:13:25.000
But again, that's all configurable because in the end, it's just SQL that you can go and edit.

00:13:25.240 --> 00:13:32.800
Congratulations. I know many people were curious about when they heard that, hey, Pydantic starting a company, they have funding.

00:13:32.800 --> 00:13:35.680
It's like, what are they going to exactly going to do with that?

00:13:35.680 --> 00:13:40.360
And maybe a lot of people were worried just, hey, it now costs money to just use the library.

00:13:40.360 --> 00:13:40.660
Right.

00:13:40.660 --> 00:13:47.800
I don't think anyone ever thought it would have been a good idea to literally have like Pydantic Pro where you had to have some API key to install Pydantic.

00:13:47.800 --> 00:13:54.360
But it could definitely have been what most open source companies do is they have like open source project as a service.

00:13:54.360 --> 00:13:58.480
And then they start, if not taking out features, then adding new features to the paid version.

00:13:58.480 --> 00:14:03.860
And I was super keen that Pydantic continued to be successful as an open source project.

00:14:03.860 --> 00:14:09.600
And so we did the slightly weird thing about building something which is in a different space from what we're known for.

00:14:09.600 --> 00:14:11.040
And that definitely has its challenges.

00:14:11.040 --> 00:14:13.680
But I think it's overall, I think it's the right decision.

00:14:13.680 --> 00:14:14.080
Awesome.

00:14:14.340 --> 00:14:15.200
Well, congratulations.

00:14:15.200 --> 00:14:17.460
Beautiful looking project service here and so on.

00:14:17.460 --> 00:14:22.200
And I think maybe one of the big pieces of news here, and that's not the one, although that is awesome.

00:14:22.200 --> 00:14:23.800
That's where we're going.

00:14:23.800 --> 00:14:25.140
Is this jitter?

00:14:25.140 --> 00:14:25.880
What is this jitter?

00:14:25.880 --> 00:14:28.120
David, are you familiar with this jitter?

00:14:28.120 --> 00:14:29.200
I've heard of it.

00:14:29.200 --> 00:14:29.740
Okay.

00:14:29.740 --> 00:14:30.200
Yeah.

00:14:30.200 --> 00:14:32.400
Because parsing JSON is super important.

00:14:32.400 --> 00:14:33.400
Tell us about this.

00:14:33.400 --> 00:14:35.660
So parsing JSON is a big thing.

00:14:35.660 --> 00:14:44.140
And when I first built Pydantic version 2 with the Rust core, we're using Serdi, which is the kind of default parsing library in Rust.

00:14:44.480 --> 00:14:51.800
The problem is that Serdi wants to parse the entire JSON object before it returns you some representation of that.

00:14:51.800 --> 00:14:57.040
And jitter came out of this idea that we could do parsing as we do validation.

00:14:57.040 --> 00:15:03.040
So if you have, imagine you have a list of integers, you, instead of what you would traditionally do is you would parse the JSON,

00:15:03.040 --> 00:15:10.040
you would allocate some vector of all of the values in that list, each of which would have to be itself a like enum of here are the different types you might get in JSON,

00:15:10.040 --> 00:15:11.360
because you don't know what it's going to be up front.

00:15:11.360 --> 00:15:14.840
And then once you finish doing that, you can then go and do validation on that.

00:15:14.840 --> 00:15:18.480
And jitter, the idea is it's an iterative JSON parser, hence the name.

00:15:18.740 --> 00:15:27.600
You can effectively get, if you think of it in Python parlance, as like an iterable that gives you back each individual element of the JSON as you go along.

00:15:27.600 --> 00:15:35.320
The truth is right now inside Pydantic core, we're still using this JSON value, which is jitter's variant of doing the whole parsing first.

00:15:35.320 --> 00:15:38.460
There are a few optimizations that we get to get away with.

00:15:38.460 --> 00:15:40.760
So there are some really neat things in JSON.

00:15:40.760 --> 00:15:50.200
Like if your strings, for example, John Doe, you're showing on the screen there, does not include any escape sequences like backslash N or Unicode sequences,

00:15:50.200 --> 00:15:58.160
then you can parse a pointer to that range of the underlying JSON object as a string instead of having to allocate that string.

00:15:58.160 --> 00:16:00.480
So we do some like clever optimizations like that.

00:16:00.480 --> 00:16:09.200
But the plan in a future version of Pydantic, either as a opt-in feature in v2 or as v3, is to be able to do the iterative parsing.

00:16:09.200 --> 00:16:17.160
What's crazy about jitter is, well, one, once we started work on this, we've actually got to the point where jitter is full on faster than CERDI in any use case,

00:16:17.160 --> 00:16:18.960
even if you're not doing the iterative thing.

00:16:18.960 --> 00:16:27.780
But also this iterative JSON parsing thing is exactly what you want when you want to allow people to query JSON in a way like JSONB in Postgres.

00:16:27.780 --> 00:16:34.680
And so we went and used jitter to implement JSON querying inside DataFusion when we moved our database to DataFusion.

00:16:34.680 --> 00:16:40.480
And it was just like very luckily, yeah, it happens to be exactly the right concept you need for like for querying JSON,

00:16:40.480 --> 00:16:45.040
where you want to iterate over looking for the like string foo and then stop as soon as you find it.

00:16:45.040 --> 00:16:49.380
So the code samples you got on the repo here, got a lot of semicolons in them.

00:16:49.380 --> 00:16:52.040
Is there a, is it interoperable with Python as well?

00:16:52.080 --> 00:16:53.700
Is it just a Rust level thing?

00:16:53.700 --> 00:16:56.380
If you go up actually, it's a, it's a, this is a monorepo.

00:16:56.380 --> 00:17:02.180
So if you go up into source, into crates, which is, so this is, you have a bunch of different crates in here.

00:17:02.180 --> 00:17:07.680
But if you look at jitter Python, and I think if you go down, you'll see an example of calling jitter directly from Python.

00:17:07.680 --> 00:17:08.060
Awesome.

00:17:08.200 --> 00:17:13.860
The reason we released this as a Python package was a large AI company who I don't know if they wanted me to name them,

00:17:13.860 --> 00:17:18.920
basically were using Pydantic V1 so heavily, but they needed some of the functionality of jitter.

00:17:18.920 --> 00:17:22.940
And so they basically begged us to release this as a separate package so that they could,

00:17:22.940 --> 00:17:26.480
they could use jitter themselves before they upgraded to Pydantic V2.

00:17:26.480 --> 00:17:28.900
In fact, the OpenAI SDK uses jitter.

00:17:28.900 --> 00:17:31.220
So I think that is public information who it might be.

00:17:33.120 --> 00:17:41.080
This portion of Talk Python to Me is brought to you by Posit, the makers of Shiny, formerly RStudio, and especially Shiny for Python.

00:17:41.080 --> 00:17:43.000
Let me ask you a question.

00:17:43.000 --> 00:17:44.700
Are you building awesome things?

00:17:44.700 --> 00:17:45.760
Of course you are.

00:17:45.760 --> 00:17:47.320
You're a developer or a data scientist.

00:17:47.320 --> 00:17:48.240
That's what we do.

00:17:48.240 --> 00:17:50.280
And you should check out Posit Connect.

00:17:50.280 --> 00:17:57.240
Posit Connect is a way for you to publish, share, and deploy all the data products that you're building using Python.

00:17:57.240 --> 00:18:00.440
People ask me the same question all the time.

00:18:00.440 --> 00:18:03.600
Michael, I have some cool data science project or notebook that I built.

00:18:03.600 --> 00:18:06.900
How do I share it with my users, stakeholders, teammates?

00:18:06.900 --> 00:18:11.700
Do I need to learn FastAPI or Flask or maybe Vue or React.js?

00:18:11.700 --> 00:18:12.920
Hold on now.

00:18:12.920 --> 00:18:17.680
Those are cool technologies, and I'm sure you'd benefit from them, but maybe stay focused on the data project?

00:18:17.680 --> 00:18:20.180
Let Posit Connect handle that side of things.

00:18:20.180 --> 00:18:24.920
With Posit Connect, you can rapidly and securely deploy the things you build in Python.

00:18:25.280 --> 00:18:31.360
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, ports, dashboards, and APIs.

00:18:31.360 --> 00:18:33.660
Posit Connect supports all of them.

00:18:33.660 --> 00:18:39.500
And Posit Connect comes with all the bells and whistles to satisfy IT and other enterprise requirements.

00:18:39.500 --> 00:18:43.880
Make deployment the easiest step in your workflow with Posit Connect.

00:18:44.120 --> 00:18:50.000
For a limited time, you can try Posit Connect for free for three months by going to talkpython.fm/posit.

00:18:50.000 --> 00:18:53.640
That's talkpython.fm/P-O-S-I-T.

00:18:53.640 --> 00:18:55.520
The link is in your podcast player show notes.

00:18:55.520 --> 00:18:58.780
Thank you to the team at Posit for supporting Talk Python.

00:19:00.780 --> 00:19:18.920
The other interesting thing that came out, which, again, I'm ashamed to say I had no idea would be useful, this idea of iteratively parsing JSON until you stop effectively turns out to be incredibly helpful in LLMs, where, as you see on screen here, you can basically parse an incomplete JSON string.

00:19:18.920 --> 00:19:28.500
And obviously, because LLMs stream you the response, you can use this to effectively do validation as you receive structured responses.

00:19:28.500 --> 00:19:32.220
Work on a JSON stream instead of a JSON response.

00:19:32.220 --> 00:19:37.220
I've been surprised by how, like, the legs that this has had, which I wasn't expecting when we first started it.

00:19:37.220 --> 00:19:47.600
But yeah, the nice bit is it's all the input, the actual JSON parsing is Rust, but then we have the logic to, yeah, basically access that from Python, both in this package and in pydantic-core.

00:19:47.600 --> 00:19:52.600
Well, you sent me over to this cargo section, or the crate section, rather.

00:19:52.600 --> 00:19:58.720
And looking here, I see the cargo.toml, pyproject.toml, some source.

00:19:58.720 --> 00:20:02.680
I think this might be, in the source, we've got some Rust.

00:20:02.680 --> 00:20:09.140
I think that this might be, David, a good way to start leading into working with Rust.

00:20:09.140 --> 00:20:13.980
And, you know, this is kind of the destination of your whole presentation you gave at PyCon Italy, right?

00:20:13.980 --> 00:20:15.860
We sort of alluded to it already.

00:20:16.280 --> 00:20:20.460
But Python and Rust can interoperate, which is an amazing fact.

00:20:20.460 --> 00:20:27.720
I think it's so easy to think, oh, well, within a particular application, you know, you're stuck with the programming language that you've picked.

00:20:27.900 --> 00:20:36.400
But actually, Python was really designed originally, from what I understand, to be a kind of glue language between different C programs and things like that.

00:20:36.480 --> 00:20:49.280
So actually, what you can do is you can use that design to use Rust to compile what are called extension modules, which are used in lots of other bits of Python, say, NumPy or something like that.

00:20:49.440 --> 00:20:52.680
Or even maybe less obvious ones like SQLAlchemy and other places.

00:20:52.680 --> 00:20:56.940
There's optional speedup C extension type things, right?

00:20:56.940 --> 00:20:57.800
Yeah, absolutely.

00:20:57.800 --> 00:20:59.360
And in the standard library, of course.

00:21:00.000 --> 00:21:04.600
But you're not writing C or you're not writing, I think NumPy might even have Fortran.

00:21:04.600 --> 00:21:05.900
You're writing Rust.

00:21:05.900 --> 00:21:12.220
You're ending up with something that's the same as you might have done with a different lower level language.

00:21:12.220 --> 00:21:20.640
And that allows you to use Python for all of the nice stuff like domain modeling and that thing that we're all familiar with.

00:21:20.640 --> 00:21:23.220
And the reason we like Python is we can be very productive with it.

00:21:23.220 --> 00:21:28.220
But just occasionally, you hit something with Python where it's basically slow.

00:21:28.220 --> 00:21:32.660
There's a high level language there and those abstractions are coming at a cost.

00:21:32.660 --> 00:21:35.060
You know, we talk about the GIL as well.

00:21:35.060 --> 00:21:39.500
You know, the GIL gets in the way of using all of the CPUs on our machine.

00:21:39.500 --> 00:21:42.120
But that's not the case for extension modules.

00:21:42.200 --> 00:21:44.280
They can leave the GIL behind if you want.

00:21:44.280 --> 00:21:52.120
So you can actually, by writing these extension modules, get more out of Python than you might have thought.

00:21:52.120 --> 00:21:58.860
And Rust is a pretty new language that's learned a lot of lessons from older languages.

00:21:58.860 --> 00:22:01.820
And it's, I think it's really lovely.

00:22:01.820 --> 00:22:04.560
You feel like you're in the presence of greatness.

00:22:04.560 --> 00:22:08.500
I want to ask both of you this question before we get too far down this path.

00:22:08.620 --> 00:22:15.560
Python often is referred to as CPython because the runtime, the core is all built in C, not Python.

00:22:15.560 --> 00:22:16.060
Right.

00:22:16.060 --> 00:22:21.420
And the original interop story is around C extensions and CFFI and those kinds of things.

00:22:21.820 --> 00:22:28.800
So why not just pick C for Pydantic or for your linter, David?

00:22:28.800 --> 00:22:30.900
You know, everyone else is doing it.

00:22:30.900 --> 00:22:31.940
They had been doing it.

00:22:31.940 --> 00:22:33.540
Maybe sometimes it would be the right answer.

00:22:33.540 --> 00:22:36.480
But Rust is offering something very different.

00:22:36.700 --> 00:22:40.020
It's offering like a really nice developer ecosystem.

00:22:40.020 --> 00:22:42.360
All the tooling is brilliant.

00:22:42.360 --> 00:22:46.440
And also, I think security is a big thing.

00:22:46.440 --> 00:22:50.500
So many security problems come from like mismanagement of pointers.

00:22:50.500 --> 00:23:00.640
And Rust is designed so that the compiler won't let you make a certain kind of mistake that happens all over the place in C and C++.

00:23:01.100 --> 00:23:02.040
I don't know if you can say more about that.

00:23:02.040 --> 00:23:03.200
I'm putting it more simply than that.

00:23:03.200 --> 00:23:04.760
I'm not clever enough to write C.

00:23:04.760 --> 00:23:08.560
That's a void pointer pointer.

00:23:08.560 --> 00:23:09.460
What are we doing here?

00:23:09.460 --> 00:23:15.660
Good way of looking at it is that you can have the unsafe mode in Rust where you effectively lose those constraints.

00:23:15.660 --> 00:23:18.940
And sometimes there are the occasional place where you need to use it.

00:23:18.940 --> 00:23:32.140
When we do that inside Pydantic core, myself or David Hewitt, who's a much better Rust developer than I am, we agonize for genuinely minutes at a time over how exact, whether or not it is really safe to write that one line of code as unsafe.

00:23:32.140 --> 00:23:35.780
And whether there was any possible case in which it could lead to problems.

00:23:35.780 --> 00:23:39.200
If you write an app in C, every single line is unsafe.

00:23:39.200 --> 00:23:40.140
And if you write a...

00:23:40.140 --> 00:23:45.340
You're agonizing even over just a string, like a sprint F equivalent.

00:23:45.580 --> 00:23:51.880
And it doesn't have to be 8.5 million lines of code for it to be incredibly hard to go through every single line of that.

00:23:51.880 --> 00:23:54.980
So I forget there's like 40,000 lines of code in Pydantic core.

00:23:54.980 --> 00:24:03.780
It is inconceivable that we could have written that in C and have anywhere near the confidence we have with it written in Rust that it was memory safe.

00:24:03.780 --> 00:24:07.940
We have had one memory safety issue reported in Pydantic core.

00:24:08.340 --> 00:24:19.200
And it was a side effect of something deep in PyO3, which in turn was a result of like greenlit doing something crazy that technically the guild didn't think you could do.

00:24:19.200 --> 00:24:21.980
I mean, that's the level of complexity.

00:24:21.980 --> 00:24:24.880
Another example is Jitter, which I showed you.

00:24:24.880 --> 00:24:27.300
We released Jitter a year ago now.

00:24:27.440 --> 00:24:31.680
It is the most downloaded JSON parser in Python other than the one in the standard library.

00:24:31.680 --> 00:24:37.060
No one has ever reported a bug in it in terms of it parsing stuff incorrectly, except for impartial mode, I think.

00:24:37.060 --> 00:24:39.120
Now, I said that someone will probably go and find one.

00:24:39.120 --> 00:24:40.580
But like it has been...

00:24:40.580 --> 00:24:41.600
That just wouldn't happen in Python.

00:24:41.600 --> 00:24:42.840
You could not write...

00:24:42.840 --> 00:24:44.040
That reliable...

00:24:44.040 --> 00:24:51.720
One of the ways it achieves this is by like really stopping you doing all the stuff that you would expect to be able to do.

00:24:51.720 --> 00:25:03.580
Whenever I sort of tell someone about Rust, I say, you know, if you have a string in Rust and you assign it to a variable, let's say X, and then you like store that X in Y.

00:25:03.580 --> 00:25:04.980
So you do Y equals X.

00:25:04.980 --> 00:25:08.080
Then you can't use X anymore because it's gone.

00:25:08.080 --> 00:25:10.580
That seems very strange.

00:25:10.880 --> 00:25:18.180
You know, and it seems strange maybe as Python developers because we don't actually hardly ever, maybe never need to think about memory safety.

00:25:18.180 --> 00:25:19.580
You know, we've got that luxury.

00:25:19.580 --> 00:25:22.960
But once you go down lower level, you are starting to.

00:25:22.960 --> 00:25:29.260
And what's going on there with the kind of you can't have X and Y both pointing to that string.

00:25:29.260 --> 00:25:34.840
I mean, you can if you copy that memory so that there's then separate bits of memory in X and Y.

00:25:34.840 --> 00:25:39.960
But it's kind of making you think in detail about where is the memory for this program?

00:25:40.280 --> 00:25:40.900
Ownership, right?

00:25:40.900 --> 00:25:42.760
The ownership of who owns this.

00:25:42.760 --> 00:25:44.880
I can give you another good practical example.

00:25:44.880 --> 00:25:58.000
So I was saying earlier in the jitter case, we have this point where some strings, many strings, you can, instead of having to copy the whole of the string out of the chunk of data within the original input of JSON,

00:25:58.000 --> 00:26:02.440
you can literally refer to that slice of data as a pointer.

00:26:02.440 --> 00:26:04.360
Literally say this is this is the string itself.

00:26:04.360 --> 00:26:05.080
You don't have to copy.

00:26:05.080 --> 00:26:11.260
But that means the type you get back for when you parse a string in jitter is what is called a cow in Rust.

00:26:11.260 --> 00:26:17.140
And it is either an owned string, e.g. when you've copied it, or it's a reference to the underlying chunk of the array.

00:26:17.140 --> 00:26:28.280
And so that gets quite difficult when you're actually writing code with that because you can't go and access that string after you've validated, after you've parsed the next token, because in theory that could have now changed.

00:26:28.280 --> 00:26:34.920
If you were writing that in C, you'd have to basically manually keep track of am I accessing that cow in the right place?

00:26:34.920 --> 00:26:39.400
Whereas in Rust, well, you wouldn't have a cow in C, but you could presumably have some similar construct.

00:26:39.400 --> 00:26:41.060
Rust basically takes care of that.

00:26:41.060 --> 00:26:52.440
As soon as you go and do another piece of validation, it immediately says, no, no, you can't even access that previous cow because the lifetime of it has now been used when you've called into the parser to get the next token.

00:26:52.440 --> 00:26:56.360
And so it's a very neat, it basically stops you from having to think about that.

00:26:56.440 --> 00:27:05.000
And that means you can actually do not more unsafe, but more complex things, knowing that the borrow checker is going to save you in the end.

00:27:05.000 --> 00:27:05.900
You can try and do something.

00:27:05.900 --> 00:27:07.800
And if it doesn't work, the borrow checker will say it's not possible.

00:27:07.800 --> 00:27:14.720
And if the borrow checker says it is possible, you're safe to access that reference to a string that you passed like 50 lines of code higher up.

00:27:14.720 --> 00:27:17.260
It sounds like a paradigm shift, but also super valuable.

00:27:17.260 --> 00:27:21.660
So I know primarily Python people are listening, so this word might not make any sense.

00:27:21.660 --> 00:27:25.940
But is this a compile time check or is this a runtime check?

00:27:26.300 --> 00:27:28.660
We don't really think about compiling much in Python.

00:27:28.660 --> 00:27:37.220
We don't think about it, but you can think of import time when you do different stuff or you think about static typing when you go and run Pyright over your code.

00:27:37.220 --> 00:27:40.180
And that is very similar in some ways to compile time.

00:27:40.180 --> 00:27:42.260
It's also one of the big disadvantages of Rust.

00:27:42.260 --> 00:27:44.320
I mean, people think Rust is faster than Python.

00:27:44.320 --> 00:27:48.260
In many cases, if you write your script, it's a lot faster to run it in Python than it is in Rust.

00:27:48.260 --> 00:27:54.660
Because it'll take two seconds to run in Rust or in Python or a few hundred milliseconds to run in Python and 10 seconds to compile in Rust.

00:27:54.660 --> 00:28:00.840
So it is not universally the case that the development cycle is faster in Rust.

00:28:00.900 --> 00:28:02.800
It depends how many times you run the code, right?

00:28:02.800 --> 00:28:09.140
If you're going to run it once or twice and you've got to create it to run it, well, you know, maybe it took you 10 minutes versus 20 minutes.

00:28:09.140 --> 00:28:23.300
And it speaks to another of the great powers of the Python ecosystem and of PyPI that we, the maintainers of Python packages built in Rust, can take care of compiling that Rust once, distribute all of the binaries.

00:28:23.300 --> 00:28:25.800
And then when people go and install it, we don't have to compile it.

00:28:25.800 --> 00:28:30.360
If you were using most other, if you were using cargo, you would have to take care.

00:28:30.360 --> 00:28:38.500
I mean, putting the controversy over Surdi to one side for a minute, you would have to take care of compiling that code yourself every time you wanted to go and go and use it.

00:28:38.580 --> 00:28:46.820
Whereas ActionPyPI does an amazing job of distributing compiled Rust for virtually every ecosystem, every architecture, and it just working when you install it.

00:28:46.820 --> 00:28:47.200
Absolutely.

00:28:47.200 --> 00:28:57.420
Something I just wanted to say about the memory management, like it is a compile time, but actually it also, you can also use reference counting and things like that.

00:28:57.420 --> 00:28:58.440
It's just opt-in.

00:28:58.440 --> 00:29:04.200
So there are lots of tools for allowing you to do runtime checking of things.

00:29:04.200 --> 00:29:05.880
And sometimes that's what you have to do.

00:29:05.880 --> 00:29:07.920
You're like, oh, I can't really do this.

00:29:08.020 --> 00:29:12.160
It's just using stuff that's worked out before the program even runs.

00:29:12.160 --> 00:29:14.400
I do need to do it at runtime, but it's fine.

00:29:14.400 --> 00:29:16.700
I can do that for this particular data type.

00:29:16.700 --> 00:29:20.520
And then there's an API to do it and it will come with other trade-offs.

00:29:20.520 --> 00:29:29.260
It's giving you that control, but it's giving you control over things which, if you've only ever programmed in Python, which to be honest, pretty much, I mean, I used to do PHP a bit.

00:29:29.260 --> 00:29:31.640
My mind is soaked up in Python.

00:29:31.640 --> 00:29:36.360
And coming to Rust, it's like, oh, this is a completely different way of thinking.

00:29:36.360 --> 00:29:38.820
It's like the red pill in the matrix.

00:29:38.820 --> 00:29:40.320
You're like, what is this?

00:29:40.320 --> 00:29:41.120
Yeah.

00:29:41.440 --> 00:29:42.440
It's nice, though.

00:29:42.440 --> 00:29:44.400
It's hard.

00:29:44.400 --> 00:29:45.300
I'm not going to lie.

00:29:45.300 --> 00:29:47.300
I feel very confused a lot of the time.

00:29:47.560 --> 00:29:50.020
I suppose this is a time for the obligatory.

00:29:50.020 --> 00:29:56.600
The White House recommends the future software should be written in memory stuff languages such as Rust and Python.

00:29:56.600 --> 00:29:59.580
So, right, that's always nice to have around to think about.

00:29:59.740 --> 00:30:05.860
Whether or not that's an argument in favor of Rust or not, depending on your take on a particular White House, is another question altogether.

00:30:05.860 --> 00:30:06.960
But it's definitely a data point.

00:30:06.960 --> 00:30:09.920
I will draw your attention to the date of this.

00:30:09.920 --> 00:30:16.880
I'm interested to see what the new leadership recommends next year.

00:30:16.880 --> 00:30:19.500
We'll see if they're like, assembly all the way.

00:30:19.500 --> 00:30:20.120
We've decided.

00:30:20.120 --> 00:30:20.800
No, okay.

00:30:20.800 --> 00:30:24.160
Let's carry on with your story, David.

00:30:24.160 --> 00:30:29.320
So, you wrote this thing called an import linter, which is kind of unique.

00:30:29.320 --> 00:30:31.580
There's lots of linters in Python, right?

00:30:31.580 --> 00:30:32.720
There's PyFlake.

00:30:32.720 --> 00:30:33.740
There's Ruff.

00:30:33.740 --> 00:30:36.540
Another Rust success story, I suppose.

00:30:36.540 --> 00:30:39.720
But this one checks more architecturally, right?

00:30:39.720 --> 00:30:43.920
And you want to use this on your small little repo that you all are running over there.

00:30:43.920 --> 00:30:45.520
Tell us about that story.

00:30:45.520 --> 00:30:46.560
I wrote it for Kraken.

00:30:46.560 --> 00:30:50.980
But actually, I had the idea for it in a previous company.

00:30:51.200 --> 00:30:55.220
You know, it was still a complex monolith, but nowhere near as big.

00:30:55.220 --> 00:31:00.820
And to be honest, I find even in quite small projects with just a handful of files, it's

00:31:00.820 --> 00:31:06.180
still useful to think about the architecture of those files.

00:31:06.180 --> 00:31:11.660
And I think, for me, architecture is ultimately about dependencies.

00:31:12.540 --> 00:31:18.740
And something that Python lets you do, which I don't think is very good, is that you can

00:31:18.740 --> 00:31:25.020
end up with lots of cross dependencies between different modules and packages within a particular

00:31:25.020 --> 00:31:26.340
Python project.

00:31:26.340 --> 00:31:30.580
So, for example, you know, I mean, we know that sometimes you get circular import errors,

00:31:30.580 --> 00:31:33.320
but this is something a bit wider than that.

00:31:33.320 --> 00:31:40.080
Like, possibly, if you've got two sibling sub packages, you might have one module which imports

00:31:40.080 --> 00:31:44.100
from something in one, in the other sibling package.

00:31:44.100 --> 00:31:47.680
And then there'd be, like, other modules that import the other way.

00:31:47.680 --> 00:31:50.580
And it won't stop Python from loading up.

00:31:50.580 --> 00:31:55.200
But there's a sort of, there's a circular dependency conceptually between those two packages.

00:31:55.200 --> 00:31:56.000
They're tightly coupled.

00:31:56.000 --> 00:32:01.020
And, you know, this is just one example of the kind of architectural rule you might want

00:32:01.020 --> 00:32:07.440
to impose on a project to say, well, actually, I want there to be a dependency only one way.

00:32:07.440 --> 00:32:11.140
I want one of those packages to be kind of lower level and one of them to be higher level.

00:32:11.140 --> 00:32:14.360
Or maybe you'd have, like, five packages that are all siblings.

00:32:14.360 --> 00:32:19.560
And, you know, you call this layer, really, but where you maybe, you know, say, yeah, this

00:32:19.560 --> 00:32:23.240
can import all the ones below it, but nothing can import the ones above it.

00:32:23.240 --> 00:32:25.500
And you sort of think of them in a sort of stack.

00:32:25.500 --> 00:32:26.380
Here are the details.

00:32:26.380 --> 00:32:27.880
Here's the public interface.

00:32:27.880 --> 00:32:29.660
And then things use the public interface.

00:32:29.660 --> 00:32:32.200
They shouldn't reach down below and vice versa.

00:32:32.200 --> 00:32:32.560
Yeah.

00:32:32.560 --> 00:32:34.760
That's certainly one thing you can do with it.

00:32:34.760 --> 00:32:40.060
It's mostly focused on controlling dependencies between packages as a whole.

00:32:40.060 --> 00:32:42.300
You can also do it for individual modules.

00:32:42.300 --> 00:32:47.440
But so what it does is it uses imports as the proxy for a dependency.

00:32:47.440 --> 00:32:52.800
So it will statically analyze all of the imports in your module.

00:32:53.020 --> 00:32:55.820
And then it will build a directed graph.

00:32:55.980 --> 00:33:05.640
So you can then think of your module, think of your package as, like, every module is a node and a graph with arrows pointing between all of them.

00:33:05.640 --> 00:33:06.900
And the arrows are the imports.

00:33:06.900 --> 00:33:09.460
Sometimes you call them edges or whatever.

00:33:09.880 --> 00:33:20.140
What import linter allows you to do is to write contracts that are just in YAML or TOML, which just say, all right, these are the rules I want you to check when you run the linter.

00:33:20.660 --> 00:33:25.760
And it will then you can put it in CI and it will fail if someone adds an import the wrong way.

00:33:25.760 --> 00:33:37.780
And it's fascinating to see, like, if you have an idea for an architecture and then you put an import linter contract on and then discover all the places where you're breaking it, they're almost always quite interesting, interesting things.

00:33:37.780 --> 00:33:40.180
And you're like, yeah, actually, this is a bit of a problem.

00:33:40.180 --> 00:33:43.220
Like, it needs a bit of thought to kind of untangle it.

00:33:43.340 --> 00:33:48.760
It is genuinely, you know, some conceptual tangling that would simplify things if we didn't do it.

00:33:48.760 --> 00:33:51.660
Yeah, it's kind of a higher order code smell.

00:33:51.660 --> 00:33:54.340
People are familiar with this idea from refactoring a code smell.

00:33:54.340 --> 00:33:58.400
Like, it's not wrong in that it won't run, but you kind of turn your nose up at it.

00:33:58.400 --> 00:34:00.060
You go, oh, right.

00:34:00.060 --> 00:34:03.340
And this is that, but not at a, oh, it takes too many parameters.

00:34:03.340 --> 00:34:05.500
But, like, why is it all tied together like this?

00:34:05.500 --> 00:34:06.980
Can we think about it better, right?

00:34:06.980 --> 00:34:07.760
Yeah, exactly.

00:34:09.940 --> 00:34:14.380
This portion of Talk Python to Me is brought to you by the Data Citizens Dialogues podcast.

00:34:14.380 --> 00:34:25.200
If you're ready for a deeper dive into the latest hot topics in data, you need to listen to the Data Citizens Dialogues podcast, brought to you by Colibra, the leader in data intelligence.

00:34:25.200 --> 00:34:31.180
In every episode of Data Citizens Dialogues, industry leaders unpack data's impact on the world.

00:34:31.300 --> 00:34:40.740
From big picture questions like AI governance and data sharing to more nuanced questions like, how do we balance offense and defense in data management?

00:34:40.740 --> 00:34:46.040
You'll hear firsthand insights about the data conversations affecting all kinds of industries.

00:34:46.280 --> 00:34:58.460
With guests sharing unique stories from some of the world's largest companies, such as Adobe, Fidelity, Deloitte, Hewlett-Packard, McDonald's, and even the United States Coast Guard, you'll get an amazing look inside how these organizations handle their data.

00:34:58.460 --> 00:35:03.220
My favorite episode is Solving Data Discovery with a Self-Service Approach.

00:35:03.220 --> 00:35:09.120
It's an interesting look inside creating a single source of truth for data inside an online university.

00:35:09.120 --> 00:35:13.400
Check them out and try an episode for yourself at talkpython.fm/citizens.

00:35:13.580 --> 00:35:16.180
That's talkpython.fm/citizens.

00:35:16.180 --> 00:35:18.480
The link is in your podcast player's show notes.

00:35:18.480 --> 00:35:22.040
Thank you to Data Citizens Dialogues podcast for supporting the show.

00:35:22.040 --> 00:35:29.160
You know, and you can do things like, say, all of these modules are independent, say, so they don't import anything from each other.

00:35:29.160 --> 00:35:36.000
I mean, this is like just my whole mentality for architecting Python packages, and I find it works really well.

00:35:36.000 --> 00:35:46.800
And I think the fact that we've got these rules in place is probably a big reason why we're still able to have a thousand PRs a week all happening in different time zones without that many faults.

00:35:46.800 --> 00:35:49.020
Because we've got, we've architected it.

00:35:49.020 --> 00:35:55.180
So say we know that there aren't any imports between, say, two energy companies or between two territories.

00:35:55.600 --> 00:36:00.060
You've got to install your competitors version as well to use yours.

00:36:00.480 --> 00:36:04.860
It's allowing us to think about things as being more independent.

00:36:04.860 --> 00:36:14.940
And so like someone can make a change in, say, Spain, and it's not going to break something in Australia because you're pretty confident because they aren't importing anything from there.

00:36:14.940 --> 00:36:25.960
Does that mean, in theory, if you've got this, that you could use this within, for example, CI to only run unit tests, systems that have changed or direct descendants of that package?

00:36:25.960 --> 00:36:30.140
Because I presume we do do that because we've got a lot of money on CI.

00:36:30.140 --> 00:36:34.920
And so we've had to invest a lot of money to like figure out how do we narrow down the tests.

00:36:34.920 --> 00:36:35.940
So, yeah.

00:36:35.940 --> 00:36:36.700
Yeah, that's awesome.

00:36:36.700 --> 00:36:37.620
That's a great observation.

00:36:37.620 --> 00:36:43.840
This is all based on an underlying library called Grimp, which is, I kind of broke the libraries up.

00:36:43.840 --> 00:36:47.460
It's a little bit like what you did, Samuel, with Pydantic and Pydantic Core.

00:36:47.620 --> 00:36:55.660
So import linter is pure Python, but it has a dependency, which is Grimp, which is, I mean, it's got Python and Rust in at the moment.

00:36:55.660 --> 00:37:01.400
But that is just a Python API for building a graph.

00:37:01.400 --> 00:37:02.900
And then you can explore the graph.

00:37:02.900 --> 00:37:09.480
And you can do things like it's really quite a useful tool if you're just interested to know something about code base.

00:37:09.480 --> 00:37:19.480
You know, you can just type in, build me a graph of this package, say, and then you could say, tell me all of the downstream modules of this module.

00:37:19.480 --> 00:37:24.860
And then it will explore the whole graph and like give you a set of modules or tell me all the upstream modules of this.

00:37:24.860 --> 00:37:31.580
So you can tell what dependencies are or you can like do, you know, what's the shortest path between this module and this module.

00:37:31.580 --> 00:37:32.480
Makes a lot of sense.

00:37:32.600 --> 00:37:37.040
Yeah. Can you get it to do dependencies, the things you pip install?

00:37:37.040 --> 00:37:37.980
Oh, I see what you mean.

00:37:37.980 --> 00:37:42.020
Well, you can build the graph with multiple packages.

00:37:42.020 --> 00:37:45.660
I don't even know if that's really, is that possible?

00:37:45.660 --> 00:37:50.580
Can you have two installable PyPI packages that depend on each other?

00:37:50.580 --> 00:37:54.700
I'm more wondering if I can use this to visualize, well, what parts of my app?

00:37:54.700 --> 00:37:58.220
So I know that I have this dependency and I have to have it to run.

00:37:58.220 --> 00:38:01.540
But what parts of my app are using that library?

00:38:01.680 --> 00:38:04.100
So if I wanted to change it or whatever, you know what I mean?

00:38:04.100 --> 00:38:08.980
You can build a tree from there's a package for it or UV will give you a tree of dependencies.

00:38:08.980 --> 00:38:12.760
But that is based on what packages require what other packages to be installed.

00:38:12.760 --> 00:38:15.520
It doesn't actually say what's being imported from where.

00:38:15.520 --> 00:38:24.560
So if you have an issue with URL in three, what is the actual like graph of where URL in three is being imported rather than what packages depend on it?

00:38:24.560 --> 00:38:28.780
There's a flag when you build the graph, which is include external packages.

00:38:29.280 --> 00:38:32.060
And if you pass it, then it will include them.

00:38:32.060 --> 00:38:33.440
But it doesn't include them.

00:38:33.440 --> 00:38:35.620
It just like includes the root name.

00:38:35.620 --> 00:38:39.900
If you wanted the whole thing, then you'd say, build me the graph of, I mean, that would work as well.

00:38:39.900 --> 00:38:45.360
But you could say, build me the graph of Django and Kraken, whatever.

00:38:45.620 --> 00:38:49.400
Or you could say, build me the graph of Kraken with external packages.

00:38:49.400 --> 00:38:54.420
Then you'd just see like Django would just be a node in the graph, but it would just be one node.

00:38:54.420 --> 00:38:55.420
Yeah, that'd be great.

00:38:55.420 --> 00:38:56.000
Does that make sense?

00:38:56.100 --> 00:38:59.280
The story is this was working, but slow.

00:38:59.280 --> 00:39:05.440
As an example, one of our contracts, and we had lots of contracts, one contract was taking six minutes to check.

00:39:05.440 --> 00:39:14.600
The reason for this is because actually it is quite algorithmically expensive to check whether or not certain rules are being followed.

00:39:14.600 --> 00:39:17.880
Because it's not like just doing a kind of search.

00:39:17.880 --> 00:39:20.540
It's actually looking for indirect imports.

00:39:20.540 --> 00:39:24.360
So it kind of needs to explore the whole graph to see.

00:39:24.360 --> 00:39:30.380
It's like a pathfinding algorithm to sort of see, oh, well, do you end up here via this other thing that you didn't ask about?

00:39:30.380 --> 00:39:33.640
And yeah, so certain things were taking a really long time.

00:39:33.640 --> 00:39:40.140
And that was costing us money because we run this, you know, hundreds, if not thousands of times a day.

00:39:40.140 --> 00:39:41.320
And it all adds up.

00:39:41.320 --> 00:39:44.520
And it also just slows down, you know, your pull request.

00:39:44.520 --> 00:39:46.100
You want to get to green quicker.

00:39:46.100 --> 00:39:51.080
So I had heard that Rust was interoperable with Python.

00:39:51.080 --> 00:39:53.040
I didn't really know anything about it.

00:39:53.040 --> 00:39:59.440
And I found this library called Py03, which is a Rust library.

00:39:59.440 --> 00:40:04.240
And it makes it, I'm not going to say easy, but it makes it.

00:40:04.240 --> 00:40:04.700
Easier.

00:40:04.700 --> 00:40:09.460
It makes it surprisingly easy to write Rust extension modules.

00:40:09.460 --> 00:40:11.140
It gives you sort of all the tooling in place.

00:40:11.140 --> 00:40:16.920
And I would say, you know, you're writing a lot less code than you would be if you're writing a C extension module.

00:40:16.920 --> 00:40:23.740
Because it's sort of a nice, it's a really nice API for creating these interoperable compiled modules.

00:40:23.740 --> 00:40:31.800
So like I started by just finding the function that was taking all the time and had millions and millions and millions of calls.

00:40:31.800 --> 00:40:34.980
I was like, why don't I just write that in Rust?

00:40:34.980 --> 00:40:44.780
And I kind of just sort of almost copied and pasted it over and like cobbled together some pretty rubbish Rust that did basically exactly the same algorithm.

00:40:45.280 --> 00:40:47.300
And it was a thousand times slower.

00:40:47.300 --> 00:40:49.540
Well done.

00:40:49.540 --> 00:40:50.120
Well done.

00:40:50.120 --> 00:40:54.680
There's a good reason for that, which is I just zoomed in too close.

00:40:54.680 --> 00:41:00.780
So because that function was called a lot of times, there is actually a cost in crossing the boundary.

00:41:00.780 --> 00:41:06.980
So I just had to step one level up and like wrap all of those calls for that function in Rust instead.

00:41:06.980 --> 00:41:09.560
So there's only one call from Python to Rust.

00:41:09.560 --> 00:41:12.620
And then suddenly, majorly quicker.

00:41:12.960 --> 00:41:18.760
I mean, I think that that particular problematic contract went from about six minutes to one minute.

00:41:18.760 --> 00:41:21.800
That is, to be honest, and that was brilliant.

00:41:21.800 --> 00:41:22.980
But that is not.

00:41:22.980 --> 00:41:25.780
That's just scratching the surface of how much quicker it could get.

00:41:25.780 --> 00:41:35.240
But still, a six times speed up for relatively little work and basically just writing the same algorithm, but with some curly brackets and a bit of head scratching.

00:41:35.620 --> 00:41:40.780
Like I was able to deliver something without having ever done anything in Rust.

00:41:40.780 --> 00:41:44.620
And it really made a difference, you know, and saved us lots of money.

00:41:44.620 --> 00:41:45.100
Yeah.

00:41:45.100 --> 00:41:46.760
So that was a risk.

00:41:46.760 --> 00:41:48.060
And now you're a Rust developer as well.

00:41:48.060 --> 00:41:49.780
Now I'm a Rust developer and I read through it.

00:41:49.780 --> 00:41:52.460
And I'm, you know, I want to move more of Grimp into Rust.

00:41:52.800 --> 00:41:57.560
Another example, even less work, was we had a problem with translations.

00:41:57.560 --> 00:42:01.640
So there's a kind of standard for doing translations called Fluent.

00:42:01.640 --> 00:42:04.980
And some of the listeners may have come across it.

00:42:04.980 --> 00:42:09.380
And there are libraries for it in all sorts of different languages, including Python and Rust.

00:42:09.380 --> 00:42:22.260
And we realized that it was responsible for almost all of the bootstrap time of our application in production was loading and scanning these translation files.

00:42:22.260 --> 00:42:24.240
You know, it was pretty problematic.

00:42:24.240 --> 00:42:26.280
It was like really spiky as well.

00:42:26.280 --> 00:42:30.520
You could see sometimes it would spike to like nine minutes to turn on the application.

00:42:30.520 --> 00:42:33.240
And we knew it was all in this translations thing.

00:42:33.240 --> 00:42:36.760
And someone pointed out, look, there's a Rust library for this.

00:42:36.760 --> 00:42:39.300
So all we need to do is just link them up.

00:42:39.300 --> 00:42:46.740
And so they, it wasn't, it wasn't actually me, but they just wrote this Py03 crate that a crate is like a Rust library.

00:42:46.740 --> 00:42:52.220
You know, probably only about 10, 15 lines of code just glued the two things together.

00:42:52.220 --> 00:42:55.100
It was really like not very much work.

00:42:55.100 --> 00:42:59.060
And compile that, it just completely sorted the problem out.

00:42:59.060 --> 00:43:01.840
We went from eight minutes to 30 seconds.

00:43:02.440 --> 00:43:06.620
And, you know, of that, like the, the, you know, that 30 seconds is other stuff.

00:43:06.620 --> 00:43:13.620
You know, I think, I think it turned it from being something that took several minutes to being virtually instant for really hardly any work.

00:43:13.620 --> 00:43:18.880
And I think that that's a really good example of where, as Python developers, we should be aware this is an option.

00:43:18.880 --> 00:43:24.080
If something's slow, you might just, I mean, Rust has so many good libraries.

00:43:24.080 --> 00:43:27.760
You might just be able to like just glue it up and job done.

00:43:27.760 --> 00:43:32.720
One thing I would add, the, the overhead of calling into Py03 has, has dropped a lot.

00:43:32.720 --> 00:43:37.680
I don't know how long ago that was you, you were trying, but I think it's, yeah, reduced significantly.

00:43:37.680 --> 00:43:43.740
So, I mean, I did this quite a lot of the same work in Pydantic Core to avoid the overhead of calling into and out of it lots of times.

00:43:43.740 --> 00:43:45.840
And I think that's less of a thing now than it used to be.

00:43:45.840 --> 00:43:46.500
That's good to hear.

00:43:46.500 --> 00:44:05.540
One point I want to make is, I think that's really interesting, David, to say that, hey, there's this whole equivalent of PyPI called Cargo, or you can get these libraries just like we can, I mean, sorry, that you install with Cargo, that you can get all these pre-built, pre-tested libraries and maybe just put a wrapper on them and do some amazing stuff.

00:44:06.020 --> 00:44:11.160
I just started using this web server at the Python layer called Granian.

00:44:11.160 --> 00:44:14.360
And you're like, well, how many people are working on it?

00:44:14.360 --> 00:44:16.380
It's got up to 3,000 stars now.

00:44:16.380 --> 00:44:17.200
Is that enough to trust?

00:44:17.200 --> 00:44:22.080
Yes, but if you really look at it, it's really using just Hyper, right?

00:44:22.080 --> 00:44:29.860
And Hyper, Hyper is a library that, excuse me, that has got 14,000 GitHub stars, 400 contributors.

00:44:29.860 --> 00:44:38.140
And like, oh, you know, it's kind of this cool application is something of a wrapper around this really popular and well-known thing, right?

00:44:38.140 --> 00:44:39.920
I think we'll see more of this kind of stuff.

00:44:39.920 --> 00:44:45.660
Giovanni, who worked on this, is also working on, it's R-loop, basically an alternative to UV-loop.

00:44:45.660 --> 00:44:46.220
Yes.

00:44:46.300 --> 00:44:48.140
I don't know if that's in here as well.

00:44:48.140 --> 00:44:55.880
I maintain watch files, which is the file watching library used by uvicorn and some other things.

00:44:55.880 --> 00:45:00.720
And that is, again, wrapping a Rust library for getting fast system notifications.

00:45:00.720 --> 00:45:06.920
And also R-toml, which is the fastest tomml parser in Python, which is, again, just wrapping the Rust library.

00:45:06.920 --> 00:45:15.620
So there are a number of places where you can get enormous performance improvements and indeed like fundamentally more reliable libraries because you're building in Rust.

00:45:15.620 --> 00:45:20.040
when you're doing complex, particularly multi-threaded things by relying on Rust.

00:45:20.040 --> 00:45:23.300
These libraries seem to be very good quality and well thought through.

00:45:23.300 --> 00:45:24.540
That's been my experience.

00:45:24.540 --> 00:45:31.540
Somehow it attracts people that are very thorough because you can't really program in Rust unless you're thorough because you can't get an extra pile.

00:45:31.960 --> 00:45:35.160
I think it's hard to say Rust does have a bit of a problem with abandoned libraries.

00:45:35.160 --> 00:45:43.980
I think that is, I think if we didn't call it out, I know David, you and I were speaking at an event where there was one particular chap who had a bee in his bonnet about that exact issue.

00:45:43.980 --> 00:45:45.580
I think he was slightly overblown on it.

00:45:45.620 --> 00:45:49.800
But there is definitely an issue with some abandoned libraries in Rust.

00:45:49.800 --> 00:45:52.980
But like, I mean, same is true in Python in its own place.

00:45:52.980 --> 00:45:53.940
But you're right.

00:45:53.940 --> 00:45:57.780
There are also libraries that are abandoned and remaining incredibly good quality.

00:45:57.780 --> 00:46:00.300
So Jitter uses a library for parsing floats.

00:46:00.300 --> 00:46:06.020
I didn't know this, but the complexity of parsing floats from strings is a entire subject of academic interest.

00:46:06.020 --> 00:46:12.560
There are eight different algorithms for doing it with different performance, depending on whether or not it is the structure of the float.

00:46:12.560 --> 00:46:14.520
And there was a library that does this very well.

00:46:14.520 --> 00:46:17.160
And the library was abandoned, but it worked perfectly.

00:46:17.160 --> 00:46:19.480
And eventually the guy replied to my email and went and fixed it.

00:46:19.480 --> 00:46:22.640
So, I mean, the quality, yeah, the quality is very high in my experience.

00:46:22.640 --> 00:46:23.640
Yeah, I just make the point.

00:46:23.640 --> 00:46:27.320
I think, you know, there's over half a million packages in PyPI as well.

00:46:27.320 --> 00:46:31.320
And I'm sure there's a non-trivial amount of them that people are no longer maintaining as well.

00:46:31.320 --> 00:46:33.760
Sometimes things are done and sometimes they're abandoned.

00:46:33.760 --> 00:46:35.420
And it's hard to tell the difference, you know?

00:46:35.420 --> 00:46:38.180
Like, no, I haven't updated it in two years because it's done.

00:46:38.180 --> 00:46:40.500
But also, also.

00:46:40.500 --> 00:46:46.000
It's hard to tell the difference until you're three weeks in and you don't want to back out of using that library and you realize that actually it's...

00:46:46.000 --> 00:46:46.860
It's actually not done.

00:46:46.860 --> 00:46:47.640
It's not done.

00:46:47.640 --> 00:46:49.020
But nobody wants to worry.

00:46:49.020 --> 00:46:56.320
All right, David, before we wrap this up, I would really like to have you talk us through sort of the tool chain workflow of...

00:46:56.920 --> 00:46:58.020
I've got this idea.

00:46:58.020 --> 00:47:02.500
I want to maybe, you know, rewrite it in Rust if you've spoken about it.

00:47:02.500 --> 00:47:03.740
What are the building blocks?

00:47:03.740 --> 00:47:04.520
What are the moving pieces?

00:47:04.520 --> 00:47:05.460
What do people need to know?

00:47:05.460 --> 00:47:05.880
Absolutely.

00:47:05.880 --> 00:47:06.300
Okay.

00:47:06.440 --> 00:47:16.400
So the things you need to know is, first of all, the thing you're going to create is an extension module, which is like a built compiled thing.

00:47:16.400 --> 00:47:20.040
And that is going to end up being a Python wheel.

00:47:20.040 --> 00:47:28.600
And what you want to do is when you release something on PyPI, you want to have wheels for all the different versions of Python and chip architectures and things.

00:47:28.600 --> 00:47:31.600
So that's kind of like some of the complexity.

00:47:31.600 --> 00:47:33.360
So that's kind of the end goal.

00:47:33.620 --> 00:47:44.940
We want to end up with these built versions of Python that are going to contain some Python code, but also some compiled things for, you know, macOS under Python 312 or whatever like that.

00:47:44.940 --> 00:47:48.760
So the way you start this, you need to install Rust on your computer.

00:47:48.760 --> 00:47:52.620
And the tool for that is actually called RustUp.

00:47:52.620 --> 00:47:54.260
This kind of confused me to start with.

00:47:54.260 --> 00:47:55.760
I didn't really understand what RustUp is.

00:47:55.760 --> 00:47:58.760
But RustUp is kind of like one level up.

00:47:58.760 --> 00:48:02.760
And it's maybe a bit like PyPI if people have used that.

00:48:02.760 --> 00:48:04.600
But it sort of does a bit more than that.

00:48:04.600 --> 00:48:13.360
Maybe also a bit like UV these days where you can UV install Python based on what you asked for or just create a virtual environment and it'll just grab the tools you need to make that happen.

00:48:13.360 --> 00:48:17.540
I'd say that Cargo is closer to UV probably, which is the next thing I'll talk about.

00:48:17.540 --> 00:48:30.260
But RustUp is like one step up and it's like it's for managing the versions of Rust that are on your computer and the versions of Cargo that are on your computer, which are Cargo is the package manager for Rust.

00:48:30.720 --> 00:48:35.320
What you'll do, your first step is to go to the Rust website and install RustUp.

00:48:35.320 --> 00:48:40.420
And then hopefully at the command line, you'll be able to type rustc and then you can compile a Rust file if you want to.

00:48:40.420 --> 00:48:43.980
But you don't actually need to do that because that's what you use Cargo for.

00:48:43.980 --> 00:48:50.220
So your main kind of thing that you're typing all the time when you're using Rust is Cargo and then some kind of command.

00:48:50.220 --> 00:48:53.040
So you've installed RustUp and you've got Cargo.

00:48:53.040 --> 00:48:58.880
Then what you'd want to do is create a project and you can create a project using Cargo.

00:48:59.000 --> 00:49:05.400
You could do Cargo new and then it'll give you a whole file system structure and you'll be able to run it and run tests and all that.

00:49:05.400 --> 00:49:06.060
Very nice.

00:49:06.060 --> 00:49:10.380
And that is how you would install the latest version of Py03.

00:49:10.380 --> 00:49:17.300
So you would, I probably would just go over onto crates.io, which is the PyPI equivalent,

00:49:17.300 --> 00:49:24.780
and look at what the version is of PyPI and then write it in a, I think there is a Cargo command probably for adding it.

00:49:24.780 --> 00:49:29.180
But it's also worth saying that Maturin is a big part of the ecosystem.

00:49:29.180 --> 00:49:33.520
Jono, David, maybe you could introduce Maturin because I think that's about where that comes in.

00:49:33.520 --> 00:49:37.440
Cargo is the thing that Rust people will be using to compile these things.

00:49:37.580 --> 00:49:43.440
But you can't just use that on your own because you need the whole pip installing kind of side of things.

00:49:43.440 --> 00:49:49.920
So you can use Cargo and just create an extension module, but then you need to like give it the right name and copy it into the right place.

00:49:49.920 --> 00:49:53.400
So there's a bit of kind of gluing that needs to happen.

00:49:53.400 --> 00:49:55.400
And that is what Maturin is for.

00:49:55.400 --> 00:49:57.100
Why do we need two tools?

00:49:57.100 --> 00:50:03.960
Well, Cargo is the Rust side of things, but Maturin is actually just a pip installable Python package.

00:50:03.960 --> 00:50:15.560
So what you'll do is in your, in the Python project that you want to Rustify, you will do, go into your, activate your virtual environment or whatever, and then do pip install Maturin.

00:50:15.560 --> 00:50:18.180
And then you've got this tool for Maturin.

00:50:18.180 --> 00:50:21.480
And you could even do Maturin new project or something like that.

00:50:21.480 --> 00:50:22.420
I can't remember what the command is.

00:50:22.500 --> 00:50:27.700
What I had to do was I had a pre-existing project, so I couldn't just do it like that.

00:50:27.700 --> 00:50:33.920
But it might be quite a nice way to learn is to follow the Maturin docs to do a new project.

00:50:33.920 --> 00:50:41.220
And what Maturin allows you to do is I think you might edit your Rust code and then you would type Maturin develop.

00:50:41.220 --> 00:50:47.960
And then it would compile your Rust code, but it would kind of install it locally so that you can work with it.

00:50:48.200 --> 00:50:52.460
And then the final piece of this picture is how that gets onto PyPI.

00:50:52.460 --> 00:50:54.740
Maturin also gives you some tools for that.

00:50:54.740 --> 00:51:03.180
There's a command called generate CI, I think, which gives you, it just spits out YAML for the, for whatever CI provider you want.

00:51:03.180 --> 00:51:04.980
And that's really helpful as well.

00:51:04.980 --> 00:51:07.520
I mean, that's a bit about verbally.

00:51:07.520 --> 00:51:09.920
I've given a talk of people.

00:51:10.060 --> 00:51:21.160
Yeah, well, I think one of the things you both have to deal with here is releasing a package, a wheel for this is not just, well, let's zip up the Python files and put them up there, right?

00:51:21.160 --> 00:51:25.420
You're compiling native code and that means you need variations, right?

00:51:25.420 --> 00:51:33.580
Yeah, I think Pydantic core releases 60 something different wheels to cover all different possible combinations of Python version and architecture.

00:51:33.580 --> 00:51:35.480
I would basically second what David was saying.

00:51:35.480 --> 00:51:41.760
Maturin in particular does an amazing job of smoothing out the kind of rough edges between Rust and Python.

00:51:41.760 --> 00:51:45.580
Rust has had a good, relatively good story on package management for some time.

00:51:45.960 --> 00:51:57.880
Python is just coming, but often when you're trying to do these things, it's the, like, trying to get one to speak to the other and working out what the hell is going wrong and what does that file need to be or that, like, sim link between some DLL and some other place.

00:51:57.880 --> 00:52:07.680
Maturin effectively gets rid of that whole challenge for you and just works and lets you work on it like you're, it's as easy as writing Python or Rust interacting with the two.

00:52:07.680 --> 00:52:18.220
Yeah, because cargo and Rust C will output Rust conventions, but Python wants C extension conventions, naming like .so versus Dynelib and things like that, right?

00:52:18.220 --> 00:52:19.880
And getting the inputs right and yeah.

00:52:19.880 --> 00:52:29.960
So what your work, once you've sort of set it all up, your workflow looks like is if you haven't changed any of the Rust, then, you know, maybe like you run tests, you just run pytest or whatever.

00:52:29.960 --> 00:52:36.280
That will run tests against the compiled bit, assuming you're writing Python tests against that.

00:52:36.740 --> 00:52:40.820
But if you make a change to the Rust, then you do have to have an extra step of building it.

00:52:40.820 --> 00:52:43.600
So you type Maturin, develop, and then it would build it.

00:52:43.600 --> 00:52:45.100
And then you could run pytest.

00:52:45.100 --> 00:52:50.280
Or you might recommend you do, actually, if you're working with Rust and you're not very experienced.

00:52:50.280 --> 00:53:03.040
I tend to have a test suite for Python, but also some tests in Rust because you get a much quicker feedback loop because you can type cargo test and that will compile it and run the test really quite quickly.

00:53:03.040 --> 00:53:11.520
One other thing I think is worth adding is that, obviously, if you have this binary that contains your Rust code, which is, you know, in the end, it becomes a module that you can import in Python.

00:53:11.520 --> 00:53:14.960
But by default, that is obviously opaque to type checkers.

00:53:15.200 --> 00:53:19.820
So things like IDEs and static type checking can't look inside there and see what your functions are.

00:53:19.820 --> 00:53:26.820
So you want to write a PYI file, which contains your definitions in like stub Python code, effectively.

00:53:26.820 --> 00:53:31.900
The problem you then have is you end up with two separate definitions of what your functions have in them.

00:53:31.940 --> 00:53:44.220
And so there's a really neat tool, which I didn't know about until quite recently, but we use it in Pydantic Core, which mypy can basically type check that the PYI file stubs match the definitions inside the DLL.

00:53:44.440 --> 00:53:54.200
And so you can have like guarantees that where you've written in a PYI file, my function foobar takes A as a string and C as a list of bytes.

00:53:54.200 --> 00:53:55.000
That's really cool.

00:53:55.000 --> 00:53:55.800
I didn't know about that.

00:53:55.800 --> 00:53:56.500
Yeah, that's awesome.

00:53:56.500 --> 00:53:57.380
Fixes all together.

00:53:57.380 --> 00:53:58.440
Is it a mypy plugin?

00:53:58.700 --> 00:54:04.620
If you have a look at Pydantic Core, we run it in CI or in maybe even pre-commit so you can find it there.

00:54:04.620 --> 00:54:05.420
I couldn't remember.

00:54:05.420 --> 00:54:12.020
I discovered it because like so often with so many of us, I discovered it because it had a bug.

00:54:12.020 --> 00:54:14.340
And so it suddenly didn't do quite the right thing for me.

00:54:14.340 --> 00:54:16.380
But I mean, in general, it's been perfect until now.

00:54:16.380 --> 00:54:18.980
Yeah, it's plumbing until it doesn't work and then it's a flood.

00:54:18.980 --> 00:54:19.980
Bug-based discovery.

00:54:19.980 --> 00:54:21.880
Definitely a thing we've all practiced.

00:54:21.880 --> 00:54:23.460
Bug-driven development.

00:54:23.460 --> 00:54:24.100
Yeah, okay.

00:54:24.260 --> 00:54:38.820
And if people want to check out these PYI files, there's a project called TypeShed on GitHub that whose job is to basically become these so-called stub files for a ridiculous number of projects that, you know, we're talking about things that are not going to get upgraded.

00:54:38.820 --> 00:54:44.420
Maybe they're never going to get typing put on them, but you can go and import one of these or whatever and get.

00:54:44.420 --> 00:54:52.720
But also lots of packages now have their own, either they have types in them or they have a PYI file that defines the types either in the Python code or in PYI.

00:54:52.720 --> 00:54:53.460
That's really cool.

00:54:53.520 --> 00:54:56.840
I didn't realize about the tool there, though, that does the integration.

00:54:56.840 --> 00:54:57.300
That's awesome.

00:54:57.300 --> 00:55:00.180
I think presumably you can use it to generate your first PYI file.

00:55:00.180 --> 00:55:04.280
Then you go in and put your doc strings in, tweak things a bit, and then you run it in test mode.

00:55:04.280 --> 00:55:04.800
Oh, nice.

00:55:04.800 --> 00:55:11.080
Yeah, because that way use the true version, the Rust version, and just say generate what I need to make this work.

00:55:11.080 --> 00:55:11.840
That makes a lot of sense.

00:55:11.840 --> 00:55:12.040
Yeah.

00:55:12.040 --> 00:55:12.380
Awesome.

00:55:12.380 --> 00:55:12.980
All right.

00:55:12.980 --> 00:55:16.140
Well, gentlemen, we are just pretty much out of time.

00:55:16.140 --> 00:55:20.440
I guess let me ask you one more thing here.

00:55:20.440 --> 00:55:21.760
And I don't think I pulled it up.

00:55:21.760 --> 00:55:24.640
So there's a new PEP called external wheel hosting.

00:55:24.640 --> 00:55:25.860
Have you all heard of this?

00:55:25.860 --> 00:55:27.640
I have not seen that particular.

00:55:27.640 --> 00:55:28.840
Is that for Wasm?

00:55:28.840 --> 00:55:35.200
I know that I've been talking to a fair bit about the challenges of uploading Wasm wheels.

00:55:35.200 --> 00:55:38.360
I know it has to do with more than it is five.

00:55:38.360 --> 00:55:39.200
Here we go.

00:55:39.200 --> 00:55:40.120
Copy link.

00:55:40.120 --> 00:55:43.000
It is five, seven, five, nine.

00:55:43.000 --> 00:55:47.840
And the idea that if you could, the nomenclature here is ridiculous.

00:55:47.840 --> 00:55:49.900
It is in clever.

00:55:50.380 --> 00:55:57.740
So the idea is that, you know, each build of Pydantic puts 60 binary artifacts onto PYPI.

00:55:57.740 --> 00:56:05.200
And there's limitations on how large your projects can be and how large individual releases can be.

00:56:05.200 --> 00:56:09.040
This is especially problematic for machine learning stuff, right?

00:56:09.040 --> 00:56:11.540
And so the idea is, can we create a wheel stub?

00:56:11.540 --> 00:56:13.100
And what is a wheel stub called?

00:56:13.460 --> 00:56:15.660
It's like the wheel without the content.

00:56:15.660 --> 00:56:20.100
It's called a rim because wheels go on, you know, and there's all sorts of stuff like that here.

00:56:20.100 --> 00:56:26.960
But it contains a hash and then a location where the thing actually lives, right?

00:56:26.960 --> 00:56:29.160
So you mentioned OpenAI, for example.

00:56:29.160 --> 00:56:32.480
Maybe they have some huge thing they want you to download eventually.

00:56:32.480 --> 00:56:36.640
They could host it and you just publish the rim, not the wheel.

00:56:36.640 --> 00:56:38.720
Do you know the story of why they're called wheels?

00:56:38.720 --> 00:56:40.100
This entertains me a lot.

00:56:40.100 --> 00:56:40.940
No, tell me.

00:56:40.940 --> 00:56:43.760
So they're called wheels because you have wheels of cheese.

00:56:43.760 --> 00:56:48.780
They're called wheels of cheese because the original PYPI was called the cheese shop,

00:56:48.780 --> 00:56:54.280
which in turn was called the cheese shop because there is a Monty Python sketch called the cheese shop

00:56:54.280 --> 00:56:58.020
where he goes in to buy cheese and none of the cheeses he asked for are available.

00:56:58.020 --> 00:57:04.060
And it was called that as a way of taking the piss out of, I forget which other language,

00:57:04.060 --> 00:57:11.900
it might've been Ruby or PHP, how their original package registry had no packages in it like the cheese shops get in Monty Python.

00:57:11.900 --> 00:57:16.440
And that has now assisted to rims in 2024.

00:57:16.440 --> 00:57:17.400
That's incredible.

00:57:17.400 --> 00:57:18.040
Yeah.

00:57:18.040 --> 00:57:25.400
I did know the cheese shop equivalent there that that was part of it, but I didn't realize that it was the wheels of cheese.

00:57:25.400 --> 00:57:25.880
Okay.

00:57:25.880 --> 00:57:26.320
Incredible.

00:57:26.320 --> 00:57:28.180
There's a lot of Monty Python.

00:57:28.180 --> 00:57:30.880
You know, people that you look around everywhere.

00:57:30.880 --> 00:57:32.700
The logo is the snake, right?

00:57:32.740 --> 00:57:35.920
But the logo, the name is not Python, the snake.

00:57:35.920 --> 00:57:38.960
It's Monty Python and that horrible bunny.

00:57:38.960 --> 00:57:42.980
If I wrote a book about Python, I'd want to have the knights who say me on the front.

00:57:42.980 --> 00:57:44.100
Yes.

00:57:44.100 --> 00:57:47.020
I want the bunny, the killer bunny.

00:57:47.020 --> 00:57:49.020
It's definitely a certain era of humor.

00:57:49.020 --> 00:57:49.860
I don't know.

00:57:49.860 --> 00:57:51.820
You know, it definitely dates Python in its way.

00:57:51.820 --> 00:57:52.900
And us, perhaps I fear.

00:57:52.900 --> 00:57:55.300
Yeah, perhaps, perhaps.

00:57:55.300 --> 00:57:58.160
I don't know what this gray hair is about, but we're going to go.

00:57:58.160 --> 00:58:00.360
All right, guys, let's close this out.

00:58:00.820 --> 00:58:08.260
I'll give each of you a chance to just give us sort of a parting thought on integrating Rust and maybe thoughts and just Rust and Python together.

00:58:08.260 --> 00:58:09.300
I'll go, David.

00:58:09.300 --> 00:58:13.900
Only really to say I am a better programmer for having learned to write Rust as well as Python.

00:58:13.900 --> 00:58:19.000
And I fail to see the value in C anymore for new projects.

00:58:19.000 --> 00:58:21.040
I get why I exist for lots of existing ones.

00:58:21.040 --> 00:58:24.520
I'm not going to get into the issue of whether stuff should be rewritten in Rust.

00:58:24.520 --> 00:58:30.180
But I think if you're starting from scratch and you're trying to write something high performance, the experience of doing it in Rust is completely different.

00:58:30.180 --> 00:58:35.900
from trying to do it in C or C++ or C# or any of the other or Fortran or Julia or any of those other languages.

00:58:35.900 --> 00:58:36.900
Rust is awesome.

00:58:36.900 --> 00:58:39.420
So I'd really encourage people to give it a go.

00:58:39.420 --> 00:58:43.040
And when you're giving it a go, you might also have a give Logfire a quick go.

00:58:43.040 --> 00:58:45.200
We're releasing our Rust SDK fairly soon.

00:58:45.200 --> 00:58:45.940
We have Python already.

00:58:45.940 --> 00:58:52.080
So we're matching the like Python Rust TypeScript ecosystem, which I think is the like the stack to build with today.

00:58:52.080 --> 00:58:59.040
My parting thought would be like, if you give it a go, don't be surprised if you feel quite inadequate.

00:58:59.040 --> 00:59:03.560
It's really quite hard to sort of get your head around what's going on.

00:59:03.560 --> 00:59:06.760
And I feel very much still at the beginning of my journey.

00:59:06.760 --> 00:59:16.860
But nevertheless, I have actually managed to like deliver some stuff which is valuable, even though, to be honest, I'm not like particularly proud of the code I'm writing.

00:59:17.080 --> 00:59:18.900
It's like, you know, I'm a beginner again.

00:59:18.900 --> 00:59:21.300
And I just want to say, like, don't let that put you off.

00:59:21.300 --> 00:59:26.780
And if you're confused, you know, just keep on going and trying to get your head around it.

00:59:26.780 --> 00:59:28.300
It will make you a better programmer.

00:59:28.300 --> 00:59:36.560
The book that I found the best for learning Rust is the Rust Programming Language, which is a free book on the Rust website.

00:59:36.560 --> 00:59:36.860
Right.

00:59:36.860 --> 00:59:39.000
Just click the learn button in the top, right?

00:59:39.000 --> 00:59:39.640
Yeah, exactly.

00:59:39.640 --> 00:59:40.220
Learn menu item.

00:59:40.220 --> 00:59:40.480
Yeah.

00:59:40.480 --> 00:59:40.980
Awesome.

00:59:41.280 --> 00:59:54.000
Yeah, I'll also just add one quick thought as well to just follow up to what you said, David, is whenever you're switching programming languages and you've been programming for a while, you just, you feel inadequate and you feel like I was so good.

00:59:54.000 --> 00:59:55.000
I had it figured out.

00:59:55.000 --> 00:59:56.640
I could just sit down and do stuff.

00:59:56.640 --> 01:00:00.600
And now even how do I just read a file or just run a program?

01:00:00.600 --> 01:00:02.100
I'm lost all over again.

01:00:02.100 --> 01:00:07.840
But every time you do that, your prior experience still carries over way more than it initially feels like it does.

01:00:07.840 --> 01:00:10.940
And you're not throwing everything away and starting over.

01:00:10.940 --> 01:00:13.580
You're learning a new tool chain and then on you go.

01:00:13.580 --> 01:00:14.120
Absolutely.

01:00:14.120 --> 01:00:17.560
And particularly when it's so easy to call Python from Rust and vice versa.

01:00:17.560 --> 01:00:20.960
And so you can build applications that are like hybrid of the two.

01:00:20.960 --> 01:00:21.340
Absolutely.

01:00:21.340 --> 01:00:21.860
Yeah.

01:00:21.860 --> 01:00:25.060
Well, congratulations both on some awesome projects.

01:00:25.060 --> 01:00:26.240
And yeah, thanks.

01:00:26.240 --> 01:00:27.400
Thanks for being here as well.

01:00:27.400 --> 01:00:27.720
Bye, y'all.

01:00:27.720 --> 01:00:28.460
Thanks for having us.

01:00:28.460 --> 01:00:29.180
Thank you so much.

01:00:30.180 --> 01:00:33.000
This has been another episode of Talk Python to Me.

01:00:33.000 --> 01:00:34.800
Thank you to our sponsors.

01:00:34.800 --> 01:00:36.420
Be sure to check out what they're offering.

01:00:36.420 --> 01:00:37.840
It really helps support the show.

01:00:37.840 --> 01:00:42.480
This episode is sponsored by Posit Connect from the makers of Shiny.

01:00:42.480 --> 01:00:47.000
Publish, share, and deploy all of your data projects that you're creating using Python.

01:00:47.000 --> 01:00:53.580
Streamlit, Dash, Shiny, Bokeh, FastAPI, Flask, Quarto, Reports, Dashboards, and APIs.

01:00:53.580 --> 01:00:55.960
Posit Connect supports all of them.

01:00:55.960 --> 01:01:00.340
Try Posit Connect for free by going to talkpython.fm/posit.

01:01:00.340 --> 01:01:01.640
P-O-S-I-T.

01:01:01.640 --> 01:01:06.300
This episode is brought to you by the Data Citizens Dialogues podcast from Colibra.

01:01:06.300 --> 01:01:13.240
If you're ready for a deeper dive into the latest hot topics and data, listen to an episode at talkpython.fm/citizens.

01:01:13.240 --> 01:01:15.020
Want to level up your Python?

01:01:15.400 --> 01:01:19.060
We have one of the largest catalogs of Python video courses over at Talk Python.

01:01:19.060 --> 01:01:24.240
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:01:24.240 --> 01:01:26.900
And best of all, there's not a subscription in sight.

01:01:26.900 --> 01:01:29.800
Check it out for yourself at training.talkpython.fm.

01:01:29.800 --> 01:01:31.920
Be sure to subscribe to the show.

01:01:31.920 --> 01:01:34.700
Open your favorite podcast app and search for Python.

01:01:34.700 --> 01:01:36.000
We should be right at the top.

01:01:36.000 --> 01:01:45.380
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

01:01:45.380 --> 01:01:48.320
We're live streaming most of our recordings these days.

01:01:48.320 --> 01:01:56.120
If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:01:56.120 --> 01:01:58.220
This is your host, Michael Kennedy.

01:01:58.220 --> 01:01:59.520
Thanks so much for listening.

01:01:59.520 --> 01:02:00.660
I really appreciate it.

01:02:00.660 --> 01:02:02.580
Now get out there and write some Python code.

01:02:02.580 --> 01:02:23.740
I'll see you next time.

