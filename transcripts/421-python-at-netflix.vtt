WEBVTT

00:00:00.001 --> 00:00:05.800
When you think of Netflix as a technology company, you probably imagine them as cloud innovators.

00:00:05.800 --> 00:00:10.100
They were one of the first companies to go all in on a massive scale for cloud computing,

00:00:10.100 --> 00:00:13.960
as well as throwing that pesky chaos monkey into those servers.

00:00:13.960 --> 00:00:18.000
But they have become a hive of amazing Python activity.

00:00:18.000 --> 00:00:23.260
From their CDN, their demand predictions and failover, security, machine learning,

00:00:23.260 --> 00:00:27.900
executable notebooks, and lots more, the Python at play is super interesting.

00:00:28.060 --> 00:00:34.900
And on this episode, we have Zoran Simic and Amjith Ramanujan on the show to give us this rare look inside.

00:00:34.900 --> 00:00:40.320
This is Talk Python To Me, episode 421, recorded June 8th, 2023.

00:00:40.320 --> 00:00:56.840
Welcome to Talk Python To Me, a weekly podcast on Python.

00:00:56.840 --> 00:00:58.580
This is your host, Michael Kennedy.

00:00:58.580 --> 00:01:03.680
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython,

00:01:03.680 --> 00:01:06.060
both on fosstodon.org.

00:01:06.060 --> 00:01:08.660
Be careful with impersonating accounts on other instances.

00:01:08.660 --> 00:01:09.620
There are many.

00:01:09.620 --> 00:01:14.700
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:01:14.700 --> 00:01:18.660
We've started streaming most of our episodes live on YouTube.

00:01:19.160 --> 00:01:26.260
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.

00:01:26.860 --> 00:01:32.760
This episode is brought to you by JetBrains, who encourage you to get work done with PyCharm.

00:01:32.760 --> 00:01:39.660
Download your free trial of PyCharm Professional at talkpython.fm/done dash with dash PyCharm.

00:01:39.660 --> 00:01:42.160
And it's brought to you by InfluxDB.

00:01:42.160 --> 00:01:48.760
InfluxDB is the database purpose built for handling time series data at a massive scale for real-time analytics.

00:01:49.260 --> 00:01:52.600
Try them for free at talkpython.fm/InfluxDB.

00:01:52.600 --> 00:01:54.820
Hey, Zorin.

00:01:54.820 --> 00:01:55.360
Hey, I'm G.

00:01:55.360 --> 00:01:55.800
Hello, Michael.

00:01:55.800 --> 00:01:56.300
Hello, Michael.

00:01:56.300 --> 00:01:58.320
Welcome to Talk Python To Me, you guys.

00:01:58.320 --> 00:01:59.980
It's excellent to have you here.

00:01:59.980 --> 00:02:00.980
Thank you very much.

00:02:00.980 --> 00:02:04.080
I'm a big fan, so it's very nice to be on the show, actually.

00:02:04.080 --> 00:02:04.700
Awesome.

00:02:04.700 --> 00:02:05.080
Yeah.

00:02:05.080 --> 00:02:10.480
We've got to meet a couple times at PyCon, which is honestly one of my favorite purposes of PyCon,

00:02:10.480 --> 00:02:14.120
is to meet people and just hang out and have those experiences, you know?

00:02:14.120 --> 00:02:15.100
Yeah, absolutely.

00:02:15.100 --> 00:02:15.760
Yeah.

00:02:15.760 --> 00:02:16.020
Yeah.

00:02:16.020 --> 00:02:17.840
And nice to have you on the show, Zorin.

00:02:17.840 --> 00:02:18.160
Yeah.

00:02:18.420 --> 00:02:19.300
Big fan as well.

00:02:19.300 --> 00:02:20.660
Thank you very much.

00:02:20.660 --> 00:02:21.820
That's very kind to both of you.

00:02:21.820 --> 00:02:26.900
So we're going to talk about a pretty awesome tech company, I think.

00:02:26.900 --> 00:02:27.400
Netflix.

00:02:27.400 --> 00:02:31.240
You both work at Netflix, and people who are watching the video, you're coming to us from

00:02:31.240 --> 00:02:36.500
the Netflix headquarters, which I've got the chance to be there for some Python stuff going

00:02:36.500 --> 00:02:37.540
on there before as well.

00:02:37.540 --> 00:02:40.740
Got cool posters and sort of movie studio feel.

00:02:40.740 --> 00:02:44.400
So that's the backdrop you both have going on, which is excellent.

00:02:44.400 --> 00:02:44.940
Yeah.

00:02:44.940 --> 00:02:45.400
Yeah.

00:02:45.400 --> 00:02:45.780
Yeah.

00:02:45.780 --> 00:02:48.140
It's pretty nice to work at Netflix.

00:02:48.360 --> 00:02:49.860
It's a very good company.

00:02:49.860 --> 00:02:50.940
I'm very happy.

00:02:50.940 --> 00:02:52.740
A lot of Python we're going to learn.

00:02:52.740 --> 00:02:53.200
Yes.

00:02:53.200 --> 00:02:53.540
Yeah.

00:02:53.540 --> 00:02:54.680
We do use a lot of Python.

00:02:54.680 --> 00:02:55.200
Yeah.

00:02:55.200 --> 00:02:56.440
Excellent.

00:02:56.440 --> 00:03:01.900
So we're going to talk about Python and Netflix, a wide ranging sort of survey of a lot of projects

00:03:01.900 --> 00:03:02.680
you all have created.

00:03:02.680 --> 00:03:03.700
How are you using it?

00:03:03.700 --> 00:03:09.480
Some other ones that you both of you personally created, either tied to or not tied to Netflix.

00:03:09.480 --> 00:03:13.600
But I think people are going to really enjoy this look inside what you all got going on.

00:03:13.600 --> 00:03:15.880
Before we get to that, though, let's start with your stories.

00:03:15.880 --> 00:03:17.000
Quick introduction.

00:03:17.000 --> 00:03:19.680
How do you get here working on Python?

00:03:19.680 --> 00:03:20.820
Soren, you want to go first?

00:03:20.820 --> 00:03:21.140
Yeah.

00:03:21.140 --> 00:03:26.000
So I was hooked into programming ever since I saw my first computer.

00:03:26.620 --> 00:03:28.180
Age of 13 in middle school.

00:03:28.180 --> 00:03:30.100
I was in Amstrad CPC.

00:03:30.100 --> 00:03:30.600
Right.

00:03:30.600 --> 00:03:33.340
I was like, yeah, that was the thing I wanted to do.

00:03:33.340 --> 00:03:36.820
So yeah, I started programming as a hobby at first.

00:03:36.820 --> 00:03:42.060
And fun fact, way back then, later on in high school, one of my math teachers told me, hey,

00:03:42.160 --> 00:03:44.220
do something real, don't do programming.

00:03:44.220 --> 00:03:48.060
It's like a dead end, you know, you won't be able to find a job.

00:03:48.060 --> 00:03:55.380
Did they tell you things like these drag and drop visual tools are going to replace all the

00:03:55.380 --> 00:04:00.420
programmers and like the low code of the 80s and 90s, maybe?

00:04:00.420 --> 00:04:00.900
Yeah.

00:04:00.900 --> 00:04:02.480
You know, yeah.

00:04:02.480 --> 00:04:06.940
Back then, I guess it was very, well, didn't seem that obvious.

00:04:06.940 --> 00:04:07.180
Yeah.

00:04:07.180 --> 00:04:07.540
Yeah.

00:04:07.540 --> 00:04:12.000
And then, yeah, I decided to go computer science anyway, because

00:04:12.000 --> 00:04:13.540
that's what I wanted to do.

00:04:13.540 --> 00:04:19.880
And then I spent the vast majority of my career in a language that is not very much known or

00:04:19.880 --> 00:04:21.260
used, I think, iPhone.

00:04:21.260 --> 00:04:25.360
So I spent more than a decade on doing iPhone mostly.

00:04:25.360 --> 00:04:29.340
And then I discovered Python once I joined LinkedIn in 2011.

00:04:29.340 --> 00:04:35.860
And that's when I kind of, well, got hooked and decided to do more and more things Python.

00:04:35.860 --> 00:04:41.440
And now at Netflix, even more so trying to support NetPython across the board.

00:04:41.840 --> 00:04:47.780
You're kind of doing MetaPython in the sense that your team does a lot of stuff to facilitate

00:04:47.780 --> 00:04:49.560
other people doing Python too, right?

00:04:49.560 --> 00:04:50.340
Exactly.

00:04:50.340 --> 00:04:50.720
Yes.

00:04:50.720 --> 00:04:51.140
Yeah.

00:04:51.140 --> 00:04:53.100
That's our team at Netflix.

00:04:53.100 --> 00:04:58.720
Like we enable other Python developers to be more productive by building tools or building

00:04:58.720 --> 00:05:04.380
the infrastructure necessary to ship their code faster or build their products sooner, things

00:05:04.380 --> 00:05:04.760
like that.

00:05:04.760 --> 00:05:05.000
Yeah.

00:05:05.000 --> 00:05:05.260
Cool.

00:05:05.880 --> 00:05:06.620
How about you, Amjith?

00:05:06.620 --> 00:05:10.340
Oh, I got introduced to programming in high school.

00:05:10.340 --> 00:05:13.360
We had like one hour of computer lab every week.

00:05:13.360 --> 00:05:15.660
I got to learn GW Basic.

00:05:15.660 --> 00:05:17.300
That was my first language.

00:05:17.300 --> 00:05:18.200
It was fantastic.

00:05:18.200 --> 00:05:22.280
I still have fond memories of like trying to draw circles on the screen.

00:05:22.280 --> 00:05:23.760
And then I went to college.

00:05:23.980 --> 00:05:25.160
I learned C and C++.

00:05:25.160 --> 00:05:26.340
I liked those.

00:05:26.340 --> 00:05:30.620
But then after I got a job, I wanted to learn, you know, how to be a better programmer.

00:05:30.620 --> 00:05:33.200
And somebody mentioned, you know, oh, functional programming is the bee's knees.

00:05:33.200 --> 00:05:36.640
You should actually, you know, if you learn how to do functional programming, your general

00:05:36.640 --> 00:05:37.760
programming will get better.

00:05:37.760 --> 00:05:40.840
And the best language to learn functional programming is Haskell.

00:05:40.840 --> 00:05:44.220
And so I took a book called Learn You a Haskell.

00:05:44.220 --> 00:05:47.920
And then I went through like the first few chapters and it was mind blowing.

00:05:47.920 --> 00:05:49.940
It was like a really fantastic language.

00:05:49.940 --> 00:05:55.300
And I got first introduced to a concept of REPL and like trying out like little snippets in

00:05:55.300 --> 00:05:56.800
the interpreter and getting answers.

00:05:56.800 --> 00:05:57.560
And it was fantastic.

00:05:57.560 --> 00:06:02.140
And I got introduced to list comprehension in Haskell and it was just mind blowing.

00:06:02.140 --> 00:06:06.180
It's like, you know, without having to write a, write like five lines of for loop, you could

00:06:06.180 --> 00:06:08.160
just, it's a single line thing.

00:06:08.160 --> 00:06:14.420
And I quickly realized that, you know, you can't find actual jobs writing Haskell or at

00:06:14.420 --> 00:06:15.180
least, you know, not.

00:06:15.180 --> 00:06:22.540
So I figured out like, what's a language that has list comprehension that is actually employable,

00:06:22.540 --> 00:06:24.280
you know, that I could find jobs.

00:06:24.280 --> 00:06:28.340
And that's how I found Python because I came to Python because of list comprehension.

00:06:28.340 --> 00:06:29.360
Oh, awesome.

00:06:29.360 --> 00:06:29.700
Yeah.

00:06:29.700 --> 00:06:30.040
Okay.

00:06:30.540 --> 00:06:33.200
Learn You a Haskell for Great Good, a beginner's guide.

00:06:33.200 --> 00:06:33.800
Is that the book?

00:06:33.800 --> 00:06:34.920
That is the book.

00:06:34.920 --> 00:06:35.200
Yeah.

00:06:35.200 --> 00:06:39.260
And it's actually still available online for free that anybody could read.

00:06:39.260 --> 00:06:40.060
I'm fairly certain.

00:06:40.060 --> 00:06:42.760
And I actually bought like a paper copy of the book.

00:06:42.760 --> 00:06:43.980
It's, it's a good book.

00:06:43.980 --> 00:06:45.380
It's fun one to go through.

00:06:45.380 --> 00:06:46.120
Yeah.

00:06:46.120 --> 00:06:48.680
It looks like it's really got a playful nature to it.

00:06:48.680 --> 00:06:49.440
Yeah, exactly.

00:06:49.440 --> 00:06:50.060
Yeah.

00:06:50.060 --> 00:06:55.180
You know, your thoughts about list comprehension really connects with me as well.

00:06:55.180 --> 00:07:00.360
I guess my first exposure to something like that was LINQ, L-I-N-Q and C-sharp.

00:07:00.440 --> 00:07:00.720
Mm-hmm.

00:07:00.720 --> 00:07:04.040
Which is, it's, honestly, I think it's better than Python list comprehensions.

00:07:04.040 --> 00:07:06.300
I wish Python had just a little bit more.

00:07:06.300 --> 00:07:06.980
Nice.

00:07:06.980 --> 00:07:07.580
A little bit.

00:07:07.580 --> 00:07:09.240
Just one or two things more.

00:07:09.240 --> 00:07:13.540
For example, wouldn't it be nice in a list comprehension if you could specify a sort?

00:07:13.540 --> 00:07:14.220
Mm-hmm.

00:07:14.220 --> 00:07:19.500
Because I find myself often doing a list comprehension and then sorting the thing in the end afterwards.

00:07:19.500 --> 00:07:25.960
But if you could just say order by and give it an expression like you would to lambda, pass a lambda over to a, you know.

00:07:25.960 --> 00:07:27.600
So there's room for more.

00:07:27.600 --> 00:07:27.960
What is it?

00:07:27.960 --> 00:07:30.560
What PEP do I need to write to get sort in a list comprehension?

00:07:30.560 --> 00:07:31.640
I don't know, but I want it.

00:07:31.640 --> 00:07:32.100
Yeah.

00:07:32.100 --> 00:07:32.700
Yeah.

00:07:32.700 --> 00:07:35.960
So I really think that that's a cool language feature.

00:07:35.960 --> 00:07:42.780
And, you know, it's also one of the areas that they're applying some of these speedups in the faster CPython work that's coming.

00:07:42.780 --> 00:07:46.720
And they're doing, you know, list comprehensions for isolation purposes.

00:07:46.720 --> 00:07:53.620
And Python 3 are basically hidden function calls with their own stack frame and variables that you don't actually see, right?

00:07:53.620 --> 00:07:54.060
Mm-hmm.

00:07:54.060 --> 00:07:56.300
You don't write it, but that's kind of the execution level.

00:07:56.300 --> 00:07:58.820
And now they're inlining those to make them a little bit faster.

00:07:58.820 --> 00:07:59.500
Nice.

00:07:59.500 --> 00:08:00.360
I don't know.

00:08:00.360 --> 00:08:00.740
Yeah.

00:08:00.740 --> 00:08:04.120
I think the faster Python team is doing like a fantastic job.

00:08:04.120 --> 00:08:11.400
Like there was a talk that I attended at PyCon, not this year, but the previous year, where they introduced like switch case, how they were doing the case statements.

00:08:11.720 --> 00:08:15.940
It's not the exact switch case, but, you know, coming from C and C++, I knew what switch cases are.

00:08:15.940 --> 00:08:24.200
And when I saw what is possible with the pattern matching, like structural pattern matching in Python, it's like take switch case and then like turn it up to 11.

00:08:24.200 --> 00:08:25.280
And that's what this is.

00:08:25.280 --> 00:08:26.040
And you're right.

00:08:26.040 --> 00:08:30.040
I mean, there is always more that can be done, but I think it's going in a great direction.

00:08:30.040 --> 00:08:31.740
I think it's fantastic.

00:08:31.740 --> 00:08:32.200
Yeah.

00:08:32.200 --> 00:08:33.220
Let's talk about that.

00:08:33.220 --> 00:08:37.020
I mean, we're going to dive into the details of Netflix and stuff.

00:08:37.020 --> 00:08:45.180
But just, you know, this whole Python 3.11, 3.12, these are really big performance improvements coming along.

00:08:45.180 --> 00:08:45.440
Yeah.

00:08:45.440 --> 00:08:48.240
Are you able yet to take advantage of those at Netflix?

00:08:48.240 --> 00:08:49.680
And is that making a big difference?

00:08:49.680 --> 00:08:56.420
You know, like, are you guys still running, you know, 3.8 or are you more closer to the cutting edge in terms of releases?

00:08:56.740 --> 00:09:03.760
So I think one of the advantages here at Netflix is that every team has the freedom to choose the tools that they need to use.

00:09:03.760 --> 00:09:10.820
And it's great and also kind of painful for central teams because now, you know, there is like a bifurcation of all kinds of different versions out there.

00:09:10.820 --> 00:09:17.160
But where I'm going with this is that every team is allowed to choose what is what they need to use in order to get their job done.

00:09:17.160 --> 00:09:25.320
And so my previous team, we were at the cutting edge, like we used 3.11 or we still use 3.11 in the projects that we built and the services that we used.

00:09:25.320 --> 00:09:26.840
And it is a nice boost.

00:09:26.840 --> 00:09:28.360
Like we could certainly see.

00:09:28.360 --> 00:09:35.540
So, for instance, there is like a periodic job that runs and it's like a sort of a cron job that runs every five minutes or so.

00:09:35.540 --> 00:09:42.200
And we had put in like so much optimization so that it will actually finish within the five minutes because we were doing a lot of data crunching and so forth.

00:09:42.540 --> 00:09:45.660
And just so we don't like stack up the cron tasks.

00:09:45.660 --> 00:09:52.340
But when we switched from, I think from like we did jump from 3.9 to 3.11 directly, we didn't we did not like go to 3.10.

00:09:52.340 --> 00:09:58.520
But then when we jumped, it felt like, you know, things that were taking like four minutes were now finishing in like two minutes.

00:09:58.520 --> 00:10:02.940
And it was it was like it was like a huge improvement that you could see.

00:10:02.940 --> 00:10:04.860
And like it felt very rewarding to see that.

00:10:04.860 --> 00:10:05.720
So, yeah, absolutely.

00:10:05.720 --> 00:10:08.060
So every team gets to choose what they want to use.

00:10:08.060 --> 00:10:17.560
And our job as a central Python team that Zoran and I are currently part of is to try and enable people to use that use whatever is the latest that is available.

00:10:17.560 --> 00:10:29.240
So, you know, whatever internal tools that we have, we have to make sure that it actually gets exercised in the latest Python version that got released and make sure that everything is building and deploying as they are supposed to do.

00:10:29.240 --> 00:10:29.720
And so on.

00:10:29.720 --> 00:10:30.540
OK, excellent.

00:10:30.700 --> 00:10:31.600
That's pretty cool.

00:10:31.600 --> 00:10:33.540
That story is speeding up your cron jobs.

00:10:33.540 --> 00:10:34.040
That's.

00:10:34.040 --> 00:10:34.360
Yes.

00:10:34.360 --> 00:10:35.560
That's a non-trivial.

00:10:35.560 --> 00:10:39.280
And it's probably wasn't a lot of work to move from 3.9 to 3.11.

00:10:39.280 --> 00:10:43.500
I know my upgrade path was rebuild some virtual environments on the server.

00:10:43.500 --> 00:10:44.480
And now we're good to go.

00:10:44.480 --> 00:10:45.460
Exactly.

00:10:45.460 --> 00:10:45.880
Yeah.

00:10:45.880 --> 00:10:46.400
Yeah.

00:10:46.400 --> 00:10:47.560
Yeah.

00:10:47.560 --> 00:10:47.900
Yeah.

00:10:47.900 --> 00:10:51.820
So, Ren, do you want to add about that 3.11, faster CPython side?

00:10:51.820 --> 00:10:52.300
Oh, yeah.

00:10:52.300 --> 00:10:54.060
So, yeah, absolutely.

00:10:54.060 --> 00:10:54.880
It's so faster.

00:10:54.880 --> 00:10:56.100
So much faster.

00:10:56.100 --> 00:10:56.380
Yeah.

00:10:56.380 --> 00:11:02.360
The main issue when upgrading is the lack of wheels if you're like stuck on older libraries.

00:11:02.360 --> 00:11:05.020
But we do have like a few numbers.

00:11:05.020 --> 00:11:08.720
Like the most used right now is Python 3.10 across the board, right?

00:11:08.720 --> 00:11:10.340
It will depend on the team, right?

00:11:10.340 --> 00:11:13.080
Everybody is upgrading at their own pace.

00:11:13.080 --> 00:11:15.720
And 3.11 is starting to grow a bit.

00:11:15.720 --> 00:11:19.540
But yeah, most used right now is 3.10 statically.

00:11:19.540 --> 00:11:26.600
Honestly, that sounds really quite good for a company the size of Netflix and how much Python you're doing.

00:11:26.600 --> 00:11:28.800
That's pretty close to pushing the envelope.

00:11:28.800 --> 00:11:29.280
Yeah.

00:11:29.280 --> 00:11:34.720
And there are still some teams that are sort of stuck on 3.8 or 3.7, I want to say.

00:11:34.720 --> 00:11:40.680
Simply because they provide a platform that allows data scientists to write their code.

00:11:40.680 --> 00:11:47.220
And they have this pre-built image with all of the necessary libraries pre-installed in there.

00:11:47.220 --> 00:11:53.640
And so they have like a pretty tight control over which libraries will get upgraded on what cadence and so on.

00:11:53.640 --> 00:11:57.800
And so for them, I think they're still running on 3.7.

00:11:57.800 --> 00:12:03.700
And I'm sure when they switch to 3.10 or 3.11, it's going to be like a screaming fast improvement.

00:12:03.700 --> 00:12:06.340
So I'm looking forward to that migration to happen.

00:12:06.340 --> 00:12:07.060
Yeah, excellent.

00:12:07.060 --> 00:12:09.060
This number is very static, right?

00:12:09.060 --> 00:12:13.100
It's a number of like pre-short Pythons across repos.

00:12:13.100 --> 00:12:15.560
But yeah, dynamically, right?

00:12:15.560 --> 00:12:20.980
Like you may have lots of instances who still run on 3.7 and they will massively move to a...

00:12:20.980 --> 00:12:24.080
So that team is moving from 3.7 to 3.10, for example.

00:12:24.080 --> 00:12:24.360
Right.

00:12:24.360 --> 00:12:25.120
Yeah.

00:12:25.120 --> 00:12:26.340
Yeah, so upgrade paths.

00:12:28.600 --> 00:12:32.700
This portion of Talk Python To Me is brought to you by JetBrains and PyCharm.

00:12:32.700 --> 00:12:37.500
Are you a data scientist or a web developer looking to take your projects to the next level?

00:12:37.500 --> 00:12:40.180
Well, I have the perfect tool for you, PyCharm.

00:12:40.180 --> 00:12:49.480
PyCharm is a powerful integrated development environment that empowers developers and data scientists like us to write clean and efficient code with ease.

00:12:49.720 --> 00:12:55.820
Whether you're analyzing complex data sets or building dynamic web applications, PyCharm has got you covered.

00:12:55.820 --> 00:13:02.960
With its intuitive interface and robust features, you can boost your productivity and bring your ideas to life faster than ever before.

00:13:02.960 --> 00:13:09.120
For data scientists, PyCharm offers seamless integration with popular libraries like NumPy, Pandas, and Matplotlib.

00:13:09.120 --> 00:13:16.280
You can explore, visualize, and manipulate data effortlessly, unlocking valuable insights with just a few lines of code.

00:13:16.280 --> 00:13:20.920
And for us web developers, PyCharm provides a rich set of tools to streamline your workflow.

00:13:20.920 --> 00:13:29.920
From intelligent code completion to advanced debugging capabilities, PyCharm helps you write clean, scalable code that powers stunning web applications.

00:13:29.920 --> 00:13:38.200
Plus, PyCharm's support for popular frameworks like Django, FastAPI, and React make it a breeze to build and deploy your web projects.

00:13:38.580 --> 00:13:43.140
It's time to say goodbye to tedious configuration and hello to rapid development.

00:13:43.140 --> 00:13:44.660
But wait, there's more!

00:13:44.660 --> 00:13:53.380
With PyCharm, you get even more advanced features like remote development, database integration, and version control, ensuring your projects stay organized and secure.

00:13:53.380 --> 00:13:58.840
So whether you're diving into data science or shaping the future of the web, PyCharm is your go-to tool.

00:13:58.840 --> 00:14:00.900
Join me and try PyCharm today.

00:14:00.900 --> 00:14:07.020
Just visit talkpython.fm/done-with-pycharm, links in your show notes,

00:14:07.680 --> 00:14:11.560
and experience the power of PyCharm firsthand for three months free.

00:14:11.560 --> 00:14:12.740
PyCharm.

00:14:12.740 --> 00:14:14.480
It's how I get work done.

00:14:16.960 --> 00:14:23.540
Let's start by talking about kind of the broad story of Python at Netflix.

00:14:23.540 --> 00:14:29.900
Maybe we could start with what you all do day-to-day in terms of what's your role?

00:14:29.900 --> 00:14:33.880
Because you kind of support other people's Python, as I hinted before.

00:14:33.880 --> 00:14:35.920
So maybe we could get a sense of what you all do day-to-day.

00:14:35.920 --> 00:14:36.840
And then we'll...

00:14:36.840 --> 00:14:43.960
Omg, you wrote a nice blog article that's a big, broad, pure survey of how Python's being used in all these different places.

00:14:43.960 --> 00:14:47.740
So maybe start with what you all do day-to-day on your team, and then we'll go into that.

00:14:47.740 --> 00:14:48.460
Yeah, sure thing.

00:14:48.460 --> 00:14:51.060
I've been with Netflix for about six years now.

00:14:51.300 --> 00:14:57.520
And previously, I was in a different team, and we were doing failovers, which was a way of running...

00:14:57.520 --> 00:15:02.140
You know, if Netflix ever goes down in one of the AWS regions, we are the team that gets paged in,

00:15:02.140 --> 00:15:05.460
and we go and move all the traffic from that region to another...

00:15:05.460 --> 00:15:06.680
Other two regions that we run in.

00:15:06.680 --> 00:15:10.760
So that's what I was doing up until, like, February of this year.

00:15:10.860 --> 00:15:13.440
And let me just take a step back real quick with you.

00:15:13.440 --> 00:15:16.000
Netflix is kind of all in on AWS, right?

00:15:16.000 --> 00:15:22.980
Like, there's been a lot of stories about how you all have set loose the chaos monkey into your data centers

00:15:22.980 --> 00:15:26.300
and how you worked on failover from AWS regions.

00:15:26.300 --> 00:15:30.140
And so I don't know if you all are the largest users of AWS,

00:15:30.140 --> 00:15:34.940
but certainly one of the more interesting, complicated deployments out there, right?

00:15:34.940 --> 00:15:40.460
Yeah, so I think we were the earliest adopters of cloud computing when AWS first came out.

00:15:40.680 --> 00:15:46.580
And so AWS has used as the poster child for, you know, see, big companies can run in cloud,

00:15:46.580 --> 00:15:48.060
and you don't have to be on-prem.

00:15:48.060 --> 00:15:55.160
And so we think of them as partners, not so much as, you know, like this client-owner relationship or anything like that.

00:15:55.160 --> 00:15:58.520
So we consider AWS as our business partners.

00:15:58.520 --> 00:16:00.960
And yes, we are full in on AWS.

00:16:00.960 --> 00:16:05.720
And Chaos Monkey, even now, yes, it functions in AWS.

00:16:05.720 --> 00:16:10.440
Like, it goes around, and just inside our VPC, it does terminate instances,

00:16:10.500 --> 00:16:15.280
occasionally, or not occasionally, like once every day, one instance every day on every service.

00:16:15.280 --> 00:16:17.300
That is so wild.

00:16:17.300 --> 00:16:22.160
I mean, obviously, you don't want to set it loose on other people's AWS instances, right?

00:16:22.160 --> 00:16:23.560
Yeah.

00:16:23.660 --> 00:16:34.180
But no, that's a really interesting way to force people to think about developers and infrastructure folks to think about what happens if the cloud somehow, your server dies.

00:16:34.180 --> 00:16:35.540
And maybe it's not even the cloud's fault, right?

00:16:35.540 --> 00:16:38.220
It's just like, okay, there's a Linux machine running, and that thing died.

00:16:38.220 --> 00:16:39.440
It could have been running anywhere.

00:16:39.440 --> 00:16:40.780
It happened to be in AWS.

00:16:41.040 --> 00:16:43.880
But to force them to think about it going, like, we will.

00:16:43.880 --> 00:16:45.560
It's not an eventuality.

00:16:45.560 --> 00:16:46.420
This will happen.

00:16:46.420 --> 00:16:47.620
And so you plan for it.

00:16:47.720 --> 00:16:47.840
Yeah.

00:16:48.200 --> 00:16:53.100
It's even more than just the idea of, like, it will happen, so we plan for it thing.

00:16:53.100 --> 00:17:00.120
It's more like, you know, it's a way of building software where you need to build software that's resilient and has enough fallbacks built in.

00:17:00.120 --> 00:17:09.760
And so, for instance, if you are not able to reach the database, do you have a cache in front that can sort of, you know, keep the thing going for the few network calls that are failing to reach the database?

00:17:09.760 --> 00:17:20.300
Those are, like, basic common things, paradigms that have become commonplace nowadays in software development where, you know, building fallbacks automatically is like standard practice these days.

00:17:20.300 --> 00:17:26.500
But when Chaos Monkey was created, which was about 10 years ago, you know, these were, like, new concepts that people were not using.

00:17:26.760 --> 00:17:37.580
And it was assumed that, you know, once you have a server and you put your software on the server and you run it, it's basically done, like, until you do the next deploy, which takes another month or so to refresh that server, refresh that code.

00:17:37.580 --> 00:17:44.960
But that all changed once we went to cloud where, you know, we started doing deployments on a daily basis or maybe even more hourly basis and things like that.

00:17:44.960 --> 00:17:54.220
And so when you are doing that, you know, when you are shutting down one server with old version and bringing up the new server with a new version, how are you going to make sure that the connections are not going to fall?

00:17:54.400 --> 00:17:57.940
And how are you going to make sure that the network continuity continues and so forth?

00:17:57.940 --> 00:18:04.680
So, yeah, Chaos Monkey was just introduced as a way to ensure that people are building software in a way that is resilient.

00:18:04.680 --> 00:18:09.100
And this is just a way to sort of test that on an ongoing basis.

00:18:09.100 --> 00:18:11.340
Yeah, it's quite an operational challenge.

00:18:11.340 --> 00:18:15.760
I mean, I don't recall seeing Netflix saying, our scheduled maintenance is coming up on Sunday.

00:18:15.760 --> 00:18:17.180
We'll be down for five hours.

00:18:17.180 --> 00:18:19.180
Not acceptable, is it?

00:18:19.180 --> 00:18:21.600
It just makes you laugh when you think about it.

00:18:21.600 --> 00:18:23.240
Especially not on a Sunday.

00:18:23.240 --> 00:18:23.500
Okay.

00:18:23.500 --> 00:18:26.420
I've even seen government sites.

00:18:26.420 --> 00:18:29.920
I can't remember which government it was saying that the website was closed.

00:18:29.920 --> 00:18:31.460
Like the website had business hours.

00:18:31.460 --> 00:18:32.260
That's a different deal.

00:18:32.260 --> 00:18:34.860
Like you came at night, like, oh, you can't come here right now.

00:18:34.860 --> 00:18:35.420
It's like, what?

00:18:35.420 --> 00:18:35.740
Yeah.

00:18:35.740 --> 00:18:36.200
It's the web.

00:18:36.200 --> 00:18:37.480
I don't understand what's going on.

00:18:37.480 --> 00:18:38.560
All right.

00:18:38.560 --> 00:18:45.020
So let's go through this blog post that you wrote here entitled just Python at Netflix on the Netflix technology blog.

00:18:45.020 --> 00:18:45.520
Yeah.

00:18:45.520 --> 00:18:48.180
So you wrote this in preparation of PyCon.

00:18:48.180 --> 00:18:49.600
This is PyCon 2023?

00:18:49.600 --> 00:18:52.020
No, this was 2019, actually.

00:18:52.020 --> 00:18:56.160
So this is old by at least two or three days, three years now.

00:18:56.160 --> 00:18:56.680
Okay.

00:18:56.680 --> 00:18:57.020
Yeah.

00:18:57.020 --> 00:19:03.340
You had pointed out before we press record that some of these projects mentioned here that used to be internal things are now also open source.

00:19:03.340 --> 00:19:07.040
So there's a little more access to these than the blog posts might indicate.

00:19:07.260 --> 00:19:07.420
Yeah.

00:19:07.420 --> 00:19:11.200
Some of the things that are mentioned here, yes, they have been open source since then.

00:19:11.200 --> 00:19:16.520
So specifically the one that I remember right now is Metaflow, which is a infrastructure.

00:19:16.520 --> 00:19:33.000
It's like a platform orchestration infrastructure framework that is used by our machine learning organization where, you know, scientists would try and build their model or they use existing models from like XGBoost or like tons of other Python libraries.

00:19:33.640 --> 00:19:43.840
And their interest and their expertise lies in, you know, crafting those models, training those models and building the correct algorithm to do the predictions and so on.

00:19:43.840 --> 00:20:00.080
They are not so interested in like, you know, making sure that enough compute is available to run these models or they're not interested in making sure that the plumbing works or this model's data is now going to the next step of this algorithm or even like getting it deployed and making it available in the production environment.

00:20:00.080 --> 00:20:04.480
So that's all that abstraction is taken care of by Metaflow.

00:20:04.480 --> 00:20:14.680
So Metaflow is the project that was mentioned here and that allows you to make it easy for machine learning folks to get their system running and as well as deploying it out to production.

00:20:14.680 --> 00:20:19.160
And now that is now open sourced and it is available for folks to use.

00:20:19.160 --> 00:20:22.480
And I think some other companies have actually adopted to using that as well.

00:20:22.480 --> 00:20:23.260
So, yeah.

00:20:23.260 --> 00:20:28.880
Kind of operate like a DevOps-y automation for machine learning.

00:20:28.880 --> 00:20:34.060
So the people they're writing, creating the models and the data scientists don't have to also be DevOps people.

00:20:34.060 --> 00:20:34.520
Right.

00:20:34.520 --> 00:20:44.800
It's slightly more than DevOps as well because it also does the pipelining work to make it possible for someone to, you know, bring the data from this database and load it in.

00:20:45.080 --> 00:20:50.700
All of that work is already taken care of or at least there are libraries that are built into Metaflow that makes it possible to bring those in.

00:20:50.700 --> 00:20:53.100
And then it allows you to also do orchestration.

00:20:53.100 --> 00:20:57.520
So, for instance, machine learning models typically happen in multi-steps and multi-stages.

00:20:57.820 --> 00:21:04.400
And so the data gets processed by this function and then it gets moved on to this other function and then it gets moved on to this other thing and so forth.

00:21:04.400 --> 00:21:10.900
And so it does the plumbing to make sure that the data can flow through this topology and actually produce results and so on.

00:21:10.900 --> 00:21:11.100
Yeah.

00:21:11.100 --> 00:21:11.480
Yeah.

00:21:11.480 --> 00:21:14.360
You probably have enough data that that's a lot of data to move.

00:21:14.760 --> 00:21:16.760
All right.

00:21:16.760 --> 00:21:30.620
A quick question from the audience before we dive into the topics here is Diego asks, on such a big platform with so many software engineers with different coding practices, do you all get together and follow some set norms by Netflix or is it more team by team basis?

00:21:30.620 --> 00:21:32.700
It is very much team by team basis.

00:21:32.700 --> 00:21:35.900
So each team has their style and their areas that they focus on.

00:21:35.900 --> 00:21:45.040
So, for instance, like machine learning engineers are not going to care too much about like, how do I make this like, you know, production grade, like super heavily fortified or whatever.

00:21:45.040 --> 00:21:48.200
And security engineers might be focusing on completely different things.

00:21:48.200 --> 00:21:49.800
So it is different.

00:21:49.800 --> 00:22:00.600
But at the same time, I do want to mention that there are certain norms that are common across the entire company where, you know, so for instance, Chaos Monkey is one of those things where since since Netflix operates in a way,

00:22:00.600 --> 00:22:12.880
where, you know, every team is given the freedom to choose and operate the way they see fit, there is no edict that can come from a VP or a president that says, like, you must write code in this way, like that doesn't happen.

00:22:12.880 --> 00:22:24.020
And so what that means is, how are you going to enforce, like, you know, you have to write resilient software or how are you going to make sure that your software will continue to run if one of the servers out of the hundred servers has gone down?

00:22:24.020 --> 00:22:26.360
And so there is not a good way to enforce that.

00:22:26.600 --> 00:22:36.780
And Chaos Monkey was created as a way to enforce that, which is, yes, we're not going to be able to tell you how to write software, but this particular service that exists, it's going to go around killing servers.

00:22:36.780 --> 00:22:40.980
And so you better make sure that your software is actually resilient to servers going down.

00:22:40.980 --> 00:22:48.600
So that's a way in which we influence people to write the, to produce the right outcome without telling them how to do it.

00:22:48.600 --> 00:22:58.580
I see. So sort of, you agree on a common principle of design for failure and design for resiliency, and then it's up to people how to make that happen.

00:22:58.580 --> 00:23:08.220
Yes. And also we have the concept of paved paths, our paved road, which is we have certain libraries that are made to operate within our infrastructure.

00:23:08.220 --> 00:23:15.460
So there is an internal discovery tool and there is an internal metrics collection tool and there is an internal, you know, like a failure recovery tool and so forth.

00:23:15.720 --> 00:23:23.620
And these libraries that are provided in these languages, they make it really that simple to just integrate with these, with these services.

00:23:23.620 --> 00:23:30.300
And so it makes it the obvious choice for people to start using those libraries rather than, you know, paving their own path, for instance.

00:23:30.300 --> 00:23:30.480
Right.

00:23:30.720 --> 00:23:34.620
So we try and make it as easy as possible to do the right thing.

00:23:34.620 --> 00:23:38.820
And so people generally like fall into that paved road solutions that we have.

00:23:38.820 --> 00:23:39.220
Excellent.

00:23:39.220 --> 00:23:46.660
And we try to make it also now, especially as a central Python team to promote good practices, right?

00:23:46.660 --> 00:23:50.240
Like you should have a pipeline, you should choose a release strategy.

00:23:50.240 --> 00:23:53.580
You should have tests and we, we help.

00:23:53.580 --> 00:24:00.020
If you don't, we can help you set that up and choose a good relevance release strategy for you, et cetera.

00:24:00.020 --> 00:24:00.320
Excellent.

00:24:00.320 --> 00:24:01.460
Yeah, that's, that's really good.

00:24:01.460 --> 00:24:03.600
So let's dive into this blog post.

00:24:03.600 --> 00:24:08.220
Now it was written by Amjit, but Soren, jump in as well as, as we talk about, please.

00:24:08.220 --> 00:24:12.340
So the first one is related to bandwidth.

00:24:12.340 --> 00:24:14.020
To some what?

00:24:14.020 --> 00:24:15.600
Like delivering the content.

00:24:15.600 --> 00:24:18.020
And there's some interesting articles and stuff.

00:24:18.020 --> 00:24:21.060
How much of the internet's bandwidth does Netflix use?

00:24:21.060 --> 00:24:26.760
And I don't know how accurate this is, but maybe give us a sense of like, you got to have a lot of traffic, right?

00:24:26.760 --> 00:24:27.260
Yes.

00:24:27.400 --> 00:24:35.800
So I think when I first joined Netflix, I was told that we use about one third of all of internet's bandwidth, but that was back in 2017.

00:24:35.800 --> 00:24:37.900
So things have changed quite a bit since then.

00:24:38.980 --> 00:24:50.120
Our use of bandwidth is slightly interesting in the sense the actual, when somebody goes to their website and they're browsing around, all of that data is served directly from AWS servers.

00:24:50.560 --> 00:25:00.960
And so we have servers running in AWS that does the search functionality, the thumbs up, the thumbs down, the, you're selecting something and reading the review or looking at related things and whatnot.

00:25:00.960 --> 00:25:12.560
But as soon as they click on the play button on a particular video, the actual video file itself is not streaming from AWS, but instead it's coming from a CDN called Open Connect.

00:25:12.960 --> 00:25:30.340
And this is a proprietary thing that we built where we ship these CDNs to various internet exchanges that are already, you know, filled with the right videos and they get populated with the correct, correct videos that are getting released like overnight or on a regular basis.

00:25:30.420 --> 00:25:36.420
The reason we do that is because we want the videos to stream from the closest possible place for the end user.

00:25:36.420 --> 00:25:42.040
And so when a end user in Florida clicks on it, it's coming from an internet exchange that is located in Florida.

00:25:42.040 --> 00:25:50.440
And that's why you don't see a lot of buffering when videos are playing from Netflix is because there's, you know, it's inside their, their network to a large extent.

00:25:50.440 --> 00:25:51.900
That's our Open Connect team.

00:25:51.900 --> 00:25:53.040
And that's, that's what they do.

00:25:53.040 --> 00:25:53.920
And yeah.

00:25:53.920 --> 00:25:54.100
Yeah.

00:25:54.100 --> 00:25:56.180
That's CDNs are awesome.

00:25:56.180 --> 00:25:59.920
And they really are just, they're kind of a bit of magic performance.

00:25:59.920 --> 00:26:08.280
performance dust you can sprinkle on, on sites that works for SS, for CSS and JavaScript and stuff.

00:26:08.280 --> 00:26:11.920
But, but when it comes to large content, then it makes all the difference.

00:26:11.920 --> 00:26:12.280
Yeah.

00:26:12.280 --> 00:26:15.220
So in the blog post you write, let's see.

00:26:15.220 --> 00:26:15.880
Yeah.

00:26:15.880 --> 00:26:20.260
It says various software systems are needed to design and build and operate the CDN infrastructure.

00:26:20.260 --> 00:26:22.860
And a big part of them are written in Python.

00:26:22.860 --> 00:26:28.220
The network devices that underlie a large portion of it are mostly managed by Python and so on.

00:26:28.260 --> 00:26:30.760
Give us a sense of where Python fits in this.

00:26:30.760 --> 00:26:31.260
Right.

00:26:31.260 --> 00:26:33.220
Open Connect CDN that you all run.

00:26:33.220 --> 00:26:33.580
Sure.

00:26:33.580 --> 00:26:33.940
Yeah.

00:26:33.940 --> 00:26:38.740
So the CDNs themselves run like high performance code to, to stream the video.

00:26:38.740 --> 00:26:43.820
That obviously that software is not written in Python, but the software, all the software that orchestrates

00:26:43.820 --> 00:26:48.060
and makes sure that these CDNs are remaining healthy, getting metrics out of them, as well as,

00:26:48.060 --> 00:26:53.260
you know, managing them and forecasting, like what sort of videos are going to be going into these,

00:26:53.400 --> 00:26:57.540
these CDNs and so forth, those are all orchestrated using Python applications.

00:26:57.540 --> 00:26:58.960
So these are all internal tools.

00:26:58.960 --> 00:27:00.600
There's like an OC tools team.

00:27:00.600 --> 00:27:03.180
OC stands for the Open Connect, which is the name of the CDN.

00:27:03.180 --> 00:27:05.740
And OC tools team is the one that builds that.

00:27:05.740 --> 00:27:11.760
And they use quite a lot of Python for not just tracking our CDNs, but also for projecting, you know,

00:27:12.080 --> 00:27:14.300
which videos and what shapes they should be going into.

00:27:14.300 --> 00:27:18.460
So for instance, like to give you a quick example, like if we are launching, let's say like Stranger Things,

00:27:18.460 --> 00:27:22.800
like the newest season, we know for a fact that these videos are going to be, you know,

00:27:22.800 --> 00:27:28.740
they're either going to be streamed like 90% of the time from television, like a 4K definition television,

00:27:28.740 --> 00:27:31.400
or people are going to be watching on their iPhone.

00:27:31.400 --> 00:27:36.060
So all these videos get encoded in different formats, like for different resolutions.

00:27:36.600 --> 00:27:40.180
And how much do we put into the CDNs and how do we get them prepared?

00:27:40.180 --> 00:27:46.600
Do we need like multiple copies so that multiple streams can be read without having to have contention and so on?

00:27:46.600 --> 00:27:50.280
Things like those kinds of projections, those are all done using Python applications.

00:27:50.280 --> 00:27:56.280
You probably can't put every version of every video at every location all the time, right?

00:27:56.280 --> 00:28:00.520
I don't know how much that is, but that's a large amount of video content, large amount of files.

00:28:00.980 --> 00:28:02.080
You probably got to predict, right?

00:28:02.080 --> 00:28:08.260
Like these, we can fall back to, you know, letting them stream from some higher upstream thing,

00:28:08.260 --> 00:28:10.680
but then it'll get cached after it gets viewed a little bit.

00:28:10.680 --> 00:28:12.720
But these were preloading, right?

00:28:12.720 --> 00:28:13.740
Yeah, yeah.

00:28:13.740 --> 00:28:18.980
Actually, Zoran used to work on the team that did all the encoding in different shapes and sizes,

00:28:18.980 --> 00:28:21.160
and they used quite a bit of Python as well.

00:28:21.160 --> 00:28:23.240
He'd be able to tell you more about that stuff.

00:28:23.240 --> 00:28:29.660
Yeah, did you just have like a huge office, like a whole building full of GPUs and just go in the whole time?

00:28:29.920 --> 00:28:31.520
Well, encoding is a lot of work.

00:28:31.520 --> 00:28:32.280
Yeah, tell us about this.

00:28:32.280 --> 00:28:33.700
Yeah, encoding is a lot of work.

00:28:33.700 --> 00:28:37.700
So that was my original start here, and we do a lot of Python as well.

00:28:37.700 --> 00:28:39.280
And yeah, we sum it up.

00:28:39.280 --> 00:28:44.860
We kind of try and scour, scavenge as many instances that we can put our hands on.

00:28:44.860 --> 00:28:51.960
So if we have any, say, AWS reservations that it so happens that nobody's using right now,

00:28:51.960 --> 00:28:58.740
we come and grab them and spawn our workers dynamically on it as much as we can.

00:28:59.120 --> 00:28:59.600
Interesting.

00:28:59.600 --> 00:29:02.160
Almost like grid computing, like a steady at home.

00:29:02.160 --> 00:29:03.140
Yeah, exactly.

00:29:03.140 --> 00:29:04.200
Like steady at home.

00:29:04.200 --> 00:29:04.240
Exactly.

00:29:04.240 --> 00:29:04.460
Yeah.

00:29:04.900 --> 00:29:09.800
And if we do have something like that is high priority, well, you know, there's not enough

00:29:09.800 --> 00:29:15.160
like kind of workers laying around, then we can go and get some on the spot, you know, market

00:29:15.160 --> 00:29:18.440
or, well, get to grab more reservations if need be.

00:29:18.440 --> 00:29:24.340
So that is the encoding is basically we take these big master files, right?

00:29:24.340 --> 00:29:29.540
Like we have these originals, and we encode them for every single variation where it makes

00:29:29.540 --> 00:29:29.760
sense.

00:29:29.760 --> 00:29:33.160
Like for this TV, for that phone, for, you know, Android phone, iOS phone.

00:29:33.160 --> 00:29:36.700
What is the product of all the different resolutions and different platforms?

00:29:36.700 --> 00:29:41.620
How many video files do you have to make for how many formats do you have to have for one

00:29:41.620 --> 00:29:42.460
movie?

00:29:42.460 --> 00:29:43.180
Do you know?

00:29:43.180 --> 00:29:44.560
That changes per lead.

00:29:44.560 --> 00:29:51.040
And, you know, we kind of keep fine tuning how we want the smallest files with the best

00:29:51.040 --> 00:29:51.740
quality, right?

00:29:51.900 --> 00:29:53.300
So that keeps evolving.

00:29:53.300 --> 00:29:58.780
And sometimes we re-encode the full catalog because now we have like a better way of encoding,

00:29:58.780 --> 00:30:04.120
say, anime things versus, you know, action movies versus like it gets to us.

00:30:04.120 --> 00:30:04.440
I see.

00:30:04.440 --> 00:30:10.180
You might choose a different encoder for a cartoon-like thing versus the planet Earth type

00:30:10.180 --> 00:30:11.100
of video.

00:30:11.100 --> 00:30:11.360
Yeah.

00:30:11.360 --> 00:30:11.760
Okay.

00:30:11.760 --> 00:30:12.200
Yeah.

00:30:12.200 --> 00:30:12.580
Yeah.

00:30:12.580 --> 00:30:17.640
And all of this, basically by way of a product of all of this, ends up on Open Connect.

00:30:17.640 --> 00:30:20.000
I mean, S3, but also Open Connect.

00:30:20.000 --> 00:30:20.360
Yep.

00:30:20.360 --> 00:30:20.880
Yep.

00:30:20.880 --> 00:30:21.660
Excellent.

00:30:21.660 --> 00:30:26.120
One thing in there that is mentioned on my team, very interesting project called vMath.

00:30:26.120 --> 00:30:27.780
So that is written in Python.

00:30:27.780 --> 00:30:28.880
It's machine learning.

00:30:28.880 --> 00:30:31.900
And once you have encoded, right?

00:30:31.900 --> 00:30:36.320
Like, let's say you're trying a new way of encoding to make the files even smaller, right?

00:30:36.320 --> 00:30:40.180
You want to know during while you're researching, right?

00:30:40.180 --> 00:30:44.420
You want to know, did you come up with a very good, better encoder than before?

00:30:44.420 --> 00:30:51.480
So vMath is like a little bot that will look at encode a new file and give it a human-like,

00:30:51.480 --> 00:30:52.100
score.

00:30:52.100 --> 00:30:56.140
Like, what quality would the human assess this to be?

00:30:56.140 --> 00:30:59.900
And it has to be, you know, basically excellent quality.

00:30:59.900 --> 00:31:01.240
Get a high score.

00:31:01.240 --> 00:31:06.080
I think 90 out of 100, roughly, to pass.

00:31:06.080 --> 00:31:07.660
And then this is better, right?

00:31:07.660 --> 00:31:10.700
Like, we have a smaller file, but the quality is still excellent.

00:31:10.700 --> 00:31:13.180
And perceptibly, it's as good as before.

00:31:13.180 --> 00:31:14.440
It was just a fairly smaller.

00:31:14.820 --> 00:31:18.000
Then we could decide and re-encode the full catalog with that.

00:31:18.000 --> 00:31:18.500
Yeah.

00:31:18.500 --> 00:31:18.960
I see.

00:31:18.960 --> 00:31:19.860
That's really interesting.

00:31:19.860 --> 00:31:24.560
So what you're telling me is you have an AI that you just make watch Netflix movies all

00:31:24.560 --> 00:31:25.000
the time.

00:31:25.160 --> 00:31:25.800
All the time.

00:31:25.800 --> 00:31:26.720
All the time.

00:31:26.720 --> 00:31:26.740
All the time.

00:31:26.740 --> 00:31:33.140
And we have other AIs that watch the whole catalog, for example, and find where text appears,

00:31:33.140 --> 00:31:33.580
say.

00:31:33.580 --> 00:31:37.820
You know, so that when we put subtitles, we can move them up or down, you know, to not put

00:31:37.820 --> 00:31:38.600
text on text.

00:31:38.960 --> 00:31:42.380
And all kinds of metadata, like where can we find landscapes?

00:31:42.380 --> 00:31:43.880
Where does Brad Pitt show up?

00:31:43.880 --> 00:31:44.720
Things like that.

00:31:44.720 --> 00:31:46.200
Incredible.

00:31:46.200 --> 00:31:47.040
I had no idea.

00:31:47.040 --> 00:31:49.340
People are always full of a lot of surprises.

00:31:49.340 --> 00:31:56.440
This portion of Talk Python To Me is brought to you by Influx Data, the makers of InfluxDB.

00:31:56.440 --> 00:32:03.720
InfluxDB is a database purpose built for handling time series data at a massive scale for real-time

00:32:03.720 --> 00:32:04.240
analytics.

00:32:04.920 --> 00:32:09.780
Developers can ingest, store, and analyze all types of time series data, metrics, events,

00:32:09.780 --> 00:32:11.600
and traces in a single platform.

00:32:11.600 --> 00:32:14.040
So, dear listener, let me ask you a question.

00:32:14.040 --> 00:32:19.120
How would boundless cardinality and lightning-fast SQL queries impact the way that you develop

00:32:19.120 --> 00:32:20.260
real-time applications?

00:32:20.260 --> 00:32:26.380
InfluxDB processes large time series data sets and provides low-latency SQL queries, making

00:32:26.380 --> 00:32:31.800
it the go-to choice for developers building real-time applications and seeking crucial insights.

00:32:31.800 --> 00:32:34.880
For developer efficiency, InfluxDB helps you.

00:32:34.880 --> 00:32:40.900
Create IoT, analytics, and cloud applications using timestamped data rapidly and at scale.

00:32:40.900 --> 00:32:46.260
It's designed to ingest billions of data points in real-time with unlimited cardinality.

00:32:46.260 --> 00:32:52.180
InfluxDB streamlines building once and deploying across various products and environments from

00:32:52.180 --> 00:32:54.640
the edge, on-premise, and to the cloud.

00:32:54.640 --> 00:32:58.660
Try it for free at talkpython.fm/InfluxDB.

00:32:58.660 --> 00:33:01.080
The link is in your podcast player show notes.

00:33:01.780 --> 00:33:04.260
Thanks to InfluxData for supporting the show.

00:33:06.700 --> 00:33:11.620
And I think the VMAP software that's written in Python, I believe that is open source, right,

00:33:11.620 --> 00:33:11.960
Zoran?

00:33:11.960 --> 00:33:12.460
It is.

00:33:12.460 --> 00:33:13.540
It is open source, yes.

00:33:13.540 --> 00:33:16.880
And I think it's one of the Emmy Award winning software.

00:33:16.880 --> 00:33:20.100
I did not know that software could win Emmy Awards before this one.

00:33:20.100 --> 00:33:25.020
And it apparently won an Emmy Award for something.

00:33:25.020 --> 00:33:27.140
Videography or something?

00:33:28.120 --> 00:33:29.200
Probably, yeah.

00:33:29.200 --> 00:33:29.660
Wow.

00:33:29.660 --> 00:33:30.740
That's awesome.

00:33:30.740 --> 00:33:31.340
All right.

00:33:31.340 --> 00:33:34.280
The next major section is demand engineering.

00:33:34.280 --> 00:33:34.900
Yeah.

00:33:34.900 --> 00:33:37.260
This is kind of like DevOps type stuff, right?

00:33:37.260 --> 00:33:39.300
Keeping things running, capacity planning.

00:33:39.300 --> 00:33:40.060
Yes.

00:33:40.060 --> 00:33:40.960
That is exactly right.

00:33:40.960 --> 00:33:41.200
Yeah.

00:33:41.200 --> 00:33:43.000
That was the team that I was in previously.

00:33:43.000 --> 00:33:47.440
And the regional failover is the one where I mentioned where you could traffic from one

00:33:47.440 --> 00:33:49.040
of the AWS regions into the other two regions.

00:33:49.040 --> 00:33:51.960
And so we run in three separate AWS regions.

00:33:51.960 --> 00:33:56.000
And anytime any of those regions is having a difficulty, we can easily move the traffic

00:33:56.000 --> 00:34:00.880
to the other two regions without users even noticing that there was a glitch or any kind

00:34:00.880 --> 00:34:01.900
of issue there.

00:34:01.900 --> 00:34:03.380
How long does it take?

00:34:03.380 --> 00:34:10.200
If you say you've got to move 50% of the traffic out of U.S. East Virginia to somewhere else,

00:34:10.200 --> 00:34:12.500
is that hours, minutes?

00:34:12.500 --> 00:34:18.360
So the fastest we have done is, so on average, it takes about seven minutes.

00:34:18.720 --> 00:34:19.300
Do all of that.

00:34:19.300 --> 00:34:20.360
And that was our target.

00:34:20.360 --> 00:34:22.380
So when I first joined, I was given as a target.

00:34:22.380 --> 00:34:24.380
It used to be around 45 minutes at the time.

00:34:24.380 --> 00:34:29.560
And we built some, you know, interesting things to make it possible to run it inside seven minutes.

00:34:29.560 --> 00:34:33.540
But the fastest we've done is like around five minutes in like an emergency where, you know,

00:34:33.540 --> 00:34:38.420
oh God, the entire region is tanked and people in the U.S. are not happy about this.

00:34:38.420 --> 00:34:40.160
Let's move as fast as we can.

00:34:40.160 --> 00:34:41.540
And we can do it in five minutes.

00:34:41.540 --> 00:34:47.180
Doesn't happen often, but you know when it happens, especially, you know, when AWS Virginia

00:34:47.180 --> 00:34:50.300
goes down because a quarter of the internet stops working.

00:34:50.300 --> 00:34:51.820
Sure.

00:34:51.820 --> 00:34:54.460
But it's not just AWS that goes down.

00:34:54.460 --> 00:34:58.140
Sometimes we shoot our spells in the foot.

00:34:58.140 --> 00:35:02.860
One of the interesting things to make sure that we release software that is safe is we do something

00:35:02.860 --> 00:35:05.000
called regionally staggered releases.

00:35:05.000 --> 00:35:10.500
And so when a new software or when a new version gets released, since it's like hundreds of microservices

00:35:10.500 --> 00:35:14.940
that are running inside of Netflix to make it all possible, every service will deploy.

00:35:14.940 --> 00:35:20.040
And when they start to deploy, they deploy it into a single region, wait about like five to 10 minutes

00:35:20.040 --> 00:35:21.840
to make sure that, you know, nothing bad has happened.

00:35:21.840 --> 00:35:24.040
And then they proceed to the next one and then the next one.

00:35:24.420 --> 00:35:29.600
And so when they release it to the first region, they can either, if they find out that it's

00:35:29.600 --> 00:35:34.860
bad, they can either quickly roll it back or we could just evacuate out of that region because

00:35:34.860 --> 00:35:36.940
we can do that in like under seven minutes.

00:35:36.940 --> 00:35:41.180
And so if the rollback takes longer than seven minutes, then a call will be made by the core

00:35:41.180 --> 00:35:43.460
team, which will say, let's evacuate out.

00:35:43.660 --> 00:35:45.280
We haven't figured out what the problem is.

00:35:45.280 --> 00:35:49.880
So and then, you know, we evacuate and then we'll debug, you know, oh, which service did

00:35:49.880 --> 00:35:53.480
a release and what do we need to roll back and so on.

00:35:53.480 --> 00:35:57.060
Because there are like hundreds of services that are simultaneously releasing at the same

00:35:57.060 --> 00:35:57.260
time.

00:35:57.260 --> 00:36:01.500
So it's like quickly trying to identify which service that we need to roll back can sometimes

00:36:01.500 --> 00:36:01.980
be tricky.

00:36:01.980 --> 00:36:04.100
So we have used failovers for that as well.

00:36:04.100 --> 00:36:04.380
Yeah.

00:36:04.380 --> 00:36:06.120
So it's not just AWS's fault.

00:36:06.120 --> 00:36:06.840
Yeah, sure.

00:36:06.840 --> 00:36:11.520
And I don't mean to pick on AWS because all these data centers go down.

00:36:11.520 --> 00:36:17.620
The difference is when AWS goes down, like the internet goes down, you know, the observability

00:36:17.620 --> 00:36:20.900
of it is so high because so much runs on there.

00:36:20.900 --> 00:36:23.080
It's like that in Cloudflare when they go down too.

00:36:23.080 --> 00:36:24.420
You're like, oh, I see everything's broken.

00:36:24.420 --> 00:36:24.700
Okay.

00:36:24.700 --> 00:36:25.340
Yeah.

00:36:25.340 --> 00:36:30.880
When sites go down in production, even for places way smaller than Netflix, it's really

00:36:30.880 --> 00:36:34.720
stressful and you might make it worse by trying to fix it.

00:36:34.720 --> 00:36:39.300
So the ability to just go, let's buy ourselves some time to figure this out and just get everyone

00:36:39.300 --> 00:36:40.560
out and then we're going to look at it.

00:36:40.660 --> 00:36:41.680
And then we'll get bring them back.

00:36:41.680 --> 00:36:42.540
That's, that's pretty cool.

00:36:42.540 --> 00:36:47.240
You did write an article called how Netflix does failovers in seven minutes flat, which

00:36:47.240 --> 00:36:50.100
I'll put in the show notes so people can read more about that if they want.

00:36:50.100 --> 00:36:50.460
Thanks.

00:36:50.680 --> 00:36:57.360
So this demand engineering side, talk about obviously tools are primarily built in Python

00:36:57.360 --> 00:36:57.820
there.

00:36:57.820 --> 00:37:02.100
You got some NumPy and SciPy and even the B Python shell.

00:37:02.100 --> 00:37:04.480
Tell us about some of the Python stuff going on here.

00:37:04.480 --> 00:37:09.940
Before I joined Netflix, like when I actually first started learning Python, I loved the REPL,

00:37:09.940 --> 00:37:13.360
but I always felt like the REPL did not have auto-completion in it.

00:37:13.360 --> 00:37:18.380
And that like B Python is a, is a alternate REPL for Python that provides you with like

00:37:18.380 --> 00:37:21.140
auto-completion and syntax highlighting and all that stuff.

00:37:21.140 --> 00:37:23.340
So I am a, I'm a huge fan of B Python.

00:37:23.340 --> 00:37:28.320
One of the things that we have done, like demand engineering specifically is, you know, we get

00:37:28.320 --> 00:37:33.480
paged and we have to go in and try and rescue our traffic out of that region into the other

00:37:33.480 --> 00:37:33.960
two regions.

00:37:34.340 --> 00:37:39.760
And sometimes our software itself will not work because if an entire region is down,

00:37:39.760 --> 00:37:43.600
let's say it's because of a network connectivity issue or something, then the things that we

00:37:43.600 --> 00:37:48.480
call out to in order to make these, you know, changes to, to scale up the other regions and

00:37:48.480 --> 00:37:51.780
like evacuate and make the NS changes or whatever, that itself might be broken.

00:37:51.780 --> 00:37:57.480
And when that's broken, like literally SSH into the box and we will open up like a shell,

00:37:57.480 --> 00:38:00.780
Python shell and do whatever we need to do.

00:38:01.000 --> 00:38:05.520
That has not happened in like the last four years, I would say, but six years ago, yeah,

00:38:05.520 --> 00:38:06.960
that was the thing that we used to do.

00:38:06.960 --> 00:38:11.600
And I wanted to call out B Python specifically in this, in this particular case, because it was so

00:38:11.600 --> 00:38:15.440
much more useful than trying to remember, oh, I remember I wrote this function.

00:38:15.440 --> 00:38:16.060
Like, what is it?

00:38:16.060 --> 00:38:19.520
Like, instead of like opening my IDE to try to find out what that function is, like I just

00:38:19.520 --> 00:38:24.260
import the module and then I do the module dot and it lists me all the functions and I could

00:38:24.260 --> 00:38:24.880
invoke it.

00:38:24.880 --> 00:38:26.140
And yeah, it's such a time saver.

00:38:26.140 --> 00:38:26.520
Yeah.

00:38:26.520 --> 00:38:30.880
The Python REPL is cool, but it, it leaves a lot to be desired in terms of.

00:38:30.920 --> 00:38:31.120
Right.

00:38:31.120 --> 00:38:31.680
History.

00:38:31.680 --> 00:38:38.600
Or even if you want to edit a function that is five lines long, it's, it's, it's, it's

00:38:38.600 --> 00:38:39.120
hard to go through.

00:38:39.120 --> 00:38:39.640
It becomes cumbersome.

00:38:39.640 --> 00:38:42.200
Another one is PT Python that I'm.

00:38:42.200 --> 00:38:42.480
Yeah.

00:38:42.480 --> 00:38:44.180
I'm also a fan of that one.

00:38:44.180 --> 00:38:44.780
Yes.

00:38:44.780 --> 00:38:46.800
They're kind of the same category, right?

00:38:46.800 --> 00:38:47.240
Yeah.

00:38:47.240 --> 00:38:51.540
Prompt Toolkit, the one that powered PT Python, written by Jonathan Slenders, actually.

00:38:51.540 --> 00:38:54.220
And it's like a fantastic library.

00:38:54.220 --> 00:38:57.340
I just like kudos to, to Jonathan for doing that.

00:38:57.340 --> 00:38:58.800
That was, it's a fantastic library.

00:38:58.800 --> 00:38:59.200
Yeah.

00:38:59.200 --> 00:38:59.800
Awesome.

00:39:00.420 --> 00:39:05.220
So are you, you got a particular enhancement there for your, your REPL?

00:39:05.220 --> 00:39:07.820
I'm not like that big of a user of REPL.

00:39:07.820 --> 00:39:12.680
In the terminal, we do like, you know, ask questions for generating new projects, et cetera.

00:39:12.680 --> 00:39:14.440
I'm much more of a PyCharm user myself.

00:39:14.440 --> 00:39:16.360
Like I go in the computer over there.

00:39:16.480 --> 00:39:20.240
As you bring that up, you know, one of the really nice Python REPLs is the, what I guess

00:39:20.240 --> 00:39:23.840
it's called probably the Python console in PyCharm, right?

00:39:23.840 --> 00:39:28.380
Because if you go to that, you get the Python REPL, but you get PyCharm's autocomplete and,

00:39:28.380 --> 00:39:33.180
you know, type consistency and it automatically modifies the path to import your project.

00:39:33.180 --> 00:39:33.580
So yeah.

00:39:33.580 --> 00:39:34.780
And like, you got one in there.

00:39:34.780 --> 00:39:35.140
Yeah.

00:39:35.220 --> 00:39:36.160
Just that one's yours.

00:39:36.160 --> 00:39:36.600
All right.

00:39:36.600 --> 00:39:41.720
Let's see the core team alerting and statistical work.

00:39:41.720 --> 00:39:42.860
What's this one about?

00:39:42.860 --> 00:39:44.780
Core team is our frontline SRE.

00:39:45.040 --> 00:39:50.180
So demand team is like building tools that the core team will leverage to, to get us out

00:39:50.180 --> 00:39:50.560
of trouble.

00:39:50.560 --> 00:39:54.760
So core team is the one that, you know, anytime there is like, they monitor a lot of metrics,

00:39:54.760 --> 00:40:00.340
not just streaming metrics, but also things like error rates between services that are happening

00:40:00.340 --> 00:40:03.780
and how many requests are successfully coming back and so forth.

00:40:03.780 --> 00:40:08.760
They obviously use Python to kind of keep tabs on, like obviously a person can't be sitting

00:40:08.760 --> 00:40:10.820
in front of a dashboard, just monitoring it themselves.

00:40:11.300 --> 00:40:16.320
So they use quite a bit of Python to analyze the data from all of the hundreds of microservices

00:40:16.320 --> 00:40:20.040
and between them, the inter-process communication that actually happens and the metrics that

00:40:20.040 --> 00:40:21.500
come through and so forth.

00:40:21.500 --> 00:40:23.740
So they use Python for alerting.

00:40:23.740 --> 00:40:25.860
And so actually they use the monitoring.

00:40:25.860 --> 00:40:29.900
The next section that I was, that's right there is a monitoring, alerting and auto remediation.

00:40:29.900 --> 00:40:36.180
We have an internal observability organization that has built our own time series database that's

00:40:36.180 --> 00:40:39.140
not in Python, but you know, it's open source called Atlas.

00:40:39.700 --> 00:40:44.320
And that uses, that collects all of the time series data from all of these services.

00:40:44.320 --> 00:40:48.400
And then they try and do alerting and remediation, auto remediation.

00:40:48.400 --> 00:40:54.020
So when a particular alert condition is met, they can, you can run a small Python script inside

00:40:54.020 --> 00:40:56.060
of a framework called Winston.

00:40:56.060 --> 00:40:59.520
That's again, internal that allows you to do more complicated things.

00:40:59.520 --> 00:41:04.560
So for instance, if you have like this one bad instance in like this, this collection of

00:41:04.560 --> 00:41:09.920
20 instances, instead of a user going and terminating that instance, you can now automate that by

00:41:09.920 --> 00:41:14.320
writing a script that says, you know, automatically restart that, that instance or just kill it.

00:41:14.320 --> 00:41:15.100
And so on.

00:41:15.100 --> 00:41:16.040
That's, that's our.

00:41:16.040 --> 00:41:16.360
Cool.

00:41:16.360 --> 00:41:18.820
That's part of the auto, auto remediation of it.

00:41:18.820 --> 00:41:23.940
And it says it's built on G unicorn flask and flask rest plus.

00:41:24.340 --> 00:41:30.860
I'm familiar with the first batch, but the flask rest plus, this is new, an extension for flask that adds

00:41:30.860 --> 00:41:33.060
support for quickly building rest APIs.

00:41:33.060 --> 00:41:33.500
Okay.

00:41:33.500 --> 00:41:34.200
Interesting.

00:41:34.200 --> 00:41:36.040
Because flask itself already does rest.

00:41:36.040 --> 00:41:40.600
I don't like, so rest plus I think provides things like a swagger endpoints automatically.

00:41:40.600 --> 00:41:44.240
So you could, you know, try it out on the browser and so on.

00:41:44.240 --> 00:41:48.440
I have not used flask rest plus myself, but that team uses it quite a bit.

00:41:48.760 --> 00:41:48.960
Yeah.

00:41:48.960 --> 00:41:49.200
Cool.

00:41:49.200 --> 00:41:54.680
Probably some of the, some, some similarities to like what FastAPI kind of brings in addition

00:41:54.680 --> 00:41:56.080
to standard flask, I'd imagine.

00:41:56.080 --> 00:41:56.560
Exactly.

00:41:56.560 --> 00:41:57.060
Yeah.

00:41:57.060 --> 00:41:57.620
Yeah.

00:41:57.620 --> 00:41:59.840
You use more FastAPI nowadays.

00:41:59.840 --> 00:42:00.360
Yes.

00:42:00.360 --> 00:42:00.620
Oh yeah.

00:42:00.620 --> 00:42:01.120
Yeah.

00:42:01.120 --> 00:42:04.720
We're using quite a bit of FastAPI in most of our internal tools actually.

00:42:04.720 --> 00:42:05.280
Yeah.

00:42:05.280 --> 00:42:10.100
Just from reading through this article, it sounds like there's a lot of APIs and just a lot of

00:42:10.100 --> 00:42:11.140
connectivity through.

00:42:11.140 --> 00:42:14.040
There's probably a lot of JSON going around Netflix.

00:42:14.040 --> 00:42:14.340
Yes.

00:42:14.340 --> 00:42:14.880
Yeah.

00:42:14.880 --> 00:42:21.440
So the, some of the heavy, heavier data stuff or like high streaming services like that

00:42:21.440 --> 00:42:25.360
are in the streaming path are all typically written in Java and they use for inter-process

00:42:25.360 --> 00:42:25.780
communication.

00:42:25.780 --> 00:42:30.080
They use gRPC and that uses protobuf to communicate and so forth.

00:42:30.080 --> 00:42:36.000
But most of our internal tools that are written in Python either use JSON directly or sometimes

00:42:36.000 --> 00:42:38.120
they need to talk to a gRPC service.

00:42:38.120 --> 00:42:41.200
And so they use Python gRPC to get the work done.

00:42:41.200 --> 00:42:43.760
Maybe we'll have some time to come back to gRPC.

00:42:44.020 --> 00:42:44.740
I'm not sure.

00:42:44.740 --> 00:42:46.740
We got a lot of things to talk about here.

00:42:46.740 --> 00:42:47.480
Yeah.

00:42:47.480 --> 00:42:49.580
We don't have to go through every section here.

00:42:49.580 --> 00:42:50.400
I mean.

00:42:50.400 --> 00:42:50.800
No, I know.

00:42:50.800 --> 00:42:52.700
But there's, there's just so many interesting angles.

00:42:52.700 --> 00:42:53.040
Right.

00:42:53.040 --> 00:42:53.560
And so.

00:42:53.560 --> 00:42:53.880
Yeah.

00:42:53.880 --> 00:42:58.980
The next one here is information security, which obviously if you just put anything on

00:42:58.980 --> 00:43:03.640
the internet and just tail the log of it within minutes, you'll see a request for,

00:43:03.640 --> 00:43:05.520
you know, WP admin.php.

00:43:05.520 --> 00:43:11.580
You know, like it's just, it's already just constantly being, you know, people are just after it.

00:43:11.580 --> 00:43:11.780
Right.

00:43:11.780 --> 00:43:12.060
Yep.

00:43:12.060 --> 00:43:12.460
Yep.

00:43:12.460 --> 00:43:17.040
One of the things you have here that looks interesting is security monkey written in Python,

00:43:17.040 --> 00:43:20.160
which is, I guess, like chaos monkey, but.

00:43:20.160 --> 00:43:21.860
It is kind of like chaos monkey.

00:43:21.860 --> 00:43:27.640
I think this project may have been archived or it's not actively in development.

00:43:28.180 --> 00:43:31.600
It tries to scan our infrastructure for unsafe practices.

00:43:31.600 --> 00:43:37.180
That's like a, an umbrella term to try to add like whatever is like good practices that

00:43:37.180 --> 00:43:39.500
should exist for, for, from the security standpoint.

00:43:39.500 --> 00:43:40.040
Yeah.

00:43:40.040 --> 00:43:40.640
Okay.

00:43:40.640 --> 00:43:41.540
So people can check it out.

00:43:41.540 --> 00:43:44.880
Maybe it's not totally active anymore, but they can take it as inspiration.

00:43:44.880 --> 00:43:45.180
Right.

00:43:45.180 --> 00:43:45.680
Yeah.

00:43:45.680 --> 00:43:45.680
Yeah.

00:43:45.680 --> 00:43:45.680
Yeah.

00:43:45.680 --> 00:43:46.180
Yeah.

00:43:46.180 --> 00:43:48.800
Like back in 2019, it was one of our most active projects.

00:43:48.800 --> 00:43:52.060
But apparently 2023 is a different world.

00:43:52.060 --> 00:43:53.080
It is a different world.

00:43:53.080 --> 00:43:59.800
And one of the areas in which 2023 is a different world is really the AI ML side.

00:43:59.800 --> 00:44:06.180
And you all are doing a lot of stuff with personalization algorithms, recommendation engines, machine learning.

00:44:06.180 --> 00:44:09.180
And you talked about Metaflow, which is now available.

00:44:09.580 --> 00:44:09.680
Yeah.

00:44:09.680 --> 00:44:14.000
The personalization one, I think we've just mentioned a bunch of things that we use from

00:44:14.000 --> 00:44:14.960
the open source world here.

00:44:14.960 --> 00:44:19.120
So I think XGBoost is a, is a library that does machine learning.

00:44:19.120 --> 00:44:21.760
So personally, I am not, I am not in this field.

00:44:21.760 --> 00:44:25.820
So I just went and interviewed the team and asked them to give me a blurb.

00:44:25.820 --> 00:44:30.940
So I wouldn't be able to talk in detail about any of the personalization stuff here,

00:44:30.940 --> 00:44:37.480
but yeah, this is just a showcase of how much this team relies on Python and the, and the

00:44:37.480 --> 00:44:40.500
open source ecosystem that comes with Python in general.

00:44:40.500 --> 00:44:45.720
So it's like heavy users of Panda TensorFlow and PyTorch and so on.

00:44:45.720 --> 00:44:46.160
Yeah.

00:44:46.160 --> 00:44:53.460
So let me ask you, is it your, both of your, your team supports Python developers and Python

00:44:53.460 --> 00:44:58.560
applications indirectly in that way, but is it different to support the data scientists than

00:44:58.560 --> 00:45:00.880
it is to support, say software developers?

00:45:00.880 --> 00:45:02.920
Like, do you have to think about that differently?

00:45:02.920 --> 00:45:03.640
How so?

00:45:03.640 --> 00:45:04.140
Yes.

00:45:04.140 --> 00:45:04.500
Yes.

00:45:04.500 --> 00:45:08.780
We do have like a, a team that is dedicated to supporting all the data scientists and we

00:45:08.780 --> 00:45:11.440
are like the team that supports the team who supports the data scientists.

00:45:11.440 --> 00:45:12.620
They should.

00:45:12.620 --> 00:45:13.580
Right now.

00:45:13.580 --> 00:45:19.620
So, so yeah, we were, definitely like now in 2023, you know, betting more on

00:45:19.620 --> 00:45:24.800
Python before Python was more like, if it makes sense for you because of freedom and responsibility,

00:45:24.800 --> 00:45:28.840
if it makes sense to use Python in your team, you use Python, you know, and now we're trying

00:45:28.840 --> 00:45:31.420
to provide basically like a better base path.

00:45:31.420 --> 00:45:36.780
This is, me and Amjit with this new team that we started, we're trying to kind of enhance

00:45:36.780 --> 00:45:39.640
this base path better and better for all these teams.

00:45:39.640 --> 00:45:46.640
And we, you know, it's hard to know all the specifics in every single team, but we're

00:45:46.640 --> 00:45:50.980
trying to provide them with as good practices and automation as possible.

00:45:50.980 --> 00:45:55.160
So I think you asked like, how is it different, supporting one versus the other?

00:45:55.160 --> 00:46:00.720
I think we built, so when we first started the team, we met with 10 different organizations

00:46:00.720 --> 00:46:03.480
inside of Netflix to find out like how they use Python.

00:46:03.480 --> 00:46:08.660
And we found that there were some commonalities, but the way, for instance, like algorithms

00:46:08.660 --> 00:46:12.980
engineering uses Python is very different from the way a SRE team uses Python.

00:46:12.980 --> 00:46:16.980
And it's very, very different from how our animation studio uses Python.

00:46:16.980 --> 00:46:23.160
So our VFX animation uses Python in a way where they, once they start, like this is apparently

00:46:23.160 --> 00:46:28.380
common in all of, the movie industry, which is once they start a particular project, whatever

00:46:28.380 --> 00:46:32.320
they have chosen at the start of that project, they will stick to it until that project is

00:46:32.320 --> 00:46:32.680
completed.

00:46:32.680 --> 00:46:37.900
So if that movie takes two years to finish, you cannot upgrade anything inside of that particular

00:46:37.900 --> 00:46:42.020
hermetically sealed, environment, development environment that you have.

00:46:42.020 --> 00:46:46.420
So that is very different from like another, like a machine learning person who's interested

00:46:46.420 --> 00:46:48.720
in like, you know, I just want to write my algorithm.

00:46:48.720 --> 00:46:52.560
Like I don't, I don't care about how pip works or like how I pip install.

00:46:52.560 --> 00:46:55.740
Like I don't want to worry about like virtual environments and things like that.

00:46:55.740 --> 00:46:59.780
Whereas a person who's writing internal tools, they want to like main, like, you know, own

00:46:59.780 --> 00:47:00.620
the entire tool chain.

00:47:00.620 --> 00:47:05.400
It's like, I not only want to maintain virtual environment, I also want this thing to work

00:47:05.400 --> 00:47:07.980
with a front end that is written in react.

00:47:07.980 --> 00:47:12.000
And so I would like you to be able to like make it possible to do like NPM and, and, and

00:47:12.000 --> 00:47:14.580
pip to coexist and, and live together.

00:47:14.580 --> 00:47:19.060
That's not like a hard thing to do, but it's one of those things where it's like, if I'm

00:47:19.060 --> 00:47:23.160
trying to solve a problem, let's say I'm, I'm bringing in like Python dependency locking

00:47:23.160 --> 00:47:26.040
as a, as a mechanism to help these web developers, right?

00:47:26.040 --> 00:47:30.280
Because they, they don't want to automatically upgrade anytime they build their system and,

00:47:30.280 --> 00:47:31.840
and suddenly break in production.

00:47:31.840 --> 00:47:36.320
Now that might be completely useless for someone who's working in machine learning.

00:47:36.320 --> 00:47:38.940
And so they're like, you know, why are you solving that problem?

00:47:38.940 --> 00:47:43.600
This, you know, you bringing like locking to packaging doesn't help me in any way.

00:47:43.600 --> 00:47:44.760
Like, why are you wasting your time?

00:47:44.760 --> 00:47:50.180
And so we had to sort of build personas for various ways in which Python is used inside

00:47:50.180 --> 00:47:50.580
of Netflix.

00:47:50.740 --> 00:47:54.780
So that when we are working on a particular feature, we can tell them we are now targeting

00:47:54.780 --> 00:47:55.400
this persona.

00:47:55.400 --> 00:47:58.880
We are working towards making life easy for animation engineers.

00:47:58.880 --> 00:48:01.340
So if it doesn't work for you, that's fine.

00:48:01.340 --> 00:48:02.380
You know, that's fine.

00:48:02.380 --> 00:48:03.400
We will get to you.

00:48:03.400 --> 00:48:06.220
It's just that our persona that we're targeting right now is not yours.

00:48:06.220 --> 00:48:08.080
So that's, that's how it's different.

00:48:08.080 --> 00:48:08.760
I'd say.

00:48:08.760 --> 00:48:09.220
Yeah.

00:48:09.220 --> 00:48:09.540
Yeah.

00:48:10.040 --> 00:48:13.060
Data scientists have a lot less legacy code.

00:48:13.060 --> 00:48:16.900
That's just still cranking along because a lot of times once they get, they discover

00:48:16.900 --> 00:48:18.540
an insight, they don't need to run it again.

00:48:18.540 --> 00:48:18.760
Right.

00:48:18.760 --> 00:48:20.880
They, or the algorithms are changing so fast.

00:48:20.880 --> 00:48:26.200
They can just, well, now we're using large language models instead of whatever, you know?

00:48:26.200 --> 00:48:26.520
Yeah.

00:48:26.520 --> 00:48:26.940
There you go.

00:48:26.940 --> 00:48:27.160
Yeah.

00:48:27.160 --> 00:48:27.860
Yeah.

00:48:27.860 --> 00:48:32.160
Whereas once you get a web app running, you might not touch that thing if it doesn't

00:48:32.160 --> 00:48:32.600
need touching.

00:48:32.600 --> 00:48:32.860
Right.

00:48:32.860 --> 00:48:33.440
So you just.

00:48:33.440 --> 00:48:33.960
Exactly.

00:48:33.960 --> 00:48:35.940
Stability is what you need there.

00:48:35.940 --> 00:48:40.020
So anything else you want to call out out of this article before we move on?

00:48:40.740 --> 00:48:42.640
We don't have a ton of time left, honestly, but.

00:48:42.640 --> 00:48:43.720
No, no.

00:48:43.720 --> 00:48:47.580
I think this was a great article, but yeah, two things.

00:48:47.580 --> 00:48:53.300
With regard to this, let's just leave people with this idea that we only touched on a small

00:48:53.300 --> 00:48:58.040
part of what is laid out here and all the projects and all the ways in which it's being

00:48:58.040 --> 00:48:58.240
used.

00:48:58.240 --> 00:49:02.840
So certainly check out the article just called Python at Netflix that I'll put in the show

00:49:02.840 --> 00:49:03.040
notes.

00:49:03.040 --> 00:49:05.840
It's hard to cover it all in just one hour.

00:49:05.840 --> 00:49:06.840
It sure is.

00:49:06.840 --> 00:49:07.480
It sure is.

00:49:08.020 --> 00:49:13.520
So let's maybe talk for a minute here about this project that you're involved with, Soren,

00:49:13.520 --> 00:49:14.960
called Portable Python.

00:49:14.960 --> 00:49:21.580
You know, I not long ago had Nathaniel Smith on to talk about PEP 7-11, distributing Python

00:49:21.580 --> 00:49:27.240
binaries and maybe treating like CPython runtimes as wheels almost.

00:49:28.080 --> 00:49:33.760
And you guys also have a way that you've been using for a while internally to package up

00:49:33.760 --> 00:49:37.560
Python into something that can run as well called Portable Python, which is open source.

00:49:37.560 --> 00:49:38.760
You want to talk a bit about that?

00:49:38.760 --> 00:49:39.140
Yes.

00:49:39.140 --> 00:49:41.720
That is in PEP 7-11.

00:49:41.720 --> 00:49:44.160
I discovered it by listening to your podcast.

00:49:44.160 --> 00:49:45.780
Right around PyCon, I think.

00:49:45.840 --> 00:49:46.060
Yes.

00:49:46.060 --> 00:49:50.440
It would be very interesting to see if we could partner up once this is.

00:49:50.440 --> 00:49:56.900
So Portable Python is, we want to provide Python, of course, to all Python developers inside.

00:49:56.900 --> 00:49:57.220
Right?

00:49:57.220 --> 00:50:00.840
You can always grab your own Python via all kinds of ways.

00:50:00.840 --> 00:50:01.080
Right?

00:50:01.080 --> 00:50:03.340
PyN, Docker image, et cetera.

00:50:03.460 --> 00:50:07.940
But we also provide builds of Python inside to be used internally.

00:50:07.940 --> 00:50:11.180
So Portable Python is trying to solve, adjust that.

00:50:11.180 --> 00:50:15.760
Well, one particular issue, how do you go and distribute Python on laptops?

00:50:15.760 --> 00:50:23.400
So the end goal is we want to provide a tarball, just like that PEP says, you know, like a wheel.

00:50:23.400 --> 00:50:30.800
A tarball that you can download and drop somewhere, typically in, you know, a user's own folder,

00:50:30.800 --> 00:50:32.740
tilde slash, you know, mypythons.

00:50:33.060 --> 00:50:34.740
And we want it to work from there.

00:50:34.740 --> 00:50:39.180
So you could use PyN for that, but with PyN, we need to wait for it to build.

00:50:39.180 --> 00:50:39.600
Right?

00:50:39.600 --> 00:50:42.100
And we want to basically build it ahead of time.

00:50:42.100 --> 00:50:46.220
And as soon as it's available and, you know, make it available internally.

00:50:46.220 --> 00:50:51.300
So what Portable Python is designed to do is to do such a build, we call it Portable,

00:50:51.300 --> 00:50:53.560
and drop it in Artifactory.

00:50:53.560 --> 00:50:58.360
And then our tooling can just go fetch that real quick, unzip, and it's ready to go.

00:50:58.360 --> 00:51:01.820
So your tooling, the Portable Python tooling, basically says,

00:51:01.960 --> 00:51:03.640
I'm on this platform.

00:51:03.640 --> 00:51:06.560
So I'm on macOS and it's Apple Silicon.

00:51:06.560 --> 00:51:09.540
So here's the, and they want this version of Python.

00:51:09.540 --> 00:51:11.540
So that means this binary.

00:51:11.540 --> 00:51:12.560
Let's go grab it.

00:51:12.560 --> 00:51:12.960
Right.

00:51:12.960 --> 00:51:13.480
Right.

00:51:13.480 --> 00:51:16.720
So Portable Python is invoked by our building machinery.

00:51:16.960 --> 00:51:24.980
There's one worker on macOS, x86, macOS M1, Linux, x86, Linux, ARM64.

00:51:24.980 --> 00:51:31.380
And there's some external internal tooling that kind of detects that the new open source version

00:51:31.380 --> 00:51:33.200
is available using Portable Python.

00:51:33.200 --> 00:51:35.520
So Portable Python can report you.

00:51:35.520 --> 00:51:36.820
What is the latest?

00:51:36.820 --> 00:51:38.180
3.11, for example.

00:51:38.540 --> 00:51:41.340
By looking at the ftp.python.org, basically.

00:51:41.340 --> 00:51:41.720
Okay.

00:51:41.720 --> 00:51:43.460
So the latest is 3.11.3.

00:51:43.460 --> 00:51:44.140
Let's see.

00:51:44.140 --> 00:51:45.000
Do we have it internally?

00:51:45.000 --> 00:51:45.460
No.

00:51:45.460 --> 00:51:45.820
Okay.

00:51:45.820 --> 00:51:46.720
Let's kick off a build.

00:51:46.720 --> 00:51:51.440
So we kick off one build for M1, one build for Linux, et cetera.

00:51:51.660 --> 00:51:55.180
And with Portable Python, we fit the configuration.

00:51:55.180 --> 00:51:57.600
We say we want OpenSSL, that version.

00:51:57.600 --> 00:51:59.220
We want SQLite, that version.

00:51:59.220 --> 00:52:02.980
And Portable Python goes ahead and does the build, produces a tarball.

00:52:02.980 --> 00:52:05.800
We take that tarball and publish it internally.

00:52:05.800 --> 00:52:06.340
That's interesting.

00:52:06.340 --> 00:52:10.460
So you can control a little bit some of the internals as well, like the OpenSSL version

00:52:10.460 --> 00:52:12.880
and SQLite version, maybe a bit more carefully.

00:52:12.880 --> 00:52:13.500
Yes.

00:52:13.500 --> 00:52:13.760
Yes.

00:52:13.760 --> 00:52:19.740
And since it's written in Python, then it's able to also inspect, say, any Python.

00:52:20.040 --> 00:52:24.540
Like you could run Portable Python, inspect path to this installation, and it will tell

00:52:24.540 --> 00:52:27.880
you, okay, it has a SSL, that version, SQLite, that version.

00:52:27.880 --> 00:52:32.480
It does it use like homebrew, shared libraries or what.

00:52:32.480 --> 00:52:34.420
It can report on that.

00:52:34.420 --> 00:52:40.500
And, oh yeah, it generates a thing that I find very important, like a little file that says

00:52:40.500 --> 00:52:42.120
it's called manifest.yaml.

00:52:42.120 --> 00:52:48.640
So every time it builds anything, it generates a dot manifest.yaml where it says, well, I did

00:52:48.640 --> 00:52:53.800
the build with dash dash, LTO optimization, dash dash, like it says everything that was

00:52:53.800 --> 00:52:59.820
used to kind of inform what the build had and which worker it ran on, what time, what was

00:52:59.820 --> 00:53:00.440
the platform.

00:53:00.440 --> 00:53:02.760
Like a little bit of metadata, which sometimes.

00:53:02.760 --> 00:53:07.700
So you could even see things like what C compiler optimization flags were enabled when you created

00:53:07.700 --> 00:53:08.580
it, for example.

00:53:08.580 --> 00:53:09.420
Yes.

00:53:09.700 --> 00:53:09.860
Okay.

00:53:09.860 --> 00:53:11.640
And there is one additional thing.

00:53:11.640 --> 00:53:15.220
So Portable Python does not install Python on your system for you.

00:53:15.220 --> 00:53:16.940
So it is a builder.

00:53:16.940 --> 00:53:21.480
So it builds them and produces tarballs that can be used in a standalone manner.

00:53:21.480 --> 00:53:26.560
And so if you want to bring Python onto your system, you just download the tarball from our

00:53:26.560 --> 00:53:29.760
internal artifact storage and then expand it.

00:53:29.820 --> 00:53:32.240
And that we have another tool that automatically does that.

00:53:32.240 --> 00:53:37.120
And so when somebody bootstraps a brand new Python project and they say, I would like to

00:53:37.120 --> 00:53:41.080
use 3.11.3, which are 3.11.4, I think that got released yesterday.

00:53:41.080 --> 00:53:46.740
Then we will already have a binary ready for them that is in the artifactory, in our internal

00:53:46.740 --> 00:53:47.260
artifactory.

00:53:47.480 --> 00:53:52.480
And when they run their build for the very first time, it will bring the appropriate Python

00:53:52.480 --> 00:53:57.360
version that they have specified in either pyproject.toml or in their tox.ini or somewhere.

00:53:57.360 --> 00:54:02.680
And it will bring that appropriate Python, install it or expand it in a known location, and it

00:54:02.680 --> 00:54:05.220
will use that for their building their project and so forth.

00:54:05.220 --> 00:54:10.740
So this is, it's a way to make it easy for people to not have to manage their Python on their

00:54:10.740 --> 00:54:11.980
laptop individually.

00:54:11.980 --> 00:54:15.900
And also this can build Python with a specific prefix.

00:54:15.900 --> 00:54:21.920
So on servers, on our internal servers, what we do is we install Python in a specific location.

00:54:21.920 --> 00:54:25.940
Like we always put it inside, let's say, for example, slash app slash Python, for example.

00:54:25.940 --> 00:54:29.840
It will build it in a way that it makes it easy for Debiants to be built.

00:54:29.840 --> 00:54:33.440
And when you install the Debian, it will put the Python in a specific location.

00:54:33.440 --> 00:54:40.120
And also it has other benefits, such as it tries to make the Python binary as small as

00:54:40.120 --> 00:54:44.360
possible because we're trying to deploy it out to like hundreds of thousands or a hundred

00:54:44.360 --> 00:54:45.460
thousand servers.

00:54:45.460 --> 00:54:49.920
So we would try to reduce the amount that we need to put on that server.

00:54:49.920 --> 00:54:50.800
It does that.

00:54:50.800 --> 00:54:55.840
The final product that Zoran checked yesterday, I believe it was only 50 megabytes compared to

00:54:55.840 --> 00:54:59.900
what other like buy-in on other things are producing, which was 200 megabytes.

00:54:59.900 --> 00:55:01.820
It does it by a few tricks.

00:55:01.820 --> 00:55:05.220
It looks like it removes the test folder because, you know, once you have built it, like, you

00:55:05.220 --> 00:55:08.060
know, having the test folder as part of your final artifact makes no sense.

00:55:08.060 --> 00:55:10.300
That was like a hundred megabytes savings right there.

00:55:10.300 --> 00:55:14.880
So things like that, some optimizations that we do that is custom for our work.

00:55:15.100 --> 00:55:15.220
Yeah.

00:55:15.220 --> 00:55:16.680
That's a really interesting system.

00:55:16.680 --> 00:55:23.080
I think there's increasing momentum around having some kind of tool that is outside of

00:55:23.080 --> 00:55:24.980
Python for managing Python, right?

00:55:24.980 --> 00:55:30.640
So far, primarily what we've had is things like Pip, PipX, Soarin' You have a project called

00:55:30.640 --> 00:55:31.180
Pickley.

00:55:31.740 --> 00:55:33.480
And it's all about like, okay, you have Python.

00:55:33.480 --> 00:55:35.140
Now, how do you go forward?

00:55:35.140 --> 00:55:39.720
But I think a lot of people are realizing like, wait, that assumption that I have Python, now

00:55:39.720 --> 00:55:41.500
what, is not a great assumption, right?

00:55:41.500 --> 00:55:46.140
And so people are starting to look at tools like RustUp, which actually is kind of like Pip,

00:55:46.140 --> 00:55:48.100
but it brings Rust into it, yeah.

00:55:48.100 --> 00:55:48.820
Over, yeah.

00:55:48.820 --> 00:55:50.540
So we're going to see something there, I think.

00:55:50.540 --> 00:55:52.240
I don't know what it is, but it'll be interesting.

00:55:52.240 --> 00:55:52.580
Yeah.

00:55:52.580 --> 00:55:54.220
Did you see the one Rai?

00:55:54.220 --> 00:55:58.520
Rai is the package manager that Armin wrote, which...

00:55:58.520 --> 00:55:59.880
Yeah, from Armin Roenker.

00:55:59.880 --> 00:56:00.260
Yeah.

00:56:00.440 --> 00:56:02.540
That brings Python for you.

00:56:02.540 --> 00:56:05.460
His inspiration is from RustUp, apparently.

00:56:05.460 --> 00:56:11.500
So Rai is actually written in Rust, and it does all the things that Poetry and PDM and

00:56:11.500 --> 00:56:12.520
other package managers does.

00:56:12.520 --> 00:56:15.320
But in addition to that, it also brings Python for you.

00:56:15.320 --> 00:56:20.880
And it's using a different Python called StandalonePython or something that you already had a link

00:56:20.880 --> 00:56:21.420
for, I forgot.

00:56:21.420 --> 00:56:25.300
But it brings Python from there to expand it into your system.

00:56:25.300 --> 00:56:27.880
Yeah, Python Build Standalone, that's the project that it uses.

00:56:27.880 --> 00:56:29.520
Yeah, I've heard of that.

00:56:29.540 --> 00:56:31.340
I haven't done anything with it, but it looks interesting.

00:56:31.340 --> 00:56:31.900
Yeah.

00:56:31.900 --> 00:56:32.200
All right.

00:56:32.200 --> 00:56:33.120
I think we have time.

00:56:33.120 --> 00:56:34.240
We're getting short on time here.

00:56:34.240 --> 00:56:38.920
I think we have time for one more really quick thing, something that you're participating in,

00:56:38.920 --> 00:56:39.620
Amjith.

00:56:39.620 --> 00:56:41.040
I'm sure I don't know if you are as well.

00:56:41.040 --> 00:56:45.560
But Command Line Database Clients with Autocomplete and Syntax Highlighting.

00:56:46.220 --> 00:56:47.020
Tell us about this.

00:56:47.020 --> 00:56:47.680
This looks cool.

00:56:47.680 --> 00:56:48.220
Yeah.

00:56:48.220 --> 00:56:51.040
This is just my personal project that I wrote before.

00:56:51.040 --> 00:56:52.520
This was a while back.

00:56:52.520 --> 00:56:58.040
But the idea is, at the time, I was trying to learn Postgres, and I didn't know how to do,

00:56:58.040 --> 00:57:01.560
like, I was learning Postgres, and I was using PSQL to do this.

00:57:01.740 --> 00:57:06.120
And every time I come to, like, a table, I'd be like, you know, oh, what columns were there?

00:57:06.120 --> 00:57:10.000
I forgot the exact name of the column, and I tried to find it and so forth.

00:57:10.000 --> 00:57:17.380
And so, finally, you know, I broke down and decided to write, like, a shell for Postgres called PGCLI

00:57:17.380 --> 00:57:21.680
that uses, actually, PromToolkit, like the same toolkit that's used by PtPython.

00:57:21.900 --> 00:57:24.140
I was going to say, it looks a lot like PtPython.

00:57:24.140 --> 00:57:25.560
It's got that Emacs mode.

00:57:25.560 --> 00:57:26.020
Yep.

00:57:26.020 --> 00:57:31.980
You've got Autocomplete for basically the whole SQL language, but also the database schema that

00:57:31.980 --> 00:57:32.760
you're connected to, right?

00:57:32.760 --> 00:57:33.660
Yes, that is correct.

00:57:33.660 --> 00:57:38.000
So, it reads the tables and the columns in that database, and then it tries to Autocomplete

00:57:38.000 --> 00:57:39.800
as part of the SQL statement.

00:57:39.800 --> 00:57:42.860
So, after a where clause, it'll only suggest columns.

00:57:42.860 --> 00:57:45.620
And after a from clause, it'll only suggest tables and so on.

00:57:45.620 --> 00:57:46.080
Wow.

00:57:46.080 --> 00:57:46.540
Okay.

00:57:46.540 --> 00:57:50.300
So, after PGCLI, people wanted something for MySQL.

00:57:50.480 --> 00:57:55.140
So, I created MyCLI, and then Microsoft came over and said, like, we would like to fork

00:57:55.140 --> 00:57:58.640
PGCLI to make one for Microsoft's MS SQL server.

00:57:58.640 --> 00:58:00.320
So, they did that themselves.

00:58:00.320 --> 00:58:01.160
Like, we didn't.

00:58:01.160 --> 00:58:03.760
So, they took PGCLI source code, and then they created that.

00:58:03.760 --> 00:58:07.600
And then another person created Lite CLI, which is for SQLite.

00:58:07.600 --> 00:58:08.480
And, yeah.

00:58:08.480 --> 00:58:09.960
And there's other things now.

00:58:09.960 --> 00:58:14.220
iRedis is, like, for a Redis client that's similar to these things, but there's a lot more,

00:58:14.220 --> 00:58:17.420
like, more friendlier shells for databases in general.

00:58:17.420 --> 00:58:17.860
Excellent.

00:58:17.860 --> 00:58:18.480
All right.

00:58:18.480 --> 00:58:19.720
This looks really cool, I think.

00:58:20.120 --> 00:58:22.140
Yeah, this has got nothing to do with Netflix.

00:58:22.140 --> 00:58:27.200
It's mostly just, like, hey, it's my personal project, and, you know, just what I do in my

00:58:27.200 --> 00:58:28.280
free time sort of a thing.

00:58:28.280 --> 00:58:28.620
Yeah.

00:58:28.620 --> 00:58:34.580
Well, it looks really helpful for people, because talking to databases just in your terminal,

00:58:34.580 --> 00:58:35.800
it can be tricky, right?

00:58:35.800 --> 00:58:40.920
And having autocomplete, especially not so much, you know, the select and where people get that

00:58:40.920 --> 00:58:45.220
pretty quick, but the database schema understanding keeps you in your flow pretty well.

00:58:45.340 --> 00:58:45.540
Right.

00:58:45.540 --> 00:58:45.780
Yeah.

00:58:45.780 --> 00:58:45.900
Yeah.

00:58:45.900 --> 00:58:47.780
Again, inspired by Bpython, actually.

00:58:47.780 --> 00:58:49.120
Took the inspiration from them.

00:58:49.120 --> 00:58:49.620
Yeah.

00:58:49.620 --> 00:58:50.060
Excellent.

00:58:50.060 --> 00:58:50.780
All right.

00:58:50.780 --> 00:58:52.140
Well, that'll be in the show notes as well.

00:58:52.140 --> 00:58:55.080
Guys, I think that is it for time that we have today.

00:58:55.080 --> 00:58:59.780
So we're going to have to wrap it up with the final two questions here and recommendations.

00:58:59.780 --> 00:59:02.520
Let's start with a PyPI project.

00:59:02.520 --> 00:59:05.820
Not necessarily the most popular one, but something that you're like, oh, this is awesome.

00:59:05.820 --> 00:59:06.760
People should know about it.

00:59:07.000 --> 00:59:08.620
Soren, got a recommendation for folks?

00:59:08.620 --> 00:59:09.960
I'm going to say Pickly.

00:59:09.960 --> 00:59:11.060
Go check out Pickly.

00:59:11.060 --> 00:59:11.820
Pickly.

00:59:11.820 --> 00:59:12.180
Okay.

00:59:12.180 --> 00:59:14.500
So give us the elevator pitch on Pickly.

00:59:14.500 --> 00:59:21.200
It's a CLI tool that allows you to install other CLI tools, very similar to Pipex in that sense.

00:59:21.200 --> 00:59:26.300
The main difference is being that if you Pickly install Poetry, every time you run Poetry,

00:59:26.300 --> 00:59:29.100
it will keep itself up to date in the background.

00:59:29.100 --> 00:59:32.080
So it will keep self-upgrading by default.

00:59:32.080 --> 00:59:35.860
You can tell it also not to do that, but that's its main useful thing.

00:59:36.060 --> 00:59:36.100
Cool.

00:59:36.100 --> 00:59:41.620
So when you launch it, basically you're launching like a shim that says run this and then the

00:59:41.620 --> 00:59:42.540
background check for update.

00:59:42.540 --> 00:59:44.800
And when it exits, if there's an update, just update it.

00:59:44.800 --> 00:59:45.080
Yes.

00:59:45.080 --> 00:59:49.340
You can take a look at the little shell script, shell wrapper that it wraps it with.

00:59:49.340 --> 00:59:49.800
Yes.

00:59:49.800 --> 00:59:50.180
All right.

00:59:50.180 --> 00:59:50.480
Pickly.

00:59:50.480 --> 00:59:50.900
Awesome.

00:59:50.900 --> 00:59:51.400
Amjith.

00:59:51.400 --> 00:59:54.020
Oh, I guess I could plug again for Bpython.

00:59:54.020 --> 00:59:55.480
Like good design aesthetics.

00:59:55.480 --> 00:59:59.600
I think, yeah, it's an overall better shell than Python shell.

00:59:59.600 --> 00:59:59.880
Yeah.

00:59:59.880 --> 01:00:01.860
Oh, actually PDB++.

01:00:01.860 --> 01:00:03.780
That's the one that I would actually recommend.

01:00:03.920 --> 01:00:10.540
So if you ever use PDB and you wish that PDB had auto-completion, it's PDBPP in PyPy.

01:00:10.540 --> 01:00:13.340
You don't have to change your thing at all.

01:00:13.340 --> 01:00:15.340
All you have to do is pip install PDBPP.

01:00:15.340 --> 01:00:21.680
And then anytime you do a breakpoint and it stops you there, you can do like a variable

01:00:21.680 --> 01:00:23.500
dot and it'll give you auto-completion.

01:00:23.500 --> 01:00:24.220
And yeah.

01:00:24.220 --> 01:00:24.740
I don't know.

01:00:24.740 --> 01:00:26.020
I'm a huge fan of auto-completion.

01:00:26.280 --> 01:00:26.460
Yeah.

01:00:26.460 --> 01:00:29.220
I was going to say, you and I are kindred spirits.

01:00:29.220 --> 01:00:31.240
I am all about the auto-completion.

01:00:31.240 --> 01:00:33.860
I'm like, this tool is broken if it doesn't give me auto-complete.

01:00:33.860 --> 01:00:36.360
Because it sends you into the documentation.

01:00:36.360 --> 01:00:39.680
You'll be like, oh, I need to create one of these client libraries.

01:00:39.680 --> 01:00:40.300
What does it take?

01:00:40.300 --> 01:00:42.340
Oh, star args, star, star, kwrgs.

01:00:42.340 --> 01:00:42.700
Great.

01:00:42.700 --> 01:00:43.940
Now what am I supposed to do?

01:00:43.940 --> 01:00:44.160
Right?

01:00:44.240 --> 01:00:49.240
Like, you know, the auto-complete, it really makes you more productive.

01:00:49.240 --> 01:00:49.620
All right.

01:00:49.620 --> 01:00:54.380
And then if you're going to write some Python code, what editor, if you're not in the Ripple,

01:00:54.380 --> 01:00:54.960
are you using?

01:00:54.960 --> 01:00:56.760
For me, it's PyCharm.

01:00:56.760 --> 01:01:02.520
PyCharm mostly sublime text and VI if I'm SSHing somewhere.

01:01:02.520 --> 01:01:03.000
Excellent.

01:01:03.000 --> 01:01:03.880
And Amjith?

01:01:03.880 --> 01:01:05.260
Vim all the way.

01:01:05.260 --> 01:01:08.380
You know, even if I don't know how to quit it, I can restart my computer.

01:01:11.380 --> 01:01:14.860
That is the source of, the endless source of jokes.

01:01:14.860 --> 01:01:20.080
You know, like, I saw some laptop, a picture of a laptop, and it was just smashed to pieces.

01:01:20.080 --> 01:01:22.420
And it said, finally figured out how to quit Vim.

01:01:22.420 --> 01:01:31.080
For the longest time, actually, I had colon Q as a way to quit out of PGCLI because I, by

01:01:31.080 --> 01:01:33.040
instinct, just kept hitting colon Q.

01:01:33.040 --> 01:01:34.140
And yeah.

01:01:34.140 --> 01:01:35.460
That's amazing.

01:01:35.460 --> 01:01:37.020
All right, you guys.

01:01:37.020 --> 01:01:39.020
Well, it's been great to have you on the show.

01:01:39.020 --> 01:01:40.000
Thanks for being here.

01:01:40.240 --> 01:01:44.300
Thanks for giving us this look at what you're all doing up over at Netflix and your personal

01:01:44.300 --> 01:01:44.680
projects.

01:01:44.680 --> 01:01:45.020
Yeah.

01:01:45.020 --> 01:01:45.680
Thank you, Michael.

01:01:45.680 --> 01:01:50.440
I just would like to mention that we have a lot of jobs at Netflix that require Python.

01:01:50.440 --> 01:01:55.760
So if you are at all interested, please go to jobs.netflix.com and type in Python, and you

01:01:55.760 --> 01:01:58.560
should get all of the Python job openings that are available.

01:01:58.560 --> 01:01:59.800
There's a wide variety.

01:01:59.800 --> 01:02:02.000
If you want to do infrastructures of, there's that.

01:02:02.000 --> 01:02:04.220
If you want to do data science, there's that, right?

01:02:04.220 --> 01:02:05.720
Like a lot of coolers.

01:02:05.720 --> 01:02:06.860
Yes, absolutely.

01:02:06.860 --> 01:02:07.400
All right.

01:02:07.400 --> 01:02:08.560
Have a great day, guys.

01:02:08.560 --> 01:02:09.180
Thank you.

01:02:09.380 --> 01:02:09.780
Bye.

01:02:09.780 --> 01:02:10.140
Bye.

01:02:10.140 --> 01:02:10.200
Bye.

01:02:10.200 --> 01:02:13.920
This has been another episode of Talk Python To Me.

01:02:13.920 --> 01:02:15.740
Thank you to our sponsors.

01:02:15.740 --> 01:02:17.340
Be sure to check out what they're offering.

01:02:17.340 --> 01:02:18.760
It really helps support the show.

01:02:18.760 --> 01:02:24.100
The folks over at JetBrains encourage you to get work done with PyCharm.

01:02:24.100 --> 01:02:29.660
PyCharm Professional understands complex projects across multiple languages and technologies,

01:02:29.660 --> 01:02:35.320
so you can stay productive while you're writing Python code and other code like HTML or SQL.

01:02:35.320 --> 01:02:40.460
Download your free trial at talkpython.fm/done with PyCharm.

01:02:41.460 --> 01:02:44.220
Influx data encourages you to try InfluxDB.

01:02:44.220 --> 01:02:50.720
InfluxDB is a database purpose-built for handling time series data at a massive scale for real-time

01:02:50.720 --> 01:02:51.180
analytics.

01:02:51.180 --> 01:02:55.080
Try it for free at talkpython.fm/InfluxDB.

01:02:55.500 --> 01:02:56.760
Want to level up your Python?

01:02:56.760 --> 01:03:00.800
We have one of the largest catalogs of Python video courses over at Talk Python.

01:03:00.800 --> 01:03:05.980
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:03:05.980 --> 01:03:08.640
And best of all, there's not a subscription in sight.

01:03:08.640 --> 01:03:11.560
Check it out for yourself at training.talkpython.fm.

01:03:11.740 --> 01:03:16.240
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:03:16.240 --> 01:03:17.540
We should be right at the top.

01:03:17.540 --> 01:03:22.700
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:03:22.700 --> 01:03:26.900
and the direct RSS feed at /rss on talkpython.fm.

01:03:26.900 --> 01:03:30.340
We're live streaming most of our recordings these days.

01:03:30.340 --> 01:03:33.740
If you want to be part of the show and have your comments featured on the air,

01:03:33.740 --> 01:03:38.180
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:03:38.180 --> 01:03:40.020
This is your host, Michael Kennedy.

01:03:40.020 --> 01:03:41.300
Thanks so much for listening.

01:03:41.480 --> 01:03:42.480
I really appreciate it.

01:03:42.480 --> 01:03:44.400
Now get out there and write some Python code.

01:03:44.400 --> 01:03:45.220
Why?

01:03:45.220 --> 01:03:46.220
Why?

01:03:46.220 --> 01:03:47.220
Why?

01:03:47.220 --> 01:04:05.180
I'll see you next time.

