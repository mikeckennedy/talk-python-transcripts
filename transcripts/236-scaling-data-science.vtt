WEBVTT

00:00:00.001 --> 00:00:07.100
Do you do data science? Imagine you work with over 200 data scientists, many of whom have diverse

00:00:07.100 --> 00:00:12.760
backgrounds who have come from non-CS backgrounds. Some of them want to use Python, others are keen

00:00:12.760 --> 00:00:18.260
to work with R. Your job is to level the playing field across these experts through technical

00:00:18.260 --> 00:00:23.520
education and to build libraries and tooling that are useful to both Python and R-loving data

00:00:23.520 --> 00:00:27.940
scientists. It sounds like a fun challenge, doesn't it? That's what Ethan Swan and Bradley

00:00:27.940 --> 00:00:32.900
Baumke are up to, and they're here to give us a look inside their world. This is Talk Python to Me,

00:00:32.900 --> 00:00:53.120
episode 236, recorded September 27th, 2019. Welcome to Talk Python to Me, a weekly podcast on Python,

00:00:53.120 --> 00:00:57.500
the language, the libraries, the ecosystem, and the personalities. This is your host,

00:00:57.680 --> 00:01:01.860
Michael Kennedy. Follow me on Twitter, where I'm @mkennedy. Keep up with the show and listen to

00:01:01.860 --> 00:01:07.720
past episodes at talkpython.fm, and follow the show on Twitter via at Talk Python. This episode is

00:01:07.720 --> 00:01:12.120
brought to you by Linode and Tidelift. Please check out what they're offering during their segments.

00:01:12.120 --> 00:01:15.780
It really helps support the show. Ethan, Brad, welcome to Talk Python to Me.

00:01:15.780 --> 00:01:16.680
Thanks. Good to be here.

00:01:16.680 --> 00:01:17.320
Yeah, thanks.

00:01:17.320 --> 00:01:22.400
Yeah, it's great to have you both here. It's going to be really fun to talk about enabling data science

00:01:22.400 --> 00:01:29.520
across large teams and this whole blended world of data science, which it sounds pretty good,

00:01:29.520 --> 00:01:31.200
actually. It sounds like a positive place.

00:01:31.200 --> 00:01:33.500
Yeah, it's definitely getting more and more tangled, too.

00:01:33.500 --> 00:01:39.620
Yeah, I can imagine. I can imagine. So we're going to talk about things like R and Python and

00:01:39.620 --> 00:01:45.860
how those can maybe live together, how to bring maybe some computer science techniques and stuff

00:01:45.860 --> 00:01:52.180
to work together across these different teams and so on. But before we do, let's get started with

00:01:52.180 --> 00:01:55.320
your story. How did you get into programming in Python? Ethan, you want to go first?

00:01:55.320 --> 00:01:59.400
I went into college as an undecided engineering major and didn't really know what I wanted to do,

00:01:59.400 --> 00:02:03.920
but I was pretty sure it wasn't computer science. I was pretty sure that was for people who sat in

00:02:03.920 --> 00:02:08.840
front of a computer and it sounded very boring. And I got into the intro class for engineering and

00:02:08.840 --> 00:02:13.940
picked up MATLAB and just loved it. So from that point forward, I did some C and C++ in college

00:02:13.940 --> 00:02:18.620
and then came out of college and started working in data science. I started with a little bit of R and

00:02:18.620 --> 00:02:22.340
then found I was a lot more comfortable with Python. And now I use it in my job and also a little bit

00:02:22.340 --> 00:02:26.180
outside of work for some personal projects. So I really, really enjoyed it after going through a

00:02:26.180 --> 00:02:26.800
number of languages.

00:02:26.800 --> 00:02:33.280
It's interesting that MATLAB was sort of the beginning programming experience. I think looking

00:02:33.280 --> 00:02:37.880
in from the outside at the computer programming world, a lot of folks probably don't think that,

00:02:37.880 --> 00:02:42.760
but I went through a math program and when I was studying, a lot of people, their first programming

00:02:42.760 --> 00:02:46.320
experience was working in MATLAB and .m files and all that stuff.

00:02:46.320 --> 00:02:51.520
Yeah. Well, it seems to be very useful across other engineering fields. And also,

00:02:51.520 --> 00:02:55.920
it's relatively friendly. It's not like learning C or C++, which would probably scare a lot of people

00:02:55.920 --> 00:02:56.180
away.

00:02:56.180 --> 00:02:59.320
Yeah, absolutely. Absolutely. Brad, how about you?

00:02:59.320 --> 00:03:05.420
My background is much more along economics. So I was in the Air Force doing a lot of life cycle

00:03:05.420 --> 00:03:11.040
cost estimates for weapon systems, aircraft and the like. And a lot of that was done in Excel.

00:03:11.440 --> 00:03:16.500
And when I went up and I did my PhD, I mean, I started getting a lot of my research data.

00:03:16.500 --> 00:03:19.660
It was gnarly, just stuff spread out all over the place, ugly.

00:03:19.660 --> 00:03:21.080
And your PhD was in economics?

00:03:21.080 --> 00:03:26.900
No, it kind of. Yes and no. I had a unique PhD. It's technically called logistics,

00:03:26.900 --> 00:03:31.180
but it was kind of a hybrid of like economics, applied stats and ops research.

00:03:31.180 --> 00:03:32.100
Oh, right. Okay, cool.

00:03:32.240 --> 00:03:36.460
Yep. Yep. So and the problem was, you know, I spent a couple months just trying to figure out,

00:03:36.460 --> 00:03:41.380
like, how can I clean this data up and do my analysis within Excel? It was horrible. And so

00:03:41.380 --> 00:03:47.720
that was about the same time that Johns Hopkins came out with a like an online data science course

00:03:47.720 --> 00:03:53.180
through Coursera. And they featured or primarily focused on R. And that was kind of when I decided,

00:03:53.300 --> 00:03:57.060
all right, you know, I need to, I need to take a programming language to really get through this

00:03:57.060 --> 00:03:57.520
research.

00:03:57.520 --> 00:03:59.700
You've outgrown Excel in the extreme.

00:03:59.700 --> 00:04:01.060
Yes. Yes. Yep.

00:04:01.060 --> 00:04:05.420
So did you abuse it pretty badly? Were you trying to make it do things that just wouldn't?

00:04:05.580 --> 00:04:10.680
You know, it's funny because the work I was in within the Air Force, it was your classic

00:04:10.680 --> 00:04:16.280
abuse Excel as much as possible, right? You open it up, you got a workbook that's got like 26

00:04:16.280 --> 00:04:21.700
worksheets. You got stuff that is hyperlinked all over the place. You got, you know, hard coded

00:04:21.700 --> 00:04:26.240
changes going on in there and you leave for one week, you come back and there's just no way you can

00:04:26.240 --> 00:04:31.340
reproduce anything. And that was exactly what I was running into. And so that's, that's really what

00:04:31.340 --> 00:04:32.160
got me into programming.

00:04:32.360 --> 00:04:36.460
I think there's a lot of people out there who definitely consider themselves not programmers.

00:04:36.460 --> 00:04:43.340
And yet they basically program Excel all the time. Right. Right. And a lot of folks could follow

00:04:43.340 --> 00:04:48.020
your path and just add some programming skills and really be more effective.

00:04:48.020 --> 00:04:53.060
I think that's kind of a theme of past shows. I know you bring that up a bit where, you know,

00:04:53.060 --> 00:04:56.300
a lot of people would benefit from having a little bit of programming skill that they could bring to

00:04:56.300 --> 00:04:59.520
their regular job rather than being full-time programmers. And that seems very true.

00:04:59.520 --> 00:05:04.300
Yeah. And it sounds like exactly like this is a scenario for that. And it's definitely something

00:05:04.300 --> 00:05:07.780
that I'm passionate about. So I bring it up all the time. The other thing I think that's

00:05:07.780 --> 00:05:13.620
interesting about programming and programming and quotes around in Excel is we did a show called

00:05:13.620 --> 00:05:19.680
escaping Excel hell. And one of the themes is Excel is basically full of all of these go-to

00:05:19.680 --> 00:05:24.660
statements, right? Like you just go down and it says, go to that place and then go over here and

00:05:24.660 --> 00:05:29.180
go across this sheet over to that up there. It's totally unclear what the flow of these things are.

00:05:29.180 --> 00:05:35.700
It's bizarre. All right. So definitely programming languages are better. You both work at the same

00:05:35.700 --> 00:05:40.320
company. Let's talk about what you do day to day because you're sort of on the same team, right?

00:05:40.320 --> 00:05:45.080
Sort of. We collaborate very tightly. So I actually work on the education team. So our company is called

00:05:45.080 --> 00:05:50.420
8451. We're a subsidiary of Kroger. We're mainly their data science marketing agency. And we both work

00:05:50.420 --> 00:05:55.540
within the data science function. So my team is mainly involved with upskilling the function just

00:05:55.540 --> 00:06:00.260
generally. That may mean scheduling classes for people that are new starters. It may also mean what

00:06:00.260 --> 00:06:04.920
we call continuing education. So figuring out what people need to learn going forward to stay relevant

00:06:04.920 --> 00:06:09.940
in the industry. I tend to be more on the technical side of that team. And that means that I collaborate

00:06:09.940 --> 00:06:12.780
more tightly with Brad's team, which is more aligned to the technology.

00:06:12.780 --> 00:06:14.200
Yeah, for sure. And Brad, how about you?

00:06:14.200 --> 00:06:19.260
Yeah. So my team really focused on building kind of like internal components or internal packages.

00:06:19.760 --> 00:06:24.220
Yeah, I'm sure we'll talk more about this a little later. But, you know, we have about 200 data

00:06:24.220 --> 00:06:30.220
scientists that are at some point transitioning to using R and Python primarily or already are.

00:06:30.220 --> 00:06:37.320
So we try to standardize certain tasks as much as possible. And, you know, we'll wrap that up into

00:06:37.320 --> 00:06:43.620
like an R or Python package and kind of have like that centralized business logic for our own internal

00:06:43.620 --> 00:06:48.900
capabilities as a package in either R or Python. So our team just focuses a lot on building those

00:06:48.900 --> 00:06:54.860
packages. Yeah, that sounds super fun. It sounds like almost as if you're a small software team

00:06:54.860 --> 00:07:00.180
or company building all these tools for the broader company, right? Or the broader data science

00:07:00.180 --> 00:07:00.900
organization.

00:07:00.900 --> 00:07:04.520
One thing that's definitely coming more and more clear is, you know, we have kind of like the

00:07:04.520 --> 00:07:08.560
traditional data scientists and then we have the traditional like engineering function within the

00:07:08.560 --> 00:07:12.700
company. And there's kind of like that big void in between that kind of bridges that gap,

00:07:12.740 --> 00:07:18.780
where you have folks that have somewhat the software engineering capabilities, but they're

00:07:18.780 --> 00:07:22.920
coming from it more of a data science perspective, right? And they can build things that are a little

00:07:22.920 --> 00:07:25.780
bit more geared directly to how the data scientists work.

00:07:25.780 --> 00:07:26.720
Yeah. Interesting.

00:07:26.720 --> 00:07:31.160
We have about 250 total data scientists just for a sense of scale, which is one of the reasons that

00:07:31.160 --> 00:07:35.900
we have a dedicated internal team to enable them because at that scale, so many people are doing

00:07:35.900 --> 00:07:40.480
similar work that it makes sense to automate some of that stuff to build it into packages and things like that.

00:07:40.480 --> 00:07:45.860
I can't think of many other companies that have that many data scientists. Why don't you tell folks

00:07:45.860 --> 00:07:52.560
who, what Kroger is? Because I know being here in the U.S. and certainly spending some time in the

00:07:52.560 --> 00:07:57.720
South there, you know, Kroger directly is there, but they also own a bunch of other companies and

00:07:57.720 --> 00:08:00.700
stuff. So maybe just give people a quick background so they know.

00:08:00.700 --> 00:08:06.660
Kroger is in, I believe, 38 states and has something on the order of 3,000 stores. So it's just an

00:08:06.660 --> 00:08:11.560
enormous grocery chain in the U.S. So you may not have seen Kroger itself under the name Kroger

00:08:11.560 --> 00:08:17.880
because they own other chains, Ralph's, Food for Less. I think there's 20 different labels. But yeah,

00:08:17.880 --> 00:08:21.900
they're all over the place. And so it makes a lot of sense to have some sort of customer analytics

00:08:21.900 --> 00:08:23.420
organization, which is what we are.

00:08:24.460 --> 00:08:30.460
There's a lot of analytics around grocery stores and things like that and how you place things. You

00:08:30.460 --> 00:08:35.420
know, there's the story of putting the bananas in the back and in back corner and things like this,

00:08:35.420 --> 00:08:35.660
right?

00:08:35.780 --> 00:08:40.100
There's definitely a lot of different areas. So yeah, the banana story or like the milk in the

00:08:40.100 --> 00:08:45.520
back, people often tell what might actually be apocryphal, this idea that like these things are

00:08:45.520 --> 00:08:49.020
in the back because it makes people go get them and walk through the rest of the store. It might be true,

00:08:49.020 --> 00:08:52.700
but at this point, it's so ingrained. I'm not sure anybody knows. But there's other areas too,

00:08:52.700 --> 00:08:56.720
where it's like, what kinds of coupons do you mail people? So in general, when people ask me what my

00:08:56.720 --> 00:09:02.240
company does, the simplest summary is when you get coupons from a grocery store, that's people like us,

00:09:02.560 --> 00:09:06.040
essentially, where based on what you bought in the past, we know that like you would probably

00:09:06.040 --> 00:09:07.480
appreciate these kinds of coupons.

00:09:07.480 --> 00:09:12.800
Largely the way you probably collect data, I can imagine two ways or maybe more, is one,

00:09:12.800 --> 00:09:17.740
just when people pay with a credit card, that credit card number doesn't change usually, right? So you

00:09:17.740 --> 00:09:23.980
can associate that with a person. And then also, a lot of these stores in the US have these

00:09:23.980 --> 00:09:29.400
membership numbers that are free to sign up, but you get a small discount or you get some kind of

00:09:29.400 --> 00:09:35.120
like dash reward. There's some kind of benefit to getting a membership and always using that number.

00:09:35.120 --> 00:09:37.840
And that obviously feeds right back to what you guys need, right?

00:09:37.840 --> 00:09:41.920
Yeah, like that loyalty membership that a lot of folks have, and that is like the majority of

00:09:41.920 --> 00:09:46.640
customers. That's really what allows the data science that we do to kind of like personalize

00:09:46.640 --> 00:09:50.760
shopping experience, right? So if you're going to go online and do like online shopping,

00:09:50.760 --> 00:09:54.520
or if you're going to likely be going to the store in the next week, you know, we can try to

00:09:54.520 --> 00:09:58.680
personalize what do we expect you to be shopping based off of your history, we can link that back

00:09:58.680 --> 00:10:00.240
to your loyalty card number and everything.

00:10:00.240 --> 00:10:06.600
Yeah, super interesting. We could go on all sorts of the stories like the bananas and so on. I don't

00:10:06.600 --> 00:10:13.040
know the truth of them, so I won't go too much into them, but they sound fun. But 250 data scientists,

00:10:13.040 --> 00:10:18.060
that's quite the large group, as I said, and it's a little bit why I touched on the MATLAB story and

00:10:18.060 --> 00:10:23.800
the Excel story, because people seem to come to data science from different directions. I mean,

00:10:24.200 --> 00:10:28.960
you tell me where your people come from, but there's the computer science side, like I want to

00:10:28.960 --> 00:10:35.260
be a programmer, or maybe I'll focus on data, but also just statisticians or people interested in

00:10:35.260 --> 00:10:38.700
marketing or all these different angles. And that's an interesting challenge, right?

00:10:38.700 --> 00:10:45.240
With 200, 250 analysts or data scientists, you have this huge spectrum of kind of like talent and

00:10:45.240 --> 00:10:51.340
backgrounds. And so we kind of categorize our data scientists into like three big buckets, right?

00:10:51.340 --> 00:10:55.700
So we have like the insights folks, and those are the folks that are really focusing on like looking

00:10:55.700 --> 00:11:00.820
at historical trends going on, doing a lot of visualization to try to tell a story about what's

00:11:00.820 --> 00:11:05.160
going on with a product over time, what's going on with their customers. Then we got kind of another

00:11:05.160 --> 00:11:10.620
bucket that is kind of our statistical modelers or machine learning specialists, right? And those are

00:11:10.620 --> 00:11:16.360
the people that, you know, you would typically think of that are more educated on the stats or the

00:11:16.360 --> 00:11:20.920
algorithms that we're applying within the company. And then we got another bucket that's

00:11:20.920 --> 00:11:25.880
technology, right? And those are the folks that are really specialized on usually like the languages

00:11:25.880 --> 00:11:31.720
that we're using are Python, really understanding like, how to really be using Git, how to be using

00:11:31.720 --> 00:11:36.260
Linux and, and kind of maneuver around all the servers and different tech stack environments that

00:11:36.260 --> 00:11:41.420
we have going on. Obviously, the largest bucket is that insights. And I don't know what the actual

00:11:41.420 --> 00:11:47.520
number is. But I always say that roughly 60 to probably 70% of our data scientists kind of fall

00:11:47.520 --> 00:11:51.820
towards that insights. And that's kind of where you're going to see a lot of folks that have a

00:11:51.820 --> 00:11:56.520
background that would be typically aligned with like a business analyst, right? Maybe they're coming

00:11:56.520 --> 00:12:03.200
from more of an engineering or economics background. And the folks in the that middle bucket that machine

00:12:03.200 --> 00:12:08.360
learning that's gonna be more of your folks coming with like a stats, maybe stats, masters or PhD or

00:12:08.360 --> 00:12:13.580
more. They could even be economics, but you know, they can add a stronger focus on account of metrics,

00:12:13.580 --> 00:12:18.280
economics than kind of traditional economics. And then you've got that small bucket, which you get

00:12:18.280 --> 00:12:23.580
a lot of people that I think are more like Ethan, Ethan's kind of what I would consider like a classic

00:12:23.580 --> 00:12:27.780
person going in that bucket where they kind of have that computer science background, coming from school.

00:12:27.780 --> 00:12:32.920
And that kind of creates that strong link between traditional software engineering in our data science

00:12:32.920 --> 00:12:38.720
folks. That's a good taxonomy. Specific to our folks, I would say we have a lot of folks that have

00:12:38.720 --> 00:12:44.520
kind of like an economics background. That's definitely a big kind of traditional degree that

00:12:44.520 --> 00:12:48.880
we recruit a lot of people from. We have a lot of people from computer science programs, and then

00:12:48.880 --> 00:12:54.080
kind of the traditional stats, right? So, and Ethan, you can throw in some others. But for my experience,

00:12:54.080 --> 00:12:58.440
those kind of seem to be like the three like major themes of the backgrounds that we see.

00:12:58.440 --> 00:13:04.180
That's definitely very common. I think historically, we we leaned more from economics and statistics. And

00:13:04.180 --> 00:13:07.980
recently, there's there's been a lot of changes. Data science as a product is like a newer thing.

00:13:07.980 --> 00:13:12.860
In the past, I think there was less of a need for strong technical skills being a data scientist,

00:13:12.860 --> 00:13:16.780
if that formal title even existed, right? Right. It was so new. It's like,

00:13:16.780 --> 00:13:22.160
can you make graphs out of this big data with? Yeah, we love you just to do that. Right.

00:13:22.160 --> 00:13:26.440
Things have really changed, especially because we've moved into using distributed systems like Spark.

00:13:26.440 --> 00:13:31.400
And those things simply demand a higher level of technical expertise. And that's part of the reason that

00:13:31.400 --> 00:13:35.380
we've shifted to hiring more technical people to at least support and sometimes do different work.

00:13:35.380 --> 00:13:40.000
Sure. And that probably also feeds into why you all are building a lot of internal packages to help

00:13:40.000 --> 00:13:43.500
put a smooth facade on top of some of these more technical

00:13:43.500 --> 00:13:48.500
things like Spark. That's definitely been a theme of shifting to new platforms. So, you know,

00:13:48.500 --> 00:13:53.920
like probably most companies, we have a monolithic database system that for a long time,

00:13:53.920 --> 00:13:59.440
we've relied upon. So most data scientists are pulling from one primary database. But over the last

00:13:59.440 --> 00:14:04.300
couple of years, as we started to get things like clickstream data and just the needs of our

00:14:04.300 --> 00:14:11.160
modeling changed, we started to push towards Spark. And Spark tends to be a really, I don't know,

00:14:11.160 --> 00:14:15.160
a difficult adjustment for people coming from traditional databases, in my experience. And so

00:14:15.160 --> 00:14:21.280
a lot of the work that Brad and I have done is work on simplifying that transition. Try to hide some of

00:14:21.280 --> 00:14:24.860
the complexity that most people don't need to deal with. You probably don't need to configure

00:14:24.860 --> 00:14:29.420
everything in your Spark environment, because you're not used to doing that in something like Oracle.

00:14:29.720 --> 00:14:36.680
Yeah, absolutely. How much data skill do folks need to have for, as a data scientist, you know,

00:14:36.680 --> 00:14:41.840
when I think data science, I think pandas, I think CSV, I think, you know, those kinds of

00:14:41.840 --> 00:14:49.220
things, map, plot, lib, numpy, scikit, learn, these kinds of things, but not just the SQL query language

00:14:49.220 --> 00:14:54.980
and things like Spark and stuff. Although I know that that's also a pretty big part of it. So maybe

00:14:54.980 --> 00:14:58.940
could you just tell us for people out there listening, thinking, hey, I'd like to be a data

00:14:58.940 --> 00:15:02.480
scientist, what skills should I go acquire? And where's that fit into that?

00:15:02.660 --> 00:15:07.020
In my view, it's really a matter of the size of your data. Big data is such a generic term that I

00:15:07.020 --> 00:15:09.040
think it may have lost meaning in a lot of cases.

00:15:09.040 --> 00:15:12.460
Yeah, some person's big data is actually like, oh, that's nothing. We just, that's our test data,

00:15:12.460 --> 00:15:12.800
right?

00:15:12.800 --> 00:15:17.160
It's like, yeah, how big is your laptop's memory? That's really the question. And for us,

00:15:17.160 --> 00:15:20.780
so we literally have every transaction that's happened at Kroger over the last

00:15:20.780 --> 00:15:26.520
at least 10 or 15 years. And so the size of that data is just enormous. To do even trivial things like

00:15:26.520 --> 00:15:31.920
filters, you still need a very powerful system. And so for us, and for large companies with

00:15:31.920 --> 00:15:37.300
transactional records or clickstream records, you generally need very powerful distributed systems

00:15:37.300 --> 00:15:43.420
or a central database. But, you know, historically, people think of pandas as being the primary data

00:15:43.420 --> 00:15:47.580
science package. And that is true once you reduce your data to a manageable size. And perhaps some

00:15:47.580 --> 00:15:51.060
companies have small enough data that they could do that on a single server. But for us, that's

00:15:51.060 --> 00:15:51.820
generally not true.

00:15:51.820 --> 00:15:55.680
Do you guys use things like Dask or stuff for distributed processing?

00:15:55.680 --> 00:16:00.920
We don't really use Dask. There's been some interest in it, I think. So I'm not super familiar with

00:16:01.180 --> 00:16:06.360
but I think that it occupies a similar niche to Spark. We are pretty, pretty far down the Spark.

00:16:06.360 --> 00:16:06.960
Spark.

00:16:07.640 --> 00:16:13.020
Sure. Once you kind of place your bets and you invest that many hours of that many people's work,

00:16:13.020 --> 00:16:17.920
it can't just be slightly better or slightly different or whatever. It's got to be changing

00:16:17.920 --> 00:16:19.440
the world type of thing to make you guys move.

00:16:19.440 --> 00:16:23.320
We're also pushing towards migrating a lot of applications to the cloud. And in doing something

00:16:23.320 --> 00:16:27.100
like that, you sometimes are a little more restricted in what you can do in an enterprise

00:16:27.100 --> 00:16:31.900
setting because there's rules about how your environments work and things. And so we don't

00:16:31.900 --> 00:16:36.420
generally get to like customize our own clusters, which you might want to do for Dask. So we have an

00:16:36.420 --> 00:16:40.780
engineering and architecture team that sets up the Spark clusters for us that then we as data

00:16:40.780 --> 00:16:43.300
scientists log into and use for our work.

00:16:43.300 --> 00:16:48.720
That's kind of handy. I know there's a lot of places like that where there's just cluster computing

00:16:48.720 --> 00:16:55.360
available like CERN has got some ginormous set of computers. You can just say run this on that

00:16:55.360 --> 00:16:57.020
somehow, you know, and it just happens.

00:16:59.520 --> 00:17:04.480
This portion of Talk Python to me is brought to you by Linode. Are you looking for hosting that's fast,

00:17:04.480 --> 00:17:09.200
simple, and incredibly affordable? Well, look past that bookstore and check out Linode at

00:17:09.200 --> 00:17:16.460
 talkpython.fm/Linode. That's L-I-N-O-D-E. Plans start at just $5 a month for a dedicated server

00:17:16.460 --> 00:17:21.560
with a gig of RAM. They have 10 data centers across the globe. So no matter where you are or where your

00:17:21.560 --> 00:17:26.380
users are, there's a data center for you. Whether you want to run a Python web app, host a private Git

00:17:26.380 --> 00:17:32.360
server, or just a file server, you'll get native SSDs on all the machines, a newly upgraded 200

00:17:32.360 --> 00:17:37.980
gigabit network, 24-7 friendly support, even on holidays, and a seven-day money-back guarantee.

00:17:37.980 --> 00:17:42.740
Need a little help with your infrastructure? They even offer professional services to help you with

00:17:42.740 --> 00:17:47.300
architecture, migrations, and more. Do you want a dedicated server for free for the next four months?

00:17:47.300 --> 00:17:55.400
Just visit talkpython.fm/Linode. One of the things I think is interesting is this blend

00:17:55.400 --> 00:18:02.680
between Python and R. And it sounds to me like people are coming to one of those two languages,

00:18:02.680 --> 00:18:09.040
maybe even from somewhere else, maybe from Excel or from MATLAB or some of these other closed source

00:18:09.040 --> 00:18:15.580
commercial tools. What's that look like? Because for me, it feels like a lot of times these are

00:18:15.580 --> 00:18:23.900
positioned as an exclusive Python or R conversation. But maybe with that number of people, it's a slightly

00:18:23.900 --> 00:18:28.720
different dynamic. What's it like there for you? I would say historically, at least my experience,

00:18:28.720 --> 00:18:32.600
what I saw a lot of were people that were coming more from a computer science background,

00:18:32.600 --> 00:18:40.020
kind of naturally aligned with the Python mindset and syntax. And the folks that traditionally came from

00:18:40.020 --> 00:18:47.020
like a stats background or more of like a business analyst kind of gravitated towards R. And I still

00:18:47.020 --> 00:18:51.020
see a lot of that, but I think it's starting to change quite a bit because you're getting more of

00:18:51.020 --> 00:18:56.240
these like data science programs in universities. I mean, you're starting to get more of a mix within

00:18:56.240 --> 00:19:03.140
those programs. And those programs are trying to either select one language or they're blending

00:19:03.140 --> 00:19:09.400
two languages throughout the curriculum. So we still see a lot of crossover and folks coming with like

00:19:09.400 --> 00:19:15.360
more of an R or Python. It's just, to me, it's not as easy to kind of pick out who it is, right? I used

00:19:15.360 --> 00:19:19.240
to be able to look at someone and, you know, they said, well, you know, it's cool for computer science.

00:19:19.240 --> 00:19:23.420
I was like, okay, well, obviously you're going to be a Python, more likely a Python than an R.

00:19:23.420 --> 00:19:29.300
That's not always the case. So to me, it's getting a little bit more blurred. I think a lot of it just

00:19:29.300 --> 00:19:33.480
has to do with the environment they're coming from. So if they're coming from a university, then,

00:19:33.480 --> 00:19:37.900
you know, which university and what language are they just kind of like defaulting to?

00:19:37.900 --> 00:19:41.160
Maybe even down to who the professor was and what book they chose.

00:19:41.160 --> 00:19:41.660
Exactly. Yeah.

00:19:41.660 --> 00:19:46.740
Right. It's, it's, I feel like it's almost not even chosen. It's, it's this organic growth of,

00:19:46.740 --> 00:19:50.520
well, I was in this program and I had this professor a lot and that professor

00:19:50.520 --> 00:19:54.300
knew Python or they knew R. So that's what we did, right? That.

00:19:55.000 --> 00:19:59.500
Yep. And then also I think a lot of folks coming from, if you've got experience in industry and

00:19:59.500 --> 00:20:04.300
you're coming from a different company over at 8451, then lots of times it just kind of depends on

00:20:04.300 --> 00:20:10.180
the size of that company. It seems like companies that are smaller, that may be working with smaller

00:20:10.180 --> 00:20:15.100
data sets, have a smaller infrastructure. It's easier to work on your, your local R studio or

00:20:15.100 --> 00:20:17.120
PyCharm IDE and do your work. Yeah.

00:20:17.120 --> 00:20:21.900
Those companies that are much larger and you need like a larger infrastructure for your tech stack,

00:20:22.040 --> 00:20:26.580
I feel like they're kind of gravitating more towards Python. There's other reasons behind

00:20:26.580 --> 00:20:30.160
that. But so I think the size of the company also determines it.

00:20:30.160 --> 00:20:37.220
It's probably wired a little bit more aligned with a computer science and DevOps side of the world.

00:20:37.220 --> 00:20:42.480
And, you know, it's probably just, there's a, a greater tendency for those folks to also be using

00:20:42.480 --> 00:20:46.740
Python rather than to also be using R because, you know, if you come from a stats background,

00:20:46.740 --> 00:20:51.700
what do you know about Docker? Right. I mean, probably not much unless you had to just set it up for some

00:20:51.700 --> 00:20:53.320
reason for some research project, right?

00:20:53.320 --> 00:20:58.800
We find that especially at our size, having a very large dedicated engineering function and an

00:20:58.800 --> 00:21:03.540
architecture team and these other more technical teams tend to be a lot more fluent in Python.

00:21:03.540 --> 00:21:09.160
And so even in communicating with them and like when you have proof of concept applications, if you

00:21:09.160 --> 00:21:13.520
want to say, we're going to try to deploy something in a new way, that team is going to be a lot better

00:21:13.520 --> 00:21:18.760
able to support Python in general because it's, it's more like their background. So I've definitely seen

00:21:18.760 --> 00:21:24.200
since I've started R was a bit more popular. I think it's shifted to be about 50 50, but Python and R have sort of

00:21:24.200 --> 00:21:30.100
found their niche. I think R is still the superior tool for visualization, which is sad because I like Python a lot

00:21:30.100 --> 00:21:35.140
and I wish it were better, but, and I think there's hope, but R still is really, really good at that and really good at some

00:21:35.140 --> 00:21:42.160
other things, readable code with the pipe operator and things like that. And it seems like R is doing really well in more of our

00:21:42.160 --> 00:21:48.160
ad hoc analysis work. And then in our, our product style, like sciences that we deploy, that tends to be Python.

00:21:48.160 --> 00:21:56.940
Interesting. So yeah, so the research may happen more in R, but the productization and the deployment might happen, might find its way over to Python.

00:21:56.940 --> 00:22:11.600
Yeah. I think the more interactive type of work that you're doing, lots of times it's probably a little bit more majority on the R side, but the more we're trying to like standardize things or put things in some kind of automated procedure for production or whatever, that's when it starts to kind of gravitate towards Python.

00:22:11.600 --> 00:22:22.980
Python, just because that's usually when we start getting the engineers involved a little bit more. And then how do we, how can we integrate this within our tech stack? And there's usually just less friction if we're doing that on the Python side.

00:22:22.980 --> 00:22:50.880
Okay. So you talked about building these packages and libraries for folks to use to make things like Spark easier and so on. What is your view on this blended Python R world? Do you try to build the same basic API for both groups, but keep it Pythonic and I don't know, R-esque, whatever R is equivalent of Pythonic is? How do you think about that? Are they different functions? Because Python is more on the product side?

00:22:50.880 --> 00:23:01.140
This is a great question. It's been something that Ethan and I and a few other folks have really been trying to get our arms around. We don't know what the best approach is. We've tried a few different things.

00:23:01.880 --> 00:23:20.580
For example, so like we just have a standard process of ingesting data, right? So we got to do some kind of a data query. There's lots of times just common like business rules that we need to apply. We call them golden rules. You know, certain stores, certain products we're going to filter out, certain kind of loyalty membership, whatever, we're going to discard those.

00:23:20.880 --> 00:23:30.960
And that's all business logic. And typically, historically, we've had very large SQL scripts that people were applying the same thing over and over, maybe slight twists.

00:23:31.360 --> 00:23:41.800
A lot of that stuff, we can just kind of bundle up in both an R and a Python package to apply that golden rules or the business logic. And it just makes their work more efficient, right?

00:23:41.840 --> 00:23:52.580
So now their data query goes from like applying this big script to just like, all right, here's a function that does that initial data query, get that output, then go and personalize your science, whatever you're doing.

00:23:52.580 --> 00:24:00.200
Something like that, that's a great way where we can have both an R and a Python capability, as long as it doesn't get too large, right?

00:24:00.200 --> 00:24:08.220
So when we do something like that, you know, we want to try to keep the R and Python packages, one, a similar capability, right?

00:24:08.220 --> 00:24:18.400
So that the output that we get from both packages are going to be the same, that the syntax is going to be very similar, that the functionality is going to be very similar as well, right?

00:24:18.400 --> 00:24:30.800
So basically, you want somebody to look at R and the Python packages, like it's doing the same thing, we're getting the same output, it has no impact on the output of the analysis, regardless of what package you use.

00:24:30.800 --> 00:24:47.340
Yeah, well, it sounds super important, because if you evolve or version that SQL query just a little bit, and they get out of sync, and then you go do a bunch of predictive analysis on top of it, and you say, well, we decided this, but actually earlier, we thought this, but now it's that.

00:24:47.340 --> 00:24:48.900
Like, no, that's just a different query.

00:24:48.900 --> 00:24:50.520
This is the problem, right?

00:24:50.520 --> 00:24:51.980
Like, it's a huge problem.

00:24:51.980 --> 00:24:57.680
Yeah, it seems like you really want to control that if you can bundle that away into it, your call this function will tell you what the data is.

00:24:57.680 --> 00:24:59.040
And just maintain that.

00:24:59.040 --> 00:24:59.440
That's great.

00:24:59.440 --> 00:25:05.740
But even that kind of what you're talking about right there, we see the same thing happen when we're building these packages kind of in tandem between the two languages.

00:25:05.740 --> 00:25:13.040
Because it may be easy to kind of like, create that initial package that does a few things, and they're both operating very similar.

00:25:13.360 --> 00:25:18.560
But the second you start getting, you know, eight other folks from across the company, it's like, oh, this is great.

00:25:18.560 --> 00:25:22.200
I want to go and do a pull request and make a slight modification.

00:25:22.200 --> 00:25:26.140
Then it's like, all right, well, I saw the Python just had like eight updates.

00:25:26.140 --> 00:25:27.780
What are we going to do on the R side?

00:25:27.780 --> 00:25:30.380
Are we going to do these exact same implementations or not?

00:25:30.760 --> 00:25:33.240
Or maybe it's a unique thing that's kind of language specific.

00:25:33.240 --> 00:25:36.380
And it's like, well, how do we kind of do that same thing within R?

00:25:36.380 --> 00:25:46.100
And that's where it kind of explodes to be like, okay, there's no way we could actually build every single package we want to build in both R and Python and keep them at the same level.

00:25:46.100 --> 00:25:46.480
Sure.

00:25:46.480 --> 00:25:49.280
That's where it gets difficult to kind of figure out like what direction we need to go.

00:25:49.280 --> 00:25:49.560
Yeah.

00:25:49.560 --> 00:25:50.320
And what's your philosophy?

00:25:50.320 --> 00:25:54.820
Are you let people make these changes and get the best library they can?

00:25:54.820 --> 00:25:56.960
Or is it like, no, they need to be more similar.

00:25:56.960 --> 00:25:57.920
This is a problem.

00:25:58.040 --> 00:25:59.180
We're kind of figuring that out.

00:25:59.180 --> 00:26:05.660
That's been one really interesting experience because in this regard, I mean, both in terms of the size of the data science function and how heterogeneous it is.

00:26:05.660 --> 00:26:13.140
I do think we're maybe, if not totally unusual, we're maybe a little ahead in running into these problems than what I read on the Internet.

00:26:13.140 --> 00:26:15.680
But I haven't read a lot of other people grappling with this problem.

00:26:15.680 --> 00:26:20.120
So, you know, if you're listening and you've done this and you figured out a good strategy, let us know.

00:26:20.120 --> 00:26:22.780
But I think we're still figuring out exactly what it is.

00:26:22.780 --> 00:26:31.640
And so one thing Brad and I have discussed a lot is what are our options for building one underlying set of functionality that then you can interface with from both languages?

00:26:31.640 --> 00:26:37.680
And that's pretty tricky because, you know, there's like an R package called reticulate that you can run Python code in.

00:26:37.680 --> 00:26:41.000
And then there's a Python package called RPy2 that you can run R code in.

00:26:41.260 --> 00:26:48.620
But these things tend to get a little unmanageable because they don't deal with environments the same way that native Python or R install does.

00:26:48.620 --> 00:26:50.140
And so these things are just challenges.

00:26:50.140 --> 00:27:00.680
We're experimenting right now with a way of tying together R and Python in the same session of a notebook by having them share what's called a Spark session, which is your connection to a Spark cluster.

00:27:01.260 --> 00:27:08.940
And so in theory, under the hood, you could do all the work in one of the languages and return to the user a Spark object, which is translatable to both.

00:27:08.940 --> 00:27:12.460
And so this is one of the things we're experimenting with, but we're trying a few different things.

00:27:12.460 --> 00:27:17.820
But we've definitely found that separately maintaining two identical APIs is extremely challenging.

00:27:17.820 --> 00:27:20.640
And I don't think we can do that for multiple packages going forward.

00:27:20.640 --> 00:27:21.040
Right.

00:27:21.300 --> 00:27:21.420
Yeah.

00:27:21.420 --> 00:27:29.020
You have to have a pretty ironclad decider of the API, and then we'll just manifest that in the two languages.

00:27:29.020 --> 00:27:30.940
And that's also pretty constrained, right?

00:27:30.940 --> 00:27:33.540
Well, it really stifles contributions, right?

00:27:33.540 --> 00:27:36.380
Because like Brad said, people want to issue a pull request.

00:27:36.380 --> 00:27:41.460
And we don't want anybody who contributes to have to know both languages thoroughly enough to build it in both.

00:27:41.460 --> 00:27:43.900
I mean, already we would ask them for documentation and things.

00:27:43.900 --> 00:27:48.120
And it's like you're just broadening the size of the ask and limiting your potential contributors at that point.

00:27:48.120 --> 00:27:48.940
Where's your unit tests?

00:27:48.940 --> 00:27:50.960
And where your unit tests are, right?

00:27:51.100 --> 00:27:51.660
Oh my goodness.

00:27:51.660 --> 00:27:51.940
Yeah.

00:27:51.940 --> 00:27:53.260
Interesting.

00:27:53.260 --> 00:27:58.020
Well, my first thought when you were talking about this as a web developer background was,

00:27:58.020 --> 00:28:02.280
well, maybe you could build some kind of API endpoint that they call.

00:28:02.280 --> 00:28:04.320
And it doesn't matter what that's written in.

00:28:04.320 --> 00:28:05.880
Heck, that could be Java or something.

00:28:05.880 --> 00:28:06.360
Who knows?

00:28:06.360 --> 00:28:06.920
Yeah.

00:28:06.920 --> 00:28:13.160
Long as they get their JSON back in a uniform manner across the different languages, that might work.

00:28:13.160 --> 00:28:17.160
It sounds like the Spark object is a little bit like the data side of that.

00:28:17.160 --> 00:28:20.460
That's the issue, ultimately, that for a lot of the stuff we're doing,

00:28:20.700 --> 00:28:23.120
we need to actually transform data in some way.

00:28:23.260 --> 00:28:29.460
And so sending a huge, you know, sending many gigabytes of data across a web API is not going to be very efficient.

00:28:29.460 --> 00:28:31.560
Even if you turn on GZEP, it's still slow.

00:28:31.560 --> 00:28:32.260
Yeah.

00:28:32.400 --> 00:28:39.820
So that solution is something we've considered also that idea of like, maybe we can subscribe to some kind of REST endpoint and just use that.

00:28:39.820 --> 00:28:41.200
And that works for certain problems.

00:28:41.200 --> 00:28:44.240
But for a lot of our problems, it's ultimately about changing the data in some way.

00:28:44.240 --> 00:28:45.800
So it doesn't work quite as well.

00:28:45.800 --> 00:28:46.200
I see.

00:28:46.200 --> 00:28:54.920
So the ability to directly let the database or Spark cluster do its processing and then give you the answer is really where it has to be.

00:28:54.920 --> 00:28:55.580
Exactly.

00:28:55.580 --> 00:28:56.020
Yeah.

00:28:56.140 --> 00:28:56.460
Okay.

00:28:56.460 --> 00:28:58.000
Interesting.

00:28:58.700 --> 00:29:03.720
What other lessons do you all have from building the packages for two groups?

00:29:03.720 --> 00:29:07.200
People out there thinking, you know, maybe it doesn't even have to be Python or R.

00:29:07.200 --> 00:29:09.020
It could be Python and Java, like I said.

00:29:09.020 --> 00:29:12.000
But there's a lot of these mixed environments out there.

00:29:12.000 --> 00:29:18.500
Although, like I said, I think this is a particularly interesting data science blend of at the scale you all are working at.

00:29:18.500 --> 00:29:27.000
One thing I've noticed is that being closely tied into a wide number of people in different parts of your data science function is really important because the way people use things is so different.

00:29:27.000 --> 00:29:32.600
So we talked briefly about how people come from very different backgrounds within our data science function.

00:29:32.600 --> 00:29:37.260
And that means that their understanding of how to use functionality is quite different.

00:29:37.260 --> 00:29:46.460
And one thing I have to resist all the time is building a piece of functionality that to me looks really elegant because I realize the ways that it could be used or it supports some kind of customization.

00:29:47.200 --> 00:29:56.660
For example, and I was talking about this with someone else who works on packages, the idea that maybe the user could pass in a custom function that would then override part of a pipeline or something.

00:29:56.660 --> 00:29:59.860
And I always have to remember that, like, most people aren't going to do that.

00:29:59.860 --> 00:30:03.100
The vast majority of our data scientists aren't attracted to these elegant solutions.

00:30:03.100 --> 00:30:05.000
They just want the purely functional ones.

00:30:05.000 --> 00:30:06.320
Like, what is this Lambda word?

00:30:06.320 --> 00:30:07.760
Why do you make it so complicated?

00:30:07.760 --> 00:30:08.660
Can I just call it?

00:30:08.660 --> 00:30:10.140
Lambdas are a very good example.

00:30:10.140 --> 00:30:10.500
Yeah.

00:30:10.500 --> 00:30:17.100
And so it's good to remember, like, we're building this as a functional thing for people who don't want to learn every aspect of computer science.

00:30:17.100 --> 00:30:18.560
They want to get their data science work done.

00:30:18.560 --> 00:30:18.880
Okay.

00:30:18.880 --> 00:30:19.500
Yeah.

00:30:19.500 --> 00:30:20.560
Good advice.

00:30:20.560 --> 00:30:21.160
Brad?

00:30:21.160 --> 00:30:30.480
So I think another thing that we've kind of been running into is, and I think this is more and more common with other companies, is we have kind of a, we have many different tech stacks.

00:30:30.480 --> 00:30:34.620
Basically, we are working on-prem servers.

00:30:34.620 --> 00:30:36.300
We have on-prem Hadoop.

00:30:36.300 --> 00:30:40.060
We are working in two different cloud environments right now.

00:30:40.600 --> 00:30:46.880
So basically, we have, like, four different environments that our data scientists could be using these packages in.

00:30:46.880 --> 00:30:49.200
And so a lot of times it takes a lot of planning.

00:30:49.200 --> 00:30:56.080
Like, are we going to actually try to make this package completely agnostic to whatever environment you're in and be able to use it?

00:30:56.080 --> 00:31:02.520
Or do we just want to say, hey, look, this is a package that does this one capability, but it's specific to this one cloud environment?

00:31:03.060 --> 00:31:04.980
And that takes a lot of planning.

00:31:04.980 --> 00:31:15.580
I think going into it, you know, like myself, Ethan, several other folks, we have built packages before, but it was largely, like, in more of an isolated environment.

00:31:15.580 --> 00:31:22.540
Or it was just like, I'm just building a package that someone's going to use on their local ID on their own laptop.

00:31:22.780 --> 00:31:25.600
It's focused, and you know what they're going to try to do with it.

00:31:25.600 --> 00:31:26.080
Right, right.

00:31:26.080 --> 00:31:31.600
So I think we've gotten a lot better at, like, really trying to plan out, like, what do we want this to look like?

00:31:31.600 --> 00:31:33.520
And what are the stages that we're going to take?

00:31:33.520 --> 00:31:36.720
That's still something we have a lot of work to do and get better at.

00:31:36.720 --> 00:31:42.780
But I think the nice thing is we have kind of a group of data scientists that are really getting better at this.

00:31:42.780 --> 00:31:48.820
And it's allowing us to kind of, like, understand, like, good, proper software engineering and approaches to that.

00:31:48.820 --> 00:31:52.180
And I think that's slowly kind of filtering out to the other data scientists.

00:31:52.180 --> 00:31:56.400
As we get smarter, we're trying to upscale their folks on thinking that same way.

00:31:56.400 --> 00:31:56.680
Sure.

00:31:56.680 --> 00:31:57.060
Yeah.

00:31:57.060 --> 00:32:04.240
And building off what Brad's saying about, like, the challenges of building packages in an enterprise environment for people to use them in a variety of different ways.

00:32:04.240 --> 00:32:10.040
One thing that was new to me was, like, building this stuff through enterprise tools is quite different than doing it on your own.

00:32:10.040 --> 00:32:16.060
So a lot of people who maintain things like open source packages are using Travis CI, for example.

00:32:16.060 --> 00:32:18.960
And we have, like, an enterprise CI-CD solution.

00:32:18.960 --> 00:32:21.300
And these things tend to require authentication.

00:32:21.580 --> 00:32:24.200
And they need to be integrated with other enterprise systems.

00:32:24.200 --> 00:32:29.680
And so these things are all, at least for me, things that I never encountered in, like, personal projects or things in school.

00:32:29.680 --> 00:32:31.480
But it is the challenges of working in a large company.

00:32:31.480 --> 00:32:34.420
There's a lot of things that are locked down that require a sign-on in some way.

00:32:34.420 --> 00:32:35.380
You have to pass credentials.

00:32:35.380 --> 00:32:38.260
And these are like a whole new realm of problems to solve.

00:32:38.420 --> 00:32:38.540
Yeah.

00:32:38.640 --> 00:32:43.340
There's definitely more molasses in the gears or whatever in the enterprise world.

00:32:43.340 --> 00:32:45.940
You can't just quickly throw things together, right?

00:32:45.940 --> 00:32:49.480
You might have to do, well, like, my unit tests require a single sign-on.

00:32:49.480 --> 00:32:50.060
Why is that?

00:32:50.060 --> 00:32:51.120
This is really crazy.

00:32:51.120 --> 00:32:51.540
Yeah.

00:32:51.540 --> 00:32:53.160
And mocking gets quite challenging.

00:32:53.400 --> 00:33:02.000
So that's one issue we have where mocking our tests, I mean, it could either be a giant project or we could do it in a mostly correct way.

00:33:02.000 --> 00:33:05.620
You know, we could take a subset of the data and say this is, like, a good enough sample of it.

00:33:05.620 --> 00:33:12.120
But this isn't really representative of what we want this package to do, especially because these are all really integration tests.

00:33:12.120 --> 00:33:15.180
They're all, like, making sure that you actually can connect to the system.

00:33:15.180 --> 00:33:18.980
So if you mock a system, essentially you're taking out one of the things you want to test.

00:33:18.980 --> 00:33:23.440
You want to make sure you actually can connect to the real system because that's the challenge of building this functionality.

00:33:23.440 --> 00:33:28.380
It's such a challenge because sometimes the thing that you're mocking out is simple.

00:33:28.900 --> 00:33:37.360
But sometimes it's such an important system that if you don't do a genuine job of mocking it out, then what's the point of even having the test?

00:33:37.360 --> 00:33:41.980
You know, I'm thinking of, like, complicated databases with 50 tables.

00:33:41.980 --> 00:33:46.000
Yeah, sure, you can tell it's just going to return this data when you do this query.

00:33:46.000 --> 00:33:49.980
But what if the data structure actually changes in the database, right?

00:33:49.980 --> 00:33:52.400
Sure, the tests run because it thinks it has the old data.

00:33:52.400 --> 00:33:53.520
But what does that tell you, right?

00:33:53.860 --> 00:34:03.440
Or if you're integrating with, say, AWS and talking to S3 and Elastic Transcoder and you've got to get some result or, like, Elastic Transcriber for text.

00:34:03.440 --> 00:34:10.440
And you're going to process those, you know, at some point, you're almost not even testing if you mock it too little.

00:34:10.440 --> 00:34:13.740
And then, like you said, it's a huge project to recreate something like that.

00:34:13.740 --> 00:34:18.920
It's funny you say the 50 tables thing because our central data mart is itself about 50 tables.

00:34:18.920 --> 00:34:23.120
And then occasionally we also rely on things that are created by other data scientists.

00:34:23.120 --> 00:34:26.260
And so, yeah, the scope of it is very large and it changes a lot in the background.

00:34:26.260 --> 00:34:32.640
And then also, I kind of feel that Spark is a much more immature technology than some of the old database technologies.

00:34:32.640 --> 00:34:36.420
And so updates happen that actually change the functionality of the system.

00:34:36.420 --> 00:34:39.740
And suddenly it's like the things that worked before don't work anymore.

00:34:39.740 --> 00:34:43.020
And you're mocking, you know, like if you mock up Spark, that's not going to work.

00:34:43.020 --> 00:34:43.980
It's not going to be the same.

00:34:43.980 --> 00:34:47.960
Yeah, it's going to say the test passed, but it'll wait till production and maybe Q&A to fail, right?

00:34:47.960 --> 00:34:50.120
Yeah, these are things we have to think about more and more.

00:34:52.380 --> 00:34:54.760
The next episode of Talk Python to me is brought to you by Tidelift.

00:34:54.760 --> 00:34:57.860
Tidelift is the first managed open source subscription,

00:34:57.860 --> 00:35:04.060
giving you commercial support and maintenance for the open source dependencies you use to build your applications.

00:35:04.060 --> 00:35:07.320
And with Tidelift, you not only get more dependable software,

00:35:07.320 --> 00:35:10.540
but you pay the maintainers of the exact packages you're using,

00:35:10.540 --> 00:35:12.820
which means your software will keep getting better.

00:35:13.220 --> 00:35:20.040
The Tidelift subscription covers millions of open source projects across Python, JavaScript, Java, PHP, Ruby, .NET, and more.

00:35:20.040 --> 00:35:25.160
And the subscription includes security updates, licensing, verification, and indemnification,

00:35:25.160 --> 00:35:29.040
maintenance and code improvements, package selection and version guidance,

00:35:29.040 --> 00:35:32.080
roadmap input, and tooling and cloud integration.

00:35:32.080 --> 00:35:37.340
The bottom line is you get the capabilities you'd expect and require from commercial software.

00:35:37.340 --> 00:35:41.260
But now for all the key open source software you depend upon,

00:35:41.260 --> 00:35:45.780
just visit talkpython.fm/Tidelift to get started today.

00:35:47.360 --> 00:35:51.520
So you talked about the four different places where code runs, Brian.

00:35:51.520 --> 00:35:54.880
You've got your Hadoop cluster locally, your Spark cluster locally,

00:35:54.880 --> 00:35:57.400
the two cloud vendors that you're running on.

00:35:57.400 --> 00:35:58.560
Where are you headed?

00:35:58.560 --> 00:36:01.840
Which one of those is legacy and which one is where you're headed?

00:36:01.840 --> 00:36:02.820
Or are they all active?

00:36:02.820 --> 00:36:04.680
We're definitely headed towards a cloud environment.

00:36:04.680 --> 00:36:04.960
Okay.

00:36:04.960 --> 00:36:09.500
The problem that we have, one, we do have data that is quite sensitive still.

00:36:09.500 --> 00:36:15.560
And, you know, we got to make sure that we have all the security aligned within the cloud environment

00:36:15.560 --> 00:36:17.080
before we can transition that.

00:36:17.080 --> 00:36:20.700
And then we just have a lot of historical code still running.

00:36:20.700 --> 00:36:27.820
And so you figure we got, you know, 250 analysts and we have just that many projects going on.

00:36:27.820 --> 00:36:30.500
Like, how do we transition a lot of that code into the cloud?

00:36:30.500 --> 00:36:37.840
So I think it's going to be many years of working in this kind of multi-environment kind of strategy.

00:36:38.160 --> 00:36:42.520
I think ultimately the goal would be to be to a single cloud environment.

00:36:42.520 --> 00:36:49.380
But then also from like a bit, I understand for like a business strategy that locks you into a kind of a certain pricing structure.

00:36:49.380 --> 00:36:52.160
We may try to have multi-cloud environment.

00:36:52.160 --> 00:36:53.580
That's pretty common across companies.

00:36:53.960 --> 00:36:58.920
I think long-term we will try to be mostly in the cloud, whether or not we'll be with one vendor or not.

00:36:58.920 --> 00:37:00.060
That's to be decided.

00:37:00.060 --> 00:37:00.360
Yeah.

00:37:00.360 --> 00:37:08.180
The one thing that I think what has changed with our recruiting is definitely looking for folks that aren't scared away from, you know, the work in a cloud environment.

00:37:08.180 --> 00:37:08.700
Yeah.

00:37:08.700 --> 00:37:14.120
A lot of students are coming from university that do not have any experience with like a Spark environment.

00:37:14.120 --> 00:37:15.320
And that's fine.

00:37:15.320 --> 00:37:17.460
It's not like we're expecting you to do that.

00:37:17.460 --> 00:37:21.280
But you need to be open and willing and be prepared to work in that environment.

00:37:21.280 --> 00:37:22.580
So that's definitely a big change.

00:37:22.580 --> 00:37:32.560
It's also amazing we got this far without talking about SaaS because we, like many, many analytical companies that have been around for more than five or 10 years, have still dependencies on SaaS.

00:37:32.560 --> 00:37:35.220
It's just very difficult to migrate off of enterprise tools.

00:37:35.760 --> 00:37:39.080
And so, you know, we've been in the process of migrating from SaaS for quite some time.

00:37:39.080 --> 00:37:45.480
And it's funny because when I came in here, which was three and a half years ago, the company was almost entirely on SaaS.

00:37:45.480 --> 00:37:47.380
And R was like the upstart language.

00:37:47.380 --> 00:37:50.220
And I think I was one of like two or three Python users in the whole company.

00:37:50.220 --> 00:37:51.300
And things have changed a lot.

00:37:51.300 --> 00:37:55.680
But like making the final cut, severing ties from old technologies is challenging.

00:37:55.680 --> 00:37:57.600
It's one of the reasons we have so many platforms.

00:37:57.600 --> 00:38:02.480
You just end up with production of things running on all these platforms and it would be a lot of work to change them.

00:38:02.480 --> 00:38:03.760
So it just moves slowly.

00:38:04.040 --> 00:38:09.420
Well, some of those systems, they're carefully balanced and highly finicky, but important.

00:38:09.420 --> 00:38:09.940
Right.

00:38:09.940 --> 00:38:15.220
And if you try to change them and you break it, all of a sudden that becomes your baby.

00:38:15.220 --> 00:38:17.340
You have to babysit when it cries at night.

00:38:17.340 --> 00:38:17.600
Right.

00:38:17.600 --> 00:38:22.000
Like I'd rather not have SaaS, but I'd more than that.

00:38:22.000 --> 00:38:25.700
I'd rather not touch that thing and make it my responsibility because currently it's not.

00:38:25.700 --> 00:38:25.940
Right.

00:38:25.940 --> 00:38:29.900
Like that's certainly an enterprise sort of experience, right?

00:38:29.900 --> 00:38:30.320
Yep.

00:38:30.320 --> 00:38:30.920
For sure.

00:38:30.920 --> 00:38:31.480
Yeah.

00:38:31.480 --> 00:38:40.200
Well, what's the transition been like from this somewhat expensive commercial product over to the combination of Python and R?

00:38:40.200 --> 00:38:41.920
Was that easy?

00:38:41.920 --> 00:38:42.840
Was it hard?

00:38:42.840 --> 00:38:43.860
Did people welcome it?

00:38:43.860 --> 00:38:44.740
Did they resist it?

00:38:45.000 --> 00:38:48.280
You both do some on the education side within the company.

00:38:48.280 --> 00:38:52.460
So you probably have a lot of visibility into how that first impression went.

00:38:52.600 --> 00:38:56.140
So I used to lead our introduction to Python trainings.

00:38:56.140 --> 00:38:59.840
So we have, like I said, some continuing education classes in the company.

00:39:00.200 --> 00:39:07.640
And I will say I was just so surprised by the reaction people had to a new technology training the first time I gave it.

00:39:07.640 --> 00:39:15.980
Because coming out of a computer science program where you sort of get thrown into languages, like I had a class in Java my senior year and I'd never use Java and the professor just sort of expected we'd pick it up.

00:39:15.980 --> 00:39:20.800
I never really thought about this idea that you would be resistant to learning new technologies.

00:39:20.800 --> 00:39:27.320
But when one software tool has dominated your industry for 20 years as SAS had, it's just really unfamiliar.

00:39:27.320 --> 00:39:31.900
So I gave this course and a lot of people were asking questions that to me it was like, well, obviously you would Google that.

00:39:31.900 --> 00:39:34.040
You know, like obviously you would look in the docs.

00:39:34.040 --> 00:39:35.000
Obviously you do this.

00:39:35.000 --> 00:39:41.640
And it's not obvious because these people come from a closed source tool that is carefully maintained and is highly backwards compatible.

00:39:41.640 --> 00:39:46.320
But at the same time, it's not nearly as dynamic an ecosystem as something like Python or R.

00:39:46.320 --> 00:39:49.820
And I think I've watched the culture change a lot since I started.

00:39:50.240 --> 00:39:56.240
And I look at even the people coming out of school that start and they're so much more willing to jump into things, which I think is great.

00:39:56.240 --> 00:40:00.100
And even the people that were here when I started have gotten more that way as well.

00:40:00.100 --> 00:40:06.040
People have just like learned that the culture of open source tools is very different and you have to be more willing to jump from thing to thing.

00:40:06.040 --> 00:40:11.180
And as we introduce new technologies, because we still do, people are more able to learn those, which I think is really great.

00:40:11.180 --> 00:40:12.320
I can certainly see that.

00:40:12.320 --> 00:40:14.920
You know, I'm somewhat sympathetic to those folks.

00:40:14.920 --> 00:40:28.020
If you have spent a long time and you are very good at the tasks that you have to get done in one language or one technology and you've got to switch over, it's all of a sudden like I feel brand new again.

00:40:28.020 --> 00:40:31.060
Like I remember not being able to load a file.

00:40:31.060 --> 00:40:35.620
I remember not being able to actually properly, efficiently query a database.

00:40:35.840 --> 00:40:39.140
I remember like all these things you're like, all of these are, I have these problems again.

00:40:39.140 --> 00:40:40.580
I thought like I was beyond that.

00:40:40.580 --> 00:40:40.820
Right.

00:40:40.820 --> 00:40:43.200
And that's, that's certainly a challenging.

00:40:43.200 --> 00:40:54.980
The other thing I think that makes it tricky going from something like that, or, you know, even something from like, say, C# and .net, where there's like a Microsoft that says, here's what the web stack looks like.

00:40:54.980 --> 00:41:01.040
And we'll, we'll tell you in six months what the changes are going to be is in the open source space.

00:41:01.040 --> 00:41:04.760
There's probably 10 different things that do what you want to do.

00:41:04.760 --> 00:41:07.780
And how do you know which one of those to pick?

00:41:07.780 --> 00:41:16.240
And then once you bet on one and you work on it for a while, all of a sudden, either maybe it gets sort of, it loses cache or something else comes along.

00:41:16.400 --> 00:41:20.120
There's just, instead of being one or two ways to do a thing, now there's 20.

00:41:20.120 --> 00:41:22.760
And it's like, I'm kind of new here.

00:41:22.760 --> 00:41:24.660
So how do I even decide which of those 20?

00:41:24.660 --> 00:41:26.000
Because it's, it's hard.

00:41:26.000 --> 00:41:28.540
Yeah, that is absolutely a concern that people had.

00:41:28.540 --> 00:41:31.940
I all the time would get this question because I was known as the Python guy early on.

00:41:31.940 --> 00:41:34.980
You know, like, what do I do if this package changes?

00:41:34.980 --> 00:41:36.840
Or like, how do I know this is still going to work?

00:41:36.840 --> 00:41:38.760
There's no company that's behind this tool.

00:41:38.760 --> 00:41:44.380
And if you come from this world, like if you come from the open source side, you think two things.

00:41:44.500 --> 00:41:46.460
One, like most of the time the stuff keeps working.

00:41:46.460 --> 00:41:48.660
Like the core functionality is extremely stable.

00:41:48.660 --> 00:41:53.040
All the most popular open source languages, like they don't just stop being maintained.

00:41:53.040 --> 00:41:56.020
Stuff is extremely, extremely well used.

00:41:56.020 --> 00:42:01.580
And also, you know that if a package is no longer maintained, you look for another one because that stuff happens dynamically.

00:42:01.580 --> 00:42:02.840
And it's unusual.

00:42:02.840 --> 00:42:04.400
You'd have to be using something pretty fringe.

00:42:04.400 --> 00:42:10.280
But it's unusual for you to end up being just out of luck in terms of having some functionality available to you.

00:42:10.280 --> 00:42:10.540
Right.

00:42:10.540 --> 00:42:12.540
Yeah, there's some few edge cases, but it's not common.

00:42:12.700 --> 00:42:16.720
And, you know, there's always the, well, you can fork it and just run it.

00:42:16.720 --> 00:42:16.920
Right.

00:42:16.920 --> 00:42:25.040
If you use something that's pretty mature, the chances that it has a massive show-stopping problem discovered down the road, they're not that high usually.

00:42:25.040 --> 00:42:26.520
Things stick around.

00:42:26.520 --> 00:42:26.740
Right.

00:42:26.740 --> 00:42:28.860
NumPy is probably not going to go unmaintained.

00:42:28.860 --> 00:42:29.180
You know.

00:42:29.180 --> 00:42:29.760
Exactly.

00:42:29.980 --> 00:42:31.020
Django still has users.

00:42:31.020 --> 00:42:32.360
Things like that, right?

00:42:32.360 --> 00:42:34.500
You know, that's one thing that we do try to do internally.

00:42:34.500 --> 00:42:38.360
And it's one thing that we're trying to get a little bit more smart on how we do it.

00:42:38.360 --> 00:42:49.500
But with so many packages and so many capabilities out there, it's like, how do we make sure people are using kind of like a core set of packages that we kind of endorse or do the primary things that we want to do?

00:42:50.040 --> 00:42:55.080
We try to create a little bit more structure around like what packages should we be using internally?

00:42:55.080 --> 00:42:58.300
And then what's the process of bringing in like a newer package, right?

00:42:58.420 --> 00:43:03.300
Do you guys have like a white labeling process where you sort of vet them or how does that work?

00:43:03.300 --> 00:43:15.380
We're a little bit better about setting up like a sandbox area where, you know, if we find a package that is new or even like a package that's just on GitHub and not PyPI or CRAN, then how can we bring that in?

00:43:15.380 --> 00:43:16.480
Do some testing.

00:43:16.480 --> 00:43:21.200
Make sure that there's not any like interactions going on within our servers or whatever.

00:43:21.540 --> 00:43:32.040
And then as long as we kind of pass all those regression tests, then yeah, okay, we can start bringing that in formally as a standard package in our servers or wherever.

00:43:32.040 --> 00:43:34.100
Do you have a private PyPI server?

00:43:34.100 --> 00:43:41.720
I don't know if you do have a CRAN, but CRAN server as well, like that you have more control over or do you let people just pip install straight off the main?

00:43:41.720 --> 00:43:48.840
We use Artifactory, which is a tool that basically sets up those package repositories and you can have it clone them.

00:43:48.840 --> 00:43:52.860
So, you know, we have what looks like a copy of PyPI, but then we blacklist certain things.

00:43:52.860 --> 00:43:54.920
We whitelist certain things depending on the environment.

00:43:54.920 --> 00:43:55.420
Yeah.

00:43:55.420 --> 00:43:56.680
And it works for CRAN as well.

00:43:56.680 --> 00:43:57.440
That's a really cool.

00:43:57.440 --> 00:44:02.260
That's a quite, it seems like a very elaborate system, but for you all, it sounds like it's the right thing.

00:44:02.260 --> 00:44:17.360
The nice thing about that is with our internal packages, we can actually have our CICD process push them to that Artifactory so that they could do, you know, pip install, whatever the package or install.packages in our, that package name.

00:44:17.360 --> 00:44:24.280
And it's like you are importing it from PyPI or CRAN, but really you're just pulling it from our internal Artifactory.

00:44:24.280 --> 00:44:24.560
Yeah.

00:44:24.560 --> 00:44:33.940
When you have a scale of 250 people, you almost want to say the way that you share code across teams is the same way that you share code across open source, right?

00:44:33.940 --> 00:44:43.680
It's, you create these packages, you put them into, you version them, you put them into Artifactory, maybe even pin your version in your deployment, things like that, right?

00:44:43.680 --> 00:44:44.320
Is that what you do?

00:44:44.400 --> 00:44:50.380
Sort of like getting that standard across the, getting the knowledge of these standards across the business is like one of our chief challenges.

00:44:50.380 --> 00:44:56.800
Because just like open source, people don't necessarily hear about new packages that solve problems they've been encountering a bunch of times.

00:44:57.340 --> 00:45:06.140
So while we encourage people to do things like pinning packages, we're still at an even earlier step where it's like, be aware of what new functionality is in these packages we're using.

00:45:06.140 --> 00:45:10.200
Because all the time I see people setting up elaborate configurations with Spark.

00:45:10.200 --> 00:45:16.100
And then I tell them we have a package that we, you know, we first released 1.0 like two months ago.

00:45:16.100 --> 00:45:20.640
And it's like, all of this could be done for you, you know, and we can send as many emails as we want.

00:45:20.640 --> 00:45:25.880
But people who work with 249 other data scientists delete a lot of emails because there's too many.

00:45:25.880 --> 00:45:28.000
So, so finding a good.

00:45:28.000 --> 00:45:28.440
Yeah.

00:45:28.440 --> 00:45:32.520
It's another plague in the enterprise is like everyone thinks that you need to be copied.

00:45:32.520 --> 00:45:39.820
Like if there's even a chance you need to know about it and what it results in is if everything's important, nothing is important, right?

00:45:39.820 --> 00:45:40.620
A big problem.

00:45:40.620 --> 00:45:40.920
Yeah.

00:45:40.920 --> 00:45:46.500
And so figuring out how to socialize these, the, the way to use these packages and what packages even exist.

00:45:46.500 --> 00:45:52.460
And then beyond that, like how to use them properly and version things properly is always something we have to think carefully about.

00:45:52.460 --> 00:45:53.260
How do you all do that?

00:45:53.260 --> 00:46:01.620
I mean, just letting folks know, like there is now a library that you can install that solves this problem or does that, or it has this challenge.

00:46:02.080 --> 00:46:03.900
We're looking for feedback on how to make it better.

00:46:03.900 --> 00:46:09.240
How do you get the word out about your projects and packages internally?

00:46:09.240 --> 00:46:12.280
So we've tried to start doing a little bit of like beta testing.

00:46:12.280 --> 00:46:21.260
So if we have a brand new package we're developing before we actually do a full release, we'll try to get a group of folks that do some beta testing on it to kind of give feedback.

00:46:21.380 --> 00:46:23.600
You know, one is the functionality there.

00:46:23.600 --> 00:46:24.660
Are there bugs that we're missing?

00:46:24.660 --> 00:46:30.240
Two is the syntax kind of logical coming from more of the data science perspective.

00:46:30.660 --> 00:46:37.660
And then three is the documentation there that they need to basically pick up from no knowledge of it and start applying it.

00:46:37.940 --> 00:46:39.920
And that gives us that good initial feedback.

00:46:39.920 --> 00:46:49.860
And then once we start getting the first release and everything, right now what we are doing is basically doing that email blast to all our data scientists and saying, here's the version number.

00:46:49.860 --> 00:46:53.000
Here's what's new, what you need to know, how it impacts you.

00:46:53.460 --> 00:47:00.560
But ultimately, I think what I've learned is that the most important thing is having advocates across the company that know about this.

00:47:00.560 --> 00:47:05.600
Because often new functionality will arise and will only take over in part of the business.

00:47:05.600 --> 00:47:10.740
When you have 250 people, it's like who knows about what is very different across teams.

00:47:10.740 --> 00:47:16.600
And so one of the things we focused on with like our beta testers is making sure that this is a well-rounded group of people in different teams.

00:47:16.740 --> 00:47:23.600
So those people serve as sort of the evangelists to tell other people on their team like, well, when you run into these problems, you should be doing this.

00:47:23.600 --> 00:47:26.720
And that's really the only way to get that information across.

00:47:26.720 --> 00:47:31.340
Because we can't sit in everybody's meetings and we can't like go and look over people's shoulders as they code.

00:47:31.340 --> 00:47:33.200
So we need other people to do that for us.

00:47:33.200 --> 00:47:35.640
So our first adopters are really the people that help.

00:47:35.640 --> 00:47:38.520
That sounds like a pretty good way to set things up.

00:47:38.520 --> 00:47:45.700
I want to come back to this, building these two packages and one, the same package for both languages.

00:47:45.700 --> 00:47:48.000
And I'm not sure if we exactly covered it.

00:47:48.000 --> 00:47:54.080
Do you try to have the same API for both as close as possible?

00:47:54.080 --> 00:48:03.040
Or do you try to have something Pythonic for the Python one and something that's maybe effectively the same, but very much what our folks expect?

00:48:03.040 --> 00:48:06.880
Like what is your philosophy in trying to build these packages for both groups?

00:48:06.880 --> 00:48:07.780
That's a great question.

00:48:07.780 --> 00:48:09.360
We try to balance the two.

00:48:09.360 --> 00:48:14.220
We want the syntax, the API to be very similar across both.

00:48:14.660 --> 00:48:20.840
But obviously we want folks that are coming from the R side or from the Python side to feel very natural in using it.

00:48:20.840 --> 00:48:26.380
And so that means that we can't always have the exact same comparable syntax across the two.

00:48:26.380 --> 00:48:33.260
You know, in R, it's very common within like the tidyverse packages, if you've heard that, where there's no quoting.

00:48:33.560 --> 00:48:38.120
There's been ways that you can remove the quotations of argument inputs and everything.

00:48:38.480 --> 00:48:45.920
So that's kind of a natural thing that we do, where if you look at the Python side, you get the same arguments and the same valid inputs that you could supply.

00:48:45.920 --> 00:48:48.480
But you're going to have quotes versus non-quoted.

00:48:48.480 --> 00:48:49.940
And so that can be differences.

00:48:49.940 --> 00:48:51.800
And then there's, you know, other kind of differences.

00:48:51.800 --> 00:48:54.460
And underneath the hood, like how do you do logging?

00:48:54.880 --> 00:48:58.420
Obviously, that's going to be a little bit different in both of the two languages.

00:48:58.420 --> 00:49:05.720
And one thing that's really hard to avoid is that fundamentally object orientation is extremely different in R and Python.

00:49:05.720 --> 00:49:07.780
And, you know, R has things.

00:49:07.780 --> 00:49:09.400
I believe the term is method dispatch.

00:49:09.400 --> 00:49:11.720
So methods don't come after object names.

00:49:11.720 --> 00:49:14.180
They come before and they look like standard functions.

00:49:14.600 --> 00:49:20.500
And so things are just, if we wanted to build an exactly identical API, we would actually have to jump through a lot of hoops.

00:49:20.500 --> 00:49:23.180
That wouldn't be very native to either of the languages.

00:49:23.180 --> 00:49:25.100
So like Brad said, it's a fine line to walk.

00:49:25.100 --> 00:49:30.620
We want it to be recognizable and similar, but we don't want to sacrifice the merits of the language for that.

00:49:30.620 --> 00:49:31.440
Sounds like a good balance.

00:49:31.440 --> 00:49:35.900
You know, let's round out our conversation with one more short topic.

00:49:36.440 --> 00:49:48.660
When you think about data science, a lot of times, at least I think about things like Jupyter Notebooks, Jupyter Lab, maybe RStudio, and this exploring data.

00:49:48.660 --> 00:50:00.400
When I think about product, like productizing, putting this behind some REST API or putting it in production, some of this stuff, I don't think notebooks and RStudio anymore.

00:50:00.400 --> 00:50:02.800
What does that transition look like?

00:50:02.800 --> 00:50:09.800
Like, how do you guys take this research and turn it into products like services and APIs and whatnot that can run?

00:50:09.800 --> 00:50:11.100
So there's a few different approaches.

00:50:11.100 --> 00:50:17.800
Historically, so I used to work on our digital team that would build the recommender systems for the Kroger website.

00:50:17.800 --> 00:50:23.240
So much like Amazon's website, Kroger's website has like, because you bought this, you might also like this.

00:50:23.240 --> 00:50:23.560
Right.

00:50:23.560 --> 00:50:25.640
And so we need to find ways to serve recommendations.

00:50:25.640 --> 00:50:29.660
Historically, that was largely done in batch style processing.

00:50:29.660 --> 00:50:36.000
So at the beginning of a given week or something, we would say for each customer identifier, these are the products that they should get.

00:50:36.000 --> 00:50:37.640
And we would send over these flat files.

00:50:37.640 --> 00:50:47.140
But increasingly, we're moving to something that looks more like we will ship you an actual, usually it's container, but some kind of item that takes input and gives output.

00:50:47.140 --> 00:50:49.240
So we can serve up dynamic recommendations.

00:50:49.240 --> 00:51:00.700
So people, I think a common workflow for things like that is people build their model and do their exploration and do their just like modeling initially in notebooks or in RStudio.

00:51:00.840 --> 00:51:05.400
But then they package this up as some kind of product that ends up being much more polished.

00:51:05.400 --> 00:51:17.260
So in some cases, if we ship a container, people need to actually dockerize that and make sure that it can be used by someone external and then throw it over the wall to whoever actually manages the Kroger website, for example.

00:51:17.260 --> 00:51:17.980
Okay, interesting.

00:51:17.980 --> 00:51:18.480
Brad?

00:51:18.480 --> 00:51:31.120
Yeah, and lots of times, you know, if you're doing like machine learning type of models, you know, you're not going to, you know, basically build a script that's got the machine learning code in it and use that to kind of score incoming observations.

00:51:31.520 --> 00:51:35.440
Most of the time, you're going to have some kind of Java output product from these.

00:51:35.440 --> 00:51:42.480
So data robot is a tool that we use internally that allows you to do kind of like automated machine learning tasks.

00:51:42.480 --> 00:51:44.880
H2O is another very popular one.

00:51:44.880 --> 00:51:50.360
And both of those have very similar like R and Python APIs to perform machine learning.

00:51:50.500 --> 00:52:02.260
But the thing is, once you get done with kind of like finding what that optimal model is, then you typically are kicking out, you're going to use like a code gen or like a POJO, which just ends up being kind of like a Java object.

00:52:02.260 --> 00:52:05.260
And that's what we can use to kind of like score new observations.

00:52:05.260 --> 00:52:13.240
And so that gets away completely from using any kind of a notebook or scripting as far as like a Python or R scripting capability.

00:52:13.240 --> 00:52:13.600
Okay.

00:52:13.600 --> 00:52:18.200
Have either of you played around with or entertained the idea of something like Paper Mill?

00:52:18.200 --> 00:52:19.480
Remember Paper Mill?

00:52:19.660 --> 00:52:22.060
We do use Paper Mill internally for a couple of things.

00:52:22.060 --> 00:52:26.000
Maybe tell people just like the quick elevator pitch of what that is so they know.

00:52:26.000 --> 00:52:26.900
A little bit of background.

00:52:26.900 --> 00:52:30.960
So notebooks, if you've used Jupyter notebooks before, they are designed for interactive work.

00:52:30.960 --> 00:52:33.620
They're designed for like run this line of code, see this output, etc.

00:52:33.620 --> 00:52:35.340
They're not really designed to be automated.

00:52:35.340 --> 00:52:38.160
They don't lend themselves to being run from the command line.

00:52:38.160 --> 00:52:44.580
And Paper Mill is a package that Netflix has produced that is open source that lets you automate notebook runs.

00:52:44.580 --> 00:52:48.480
So you get the benefits of notebooks where you get this output in line with your work.

00:52:48.820 --> 00:52:51.700
And you can do the development of the notebook as you did before.

00:52:51.700 --> 00:52:54.040
But now you can batch these things.

00:52:54.040 --> 00:52:56.000
You can run them every night or whatever you want to do.

00:52:56.000 --> 00:52:57.460
I was going to say one can call the other.

00:52:57.460 --> 00:52:59.900
You can almost treat them like little functions with inputs and outputs.

00:52:59.900 --> 00:53:00.540
Yeah, exactly.

00:53:00.540 --> 00:53:00.960
Yeah.

00:53:00.960 --> 00:53:01.780
So you used them a little bit?

00:53:01.840 --> 00:53:03.580
We use them internally for a couple of things.

00:53:03.580 --> 00:53:09.620
Mainly, so again, because we are on so many different platforms, it's like different things come to different platforms at different times.

00:53:09.620 --> 00:53:12.920
Especially because these are managed platforms everyone has to work on.

00:53:12.920 --> 00:53:15.940
So I can't just go install Paper Mill because that's going to affect everyone.

00:53:16.380 --> 00:53:18.800
So we have Paper Mill set up on some of our on-prem environments.

00:53:18.800 --> 00:53:21.460
And I think we're still working on getting it set up in the cloud.

00:53:21.600 --> 00:53:28.660
But in general, a lot of the stuff that we would want to automate in the cloud is a little easier to end up scripting in the end.

00:53:28.660 --> 00:53:29.820
I think that's a heuristic.

00:53:29.820 --> 00:53:31.060
Not always true, but often.

00:53:31.060 --> 00:53:31.600
Yeah.

00:53:31.600 --> 00:53:35.240
And one thing that we're using or kind of moving towards is using Databricks.

00:53:35.560 --> 00:53:41.940
And there's a lot of functionality within Databricks that allows you to kind of parameterize and automate the runtime of those scripts.

00:53:41.940 --> 00:53:46.060
So it ends up being kind of a notebook that can operate a little bit like Paper Mill.

00:53:46.060 --> 00:53:54.980
That seems like the shortest or the most native way to bring where the work was originally done into productized data science.

00:53:54.980 --> 00:54:01.020
But also, I see definitely some engineering challenges around that, you know, like testing, refactoring, etc.

00:54:01.020 --> 00:54:11.600
I think historically, what we've primarily gone to is basically having your .r or .py scripts and just automating those with normal batching.

00:54:11.600 --> 00:54:12.520
Yeah, it makes a lot of sense.

00:54:12.520 --> 00:54:13.580
All right.

00:54:13.580 --> 00:54:17.060
Well, I think we're just about out of time, so we'll have to leave it there.

00:54:17.060 --> 00:54:25.120
But this was a really fascinating look inside what you all are doing there because it sounds like you're operating at a scale that most folks don't get to operate at maybe just yet.

00:54:25.120 --> 00:54:25.520
Who knows?

00:54:25.520 --> 00:54:26.500
Yeah, it's good to talk.

00:54:26.500 --> 00:54:26.920
Absolutely.

00:54:26.920 --> 00:54:29.980
Now, before I let you two out of here, I've got to ask you the last two questions.

00:54:30.760 --> 00:54:32.720
So let's go with you, Ethan, first.

00:54:32.720 --> 00:54:37.260
If you're going to write some data science code, I'll generalize it a little bit this time around.

00:54:37.260 --> 00:54:38.480
What editor do you use?

00:54:38.480 --> 00:54:41.660
I'm pretty all in on Vim, which is not all that popular in data science.

00:54:41.660 --> 00:54:43.260
I use Jupyter Notebook sometimes.

00:54:43.260 --> 00:54:44.780
I found a lot of extensions.

00:54:44.780 --> 00:54:47.220
Let me use the Vim key bindings, but old habits die hard.

00:54:47.220 --> 00:54:49.740
I've dabbled in VS Code recently, but I always come back to Vim.

00:54:49.740 --> 00:54:50.140
All right.

00:54:50.140 --> 00:54:50.420
Cool.

00:54:50.420 --> 00:54:50.840
Brad?

00:54:50.840 --> 00:54:54.180
I do write a lot of R code, so RStudio is kind of my go-to.

00:54:54.180 --> 00:54:58.600
Even when I write my Python, I definitely enjoy writing it within RStudio.

00:54:58.760 --> 00:55:02.660
RStudio actually supports multiple different languages, and it's just one of those editors

00:55:02.660 --> 00:55:03.480
I've gotten used to.

00:55:03.480 --> 00:55:10.520
I do use Notebooks sometimes when I'm teaching, whether it's an RStudio Notebook or Jupyter Notebook.

00:55:10.520 --> 00:55:13.400
But if I want to be truly Pythonic, I go to PyCharm.

00:55:13.400 --> 00:55:13.840
It's funny.

00:55:13.840 --> 00:55:18.040
Editors are one of those things that once you get really comfortable with it, you can just

00:55:18.040 --> 00:55:19.900
be more effective in the one that you like, right?

00:55:20.100 --> 00:55:20.540
Exactly.

00:55:20.540 --> 00:55:20.860
Yeah.

00:55:20.860 --> 00:55:21.900
Cool.

00:55:21.900 --> 00:55:27.120
And then a notable PyPI or, Brad, if you want, CRAN package for folks out there, something

00:55:27.120 --> 00:55:30.120
some library you ran across that people should just know about.

00:55:30.120 --> 00:55:34.120
Maybe not the most popular, but you're like, I found this thing and it was amazing and I

00:55:34.120 --> 00:55:34.860
didn't even know about it.

00:55:34.860 --> 00:55:37.240
I am all in on this package called Altair.

00:55:37.240 --> 00:55:39.560
I think you've had Jake Vanderplass on the pod before.

00:55:39.560 --> 00:55:40.300
I have, yeah.

00:55:40.460 --> 00:55:45.140
Earlier, I alluded to Python's relatively weak visualization ecosystem for data science.

00:55:45.140 --> 00:55:51.300
And it is, I teach some Python classes both internally and at the University of Cincinnati.

00:55:51.300 --> 00:55:54.520
And teaching the visualization ecosystem is just terrible every time.

00:55:54.520 --> 00:55:55.320
It's so bad.

00:55:55.320 --> 00:55:58.300
And MatBotlib and Seaborn are so difficult to use and inconsistent.

00:55:58.300 --> 00:56:02.140
And Altair is like the hope that I have for the Python ecosystem.

00:56:02.140 --> 00:56:03.700
I think it's so, so nice.

00:56:03.700 --> 00:56:05.140
I just want to see more adoption.

00:56:05.140 --> 00:56:05.860
But it's great.

00:56:05.860 --> 00:56:09.040
Like if you work in data science, you should absolutely switch to Altair.

00:56:09.040 --> 00:56:13.840
And if you are used to the ggplot, really nice encoding style syntax and coding channels,

00:56:13.840 --> 00:56:15.760
Altair is such a good answer in Python.

00:56:15.760 --> 00:56:17.540
Yeah, I've heard really good things about it.

00:56:17.540 --> 00:56:20.780
I haven't actually done that much with it myself.

00:56:20.780 --> 00:56:22.820
But yeah, it's definitely good.

00:56:22.820 --> 00:56:23.740
And Jake does nice work.

00:56:23.740 --> 00:56:24.040
Yeah.

00:56:24.040 --> 00:56:24.380
Brad?

00:56:24.380 --> 00:56:27.520
I've been spending a lot more time in both R and Python.

00:56:27.520 --> 00:56:33.120
So I'm getting more and more drawn towards packages that are available in both languages

00:56:33.120 --> 00:56:36.620
and that kind of have very similar syntax or API.

00:56:36.620 --> 00:56:38.280
So a few good ones.

00:56:38.280 --> 00:56:40.080
So we use DataRobot internally.

00:56:40.080 --> 00:56:43.120
So that's got a similar R and Python API.

00:56:43.120 --> 00:56:47.020
H2O is another machine learning package that I really like.

00:56:47.020 --> 00:56:50.880
And if you look at those, it's really tough to tell the difference between the R and the

00:56:50.880 --> 00:56:51.800
Python syntax.

00:56:51.800 --> 00:56:54.720
It must be nice when those exist for your ecosystem, right?

00:56:54.720 --> 00:56:55.020
Yeah.

00:56:55.360 --> 00:56:59.080
And even like TensorFlow and Keras, I've been doing a lot of stuff with deep learning lately.

00:56:59.080 --> 00:57:04.980
And the R, Keras TensorFlow is, I mean, basically it is, it's using Reticulate to communicate

00:57:04.980 --> 00:57:06.180
towards the Python Keras.

00:57:06.180 --> 00:57:09.160
So the syntax between those two are very similar as well.

00:57:09.160 --> 00:57:09.460
Yeah.

00:57:09.460 --> 00:57:10.960
We talked about mocking stuff earlier.

00:57:11.040 --> 00:57:12.240
I want to just throw out Modo.

00:57:12.240 --> 00:57:17.940
If you guys use AWS, Modo will let you mock out almost every AWS service.

00:57:17.940 --> 00:57:19.000
Really?

00:57:19.000 --> 00:57:19.420
Okay.

00:57:19.780 --> 00:57:20.040
Yeah.

00:57:20.440 --> 00:57:23.680
If you want to mock out the API for EC2, you can do it.

00:57:23.680 --> 00:57:25.120
You want to mock out S3, you can do it.

00:57:25.120 --> 00:57:25.680
It's all in there.

00:57:25.680 --> 00:57:28.040
So Bodo is the regular API in Python.

00:57:28.040 --> 00:57:30.940
Modo is the mock Bodo, right?

00:57:30.940 --> 00:57:31.340
Gotcha.

00:57:31.340 --> 00:57:33.900
So is that built and maintained by AWS folks?

00:57:34.100 --> 00:57:35.260
I don't think so.

00:57:35.260 --> 00:57:36.900
It definitely doesn't look like it.

00:57:36.900 --> 00:57:40.340
But anyway, there's some interesting things you can do with like a local version of it and

00:57:40.340 --> 00:57:42.280
all sorts of funky stuff.

00:57:42.280 --> 00:57:44.220
It looks like someone put a lot of effort into it.

00:57:44.220 --> 00:57:46.780
Trying to solve that mocking problem.

00:57:46.780 --> 00:57:47.900
It's a lot of work, right?

00:57:47.900 --> 00:57:48.720
Yeah.

00:57:48.720 --> 00:57:49.360
It is.

00:57:49.360 --> 00:57:49.860
Yeah, definitely.

00:57:49.860 --> 00:57:50.060
Cool.

00:57:50.060 --> 00:57:50.940
All right.

00:57:50.940 --> 00:57:53.600
Well, Ethan, Brad, this has been really interesting.

00:57:53.600 --> 00:57:54.520
Final call to action.

00:57:54.520 --> 00:58:00.360
People maybe want to try to create these unified environments or work better across their data

00:58:00.360 --> 00:58:01.080
science teams.

00:58:01.080 --> 00:58:02.020
What will you tell them?

00:58:02.120 --> 00:58:06.600
It's worth investing in having some kind of centralized data science team within your overall

00:58:06.600 --> 00:58:09.260
data science department that works on these resources.

00:58:09.260 --> 00:58:11.380
You know, you have to carve out time for people.

00:58:11.380 --> 00:58:15.260
Brad and I are both, I think, pretty lucky to be able to do this as most of our job.

00:58:15.260 --> 00:58:18.700
If you don't have that time carved out, people just don't have time to contribute to centralized

00:58:18.700 --> 00:58:21.080
resources and you end up with a lot of duplication of work.

00:58:21.080 --> 00:58:25.000
And it's also good for some of your data scientists to have a more technical background

00:58:25.000 --> 00:58:26.220
and be able to think about this stuff.

00:58:26.220 --> 00:58:27.880
And I think we've benefited very much from that.

00:58:27.880 --> 00:58:28.640
Yeah, it sounds like it.

00:58:28.640 --> 00:58:29.200
Brad?

00:58:29.320 --> 00:58:29.460
Yeah.

00:58:29.460 --> 00:58:33.760
And I would say for the data scientists, like, you know, historically, you've been able to

00:58:33.760 --> 00:58:34.920
kind of focus in one language.

00:58:34.920 --> 00:58:36.980
And I think that's becoming less and less common.

00:58:36.980 --> 00:58:41.080
So I think a lot of people need to be flexible in understanding both languages.

00:58:41.080 --> 00:58:46.060
You know, you may be dominant in one, but at least be able to have some read capability

00:58:46.060 --> 00:58:46.760
in the other one.

00:58:46.760 --> 00:58:51.640
And one thing I've definitely benefited a lot from is working closely with Ethan and some

00:58:51.640 --> 00:58:53.880
of the other folks in the company that are strong Python programmers.

00:58:54.460 --> 00:58:56.220
There's a lot of good exchange of knowledge.

00:58:56.220 --> 00:59:00.640
And once you start understanding, like, different types of languages, you kind of see the same

00:59:00.640 --> 00:59:01.680
patterns that exist.

00:59:01.680 --> 00:59:04.640
And that can really help you become a stronger developer.

00:59:04.640 --> 00:59:06.280
There's always good stuff on both sides.

00:59:06.280 --> 00:59:08.340
And if you can bring it over the fence, it's good, right?

00:59:08.340 --> 00:59:08.960
Yeah, definitely.

00:59:08.960 --> 00:59:10.720
Well, thank you both for being on the show.

00:59:10.720 --> 00:59:12.220
It's been really interesting.

00:59:12.220 --> 00:59:12.960
Yeah, thanks, Michael.

00:59:12.960 --> 00:59:13.840
Yeah, thank you very much.

00:59:14.620 --> 00:59:17.220
This has been another episode of Talk Python to Me.

00:59:17.220 --> 00:59:20.340
Our guests on this episode were Ethan Swan and Bradley Baumke.

00:59:20.340 --> 00:59:22.800
And it's been brought to you by Linode and Tidelift.

00:59:22.800 --> 00:59:26.560
Linode is your go-to hosting for whatever you're building with Python.

00:59:26.560 --> 00:59:30.140
Get four months free at talkpython.fm/linode.

00:59:30.140 --> 00:59:32.000
That's L-I-N-O-D-E.

00:59:32.000 --> 00:59:37.200
If you run an open source project, Tidelift wants to help you get paid for keeping it going

00:59:37.200 --> 00:59:37.680
strong.

00:59:37.680 --> 00:59:43.300
Just visit talkpython.fm/Tidelift, search for your package, and get started today.

00:59:44.380 --> 00:59:45.520
Want to level up your Python?

00:59:45.520 --> 00:59:50.380
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

00:59:50.380 --> 00:59:55.460
Or if you're looking for something more advanced, check out our new async course that digs into

00:59:55.460 --> 00:59:58.520
all the different types of async programming you can do in Python.

00:59:58.520 --> 01:00:02.480
And of course, if you're interested in more than one of these, be sure to check out our

01:00:02.480 --> 01:00:03.200
Everything Bundle.

01:00:03.200 --> 01:00:05.080
It's like a subscription that never expires.

01:00:05.080 --> 01:00:07.220
Be sure to subscribe to the show.

01:00:07.220 --> 01:00:09.720
Open your favorite podcatcher and search for Python.

01:00:09.720 --> 01:00:10.860
We should be right at the top.

01:00:10.860 --> 01:00:13.820
You can also find the iTunes feed at /itunes.

01:00:14.140 --> 01:00:15.700
The Google Play feed at /play.

01:00:15.700 --> 01:00:19.860
And the direct RSS feed at /rss on talkpython.fm.

01:00:20.300 --> 01:00:21.940
This is your host, Michael Kennedy.

01:00:21.940 --> 01:00:23.440
Thanks so much for listening.

01:00:23.440 --> 01:00:24.480
I really appreciate it.

01:00:24.480 --> 01:00:26.260
Now get out there and write some Python code.

01:00:26.260 --> 01:00:26.960
And I'll see you next time.

01:00:26.960 --> 01:00:27.060
Bye.

01:00:27.060 --> 01:00:27.180
Bye.

01:00:27.180 --> 01:00:27.460
Bye.

01:00:27.460 --> 01:00:27.960
you

01:00:27.960 --> 01:00:28.460
you

01:00:28.460 --> 01:00:28.960
you

01:00:28.960 --> 01:00:29.460
you

01:00:29.460 --> 01:00:29.960
you

01:00:29.960 --> 01:00:30.460
you

01:00:30.460 --> 01:00:30.960
you

01:00:30.960 --> 01:00:31.460
you

01:00:31.460 --> 01:00:31.960
you

01:00:31.960 --> 01:00:32.460
you

01:00:32.460 --> 01:00:32.960
you

01:00:32.960 --> 01:00:33.460
you

01:00:33.460 --> 01:00:33.960
you

01:00:33.960 --> 01:00:34.460
you

01:00:34.460 --> 01:00:34.960
you

01:00:34.960 --> 01:00:35.460
you

01:00:35.460 --> 01:00:35.960
you

01:00:35.960 --> 01:00:36.460
you

01:00:36.460 --> 01:00:36.960
you

01:00:36.960 --> 01:00:37.460
you

01:00:37.460 --> 01:00:37.960
you

01:00:37.960 --> 01:00:38.460
you

01:00:38.460 --> 01:00:38.960
you

01:00:38.960 --> 01:00:39.460
you

01:00:39.460 --> 01:00:39.960
you

01:00:39.960 --> 01:00:40.460
you

01:00:40.460 --> 01:00:40.960
you

01:00:40.960 --> 01:00:41.460
you

01:00:41.460 --> 01:00:41.960
you

01:00:41.960 --> 01:00:42.460
you

01:00:42.460 --> 01:00:42.960
you

01:00:42.960 --> 01:00:43.460
you

01:00:43.460 --> 01:00:43.960
you

01:00:43.960 --> 01:00:44.460
you

01:00:44.460 --> 01:01:14.440
Thank you.

