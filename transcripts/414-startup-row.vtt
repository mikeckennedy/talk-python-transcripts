WEBVTT

00:00:00.001 --> 00:00:06.060
At PyCon 2023, there was a section of the expo floor dedicated to new Python-based companies

00:00:06.060 --> 00:00:11.440
called Startup Row. I wanted to bring their stories and the experience of talking with

00:00:11.440 --> 00:00:16.540
these new startups to you. So in this episode, we talk with the founders of these companies for

00:00:16.540 --> 00:00:23.900
about five to 10 minutes each. This is Talk Python To Me, episode 414, recorded on location at PyCon

00:00:23.900 --> 00:00:27.300
in Salt Lake City on April 22nd, 2023.

00:00:27.300 --> 00:00:44.960
Welcome to Talk Python To Me, a weekly podcast on Python. This is your host, Michael Kennedy.

00:00:44.960 --> 00:00:50.080
Follow me on Mastodon, where I'm @mkennedy and follow the podcast using @talkpython,

00:00:50.080 --> 00:00:56.020
both on fosstodon.org. Be careful with impersonating accounts on other instances. There are many.

00:00:56.220 --> 00:01:01.080
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:01:01.080 --> 00:01:06.900
We've started streaming most of our episodes live on YouTube. Subscribe to our YouTube channel over

00:01:06.900 --> 00:01:12.640
at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.

00:01:12.640 --> 00:01:19.500
This episode is brought to you by Sentry and us over at Talk Python Training. Please check out what

00:01:19.500 --> 00:01:22.960
we're both offering during our segments. It really helps support the show.

00:01:24.100 --> 00:01:29.360
We kick off the interviews with Devin Peterson from Ponder. Ponder is taking Moden, a distributed

00:01:29.360 --> 00:01:34.220
compute library for Python, and pushing data science compute directly into the database.

00:01:34.220 --> 00:01:36.380
Welcome to Talk Python here on Startup Row.

00:01:36.380 --> 00:01:37.560
Thank you. Thank you.

00:01:37.560 --> 00:01:42.220
Yeah, it's fantastic to have you here. You know, we met yesterday here at PyCon US,

00:01:42.580 --> 00:01:49.620
and you were telling me about your project Ponder and how it's built upon Moden, the open source

00:01:49.620 --> 00:01:53.540
project. And as I looked around, I'm like, everyone here has a story. And I just thought it'd be so

00:01:53.540 --> 00:01:58.160
great to have you on the show along with all the others and just kind of tell your story. You know,

00:01:58.160 --> 00:02:01.140
how did you, how did you get here to start up Row at PyCon?

00:02:01.420 --> 00:02:07.400
Yeah, it's interesting. So Moden started as my PhD project, and I was doing my PhD at Berkeley,

00:02:07.400 --> 00:02:13.560
and I started in the genomics world, trying to build large scale data science tools for,

00:02:13.560 --> 00:02:18.440
for, you know, the people who actually do the science. I'm not a biologist myself. I don't know

00:02:18.440 --> 00:02:20.060
the first thing about biology, honestly.

00:02:20.060 --> 00:02:23.420
But you got some good programming skills, and they can always use that applied to their data,

00:02:23.420 --> 00:02:23.680
right?

00:02:23.680 --> 00:02:27.400
Right. The problem was we were building tools in Spark, and it was really hard for these Spark-like

00:02:27.400 --> 00:02:31.900
APIs to translate natively to the way that they were reasoning about data. And like,

00:02:31.900 --> 00:02:36.760
they're using Python. And so there's a very kind of natural way that scientists think about,

00:02:36.760 --> 00:02:42.460
you know, interacting with data that's not Spark, right? It's not intuitive, as intuitive in Spark,

00:02:42.460 --> 00:02:43.600
even PySpark, right?

00:02:43.600 --> 00:02:48.680
A lot of Python people avoid databases as much as they can, at least SQL and directly talking to them like

00:02:48.680 --> 00:02:48.920
that.

00:02:48.920 --> 00:02:53.620
Yeah, totally. Because like, often the way, when you're exploring data there, you have a mental

00:02:53.620 --> 00:03:00.840
model of how you want to interact with the data. And that is not SQL often. Like, it's just the way

00:03:00.840 --> 00:03:01.340
that it is.

00:03:01.340 --> 00:03:01.580
Yeah.

00:03:01.580 --> 00:03:01.720
Yeah.

00:03:01.720 --> 00:03:08.040
So yeah, I had a moment there where a data scientist was like, if I don't, I don't want your tool,

00:03:08.040 --> 00:03:14.340
can you just make my tool run faster? And so I was like, ah, yes, wait a second, this is actually

00:03:14.340 --> 00:03:19.140
a real project. And so we, I started like looking into pandas and looking into like, you know, the,

00:03:19.340 --> 00:03:24.240
the world of, you know, databases and, and like the kind of academic space. And nobody had really

00:03:24.240 --> 00:03:29.780
dug that deep into pandas because in, in the academic sense, everybody was like, okay, pandas

00:03:29.780 --> 00:03:35.760
is just a bad database. That's what database people thought at the time. So we did a bunch of work and

00:03:35.760 --> 00:03:41.040
it kind of turned out that's not the case. They're, they're totally new things. And so from there, we built

00:03:41.040 --> 00:03:46.140
modem and, and now with ponder, we're kind of extending that to, to basically bridge these

00:03:46.140 --> 00:03:51.080
two worlds where you can use Python, but we're, we're generating SQL on the backend and able to

00:03:51.080 --> 00:03:54.000
run pandas directly in your database or your data warehouse.

00:03:54.000 --> 00:04:00.220
Yeah. Fantastic. So when I first heard about what you're doing at ponder, it, I immediately thought

00:04:00.220 --> 00:04:06.920
of Dask and Dask is another popular startup success, open source startup success story with

00:04:06.920 --> 00:04:11.640
Matthew Rocklin and Foreman coiled and stuff. And I mean, I think they may have outgrown startup

00:04:11.640 --> 00:04:16.440
row, but you know, good for them. Yeah, totally. My first thought was, okay, well, how is this

00:04:16.440 --> 00:04:21.700
different than Dask? But the big difference is Dask is grid computing and yours runs in the database.

00:04:21.700 --> 00:04:27.420
Yeah. For ponder, definitely open source motor and also integrates with Dask clusters as well. So

00:04:27.420 --> 00:04:33.300
Dask has Dask data frame and that runs on Dask clusters. We can also run a mode in open source on,

00:04:33.300 --> 00:04:36.720
on Dask clusters. It's very important to us that whatever infrastructure that you

00:04:36.720 --> 00:04:41.860
have, you can run pandas on top of that. So ponder is the next level of that, where if you have,

00:04:41.860 --> 00:04:46.340
if your data is in the database, it doesn't leave, right? We can just execute it directly there.

00:04:46.340 --> 00:04:51.080
And you know, all of your assumptions from Python and pandas hold true in the database,

00:04:51.080 --> 00:04:54.840
even though the database actually doesn't like the assumptions that you might have in pandas,

00:04:54.840 --> 00:04:58.780
right? We emulate those behaviors and we we've done a lot of work to actually make that feel very

00:04:58.780 --> 00:05:04.600
native. So that is a key difference with, with ponder and, and Dask though, is that your data never

00:05:04.600 --> 00:05:08.980
leaves the database. So you don't have to have a separate Dask cluster to kind of pull the data

00:05:08.980 --> 00:05:13.420
into and execute on it there. You can just run things natively in the database or the data warehouse.

00:05:13.420 --> 00:05:17.220
So if you have a large database, you already have a probably powerful database server. Why

00:05:17.220 --> 00:05:21.800
suck, transfer all the data off of that, load it into something else, analyze it and throw it away,

00:05:21.800 --> 00:05:23.420
right? Just like make it run there.

00:05:23.740 --> 00:05:29.100
Exactly. Exactly. Yeah. So maybe a quick elevator pitch type of thing might be like,

00:05:29.100 --> 00:05:33.960
you all take pandas and turn it into SQL statements that run on the database,

00:05:33.960 --> 00:05:35.460
but people get a program in pandas.

00:05:35.460 --> 00:05:36.140
Yes, exactly.

00:05:36.140 --> 00:05:40.840
That's exactly it. Yes. Some things that are really, really native in pandas,

00:05:41.220 --> 00:05:45.740
like describe, for example, df.describe. Super, super common.

00:05:45.740 --> 00:05:48.360
It seems easy. Like it just gives me some summary stats.

00:05:48.360 --> 00:05:51.200
Yes, exactly. That's 300 lines of SQL.

00:05:51.200 --> 00:05:51.840
No.

00:05:51.840 --> 00:05:57.620
Like you wouldn't believe it looking at it though, because you know, it seems so simple and it's,

00:05:57.620 --> 00:06:01.640
it is a simple, simple output, right? I want to get some summary statistics for my data,

00:06:01.640 --> 00:06:07.260
but SQL is so declarative and the language itself doesn't lend itself well to this type of iterative,

00:06:07.400 --> 00:06:09.200
interactive kind of like workflow. So.

00:06:09.200 --> 00:06:14.440
Right. And the notebooks remember step by step, they have like a history sort of a memory,

00:06:14.440 --> 00:06:16.980
whereas SQLs, every statement is standalone.

00:06:16.980 --> 00:06:22.500
Exactly. So all or nothing basically. And you have to do the whole thing up front. And that's

00:06:22.500 --> 00:06:25.740
the thing people love about pandas is that you can incrementally build these things up.

00:06:25.740 --> 00:06:28.780
So, so we're giving that interface to SQL basically.

00:06:28.780 --> 00:06:32.760
Awesome. All right. Well, let's wrap this up with a bit of a bit of a talk,

00:06:32.760 --> 00:06:35.340
how you got to startup row. How'd you start this company?

00:06:35.340 --> 00:06:35.700
Yeah.

00:06:35.700 --> 00:06:40.180
Where are you? Like so many people are excited to take their open source work and instead of making

00:06:40.180 --> 00:06:45.340
it their side job or something they do part-time at their company, make it their full-time energy.

00:06:45.340 --> 00:06:46.720
And you're there. How'd you do it?

00:06:46.720 --> 00:06:54.600
Yeah. So the way that we started was we talked to a lot of companies where they basically asked us,

00:06:54.600 --> 00:06:58.180
can you make this work on top of our infrastructure? We didn't support, we, you know,

00:06:58.180 --> 00:07:02.760
we only supported in the open source Ray and Dask. And we saw a motion there to have kind of an open

00:07:02.760 --> 00:07:06.840
core model. So we follow the open core model where these more enterprise-y features like,

00:07:06.840 --> 00:07:11.240
you know, security features and being able to push into data warehouses, right? Like an individual,

00:07:11.240 --> 00:07:16.080
you know, consultant may not have, you know, a data warehouse. They probably don't, right? But,

00:07:16.080 --> 00:07:19.500
but enterprises do. And these are the types of features that enterprises really care about. So

00:07:19.500 --> 00:07:24.400
this open core model, I think, lended itself really well to our business, particularly because,

00:07:24.400 --> 00:07:30.940
you know, enterprises will pay for these features. And so, yeah. And then we, we went out and we raised

00:07:30.940 --> 00:07:36.980
this, a seed around and, you know, saw the opportunity to come here and be in, in PyCon startup row. And

00:07:36.980 --> 00:07:41.020
fortunately, you know, it's, it's a competitive process. Really it is. Yeah. We're, we're very,

00:07:41.020 --> 00:07:46.020
we feel very fortunate to be, you know, chosen among the few that are chosen here. But yeah,

00:07:46.020 --> 00:07:51.440
that's kind of our journey is, is basically, you know, starting talking like, so for folks out there who are

00:07:51.440 --> 00:07:55.020
like interested in this, talk to people who are using this, people who are interested in the

00:07:55.020 --> 00:07:59.740
problem that you're solving and figure out where the gaps are and kind of ask questions. Don't be

00:07:59.740 --> 00:08:03.480
afraid to ask, like, would you pay for this? Or how much would you pay for this? Those, those questions,

00:08:03.480 --> 00:08:09.360
they're uncomfortable to ask. And like, especially the developer who's not used to presenting salesy type

00:08:09.360 --> 00:08:14.120
marketing things. You always, salespeople as kind of, yeah, I got it. It's a necessary evil.

00:08:14.120 --> 00:08:19.780
Totally. It totally is. Yeah. So, but, but you have to ask, because how do you know if you can kind of

00:08:19.780 --> 00:08:24.780
take that next step? Unless you ask, Hey, would you pay $50 a month for this? Would you pay $10 a

00:08:24.780 --> 00:08:29.200
month for this? Right. You can't know unless you, unless you really go out there and ask. So that's

00:08:29.200 --> 00:08:32.920
what I would encourage folks to do if they're interested in this is, you know, find those gaps

00:08:32.920 --> 00:08:37.320
and, and, and really ask the hard questions that are kind of hard, but yeah. Awesome. Well,

00:08:37.320 --> 00:08:41.140
congratulations. Thanks for taking the time to talk to us. Thank you. Thank you. Yeah, you bet. Bye.

00:08:41.140 --> 00:08:45.660
Next up is Generally Intelligent and Josh Albrecht. Generally Intelligent is an independent

00:08:45.660 --> 00:08:51.040
research company developing AI agents with general intelligence that can be safely deployed in the

00:08:51.040 --> 00:08:55.480
real world. Josh, welcome to Talk Python To Me. Hey, thanks. Hey, it's great to have you here. Tell

00:08:55.480 --> 00:09:00.860
people quickly who you are. Yeah. So I'm Josh, Josh Albrecht. I'm the CTO of Generally Intelligent.

00:09:00.860 --> 00:09:06.880
We're an AI research company based in San Francisco. Awesome. I love the humbleness. Generally,

00:09:06.880 --> 00:09:11.660
generally intelligent, right? You're not a super genius, but no, it's a clever name. I like it.

00:09:11.660 --> 00:09:15.540
Thank you. Yeah. Yeah. And you know, what, what's the problem you're solving here?

00:09:15.540 --> 00:09:19.540
So yeah, we, you know, kind of, as it says on the tin, like we're working on artificial general

00:09:19.540 --> 00:09:22.640
intelligence. We don't usually like to use that term because it can mean lots of different things to

00:09:22.640 --> 00:09:27.000
lots of different people. But in, in general, what we're working on is making more capable,

00:09:27.000 --> 00:09:32.920
safer, more robust AI systems. And in particular, we're focused on agents. So systems that can act

00:09:32.920 --> 00:09:38.020
on their own. And like right now, mostly what we're focused on is agents that can work kind of in your

00:09:38.020 --> 00:09:42.040
browser, on your desktop, in your code editor, those kinds of virtual environments and digital

00:09:42.040 --> 00:09:47.500
environments. How much of this are you envisioning running locally versus running on a big cluster in

00:09:47.500 --> 00:09:51.940
the cloud? Yeah, I think it'd be nice someday in the future to have things run totally locally. But

00:09:51.940 --> 00:09:57.220
right now, a lot of these technologies do require a large cluster of GPUs, which are very expensive.

00:09:57.220 --> 00:10:01.880
And most people don't even have, you know, a GPU or have a bunch of GPUs at home. So it's kind of hard

00:10:01.880 --> 00:10:05.420
to actually get it running locally. Hopefully someday in the future, we'll be able to do that. But for now,

00:10:05.420 --> 00:10:08.760
you'll, you'll probably need internet access to use a lot of these things. Right. Okay. So you're

00:10:08.760 --> 00:10:15.000
envisioning a bunch of these agents that have access to an API that can quickly respond. Right,

00:10:15.000 --> 00:10:21.060
right. Over there. Yeah. Okay. So give us some ideas, you know. Yeah. So what this looks like

00:10:21.060 --> 00:10:26.600
concretely, you can imagine like a coding agent. So one thing you can do with GitHub Copilot right now is

00:10:26.600 --> 00:10:31.260
you can write a function declaration and a doc string and have it generate the function. But you can imagine for a

00:10:31.260 --> 00:10:35.620
coding agent, you can not only generate the function, but also generate some tests, run those tests,

00:10:35.620 --> 00:10:40.200
see errors in those tests, try and fix the errors, kind of do that whole life cycle to ideally give you

00:10:40.200 --> 00:10:44.340
a, you know, output that's actually a lot better. And then also, if you're thinking about this as an

00:10:44.340 --> 00:10:47.740
agent, maybe it's more of a back and forth. It's not just an autocomplete in your editor,

00:10:47.740 --> 00:10:51.600
but it can come back to you and say, you know, I'm sort of uncertain about this part here. What did you

00:10:51.600 --> 00:10:55.900
mean? Or, hmm, like, you know, I wrote these tests, but I'm not sure if it's quite what you wanted. Or maybe,

00:10:56.060 --> 00:10:58.900
you know, it's kind of running in the background and flagging different things that it sees in your

00:10:58.900 --> 00:11:02.580
code base. Like maybe you made some change and it can like detect that you, your doc string is out

00:11:02.580 --> 00:11:06.020
of date and kind of flag that for you. So thinking about it more as like an actual pair programmer.

00:11:06.020 --> 00:11:11.880
Okay. And is it primarily focused on, yeah. Are you thinking to focus mostly on programming or is it

00:11:11.880 --> 00:11:17.020
more abroad? Like I'm looking for a great deal on this classic car, go scour the internet and,

00:11:17.020 --> 00:11:21.680
and, and, you know, negotiate it for me. Yeah. Yeah. So, so, you know, the company is generally

00:11:21.680 --> 00:11:25.480
intelligent. So we certainly do want to be able to address all these different use cases over time.

00:11:25.480 --> 00:11:30.080
I think for us right now, one of the domains that we are interested in is code, especially because

00:11:30.080 --> 00:11:33.640
it's so objective. You can know if it's right or wrong, you have tests, that sort of stuff. So it's

00:11:33.640 --> 00:11:37.340
a nice playground for, for ourselves and something that we can build for ourselves to kind of iterate

00:11:37.340 --> 00:11:42.360
on internally, but we're not exactly sure what the final product will be. We're also training our own

00:11:42.360 --> 00:11:45.640
kind of large language models. We might prioritize some stuff around those. So there's lots of

00:11:45.640 --> 00:11:49.640
possibilities. We're not wedded to anything yet. Thankfully, we have the luxury to kind of take a little

00:11:49.640 --> 00:11:53.800
bit of time to figure that out as a, as a research company. Yeah. That's excellent. What about science?

00:11:53.800 --> 00:11:58.800
Yeah. Science is definitely a thing that we're interested in. It's pretty hard. And so, you know,

00:11:58.800 --> 00:12:02.600
do we necessarily want these things like, you know, running around making things in test tubes or

00:12:02.600 --> 00:12:05.340
whatever? I think that's probably a little bit harder than coding and coding is already pretty

00:12:05.340 --> 00:12:09.020
hard. So I think we'll get there. That's some of the stuff that we like personally on the team are

00:12:09.020 --> 00:12:13.700
really excited about to see, you know, how can we use these to uncover new cures for diseases or

00:12:13.700 --> 00:12:16.000
whatever. I'm really excited for that kind of stuff a little further in the future.

00:12:16.000 --> 00:12:19.560
Yeah. That'd be amazing. I was just talking to someone on the expo floor hall here,

00:12:19.560 --> 00:12:24.560
about protein folding. Yeah. Right. That kind of stuff. Yeah. It's kind of been elusive for people.

00:12:24.560 --> 00:12:29.220
We more or less have just tried to brute force it. Yeah. Right. With the folding at home thing.

00:12:29.220 --> 00:12:32.980
Let's just run every computer and just try every possibility, but there's a lot of possibilities.

00:12:32.980 --> 00:12:36.980
Yeah. Yeah. Exactly. All right. So where's Python fit in here? What are some of the tools that you're

00:12:36.980 --> 00:12:41.920
using? Yeah. So Python is, we love Python. We, we basically write everything in Python or bash,

00:12:41.920 --> 00:12:46.300
but you know, mostly Python or Python generates a little bit bash, you know, but it's mostly Python. So yeah,

00:12:46.300 --> 00:12:51.400
we use a lot of PyTorch for our models. And then other than that, you know, let's see,

00:12:51.400 --> 00:12:55.800
what other libraries do we use? I mean, we use tons of Python libraries like numpy and scikit and,

00:12:55.800 --> 00:13:00.260
you know, adders and just, there's, there's so many like wonderful, you know, things that people have

00:13:00.260 --> 00:13:04.080
built that we just, yeah, that are just so nice to work with. So we love the Python. You can kind of

00:13:04.080 --> 00:13:07.680
take it, open it up, look at all the source and like really understand everything in that full

00:13:07.680 --> 00:13:11.360
stack for us doing research. That's really valuable to be able to know everything that's going on.

00:13:11.360 --> 00:13:16.440
Yeah. You have these Lego block types of things. Like what if we arranged it like this? You don't

00:13:16.440 --> 00:13:20.260
have to write the whole machine learning, but you can click a few pieces together and

00:13:20.260 --> 00:13:21.340
yeah, off it goes.

00:13:21.340 --> 00:13:25.480
Yeah. Yeah. We build on top of Mosaic, for example, or other open source libraries that,

00:13:25.480 --> 00:13:29.080
that people put together for training stuff and kind of adapted for yourself. It's so nice.

00:13:29.120 --> 00:13:30.900
you can just pull things in and so easily change everything.

00:13:30.900 --> 00:13:36.220
Yeah. Awesome. I must've somehow blinked along the way and I, these large language models just

00:13:36.220 --> 00:13:40.620
seem to have come out of nowhere and all of a sudden, you know, AI is one of these things. It's

00:13:40.620 --> 00:13:45.200
kind of where I kind of recommended stuff and now all of a sudden it's mind bogglingly good.

00:13:45.200 --> 00:13:49.820
Yeah. Do things like TensorFlow and stuff work with these large language models or do you need

00:13:49.820 --> 00:13:55.940
other libraries? Yeah. So TensorFlow and PyTorch are probably the two main machine learning libraries

00:13:55.940 --> 00:14:00.700
that people do deep learning systems on top of. Pretty sure that, you know, GPT-3 and GPT-4 were

00:14:00.700 --> 00:14:05.780
probably trained on top of PyTorch. I think a lot of the stuff at Google, like Palm and BART and those

00:14:05.780 --> 00:14:09.080
types of things are trained on TensorFlow, but at the end of the day, they're, they're actually very

00:14:09.080 --> 00:14:13.320
similar and they're sort of converging to kind of similar ideas too as well. So it's interesting to

00:14:13.320 --> 00:14:14.440
see, to see them evolve.

00:14:14.440 --> 00:14:19.880
Yeah. Fantastic. All right. Last question, close out our conversation here is we're sitting here on

00:14:19.880 --> 00:14:25.080
startup row. Well, just outside of startup row, I suppose, but it's, you know, there's a bunch of people out

00:14:25.080 --> 00:14:30.100
here who are working on open source projects who would like to make it somehow find a way to make

00:14:30.100 --> 00:14:35.120
it their passion, their job, spend more time on it, maybe make it a company. How'd you get here?

00:14:35.120 --> 00:14:36.240
Tell people your journey.

00:14:36.240 --> 00:14:43.300
Yeah. So we got here and a little bit of a different route. So we, a lot of us were working at a previous

00:14:43.300 --> 00:14:48.060
company called Sorceress that did apply more of an applied machine learning thing where we are taking

00:14:48.060 --> 00:14:51.480
machine learning and applying it to the job of recruiting and trying to figure out, you know,

00:14:51.480 --> 00:14:54.880
can we find good people online that might be a good fit for a particular position and,

00:14:54.880 --> 00:14:58.440
you know, and reach out to them and get them interested in the job and that sort of stuff.

00:14:58.440 --> 00:15:03.000
We went through YC with this in 2017 and we raised our series A and eventually, you know,

00:15:03.000 --> 00:15:06.860
it was growing. We had a few million in revenue and customers and everything. And it just, in 2019,

00:15:06.860 --> 00:15:10.480
we were looking and it felt like, you know, there's so much really interesting stuff happening in

00:15:10.480 --> 00:15:14.200
self-supervised learning and in deep learning and in machine learning. And it feels like, you know,

00:15:14.200 --> 00:15:17.760
recruiting is very important, but is this going to be the most important thing in the world? Is this going to

00:15:17.760 --> 00:15:21.020
really be the thing that changes the world? Or will there be something a little bit larger in

00:15:21.020 --> 00:15:24.160
this more general purpose AI? And the more we thought about it, the more we felt like, you know,

00:15:24.160 --> 00:15:27.520
the AI stuff is probably going to have a huge impact. Like we should really be working on that.

00:15:27.520 --> 00:15:31.280
So we kind of wound down the previous company, a bunch of us moved over and started up Generally

00:15:31.280 --> 00:15:33.860
Intelligent. And then we've been working on stuff ever since then.

00:15:33.860 --> 00:15:39.320
Fantastic. Well, I know you've got some really cool stuff where the agents can sort of look at the

00:15:39.320 --> 00:15:43.540
code they're writing, think about it, evolve. And it's, it looks like a really interesting take.

00:15:43.540 --> 00:15:49.220
So congratulations. And I'll put the link to the, all your work in the show notes. People can check

00:15:49.220 --> 00:15:52.780
it out. Yeah. Sounds good. Yeah. Thank you very much. Yeah. Thanks for being here. It's great to

00:15:52.780 --> 00:16:00.360
chat. Take care. You bet. This portion of Talk Python To Me is brought to you by Sentry. Is your Python

00:16:00.360 --> 00:16:07.220
application fast or does it sometimes suffer from slowdowns and unexpected latency? Does this usually

00:16:07.220 --> 00:16:11.480
only happen in production? It's really tough to track down the problems at that point, isn't it?

00:16:11.800 --> 00:16:16.800
If you've looked at APM application performance monitoring products before, they may have felt

00:16:16.800 --> 00:16:22.280
out of place for software teams. Many of them are more focused on legacy problems made for ops and

00:16:22.280 --> 00:16:28.300
infrastructure teams to keep their infrastructure and services up and running. Sentry has just launched

00:16:28.300 --> 00:16:34.860
their new APM service. And Sentry's approach to application monitoring is focused on being actionable,

00:16:34.860 --> 00:16:40.620
affordable, and actually built for developers. Whether it's a slow running query or latent payment endpoint

00:16:40.620 --> 00:16:46.200
that's at risk of timing out and causing sales to tank, Sentry removes the complexity and does the

00:16:46.200 --> 00:16:50.740
analysis for you, surfacing the most critical performance issues so you can address them

00:16:50.740 --> 00:16:57.320
immediately. Most legacy APM tools focus on an ingest everything approach, resulting in high storage

00:16:57.320 --> 00:17:03.180
costs, noisy environments, and an enormous amount of telemetry data most developers will never need to

00:17:03.180 --> 00:17:08.740
analyze. Sentry has taken a different approach, building the most affordable APM solution in the market.

00:17:09.220 --> 00:17:13.900
They've removed the noise and extract the maximum value out of your performance data while passing

00:17:13.900 --> 00:17:19.400
the savings directly onto you, especially for Talk Python listeners who use the code Talk Python.

00:17:19.400 --> 00:17:27.040
So get started at talkpython.fm/sentry and be sure to use their code Talk Python all lowercase

00:17:27.040 --> 00:17:33.960
so you let them know that you heard about them from us. My thanks to Sentry for keeping this podcast going strong.

00:17:36.540 --> 00:17:43.140
Now we talk with Mo Sarat from Wereobots. They're building the database platform for geospatial analytics and AI.

00:17:43.140 --> 00:17:44.960
Hey Mo, welcome to Talk Python.

00:17:44.960 --> 00:17:45.960
Thank you so much.

00:17:45.960 --> 00:17:49.340
Yeah, it's good to have you here. Let's start off with a quick introduction. Who are you?

00:17:49.340 --> 00:17:54.880
Absolutely. So my name is Mo and I'm the co-founder and CEO of a company called Wereobots.

00:17:54.880 --> 00:18:00.500
Wereobots' grand vision is enable every organization to drive value from data via space and time.

00:18:00.820 --> 00:18:06.960
Awesome. I love it. I love it. So yeah, thanks for being here on the show. Let's dive into Wereobots.

00:18:06.960 --> 00:18:09.380
What is the problem you're solving? What are you guys building?

00:18:09.380 --> 00:18:14.100
Think about like, again, every single data record that is collecting on a daily basis.

00:18:14.100 --> 00:18:20.000
Even like we're here right now, we're talking on this podcast at this specific location at this specific time.

00:18:20.000 --> 00:18:25.840
So if you think about the space and time aspect, it's actually a very important aspect of every single piece of data that is being collected.

00:18:25.840 --> 00:18:30.800
Right. If we're here next week, who knows why we're here? We could be here for a different reason. That might mean something different, right?

00:18:30.800 --> 00:18:38.860
Absolutely. Yeah. So that's exactly. So that space and time lens that you can apply to your data can actually also tell you a better story about your data.

00:18:38.860 --> 00:18:43.220
You can drive more value, more insights from your data if you apply that space and time lens.

00:18:43.700 --> 00:18:48.960
And this is basically what we are, not necessarily like, this is exactly what we focus on in our company.

00:18:48.960 --> 00:18:58.940
But more specifically, I mean, we are trying to build like kind of a database infrastructure to enable people to use that space and time lens to drive value from their data.

00:18:58.940 --> 00:19:05.780
Okay. Fantastic. Now, when you talk about space and time and data, are we talking records in a time series database?

00:19:05.800 --> 00:19:14.260
Are we talking regular database or NoSQL? Or could it be even things like the log file from Nginx about the visitors to my website?

00:19:14.260 --> 00:19:15.500
What's the scope?

00:19:15.500 --> 00:19:22.300
The scope is actually very wide. So think about any data could be structured, semi-structured, unstructured data that you have.

00:19:22.660 --> 00:19:37.600
And as long as it have like kind of a geospatial aspect to it, a geospatial aspect to it means like the record or the document has, was, let's say, created in a specific location or represent an event that happened in a certain location at a certain time.

00:19:37.800 --> 00:19:44.260
Or represent like, again, like an object or an asset that you monitor at different locations at different times.

00:19:44.260 --> 00:19:47.660
Whatever it is, it can be stored in any of these kind of formats.

00:19:47.660 --> 00:19:55.380
As long as it have this kind of geospatial aspect to it, you can definitely apply that kind of geospatial or space-time lens to it.

00:19:55.380 --> 00:19:58.980
Right. Okay. So what are some of the questions you might answer with Orlot?

00:19:58.980 --> 00:20:03.400
Questions that varies. I mean, so there are, it depends on the type of the data. It depends on the use case.

00:20:03.400 --> 00:20:08.900
You have a horizontal technology that enables you to enable so many industry protocols, but I'll give a couple of examples.

00:20:08.900 --> 00:20:10.500
Yeah, yeah. Make it concrete for us.

00:20:10.500 --> 00:20:14.240
Absolutely. Think about like a logistics company or a delivery company.

00:20:14.240 --> 00:20:18.020
Like the most, I mean, well-known delivery company is Amazon, right?

00:20:18.020 --> 00:20:30.940
I mean, you go to the app, you purchase an item or a product, and then the whole journey of that product from the supplier to the warehouse to the driver, Amazon driver, all the way that makes it to your door.

00:20:30.940 --> 00:20:36.080
There is a whole kind of, everything has a geospatial location to it, attached to it.

00:20:36.080 --> 00:20:40.200
The package is moving around. You're located somewhere. Their house is a certain location.

00:20:40.200 --> 00:20:49.800
Handling the logistics behind all of that, understanding how things are, you're monitoring all these assets in space and time as it reaches the door.

00:20:50.220 --> 00:21:00.980
This whole journey, there's a lot of kind of data processing, data analytics happening that you have to do through, again, the geospatial kind of aspect, the geospatial contextual aspect of things.

00:21:00.980 --> 00:21:02.260
So this is one example.

00:21:02.260 --> 00:21:15.040
Another example could be if you're like an insurance company and you're insuring homes, for example, and you want to understand what are the nearby kind of climate conditions, natural disaster conditions compared to your home.

00:21:15.040 --> 00:21:21.720
There's also the home has a location, these kind of natural disaster, weather changes at different locations all the time.

00:21:21.720 --> 00:21:25.920
That will impact how you take decisions about insuring these homes.

00:21:25.920 --> 00:21:29.600
Do I buy it? Do insurers want to insure it? What do I have to pay to do that?

00:21:29.600 --> 00:21:29.660
Exactly.

00:21:29.840 --> 00:21:39.240
That's another example, again, that space and time lens or the geospatial aspect impacts your decision when it comes to taking, it's an important decision that you take in here.

00:21:39.240 --> 00:21:40.400
So that's another example.

00:21:40.400 --> 00:21:47.360
So these are just a couple of use cases, but there are tons of other use cases and use cases that may not exist even yet.

00:21:47.360 --> 00:21:51.460
So there's a lot of movement now into climate tech and ag tech.

00:21:51.460 --> 00:22:01.140
And we are like what we're trying to do at Whereabouts is we're building the database infrastructure that enable the next generation climate tech and agriculture technology.

00:22:01.140 --> 00:22:06.080
So they can ask the questions that they might have, but you already have the machinery to answer them.

00:22:06.080 --> 00:22:07.760
We have machinery to answer them.

00:22:07.760 --> 00:22:11.400
And they build their own secret sauce on top of our infrastructure.

00:22:11.400 --> 00:22:13.240
So kind of a framework platform.

00:22:13.240 --> 00:22:13.880
Absolutely.

00:22:13.880 --> 00:22:14.240
Yeah.

00:22:14.240 --> 00:22:14.620
Got it.

00:22:14.620 --> 00:22:14.780
Yeah.

00:22:14.780 --> 00:22:16.860
So Python, where's Python fit in this story?

00:22:16.940 --> 00:22:17.980
That's a great question.

00:22:17.980 --> 00:22:24.420
So geospatial data or the geospatial aspect of data has existed for so long.

00:22:24.420 --> 00:22:26.220
As you said, we live in the space-time continuum.

00:22:26.220 --> 00:22:28.520
Everything has a space-time aspect, geospatial aspect.

00:22:28.520 --> 00:22:33.700
And that's why developers already have APIs to interact with geospatial data.

00:22:33.700 --> 00:22:36.260
And these APIs, the language varies.

00:22:36.260 --> 00:22:45.140
So there are some people that use SQL to interact with the data, process the data in either SQL databases or any other kind of SQL processing engine, right?

00:22:45.140 --> 00:22:51.680
But a lot of the geospatial developers or people developing with geospatial data, they use Python.

00:22:51.680 --> 00:22:55.580
There are so many libraries that use Python to actually...

00:22:55.580 --> 00:22:57.680
Example of these libraries is a library called Geopandas.

00:22:57.680 --> 00:22:58.800
It's a fantastic library.

00:22:58.800 --> 00:23:03.480
It's an extension to Pandas to kind of wrangle and crunch geospatial data.

00:23:03.620 --> 00:23:08.080
Ask questions about what things are contained in here, what things are outside of here, how far away is it?

00:23:08.080 --> 00:23:08.680
Absolutely.

00:23:08.680 --> 00:23:09.900
So this is what Geopandas does.

00:23:09.900 --> 00:23:15.160
The only problem is that Geopandas is a library, has a great functionality, but again, it doesn't...

00:23:15.160 --> 00:23:17.460
It's not enterprise-ready for the most part.

00:23:17.460 --> 00:23:19.240
It doesn't scale, all that kind of stuff.

00:23:19.580 --> 00:23:29.020
So what we do at WorderBots is that we provide SQL API to the user to run spatial queries on the data, but we also provide spatial Python API.

00:23:29.020 --> 00:23:46.600
Like if you're using Geopandas, you can use the same API, do the heavy lifting enterprise scale kind of processing of the data using our platform, and then do the major Geopandas kind of functionality you're familiar with to, again, do the geospatial processing with it.

00:23:46.600 --> 00:23:50.600
So this is how it fits within Python, and actually looking at our...

00:23:50.600 --> 00:23:53.600
We have an open source software called Apache Sedona.

00:23:53.600 --> 00:24:01.880
It's an Apache under the Apache license, and it has all these APIs, SQL and Python, and Python is the most popular.

00:24:01.880 --> 00:24:11.540
So it's been the Python package alone on PyPy is being downloaded a million times over on a monthly basis as we're speaking today.

00:24:11.540 --> 00:24:15.140
So definitely Python fits very well within our...

00:24:15.140 --> 00:24:16.160
Yeah, that's awesome.

00:24:16.160 --> 00:24:16.980
Absolutely, yeah.

00:24:16.980 --> 00:24:23.480
So it sounds like your business, WorderBots, is a little bit following the open core model, you say?

00:24:23.480 --> 00:24:24.120
Yes.

00:24:24.120 --> 00:24:25.860
Let's round out our conversation here with a...

00:24:25.860 --> 00:24:28.620
Talking about the business itself, how do you get a startup row?

00:24:28.620 --> 00:24:30.240
We follow the open core model.

00:24:30.240 --> 00:24:31.280
You're totally right about that.

00:24:31.280 --> 00:24:33.300
So we have our open source software, Apache Sedona.

00:24:33.300 --> 00:24:37.700
It's available for free open source, very permissive license, the Apache license 2.0.

00:24:37.700 --> 00:24:39.060
And it's the open source.

00:24:39.060 --> 00:24:41.960
It's also used in operational production in so many use cases.

00:24:41.960 --> 00:24:43.460
There are so many contributors outside.

00:24:43.460 --> 00:24:46.080
I'm the original creator of it, as well as my partner, Gia.

00:24:46.080 --> 00:24:49.440
We're both the original creators, but it's grew beyond us now.

00:24:49.440 --> 00:24:53.280
So there are like dozens, like 100 contributors now, something like this.

00:24:53.280 --> 00:24:57.920
And we use Sedona as an open core, but we build a whole platform around it.

00:24:57.920 --> 00:25:06.280
So if you want to think about like what we do compared to the other data platforms in the market, there are generic data platforms like Snowflake Databricks.

00:25:06.280 --> 00:25:11.260
There are more specific specialized data platforms like MongoDB for NoSQL.

00:25:11.260 --> 00:25:12.700
There's Neo4j for Graph.

00:25:12.700 --> 00:25:13.780
We are...

00:25:13.780 --> 00:25:16.580
Webinar Bots is like the data platform for Geospatial.

00:25:16.580 --> 00:25:18.240
So this is basically...

00:25:18.240 --> 00:25:21.520
And we use Apache Sedona as an open core to enable us to do all of this.

00:25:21.520 --> 00:25:22.240
Fantastic.

00:25:22.240 --> 00:25:23.040
All right.

00:25:23.040 --> 00:25:25.020
Well, congratulations on being here.

00:25:25.020 --> 00:25:25.560
Yeah.

00:25:25.560 --> 00:25:27.600
I wish you success with the whole project.

00:25:27.600 --> 00:25:28.900
And thanks for coming on the show.

00:25:28.900 --> 00:25:29.860
Thank you so much.

00:25:29.860 --> 00:25:30.460
I appreciate it.

00:25:30.460 --> 00:25:31.120
Looking forward to it.

00:25:31.120 --> 00:25:31.320
Yeah.

00:25:31.320 --> 00:25:31.720
You bet.

00:25:31.720 --> 00:25:32.520
Thank you so much.

00:25:32.520 --> 00:25:32.680
Yeah.

00:25:32.680 --> 00:25:32.820
Bye.

00:25:32.820 --> 00:25:40.560
Time to talk to Nip Time, who have created Python programmable spreadsheets that are super powered with Python and AI.

00:25:40.560 --> 00:25:43.420
I got to tell you, this product looks super awesome.

00:25:43.420 --> 00:25:46.580
It looks so much better than things like Google Sheets or Excel.

00:25:46.580 --> 00:25:48.820
And I can't wait to get a chance to play with it.

00:25:48.820 --> 00:25:49.360
Hey, guys.

00:25:49.360 --> 00:25:50.020
Hello.

00:25:50.020 --> 00:25:51.600
Welcome to Talk Python To Me.

00:25:51.600 --> 00:25:52.120
Yeah.

00:25:52.120 --> 00:25:53.260
It's great to have you here.

00:25:53.260 --> 00:25:54.600
First, introduce yourselves.

00:25:54.600 --> 00:25:55.680
Thanks for having us.

00:25:55.680 --> 00:25:56.680
I'm Dawa.

00:25:56.680 --> 00:26:00.900
I've been doing Python professionally for, I don't know, 20 years or so.

00:26:00.900 --> 00:26:02.140
I'm Jack.

00:26:02.340 --> 00:26:03.360
I'm Dawa's co-founder.

00:26:03.360 --> 00:26:03.980
Uh-huh.

00:26:03.980 --> 00:26:07.780
Been doing Python a little less than that, but met Dawa about five years ago.

00:26:07.780 --> 00:26:10.380
And we founded Nip Time about a year ago.

00:26:10.380 --> 00:26:10.980
Yeah.

00:26:10.980 --> 00:26:13.160
So, you know, let's dive into it.

00:26:13.160 --> 00:26:15.480
Nip Time, what's the product?

00:26:15.480 --> 00:26:16.380
What's the problem you're solving?

00:26:16.380 --> 00:26:17.000
Yeah.

00:26:17.000 --> 00:26:19.800
The proposition that we have is pretty straightforward.

00:26:19.800 --> 00:26:31.800
We build a spreadsheet on top of a Jupyter notebook engine, which basically gives you all the data science, superpowers that the notebook gives you in a familiar way.

00:26:31.860 --> 00:26:42.820
It's a familiar spreadsheet environment, which means that you can share your work as a Python programmer much easier with people that are not familiar with notebooks because they have the universal data canvas of a spreadsheet.

00:26:42.820 --> 00:26:54.820
How interesting, because one of the big challenges data scientists often have is they work in Jupyter, they work in Jupyter, and then some executive wants to share it at a presentation or they want to continue working on it, but they're not developers.

00:26:55.380 --> 00:26:56.220
So what do you do?

00:26:56.220 --> 00:27:01.000
You write an Excel file and you hand that off and then you re-import it somewhere, maybe?

00:27:01.000 --> 00:27:01.740
I don't know.

00:27:01.740 --> 00:27:02.160
Yeah, yeah.

00:27:02.160 --> 00:27:10.200
The typical flow is indeed very much like you write out the CSV, you email that to the person that is going to put it into Excel.

00:27:10.420 --> 00:27:19.780
That person then creates a graph in Excel, screenshot that graph in Excel and sends it to the person that puts it in the presentation and then the CEO can do something with it.

00:27:19.780 --> 00:27:21.900
It goes either in PowerPoint or it goes in Word.

00:27:21.900 --> 00:27:23.040
Yeah, one of those two, right?

00:27:23.040 --> 00:27:23.800
Probably the picture.

00:27:24.140 --> 00:27:28.000
But that's a bunch of steps that are disassociated from data.

00:27:28.000 --> 00:27:29.780
So that's one problem, right?

00:27:29.780 --> 00:27:30.480
That's the one problem.

00:27:30.480 --> 00:27:36.560
But since no one really sees your product in action while we're talking here, maybe just a bit of an explanation.

00:27:36.560 --> 00:27:44.880
It looks very much like Google Docs or one of the online Excel, I say Doc, I mean Sheets, like one of the online spreadsheet things.

00:27:44.880 --> 00:27:48.160
It doesn't look like something embedded into notebooks, right?

00:27:48.160 --> 00:27:49.080
Yeah, that's right.

00:27:49.080 --> 00:27:51.340
It is a spreadsheet first and foremost.

00:27:51.820 --> 00:27:54.920
It looks a lot like Google Sheets, but you can run Python in it.

00:27:54.920 --> 00:27:55.420
Yes.

00:27:55.420 --> 00:27:57.700
You can run Python both directly in the spreadsheet cells.

00:27:57.700 --> 00:28:02.760
You can also define other functionality in Python and then run that with your spreadsheet.

00:28:02.760 --> 00:28:05.220
Yeah, I mean, to me, that's where the magic is, right?

00:28:05.220 --> 00:28:10.340
Like Excel or Sheets, the spreadsheets more broadly are super useful.

00:28:10.340 --> 00:28:14.540
But it's always like, how do I do an if statement in this dreaded thing again?

00:28:14.540 --> 00:28:17.540
And how do I do a max with a condition?

00:28:17.640 --> 00:28:23.160
You know, just all the programming aspect of going beyond just having raw data is just like, oh boy, this is.

00:28:23.160 --> 00:28:27.880
And you just showed me an example where like here, you just write range of a thing and boom, it just writes that out.

00:28:27.880 --> 00:28:32.700
Or you write a Python tertiary statement and it just runs.

00:28:32.700 --> 00:28:33.280
Right.

00:28:33.620 --> 00:28:38.040
Yeah, but also common things in spreadsheets that are hard are data cleaning, right?

00:28:38.040 --> 00:28:40.740
You get some data from somewhere and it's not quite right.

00:28:41.220 --> 00:28:43.860
And most of the time people end up doing this by hand.

00:28:43.860 --> 00:28:46.540
And that's fine the first time you do it.

00:28:46.540 --> 00:28:49.140
The second time and the third time it gets very annoying.

00:28:49.140 --> 00:28:53.320
While if you just write a little bit of Python, you can clean data like that.

00:28:53.320 --> 00:28:53.680
Yeah.

00:28:53.680 --> 00:28:57.820
And then the next time you have the data, you just rerun the script and it's clean again.

00:28:57.820 --> 00:29:00.840
So that's a very powerful way of doing this thing.

00:29:00.840 --> 00:29:03.360
And we have a full Python environment.

00:29:03.360 --> 00:29:05.760
It's not just a lightweight, you know, runs in the browser.

00:29:05.760 --> 00:29:08.480
You can do pip install anything you want.

00:29:08.480 --> 00:29:13.220
So you can connect any API out there, use any data, export any data.

00:29:13.220 --> 00:29:15.080
It's a complete environment.

00:29:15.080 --> 00:29:15.580
Yeah, how interesting.

00:29:15.580 --> 00:29:22.280
Yeah, there's a little window where you can write straight Python, you know, some function that does arbitrary Python.

00:29:22.280 --> 00:29:25.480
And then you can invoke it like a function in the spreadsheet, right?

00:29:25.480 --> 00:29:26.020
Exactly.

00:29:26.020 --> 00:29:26.660
Exactly.

00:29:26.660 --> 00:29:28.840
And you can talk to things on the internet.

00:29:28.840 --> 00:29:30.660
For example, I could do web scraping there.

00:29:30.660 --> 00:29:31.020
Yes.

00:29:31.020 --> 00:29:33.480
So you can call an API, like a currency API?

00:29:33.480 --> 00:29:34.780
Yeah, exactly.

00:29:34.780 --> 00:29:35.440
Okay.

00:29:35.440 --> 00:29:40.820
But yeah, any REST call you want to make, you just import requests and go for it.

00:29:40.820 --> 00:29:41.280
Wow.

00:29:41.280 --> 00:29:42.480
So where does it run?

00:29:42.480 --> 00:29:44.920
Is this PyScript, Pyodide?

00:29:44.920 --> 00:29:45.860
Is this Sculpt?

00:29:45.860 --> 00:29:47.460
Is this Docker on a server?

00:29:47.460 --> 00:29:49.440
It's all running in a Docker container.

00:29:49.440 --> 00:29:49.860
Okay.

00:29:49.860 --> 00:29:50.620
Server side.

00:29:50.620 --> 00:29:51.840
That's how it works.

00:29:51.840 --> 00:29:55.680
And that's kind of, we do that for maximum flexibility, maximum capability.

00:29:55.920 --> 00:30:02.320
So it means that anything you can install, anything you can run on a Jupyter notebook running on Linux, you can run in Neptune.

00:30:02.320 --> 00:30:02.820
I see.

00:30:02.820 --> 00:30:05.680
So we get full Python 3.11 or 3.10 or whatever it is.

00:30:05.680 --> 00:30:05.900
Yep.

00:30:05.900 --> 00:30:06.260
Yep.

00:30:06.260 --> 00:30:10.260
And, you know, we ship with a bunch of useful packages pre-installed.

00:30:10.400 --> 00:30:14.860
But if you want to install something else, you just open up our dependency management window.

00:30:14.860 --> 00:30:15.300
Okay.

00:30:15.300 --> 00:30:16.600
Install anything else you want to use.

00:30:16.600 --> 00:30:19.140
It's all very manageable, very configurable.

00:30:19.140 --> 00:30:21.400
Well, it looks super good to me.

00:30:21.400 --> 00:30:23.400
What's the user model?

00:30:23.400 --> 00:30:27.540
Do I go and create an account on your site and it's kind of like Google Docs or what's the story?

00:30:27.540 --> 00:30:28.020
Yep.

00:30:28.020 --> 00:30:28.400
Exactly.

00:30:28.400 --> 00:30:29.340
You can try it out.

00:30:29.340 --> 00:30:31.800
You can go to neptine.com in the upper right.

00:30:31.800 --> 00:30:32.640
Just click log in.

00:30:32.640 --> 00:30:33.440
You can create an account.

00:30:33.540 --> 00:30:36.380
It's totally free to use the free tier.

00:30:36.380 --> 00:30:36.920
Yeah.

00:30:36.920 --> 00:30:37.740
Give it a shot.

00:30:37.740 --> 00:30:38.280
Awesome.

00:30:38.280 --> 00:30:39.000
All right.

00:30:39.000 --> 00:30:39.680
Final question.

00:30:39.680 --> 00:30:41.740
You know, how did you guys get here in Startup Row?

00:30:41.740 --> 00:30:48.840
You know, everyone wants to build something amazing with open source, but how did you turn that into a business and something you can put your full time into?

00:30:48.840 --> 00:31:02.700
I mean, I guess we're kind of lucky in that when we started, I, you know, I pitched it to a bunch of people that due to no fault of their own got into some money.

00:31:03.060 --> 00:31:05.640
And they, they were willing to back us.

00:31:05.640 --> 00:31:09.000
And then later we joined YC for the winter batch.

00:31:09.000 --> 00:31:09.600
Awesome.

00:31:09.600 --> 00:31:16.020
And in that process, we, you know, got a little bit of publicity and were picked up for the Startup Row.

00:31:16.020 --> 00:31:28.520
Just to add to that too, based on our experience in Y Combinator, there are lots of open source tools out there that are able to get started on some commercial path just, just based on the community that they're building, based on the users.

00:31:28.520 --> 00:31:29.180
Right.

00:31:29.180 --> 00:31:31.000
It's a, it's a very good path.

00:31:31.000 --> 00:31:38.180
I feel like this whole open core business model has really taken off in the last couple of years where it used to be a PayPal donate button.

00:31:38.180 --> 00:31:41.560
And now it's a legitimate offering that businesses will buy.

00:31:41.560 --> 00:31:42.620
And it's good.

00:31:42.620 --> 00:31:43.800
I think it's very positive.

00:31:43.800 --> 00:31:46.680
So I'm really impressed with what you guys built.

00:31:46.680 --> 00:31:47.580
I think it's awesome.

00:31:47.760 --> 00:31:48.960
I think people really like it.

00:31:48.960 --> 00:31:49.400
Yeah.

00:31:49.400 --> 00:31:50.380
So good luck.

00:31:50.380 --> 00:31:51.280
Thanks for being here.

00:31:51.280 --> 00:31:52.260
Thank you so much.

00:31:52.260 --> 00:31:53.440
Now up is Nixla.

00:31:53.440 --> 00:32:02.000
We have Federico Garza and Christian Chula here to tell us about their time series startup ready to make predictions based on an open source time series ecosystem.

00:32:02.000 --> 00:32:02.620
Hey there.

00:32:02.620 --> 00:32:03.140
Hello.

00:32:03.140 --> 00:32:04.180
Welcome to Talk Python.

00:32:04.180 --> 00:32:04.820
Hello.

00:32:04.820 --> 00:32:05.100
Hello.

00:32:05.100 --> 00:32:05.640
Hello.

00:32:05.920 --> 00:32:06.800
Let's start with introductions.

00:32:06.800 --> 00:32:07.680
Who are y'all?

00:32:07.680 --> 00:32:09.360
So I am Christian Chalew.

00:32:09.360 --> 00:32:11.160
I'm a co-founder of Nixla.

00:32:11.160 --> 00:32:11.720
Yep.

00:32:11.720 --> 00:32:12.160
Hello.

00:32:12.160 --> 00:32:12.800
I'm Fede.

00:32:12.800 --> 00:32:14.700
I'm CTO and co-founder of Nixla.

00:32:14.700 --> 00:32:15.820
Nice to meet you both.

00:32:15.820 --> 00:32:16.520
Welcome.

00:32:16.520 --> 00:32:17.520
Welcome to the show.

00:32:17.520 --> 00:32:19.600
Really great to have you here at PyCon.

00:32:19.980 --> 00:32:23.820
And yeah, let's start with the problem y'all are trying to solve.

00:32:23.820 --> 00:32:24.380
Okay.

00:32:24.380 --> 00:32:24.620
Yeah.

00:32:24.620 --> 00:32:27.400
So at Nixla, what we do is time series forecasting.

00:32:27.400 --> 00:32:36.380
So as you know, time series forecasting is a very relevant task that a lot of companies and practitioners need to solve.

00:32:36.380 --> 00:32:40.040
So essentially predicting future values of something, right?

00:32:40.040 --> 00:32:42.480
It could be demand of a product or the weather.

00:32:42.480 --> 00:32:45.080
So there are many use cases for forecasting.

00:32:45.080 --> 00:32:47.100
It's a very common problem in industry.

00:32:47.220 --> 00:32:55.660
And essentially we want to provide tools to developers, engineers, researchers to be able to do this more efficiently and with good practices.

00:32:55.660 --> 00:32:58.160
And yeah, that's mostly it.

00:32:58.160 --> 00:32:58.440
Right.

00:32:58.440 --> 00:32:58.700
Okay.

00:32:58.700 --> 00:33:01.120
So is this like a Python API?

00:33:01.120 --> 00:33:02.720
Is this a database?

00:33:02.720 --> 00:33:06.280
What is the actual product?

00:33:06.280 --> 00:33:06.700
The product.

00:33:06.700 --> 00:33:07.120
Yeah.

00:33:07.120 --> 00:33:14.380
So we have an ecosystem of Python libraries and we have different libraries for different use cases.

00:33:14.380 --> 00:33:21.800
For example, we have the stats forecast library, which specializes in statistical econometric models.

00:33:21.800 --> 00:33:30.700
And also we have a more complex models and libraries for deep learning and machine learning applications.

00:33:30.700 --> 00:33:31.140
Yeah.

00:33:31.140 --> 00:33:31.840
Nice.

00:33:31.840 --> 00:33:38.000
And if you train some of these models yourself on certain data, things like that, or where do you get the models from?

00:33:38.000 --> 00:33:43.340
The idea behind the libraries is that you can use whatever your data is.

00:33:43.340 --> 00:33:50.300
The only restriction is that it must be time series data, but you can use whatever data you have.

00:33:50.300 --> 00:33:51.180
Okay.

00:33:51.180 --> 00:33:52.020
Fantastic.

00:33:52.020 --> 00:33:54.060
And where's its data?

00:33:54.060 --> 00:33:57.320
Python's at the heart of so much data processing these days.

00:33:57.320 --> 00:34:02.440
And, you know, I guess give a shout out to all the different Python packages that are already out there.

00:34:02.500 --> 00:34:06.420
Maybe you want to just give a rundown on those and what they're for and then talk about them.

00:34:06.420 --> 00:34:06.720
Yeah.

00:34:06.720 --> 00:34:10.140
So we have like six packages right now.

00:34:10.140 --> 00:34:14.380
They are all libraries on GitHub that you can install or install it with Conda.

00:34:14.380 --> 00:34:18.140
And essentially they focus on different ways of approaching forecasting.

00:34:18.140 --> 00:34:22.940
And they're essentially libraries built on Python, depending on some of them built on Numba.

00:34:22.940 --> 00:34:24.940
Other methods are in.

00:34:24.940 --> 00:34:25.880
Oh, you guys are using Numba.

00:34:25.880 --> 00:34:26.200
Yeah.

00:34:26.400 --> 00:34:26.980
Oh, okay.

00:34:26.980 --> 00:34:28.320
And it makes a huge difference?

00:34:28.320 --> 00:34:28.580
Yeah.

00:34:28.580 --> 00:34:28.840
Yeah.

00:34:28.840 --> 00:34:29.340
It makes a huge difference.

00:34:29.340 --> 00:34:29.860
All right.

00:34:29.860 --> 00:34:30.080
Yeah.

00:34:30.080 --> 00:34:31.400
Tell people really, really quickly.

00:34:31.400 --> 00:34:32.040
What is Numba?

00:34:32.040 --> 00:34:38.940
So Numba is this library which allows you to compile just in time your code.

00:34:38.940 --> 00:34:42.680
So it's a lot faster than using just plain Python.

00:34:42.680 --> 00:34:44.580
And how easy is it to use?

00:34:44.580 --> 00:34:45.780
It's really easy.

00:34:45.780 --> 00:34:46.180
Okay.

00:34:46.180 --> 00:34:46.580
Yeah.

00:34:46.580 --> 00:34:54.160
In fact, we wanted to make our library more efficient and more faster.

00:34:54.160 --> 00:34:58.060
And we did it in like two weeks only using Numba.

00:34:58.060 --> 00:35:00.560
So it was really easy to use.

00:35:00.560 --> 00:35:00.920
Yeah.

00:35:00.920 --> 00:35:01.220
Awesome.

00:35:01.220 --> 00:35:01.700
Awesome.

00:35:01.700 --> 00:35:04.880
And some other packages you see is PyTorch.

00:35:04.880 --> 00:35:11.740
So like our deep learning methods, neural forecasting approaches are built on PyTorch or PyTorch Lightning.

00:35:11.740 --> 00:35:12.340
Yeah.

00:35:12.340 --> 00:35:12.980
Fantastic.

00:35:13.200 --> 00:35:19.940
So would you say that your business model is something of an open core model where it's kind of built on top of these libraries?

00:35:19.940 --> 00:35:20.920
Absolutely.

00:35:20.920 --> 00:35:21.260
Yeah.

00:35:21.260 --> 00:35:21.520
Yeah.

00:35:21.520 --> 00:35:25.660
So for now, we have been focusing on building these libraries, the community.

00:35:25.660 --> 00:35:29.960
We have a very active community on Slack and people that use us and contribute with our code.

00:35:29.960 --> 00:35:39.860
And we are building services on top of these libraries like enterprise solutions or hosting computation or even simplifying the usage further.

00:35:39.860 --> 00:35:43.080
So for example, APIs where you can just simply pass your data.

00:35:43.080 --> 00:35:45.860
I want to know what is going to happen next on this data.

00:35:45.860 --> 00:35:49.380
Do you pass us some historical data and ask us to make predictions?

00:35:49.380 --> 00:35:51.440
Make predictions and then we produce the predictions.

00:35:51.440 --> 00:35:52.040
Okay.

00:35:52.040 --> 00:35:52.460
Yeah.

00:35:52.460 --> 00:35:53.660
This is one of the types.

00:35:53.660 --> 00:35:54.280
Yeah.

00:35:54.280 --> 00:35:57.200
So we are working on these different applications and services.

00:35:57.200 --> 00:35:57.720
Awesome.

00:35:57.720 --> 00:35:58.720
It sounds really cool.

00:35:58.720 --> 00:35:59.200
Thanks.

00:35:59.420 --> 00:36:03.580
So final question, how do you make your way over here to Startup Row at PyCon?

00:36:03.580 --> 00:36:06.280
Like how did you start your company and how did you get here?

00:36:06.280 --> 00:36:06.880
Yeah.

00:36:06.880 --> 00:36:08.900
It has been a long journey.

00:36:08.900 --> 00:36:16.240
I mean, we have been like for a year working on these libraries and services.

00:36:16.240 --> 00:36:20.160
And right now we are focusing on building the startup, right?

00:36:20.160 --> 00:36:26.820
We want to be able to do this full time for a long time and really, yeah, build something that can help people.

00:36:26.820 --> 00:36:27.500
Yeah.

00:36:27.500 --> 00:36:34.380
Are you looking to offer an API, like an open AI sort of model or running people's code as a service?

00:36:34.380 --> 00:36:35.940
Or where are you thinking you're going?

00:36:35.940 --> 00:36:36.520
Yeah.

00:36:36.520 --> 00:36:36.820
Yeah.

00:36:36.820 --> 00:36:38.440
That's definitely one of the options.

00:36:38.940 --> 00:36:41.980
But yeah, we are finishing our funding runs.

00:36:41.980 --> 00:36:46.860
And once we finish that, funding helps a lot on software development.

00:36:46.860 --> 00:36:47.860
Funding helps a lot on development.

00:36:47.860 --> 00:36:52.300
And yeah, so we are exploring different venues and there's very exciting things to come.

00:36:52.300 --> 00:36:53.460
All right.

00:36:53.460 --> 00:36:56.080
Well, we all wish you the best of luck on your project.

00:36:56.080 --> 00:36:58.000
And thanks for taking the time to talk to us.

00:36:58.000 --> 00:36:59.300
No, thank you for inviting me.

00:36:59.300 --> 00:36:59.900
Yeah, you bet.

00:36:59.900 --> 00:37:00.160
Thanks.

00:37:00.160 --> 00:37:00.480
Bye.

00:37:00.480 --> 00:37:00.840
Bye.

00:37:00.840 --> 00:37:02.920
We'll speak with Piero Molina from PrettyBase.

00:37:02.920 --> 00:37:08.900
They empower you to rapidly build, iterate, and deploy ML models with their declarative machine learning platform.

00:37:09.260 --> 00:37:10.640
Piero, welcome to Talk Python To Me.

00:37:10.640 --> 00:37:12.220
Thank you very much for having me.

00:37:12.220 --> 00:37:13.760
Yeah, it's fantastic to have you here.

00:37:13.760 --> 00:37:15.080
Quick introduction for everyone.

00:37:15.080 --> 00:37:15.760
Sure.

00:37:15.760 --> 00:37:18.320
So I'm Piero and I'm the CEO of PrettyBase.

00:37:18.320 --> 00:37:20.180
Can tell you about PrettyBase in a second.

00:37:20.180 --> 00:37:26.060
I'm also the author of Ludwig, which is an open source Python package for training machine learning models.

00:37:26.060 --> 00:37:27.460
And yeah.

00:37:27.460 --> 00:37:28.020
Awesome.

00:37:28.020 --> 00:37:28.980
Well, great to meet you.

00:37:28.980 --> 00:37:30.260
Tell us about your company.

00:37:30.260 --> 00:37:30.820
Yeah.

00:37:30.820 --> 00:37:37.980
So PrettyBase tries to solve the problem of the inefficiency in the development process

00:37:37.980 --> 00:37:39.500
of machine learning projects.

00:37:39.500 --> 00:37:45.400
Usually they take anywhere from six months to a year or even more, depending on the organization's,

00:37:45.400 --> 00:37:49.680
you know, their degree of expertise in developing machine learning projects.

00:37:49.680 --> 00:37:56.720
And so with using our platform, companies can get down to like from months to days of development.

00:37:56.720 --> 00:37:58.920
And that makes them substantially faster.

00:37:58.920 --> 00:38:01.620
Each machine learning project becomes cheaper.

00:38:01.620 --> 00:38:06.100
And organizations and teams can do many more machine learning projects.

00:38:06.100 --> 00:38:06.480
Yeah.

00:38:06.480 --> 00:38:09.760
I mean, training is where the time and the money is spent.

00:38:09.760 --> 00:38:10.280
Yeah.

00:38:10.280 --> 00:38:11.300
At least computationally.

00:38:11.360 --> 00:38:12.860
I mean, paying developers is expensive too.

00:38:12.860 --> 00:38:13.040
Right.

00:38:13.040 --> 00:38:17.960
But in terms of people say machine learning or AI, it takes all this energy.

00:38:17.960 --> 00:38:22.000
And it does take energy to answer questions, but it really takes energy to train the models,

00:38:22.000 --> 00:38:22.300
right?

00:38:22.300 --> 00:38:22.800
Yeah.

00:38:22.800 --> 00:38:23.000
Yeah.

00:38:23.000 --> 00:38:23.360
Definitely.

00:38:23.360 --> 00:38:25.620
There's training models is a huge part.

00:38:25.620 --> 00:38:30.400
Managing the data and putting it in a shape and form that is useful for training the models.

00:38:30.500 --> 00:38:37.100
There's also another big piece of the reason why these teams take so long to develop models.

00:38:37.100 --> 00:38:42.900
And also, usually there's several people involved in the process.

00:38:42.900 --> 00:38:44.360
There are different stakeholders.

00:38:44.360 --> 00:38:46.700
Some of them are more machine learning oriented.

00:38:46.700 --> 00:38:47.920
Some of them are more engineers.

00:38:47.920 --> 00:38:52.640
Some of them may be analysts or product developers that need to use the models downstream.

00:38:52.640 --> 00:39:00.760
And so, the handoff of the artifacts and of the whole process between these different people

00:39:00.760 --> 00:39:03.220
is also source of a lot of friction.

00:39:03.220 --> 00:39:06.740
And with the platform that we are building, we are trying also to reduce the friction as

00:39:06.740 --> 00:39:07.340
much as possible.

00:39:07.340 --> 00:39:07.800
Yeah.

00:39:07.800 --> 00:39:08.420
Sounds great.

00:39:08.420 --> 00:39:14.980
Is it about managing that workflow or is it about things like transfer learning and other

00:39:14.980 --> 00:39:17.820
more theoretical ideas?

00:39:17.820 --> 00:39:20.140
Like where exactly are you doing this?

00:39:20.140 --> 00:39:25.540
So, to give you a little bit more of a picture, I would say where we are starting from is from

00:39:25.540 --> 00:39:27.040
Ludwig, which is his open source project.

00:39:27.040 --> 00:39:32.640
And what Ludwig allows people to do, it allows to define machine learning models and pipelines

00:39:32.640 --> 00:39:35.360
in terms of a configuration file.

00:39:35.360 --> 00:39:39.220
So, you don't need to write the low-level PyTorch or TensorFlow code.

00:39:39.220 --> 00:39:43.420
You can just write a configuration that maps with the schema of your data.

00:39:43.420 --> 00:39:43.920
Okay.

00:39:43.920 --> 00:39:46.440
And that's literally all you need to get started.

00:39:46.440 --> 00:39:50.000
So, it makes it substantially easier and faster to get started training models.

00:39:50.000 --> 00:39:54.760
Then, if you are more experienced, you can go down and change more than 700 parameters

00:39:54.760 --> 00:40:01.040
that are there and change all the details of training, of the models themselves, the pre-processing,

00:40:01.040 --> 00:40:02.860
so you have full flexibility and control.

00:40:02.860 --> 00:40:09.120
And you can also go all the way down to the Python code, add your own classes, register them

00:40:09.120 --> 00:40:11.980
from the decorator, and they become available in the configuration.

00:40:11.980 --> 00:40:12.760
Very cool.

00:40:12.780 --> 00:40:14.120
This is what we have in the open source.

00:40:14.120 --> 00:40:14.640
Right, right.

00:40:14.640 --> 00:40:17.540
And what we're building on top of it is all the...

00:40:17.540 --> 00:40:22.340
Again, you can think about this for people who may be familiar with Terraform, for instance.

00:40:22.340 --> 00:40:26.880
What Terraform does for infrastructure, so they're finding your infrastructure through a configuration

00:40:26.880 --> 00:40:27.360
file.

00:40:27.360 --> 00:40:29.280
Ludwig does it for machine learning.

00:40:29.280 --> 00:40:29.920
Got it.

00:40:29.920 --> 00:40:30.360
That's a good analogy.

00:40:30.360 --> 00:40:30.520
Okay.

00:40:30.520 --> 00:40:36.440
And so, PratyBase, what does it, it uses this basic concept of models as configuration,

00:40:36.440 --> 00:40:41.400
really, and builds on top of it all sorts of infrastructure that is needed for organizations

00:40:41.400 --> 00:40:44.140
that are big enterprises to use it in the cloud.

00:40:44.140 --> 00:40:44.760
Okay.

00:40:44.760 --> 00:40:48.520
So, we have, like, we can deploy on cloud environments.

00:40:48.520 --> 00:40:53.320
We abstract away the infrastructure aspect of it, so you can run the training of your models

00:40:53.320 --> 00:40:59.500
and inference on either one small CPU machines or a thousand large GPU machines, and you don't

00:40:59.500 --> 00:41:00.400
need to think about it, basically.

00:41:00.400 --> 00:41:00.760
Oh, cool.

00:41:00.760 --> 00:41:05.480
So, I just say train it, and if you happen to have GPUs available, you might use them.

00:41:05.480 --> 00:41:06.320
Right, absolutely.

00:41:06.320 --> 00:41:06.720
Okay.

00:41:06.720 --> 00:41:07.360
Excellent.

00:41:07.360 --> 00:41:11.440
So, where does PratyBase fit into this?

00:41:11.440 --> 00:41:14.060
Like, where's the business side of this product?

00:41:14.060 --> 00:41:14.880
Right, right.

00:41:14.880 --> 00:41:20.600
I would say PratyBase makes it easy for teams, really, to develop machine learning products,

00:41:20.600 --> 00:41:20.760
right?

00:41:20.760 --> 00:41:23.240
As if, Ludwig, you can define your own configuration.

00:41:23.240 --> 00:41:26.840
But it's like, you know, a single user experience, if you want, right?

00:41:26.840 --> 00:41:32.060
PratyBase becomes like a multi-user experience, where, again, you deploy on the cloud, and you

00:41:32.060 --> 00:41:33.660
can connect with data sources.

00:41:33.660 --> 00:41:37.060
In Ludwig, you provide, like, a CSV file or a data frame, a Pandas data frame.

00:41:37.060 --> 00:41:43.240
With PratyBase, you can, like, connect to Snowflake, to Databricks, to MySQL databases,

00:41:43.240 --> 00:41:45.380
to S3 buckets, and do all of those things.

00:41:45.380 --> 00:41:50.780
And also, there's a notion of model repositories, because when you start to train a model, the first

00:41:50.780 --> 00:41:52.200
one is never the last one that you train.

00:41:52.200 --> 00:41:55.120
And so, and an analogy to Git, really.

00:41:55.120 --> 00:41:59.080
In Git, you have commits, and you have teams doing different commits and collaborating together.

00:41:59.080 --> 00:42:03.960
In our platform, you have multiple models that are configurations, and multiple people

00:42:03.960 --> 00:42:06.240
training new different models, spawning from the previous ones.

00:42:06.240 --> 00:42:09.520
So there's all a lineage of models that can be compared among each other.

00:42:09.520 --> 00:42:09.940
Yeah.

00:42:09.940 --> 00:42:14.340
And then the very last piece is that we make it easy to deploy these models with one click of a button.

00:42:14.340 --> 00:42:18.300
So you go from the data to the deployed model very, very quickly.

00:42:18.300 --> 00:42:18.940
Fantastic.

00:42:18.940 --> 00:42:19.640
It sounds great.

00:42:19.640 --> 00:42:20.800
So final question.

00:42:20.800 --> 00:42:25.280
A lot of people out there working in open source, they'd love to be here on Startup Row,

00:42:25.280 --> 00:42:28.060
talking about their startup based on their project.

00:42:28.060 --> 00:42:32.400
It sounds like what you built is based on the open core model, which seems to be really,

00:42:32.400 --> 00:42:33.820
really successful these days.

00:42:33.820 --> 00:42:36.100
You know, tell us a bit about how you got here.

00:42:36.420 --> 00:42:36.700
Right.

00:42:36.700 --> 00:42:39.900
So basically, I think it started from the open source, really.

00:42:39.900 --> 00:42:44.380
I started developing Ludwig when I was working at Uber.

00:42:44.380 --> 00:42:50.140
And initially, it was like my own project was a way for myself for being more efficient and

00:42:50.140 --> 00:42:54.060
working on the next machine learning project without reinventing the wheel every single time.

00:42:54.640 --> 00:42:59.820
And I built that because I'm lazy and I don't want like when I do one thing more than twice,

00:42:59.820 --> 00:43:01.260
then I automate it for myself, really.

00:43:01.260 --> 00:43:03.900
Productive laziness or something like this.

00:43:04.600 --> 00:43:07.640
And so then other people in the company started using it.

00:43:07.640 --> 00:43:12.200
And that convinced me that making it open source, also because it was built on top of other open

00:43:12.200 --> 00:43:16.180
source projects, would have been a great way to both have people contribute to it and improve

00:43:16.180 --> 00:43:17.860
it and also give back to the community.

00:43:17.860 --> 00:43:21.780
Because again, I was using myself a lot of open source projects to build it.

00:43:21.780 --> 00:43:22.020
Right.

00:43:22.320 --> 00:43:27.740
And then from there, I made it so that we donated the project to the Linux Foundation.

00:43:27.740 --> 00:43:29.340
So now it's backed by the Linux Foundation.

00:43:29.340 --> 00:43:33.720
And also the governance is open as opposed to what it was before when I was at Uber.

00:43:33.720 --> 00:43:38.700
And from there, actually, you know, I met a bunch of people, some of my co-founders at

00:43:38.700 --> 00:43:40.380
the company, thanks to the project.

00:43:40.380 --> 00:43:44.940
And we decided that, so for instance, one of them is Professor Chris from Stanford.

00:43:44.940 --> 00:43:48.720
He was developing a similar system that was closed internally at Apple.

00:43:48.720 --> 00:43:52.300
And so we said, this thing worked at Uber, worked at Apple, works in the open source,

00:43:52.300 --> 00:43:52.820
open source.

00:43:52.820 --> 00:43:54.320
Let's make a company out of this.

00:43:54.320 --> 00:43:54.580
Right.

00:43:54.580 --> 00:43:55.260
Fantastic.

00:43:55.260 --> 00:43:55.660
Yeah.

00:43:55.660 --> 00:43:57.900
Solving some problems for these big teams.

00:43:57.900 --> 00:43:58.180
Right.

00:43:58.180 --> 00:43:58.840
Excellent.

00:43:58.840 --> 00:44:01.060
Well, best of luck on your company.

00:44:01.060 --> 00:44:01.860
Thank you very much, Mike.

00:44:01.860 --> 00:44:02.120
Yeah.

00:44:02.120 --> 00:44:02.740
Thanks for being here.

00:44:02.740 --> 00:44:03.180
Yeah.

00:44:03.180 --> 00:44:03.640
Absolutely.

00:44:03.640 --> 00:44:04.020
A pleasure.

00:44:04.020 --> 00:44:04.740
Thank you so much.

00:44:04.740 --> 00:44:08.640
We'll finish up our stroll down startup lane by talking with the folks at Pinecone.

00:44:08.640 --> 00:44:14.300
We have Nikhil Rao to talk about the pure Python full stack web app platform that they've

00:44:14.300 --> 00:44:14.640
built.

00:44:14.640 --> 00:44:16.000
Nikhil, welcome to Talk Python.

00:44:16.000 --> 00:44:16.500
Yeah.

00:44:16.500 --> 00:44:17.120
Great to be here.

00:44:17.120 --> 00:44:17.800
Thanks for having me.

00:44:17.800 --> 00:44:18.840
It's great to have you here.

00:44:19.220 --> 00:44:24.660
I love going through all the different projects on startup row and talking about them and

00:44:24.660 --> 00:44:25.600
shedding a little light on them.

00:44:25.600 --> 00:44:26.620
So happy to have you here.

00:44:26.620 --> 00:44:27.180
Yeah.

00:44:27.180 --> 00:44:27.480
Yeah.

00:44:27.480 --> 00:44:28.900
Give a quick introduction on yourself.

00:44:28.900 --> 00:44:29.260
Yeah.

00:44:29.260 --> 00:44:29.980
So I'm Nikhil.

00:44:29.980 --> 00:44:32.000
I'm the CEO, co-founder of Pinecone.

00:44:32.000 --> 00:44:34.900
And we're building a way to make web apps in pure Python.

00:44:35.140 --> 00:44:39.880
So we have an open source framework and anyone can install this and basically start creating

00:44:39.880 --> 00:44:42.140
their apps front end and back end using Python.

00:44:42.140 --> 00:44:47.340
Our company went through the recent Y Combinator batch, just ended the winter 23 batch.

00:44:47.340 --> 00:44:51.580
And recently we raised our seed ran and starting to hire out and pretty much grow out our project

00:44:51.580 --> 00:44:52.380
and company from here.

00:44:52.380 --> 00:44:52.940
Okay.

00:44:52.940 --> 00:44:53.660
Well, awesome.

00:44:53.660 --> 00:44:54.320
Congratulations.

00:44:54.320 --> 00:44:55.560
That sounds really cool.

00:44:55.560 --> 00:44:59.400
Give us an idea of, I guess, you know, why do you build this, right?

00:44:59.400 --> 00:45:00.200
We've got Flask.

00:45:00.200 --> 00:45:00.860
We've got Django.

00:45:00.860 --> 00:45:01.300
Yeah.

00:45:01.300 --> 00:45:03.200
I mean, heck, we even have Ruby if you really want it.

00:45:03.400 --> 00:45:03.640
Yeah.

00:45:03.640 --> 00:45:04.720
There's a lot.

00:45:04.720 --> 00:45:08.400
So previous to this, like you mentioned, there's frameworks like Flask and Django.

00:45:08.400 --> 00:45:12.180
And whenever you wanted to, a Python developer wanted to make a web app, they use something

00:45:12.180 --> 00:45:14.580
like this, but you always have to pair it with another front end library.

00:45:14.580 --> 00:45:16.960
So you can't just make your front end using Python.

00:45:16.960 --> 00:45:20.520
You still have to end up using JavaScript, HTML, React, stuff like that for your front end.

00:45:20.520 --> 00:45:24.800
And so a lot of people, if you're coming from a Python background, it's a lot of work

00:45:24.800 --> 00:45:26.020
to kind of get started with these.

00:45:26.020 --> 00:45:27.620
It's a different language, different tool set.

00:45:27.620 --> 00:45:31.260
So we really wanted something where Python developers can just use these tools they already know

00:45:31.260 --> 00:45:35.040
and be able to make these web apps without having to go learn something completely different.

00:45:35.040 --> 00:45:39.140
So as opposed to these tools like Flask and Django, we're very focused on unifying the front

00:45:39.140 --> 00:45:40.660
end and back end into one framework.

00:45:40.660 --> 00:45:42.760
So you don't need a separate front end and back end.

00:45:42.760 --> 00:45:47.020
And that allows us to kind of, the user can just focus on the logic of their app and not

00:45:47.020 --> 00:45:49.580
kind of these technical details on the networking and all this other stuff.

00:45:49.580 --> 00:45:50.000
Yeah.

00:45:50.000 --> 00:45:50.820
It sounds interesting.

00:45:50.820 --> 00:45:54.700
I mean, I know many Python people who don't want to do JavaScript.

00:45:54.700 --> 00:45:55.100
Yeah.

00:45:55.100 --> 00:45:57.280
They don't want to do multiple languages.

00:45:57.280 --> 00:46:02.340
But, you know, it's traditionally, at least in the web framework world, you're speaking

00:46:02.340 --> 00:46:03.740
many, many languages.

00:46:03.740 --> 00:46:08.340
You're speaking HTML, CSS, JavaScript is a big one.

00:46:08.340 --> 00:46:13.560
And honestly, I think that there was a period where people were super invested in JavaScript

00:46:13.560 --> 00:46:17.260
and thought that was kind of the right way or the necessary way.

00:46:17.260 --> 00:46:21.420
And that would take away a lot of what's important about the web framework, right?

00:46:21.420 --> 00:46:25.540
Like, well, it doesn't matter if it's Flask or Django, we're just going to return JSON

00:46:25.540 --> 00:46:26.840
anyway because it's all Angular.

00:46:26.840 --> 00:46:27.700
So who cares, right?

00:46:27.700 --> 00:46:27.880
Yeah.

00:46:27.880 --> 00:46:31.860
But I don't think that's where people really, most, many people, at least the people choosing

00:46:31.860 --> 00:46:33.040
Python want to be.

00:46:33.040 --> 00:46:35.360
And so, yeah, how is your stuff different?

00:46:35.360 --> 00:46:39.640
So I think exactly what you said before this, to make a serious web app, you always have to

00:46:39.640 --> 00:46:40.220
go to JavaScript.

00:46:40.220 --> 00:46:44.140
And what we're really trying to do is make everything in Python, including your front end.

00:46:44.140 --> 00:46:47.740
And so basically, yeah, we're trying to integrate the two together.

00:46:47.740 --> 00:46:52.480
So basically, you don't have to go learn these technical details you didn't want before.

00:46:52.480 --> 00:46:55.640
We realized for all the logic of your app, you're using Python anyway.

00:46:55.640 --> 00:47:00.040
Like Python's used in so many industries, databases, ML, AI, infrastructure.

00:47:00.040 --> 00:47:04.320
And when these people want to make a front end, it is possible to make JavaScript or these

00:47:04.320 --> 00:47:05.000
JavaScript front ends.

00:47:05.000 --> 00:47:06.820
But that's a lot of overhead.

00:47:06.820 --> 00:47:11.080
And before our kind of our framework, there are different low code tools to make front

00:47:11.080 --> 00:47:11.740
ends without JavaScript.

00:47:11.740 --> 00:47:13.200
But they all kind of have a limit.

00:47:13.380 --> 00:47:15.920
And they all have a graduation risk is what we found.

00:47:15.920 --> 00:47:17.640
So you can start making your UI.

00:47:17.640 --> 00:47:19.660
Can you make any website with them?

00:47:19.660 --> 00:47:20.040
Right.

00:47:20.040 --> 00:47:24.460
Like Streamlit and Anvil are both notable ones that kind of come to mind.

00:47:24.460 --> 00:47:28.400
But neither of them, I like them both a lot, but neither of them are necessarily like, I'm

00:47:28.400 --> 00:47:31.080
just going to build a general purpose web app.

00:47:31.080 --> 00:47:33.760
They're focused in their particular area.

00:47:33.760 --> 00:47:34.420
Yes, exactly.

00:47:34.420 --> 00:47:36.980
So I've used tools like Streamlit, Gradio in the past.

00:47:36.980 --> 00:47:38.940
And a lot of that was inspiration for Pinecone.

00:47:38.940 --> 00:47:41.520
It's really great because it's super easy to get started with.

00:47:41.560 --> 00:47:44.180
You don't have to go learn these things, but they all have this kind of ceiling you

00:47:44.180 --> 00:47:44.380
hit.

00:47:44.380 --> 00:47:48.040
So they're mostly good for like data science apps, dashboard apps.

00:47:48.040 --> 00:47:51.720
But as you try to expand your app into like a full stack web app, start adding these new

00:47:51.720 --> 00:47:55.080
features, a lot of times you find these frameworks don't really scale with your ideas.

00:47:55.080 --> 00:47:59.060
And your two options are either you have to kind of constrain your idea into what these

00:47:59.060 --> 00:48:02.220
vendors offer you, or you use that for prototyping.

00:48:02.220 --> 00:48:06.660
And when you're making a customer facing production app, you scrap it and go to like a JavaScript

00:48:06.660 --> 00:48:07.420
React world.

00:48:07.600 --> 00:48:11.280
So what we're really trying to do is make something like these Anvil or Streamlit easy

00:48:11.280 --> 00:48:12.900
to get started with for Python developers.

00:48:12.900 --> 00:48:16.460
But as you want to expand to these complex cases, you should be able to stay in our framework

00:48:16.460 --> 00:48:18.040
and we should be able to handle that also.

00:48:18.040 --> 00:48:18.520
Interesting.

00:48:18.520 --> 00:48:21.600
So how does the front end interactivity work if it's Python?

00:48:21.600 --> 00:48:22.040
Yeah.

00:48:22.040 --> 00:48:23.640
And this is also where I think we're a bit different.

00:48:23.640 --> 00:48:27.200
We're trying to really leverage a lot of the web dev ecosystem and not recreate everything

00:48:27.200 --> 00:48:27.780
from scratch.

00:48:28.000 --> 00:48:30.440
So for the front end, we leverage React and Next.js.

00:48:30.440 --> 00:48:32.700
So our front end compiles down to a Next.js app.

00:48:32.700 --> 00:48:33.680
And from this...

00:48:33.680 --> 00:48:35.080
Oh, you're transpiling the Python?

00:48:35.080 --> 00:48:36.800
We transpile the Python to Next.js.

00:48:36.800 --> 00:48:38.540
And this gives you a lot of great features.

00:48:38.540 --> 00:48:41.960
You get single page app features from Next.js, a lot of these performance features.

00:48:41.960 --> 00:48:45.220
And that means from our perspective, we don't have to recreate all this stuff.

00:48:45.220 --> 00:48:48.000
And also, we don't have to create components one by one.

00:48:48.000 --> 00:48:49.300
We just leverage React.

00:48:49.440 --> 00:48:53.520
And for what we do in Pinecode for the front end is we just wrap React components and make

00:48:53.520 --> 00:48:53.980
them accessible.

00:48:53.980 --> 00:48:58.840
So even if we don't offer something, and other local tools, sometimes if they don't offer a

00:48:58.840 --> 00:49:01.840
component you need, you may be kind of constrained in what you can build.

00:49:01.840 --> 00:49:05.740
We easily have a way for anyone to wrap their own third-party React libraries.

00:49:05.740 --> 00:49:09.660
So we're really trying to make the existing stuff out there accessible rather than recreating

00:49:09.660 --> 00:49:09.900
it.

00:49:09.900 --> 00:49:10.340
Yeah.

00:49:10.340 --> 00:49:13.220
So you can sort of extend it with React if you get boxed in.

00:49:13.220 --> 00:49:13.980
That's your escape hatch.

00:49:13.980 --> 00:49:14.380
Exactly.

00:49:14.380 --> 00:49:15.120
Okay.

00:49:15.120 --> 00:49:17.100
So that's kind of how our front end works.

00:49:17.100 --> 00:49:20.040
And for the back end, we use FastAPI to handle all the states.

00:49:20.040 --> 00:49:22.540
So the user state is all on the back end on the server.

00:49:22.540 --> 00:49:25.700
And this is what allows us to pretty much keep everything in Python.

00:49:25.700 --> 00:49:28.740
So none of the logic is transpiled to JavaScript, only the React.

00:49:28.740 --> 00:49:30.440
And all the logic stays in Python.

00:49:30.440 --> 00:49:33.540
So you can use any of your existing Python libraries, any existing tools.

00:49:33.540 --> 00:49:36.200
You don't have to wait for us to kind of make these integrations.

00:49:36.200 --> 00:49:40.360
So it's kind of leveraging React, but also leveraging Python and kind of bringing them together.

00:49:40.360 --> 00:49:41.780
What's the deployment look like?

00:49:41.780 --> 00:49:43.760
So we're working on an easy deployment.

00:49:43.760 --> 00:49:45.200
So you can just type PC deploy.

00:49:45.360 --> 00:49:48.900
We'll set up all your infrastructure and you'll get a URL back with your app live.

00:49:48.900 --> 00:49:50.540
But also we're an open source framework.

00:49:50.540 --> 00:49:52.880
So it's also very easy to self-host and self-deploy.

00:49:52.880 --> 00:49:57.460
And so what we're really trying to do is make it accessible and easy, but never kind of lock

00:49:57.460 --> 00:49:58.200
you into our framework.

00:49:58.200 --> 00:49:58.760
I see.

00:49:58.760 --> 00:50:01.080
So I could put like Nginx in front of it or something.

00:50:01.080 --> 00:50:01.420
Exactly.

00:50:01.420 --> 00:50:03.900
Like, so right now we're still working on our hosting deployment.

00:50:03.900 --> 00:50:07.920
So everyone right now who's deployed is hosting on AWS DigitalOcean or a tool like this

00:50:07.920 --> 00:50:08.760
with Nginx.

00:50:08.820 --> 00:50:08.880
Yeah.

00:50:08.880 --> 00:50:11.460
So it integrates just like you would deploy a Flask or React app.

00:50:11.460 --> 00:50:11.860
Got it.

00:50:11.860 --> 00:50:14.780
But we're really trying to make an optimized hosting service around this later.

00:50:14.780 --> 00:50:15.640
Yeah, sure.

00:50:15.640 --> 00:50:16.140
It makes sense.

00:50:16.140 --> 00:50:16.520
All right.

00:50:16.520 --> 00:50:17.780
Sounds like a great product.

00:50:17.780 --> 00:50:18.600
Thanks, sir.

00:50:18.600 --> 00:50:20.060
Final question here.

00:50:20.060 --> 00:50:21.240
You know, how'd you get here?

00:50:21.240 --> 00:50:22.320
How'd you start the company?

00:50:22.320 --> 00:50:24.180
How'd you land on Startup Row?

00:50:24.180 --> 00:50:25.780
I mean, you talked about Y Combinator a little.

00:50:25.780 --> 00:50:26.160
Yeah.

00:50:26.240 --> 00:50:27.340
So I talked a little bit.

00:50:27.340 --> 00:50:28.760
We did the Y Combinator batch.

00:50:28.760 --> 00:50:33.200
And really the idea is not only having an open source framework, but having like a business

00:50:33.200 --> 00:50:36.140
model around it and being able to create like these features around it.

00:50:36.140 --> 00:50:41.100
So we're really focused on kind of being similar to have an open source framework, similar to

00:50:41.100 --> 00:50:44.800
like how Vercel has Next.js and their hosted version and kind of bringing that to the Python

00:50:44.800 --> 00:50:45.240
community.

00:50:45.240 --> 00:50:47.840
So Python is like one of the fastest growing languages.

00:50:47.840 --> 00:50:49.720
Obviously, like that's why Python is so big.

00:50:49.720 --> 00:50:53.600
And for the web dev part, there's not really a good ecosystem for that.

00:50:53.600 --> 00:50:56.760
So when people want to share their ideas, we're really trying to become that de facto

00:50:56.760 --> 00:50:59.060
way for Python developers to create their apps and share.

00:50:59.060 --> 00:51:03.580
And so, yeah, basically working on our hosting service, growing out our team now and trying

00:51:03.580 --> 00:51:07.300
to build up all this like ecosystem around it so people can easily get their ideas out

00:51:07.300 --> 00:51:07.700
to the world.

00:51:07.700 --> 00:51:08.320
Awesome.

00:51:08.320 --> 00:51:10.560
Well, congratulations and thanks for being here.

00:51:10.560 --> 00:51:13.960
This has been another episode of Talk Python To Me.

00:51:13.960 --> 00:51:15.780
Thank you to our sponsors.

00:51:15.780 --> 00:51:17.380
Be sure to check out what they're offering.

00:51:17.380 --> 00:51:18.820
It really helps support the show.

00:51:18.820 --> 00:51:21.460
Take some stress out of your life.

00:51:21.460 --> 00:51:26.940
Get notified immediately about errors and performance issues in your web or mobile applications with

00:51:26.940 --> 00:51:27.240
Sentry.

00:51:27.240 --> 00:51:32.240
Just visit talkpython.fm/sentry and get started for free.

00:51:32.240 --> 00:51:35.840
And be sure to use the promo code talkpython, all one word.

00:51:35.840 --> 00:51:37.620
Want to level up your Python?

00:51:37.620 --> 00:51:41.680
We have one of the largest catalogs of Python video courses over at Talk Python.

00:51:41.680 --> 00:51:46.840
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:51:46.840 --> 00:51:49.520
And best of all, there's not a subscription in sight.

00:51:49.520 --> 00:51:52.420
Check it out for yourself at training.talkpython.fm.

00:51:52.420 --> 00:51:54.320
Be sure to subscribe to the show.

00:51:54.320 --> 00:51:57.100
Open your favorite podcast app and search for Python.

00:51:57.100 --> 00:51:58.420
We should be right at the top.

00:51:58.420 --> 00:52:03.560
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:52:03.560 --> 00:52:07.760
and the direct RSS feed at /rss on talkpython.fm.

00:52:07.760 --> 00:52:11.200
We're live streaming most of our recordings these days.

00:52:11.200 --> 00:52:14.620
If you want to be part of the show and have your comments featured on the air,

00:52:14.620 --> 00:52:19.040
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

00:52:19.040 --> 00:52:20.880
This is your host, Michael Kennedy.

00:52:20.880 --> 00:52:22.180
Thanks so much for listening.

00:52:22.180 --> 00:52:23.360
I really appreciate it.

00:52:23.360 --> 00:52:25.260
Now get out there and write some Python code.

00:52:25.260 --> 00:52:46.060
I'll see you next time.

