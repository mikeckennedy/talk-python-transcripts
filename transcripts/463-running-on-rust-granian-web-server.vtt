WEBVTT

00:00:00.001 --> 00:00:04.440
So you've created a web app using Flask, Django, FastiAPI, or even Emmet.

00:00:04.440 --> 00:00:06.320
It works great on your machine.

00:00:06.320 --> 00:00:08.040
How do you get it out to the world?

00:00:08.040 --> 00:00:10.360
Well, you'll need a production-ready web server, of course.

00:00:10.360 --> 00:00:13.060
On this episode, we have Giovanni Barriari

00:00:13.060 --> 00:00:17.140
to tell us about his relatively new server named Greenian.

00:00:17.140 --> 00:00:21.020
It promises better performance and much better consistency

00:00:21.020 --> 00:00:23.460
than many of the more well-known ones today.

00:00:23.460 --> 00:00:26.700
This is Talk Python to Me, episode 463.

00:00:26.700 --> 00:00:29.660
Are you ready for your host, here he is!

00:00:29.880 --> 00:00:33.080
You're listening to Michael Kennedy on Talk Python to Me.

00:00:33.080 --> 00:00:36.860
Live from Portland, Oregon, and this segment was made with Python.

00:00:36.860 --> 00:00:43.520
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:43.520 --> 00:00:45.260
This is your host, Michael Kennedy.

00:00:45.260 --> 00:00:47.920
Follow me on Mastodon, where I'm @mkennedy,

00:00:47.920 --> 00:00:52.740
and follow the podcast using @talkpython, both on fosstodon.org.

00:00:52.740 --> 00:00:57.840
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:58.200 --> 00:01:01.620
We've started streaming most of our episodes live on YouTube.

00:01:01.620 --> 00:01:05.400
Subscribe to our YouTube channel over at talkpython.fm/youtube

00:01:05.400 --> 00:01:09.180
to get notified about upcoming shows and be part of that episode.

00:01:09.720 --> 00:01:11.980
This episode is sponsored by Neo4j.

00:01:11.980 --> 00:01:16.820
It's time to stop asking relational databases to do more than they were made for

00:01:16.820 --> 00:01:20.080
and simplify complex data models with graphs.

00:01:20.080 --> 00:01:26.920
Check out the sample FastAPI project and see what Neo4j, a native graph database, can do for you.

00:01:26.920 --> 00:01:31.340
Find out more at talkpython.fm/Neo4j.

00:01:31.920 --> 00:01:35.800
And it's also brought to you by us over at Talk Python Training.

00:01:35.800 --> 00:01:40.420
Did you know that we have over 250 hours of Python courses?

00:01:40.420 --> 00:01:41.600
Yeah, that's right.

00:01:41.600 --> 00:01:44.160
Check them out at talkpython.fm/courses.

00:01:44.160 --> 00:01:48.580
In fact, I want to tell you about our latest course we just released last week,

00:01:48.580 --> 00:01:51.340
Getting Started with NLP and Spacey.

00:01:51.340 --> 00:01:53.120
This one is written by Vincent Warmerdom.

00:01:53.120 --> 00:01:57.560
You may know him from many of his educational projects and channels,

00:01:57.560 --> 00:02:01.660
but he also worked at Explosion AI, the makers of Spacey.

00:02:01.660 --> 00:02:05.900
So it's safe to say he knows his stuff when it comes to NLP and Spacey.

00:02:05.900 --> 00:02:12.460
If you have text you need to analyze, pull entities from, understand the sentiment, and so much more,

00:02:12.460 --> 00:02:15.260
then Spacey is one of the best frameworks out there for this.

00:02:15.260 --> 00:02:20.000
And now we have an awesome course you can use to get way better at NLP.

00:02:20.000 --> 00:02:23.020
During the course, you need a fun project, right?

00:02:23.100 --> 00:02:26.800
Well, Vincent uses the past nine years of Talk Python transcripts,

00:02:26.800 --> 00:02:29.780
along with a few data science programming bits of magic,

00:02:29.780 --> 00:02:34.660
to process them all with Spacey and ask awesome questions like,

00:02:34.660 --> 00:02:37.500
which frameworks are we talking about over the years?

00:02:37.500 --> 00:02:40.960
Sign up for the course at talkpython.fm/Spacey.

00:02:40.960 --> 00:02:44.040
And if you hurry and get it in the month of May, 2024,

00:02:44.040 --> 00:02:47.940
we're doing a special 10% off to celebrate the launch.

00:02:47.940 --> 00:02:50.360
That's talkpython.fm/Spacey.

00:02:50.360 --> 00:02:52.480
The link is in your podcast player show notes.

00:02:52.760 --> 00:02:53.560
Enjoy the course.

00:02:53.560 --> 00:02:55.040
Now, on to that interview.

00:02:55.040 --> 00:02:57.960
Giovanni, welcome to Talk Python to Me.

00:02:57.960 --> 00:02:58.940
Hello, Michael.

00:02:58.940 --> 00:03:00.900
Thank you for having me on the show.

00:03:00.900 --> 00:03:02.060
It's great to have you on the show.

00:03:02.060 --> 00:03:07.300
Some people you learn about just from like their public speaking or their writing,

00:03:07.300 --> 00:03:09.740
and other people you meet through their projects, right?

00:03:09.780 --> 00:03:16.200
I got to know you through Granian, your Rust-based Python and other thing, web server,

00:03:16.200 --> 00:03:17.300
that I thought was really awesome.

00:03:17.300 --> 00:03:20.900
Started playing with it, and we started talking on GitHub around some ideas.

00:03:20.900 --> 00:03:24.540
And then here you are, sort of explore more, learn more about some of your frameworks that

00:03:24.540 --> 00:03:25.600
like you'd created from.

00:03:25.780 --> 00:03:30.000
So I'm excited to talk about Emmett, Granian, and a bunch of other things that you built

00:03:30.000 --> 00:03:32.420
that kind of all go together in a big mix there.

00:03:32.420 --> 00:03:34.020
Yeah, I'm excited as well.

00:03:34.020 --> 00:03:35.020
Yeah, it should be a lot of fun.

00:03:35.020 --> 00:03:39.900
Before we get into all the details of all that stuff, just tell us a bit about yourself.

00:03:40.120 --> 00:03:41.200
I'm Giovanni Bariglari.

00:03:41.200 --> 00:03:47.220
I actually born in Italy, but today I'm living in Vienna, in Austria.

00:03:47.220 --> 00:03:48.980
I'm actually a physicist.

00:03:48.980 --> 00:03:51.720
So yeah, I graduated in physics at the university.

00:03:51.720 --> 00:04:00.480
And let's say I started working as a software engineer, focused especially on web software,

00:04:00.480 --> 00:04:02.120
pretty soon after the university.

00:04:02.120 --> 00:04:04.900
So it's like 10 years, something.

00:04:04.900 --> 00:04:09.940
I'm working as a software engineer, also like as a cypher diabetes engineer.

00:04:10.100 --> 00:04:16.840
So let's just say I'm quite like on the backend side of the things usually.

00:04:16.840 --> 00:04:24.680
And I also started, I actually started like contributing to open source software projects,

00:04:24.680 --> 00:04:29.520
even before actually starting working as a software engineer.

00:04:29.520 --> 00:04:34.000
And particularly I started like contributing to the Web2Py project.

00:04:34.000 --> 00:04:38.120
It's a quite old project by Massimo Di Piero.

00:04:38.500 --> 00:04:42.620
And yeah, today I'm working as a cyber liability engineer for Sentry.

00:04:42.620 --> 00:04:47.760
I bet that pretty much of the people know about Sentry.

00:04:47.760 --> 00:04:48.280
Awesome.

00:04:48.280 --> 00:04:52.940
Yeah, I didn't even know that you worked for Sentry until just a few minutes ago.

00:04:52.940 --> 00:04:53.740
That's pretty awesome.

00:04:53.740 --> 00:04:55.160
Obviously, people know Sentry.

00:04:55.160 --> 00:04:59.640
They're big supporters of the show and sponsor some of the episodes.

00:04:59.900 --> 00:05:02.080
But yeah, how's it like to work at Sentry?

00:05:02.080 --> 00:05:02.980
Must be fun.

00:05:02.980 --> 00:05:04.760
Well, it's super nice.

00:05:04.760 --> 00:05:06.580
A lot of talented people.

00:05:06.580 --> 00:05:08.180
They're super nice.

00:05:08.180 --> 00:05:10.860
It's a really nice environment to be within.

00:05:10.860 --> 00:05:13.380
So yeah, I'm super happy.

00:05:13.380 --> 00:05:13.940
Yeah.

00:05:13.940 --> 00:05:14.440
Awesome.

00:05:14.440 --> 00:05:17.440
What does a software reliability engineer do?

00:05:17.640 --> 00:05:25.820
So let's say it might be a complicated question because like actually the original title comes from Google.

00:05:25.820 --> 00:05:34.840
So let's say it's kind of related to infrastructure and monitoring in software.

00:05:35.100 --> 00:05:45.140
So let's say to simplify that it's about be sure that everything runs smoothly with no incidents and stuff like that.

00:05:45.140 --> 00:05:45.700
I see.

00:05:45.700 --> 00:05:48.460
Make sure you can monitor bugs, slowdowns.

00:05:48.460 --> 00:05:48.920
Yeah.

00:05:49.060 --> 00:05:52.360
work on failover type of situations, that kind of stuff.

00:05:52.360 --> 00:05:52.940
Exactly.

00:05:52.940 --> 00:05:57.540
I imagine you probably use Sentry to monitor Sentry for reliability.

00:05:57.540 --> 00:05:59.220
Is that right?

00:05:59.220 --> 00:05:59.760
Yes.

00:05:59.760 --> 00:06:00.060
Yes.

00:06:00.060 --> 00:06:04.340
We have this project called like Sentry for Sentry.

00:06:04.340 --> 00:06:04.960
Okay.

00:06:04.960 --> 00:06:12.100
Which is like a separated Sentry instance that monitors the actual SAS instance of Sentry.

00:06:12.100 --> 00:06:16.480
That's pretty interesting because of course, if Sentry went down, you're using it to monitor it.

00:06:16.480 --> 00:06:16.780
Yeah.

00:06:17.020 --> 00:06:19.260
Everyone else uses Sentry to monitor their thing.

00:06:19.260 --> 00:06:22.520
It's not about when their code goes down, it doesn't affect it.

00:06:22.520 --> 00:06:26.280
But when your code goes down, it might actually affect your ability to know that it's down.

00:06:26.280 --> 00:06:27.400
So a separate copy.

00:06:27.400 --> 00:06:27.900
That's wild.

00:06:27.900 --> 00:06:28.400
Okay.

00:06:28.400 --> 00:06:29.400
I hadn't even thought of that.

00:06:29.400 --> 00:06:30.000
Exactly.

00:06:30.000 --> 00:06:31.180
Super cool.

00:06:31.180 --> 00:06:31.600
All right.

00:06:31.600 --> 00:06:36.920
Now, first of all, there's a little bit of love out in the audience for your whole larger project, Emmett.

00:06:36.920 --> 00:06:39.480
So Tushar says, did you say Emmett?

00:06:39.480 --> 00:06:42.060
Emmett is amazing, which is super cool.

00:06:42.060 --> 00:06:45.520
Tools like that encourage him to work on his dev tooling, which is really great.

00:06:45.740 --> 00:06:49.120
Before we get into the details of that, though, why create another web framework?

00:06:49.120 --> 00:06:50.740
I don't mean this in a negative way.

00:06:50.740 --> 00:06:56.820
It's just like there's already, there's Flask and Django, and then we have FastAPI and so on.

00:06:56.820 --> 00:06:58.940
So why not just go, oh, I'm just going to use this one?

00:06:59.100 --> 00:07:01.520
Like what inspired you to go, like, I think I'll make one of them.

00:07:01.520 --> 00:07:11.380
So I think we should go back a bit in time because actually like this year will be like the 10th birthday of like Emmett.

00:07:11.380 --> 00:07:15.260
So let's just say it's like a long time.

00:07:15.260 --> 00:07:16.800
So it's not that new.

00:07:16.800 --> 00:07:17.160
Okay.

00:07:17.160 --> 00:07:18.060
Out there.

00:07:18.940 --> 00:07:19.580
Yeah.

00:07:19.580 --> 00:07:20.280
I see.

00:07:20.280 --> 00:07:20.800
Yeah.

00:07:20.800 --> 00:07:27.000
So originally it was released as, it had like a different name.

00:07:27.000 --> 00:07:32.440
It was called Weppy and I changed the name in 2020, I think.

00:07:32.680 --> 00:07:40.500
like when I moved from synchronous paradigm to the asynchronous one.

00:07:41.240 --> 00:07:57.420
So let's say at the time I designed Weppy, so the original version in 2014, the main thing was about, so in that time, it was like the time of Ruby and Rails being super popular.

00:07:57.420 --> 00:08:03.600
And I originally started working in web development using Ruby and Rails.

00:08:04.140 --> 00:08:13.640
And when comparing, let's say, the amount of, let's say, batteries included in the box of Ruby and Rails to the Python ecosystem.

00:08:13.640 --> 00:08:17.520
So let's say that the major competitor at that point in time was Django.

00:08:17.520 --> 00:08:24.760
But let's say the feeling I got from Django at that time compared to Ruby and Rails was completely different.

00:08:24.760 --> 00:08:33.960
In a sense that I found myself like spending much more time on building stuff compared to Ruby and Rails.

00:08:33.960 --> 00:08:46.060
And this is also what bring me to the Web2Py project, Web2Py community, because it was, in a sense, pretty similar in some of the design decisions with RAR.

00:08:46.060 --> 00:08:56.120
But at the same time, like once you start contributing to a web framework, you have time to like to dig into a lot of the internals and decisions.

00:08:56.120 --> 00:09:04.460
And so Web2Py at that time, so I used Web2Py to build my first, the code behind my first startup, actually.

00:09:04.460 --> 00:09:08.760
And it had quite a lot of scaling issues at that time.

00:09:09.260 --> 00:09:26.660
So let's say at that point in time, I just was looking out for the options and I started like digging into the code internals of Django and also Flask, which I mean, I really loved like the Flask approach of things.

00:09:26.660 --> 00:09:30.780
But at the same time, it was so micro.

00:09:30.780 --> 00:09:31.260
Yeah.

00:09:31.260 --> 00:09:49.300
I mean, like to build an actual project, it required like to have like tons of extensions and other pieces, let's say other libraries to add it to the project that, yeah, I think like I ended up just, you know, saying, okay, let's just rebuild Web2Py the way I wanted.

00:09:49.300 --> 00:09:53.960
And that's eventually how Web2Py came out today.

00:09:53.960 --> 00:09:56.540
Yeah, that's pretty much the story behind it.

00:09:56.760 --> 00:09:56.940
Yeah.

00:09:56.940 --> 00:09:57.540
Okay.

00:09:57.540 --> 00:09:59.360
Yeah, I didn't realize it went that far back.

00:09:59.360 --> 00:10:00.220
How about Granian?

00:10:00.220 --> 00:10:01.100
Is that newer?

00:10:01.100 --> 00:10:08.280
Yeah, Granian is, I think like the first public release is like from one year ago or something.

00:10:08.280 --> 00:10:08.880
Yeah.

00:10:08.880 --> 00:10:14.200
And I, because I learned about Emmet through Granian and like, oh, it's kind of all, probably all the same project.

00:10:14.200 --> 00:10:15.560
I didn't realize the history.

00:10:15.560 --> 00:10:16.540
Why the new name?

00:10:16.540 --> 00:10:17.060
Why Emmet?

00:10:17.060 --> 00:10:23.920
So the thing was that to support, let's say the upgrade between Web2Py and Emmet.

00:10:23.920 --> 00:10:35.320
So since like all the interfaces has to be changed to support like async code, the idea was to provide, let's say, a quick way to do that.

00:10:35.320 --> 00:10:45.860
Meaning that to make it possible for developers to, you know, install like a new version of Web2Py and getting like everything broken because of, you know, the new interfaces.

00:10:45.860 --> 00:10:54.040
So yeah, I just decided to, you know, changing the interface and also changing like the package name in order to say, sure.

00:10:54.040 --> 00:10:54.500
Okay.

00:10:54.500 --> 00:10:57.020
If you want to upgrade, you can upgrade safely.

00:10:57.020 --> 00:11:01.260
Otherwise, it's like a super mega version change.

00:11:01.260 --> 00:11:03.400
Not only you change the version, but you change the name.

00:11:03.400 --> 00:11:04.360
Yeah.

00:11:04.360 --> 00:11:05.120
I see.

00:11:05.120 --> 00:11:05.840
Exactly.

00:11:05.840 --> 00:11:08.360
That's interesting.

00:11:08.800 --> 00:11:09.100
All right.

00:11:09.100 --> 00:11:11.140
Well, let's dive into it.

00:11:11.140 --> 00:11:15.480
So I like the title, Emmet, the Web Framework for Inventors.

00:11:15.480 --> 00:11:20.000
And yeah, maybe give us a sense of like, what are some of the core features of Emmet?

00:11:20.000 --> 00:11:22.160
And what are your goals with building it?

00:11:22.160 --> 00:11:23.280
From an API perspective.

00:11:23.280 --> 00:11:28.980
The idea was to have like all in one, let's say, framework to build web application.

00:11:28.980 --> 00:11:34.420
All in one, let's say, in a sense of, again, when the project actually started.

00:11:34.420 --> 00:11:46.040
So like even 10 years after that, I still usually prefer to develop web projects without reliant too much on front-end frameworks.

00:11:46.040 --> 00:11:50.580
So this is like a big, let's say, preamble to the thing.

00:11:50.580 --> 00:11:56.060
Like this is originally from an era where like front-end web framework did exist.

00:11:56.060 --> 00:12:01.140
Like I think it was just AngularJS and maybe Ember at that time.

00:12:01.140 --> 00:12:01.580
Yeah.

00:12:01.580 --> 00:12:04.360
I mean, you're basically describing my life in 2024.

00:12:04.360 --> 00:12:07.680
So I'm a big fan of the server-side frameworks, you know?

00:12:07.680 --> 00:12:08.320
Yeah.

00:12:08.320 --> 00:12:17.040
Also because like it seems sometimes that we reinvent like a lot of stuff to catch up like the beginning at the end.

00:12:17.040 --> 00:12:26.420
Like, yeah, I saw like all of the theme about, you know, server-side rendering with front-end frameworks and server-side render components and all that kind of stuff.

00:12:26.420 --> 00:12:30.800
So sometimes it just feels, you know, we're getting back to the origin.

00:12:30.800 --> 00:12:32.020
But yeah.

00:12:32.020 --> 00:12:39.440
So the idea behind Emet is to have like all-in-one solution to develop web applications.

00:12:39.440 --> 00:12:43.720
So you have all the standard features you have with the web framework.

00:12:43.720 --> 00:12:48.080
So like routing and middlewares and that kind of stuff.

00:12:48.080 --> 00:12:49.680
You have an ORM.

00:12:49.920 --> 00:12:56.580
You have a templating system plus a few, let's say, tools embedded with Em.

00:12:56.580 --> 00:13:04.900
So for instance, it's very easy to use, I don't know, sessions or to have an authentication system.

00:13:04.900 --> 00:13:07.760
It's all like provided inside the box.

00:13:08.200 --> 00:13:19.340
So yeah, the idea was to have like, let's say, a battery of tools like in one place to do the most common things when you start developing a web application.

00:13:19.340 --> 00:13:20.300
Yeah, very nice.

00:13:20.300 --> 00:13:29.520
So yeah, like you said, it has an ORM built in and it feels, I guess, SQLAlchemy-ish in a sense, but not exactly the same.

00:13:29.520 --> 00:13:33.880
Or Django ORM would be, you know, another way in some ways there.

00:13:33.880 --> 00:13:38.500
Yeah, I think it's more near to SQLAlchemy in that sense.

00:13:38.500 --> 00:13:52.760
You tend to have like an API for using Python objects to build queries rather than, how to say, use like a lot of strings attributes like you usually tend to do in Django.

00:13:52.760 --> 00:13:57.980
Yeah, I mean, it's more close to SQLAlchemy in that sense.

00:13:57.980 --> 00:14:16.400
I think like the major difference with the ORMs out there is that the model class you define are not like, so when you, for example, select records from the database, the single, let's say, rows you select are not instances of the model class.

00:14:16.800 --> 00:14:21.720
So let's say like the model class acts more like management class.

00:14:21.720 --> 00:14:24.020
Like a schema definition sort of thing.

00:14:24.020 --> 00:14:24.720
Yeah.

00:14:24.720 --> 00:14:28.100
I mean, it does like a lot of helpers top of that.

00:14:28.100 --> 00:14:35.100
But yeah, I think like it's definitely the major difference between like the vast majority of ORMs out there for Python.

00:14:35.200 --> 00:14:42.920
When you usually have like the model class, which is also like the class of all the records you select and work on from the database.

00:14:42.920 --> 00:14:43.280
Yeah.

00:14:43.280 --> 00:14:45.440
So what do you get back in this world here?

00:14:45.440 --> 00:14:47.040
What do you get if you do a query?

00:14:47.040 --> 00:14:50.180
Like in your example on the homepage, you have a time traveler.

00:14:50.180 --> 00:14:53.320
So what do you get back when you get a group of them, a set of them?

00:14:53.320 --> 00:14:55.920
So you get like a different class.

00:14:55.920 --> 00:14:58.180
So there's like a separated class.

00:14:58.180 --> 00:15:01.780
Every model has, it's called like row class.

00:15:01.780 --> 00:15:04.640
So it's an instance of that class.

00:15:04.640 --> 00:15:11.000
And this design, it's mostly made for two reasons.

00:15:11.000 --> 00:15:18.280
Like the first one is performance in a sense, meaning that when you select records or operate on records,

00:15:18.280 --> 00:15:28.720
it avoids to, you know, fulfill like all those objects with the actual model class attributes or functions or methods.

00:15:28.720 --> 00:15:31.080
And the validation and stuff.

00:15:31.080 --> 00:15:31.300
Yeah.

00:15:31.300 --> 00:15:31.740
Yeah.

00:15:31.740 --> 00:15:43.160
And on the other end was also to kind of remind to the developer that he is working with actual data from the database

00:15:43.160 --> 00:15:46.880
and not like real Python objects in a sense, which is.

00:15:46.880 --> 00:15:47.420
Yeah.

00:15:47.420 --> 00:15:48.020
Yeah.

00:15:48.020 --> 00:15:55.520
I think like in the years is like the first reason why people tend to object against ORMs.

00:15:55.520 --> 00:15:56.280
So.

00:15:56.280 --> 00:15:56.820
Yeah.

00:15:56.820 --> 00:15:59.940
Those two were the main reasons behind this design.

00:15:59.940 --> 00:16:06.220
It's something like, you know, in the between of an ORM and just some database abstraction layer.

00:16:06.220 --> 00:16:11.580
This portion of Talk Python to Me is brought to you by Neo4j.

00:16:12.080 --> 00:16:13.560
Do you know Neo4j?

00:16:13.560 --> 00:16:16.320
Neo4j is a native graph database.

00:16:16.320 --> 00:16:21.180
And if the slowest part of your data access patterns involves computing relationships,

00:16:21.180 --> 00:16:26.360
why not use a database that stores those relationships directly in the database,

00:16:26.360 --> 00:16:28.420
unlike your typical relational one?

00:16:28.420 --> 00:16:32.280
A graph database lets you model the data the way it looks in the real world,

00:16:32.280 --> 00:16:35.100
instead of forcing it into rows and columns.

00:16:35.100 --> 00:16:39.820
It's time to stop asking a relational database to do more than they were made for

00:16:39.820 --> 00:16:42.740
and simplify complex data models with graphs.

00:16:42.740 --> 00:16:47.800
If you haven't used a graph database before, you might be wondering about common use cases.

00:16:47.800 --> 00:16:48.680
You know, what's it for?

00:16:48.680 --> 00:16:50.080
Here are just a few.

00:16:50.080 --> 00:16:51.200
Detecting fraud.

00:16:51.200 --> 00:16:52.720
Enhancing AI.

00:16:53.280 --> 00:16:54.560
Managing supply chains.

00:16:54.560 --> 00:17:00.760
Managing a 360 degree view of your data and anywhere else you have highly connected data.

00:17:00.760 --> 00:17:06.220
To use Neo4j from Python, it's a simple pip install Neo4j.

00:17:06.220 --> 00:17:13.340
And to help you get started, their docs include a sample web app demonstrating how to use it both from Flask and FastAPI.

00:17:13.720 --> 00:17:18.360
Find it in their docs or search GitHub for Neo4j movies application quick start.

00:17:18.360 --> 00:17:22.540
Developers are solving some of the world's biggest problems with graphs.

00:17:22.540 --> 00:17:23.740
Now it's your turn.

00:17:23.740 --> 00:17:28.040
Visit talkpython.fm/neo4j to get started.

00:17:28.040 --> 00:17:32.980
That's talkpython.fm/neo, the number four, and the letter j.

00:17:32.980 --> 00:17:36.060
Thank you to Neo4j for supporting Talk Python to me.

00:17:37.460 --> 00:17:39.380
I like the query syntax.

00:17:39.380 --> 00:17:48.020
You know, people visit the homepage, you'd see something like time travel dot where, then lambda of t goes to t dot return equal equal true.

00:17:48.020 --> 00:18:03.040
And while some of the ORMs let you write code in terms of like the class fields or whatever, it's never looked quite right because you're working with, say, the static value out of the class.

00:18:03.040 --> 00:18:07.820
Whereas what you really are trying to talk about is the instance level of the record, right?

00:18:07.820 --> 00:18:15.200
So instead of saying t, you'd say time travel dot return, but we'd never test that because it's the global value of it, right?

00:18:15.200 --> 00:18:15.920
And stuff like that.

00:18:15.920 --> 00:18:19.400
Or you just use strings, which is basically, in my mind, no good.

00:18:19.400 --> 00:18:23.540
But what's cool, you know, also, do you want to do an OR or an AND?

00:18:23.540 --> 00:18:27.060
And then what weird thing do you import to do the OR?

00:18:27.060 --> 00:18:29.520
And like, you know, how do you wrap the query in it?

00:18:29.820 --> 00:18:34.100
All that kind of stuff, whereas if it's a lambda, you can just express the conditions how you want.

00:18:34.100 --> 00:18:34.880
Yeah, yeah.

00:18:34.880 --> 00:18:36.460
That's pretty much the idea.

00:18:36.460 --> 00:18:44.980
So I like to use, you know, special methods from Python objects and translate those expressions like in actually SQL code.

00:18:44.980 --> 00:18:45.800
So, yeah.

00:18:45.800 --> 00:18:46.400
Nice.

00:18:46.400 --> 00:18:52.660
For my apps, I have a combination of Beanie and Mongo Engine, depending on which one you're talking about.

00:18:52.960 --> 00:18:56.080
And for Mongo Engine, you do things that are pretty funky.

00:18:56.080 --> 00:19:01.540
Like, if you want to say greater than, you would say time travel dot, I don't know, it doesn't have a value, but age.

00:19:01.540 --> 00:19:02.260
Let's say there's an age.

00:19:02.260 --> 00:19:08.740
Like, time travel dot age underscore underscore GT equals value.

00:19:08.740 --> 00:19:10.100
And you're like, yes.

00:19:10.100 --> 00:19:14.180
Well, it's not equal to it, and that's not the name of it.

00:19:14.180 --> 00:19:17.240
But okay, I guess that means, you know what I mean?

00:19:17.240 --> 00:19:22.800
Like, there's a real weird way it's, like, jammed into a syntax, whereas, like, here you say greater than whatever, right?

00:19:22.800 --> 00:19:23.260
Yeah.

00:19:23.260 --> 00:19:30.020
Yeah, it's, like, the same of, it's one of the things I dislike still today of Django or M.

00:19:30.020 --> 00:19:30.400
Yeah.

00:19:30.400 --> 00:19:31.260
In that sense.

00:19:31.580 --> 00:19:35.120
I mean, it has, like, a lot more capabilities.

00:19:35.120 --> 00:19:44.160
Because, for instance, like, when you want to represent, like, complex queries, it tends to be more powerful in that sense.

00:19:44.160 --> 00:19:46.880
Meaning that special methods are limited.

00:19:46.880 --> 00:19:51.800
So, at some point, you start making custom methods.

00:19:51.800 --> 00:19:54.900
So, like, I don't know, starts with, for example.

00:19:54.900 --> 00:19:59.400
Yeah, starts with, or in this set, or the set includes this, and something like that, right?

00:19:59.580 --> 00:20:00.020
Exactly.

00:20:00.020 --> 00:20:04.800
So, I think, yeah, there are pros and cons in both, let's say, approaches.

00:20:04.800 --> 00:20:05.580
Yeah, cool.

00:20:05.580 --> 00:20:08.980
All right, so, we have a lot to talk about, even though all this code fits on one screen.

00:20:08.980 --> 00:20:11.340
The other part is to define an endpoint.

00:20:11.340 --> 00:20:12.700
This is about an API, right?

00:20:12.700 --> 00:20:15.160
So, you have an async def, which is awesome.

00:20:15.160 --> 00:20:16.980
Supports async and await.

00:20:16.980 --> 00:20:18.360
I think it's super valuable.

00:20:18.360 --> 00:20:22.180
Yeah, one note is that the RM is still synchronous.

00:20:22.180 --> 00:20:23.200
Yeah, yeah.

00:20:23.200 --> 00:20:25.500
So, what about that?

00:20:25.500 --> 00:20:29.200
Are you planning on adding an async thing, or are you just saying it's just synchronous?

00:20:29.200 --> 00:20:40.060
So, it's like a very long story, in a sense, because, like, I started asking myself the same question, like, several years ago.

00:20:40.420 --> 00:20:50.320
And I think, like, at some point, probably, I will end up doing that, in the same way SQLAlchemy did that.

00:20:50.320 --> 00:21:03.680
Even if I remember, like, a super nice blog post from the author of SQLAlchemy, stating that asynchronous code and databases are not the best way to use that.

00:21:03.680 --> 00:21:10.740
So, yeah, let's say, like, in the last few years, I just waited, in a way, to see what everyone else was doing.

00:21:10.740 --> 00:21:16.500
But, yeah, I think, like, at some point, it will be inevitable, in a sense.

00:21:16.760 --> 00:21:19.540
I just don't feel the time has come yet.

00:21:19.540 --> 00:21:20.680
So, we'll see.

00:21:20.680 --> 00:21:21.320
Yeah, cool.

00:21:21.320 --> 00:21:28.220
And then, I guess, the last thing to talk about is you have a decorator app.route, pretty straightforward.

00:21:28.220 --> 00:21:28.760
Yeah.

00:21:28.760 --> 00:21:32.100
But then, you also have an at service.json.

00:21:32.100 --> 00:21:33.380
What's this decorator do?

00:21:33.380 --> 00:21:42.520
So, you can think about that decorator, like, the service decorator, as, like, the JSONify function in Flask.

00:21:42.520 --> 00:21:48.960
So, yeah, in Emmet, you have, like, both the JSON service and the XML service.

00:21:48.960 --> 00:21:55.980
Because, like, in old times, I had to write stuff to talk with XML and points and stuff like that.

00:21:56.200 --> 00:21:57.080
Yeah, yeah, yeah.

00:21:57.080 --> 00:22:07.340
So, yeah, it's just an easy way to wrap and say everything that returns from this function, just serializing JSON or XML or whatever.

00:22:07.340 --> 00:22:13.160
If I return, rather than a response, just return a dictionary and it'll do the serialization, right?

00:22:13.160 --> 00:22:13.920
Yeah, exactly.

00:22:13.920 --> 00:22:14.520
Nice.

00:22:14.520 --> 00:22:19.560
And the audience, let's ask, does it generate an open API documentation?

00:22:19.560 --> 00:22:22.060
Like, does it automatically generate documentation?

00:22:22.540 --> 00:22:26.240
So, from standard routes, no.

00:22:26.240 --> 00:22:37.380
There's an extension, though, meaning that if you plan to design REST, let's say, APIs with Emmet, there's an extension for that.

00:22:37.380 --> 00:22:48.560
It's called Emmet REST, which, let's say, gives you, like, more tools to structure your routes and serialization and deserialization and all that kind of stuff.

00:22:48.560 --> 00:22:53.980
And that extension also brings OpenAPI documentation generation.

00:22:53.980 --> 00:23:01.860
Eventually, let's say, the OpenAPI documentation generation will come also to plain routes in Emmet.

00:23:01.860 --> 00:23:06.900
But there's quite a few design implied to do that.

00:23:06.900 --> 00:23:12.080
Meaning that, so Emmet, it's, like, not designed to have a strong type system.

00:23:12.080 --> 00:23:15.840
Because, again, it comes from the days where, like, typing.

00:23:15.840 --> 00:23:17.040
That didn't exist?

00:23:17.200 --> 00:23:18.340
Let's not, yeah.

00:23:18.340 --> 00:23:27.620
So, let's say that, for instance, for frameworks like FastAPI, which are practically designed on top of something like Pydantic.

00:23:27.620 --> 00:23:29.760
So, you have, like, a strong type system.

00:23:29.760 --> 00:23:35.880
So, everything that comes in and out from the majority of routes you write has types.

00:23:36.360 --> 00:23:42.780
And so, it's really easy for the framework to inspect the code and understand what's going on.

00:23:42.780 --> 00:23:53.360
On, let's say, general frameworks like Emmet, where you, I mean, you might have, like, I don't know, HTML routes or other kind of stuff going on.

00:23:53.500 --> 00:23:59.700
There's no, let's say, design behind that to support in the first play, like, strong typing.

00:23:59.700 --> 00:24:00.600
So, yeah.

00:24:00.600 --> 00:24:08.380
Making, like, OpenAPI documentation out of standard Emmet routes involves, like, quite a lot of decisions.

00:24:08.380 --> 00:24:09.280
So, yeah.

00:24:09.280 --> 00:24:09.680
We'll see.

00:24:09.680 --> 00:24:10.220
We'll see.

00:24:10.220 --> 00:24:10.800
Yeah.

00:24:10.800 --> 00:24:11.120
Okay.

00:24:11.120 --> 00:24:11.680
Yeah.

00:24:11.680 --> 00:24:12.000
Very cool.

00:24:12.000 --> 00:24:12.780
Yeah.

00:24:12.780 --> 00:24:15.440
We'll come back and talk about Emmet Rests in a minute.

00:24:15.440 --> 00:24:17.280
That's one of the fun things.

00:24:17.340 --> 00:24:19.140
That also has WebSocket support, right?

00:24:19.140 --> 00:24:19.660
Yep.

00:24:19.660 --> 00:24:20.140
Okay.

00:24:20.140 --> 00:24:20.940
Absolutely.

00:24:20.940 --> 00:24:25.720
WebSockets are these things that I'm always like, man, they're so cool and you can do all this interesting stuff.

00:24:25.720 --> 00:24:29.980
And then I never, ever, ever have a use case for it in my world.

00:24:29.980 --> 00:24:31.080
I just haven't yet.

00:24:31.080 --> 00:24:33.960
And so, I'm like, well, they're very cool, but I don't have it yet.

00:24:33.960 --> 00:24:34.440
Yeah.

00:24:34.440 --> 00:24:35.960
So, I mean, I'm not building Slack.

00:24:35.960 --> 00:24:36.440
Yeah.

00:24:36.440 --> 00:24:46.960
The thing is that usually, like, when you work with WebSockets, it's also pretty common that you need some broadcast facility.

00:24:46.960 --> 00:24:47.960
Yeah.

00:24:47.960 --> 00:24:56.920
So, usually you want to do channels or that kind of stuff, which usually tends to involve, like, other software.

00:24:57.120 --> 00:25:08.640
Like, you usually have Redis or something like that in order to, since Python is not exactly good in, let's say, managing threads or communicating across different processes.

00:25:08.640 --> 00:25:14.680
That's probably why it's not so easy in the Python world to actually rely on WebSockets a lot.

00:25:14.680 --> 00:25:26.260
I don't know, for instance, if you take, like, languages like, I don't know, Alex here, or you have, like, tons of stuff based on the fact that everything is actually communicating over Socket.

00:25:26.260 --> 00:25:27.440
So, yeah.

00:25:27.440 --> 00:25:41.580
And I think, like, one single thing to say on WebSockets, it's, I think Emmet is the only or one of the few frameworks that allows you to write middlewares with Sockets.

00:25:41.580 --> 00:25:42.740
So, you can.

00:25:42.740 --> 00:25:43.380
Okay.

00:25:43.380 --> 00:25:51.780
So, if you have, like, your chain of middlewares on the application, you can also define behaviors for the same middlewares to behave on WebSockets.

00:25:51.780 --> 00:25:54.560
So, you can probably use, like, a lot of code.

00:25:54.560 --> 00:26:05.180
Like, I don't know, if you are in a WebSocket and need to talk with the database, you can use the same middleware for the database connection you use on the standard request.

00:26:05.180 --> 00:26:08.120
So, I think that might be worth noting.

00:26:08.120 --> 00:26:09.360
Yeah, absolutely.

00:26:09.780 --> 00:26:18.180
Another thing that's interesting that I don't see in a lot of ORMs, they kind of just leave it to the, well, in SQL, so you write it, is aggregation.

00:26:18.180 --> 00:26:18.680
Right?

00:26:18.680 --> 00:26:18.740
Right?

00:26:18.740 --> 00:26:28.020
The aggregation stuff you have here is pretty interesting where you do a bunch of calculation type stuff in the database and then get a, sort of, the results back.

00:26:28.020 --> 00:26:28.240
Right?

00:26:28.240 --> 00:26:32.160
So, here you can say, like, select, talking about an event, like, event.location.

00:26:32.160 --> 00:26:33.080
Get the counts.

00:26:33.080 --> 00:26:35.820
And then group by this thing, order by that.

00:26:35.820 --> 00:26:37.340
Having these sort of properties.

00:26:37.340 --> 00:26:38.860
That's pretty unique.

00:26:38.920 --> 00:26:40.100
I don't see that in a lot of ORMs.

00:26:40.100 --> 00:26:49.240
Yeah, I think, like, you can do pretty much the same with SQLAlchemy, but probably, like, the syntax is less sugarly, let's say.

00:26:49.240 --> 00:26:58.200
I mean, again, this design comes from the fact that with my first startup, we had to do, like, a lot of aggregation over the database.

00:26:58.400 --> 00:27:01.580
So, that's why I wrote all of that, you know?

00:27:01.580 --> 00:27:02.860
Yeah, that's cool.

00:27:02.860 --> 00:27:04.280
The same code.

00:27:04.280 --> 00:27:05.680
Yeah, nice.

00:27:05.680 --> 00:27:11.720
You know, I'm familiar with it from all the MongoDB stuff that I've done, like, that big aggregation pipeline over there as well.

00:27:11.720 --> 00:27:13.320
Yeah, I'm also familiar.

00:27:13.320 --> 00:27:16.000
Like, I'm not a huge fan of Mongo, though.

00:27:16.000 --> 00:27:23.680
Probably because, like, being an SRE, like, making Mongo reliable is, like, a mess sometimes.

00:27:23.680 --> 00:27:27.600
I think it depends on how people rely on it, right?

00:27:27.600 --> 00:27:28.040
Yeah.

00:27:28.040 --> 00:27:29.680
For me, it's been absolutely.

00:27:29.680 --> 00:27:31.600
I've run my stuff on over 10 years, and it's been perfect.

00:27:31.600 --> 00:27:38.980
However, that's because I use a lot of structured code to talk to Mongo from one tech stack, right?

00:27:38.980 --> 00:27:44.600
But if some people are using dictionaries to talk to it, other people are using this framework, other people are using that framework,

00:27:44.600 --> 00:27:49.960
then the lack of schema structure, I think, becomes a problem.

00:27:49.960 --> 00:27:52.920
So, I think it really depends on how you use it.

00:27:52.920 --> 00:27:54.420
But, yeah, I hear what you're saying for sure.

00:27:54.420 --> 00:27:56.420
I think that that's not even necessarily a Mongo challenge.

00:27:57.100 --> 00:27:59.440
That's a document database challenge, generally, right?

00:27:59.440 --> 00:28:00.040
Yeah.

00:28:00.040 --> 00:28:03.340
Just Mongo is primarily the way people do document databases.

00:28:03.340 --> 00:28:03.960
Yeah.

00:28:03.960 --> 00:28:07.500
I tended to, like, use it for separated stuff.

00:28:07.500 --> 00:28:13.540
So, in several projects I worked on, I had, like, for instance, like the main database with Postgres, for instance,

00:28:13.660 --> 00:28:16.440
like another database with Mongo for specific stuff.

00:28:16.440 --> 00:28:24.420
Maybe stuff you don't need transactions on, or maybe you want to store, like, time series data or, you know, that kind of stuff.

00:28:24.420 --> 00:28:26.360
So, for that, I think it's really cool.

00:28:26.360 --> 00:28:26.920
Yeah, nice.

00:28:27.240 --> 00:28:28.240
All right.

00:28:28.240 --> 00:28:28.240
All right.

00:28:28.240 --> 00:28:35.900
I guess one final thing here that is worth covering, then I want to dive into a grand new as well, is the template syntax.

00:28:35.900 --> 00:28:39.680
So, you've got your own template syntax that's kind of like...

00:28:39.680 --> 00:28:40.480
That's not a syntax.

00:28:40.480 --> 00:28:42.860
All right.

00:28:42.860 --> 00:28:44.100
You tell people about it.

00:28:44.100 --> 00:28:44.740
You tell them about it.

00:28:44.740 --> 00:28:45.260
Yeah.

00:28:45.460 --> 00:28:49.600
So, the template system embedded in Emmet is called Renoir.

00:28:49.600 --> 00:28:56.260
And the idea behind it is to don't have a syntax at all.

00:28:56.260 --> 00:29:01.320
So, the idea behind Emmet template system was why...

00:29:01.320 --> 00:29:09.440
So, the question I had is, like, why do I have to learn a new language to write server-side render templates?

00:29:09.440 --> 00:29:10.500
Like, why it came out?

00:29:10.500 --> 00:29:10.900
Yeah.

00:29:10.900 --> 00:29:12.260
And those languages are...

00:29:12.260 --> 00:29:12.500
Yeah.

00:29:12.500 --> 00:29:15.240
And they're very, very Python-like, but they're not Python-like.

00:29:15.260 --> 00:29:15.700
Exactly.

00:29:15.700 --> 00:29:25.900
So, I just said, well, I guess I'll try to do just Python, you know, wrap it in the same brackets every other templating language has.

00:29:25.900 --> 00:29:27.800
So, it's just plain Python.

00:29:27.800 --> 00:29:31.420
You can do pretty much everything you can do in Python.

00:29:31.420 --> 00:29:34.060
You can even do imports inside.

00:29:34.060 --> 00:29:36.400
Not that I suggest to do that, but you can...

00:29:36.400 --> 00:29:37.840
Still, you can do that.

00:29:37.840 --> 00:29:40.660
Don't go create PHP, people.

00:29:40.660 --> 00:29:41.220
Come on now.

00:29:41.220 --> 00:29:42.220
Exactly.

00:29:42.880 --> 00:29:52.660
The only, let's say, major difference from standard Python code is that you have to write the pass keyword after a block of code.

00:29:52.660 --> 00:30:06.440
So, if you write, like, a for loop or an if statement, the template engine has to know when that block ends, given that Python relies on indentation to understand like that.

00:30:06.440 --> 00:30:10.900
But in templates, you don't have like the same indentation level you have in Python.

00:30:10.900 --> 00:30:19.720
So, that's the only major difference from plain Python code plus a few, let's say, keyword added to the game.

00:30:19.720 --> 00:30:25.320
So, you have extend and include in order to extend and include.

00:30:25.320 --> 00:30:29.500
So, there are partial templates, let's say, and blocks.

00:30:29.500 --> 00:30:30.440
That's it.

00:30:30.440 --> 00:30:30.920
Right.

00:30:30.920 --> 00:30:33.260
Blocks for the layout sections, right?

00:30:33.260 --> 00:30:33.900
Exactly.

00:30:33.900 --> 00:30:35.020
Yeah, that's really nice.

00:30:35.020 --> 00:30:36.120
I like the idea.

00:30:36.120 --> 00:30:42.680
I'm sure there are people listening that'd be like, I would like to try this stuff out, but I've got 10,000 lines.

00:30:42.880 --> 00:30:43.620
Of Jinja.

00:30:43.620 --> 00:30:48.000
Jinja, or I've got 10,000 lines of Chameleon or.

00:30:48.000 --> 00:30:49.400
Yeah, yeah, yeah, I know.

00:30:49.400 --> 00:30:49.900
Whatever.

00:30:49.900 --> 00:30:51.080
What's the story?

00:30:51.080 --> 00:30:55.380
I mean, I'm working in the office with Armin Ronaker every day.

00:30:55.380 --> 00:30:59.860
So, the amount of Jinja code we have in Sentry is like huge.

00:30:59.860 --> 00:31:03.440
So, yeah, I perfectly understand the point.

00:31:03.440 --> 00:31:07.940
I don't have like, let's say, a marketing line for selling a Renoir.

00:31:08.180 --> 00:31:17.400
It's just something that I, so today I'm so, I'm equilibrary familiar to Jinja templates and Renoir templates.

00:31:17.400 --> 00:31:24.560
I'd say it really depends on how you usually structure your application code.

00:31:24.880 --> 00:31:37.400
So, I think one good way to try out Renoir is if you tend to don't use a lot like Jinja filters or stuff like that.

00:31:37.400 --> 00:31:42.380
That might be a good case scenario to trying out Renoir.

00:31:42.380 --> 00:31:42.880
Yeah.

00:31:42.880 --> 00:31:53.360
But, of course, it has to be like a new project because converting, I mean, there's no sense into moving, translating code from one system to another once you picked.

00:31:53.360 --> 00:31:54.740
It's not super different.

00:31:54.740 --> 00:32:00.700
So, I think you change an end if to a pass, for example, or end for into a pass.

00:32:00.700 --> 00:32:07.320
But, I was thinking more, is there a way to use Jinja within Emmet instead of using Roar?

00:32:07.320 --> 00:32:12.480
I mean, there's no plain, there's no read extension for that.

00:32:12.740 --> 00:32:20.920
But, I mean, if you create like a Jinja instance over the Emmet application, you can call it in your roots.

00:32:20.920 --> 00:32:23.120
You can even create a middleware for that.

00:32:23.120 --> 00:32:26.280
So, I think it's pretty easy also to set up Emmet to work with Jinja.

00:32:26.280 --> 00:32:27.380
Yeah, I would think so.

00:32:27.380 --> 00:32:32.680
I created a chameleon FastAPI, which lets you basically put a decorator on FastAPI endpoints.

00:32:32.680 --> 00:32:36.620
And it does chameleon template rendering with a dictionary instead of rest endpoints.

00:32:36.620 --> 00:32:37.620
It wasn't that much.

00:32:37.620 --> 00:32:39.820
You basically just have to juggle it from behind.

00:32:39.820 --> 00:32:43.500
So, I imagine you could probably, someone could create a Jinja decorator.

00:32:43.500 --> 00:32:47.940
Like you have service.json, like a template.jinja or whatever, something like that, right?

00:32:47.940 --> 00:32:48.400
Probably?

00:32:48.400 --> 00:32:49.740
Yeah, yeah, absolutely.

00:32:50.140 --> 00:32:51.720
That said, I'm not a fan of Jinja.

00:32:51.720 --> 00:32:53.100
I think it's overly complicated.

00:32:53.100 --> 00:32:54.440
So, I'm not encouraged.

00:32:54.440 --> 00:32:55.580
I'm not suggesting it.

00:32:55.580 --> 00:33:05.440
But the reality is, even as much as I've tried to fight against it, is that the majority of Python web HTML, dynamic HTML, is done in Jinja these days, right?

00:33:05.440 --> 00:33:07.080
Yeah, probably too.

00:33:07.080 --> 00:33:10.680
Yeah, you kind of got to live in that space, even if you don't want to.

00:33:10.680 --> 00:33:11.260
All right.

00:33:11.260 --> 00:33:16.580
And let's talk about the thing that I opened, I talked about at the opening, is Granian.

00:33:16.580 --> 00:33:18.100
Where's Granian gone?

00:33:18.100 --> 00:33:18.860
There we go.

00:33:19.160 --> 00:33:26.180
So, this is how, as I said, I got to learn about this framework and what you're doing and stuff with Granian.

00:33:26.180 --> 00:33:26.980
Tell us about Granian.

00:33:26.980 --> 00:33:32.540
And as a way to sort of kick this off, Cody, who I've had on the show before from Litestar, says,

00:33:32.540 --> 00:33:33.840
thanks for the work on Granian.

00:33:33.840 --> 00:33:35.580
I've had an excellent time using it with Litestar.

00:33:35.580 --> 00:33:36.780
Litestar is also awesome.

00:33:36.780 --> 00:33:38.040
Yeah, thanks, Cody.

00:33:38.040 --> 00:33:39.280
Yeah, so tell us about it.

00:33:39.280 --> 00:33:47.140
Yeah, so as the description suggests, it's just an HTTP server for Python application.

00:33:47.780 --> 00:33:55.920
So, it has the same scope of UVcorn, G-Unicorn, Hypercorn, and all that libraries.

00:33:55.920 --> 00:34:03.720
The main difference compared to every other HTTP server for Python application is that it's not written in Python.

00:34:03.720 --> 00:34:05.760
It's written in Rust.

00:34:06.300 --> 00:34:16.400
And it supports natively both BoostG and ASGI, so both synchronous and asynchronous applications.

00:34:16.400 --> 00:34:22.100
Plus, a new protocol I also wrote with Granian, which is called RSGI.

00:34:22.260 --> 00:34:27.480
But the only existing framework using it that I'm aware of is Emmet, indeed.

00:34:27.480 --> 00:34:30.120
Yeah, I think there's a lot of things that are nice about this.

00:34:30.120 --> 00:34:37.440
And I have actually most of the things, including Talk Python itself, running on Granian, which is pretty cool.

00:34:37.440 --> 00:34:38.620
Cool.

00:34:39.120 --> 00:34:40.220
Yeah, yeah, absolutely.

00:34:40.220 --> 00:34:43.300
So, single correct HTTP implementation.

00:34:43.300 --> 00:34:44.060
Sounds awesome.

00:34:44.060 --> 00:34:47.640
Support for version 1, 2, and 3, I guess, when it's ratified, right?

00:34:47.840 --> 00:34:58.680
Yeah, so HTTP3, let's say, so since Granian is actually based on a Rust library, which is called Hyper, which is a super cool library.

00:34:59.320 --> 00:35:03.720
It's like vastly adopted, like everywhere in the world.

00:35:03.720 --> 00:35:11.040
Like, I don't know how many thousands, hundreds of thousands of libraries in the Rust ecosystem use it.

00:35:11.040 --> 00:35:15.840
It's used in Cloudflare for a lot of their production systems.

00:35:15.840 --> 00:35:17.720
So, super strong library.

00:35:17.720 --> 00:35:22.280
But yes, it doesn't yet support HTTP3.

00:35:22.680 --> 00:35:31.260
So, yeah, I guess when Hyper will support HTTP3, that could be easily added to Granian.

00:35:31.260 --> 00:35:32.240
Right, right.

00:35:32.240 --> 00:35:32.560
That's cool.

00:35:32.560 --> 00:35:39.800
Yeah, with things like Genocorn, you've then got to also integrate Uveacorn workers, and you kind of have a lot of stuff at play, right?

00:35:39.800 --> 00:35:42.860
So, here, you've just got one thing, which is cool.

00:35:43.180 --> 00:35:57.460
Yeah, I mean, like, I tended to find annoying the fact that if you want, like, to squeeze out, like, performance out of Uveacorn, you usually need to, yeah, pile up different libraries together.

00:35:57.460 --> 00:36:08.000
Like, oh, wait, I need to add the HTTP tools dependency, so it can use, like, the C written parsers for HTTP.

00:36:08.000 --> 00:36:13.940
I'll wait, and probably I want some process management, so I need also a Junicorn.

00:36:13.940 --> 00:36:14.720
Yeah.

00:36:14.720 --> 00:36:18.700
It's not super easy, like, for starters, at least.

00:36:18.700 --> 00:36:19.220
Yeah.

00:36:19.220 --> 00:36:25.740
I guess maybe we should just set the stage a little bit for people that don't live and breathe Python web deployment.

00:36:25.740 --> 00:36:26.520
Apologies.

00:36:27.260 --> 00:36:44.120
So, typically, you would have something like Nginx or Caddy that browser actually talks to, and then behind the scenes, you set up those, let's just say, Nginx, to when there's a request for a dynamic content or Python-based content, as opposed to, like, a CSS file or something.

00:36:44.120 --> 00:36:49.120
So, again, you can use it as a CSS file or something.

00:36:49.120 --> 00:36:51.120
So, again, you can use it as a CSS file or something.

00:36:51.120 --> 00:36:53.120
So, again, you can use it as a CSS file or something.

00:36:53.120 --> 00:36:55.120
So, again, you can use it as a CSS file or something.

00:36:55.120 --> 00:36:57.120
So, again, you can use it as a CSS file or something.

00:36:57.120 --> 00:36:59.120
So, again, you can use it as a CSS file or something.

00:36:59.120 --> 00:37:01.120
So, again, you can use it as a CSS file or something.

00:37:01.120 --> 00:37:03.120
So, again, you can use it as a CSS file or something.

00:37:03.120 --> 00:37:07.120
So, again, you can use it as a CSS file or something.

00:37:07.120 --> 00:37:08.120
So, again, you can use it as a CSS file or something.

00:37:08.120 --> 00:37:09.120
So, again, you can use it as a CSS file or something.

00:37:09.120 --> 00:37:10.120
So, again, you can use it as a CSS file.

00:37:10.120 --> 00:37:11.120
So, again, you can use it as a CSS file.

00:37:11.120 --> 00:37:13.120
So, again, you can use it as a CSS file.

00:37:13.120 --> 00:37:14.120
So, again, you can use it as a CSS file.

00:37:14.120 --> 00:37:15.120
So, again, you can use it as a CSS file.

00:37:15.120 --> 00:37:16.120
So, again, you can use it as a CSS file.

00:37:16.120 --> 00:37:17.120
So, again, you can use it as a CSS file.

00:37:17.120 --> 00:37:18.120
So, again, you can use it as a CSS file.

00:37:18.120 --> 00:37:19.120
So, again, you can use it as a CSS file.

00:37:19.120 --> 00:37:20.120
So, again, you can use it as a CSS file.

00:37:20.120 --> 00:37:21.120
So, again, you can use it as a CSS file.

00:37:21.120 --> 00:37:22.120
So, again, you can use it as a CSS file.

00:37:22.120 --> 00:37:23.120
So, again, you can use it as a CSS file.

00:37:23.120 --> 00:37:25.120
So, again, you can use it as a CSS file.

00:37:25.120 --> 00:37:26.120
So, again, you can use it as a CSS file.

00:37:26.120 --> 00:37:27.120
So, again, you can use it as a CSS file.

00:37:27.120 --> 00:37:28.120
So, again, you can use it as a CSS file.

00:37:28.120 --> 00:37:29.120
So, again, you can use it as a CSS file.

00:37:29.120 --> 00:37:30.120
So, again, you can use it as a CSS file.

00:37:30.120 --> 00:37:31.120
So, again, you can use it as a CSS file.

00:37:31.120 --> 00:37:32.120
So, again, you can use it as a CSS file.

00:37:32.120 --> 00:37:33.120
So, again, you can use it as a CSS file.

00:37:33.120 --> 00:37:34.120
So, again, you can use it as a CSS file.

00:37:34.120 --> 00:37:35.120
So, again, you can use it as a CSS file.

00:37:35.120 --> 00:37:36.120
So, again, you can use it as a CSS file.

00:37:36.120 --> 00:37:37.120
So, again, you can use it as a CSS file.

00:37:37.120 --> 00:37:40.120
So, again, you can use it as a CSS file.

00:37:40.120 --> 00:37:42.120
So, again, you can use it as a CSS file.

00:37:42.120 --> 00:37:43.120
So, again, you can use it as a CSS file.

00:37:43.120 --> 00:37:44.120
So, again, you can use it as a CSS file.

00:37:44.120 --> 00:37:46.120
So, again, you can use it as a CSS file.

00:37:46.120 --> 00:37:47.120
So, again, you can use it as a CSS file.

00:37:47.120 --> 00:37:48.120
So, again, you can use it as a CSS file.

00:37:48.120 --> 00:37:49.120
So, again, you can use it as a CSS file.

00:37:49.120 --> 00:37:50.120
So, again, you can use it as a CSS file.

00:37:50.120 --> 00:37:51.120
So, again, you can use it as a CSS file.

00:37:51.120 --> 00:37:52.120
So, again, you can use it as a CSS file.

00:37:52.120 --> 00:37:53.120
So, again, you can use it as a CSS file.

00:37:53.120 --> 00:37:54.120
So, again, you can use it as a CSS file.

00:37:54.120 --> 00:37:55.120
So, again, you can use it as a CSS file.

00:37:55.120 --> 00:38:05.120
So, I mean, having Nginx above Granian makes sense only if you want to root something out of Granian and not serve it from Granian.

00:38:05.120 --> 00:38:16.120
But, yeah, in general, I'd say that you can use it in both ways, behind Nginx or not, up to the specific needs of the application, let's say.

00:38:16.120 --> 00:38:17.120
Yeah.

00:38:17.120 --> 00:38:23.120
I have one Nginx Docker server container handling, like, 15 different apps.

00:38:23.120 --> 00:38:26.120
And so, for me, that's kind of the setup.

00:38:26.120 --> 00:38:31.120
But typically, the SSL that I do is over Let's Encrypt using Certbot.

00:38:31.120 --> 00:38:34.120
If I want to do HTTPS with Granian, how do I do it?

00:38:34.120 --> 00:38:42.120
You can keep, like, the Let's Encrypt and Backman HSH generation thing because Granian supports the SIGAP signal.

00:38:42.120 --> 00:38:48.120
So, whenever you need to refresh the certificate, you can issue a SIGAP to the Granian process.

00:38:48.120 --> 00:38:55.120
And that process will reload the workers picking up the new certificate.

00:38:55.120 --> 00:38:57.120
So, I think it's pretty straightforward.

00:38:57.120 --> 00:39:08.120
I mean, if you already manage, like, SSL certificates and, like, renewal chain and all that kind of stuff, it's pretty straightforward to do the same in Granian.

00:39:08.120 --> 00:39:17.120
You can just pass, you know, the paths to the certificates to the CLI command or even use environment variables up to you.

00:39:17.120 --> 00:39:18.120
Got you. Okay.

00:39:18.120 --> 00:39:21.120
One thing that I thought was pretty interesting was the performance.

00:39:21.120 --> 00:39:28.120
Not necessarily that it's so, so, so much faster, but that it's so, so much more consistent.

00:39:28.120 --> 00:39:29.120
You want to talk about that a little bit?

00:39:29.120 --> 00:39:30.120
Yeah.

00:39:30.120 --> 00:39:40.120
So, I think if you want to show to the YouTube audience the comparison thing, you'll find the link in the bottom of the page.

00:39:40.120 --> 00:39:47.120
Because the first phase of benchmarks in the repository contains just benchmarks of Granian itself.

00:39:47.120 --> 00:39:52.120
Whereas in the versus page, you can find, like, comparison with other servers.

00:39:52.120 --> 00:40:09.120
So, the thing behind, let's say, the stable keyword I used into describing, like, the performance of Granian was about the fact that usually when people look at benchmarks, just look at the, you know, number of requests.

00:40:09.120 --> 00:40:11.120
Yeah, yeah, yeah, yeah.

00:40:11.120 --> 00:40:14.120
What's the max request per second you can get with this thing or whatever?

00:40:14.120 --> 00:40:15.120
Yeah, exactly.

00:40:15.120 --> 00:40:31.120
But the, another, like, very important value of this to me is like the latency, because you can, you can still serve like a lot of requests in parallel, but the amount of time each request will take to be served.

00:40:31.120 --> 00:40:32.120
It's also like important.

00:40:32.120 --> 00:40:43.120
I mean, I can serve like a thousand records per second, but if those requests takes a second or it takes like 10 milliseconds, it's like a huge difference for the end user.

00:40:43.120 --> 00:40:44.120
Yeah.

00:40:44.120 --> 00:40:58.120
And so, the thing is that from, from, at least from benchmarks, it appears that the way Granian works, which relies on having like all the network stack separated from Python.

00:40:58.120 --> 00:41:08.120
So all the IO, the real IO part involving the network communication is not tied to the Python interpreter.

00:41:08.120 --> 00:41:15.120
And so it doesn't suffer from the global interpreter block and threats getting blocked between each other.

00:41:15.120 --> 00:41:36.120
It seems to make like, like, like, Runyon to be more, let's say, predictable in response time, meaning that the both the average latency and the maximum latency you have in the benchmarks is much lower compared to other, let's say, implementations, other HTTP servers.

00:41:36.120 --> 00:41:37.120
So yeah, it's not like super faster.

00:41:37.120 --> 00:41:42.120
It won't make like, obviously it won't make the Python code of your application faster.

00:41:42.120 --> 00:41:49.120
We can shut down all of our servers except for one $5 digital ocean server and just.

00:41:49.120 --> 00:41:50.120
Yeah, no, not really.

00:41:50.120 --> 00:41:50.120
Yeah.

00:41:50.120 --> 00:41:52.120
No, not really.

00:41:52.120 --> 00:41:59.120
But at least it should normalize in a way the response time of your application.

00:41:59.120 --> 00:42:00.120
Yeah.

00:42:00.120 --> 00:42:01.120
Yeah.

00:42:01.120 --> 00:42:02.120
Yeah.

00:42:02.120 --> 00:42:03.120
Yeah.

00:42:03.120 --> 00:42:05.120
So the standard deviation of the request time is way, way tighter.

00:42:05.120 --> 00:42:06.120
Exactly.

00:42:06.120 --> 00:42:12.120
The distribution of the request time is way, way tighter, even though you do seem to have generally the fastest times.

00:42:12.120 --> 00:42:16.120
But if you look at the difference of the average times in the max times.

00:42:16.120 --> 00:42:17.120
Yeah.

00:42:17.120 --> 00:42:19.120
The difference is a lot smaller.

00:42:19.120 --> 00:42:26.120
It's like two and a half times variation versus some of the other ones are many.

00:42:26.120 --> 00:42:27.120
Yeah.

00:42:27.120 --> 00:42:28.120
10 X or something.

00:42:28.120 --> 00:42:28.120
Yes.

00:42:28.120 --> 00:42:29.120
Yeah.

00:42:29.120 --> 00:42:30.120
Maybe a hundred X or some of them.

00:42:30.120 --> 00:42:31.120
Yeah.

00:42:31.120 --> 00:42:32.120
Yeah, absolutely.

00:42:32.120 --> 00:42:33.120
Okay.

00:42:33.120 --> 00:42:33.120
Yeah.

00:42:33.120 --> 00:42:37.120
That's what really I thought was pretty interesting is the super predictability of it.

00:42:37.120 --> 00:42:38.120
Yeah.

00:42:38.120 --> 00:42:41.120
One thing I want to ask you about is you did say it does this RSGI.

00:42:41.120 --> 00:42:43.120
Do you want to call it G?

00:42:43.120 --> 00:42:45.120
G SGI, the Granian server interface?

00:42:45.120 --> 00:42:46.120
No, whatever.

00:42:46.120 --> 00:42:49.120
No, it's like a RAS server gateway interface.

00:42:49.120 --> 00:42:50.120
Yeah.

00:42:50.120 --> 00:42:51.120
Yeah.

00:42:51.120 --> 00:42:52.120
Yeah.

00:42:52.120 --> 00:42:52.120
Yeah.

00:42:52.120 --> 00:42:53.120
That's what I figured.

00:42:53.120 --> 00:42:56.120
And you said Emmet uses this, which is awesome.

00:42:56.120 --> 00:42:57.120
What's the advantage?

00:42:57.120 --> 00:43:02.120
Is there a significant advantage to doing things differently rather than ASGI or something?

00:43:02.120 --> 00:43:07.120
Would it be worth like things like flask saying, Hey, should we support this if we're running on top of granny?

00:43:07.120 --> 00:43:08.120
Or things like that's what I'm getting at.

00:43:08.120 --> 00:43:13.120
So I didn't actually know if flask today also supports a synchronous.

00:43:13.120 --> 00:43:14.120
With court they do.

00:43:14.120 --> 00:43:15.120
Request.

00:43:15.120 --> 00:43:16.120
Yeah.

00:43:16.120 --> 00:43:17.120
Okay.

00:43:17.120 --> 00:43:18.120
Okay.

00:43:18.120 --> 00:43:23.120
So Quartz might take advantage of RSGI, meaning that it's still asynchronous protocols.

00:43:23.120 --> 00:43:27.120
So you have to be in an asynchronous context to use RSGI.

00:43:27.120 --> 00:43:42.120
But the main difference, let's say between ASGI and RSGI is that it's in the, how to say, the communication mechanism or let's say the communication entities, meaning that.

00:43:42.120 --> 00:43:54.120
So in ASGI, you have usually have two methods, two awaitable methods, which are like send and receive.

00:43:54.120 --> 00:43:59.120
So we have to push, let's say dictionaries to those methods, which are referred as messages.

00:43:59.120 --> 00:44:15.120
So usually have like a dictionary, which has type key, which contains like the type of message, which might be, I don't know, HTTP request or HTTP body or WebSocket message.

00:44:15.120 --> 00:44:24.120
And all the intercommunication between like the server and application relies on those dictionaries with specific keys and strings.

00:44:24.120 --> 00:44:37.120
And since you have like a single, let's say, interface to rely on that, and that interface is asynchronous, it also means you, it means two things.

00:44:37.120 --> 00:44:51.120
The first thing is that every time you want to say something to the server or to the client, you have to await for that message, even if there's no actually IO involved in that operation.

00:44:51.120 --> 00:44:55.120
So, right. Which is a context switch and overhead and all of that stuff, right?

00:44:55.120 --> 00:45:04.120
Exactly. So for example, when you, so sending back a response in ASGI, it involves typically at least two messages.

00:45:04.120 --> 00:45:14.120
So the first one is to start the response. So you instruct the server with the response code and the headers you want to send back to the client.

00:45:14.120 --> 00:45:21.120
So the following message or messages are the body of that response.

00:45:21.120 --> 00:45:29.120
So the final fact is that the response start event doesn't involve any IO at all. It doesn't use the network.

00:45:29.120 --> 00:45:42.120
So what happens in that is that you delaying the operation that you are supposed to do, which is just saying, okay, I'm gonna send some data.

00:45:42.120 --> 00:45:50.120
And these are the like, here's some text. Yeah. You're gonna delay that operation to the next cycle of the event in your Python code.

00:45:50.120 --> 00:46:00.120
So that adds quite a lot of overhead. And I mean, I understand like why the interface is made in this way, because it's like super straightforward.

00:46:00.120 --> 00:46:18.120
It's very simple. You have like the same interface to do everything, but at the same time, it feels very unperformant in a way because we are wasting like a tons of like, even, I don't understand why do we need like to waste event loop cycles to do something that is actually synchronous code.

00:46:18.120 --> 00:46:32.120
Yeah, sure. And so RSGI changed this in a way that you have interfaces which are synchronous or asynchronous depending on what you're actually planning to do.

00:46:32.120 --> 00:46:47.120
For example, like if you have the entire body. So if your root returns, I don't know, a JSON stream, okay, you don't need to actually await for sending the body because you already have like all the bodies. So the interface in our

00:46:47.120 --> 00:46:50.120
Right, right. It's all in memory. Yeah, there's no IO.

00:46:50.120 --> 00:46:51.120
Yeah, the interfacing.

00:46:51.120 --> 00:47:01.120
It's not like a file, file stream pointer or whatever they said to return. Yeah, exactly. So in that case in RSGI, you can use a synchronous method to just move the body to the server.

00:47:01.120 --> 00:47:11.120
to the server and just let the response goes nice. Whereas if you want to stream content, then you can use a specific interface for that in RSGI, which is responsible stream.

00:47:11.120 --> 00:47:19.120
And that gives you like an interface to send chunks of body or iterate over something as you're supposed to do.

00:47:19.120 --> 00:47:26.120
Oh, yeah. So that's the major thing. The other thing, like the other reason why RSGI exists is that.

00:47:26.120 --> 00:47:40.120
Yeah, ASGI is designed based on the fact that the network communication happens under Python, which is something that Granian can do because can emulate because it supports ASGI.

00:47:40.120 --> 00:47:57.120
So that's also waste. So if you have the chance to have a different implementation that makes like things a lot more difficult to implement, meaning reasoning, like if you work in Python, but you're actually in a different language.

00:47:57.120 --> 00:48:01.120
So yeah, that's the other reason why RSGI exists.

00:48:01.120 --> 00:48:02.120
Okay. Yeah, that's very interesting.

00:48:02.120 --> 00:48:07.120
Yeah, maybe some of the other frameworks could look at that and go, well, if it's available, it's an option.

00:48:07.120 --> 00:48:11.120
Okay, a couple of things I want to talk about before we run out of time here.

00:48:11.120 --> 00:48:17.120
One is Jazzy Coder out in the audience asks, how did you validate your library following the correct spec?

00:48:17.120 --> 00:48:26.120
Did you reference the RFCs or another library or if you use a go-down, back to principles of the Unix networking programming book?

00:48:26.120 --> 00:48:31.120
And for background, interested in this approach because I'm building my own WSGI server.

00:48:31.120 --> 00:48:38.120
Okay, cool. So the idea, I mean, WSGI protocol is like documented in a PEP.

00:48:38.120 --> 00:48:50.120
So I just implemented tests that respect what is defining to the original PEP about WSGI with just an exception.

00:48:50.120 --> 00:49:00.120
So the only exception in Fragornian in WSGI protocol is that it's able to serve HTTP/2 over WSGI,

00:49:00.120 --> 00:49:06.120
which is not supposed to happen. But with Granon, you can serve your WSGI application directly with HTTP/2.

00:49:06.120 --> 00:49:11.120
But yeah, that's the way I was sure to respect the protocol.

00:49:11.120 --> 00:49:18.120
Yeah. How about like the HTTP/2 protocol? Are you using just a library that already has it all figured out or?

00:49:18.120 --> 00:49:25.120
Yes, yes. I mean, reinventing the wheel like also for HTTP handling was something I wasn't looking for.

00:49:25.120 --> 00:49:27.120
No, I wouldn't want to do it either.

00:49:27.120 --> 00:49:29.120
So yeah, hyper hyper is, I mean, I don't know.

00:49:29.120 --> 00:49:34.120
It's a REST crate or something like that?

00:49:34.120 --> 00:49:35.120
Yeah, exactly.

00:49:35.120 --> 00:49:36.120
Awesome. All right. Very cool.

00:49:36.120 --> 00:49:51.120
The other thing I want to ask you about or just let you speak to real quick is there's a bunch of features like specifying the HTTP interface level.

00:49:51.120 --> 00:49:58.120
Like, do you want to restrict it to one or two? Yeah, you might care because there was a vulnerability in HTTP/2 create like some kind of too much work or too many retries or something recently.

00:49:58.120 --> 00:50:04.120
So maybe you want to switch it to one for a while. I don't know.

00:50:04.120 --> 00:50:10.120
Fun fact that Granian wasn't affected by that because hyper the library behind it wasn't affected by that.

00:50:10.120 --> 00:50:13.120
Oh, nice. That's awesome.

00:50:13.120 --> 00:50:19.120
Yeah, I figured basically just in this case, you wait until hyper either fixes it or hyper is not a problem, right?

00:50:19.120 --> 00:50:27.120
Which is great. But maybe just talk about some of the things that we haven't touched on that are interesting like blocking threads or threading mode or specifying the loop or so on.

00:50:27.120 --> 00:50:38.120
So yeah, in Granian, so since Granian has this unique architecture where you have an event loop running on the RAST side.

00:50:38.120 --> 00:50:52.120
So for instance, if you're like deploying your ASGI application with Granian, you will have two event loops like the Python one, the ones that runs your code and also a RAST event loop,

00:50:52.120 --> 00:50:59.120
which is actually the Tokyo runtime is another super popular crate in the RAST ecosystem.

00:50:59.120 --> 00:51:12.120
There are different ways to run the RAST runtime, meaning that RAST is not limited to having a single thread running the loop.

00:51:12.120 --> 00:51:20.120
And thus you can have an event loop running on several different threads on the RAST side.

00:51:20.120 --> 00:51:34.120
And so the threading mode option in Granian lets you specify that behavior, meaning that if you use the runtime option, you will end up having like multi-threaded runtimes on the RAST side.

00:51:34.120 --> 00:51:44.120
Whereas if you specify the workers option for the threading mode, it will still use a single threaded runtime also on the RAST side.

00:51:44.120 --> 00:51:49.120
If you say that the runtime mode, did the workers themselves each get multiple threads?

00:51:49.120 --> 00:51:50.120
Is that how that works?

00:51:50.120 --> 00:51:51.120
Yes, exactly.

00:51:51.120 --> 00:52:01.120
So in runtime mode, every worker has multi-threaded runtimes, whereas on the worker side, you have like the worker is also the runtime.

00:52:01.120 --> 00:52:02.120
Yeah, got it.

00:52:02.120 --> 00:52:10.120
And the option is there because like depending on the load of your application, like one of the two might work better.

00:52:10.120 --> 00:52:11.120
Sure.

00:52:11.120 --> 00:52:14.120
Depends on the IO and CPU boundness of your application.

00:52:14.120 --> 00:52:15.120
So, yeah.

00:52:15.120 --> 00:52:16.120
I don't want to go too much into these.

00:52:16.120 --> 00:52:21.120
But if I set threading mode to runtime, is it reasonable to have just one worker?

00:52:21.120 --> 00:52:26.120
Or does it still make sense to have multiple workers for Python app?

00:52:26.120 --> 00:52:33.120
So the thing is that with a single worker, so the workers will spawn their own Python interpreters.

00:52:33.120 --> 00:52:49.120
So every worker is limited to the global interpreter lock, meaning that even if you spawn like a single worker with, I don't know, 12 threads, those 12 threads will run in the RAST code.

00:52:49.120 --> 00:52:50.120
Yeah, yeah.

00:52:50.120 --> 00:52:55.120
But they share a single Python runtime, which means all the things that that means.

00:52:55.120 --> 00:52:56.120
Exactly.

00:52:56.120 --> 00:52:57.120
Got it.

00:52:57.120 --> 00:52:58.120
Okay.

00:52:58.120 --> 00:52:59.120
So the only way to scale.

00:52:59.120 --> 00:53:03.120
So the workers is the way to scale, let's say the Python code of your application.

00:53:03.120 --> 00:53:04.120
Okay.

00:53:04.120 --> 00:53:10.120
Threads and threads are useful to scale the RAST runtime of stuff.

00:53:10.120 --> 00:53:20.120
No, there are some, the RAST side of stuff, of the things, meaning that those will be like the amount of threads used by RAST to handle your requests.

00:53:20.120 --> 00:53:29.120
So for example, if your application runs, opens like a tons of WebSocket, maybe you have like a WebSocket service.

00:53:29.120 --> 00:53:34.120
It might be helpful to spawn more threads for the RAST side.

00:53:34.120 --> 00:53:40.120
So it can actually handle more of those requests in the WebSocket land.

00:53:40.120 --> 00:53:56.120
And the blocking threads are mostly relevant only for the VOOSKI protocol, meaning that the blocking threads are the amount of threads used by Granian to interact with Python code.

00:53:56.120 --> 00:54:11.120
So on ASGI, since you will have like the event loop, there's no so much difference in how many threads you, how many blocking threads you spawn because those blocking threads will still have to schedule stuff on the Python event loop.

00:54:11.120 --> 00:54:18.120
But on VOOSKI, since you don't have, you're not limited to the main thread of Python.

00:54:18.120 --> 00:54:31.120
So if you're, I don't know, maybe your application is using, you're using CyperPG to connect to the database and those libraries are able to release the global interpreter block.

00:54:31.120 --> 00:54:45.120
So having multiple blocking threads on VOOSKI might be helpful, still be helpful because like all the code which doesn't involve the GIL will be able to run in parallel.

00:54:45.120 --> 00:54:46.120
Right, right.

00:54:46.120 --> 00:54:52.120
Maybe one part, one thread, one request is waiting on a database call, which it hits the network, which releases the GIL, for example.

00:54:52.120 --> 00:54:53.120
Right.

00:54:53.120 --> 00:54:54.120
Exactly.

00:54:54.120 --> 00:54:54.120
Yeah.

00:54:54.120 --> 00:54:55.120
Okay.

00:54:55.120 --> 00:54:58.120
What about this loop optimizations, this opt/noop?

00:54:58.120 --> 00:55:00.120
Yeah, that's, that's a good thing.

00:55:00.120 --> 00:55:01.120
Yeah, that's, that's...

00:55:01.120 --> 00:55:03.120
What kind of magic is in there?

00:55:03.120 --> 00:55:16.120
Uh, that's a bit complicated, meaning that, so I think like writing Runyon was like super helpful for me, at least to understand like the internals of Async KO in the Python world.

00:55:16.120 --> 00:55:23.120
And if I have to be honest, I don't really like how Async KO is implemented behind Hoot.

00:55:23.120 --> 00:55:24.120
But anyway.

00:55:24.120 --> 00:55:29.120
Yeah, I feel like you have to juggle, you have to be so aware of what loop is running.

00:55:29.120 --> 00:55:30.120
Has a loop been created?

00:55:30.120 --> 00:55:31.120
Is there a different one?

00:55:31.120 --> 00:55:32.120
Is there a different one?

00:55:32.120 --> 00:55:33.120
Have I got the wrong loop?

00:55:33.120 --> 00:55:36.120
Like all of that stuff, it should be utterly transparent.

00:55:36.120 --> 00:55:39.120
And I just, I should just tell Python, I want to run stuff in a loop.

00:55:39.120 --> 00:55:40.120
Yeah.

00:55:40.120 --> 00:55:46.120
You know, I don't want to, it's not like I'm managing the memory or juggling, you know, the GC.

00:55:46.120 --> 00:55:48.120
Like I feel like Async IO should be the same.

00:55:48.120 --> 00:55:50.120
You should say, I want to run stuff asynchronously.

00:55:50.120 --> 00:56:07.120
And maybe somewhere I've configured that or maybe it's automatic or whatever, but just do any, you're always kind of like, you know, for example, if you talk to the database asynchronously at the start of your web app, and then you use FastAPI and you try to use it in your request there, it'll say, well, you're on the wrong event loop.

00:56:07.120 --> 00:56:09.120
Like, well, why do I care about this?

00:56:09.120 --> 00:56:11.120
Just run it on the loop.

00:56:11.120 --> 00:56:12.120
Like, you know what I mean?

00:56:12.120 --> 00:56:15.120
Like that's kind of, that's been a complaint of mine since 3.5, but hey.

00:56:15.120 --> 00:56:16.120
Yeah.

00:56:16.120 --> 00:56:17.120
Yeah.

00:56:17.120 --> 00:56:18.120
Nobody asked me, so.

00:56:18.120 --> 00:56:19.120
Yeah.

00:56:19.120 --> 00:56:20.120
So yeah.

00:56:20.120 --> 00:56:25.120
And those, let's say optimizations are actually a few hockey parts.

00:56:25.120 --> 00:56:33.120
In fact, like, I think like FastAPI doesn't work with loop optimization enabled with Granian because it skips.

00:56:33.120 --> 00:56:39.120
So those optimization just keeps like one of the first iterations into running asynchronous code.

00:56:39.120 --> 00:56:43.120
I think going more deeper than this in details would be.

00:56:43.120 --> 00:56:44.120
Yeah.

00:56:44.120 --> 00:56:45.120
Yeah.

00:56:45.120 --> 00:56:46.120
Okay.

00:56:46.120 --> 00:56:47.120
Not, not worth it, right?

00:56:47.120 --> 00:56:48.120
Long and hard to follow.

00:56:48.120 --> 00:56:52.120
But let's just say it just keeps some steps in the task running in the other one.

00:56:52.120 --> 00:56:53.120
Yeah.

00:56:53.120 --> 00:56:54.120
Okay.

00:56:54.120 --> 00:56:56.120
You can do things like specify the SSL certificates and stuff.

00:56:56.120 --> 00:56:57.120
This one right here is pretty excellent.

00:56:57.120 --> 00:57:04.120
I mean, I don't know who worked on that one, but I didn't work out, but I inspired, I requested this one as the right way to put that.

00:57:04.120 --> 00:57:06.120
You can say the process name, which is nice.

00:57:06.120 --> 00:57:07.120
Yeah.

00:57:07.120 --> 00:57:08.120
Yeah.

00:57:08.120 --> 00:57:11.120
If you're running multiple sites, all on Granian on the same server.

00:57:11.120 --> 00:57:14.120
You can differentiate which one is using the memory again.

00:57:14.120 --> 00:57:19.120
And while we're looking at this, can I ask, can I propose an idea and just get your feedback on it?

00:57:19.120 --> 00:57:20.120
Get your thoughts.

00:57:20.120 --> 00:57:32.120
What about a lifetime management type of feature where you say after 10,000 requests, just recreate the worker or after an hour recreate the worker or something like that?

00:57:32.120 --> 00:57:34.120
Is this something that is in any interest to you?

00:57:34.120 --> 00:57:49.120
I understand the need for that, especially for, I think it's like one of those requests that is based on the fact of using like Boosgi or at least like it's coming more from the jungle user land.

00:57:49.120 --> 00:58:10.120
So I think making a lifetime that kind of check would be kind of hard in a sense that there's a lot like involved into the, you know, process management of Granian because like, you know, the Python process and then you have Python threads and then you have like the rust threads and then you have like the runtimes.

00:58:10.120 --> 00:58:11.120
Yeah.

00:58:11.120 --> 00:58:14.120
And then reasoning of lifetime probably it's kind of hard.

00:58:14.120 --> 00:58:23.120
I think like the fixing, like a maximum number of requests per worker is something that can be done, let's say pretty easily.

00:58:23.120 --> 00:58:29.120
That issue is like, it's opened by, there's an issue for that, like opened by a few times, if I recall correctly.

00:58:29.120 --> 00:58:33.120
The thing is that like in the, let's say in the prioritization queue.

00:58:33.120 --> 00:58:34.120
It's not at the top.

00:58:34.120 --> 00:58:48.120
So let's say at the moment, like I'm talking with some people that propose their self to join as a contributor on Granian, but let's say at the moment I'm still like a single main contributor.

00:58:48.120 --> 00:58:49.120
So yeah, sure.

00:58:49.120 --> 00:58:53.120
I need to make, you know, some priority queues into issues.

00:58:53.120 --> 00:58:55.120
A look after your wellbeing.

00:58:55.120 --> 00:58:56.120
Yeah.

00:58:56.120 --> 00:58:57.120
Yeah.

00:58:57.120 --> 00:59:01.120
I think like the one which is more requested right now is like the access log.

00:59:01.120 --> 00:59:02.120
Yeah.

00:59:02.120 --> 00:59:06.120
So I think like that would be the next one probably.

00:59:06.120 --> 00:59:07.120
Yeah.

00:59:07.120 --> 00:59:10.120
I think honestly, that's more important of the access log than this one.

00:59:10.120 --> 00:59:11.120
Yeah.

00:59:11.120 --> 00:59:17.120
There's something changed in one of my apps and it just all of a sudden slowly just keeps growing in memory.

00:59:17.120 --> 00:59:21.120
And I'm pretty sure I've not done anything to make those changes.

00:59:21.120 --> 00:59:26.120
And it's something in a third party library, data access database or something else.

00:59:26.120 --> 00:59:30.120
I don't know what it is, but it's just, and it's fine, but it just consumes so much memory.

00:59:30.120 --> 00:59:38.120
And so I ended up setting up some other thing to just, just say, look after like a day, just, you know, just give it a refresh.

00:59:38.120 --> 00:59:39.120
Let it refresh itself.

00:59:39.120 --> 00:59:44.120
You know that we sent the SDK now we have also profiling.

00:59:44.120 --> 00:59:51.120
So you can actually look into the stocks of memory locations, even like live on your application.

00:59:51.120 --> 00:59:52.120
So that's true.

00:59:52.120 --> 00:59:57.120
If you need to that like something like that, you can try with century.

00:59:57.120 --> 00:59:59.120
Like distributed tracing or something like that.

00:59:59.120 --> 01:00:00.120
Yeah.

01:00:00.120 --> 01:00:01.120
Or the APM stuff.

01:00:01.120 --> 01:00:05.120
I mean, this should be dressing is more like about chaining together, like different sources.

01:00:05.120 --> 01:00:08.120
Like this is profiling, like.

01:00:08.120 --> 01:00:08.120
Yeah.

01:00:08.120 --> 01:00:09.120
Yeah.

01:00:09.120 --> 01:00:09.120
Okay.

01:00:09.120 --> 01:00:09.120
Yeah.

01:00:09.120 --> 01:00:13.120
Flame graphs and stuff to see where does your application.

01:00:13.120 --> 01:00:14.120
Maybe I'll put it in.

01:00:14.120 --> 01:00:15.120
Cause it's, it's driving me crazy.

01:00:15.120 --> 01:00:21.120
And I would love to just do a PR to somewhere and just go, Hey guys, this change, here's the problem.

01:00:21.120 --> 01:00:22.120
Or if it is my problem.

01:00:22.120 --> 01:00:27.120
And I just like, there's nothing I really changed in the core of this thing, but it seems to have started going weird that maybe I don't know.

01:00:27.120 --> 01:00:28.120
But anyway, it would be great.

01:00:28.120 --> 01:00:29.120
I'll have a look at it.

01:00:29.120 --> 01:00:30.120
Thanks.

01:00:30.120 --> 01:00:30.120
All right.

01:00:30.120 --> 01:00:31.120
What's next for Grandin?

01:00:31.120 --> 01:00:32.120
Yeah.

01:00:32.120 --> 01:00:43.120
I think like fulfilling a couple of feature requests, like the access log, like the worker max requests or a few, let's say minor things in that sense.

01:00:43.120 --> 01:01:07.120
I think like in terms of major features, it's pretty solid at the moment, as a server after let's say the idea is like after these feature requests, the idea was to, I mean, it's just an idea at the moment, but I'd like to try to add some features to the RSGI protocol.

01:01:07.120 --> 01:01:12.120
So for example, we talked before about channels and web sockets.

01:01:12.120 --> 01:01:26.120
So as I said before, like I find very annoying, like every time I want to make even just a chat room, I need to, you know, put red is there and manage red is and whatever.

01:01:26.120 --> 01:01:30.120
And not like that kind of complexity to my project.

01:01:30.120 --> 01:01:42.120
And so I was thinking about like embedding some broadcasting features into the RSGI protocol, because, you know, while all other servers for Python are written in Python.

01:01:42.120 --> 01:01:50.120
And so they're like still bound to, you know, the process paradigm of Python on the rough side of things.

01:01:50.120 --> 01:01:53.120
That's not true anymore. So, right. Yeah.

01:01:53.120 --> 01:02:01.120
It would be to have something to broadcast messages between processes and even different granular servers.

01:02:01.120 --> 01:02:02.120
So that's cool.

01:02:02.120 --> 01:02:03.120
Yeah.

01:02:03.120 --> 01:02:05.120
That's what I have on my table at the moment.

01:02:05.120 --> 01:02:07.120
All right. Well, excellent.

01:02:07.120 --> 01:02:08.120
And thanks for working on this.

01:02:08.120 --> 01:02:19.120
It's an excellent project and it's really cool to see like kind of the innovation, like you're saying just there, you know, if it's not in Python, if it could be in Rust, like what would we change that would make that, you know, more capable, even for us?

01:02:19.120 --> 01:02:21.120
More capable even for the Python people, right?

01:02:21.120 --> 01:02:43.120
Yeah, exactly. And I think it's like the, I think it's like the baseline philosophy or of people like Samuel Colvin with the Pydantic project, like to, you know, to try to empower Python, like the most keeping like the simplicity and the syntax we all love about Python.

01:02:43.120 --> 01:02:50.120
But I think it's like a very good way of evolving even the Python language.

01:02:50.120 --> 01:03:04.120
Yeah, absolutely. You know, sometimes you'll hear people say Python is slow and then like in some sort of pure sense, that's true. But then, you know, you put it on top of things like gradient and all of a sudden it's awesome. Right. So thanks for playing your part in that.

01:03:04.120 --> 01:03:05.120
Thank you too.

01:03:05.120 --> 01:03:08.120
Yeah, you bet. And thanks for coming on the show. See you next time.

01:03:08.120 --> 01:03:09.120
Thank you. Bye.

01:03:09.120 --> 01:03:10.120
Bye.

01:03:10.120 --> 01:03:18.120
This has been another episode of Talk Python to Me. Thank you to our sponsors. Be sure to check out what they're offering. It really helps support the show.

01:03:18.120 --> 01:03:37.120
It's time to stop asking relational databases to do more than they were made for and simplify complex data models with graphs. Check out the sample FastAPI project and see what Neo4j native graph database can do for you. Find out more at talkpython.fm/Neo4j.

01:03:37.120 --> 01:03:54.120
Want to level up your Python? We have one of the largest catalogs of Python video courses over at Talk Python. Our content ranges from true beginners to deeply advanced topics like memory and async. And best of all, there's not a subscription in sight. Check it out for yourself at training.talkpython.fm.

01:03:54.120 --> 01:04:09.120
Be sure to subscribe to the show. Open your favorite podcast app and search for Python. We should be right at the top. You can also find the iTunes feed at /itunes, the Google Play feed at /play and the direct RSS feed at /rss on talkpython.fm.

01:04:09.120 --> 01:04:20.120
We're live streaming most of our recordings these days. If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:04:20.120 --> 01:04:26.560
This is your host, Michael Kennedy. Thanks so much for listening. I really appreciate it. Now get out there and write some Python code.

01:04:26.560 --> 01:04:48.000
I'll see you next time.

