WEBVTT

00:00:00.001 --> 00:00:04.380
So you've created a web app using Flask, Django, FastAPI, or even Emmet.

00:00:04.380 --> 00:00:06.240
It works great on your machine.

00:00:06.240 --> 00:00:07.980
How do you get it out to the world?

00:00:07.980 --> 00:00:09.840
Well, you'll need a production ready web server.

00:00:09.840 --> 00:00:14.420
Of course, on this episode, we have Giovanni Barriari to tell us about his

00:00:14.420 --> 00:00:17.060
relatively new server named Grianian.

00:00:17.060 --> 00:00:22.040
It promises better performance and much better consistency than many of

00:00:22.040 --> 00:00:23.420
the more well-known ones today.

00:00:23.420 --> 00:00:26.640
This is Talk Python to Me, episode 463.

00:00:27.640 --> 00:00:29.440
Are you ready for your host, Darius?

00:00:29.440 --> 00:00:33.080
You're listening to Michael Kennedy on Talk Python to Me.

00:00:33.080 --> 00:00:36.800
Live from Portland, Oregon, and this segment was made with Python.

00:00:36.800 --> 00:00:43.600
Welcome to Talk Python to Me, a weekly podcast on Python.

00:00:43.600 --> 00:00:45.260
This is your host, Michael Kennedy.

00:00:45.260 --> 00:00:48.400
Follow me on Mastodon, where I'm @mkennedy, and follow the

00:00:48.400 --> 00:00:52.680
podcast using @talkpython, both on fosstodon.org.

00:00:53.100 --> 00:00:57.780
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:57.780 --> 00:01:01.580
We've started streaming most of our episodes live on YouTube.

00:01:01.580 --> 00:01:06.340
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified

00:01:06.340 --> 00:01:09.140
about upcoming shows and be part of that episode.

00:01:09.140 --> 00:01:11.940
This episode is sponsored by Neo4j.

00:01:11.940 --> 00:01:16.420
It's time to stop asking relational databases to do more than they were made

00:01:16.420 --> 00:01:22.360
for and simplify complex data models with graphs, check out the sample FastAPI

00:01:22.360 --> 00:01:26.740
project and see what Neo4j, a native graph database, can do for you.

00:01:26.740 --> 00:01:31.260
Find out more at talkpython.fm/neo4j.

00:01:31.260 --> 00:01:35.740
And it's also brought to you by us over at Talk Python Training.

00:01:35.740 --> 00:01:40.460
Did you know that we have over 250 hours of Python courses?

00:01:40.460 --> 00:01:41.500
Yeah, that's right.

00:01:41.500 --> 00:01:44.180
Check them out at talkpython.fm/courses.

00:01:44.180 --> 00:01:48.500
In fact, I want to tell you about our latest course we just released last week,

00:01:48.500 --> 00:01:51.260
Getting Started with NLP and Spacy.

00:01:51.620 --> 00:01:53.720
This one is written by Vincent Wormerdam.

00:01:53.720 --> 00:01:58.100
You may know him from many of his educational projects and channels, but

00:01:58.100 --> 00:02:03.540
he also worked at Explosion AI, the makers of Spacy, so it's safe to say he knows

00:02:03.540 --> 00:02:05.800
his stuff when it comes to NLP and Spacy.

00:02:05.800 --> 00:02:10.860
If you have text you need to analyze, pull entities from, understand the

00:02:10.860 --> 00:02:14.840
sentiment, and so much more, then Spacy is one of the best frameworks out there for

00:02:14.840 --> 00:02:15.160
this.

00:02:15.160 --> 00:02:20.100
And now we have an awesome course you can use to get way better at NLP.

00:02:20.560 --> 00:02:22.880
During the course, you need a fun project, right?

00:02:22.880 --> 00:02:27.440
Well, Vincent uses the past nine years of Talk Python transcripts, along with a few

00:02:27.440 --> 00:02:33.340
data science programming bits of magic, to process them all with Spacy and ask

00:02:33.340 --> 00:02:37.380
awesome questions like, "Which frameworks are we talking about over the years?"

00:02:37.380 --> 00:02:40.840
Sign up for the course at talkpython.fm/spacy.

00:02:40.840 --> 00:02:46.460
And if you hurry and get it in the month of May, 2024, we're doing a special 10%

00:02:46.460 --> 00:02:47.840
off to celebrate the launch.

00:02:47.840 --> 00:02:50.280
That's talkpython.fm/spacy.

00:02:50.700 --> 00:02:52.420
The link is in your podcast player show notes.

00:02:52.420 --> 00:02:53.580
Enjoy the course.

00:02:53.580 --> 00:02:54.980
Now onto that interview.

00:02:54.980 --> 00:02:57.660
Giovanni, welcome to Talk Python.

00:02:57.660 --> 00:02:58.880
Hello, Michael.

00:02:58.880 --> 00:03:00.860
Thank you for having me on the show.

00:03:00.860 --> 00:03:02.020
It's great to have you on the show.

00:03:02.020 --> 00:03:07.420
Some people you learn about just from like their public speaking or their writing,

00:03:07.420 --> 00:03:09.660
and other people you meet through their projects, right?

00:03:09.660 --> 00:03:15.740
I got to know you through Granian, your Rust-based Python and other thing, web

00:03:15.740 --> 00:03:17.260
server, that I thought was really awesome.

00:03:17.260 --> 00:03:20.860
Started playing with it and we started talking on GitHub around some ideas.

00:03:20.860 --> 00:03:23.820
And then here you are, sort of explored more, learn more about some of your

00:03:23.820 --> 00:03:25.540
frameworks that like you'd created from.

00:03:25.540 --> 00:03:29.560
So I'm excited to talk about Emmet, Granian, and a bunch of other things that

00:03:29.560 --> 00:03:32.340
you built, like kind of all to go together in a big mix there.

00:03:32.340 --> 00:03:33.860
Yeah, I'm excited as well.

00:03:33.860 --> 00:03:34.880
Yeah, it should be a lot of fun.

00:03:34.880 --> 00:03:38.660
Before we get into all the details of all that stuff, you know, just

00:03:38.660 --> 00:03:39.860
tell us a bit about yourself.

00:03:39.860 --> 00:03:41.100
I'm Giovanni Barillari.

00:03:41.340 --> 00:03:47.220
I actually born in Italy, but today I'm living in Vienna, in Austria.

00:03:47.220 --> 00:03:49.140
I'm actually a physicist.

00:03:49.140 --> 00:03:51.780
So yeah, I graduated in physics at the university.

00:03:51.780 --> 00:03:58.700
And let's say I started working as a software engineer, focused especially

00:03:58.700 --> 00:04:02.180
on web software pretty soon after the university.

00:04:02.180 --> 00:04:04.920
So it's like 10 years something.

00:04:04.920 --> 00:04:09.880
I'm working as a software engineer, also like as a cipher diabetes engineer.

00:04:09.880 --> 00:04:16.900
So let's just say I'm quite like on the backend side of the things usually.

00:04:16.900 --> 00:04:23.980
And I also started, I actually started like contributing to open source software

00:04:23.980 --> 00:04:29.500
projects, even before actually starting working as a software engineer.

00:04:29.500 --> 00:04:33.940
And particularly I started like contributing to the Web2Py project.

00:04:33.940 --> 00:04:38.140
It's a quite old project by Massimo Di Piero.

00:04:38.260 --> 00:04:42.680
And yeah, today I'm working as a cipher diabetes engineer for Sentry.

00:04:42.680 --> 00:04:47.720
I bet that pretty much of the people know about Sentry.

00:04:47.720 --> 00:04:48.360
Awesome.

00:04:48.360 --> 00:04:48.600
Yeah.

00:04:48.600 --> 00:04:52.880
I didn't even know that you worked for Sentry until just a few minutes ago.

00:04:52.880 --> 00:04:53.720
That's pretty awesome.

00:04:53.720 --> 00:04:58.080
Obviously people know Sentry, they're big supporters of the show and sponsor

00:04:58.080 --> 00:05:00.480
some of the episodes, but yeah.

00:05:00.480 --> 00:05:02.080
How's it like to work at Sentry?

00:05:02.080 --> 00:05:02.920
Must be fun.

00:05:02.920 --> 00:05:04.960
Well, it's super nice.

00:05:04.960 --> 00:05:06.800
A lot of talented people.

00:05:06.920 --> 00:05:08.240
They're super nice.

00:05:08.240 --> 00:05:11.060
It's a really nice environment to be within.

00:05:11.060 --> 00:05:13.320
So yeah, I'm super happy.

00:05:13.320 --> 00:05:13.880
Yeah.

00:05:13.880 --> 00:05:14.420
Awesome.

00:05:14.420 --> 00:05:17.360
What does a software reliability engineer do?

00:05:17.360 --> 00:05:22.420
So let's say it might be a complicated question because like actually

00:05:22.420 --> 00:05:25.880
the original title comes from Google.

00:05:25.880 --> 00:05:33.340
So let's say is kind of related to infrastructure and

00:05:33.340 --> 00:05:34.840
monitoring in software.

00:05:34.840 --> 00:05:42.420
So let's say to simplify that it's about be sure that everything runs smoothly

00:05:42.420 --> 00:05:44.980
with no incidents and stuff like that.

00:05:44.980 --> 00:05:45.620
I see.

00:05:45.620 --> 00:05:50.620
Make sure you can monitor bugs, slowdowns, work on failover type of

00:05:50.620 --> 00:05:52.260
situations, that kind of stuff.

00:05:52.260 --> 00:05:53.060
Exactly.

00:05:53.060 --> 00:05:57.860
I imagine you probably use Sentry to monitor Sentry for reliability.

00:05:57.860 --> 00:05:59.140
Is that right?

00:05:59.140 --> 00:05:59.660
Yes.

00:05:59.660 --> 00:05:59.940
Yes.

00:05:59.940 --> 00:06:04.340
We have this project called Sentry for Sentry.

00:06:04.500 --> 00:06:04.960
Okay.

00:06:04.960 --> 00:06:10.980
Which is like a separated Sentry instance that monitors the actual SAS

00:06:10.980 --> 00:06:12.000
instance of Sentry.

00:06:12.000 --> 00:06:15.120
That's pretty interesting because of course, if Sentry went down, you're

00:06:15.120 --> 00:06:16.320
using it to monitor it.

00:06:16.320 --> 00:06:16.760
Yeah.

00:06:16.760 --> 00:06:19.160
Everyone else uses Sentry to monitor their thing.

00:06:19.160 --> 00:06:22.400
Then it's not about when their code goes down, it doesn't affect it.

00:06:22.400 --> 00:06:25.520
But when your code goes down, it might actually affect your ability to know

00:06:25.520 --> 00:06:26.200
that it's down.

00:06:26.200 --> 00:06:27.880
So a separate copy, that's wild.

00:06:27.880 --> 00:06:28.320
Okay.

00:06:28.320 --> 00:06:29.240
I hadn't even thought of that.

00:06:29.240 --> 00:06:30.080
Exactly.

00:06:30.080 --> 00:06:31.160
Super cool.

00:06:31.160 --> 00:06:31.480
All right.

00:06:31.540 --> 00:06:34.700
Now, first of all, there's a little bit of love out in the audience for your

00:06:34.700 --> 00:06:36.900
whole larger project, Emmet.

00:06:36.900 --> 00:06:39.380
So Tushar says, "Did you say Emmet?"

00:06:39.380 --> 00:06:42.020
Emmet is amazing, which is super cool.

00:06:42.020 --> 00:06:45.420
Tools like that encourage him to work on his dev tooling, which is really great.

00:06:45.420 --> 00:06:49.140
Before we get into the details of that though, why create another web framework?

00:06:49.140 --> 00:06:50.620
I don't mean this in a negative way.

00:06:50.620 --> 00:06:56.700
It's just like there's Flask and Django and then we have FastAPI and so on.

00:06:56.700 --> 00:06:58.860
So why not just go, "Oh, I'm just going to use this one."

00:06:58.860 --> 00:07:01.420
Like what inspired you to go, "I think I'll make one of them."

00:07:01.600 --> 00:07:08.280
So I think we should go back a bit in time because actually like this year will be

00:07:08.280 --> 00:07:11.280
like the 10th birthday of like Emmet.

00:07:11.280 --> 00:07:15.160
So let's just say it's like a long time.

00:07:15.160 --> 00:07:16.680
So it's not that new.

00:07:16.680 --> 00:07:17.200
Okay.

00:07:17.200 --> 00:07:17.960
Out there.

00:07:17.960 --> 00:07:19.680
Yeah.

00:07:19.680 --> 00:07:20.320
I see.

00:07:20.320 --> 00:07:20.920
Yeah.

00:07:20.920 --> 00:07:26.920
So originally it was released as, it had like a different name.

00:07:27.400 --> 00:07:34.740
It was called Wepi and I changed the name in 2020 I think, like with the, when I

00:07:34.740 --> 00:07:40.460
moved from synchronous paradigm to the asynchronous one.

00:07:40.460 --> 00:07:49.900
So let's say at the time I designed Wepi, so the original version in 2014, the main

00:07:49.900 --> 00:07:56.820
thing was about, so that time it was like the time of Ruby on Rails being super

00:07:56.820 --> 00:08:03.540
popular and I originally started working in web development using Ruby on Rails.

00:08:03.540 --> 00:08:09.740
And when comparing, let's say the amount of, let's say batteries included in the

00:08:09.740 --> 00:08:13.680
box of Ruby on Rails to the Python ecosystem.

00:08:13.680 --> 00:08:18.540
So let's say that the major competitor at that point in time was Django, but let's

00:08:18.540 --> 00:08:24.200
say the feeling I got from Django at that time compared to Ruby on Rails was completely

00:08:24.200 --> 00:08:31.600
different in a sense that I found myself like spending much more time on building

00:08:31.600 --> 00:08:33.920
stuff compared to Ruby on Rails.

00:08:33.920 --> 00:08:39.900
And this is also what bring me to the Web2Py project or to Py community, because

00:08:39.900 --> 00:08:46.040
it was in a sense, pretty similar in some of the design decisions with RAR.

00:08:46.040 --> 00:08:51.100
And, but at the same time, like once you start contributing to a web framework,

00:08:51.160 --> 00:08:56.200
you have time to like to dig into a lot of the internals and decisions.

00:08:56.200 --> 00:09:02.920
And so Web2Py at that time, so I used Web2Py to build my first, the code behind

00:09:02.920 --> 00:09:08.720
my first startup actually, and it had quite a lot of scaling issues at that time.

00:09:08.720 --> 00:09:15.240
So let's say at that point in time, I just was looking out for the options and I

00:09:15.240 --> 00:09:22.720
started like digging into the code internals of Django and also Flask, which, I mean, I

00:09:22.720 --> 00:09:30.120
really loved like the Flask approach of things, but at the same time it was so

00:09:30.120 --> 00:09:30.800
micro.

00:09:30.800 --> 00:09:31.200
Yeah.

00:09:31.200 --> 00:09:36.040
I mean, like to build an actual project, it required like to have like tons of

00:09:36.040 --> 00:09:40.880
extensions and other pieces, let's say other libraries to add it to the project

00:09:40.880 --> 00:09:45.600
that, yeah, I think like I ended up just, you know, saying, okay, let's just

00:09:45.600 --> 00:09:49.320
rebuild Web2Py the way I want it.

00:09:49.320 --> 00:09:54.320
And that's eventually how WebP came out and today Emmet.

00:09:54.320 --> 00:09:54.840
Yeah.

00:09:54.840 --> 00:09:56.440
That's pretty much the story behind it.

00:09:56.440 --> 00:09:56.920
Yeah.

00:09:56.920 --> 00:09:57.600
Okay.

00:09:57.600 --> 00:09:58.000
Yeah.

00:09:58.000 --> 00:09:59.280
I didn't realize it went that far back.

00:09:59.280 --> 00:10:00.280
How about Granian?

00:10:00.280 --> 00:10:01.160
Is that newer?

00:10:01.160 --> 00:10:01.600
Yeah.

00:10:01.600 --> 00:10:07.800
Granian is, I think like the first public release is like from one year ago or

00:10:07.800 --> 00:10:08.280
something.

00:10:08.280 --> 00:10:08.880
Yeah.

00:10:08.880 --> 00:10:12.440
And I, because I learned about Emmet through Granian and like, oh, it's kind

00:10:12.440 --> 00:10:14.160
of all, probably all the same project.

00:10:14.160 --> 00:10:15.520
I didn't realize the history.

00:10:15.520 --> 00:10:16.440
Why the new name?

00:10:16.440 --> 00:10:17.000
Why Emmet?

00:10:17.000 --> 00:10:23.960
So the thing was that to support, let's say the upgrade between WebP and Emmet.

00:10:23.960 --> 00:10:29.200
So since like all the interfaces has to be changed to support like async code,

00:10:29.200 --> 00:10:35.200
the idea was to provide, let's say a quick way to, to do that.

00:10:35.200 --> 00:10:40.440
Meaning that to make it possible for developers to, you know, install like a

00:10:40.440 --> 00:10:44.880
new version of WebP and getting like everything broken because of, you know,

00:10:44.880 --> 00:10:45.880
the new interfaces.

00:10:45.880 --> 00:10:51.400
So yeah, I just decided to, you know, changing the interface and also changing

00:10:51.400 --> 00:10:54.000
like the package name in order to say, sure.

00:10:54.000 --> 00:10:54.400
Okay.

00:10:54.400 --> 00:10:57.080
If you want to upgrade, you can upgrade safely.

00:10:57.080 --> 00:11:01.200
Otherwise, it's like a super mega version change.

00:11:01.200 --> 00:11:03.320
Not only do you change the version, but you change the name.

00:11:03.320 --> 00:11:04.240
Yeah.

00:11:04.240 --> 00:11:05.080
I see.

00:11:05.240 --> 00:11:05.760
Exactly.

00:11:05.760 --> 00:11:08.440
That's interesting.

00:11:08.440 --> 00:11:09.000
All right.

00:11:09.000 --> 00:11:11.000
Well, let's dive into it.

00:11:11.000 --> 00:11:15.440
So I like the title Emmet, the web framework for inventors.

00:11:15.440 --> 00:11:19.520
And yeah, maybe give us a sense of like, what are some of the core features of

00:11:19.520 --> 00:11:22.000
Emmet and what are your goals with building it?

00:11:22.000 --> 00:11:23.280
From an API perspective.

00:11:23.280 --> 00:11:28.320
The idea was to have like all in one, let's say framework to build web

00:11:28.320 --> 00:11:33.520
application, all in one, let's say in a sense of, again, when the project

00:11:33.520 --> 00:11:34.400
actually started.

00:11:34.440 --> 00:11:42.040
So like even 10 years after that, I still usually prefer to develop web

00:11:42.040 --> 00:11:46.160
projects without relying too much on front-end frameworks.

00:11:46.160 --> 00:11:50.520
So this is like a big, let's say a preamble to the thing.

00:11:50.520 --> 00:11:55.400
Like this is originally from an era where like front-end web framework

00:11:55.400 --> 00:11:56.200
didn't exist.

00:11:56.200 --> 00:12:01.080
Like, I think it was just AngularJS and maybe Ember at that time.

00:12:01.080 --> 00:12:01.520
Yeah.

00:12:01.760 --> 00:12:04.440
You're basically describing my life in 2024.

00:12:04.440 --> 00:12:07.560
So I'm a big fan of the server-side frameworks, you know?

00:12:07.560 --> 00:12:08.280
Thanks, Jack.

00:12:08.280 --> 00:12:08.800
Yeah.

00:12:08.800 --> 00:12:15.080
Also because like, it seems sometimes that we reinvent like a lot of stuff to catch

00:12:15.080 --> 00:12:16.920
up, like the beginning at the end.

00:12:16.920 --> 00:12:21.480
Like, yeah, I felt like all of the theme about, you know, server-side rendering

00:12:21.480 --> 00:12:26.080
with front-end frameworks and server-side render components and all that kind of

00:12:26.080 --> 00:12:26.280
stuff.

00:12:26.280 --> 00:12:30.880
So sometimes it just feels, you know, we're getting back to the origin.

00:12:31.120 --> 00:12:38.400
But yeah, so the idea behind Emmet is to have like all in one solution to develop

00:12:38.400 --> 00:12:39.600
web applications.

00:12:39.600 --> 00:12:43.640
So you have all the standard features you have with the web framework.

00:12:43.640 --> 00:12:48.040
So like routing and middlewares and that kind of stuff.

00:12:48.040 --> 00:12:55.480
You have an ORM, you have a templating system plus a few, let's say, tools

00:12:55.480 --> 00:12:56.520
embedded within.

00:12:56.520 --> 00:13:03.480
So for instance, it's very easy to use, I don't know, sessions or to have an

00:13:03.480 --> 00:13:04.880
authentication system.

00:13:04.880 --> 00:13:07.760
It's all like provided inside the box.

00:13:07.760 --> 00:13:13.480
So yeah, the idea was to have like, let's say a battery of tools, like in one place

00:13:13.480 --> 00:13:19.280
to do the most common things when you start developing a web application.

00:13:19.280 --> 00:13:20.200
Yeah, very nice.

00:13:20.200 --> 00:13:26.200
So yeah, like you said, it has an ORM built in and it feels, I guess, SQL

00:13:26.200 --> 00:13:29.400
alchemy-ish in a sense, but not exactly the same.

00:13:29.400 --> 00:13:33.800
Or Django ORM would be, you know, another way in some ways there.

00:13:33.800 --> 00:13:38.520
Yeah, I think it's more near to SQL alchemy in that sense.

00:13:38.520 --> 00:13:44.480
You tend to have like an API for using Python objects to build queries rather than

00:13:44.480 --> 00:13:52.280
how to say, use like a lot of strings attributes like you usually tends to do in

00:13:52.280 --> 00:13:52.840
Django.

00:13:53.040 --> 00:13:58.000
Yeah, I mean, it's more close to SQL alchemy in that sense.

00:13:58.000 --> 00:14:05.160
I think like the major difference with the ORMs out there is that the model class

00:14:05.160 --> 00:14:11.000
you define are not like, so when you, for example, select records from the database,

00:14:11.000 --> 00:14:16.400
the single, let's say rows you select are not instances of the model class.

00:14:16.400 --> 00:14:21.680
So let's say like the model class acts more like management class.

00:14:21.840 --> 00:14:23.960
Like a schema definition sort of thing.

00:14:23.960 --> 00:14:29.400
Yeah, I mean, it does like a lot of helpers top of that, but yeah, I think like

00:14:29.400 --> 00:14:34.280
it's definitely the major difference between like the vast majority of ORMs out

00:14:34.280 --> 00:14:38.720
there for Python when you usually have like the model class, which is also like

00:14:38.720 --> 00:14:42.880
the class of all the records you select and work on from the database.

00:14:42.880 --> 00:14:43.160
Yeah.

00:14:43.160 --> 00:14:45.400
So what do you get back in this world here?

00:14:45.400 --> 00:14:49.080
What do you get if you do a query, like in your example on the homepage, you have a

00:14:49.080 --> 00:14:50.200
time traveler.

00:14:50.240 --> 00:14:53.200
So what do you get back when you get a group of them, a set of them?

00:14:53.200 --> 00:14:55.880
So you get like a different class.

00:14:55.880 --> 00:14:58.200
So there's like a separated class.

00:14:58.200 --> 00:15:01.800
Every model has, it's called like row class.

00:15:01.800 --> 00:15:04.560
So it's an instance of that class.

00:15:04.560 --> 00:15:10.960
And this design, it's mostly made for two reasons.

00:15:10.960 --> 00:15:16.800
Like the first one is performance in a sense, meaning that when you select records

00:15:16.800 --> 00:15:23.240
or operate on records, it avoids to, you know, fulfill like all those objects with

00:15:23.240 --> 00:15:28.680
the actual model class attributes or functions or methods.

00:15:28.680 --> 00:15:30.960
And the validation and stuff.

00:15:30.960 --> 00:15:31.240
Yeah.

00:15:31.240 --> 00:15:31.720
Yeah.

00:15:31.720 --> 00:15:40.600
And on the other end was also to kind of remind to the developer that he is working

00:15:40.600 --> 00:15:46.000
with actual data from the database and not like real Python objects in a sense,

00:15:46.080 --> 00:15:47.360
which is, yeah.

00:15:47.360 --> 00:15:47.960
Yeah.

00:15:47.960 --> 00:15:54.760
I think like in the years is like the first reason why people tend to object against

00:15:54.760 --> 00:15:55.640
ORMs.

00:15:55.640 --> 00:15:59.880
So those two were the main reasons behind this design.

00:15:59.880 --> 00:16:04.720
It's something like, you know, in the between of an ORM and just some

00:16:04.720 --> 00:16:06.200
database abstraction layer.

00:16:06.200 --> 00:16:11.640
This portion of Talk Python to Me is brought to you by Neo4j.

00:16:11.640 --> 00:16:13.560
Do you know Neo4j?

00:16:13.880 --> 00:16:16.320
Neo4j is a native graph database.

00:16:16.320 --> 00:16:20.440
And if the slowest part of your data access patterns involves computing

00:16:20.440 --> 00:16:25.760
relationships, why not use a database that stores those relationships directly in the

00:16:25.760 --> 00:16:26.360
database?

00:16:26.360 --> 00:16:31.200
Unlike your typical relational one, a graph database lets you model the data the way it

00:16:31.200 --> 00:16:35.120
looks in the real world, instead of forcing it into rows and columns.

00:16:35.120 --> 00:16:39.760
It's time to stop asking a relational database to do more than they were made for

00:16:39.760 --> 00:16:42.760
and simplify complex data models with graphs.

00:16:43.560 --> 00:16:47.320
If you haven't used a graph database before, you might be wondering about common use

00:16:47.320 --> 00:16:47.760
cases.

00:16:47.760 --> 00:16:48.680
You know, what's it for?

00:16:48.680 --> 00:16:50.040
Here are just a few.

00:16:50.040 --> 00:16:56.800
Detecting fraud, enhancing AI, managing supply chains, gaining a 360 degree view of

00:16:56.800 --> 00:17:00.720
your data, and anywhere else you have highly connected data.

00:17:00.720 --> 00:17:06.200
To use Neo4j from Python, it's a simple pip install Neo4j.

00:17:06.200 --> 00:17:10.760
And to help you get started, their docs include a sample web app demonstrating how to

00:17:10.760 --> 00:17:13.440
use it both from Flask and FastAPI.

00:17:13.840 --> 00:17:18.240
Find it in their docs or search GitHub for Neo4j Movies Application Quickstart.

00:17:18.240 --> 00:17:22.520
Developers are solving some of the world's biggest problems with graphs.

00:17:22.520 --> 00:17:23.600
Now it's your turn.

00:17:23.600 --> 00:17:27.960
Visit talkpython.fm/neo4j to get started.

00:17:27.960 --> 00:17:32.920
That's talkpython.fm/neo, the number four, and the letter J.

00:17:32.920 --> 00:17:35.920
Thank you to Neo4j for supporting Talk Python To Me.

00:17:35.920 --> 00:17:39.400
I like the query syntax.

00:17:39.600 --> 00:17:44.120
You know, people visit the homepage, you'd see something like time travel dot where,

00:17:44.120 --> 00:17:47.960
then lambda of T goes to T dot return equal equal true.

00:17:47.960 --> 00:17:55.680
And while some of the ORMs let you write code in terms of like the class fields or

00:17:55.680 --> 00:18:00.200
whatever, it's never looked quite right because you're working with, say, the

00:18:00.200 --> 00:18:02.920
static value out of the class.

00:18:02.920 --> 00:18:07.440
Whereas what you really are trying to talk about is the instance level of the record,

00:18:07.440 --> 00:18:07.720
right?

00:18:07.720 --> 00:18:12.440
So instead of saying T, you'd say time travel dot return, but we'd never test that

00:18:12.440 --> 00:18:15.080
because it's the global value of it, right?

00:18:15.080 --> 00:18:15.760
And stuff like that.

00:18:15.760 --> 00:18:19.320
Or you just use strings, which is basically in my mind, no good.

00:18:19.320 --> 00:18:23.480
But what's cool, you know, also, do you want to do an OR or an AND?

00:18:23.480 --> 00:18:27.000
And then what weird thing do you import to do the OR?

00:18:27.000 --> 00:18:30.960
And like, you know, how do you wrap the query and all that kind of stuff where if

00:18:30.960 --> 00:18:33.960
it's a lambda, you can just express the conditions how you want.

00:18:33.960 --> 00:18:34.440
Yeah.

00:18:34.440 --> 00:18:34.800
Yeah.

00:18:34.840 --> 00:18:36.400
That's pretty much the idea.

00:18:36.400 --> 00:18:42.000
So like to use, you know, special methods from Python objects and translate those

00:18:42.000 --> 00:18:44.840
expression like in actually SQL code.

00:18:44.840 --> 00:18:45.760
So yeah.

00:18:45.760 --> 00:18:46.360
Nice.

00:18:46.360 --> 00:18:51.880
For my apps, I have a combination of Beanie and Mongo engine, depending on which one

00:18:51.880 --> 00:18:52.640
you're talking about.

00:18:52.640 --> 00:18:56.040
And for Mongo engine, you do things that are pretty funky.

00:18:56.040 --> 00:19:00.360
Like if you want to say greater than, you would say time travel dot, I don't know,

00:19:00.360 --> 00:19:01.400
it doesn't have a value, but age.

00:19:01.400 --> 00:19:07.880
I'll say there's an age, like time travel dot age, underscore, underscore GT equals

00:19:07.880 --> 00:19:08.680
value.

00:19:08.680 --> 00:19:12.440
And you're like, well, it's not, it's not equal to it.

00:19:12.440 --> 00:19:15.480
And it's not that that's not the name of it, but, but okay.

00:19:15.480 --> 00:19:17.120
That, I guess that means, you know what I mean?

00:19:17.120 --> 00:19:20.920
Like there's a real weird way it's like jammed into a syntax, whereas like here

00:19:20.920 --> 00:19:22.440
you just say greater than whatever.

00:19:22.440 --> 00:19:22.680
Right.

00:19:22.680 --> 00:19:23.240
Yeah.

00:19:23.240 --> 00:19:23.560
Yeah.

00:19:23.560 --> 00:19:29.640
It's like the same of, of it's one of the things I dislike still today of Django or

00:19:29.640 --> 00:19:31.240
Ram in that sense.

00:19:31.240 --> 00:19:36.760
I mean, it has like a lot of, a lot more capabilities because for instance, like

00:19:36.760 --> 00:19:43.440
when you want to represent like complex queries, it tends to be more powerful in

00:19:43.440 --> 00:19:46.960
that sense, meaning that special methods are limited.

00:19:46.960 --> 00:19:51.720
So at some point you start making custom methods.

00:19:51.720 --> 00:19:54.840
So like, I don't know, starts with, for example.

00:19:54.840 --> 00:19:55.120
Yeah.

00:19:55.120 --> 00:19:59.080
Starts with, or in this set or the set includes this and something like that.

00:19:59.080 --> 00:19:59.320
Right.

00:19:59.400 --> 00:20:00.080
Exactly.

00:20:00.080 --> 00:20:04.840
So I think, yeah, there are pros and cons in both, let's say approaches.

00:20:04.840 --> 00:20:05.160
Yeah.

00:20:05.160 --> 00:20:05.560
Cool.

00:20:05.560 --> 00:20:05.880
All right.

00:20:05.880 --> 00:20:08.920
So we have a lot to talk about, even though all this code fits on one screen.

00:20:08.920 --> 00:20:11.360
The other part is to define an endpoint.

00:20:11.360 --> 00:20:12.640
This is about an API, right?

00:20:12.640 --> 00:20:15.120
So you have an async def, which is awesome.

00:20:15.120 --> 00:20:16.920
Supports async and await.

00:20:16.920 --> 00:20:18.440
I think it's super valuable.

00:20:18.440 --> 00:20:18.880
Yeah.

00:20:18.880 --> 00:20:22.360
One note is that your Ram is still synchronous.

00:20:22.360 --> 00:20:22.840
Yeah.

00:20:22.840 --> 00:20:23.120
Yeah.

00:20:23.120 --> 00:20:25.440
So what about that?

00:20:25.440 --> 00:20:29.240
Are you planning on adding an async thing or are you just saying it's just synchronous?

00:20:29.400 --> 00:20:36.520
So it's like a very long story in a sense, because like I started asking myself the

00:20:36.520 --> 00:20:40.000
same question like several years ago.

00:20:40.000 --> 00:20:48.280
And I think like at some point probably I will end up doing that in the same way.

00:20:48.280 --> 00:20:50.280
SQLAlchemy did that.

00:20:50.280 --> 00:20:57.560
Even if I remember like a super nice blog post from the author of SQLAlchemy stating

00:20:57.560 --> 00:21:03.560
that asynchronous code and databases are not the best way to use that.

00:21:03.560 --> 00:21:09.360
So yeah, let's say like in the last few years I just waited in a way to see what

00:21:09.360 --> 00:21:10.680
everyone else was doing.

00:21:10.680 --> 00:21:16.560
But yeah, I think like at some point it will be inevitable in a sense.

00:21:16.560 --> 00:21:19.400
I just don't feel the time has come yet.

00:21:19.400 --> 00:21:20.560
So we'll see.

00:21:20.560 --> 00:21:20.960
Yeah.

00:21:20.960 --> 00:21:21.240
Cool.

00:21:21.240 --> 00:21:27.080
And then I guess the last thing to talk about is you have a decorated app.route.

00:21:27.400 --> 00:21:28.200
Pretty straightforward.

00:21:28.200 --> 00:21:28.640
Yeah.

00:21:28.640 --> 00:21:32.040
But then you also have a @service.json.

00:21:32.040 --> 00:21:33.280
What's the stacker to do?

00:21:33.280 --> 00:21:40.000
So you can think about that decorator like the service decorator as like the JSONify

00:21:40.000 --> 00:21:42.440
function in Flask.

00:21:42.440 --> 00:21:50.040
So yeah, in Emmet you have like both the JSON service and the XML service because like in

00:21:50.040 --> 00:21:55.800
old times I had to write stuff to talk with XML and points and stuff like that.

00:21:55.800 --> 00:21:56.040
So.

00:21:56.040 --> 00:21:56.560
Yeah.

00:21:56.560 --> 00:21:56.920
Yeah.

00:21:57.120 --> 00:22:03.000
So yeah, it's just an easy way to wrap and say everything that returns from this

00:22:03.000 --> 00:22:07.320
function, just serializing JSON or XML or whatever.

00:22:07.320 --> 00:22:12.200
If I return rather than a response, just return a dictionary and it'll do the

00:22:12.200 --> 00:22:13.040
serialization, right?

00:22:13.040 --> 00:22:13.840
Exactly.

00:22:13.840 --> 00:22:14.400
Nice.

00:22:14.400 --> 00:22:19.560
And the audience asks, does it generate an open API documentation?

00:22:19.560 --> 00:22:22.160
Like auto, does it automatically generate documentation?

00:22:22.160 --> 00:22:25.440
So from standard routes?

00:22:25.440 --> 00:22:26.240
No.

00:22:26.480 --> 00:22:33.680
There's an extension though, meaning that if you plan to design REST let's say

00:22:33.680 --> 00:22:37.200
APIs with Emmet, there's an extension for that.

00:22:37.200 --> 00:22:43.520
It's called Emmet REST, which let's say gives you like more tools to structure

00:22:43.520 --> 00:22:48.440
your routes and serialization and deserialization and all that kind of stuff.

00:22:48.440 --> 00:22:54.000
And that extension also brings open API documentation generation.

00:22:54.240 --> 00:22:58.760
Eventually let's say the open API documentation generation will come

00:22:58.760 --> 00:23:06.800
also to plain routes in Emmet, but there's quite a few design implied to do that.

00:23:06.800 --> 00:23:12.040
Meaning that so Emmet it's like not designed to have a strong type system

00:23:12.040 --> 00:23:15.920
because again, it comes from the days where like typing.

00:23:15.920 --> 00:23:17.000
That didn't exist.

00:23:17.000 --> 00:23:17.680
Was not.

00:23:17.680 --> 00:23:18.400
Yeah.

00:23:19.480 --> 00:23:23.920
So let's say that for instance, for frameworks like FastAPI, which are

00:23:23.920 --> 00:23:28.920
practically designed on top of something like Pydantic, so you have like a strong

00:23:28.920 --> 00:23:34.320
type system, so everything that comes in and out from the majority of routes you

00:23:34.320 --> 00:23:41.160
write has types and so it's really easy for the framework to inspect the code and

00:23:41.160 --> 00:23:42.560
understand what's going on.

00:23:42.560 --> 00:23:47.880
On let's say general frameworks like Emmet where you, I mean, you might have

00:23:47.880 --> 00:23:53.280
like, I don't know, HTML routes or other kinds of stuff going on.

00:23:53.280 --> 00:23:59.160
There's no, let's say design behind that to support in the first play, like strong

00:23:59.160 --> 00:23:59.720
typing.

00:23:59.720 --> 00:24:06.360
So yeah, making like open API documentation out of standard Emmet routes involves

00:24:06.360 --> 00:24:08.640
like quite a lot of decisions.

00:24:08.640 --> 00:24:09.600
So yeah, we'll see.

00:24:09.600 --> 00:24:10.160
We'll see.

00:24:10.160 --> 00:24:10.720
Yeah.

00:24:10.720 --> 00:24:11.120
Okay.

00:24:11.120 --> 00:24:11.520
Yeah.

00:24:11.520 --> 00:24:11.920
Very cool.

00:24:11.920 --> 00:24:12.640
Yeah.

00:24:12.640 --> 00:24:15.400
We'll come back and talk about Emmet REST in a minute.

00:24:15.400 --> 00:24:17.160
That's one of the fun things.

00:24:17.160 --> 00:24:19.080
It also has a WebSocket support, right?

00:24:19.080 --> 00:24:19.560
Yep.

00:24:19.560 --> 00:24:20.120
Okay.

00:24:20.120 --> 00:24:20.960
Absolutely.

00:24:20.960 --> 00:24:24.400
WebSockets are these things that I'm always like, man, they're so cool and you

00:24:24.400 --> 00:24:25.600
can do all this interesting stuff.

00:24:25.600 --> 00:24:29.880
And then I never, ever, ever have a use case for it in my world.

00:24:29.880 --> 00:24:30.960
I just haven't yet.

00:24:30.960 --> 00:24:33.800
And so I'm like, well, they're very cool, but I don't have it yet.

00:24:33.800 --> 00:24:34.280
Yeah.

00:24:34.280 --> 00:24:35.840
So, I mean, I'm not building Slack.

00:24:35.840 --> 00:24:36.360
Yeah.

00:24:36.360 --> 00:24:43.320
The thing is that usually like when you work with WebSockets, it's also pretty

00:24:43.560 --> 00:24:47.520
common that you need some broadcast facility.

00:24:47.520 --> 00:24:47.840
Yeah.

00:24:47.840 --> 00:24:55.160
So usually you want to do channels or that kind of stuff, which usually tends

00:24:55.160 --> 00:24:59.960
to involve like other software, like you usually have Redis or something like that

00:24:59.960 --> 00:25:05.600
to, in order to, since Python is not exactly good in, let's say, managing

00:25:05.600 --> 00:25:10.880
threads or communicating across different processes, that's probably why it's not

00:25:10.880 --> 00:25:14.720
so easy in the Python world to actually rely on WebSockets a lot.

00:25:14.720 --> 00:25:17.600
I don't know, for instance, if you take like languages like, I don't know,

00:25:17.600 --> 00:25:23.880
Elixir or you have like tons of stuff based on the fact that everything is

00:25:23.880 --> 00:25:26.240
actually communicating over Socket.

00:25:26.240 --> 00:25:27.360
So, yeah.

00:25:27.360 --> 00:25:35.040
And I think like one single thing to say on WebSockets, it's, I think EMMET is

00:25:35.160 --> 00:25:40.960
the only, or one of the few frameworks that allows you to write middlewares with

00:25:40.960 --> 00:25:45.760
Sockets, so you can, so if you have like your chain of middlewares on the

00:25:45.760 --> 00:25:51.000
application, you can also define behaviors for the same middlewares to behave on

00:25:51.000 --> 00:25:51.720
WebSockets.

00:25:51.720 --> 00:25:54.480
So you can probably reuse like a lot of code.

00:25:54.480 --> 00:25:58.880
Like, I don't know if you are in a WebSocket and need to talk with the

00:25:58.880 --> 00:26:03.840
database, you can use the same middleware for the database connection you use on

00:26:03.840 --> 00:26:05.080
the standard request.

00:26:05.080 --> 00:26:08.080
So I think that's might be worth noting.

00:26:08.080 --> 00:26:09.440
Yeah, absolutely.

00:26:09.440 --> 00:26:13.840
Another thing that's interesting that I don't see in a lot of ORMs, they kind of

00:26:13.840 --> 00:26:18.640
just leave it to the, well, in SQL, so you write it, is aggregation, right?

00:26:18.640 --> 00:26:23.600
The aggregation stuff you have here is pretty interesting where you do a bunch

00:26:23.600 --> 00:26:27.880
of calculation type stuff in the database and then get a, sort of the results back.

00:26:27.880 --> 00:26:28.120
Right?

00:26:28.120 --> 00:26:32.120
So here you can say like, select, I'm talking about an event, like event.location,

00:26:32.320 --> 00:26:36.920
get the counts and then group by this thing, order by that, having these sort of

00:26:36.920 --> 00:26:37.320
properties.

00:26:37.320 --> 00:26:38.760
That's, that's pretty unique.

00:26:38.760 --> 00:26:40.040
I don't see that in a lot of ORMs.

00:26:40.040 --> 00:26:45.200
Yeah, I think like you can do pretty much the same with the SQL alchemy, but

00:26:45.200 --> 00:26:49.200
probably like the syntax is less sugary, let's say.

00:26:49.200 --> 00:26:55.720
I mean, again, this design comes from the fact that with my first startup, we had to

00:26:55.720 --> 00:26:58.120
do like a lot of aggregation over the database.

00:26:58.120 --> 00:27:01.480
And so that's why I wrote all of that, you know.

00:27:01.960 --> 00:27:02.760
Yeah, that's cool.

00:27:02.760 --> 00:27:05.280
Yeah.

00:27:05.280 --> 00:27:05.600
Nice.

00:27:05.600 --> 00:27:08.800
I, you know, I'm familiar with it from all the MongoDB stuff that I've done,

00:27:08.800 --> 00:27:11.640
that like that, the big aggregation pipeline over there as well.

00:27:11.640 --> 00:27:12.320
Yeah.

00:27:12.320 --> 00:27:18.280
I'm also familiar, like I'm not a huge fan of Mongo though, probably because like

00:27:18.280 --> 00:27:23.680
being an SRE, like making Mongo reliable is like a mess sometimes.

00:27:23.680 --> 00:27:26.840
So I think it depends on how people rely on it.

00:27:26.840 --> 00:27:27.600
Right.

00:27:27.600 --> 00:27:28.200
Yeah.

00:27:28.200 --> 00:27:31.440
For me, it's been absolutely, I've run my stuff on over 10 years and it's been

00:27:31.640 --> 00:27:36.760
perfect, however, that's because I use a lot of structured code to talk to Mongo

00:27:36.760 --> 00:27:38.920
from one tech stack, right?

00:27:38.920 --> 00:27:42.840
But if some people are using dictionaries to talk to it, other people using this

00:27:42.840 --> 00:27:47.720
framework, other people using that framework, then the lack of the schema

00:27:47.720 --> 00:27:49.960
structure, I think becomes a problem.

00:27:49.960 --> 00:27:53.640
So I think it really depends on how you use it, but yeah, I hear what you're

00:27:53.640 --> 00:27:54.400
saying for sure.

00:27:54.400 --> 00:27:56.920
I think that that's not even necessarily a Mongo challenge.

00:27:56.920 --> 00:27:59.320
That's a document database challenge generally, right?

00:27:59.320 --> 00:28:00.040
Yeah.

00:28:00.240 --> 00:28:03.320
Just Mongo is primarily the way people do document databases.

00:28:03.320 --> 00:28:03.920
Yeah.

00:28:03.920 --> 00:28:07.400
I tended to like use it for separate stuff.

00:28:07.400 --> 00:28:11.760
So in several projects I worked on, I had like, for instance, like the main

00:28:11.760 --> 00:28:16.000
database with Oscars, for instance, like another database with Mongo for specific

00:28:16.000 --> 00:28:20.360
stuff, maybe stuff you don't need transactions on, or maybe you want to

00:28:20.360 --> 00:28:24.320
store like time series data or, you know, that kind of stuff.

00:28:24.320 --> 00:28:26.240
So for that, I think it's really cool.

00:28:26.240 --> 00:28:26.560
Yeah.

00:28:26.560 --> 00:28:26.840
Nice.

00:28:26.840 --> 00:28:27.360
All right.

00:28:27.400 --> 00:28:32.120
I guess one final thing here that is worth covering, then we'll, I want to dive

00:28:32.120 --> 00:28:35.880
into a gradient as well as the template syntax.

00:28:35.880 --> 00:28:37.880
So you've got your own template syntax.

00:28:37.880 --> 00:28:40.600
That's kind of like, that's not a syntax.

00:28:40.600 --> 00:28:43.960
You tell people about it.

00:28:43.960 --> 00:28:44.600
You tell them about it.

00:28:44.600 --> 00:28:45.240
Yeah.

00:28:45.240 --> 00:28:49.600
So the inflating system embedded in Emmet is called Renoir.

00:28:49.600 --> 00:28:56.160
And the idea behind it is to don't have a syntax at all.

00:28:56.160 --> 00:29:01.200
So the, the idea behind Emmet template system was why?

00:29:01.200 --> 00:29:07.520
So the question I had is like, why do I have to learn a new language to write

00:29:07.520 --> 00:29:09.440
server-side rendered templates?

00:29:09.440 --> 00:29:10.440
Like why came out?

00:29:10.440 --> 00:29:10.840
Yeah.

00:29:10.840 --> 00:29:12.400
And those languages are, yeah.

00:29:12.400 --> 00:29:15.160
And they're very, very Python like, but they're not Python.

00:29:15.160 --> 00:29:15.760
Exactly.

00:29:15.760 --> 00:29:22.640
So I just said, well, I guess I'll try to do just Python, you know, wrap it in the

00:29:22.640 --> 00:29:25.920
same brackets every other templating language has.

00:29:26.040 --> 00:29:27.880
So it's just plain Python.

00:29:27.880 --> 00:29:31.400
You can do pretty much everything you can do in Python.

00:29:31.400 --> 00:29:34.000
You can even do imports inside.

00:29:34.000 --> 00:29:37.720
Not that I suggest to do that, but you can still, you can do that.

00:29:37.720 --> 00:29:40.600
Are you, you'll go create PHP people.

00:29:40.600 --> 00:29:41.120
Come on now.

00:29:41.120 --> 00:29:42.200
Exactly.

00:29:42.200 --> 00:29:47.880
The only, let's say major difference from standard Python code is that you have to

00:29:47.880 --> 00:29:52.560
write the pass keyword after a block of code.

00:29:52.560 --> 00:29:59.520
So if you write like a for loop or an if statement, the template engine has to know

00:29:59.520 --> 00:30:06.040
when that block ends, given that Python relies on indentation to understand like

00:30:06.040 --> 00:30:10.480
that, but in templates, you don't have like the same in the initial level you have in

00:30:10.480 --> 00:30:10.880
Python.

00:30:10.880 --> 00:30:17.760
So that's the only major difference from plain Python code, plus a few, let's say

00:30:17.760 --> 00:30:19.680
keyword added to the game.

00:30:19.840 --> 00:30:25.200
So you have extend and include in order to extend and include.

00:30:25.200 --> 00:30:29.640
So there are partial templates, let's say, and, and blocks.

00:30:29.640 --> 00:30:30.320
That's it.

00:30:30.320 --> 00:30:30.840
Right.

00:30:30.840 --> 00:30:33.200
Blocks for the layout sections, right?

00:30:33.200 --> 00:30:33.840
Exactly.

00:30:33.840 --> 00:30:34.160
Yeah.

00:30:34.160 --> 00:30:35.000
That's really nice.

00:30:35.000 --> 00:30:36.120
I like the idea.

00:30:36.120 --> 00:30:40.040
I'm sure there are people listening that'd be like, I would like to try this stuff out,

00:30:40.040 --> 00:30:48.520
but I've got 10,000 lines of Jinja or I've got 10,000 lines of chameleon or yeah.

00:30:48.520 --> 00:30:48.760
Yeah.

00:30:49.000 --> 00:30:49.360
I know.

00:30:49.360 --> 00:30:50.040
Whatever.

00:30:50.040 --> 00:30:51.080
What's the story?

00:30:51.080 --> 00:30:55.280
I mean, I'm working in the office with Armin Ronaker every day.

00:30:55.280 --> 00:30:59.920
So the amount of Jinja code we have in Sentry is like huge.

00:30:59.920 --> 00:31:03.480
So yeah, I perfectly understand the point.

00:31:03.480 --> 00:31:07.920
I don't have like, let's say marketing line for selling Renoir.

00:31:07.920 --> 00:31:15.440
It's just something that I, so today I'm so, I'm equitably familiar to, to Jinja

00:31:15.440 --> 00:31:17.400
templates and Renoir templates.

00:31:17.920 --> 00:31:24.480
I'd say it really depends on how you usually structure your application code.

00:31:24.480 --> 00:31:34.800
So I think one good way to try out for Renoir is if you tend to don't use a lot

00:31:34.800 --> 00:31:40.840
like Jinja filters or stuff like that, that might be a good case scenario to try

00:31:40.840 --> 00:31:42.320
it out Renoir.

00:31:42.320 --> 00:31:42.840
Yeah.

00:31:42.840 --> 00:31:46.200
But of course it has to be like a new project because.

00:31:46.200 --> 00:31:46.680
Yeah.

00:31:46.840 --> 00:31:51.640
Converting, I mean, there's no sense into moving, translating code from one

00:31:51.640 --> 00:31:53.200
system to another once you pick.

00:31:53.200 --> 00:31:54.720
It's not super different.

00:31:54.720 --> 00:32:00.640
I think you change an end if to a pass, for example, or end for into a pass.

00:32:00.640 --> 00:32:05.640
But I was thinking more, is there a way to use Jinja within Emmet?

00:32:05.640 --> 00:32:06.040
Right.

00:32:06.040 --> 00:32:07.200
Instead of using Renoir.

00:32:07.200 --> 00:32:12.480
I mean, there's no plain, there's no read extension for that.

00:32:12.640 --> 00:32:18.760
But I mean, if you create like a Jinja instance over the application, you can

00:32:18.760 --> 00:32:20.880
call it in your roots.

00:32:20.880 --> 00:32:23.000
You can even create a middleware for that.

00:32:23.000 --> 00:32:26.200
So I think it's pretty easy also to set up Emmet to work with Jinja.

00:32:26.200 --> 00:32:27.280
Yeah, I would think so.

00:32:27.280 --> 00:32:32.160
I created a chameleon FastAPI, which lets you basically put a decorator on FastAPI

00:32:32.160 --> 00:32:32.640
endpoints.

00:32:32.640 --> 00:32:36.160
And it does chameleon template rendering with the dictionary instead of rest

00:32:36.160 --> 00:32:36.560
endpoints.

00:32:36.560 --> 00:32:37.480
It wasn't that much.

00:32:37.480 --> 00:32:39.760
You basically just have to juggle it from behind.

00:32:39.760 --> 00:32:43.720
So I imagine you could probably, someone could create a Jinja decorator, like you

00:32:43.720 --> 00:32:47.600
have service.json, like a template.Jinja or whatever, something like that.

00:32:47.600 --> 00:32:47.840
Right?

00:32:47.840 --> 00:32:48.400
Probably.

00:32:48.400 --> 00:32:49.800
Yeah, yeah, absolutely.

00:32:49.800 --> 00:32:51.720
That said, I'm not a fan of Jinja.

00:32:51.720 --> 00:32:53.080
I think it's overly complicated.

00:32:53.080 --> 00:32:57.840
So I'm not encouraged, I'm not suggesting it, but the reality is, even as much as I've

00:32:57.840 --> 00:33:03.600
tried to fight against it, is that the majority of Python web HTML, dynamic HTML

00:33:03.600 --> 00:33:04.840
is done in Jinja these days.

00:33:04.840 --> 00:33:05.360
Right.

00:33:05.360 --> 00:33:05.760
Which.

00:33:05.760 --> 00:33:07.040
Yeah, probably true.

00:33:07.040 --> 00:33:07.480
Yeah.

00:33:07.600 --> 00:33:10.600
You kind of got to live in that, that space, even if you don't want to.

00:33:10.600 --> 00:33:11.160
All right.

00:33:11.160 --> 00:33:15.920
And let's talk about the thing that I opened and talked about at the opening is

00:33:15.920 --> 00:33:16.640
Granian.

00:33:16.640 --> 00:33:18.080
Where's Granian gone?

00:33:18.080 --> 00:33:18.760
There we go.

00:33:18.760 --> 00:33:24.480
So this is how, as I said, I got to learn about this framework and what you're doing

00:33:24.480 --> 00:33:26.160
and stuff with Granian.

00:33:26.160 --> 00:33:26.920
Tell us about Granian.

00:33:26.920 --> 00:33:31.160
And before, as a way to sort of kick this off, Cody, who I've had on the show before

00:33:31.160 --> 00:33:33.760
from Litestar says, thanks for the work on Granian.

00:33:33.760 --> 00:33:35.520
I've had an excellent time using it with Litestar.

00:33:35.520 --> 00:33:36.680
Litestar is also awesome.

00:33:36.680 --> 00:33:37.240
Yeah.

00:33:37.320 --> 00:33:38.040
Thanks to Cody.

00:33:38.040 --> 00:33:38.480
Yeah.

00:33:38.480 --> 00:33:39.120
So tell us about it.

00:33:39.120 --> 00:33:39.840
Yeah.

00:33:39.840 --> 00:33:47.200
So as the description suggests, it's just an HTTP server for Python application.

00:33:47.200 --> 00:33:56.080
So it does the same scope of a Uvicorn, G-Unicorn, Hypercorn and all that libraries.

00:33:56.080 --> 00:34:02.320
The main difference compared to every other HTTP server for Python application is that

00:34:02.320 --> 00:34:03.760
it's not written in Python.

00:34:03.760 --> 00:34:05.800
It's written in Rust.

00:34:06.080 --> 00:34:12.480
And it supports natively both BoozG and A-S-G-I.

00:34:12.480 --> 00:34:16.400
So both synchronous and asynchronous applications.

00:34:16.400 --> 00:34:22.040
Plus a new protocol I also wrote with Granian, which is called R-S-G-I.

00:34:22.040 --> 00:34:27.400
But the only existing framework using it that I am aware of is Emmet, indeed.

00:34:27.400 --> 00:34:28.000
Yeah.

00:34:28.000 --> 00:34:30.000
I think there's a lot of things that are nice about this.

00:34:30.040 --> 00:34:35.840
And I have actually most of the things, including Talk Python itself running on

00:34:35.840 --> 00:34:37.440
Granian, which is pretty cool.

00:34:37.440 --> 00:34:38.120
So.

00:34:38.120 --> 00:34:38.680
Cool.

00:34:38.680 --> 00:34:39.480
Yeah.

00:34:39.480 --> 00:34:40.320
Yeah, absolutely.

00:34:40.320 --> 00:34:43.360
So single correct HTTP implementation.

00:34:43.360 --> 00:34:44.000
Sounds awesome.

00:34:44.000 --> 00:34:47.600
Support for version one, two and three, I guess when it's ratified, right?

00:34:47.600 --> 00:34:48.000
Yeah.

00:34:48.000 --> 00:34:56.000
So HTTP/3, let's say since Granian is actually based on a Rust library, which is

00:34:56.000 --> 00:35:01.640
called Hyper, which is a super cool library, it's like vastly adopted, like

00:35:01.640 --> 00:35:07.200
everywhere in the world, like, I don't know how many thousands, hundreds of

00:35:07.200 --> 00:35:10.880
thousands of libraries in the Rust ecosystem use it.

00:35:10.880 --> 00:35:15.840
It is used in Cloudflare for a lot of their production systems.

00:35:15.840 --> 00:35:22.280
So super strong library, but yes, it doesn't yet support HTTP/3.

00:35:22.320 --> 00:35:29.160
So yeah, I guess when Hyper will support HTTP/3, that could be

00:35:29.160 --> 00:35:31.160
easily added those two Granian.

00:35:31.160 --> 00:35:31.640
Right.

00:35:31.640 --> 00:35:32.080
Right.

00:35:32.080 --> 00:35:32.480
That's cool.

00:35:32.480 --> 00:35:32.960
Yeah.

00:35:32.960 --> 00:35:36.480
With these things like GNU-Core, and you've then got to also integrate

00:35:36.480 --> 00:35:39.720
U-Vehicle and workers and you kind of have a lot of stuff at play, right?

00:35:39.720 --> 00:35:42.840
So here you've just got one thing, which is cool.

00:35:42.840 --> 00:35:43.320
Yeah.

00:35:43.320 --> 00:35:49.840
I mean, like I tended to find annoying the fact that if you want, like to squeeze

00:35:49.840 --> 00:35:56.440
out like performance out of U-Vehicle, you usually need to pile up different

00:35:56.440 --> 00:36:02.760
libraries together, like, Oh wait, I need to add the HTTP tools dependency.

00:36:02.760 --> 00:36:08.160
So it can use as like the C written parsers for HTTP.

00:36:08.160 --> 00:36:12.120
Oh wait, and probably I want some process management.

00:36:12.120 --> 00:36:14.200
So I need also a GNU-Core.

00:36:14.200 --> 00:36:14.640
Yeah.

00:36:14.640 --> 00:36:18.680
It's not super easy, like for starters, at least.

00:36:18.680 --> 00:36:19.200
Yeah.

00:36:19.440 --> 00:36:22.840
I guess maybe we should just set the stage a little bit for the people that

00:36:22.840 --> 00:36:26.600
don't live and breathe Python web deployment, apologies.

00:36:26.600 --> 00:36:31.880
So typically you would have something like Nginx or caddy that

00:36:31.880 --> 00:36:33.720
browser actually talks to.

00:36:33.720 --> 00:36:38.760
And then behind the scenes, you set up those, let's just say Nginx to when

00:36:38.760 --> 00:36:42.680
there's a request for a dynamic content or Python based content, as opposed

00:36:42.680 --> 00:36:47.280
to like a CSS file or something, then it will talk to this category of servers

00:36:47.320 --> 00:36:52.240
that then maybe is juggling multiple processes so that it can increase the

00:36:52.240 --> 00:36:54.920
scalability of your Python apps and stuff like that.

00:36:54.920 --> 00:36:55.160
Right.

00:36:55.160 --> 00:37:00.000
So Granian lives in that sort of bubble behind Nginx typically, right?

00:37:00.000 --> 00:37:00.960
Use it other ways?

00:37:00.960 --> 00:37:07.520
Yes and no, meaning that you can also deploy it like on the edge.

00:37:07.520 --> 00:37:14.440
So I think it really depends how your structure, let's say your code.

00:37:14.560 --> 00:37:21.240
So, so for instance, like for Vue applications, like in Django, we

00:37:21.240 --> 00:37:27.960
tend to, I mean, we open like offload, let's say static file serving to

00:37:27.960 --> 00:37:33.640
Nginx since we already have Nginx somewhere relying on some, you know,

00:37:33.640 --> 00:37:40.160
headers we sent to the response that Nginx actually parse and understand what to do.

00:37:40.360 --> 00:37:47.120
So in general, if you don't need that kind of optimization, let's say you can

00:37:47.120 --> 00:37:52.240
still use Granian like even on the edge, because I mean, it supports like SSL.

00:37:52.240 --> 00:37:54.800
It supports like HTTP2 directly.

00:37:54.800 --> 00:38:01.360
So, I mean, having Nginx above Granian makes sense only if you want to root

00:38:01.360 --> 00:38:05.440
something out of Granian and not, you know, serve it from Granian.

00:38:05.560 --> 00:38:11.440
But yeah, in general, I'd say that you can use it in both ways behind Nginx or

00:38:11.440 --> 00:38:15.960
not, up to the specific needs of the application, let's say.

00:38:15.960 --> 00:38:16.440
Yeah.

00:38:16.440 --> 00:38:23.240
I have one Nginx Docker server container handling like 15 different apps.

00:38:23.240 --> 00:38:29.640
And so for me, that's kind of the setup, but typically the SSL that I do is over

00:38:29.640 --> 00:38:31.520
Let's Encrypt using Certbot.

00:38:31.520 --> 00:38:34.720
If I want to do HTTPS with Granian, how do I do it?

00:38:34.960 --> 00:38:40.440
You can keep like the Let's Encrypt and the ACME-SH generation thing because

00:38:40.440 --> 00:38:42.680
Granian supports the sigap signal.

00:38:42.680 --> 00:38:47.760
So whenever you need to refresh the certificate, you can issue a sigap to

00:38:47.760 --> 00:38:54.400
the Granian process and that process will reload the workers picking up the new

00:38:54.400 --> 00:38:55.320
certificate.

00:38:55.320 --> 00:38:57.680
So I think it's pretty straightforward.

00:38:57.680 --> 00:39:03.200
I mean, if you already manage like SSL certificates and like renewal chain and

00:39:03.200 --> 00:39:07.560
all that kind of stuff, it's pretty straightforward to do the same in

00:39:07.560 --> 00:39:08.120
Granian.

00:39:08.120 --> 00:39:14.280
You can just pass, you know, the paths to the certificates, to the CLI command or

00:39:14.280 --> 00:39:16.840
even use environment variables up to you.

00:39:16.840 --> 00:39:17.440
Gotcha.

00:39:17.440 --> 00:39:18.200
Okay.

00:39:18.200 --> 00:39:21.080
One thing that I thought was pretty interesting was the performance.

00:39:21.080 --> 00:39:27.320
Not necessarily that it's so, so, so much faster, but that it's so, so much more

00:39:27.320 --> 00:39:28.280
consistent.

00:39:28.280 --> 00:39:29.760
You want to talk about that a little bit?

00:39:30.000 --> 00:39:37.040
Yeah, so I think if you want to show to the YouTube, your audience, the

00:39:37.040 --> 00:39:41.480
comparison thing, you find the link in the bottom of the page because the first

00:39:41.480 --> 00:39:46.800
phase of benchmarks in the repository contains just benchmarks of Granian

00:39:46.800 --> 00:39:47.520
itself.

00:39:47.520 --> 00:39:52.640
Whereas in the versus page, you can find like comparison with other servers.

00:39:52.640 --> 00:39:59.720
So the thing behind, let's say the stable keyword I used into describing like

00:39:59.800 --> 00:40:05.000
the performance of Granian was about the fact that usually when people look at

00:40:05.000 --> 00:40:09.600
benchmarks, just look at the, you know, number of requests.

00:40:09.600 --> 00:40:10.760
Yeah, yeah, yeah, yeah.

00:40:10.760 --> 00:40:14.360
What's the max request per second you can get with this thing or whatever.

00:40:14.360 --> 00:40:15.600
Yeah, exactly.

00:40:15.600 --> 00:40:22.000
But the, another like very important value, at least to me, it's like the

00:40:22.000 --> 00:40:26.880
latency because you can, you can still serve like a lot of requests in parallel,

00:40:27.040 --> 00:40:32.360
but the amount of time each request will take to be served, it's also like

00:40:32.360 --> 00:40:32.840
important.

00:40:32.840 --> 00:40:36.800
I mean, I can serve like a thousand requests per second, but if those

00:40:36.800 --> 00:40:41.760
requests takes a second or it takes like 10 milliseconds, it's like a huge

00:40:41.760 --> 00:40:43.480
difference for the end user.

00:40:43.480 --> 00:40:44.000
Yeah.

00:40:44.000 --> 00:40:50.120
And so the thing is that from, from at least from benchmarks, it appears that

00:40:50.120 --> 00:40:56.600
the way Granian it works, which relies on having like all the network stack

00:40:56.600 --> 00:40:57.960
separated from Python.

00:40:57.960 --> 00:41:06.640
So all the IO, the real IO part involving the network communication is not tied to

00:41:06.640 --> 00:41:08.360
the Python interpreter.

00:41:08.360 --> 00:41:13.800
And so it doesn't suffer from the global interpreter lock and threats getting

00:41:13.800 --> 00:41:15.240
blocked between each other.

00:41:15.240 --> 00:41:22.840
It seems to make like Granian to be more, let's say predictable in response time,

00:41:22.920 --> 00:41:29.800
meaning that the, both the average latency and the maximum latency you have in the

00:41:29.800 --> 00:41:35.720
benchmarks is much lower compared to other, let's say implementations, other

00:41:35.720 --> 00:41:36.760
HTTP servers.

00:41:36.760 --> 00:41:39.760
So yeah, it's not like super faster.

00:41:39.760 --> 00:41:44.600
It won't make like, obviously it won't make the Python code of your application

00:41:44.600 --> 00:41:45.120
faster.

00:41:45.120 --> 00:41:49.600
We can shut down all of our servers, except for one $5 DigitalOcean server and

00:41:49.600 --> 00:41:49.880
just.

00:41:51.760 --> 00:41:57.440
Yeah, no, not really, but at least it should normalize in a way the response

00:41:57.440 --> 00:41:58.840
time of your application.

00:41:58.840 --> 00:42:00.000
Yeah.

00:42:00.000 --> 00:42:00.600
Yeah.

00:42:00.600 --> 00:42:05.200
So the standard deviation of the request time is way, way tighter.

00:42:05.200 --> 00:42:05.840
Exactly.

00:42:05.840 --> 00:42:09.560
The distribution of the request time is way, way tighter, even though you do seem

00:42:09.560 --> 00:42:11.840
to have generally the fastest times.

00:42:11.840 --> 00:42:17.520
But if you look at the difference of the average times and the max times, the

00:42:17.520 --> 00:42:19.640
difference is a lot smaller.

00:42:19.640 --> 00:42:24.920
It's like one, two and a half times variation versus some of the other ones

00:42:24.920 --> 00:42:25.720
are many.

00:42:25.720 --> 00:42:26.760
Yeah.

00:42:26.760 --> 00:42:27.880
10X or something.

00:42:27.880 --> 00:42:28.240
Yes.

00:42:28.240 --> 00:42:28.600
Yeah.

00:42:28.600 --> 00:42:29.880
Maybe a hundred X or some of them.

00:42:29.880 --> 00:42:30.280
Yeah.

00:42:30.280 --> 00:42:31.200
Yeah, absolutely.

00:42:31.200 --> 00:42:31.840
Okay.

00:42:31.840 --> 00:42:32.200
Yeah.

00:42:32.200 --> 00:42:35.320
That's what really I've thought was pretty interesting is the super

00:42:35.320 --> 00:42:37.120
predictability of it.

00:42:37.120 --> 00:42:37.720
Yeah.

00:42:37.720 --> 00:42:41.680
One thing I want to ask you about is you did say it does this RSGI.

00:42:41.680 --> 00:42:45.200
You want to call it G, GSGI, the granian server?

00:42:45.200 --> 00:42:45.920
No, whatever.

00:42:46.160 --> 00:42:49.600
No, it's like a RAS, RAS, RAS server gateway interface.

00:42:49.600 --> 00:42:51.600
Yeah.

00:42:51.600 --> 00:42:51.840
Yeah.

00:42:52.080 --> 00:42:53.120
That's, that's what I figured.

00:42:53.120 --> 00:42:56.280
And you said Emmet uses this, which is awesome.

00:42:56.280 --> 00:42:57.320
What's the advantage?

00:42:57.320 --> 00:43:00.760
Is there a significant advantage to doing things differently rather than

00:43:00.760 --> 00:43:02.040
ASGI or something?

00:43:02.040 --> 00:43:05.880
Would it be worth like things like Flask saying, Hey, should we support this if

00:43:05.880 --> 00:43:08.520
we're running on top of granian or things like that's what I'm getting at?

00:43:08.520 --> 00:43:13.320
So I didn't actually know if Flask today also supports a synchronous.

00:43:13.320 --> 00:43:14.800
With court they do.

00:43:14.920 --> 00:43:15.800
A request.

00:43:15.800 --> 00:43:16.160
I'm not.

00:43:16.160 --> 00:43:16.760
Yeah.

00:43:16.760 --> 00:43:17.400
Okay.

00:43:17.400 --> 00:43:22.600
So quartz might take advantage of RSCI, meaning that is still asynchronous

00:43:22.600 --> 00:43:27.480
protocols, so you have to be in an asynchronous context to use RSGI.

00:43:27.480 --> 00:43:36.400
But the main difference, let's say between ASGI and RSGI is that it's in the, how to

00:43:36.400 --> 00:43:42.080
say the communication mechanism, or let's say the communication entities, meaning

00:43:42.080 --> 00:43:49.040
that, so in ASGI you have usually have two methods, two awaitable methods, which

00:43:49.040 --> 00:43:56.680
are like send and receive, and you get or push, let's say dictionaries to, to those

00:43:56.680 --> 00:44:00.680
methods, which are referred as messages.

00:44:00.680 --> 00:44:07.080
So usually have like a dictionary, which has type key, which contains like the

00:44:07.080 --> 00:44:14.360
type of message, which might be, I don't know, HTTP request or HTTP body or web

00:44:14.360 --> 00:44:19.200
socket message and all the intercommunication between like the server

00:44:19.200 --> 00:44:24.800
and the application relies on those dictionaries with specific keys and strings.

00:44:24.800 --> 00:44:31.960
And since you have like a single, let's say interface to rely on that, and that

00:44:31.960 --> 00:44:36.680
interface is asynchronous, it also means you, it means two things.

00:44:36.920 --> 00:44:42.760
The first thing is that every time you want to say something to the server or to

00:44:42.760 --> 00:44:48.240
the clients, you have to await for that message, even if there's no actually

00:44:48.240 --> 00:44:51.160
IO involved in that operation.

00:44:51.160 --> 00:44:51.640
So,

00:44:51.640 --> 00:44:52.120
right.

00:44:52.120 --> 00:44:55.600
Which is a context switch and overhead and all of that stuff, right?

00:44:55.600 --> 00:44:56.440
Exactly.

00:44:56.440 --> 00:45:02.400
So for example, when you, so sending back a response in ASGI involves

00:45:02.400 --> 00:45:04.240
typically at least two messages.

00:45:04.240 --> 00:45:07.120
So the first one is to start the response.

00:45:07.120 --> 00:45:12.760
So you instruct the server with the response code and the headers you

00:45:12.760 --> 00:45:14.680
want to send back to the client.

00:45:14.680 --> 00:45:21.600
And the following message or messages are the body of that response.

00:45:21.600 --> 00:45:28.080
The fun fact is that the response start event doesn't involve any IO at all.

00:45:28.080 --> 00:45:29.560
It doesn't use the network.

00:45:29.560 --> 00:45:37.880
So what happens in that is that you delaying the operation that you are supposed

00:45:37.880 --> 00:45:43.720
to do, which is just saying, okay, I'm gonna send some data and these are the,

00:45:43.720 --> 00:45:45.200
like, here's some text.

00:45:45.200 --> 00:45:45.880
Yeah.

00:45:45.880 --> 00:45:48.760
You're going to delay that operation to the next cycle of the

00:45:48.760 --> 00:45:50.240
event loop in your Python code.

00:45:50.240 --> 00:45:53.680
So that adds quite a lot of overhead.

00:45:53.680 --> 00:45:57.960
And I mean, I understand like why the interface is made in this way, because

00:45:57.960 --> 00:46:02.240
it's like super straightforward, it's very simple, you have like the

00:46:02.240 --> 00:46:03.520
same interface to do everything.

00:46:03.520 --> 00:46:08.200
But at the same time, it feels very unperformant in a way because

00:46:08.200 --> 00:46:12.600
we are wasting like a ton of like, even, I don't understand why do we need

00:46:12.600 --> 00:46:17.880
like to waste event loop cycles to do something that is actually synchronous code.

00:46:17.880 --> 00:46:19.120
Yeah, sure.

00:46:19.120 --> 00:46:27.560
And so our SGI changed this in a way that you have interfaces which are

00:46:27.560 --> 00:46:32.000
synchronous or asynchronous, depending on what you're actually planning to do.

00:46:32.000 --> 00:46:37.880
For example, like if you have the entire body, so if your route returns, I

00:46:37.880 --> 00:46:43.080
don't know, a JSON stream, okay, you don't need to actually await for sending

00:46:43.080 --> 00:46:45.880
the body because you already have like all the bodies.

00:46:45.880 --> 00:46:47.480
So the interface in R.

00:46:47.480 --> 00:46:48.120
Right, right.

00:46:48.120 --> 00:46:48.960
It's all in memory.

00:46:48.960 --> 00:46:49.320
Yeah.

00:46:49.320 --> 00:46:49.960
There's no IO.

00:46:49.960 --> 00:46:50.480
Yeah.

00:46:50.480 --> 00:46:51.560
The interfacing.

00:46:51.560 --> 00:46:55.200
It's not like a file, file stream point or whatever they said to return.

00:46:55.200 --> 00:46:55.440
Yeah.

00:46:55.440 --> 00:46:56.120
Exactly.

00:46:56.120 --> 00:47:01.000
So in that case, in RSGI, you can use a synchronous method to just move the body

00:47:01.000 --> 00:47:03.920
to the server and just let the response goes.

00:47:03.920 --> 00:47:04.440
Nice.

00:47:04.440 --> 00:47:09.160
Whereas if you want to stream content, then you can use a specific interface

00:47:09.160 --> 00:47:11.320
for that in RSGI, which is RESTfulStream.

00:47:11.320 --> 00:47:17.200
And that gives you like an interface to send chunks of body or iterate over

00:47:17.200 --> 00:47:19.080
something as you're supposed to do.

00:47:19.080 --> 00:47:19.640
Oh, yeah.

00:47:19.640 --> 00:47:22.160
So that's the major thing.

00:47:22.160 --> 00:47:25.960
The other thing, like the other reason why RSGI exists is that.

00:47:25.960 --> 00:47:26.400
Yeah.

00:47:26.400 --> 00:47:32.920
ASGI is designed based on the fact that the network communication happens under

00:47:32.920 --> 00:47:38.920
Python, which is something that Granian can do because can emulate because it

00:47:38.920 --> 00:47:44.320
supports ASGI, but that also makes that also waste.

00:47:44.320 --> 00:47:49.080
So if you have the chance to have a different implementation that makes like

00:47:49.240 --> 00:47:54.840
things a lot more difficult to implement, meaning reasoning, like if you were in

00:47:54.840 --> 00:47:57.640
Python, but you're actually in a different language.

00:47:57.640 --> 00:48:00.760
So yeah, that's the other reason why RSGI exists.

00:48:00.760 --> 00:48:01.480
Okay.

00:48:01.480 --> 00:48:01.760
Yeah.

00:48:01.760 --> 00:48:02.480
That's very interesting.

00:48:02.480 --> 00:48:05.720
And maybe some of the other frameworks could look at that and go, well, if

00:48:05.720 --> 00:48:07.200
it's available, it's an option.

00:48:07.200 --> 00:48:07.880
Okay.

00:48:07.880 --> 00:48:11.160
A couple of things I want to talk about before we run out of time here.

00:48:11.160 --> 00:48:15.200
One is Jazzy Coder out in the audience asks, how did you validate your

00:48:15.200 --> 00:48:17.120
library following the correct spec?

00:48:17.320 --> 00:48:23.360
Did you reference the RFCs or another library or if you can use a go down

00:48:23.360 --> 00:48:28.000
back to principles of the Unix networking programming book and for a background

00:48:28.000 --> 00:48:30.920
interested in this approach, cause I'm building my own WSGI server.

00:48:30.920 --> 00:48:32.040
Okay, cool.

00:48:32.040 --> 00:48:37.920
So the idea, I mean, WSGI protocol is like documented in a PEP.

00:48:37.920 --> 00:48:45.800
So I just implemented tests that respect what is defined into the original PEP

00:48:46.000 --> 00:48:49.520
about WSGI with just an exception.

00:48:49.520 --> 00:48:58.200
So the only exception in for Granian in WSGI protocol is that it's able to serve

00:48:58.200 --> 00:49:03.880
HTTP/2 over WSGI, which is not supposed to happen, but with Granian you can serve

00:49:03.880 --> 00:49:06.280
your WSGI application directly with HTTP/2.

00:49:06.280 --> 00:49:11.680
But yeah, that's the way I was sure to respect the protocol.

00:49:11.680 --> 00:49:12.080
Yeah.

00:49:12.160 --> 00:49:14.320
How about like the HTTP/2 protocol?

00:49:14.320 --> 00:49:18.160
Are you using just a library that already has it all figured out or?

00:49:18.160 --> 00:49:18.840
Yes.

00:49:18.840 --> 00:49:19.200
Yes.

00:49:19.200 --> 00:49:23.880
I mean reinventing the wheel, like also for HTTP handling was

00:49:23.880 --> 00:49:25.760
something I wasn't looking for.

00:49:25.760 --> 00:49:27.360
No, I wouldn't want to do it either.

00:49:27.360 --> 00:49:28.040
So yeah.

00:49:28.040 --> 00:49:34.160
Hyper, hyper is again, super battle tested is used by, I don't know, something

00:49:34.160 --> 00:49:35.360
like Cloudflare in production.

00:49:35.360 --> 00:49:35.560
So.

00:49:35.560 --> 00:49:38.680
And this is a rest crate or something like that?

00:49:38.680 --> 00:49:39.600
Yeah, exactly.

00:49:39.600 --> 00:49:40.200
Awesome.

00:49:40.200 --> 00:49:40.600
All right.

00:49:40.600 --> 00:49:40.960
Very cool.

00:49:41.120 --> 00:49:45.880
The other thing I want to ask you about, or just let you speak to real quick is

00:49:45.880 --> 00:49:51.480
there's a bunch of features like specifying the HTTP interface level.

00:49:51.480 --> 00:49:53.680
Like, do you want to restrict it to one or two?

00:49:53.680 --> 00:49:59.280
Yeah, you might care because there was a vulnerability in HTTP/2 create like a,

00:49:59.280 --> 00:50:02.720
some kind of too much work or too many retries or something recently.

00:50:02.720 --> 00:50:04.240
So maybe you want to switch it to one for a while.

00:50:04.240 --> 00:50:04.680
I don't know.

00:50:04.680 --> 00:50:09.240
Fun fact, the Granian wasn't affected by that because hyper, the library behind

00:50:09.240 --> 00:50:11.080
it wasn't affected by that back.

00:50:11.080 --> 00:50:12.720
Oh, nice.

00:50:12.720 --> 00:50:13.280
That's awesome.

00:50:13.280 --> 00:50:14.400
Yeah.

00:50:14.400 --> 00:50:18.400
I figured basically you just, in this case, you wait until hyper either fixes

00:50:18.400 --> 00:50:19.840
it or hyper is not a problem, right.

00:50:19.840 --> 00:50:20.400
Which is great.

00:50:20.400 --> 00:50:23.560
But maybe just talk about some of the things that we haven't touched on that

00:50:23.560 --> 00:50:26.560
are interesting, like blocking threads or threading mode or, or

00:50:26.560 --> 00:50:28.240
specifying the loop or so on.

00:50:28.240 --> 00:50:30.720
So yeah, Granian.

00:50:30.720 --> 00:50:36.800
So since Granian has this unique architecture where you have an event

00:50:36.800 --> 00:50:38.440
loop running on the Rust side.

00:50:38.520 --> 00:50:42.800
So for instance, if you're like deploying your ASGI application with

00:50:42.800 --> 00:50:47.800
Granian, you will have two event loops, like the Python one, the ones that

00:50:47.800 --> 00:50:55.560
runs your code and also a Rust event loop, which is actually the Tokyo runtime

00:50:55.560 --> 00:50:58.760
is another super popular crate in the Rust ecosystem.

00:50:58.760 --> 00:51:07.800
There are different way to run the Rust runtime, meaning that Rust is not

00:51:07.800 --> 00:51:16.200
limited to having a single thread running the loop and thus you can have an event

00:51:16.200 --> 00:51:20.000
loop running on several different threads on the Rust side.

00:51:20.000 --> 00:51:26.520
And so the threading mode option in Granian lets you specify that behavior,

00:51:26.520 --> 00:51:32.240
meaning that if you use the runtime option, you will end up having like

00:51:32.360 --> 00:51:34.720
multi-threaded runtimes on the Rust side.

00:51:34.720 --> 00:51:41.480
Whereas if you specify the workers option for the threading mode, it will still use

00:51:41.480 --> 00:51:44.680
a single threaded runtime also on the Rust side.

00:51:44.680 --> 00:51:48.240
If you say though, the runtime mode, did the workers themselves

00:51:48.240 --> 00:51:49.560
each get multiple threads?

00:51:49.560 --> 00:51:50.560
Is that how that works?

00:51:50.560 --> 00:51:51.800
Yes, exactly.

00:51:51.800 --> 00:51:56.200
So in runtime mode, every worker has multi-threaded runtimes.

00:51:56.200 --> 00:52:01.400
Whereas on the worker side, you have like the worker is also the runtime.

00:52:01.400 --> 00:52:01.920
Yeah.

00:52:02.120 --> 00:52:02.400
Got it.

00:52:02.400 --> 00:52:05.160
And the option is there because like depending on the load of your

00:52:05.160 --> 00:52:10.000
application, like one of the two might work better.

00:52:10.000 --> 00:52:10.600
Sure.

00:52:10.600 --> 00:52:14.600
Depends on the IO and CPU boundness of your application.

00:52:14.600 --> 00:52:15.480
So yeah.

00:52:15.480 --> 00:52:17.640
I don't want to go into too much into these, but if I set the

00:52:17.640 --> 00:52:21.760
threading mode to runtime, is it reasonable to have just one worker?

00:52:21.760 --> 00:52:26.160
Or does it still make sense to have multiple workers for a pet run up?

00:52:26.160 --> 00:52:31.360
So the thing is that with a single worker, so the workers will spawn their

00:52:31.360 --> 00:52:38.040
own Python interpreters, so every worker is limited to the global interpreter

00:52:38.040 --> 00:52:44.040
lock, meaning that even if you spawn like a single worker with, I don't know,

00:52:44.040 --> 00:52:52.280
12 threads, those 12 threads we run in the Rust code, but they share a single

00:52:52.280 --> 00:52:55.680
Python runtime, which means all the things that that means.

00:52:55.680 --> 00:52:56.600
Exactly.

00:52:56.600 --> 00:52:57.000
Got it.

00:52:57.000 --> 00:52:57.440
Okay.

00:52:57.640 --> 00:53:02.040
So the only way to scale, so the workers is the way to scale, let's say

00:53:02.040 --> 00:53:03.840
the Python code of your application.

00:53:03.840 --> 00:53:04.280
Okay.

00:53:04.280 --> 00:53:10.840
Threads and threads are useful to scale the Rust runtime of stuff.

00:53:10.840 --> 00:53:15.720
No, there are some, the Rust side of stuff, of the things, meaning that

00:53:15.720 --> 00:53:20.600
those will be like the amount of threads used by Rust to handle your requests.

00:53:20.600 --> 00:53:27.040
So for example, if your application runs, opens like a tons of websocket,

00:53:27.120 --> 00:53:33.000
maybe you have like a websocket service, it might be helpful to spawn more threads

00:53:33.000 --> 00:53:40.000
for the Rust side, so it can actually handle more of those requests in the

00:53:40.000 --> 00:53:47.120
websocket lane and the blocking threads are mostly relevant only for the WSGI

00:53:47.120 --> 00:53:52.840
protocol, meaning that the blocking threads are the amount of threads used

00:53:52.840 --> 00:53:56.240
by Granian to interact with Python code.

00:53:56.240 --> 00:54:01.080
So on ASGI, since you will have like the event loop, there's no so much

00:54:01.080 --> 00:54:05.400
difference in how many threads you, how many blocking threads you spawn,

00:54:05.400 --> 00:54:11.000
because those blocking threads will still have to schedule stuff on the Python

00:54:11.000 --> 00:54:16.520
event loop, but on WSGI, since you don't have, you're not limited to

00:54:16.520 --> 00:54:18.120
the main thread of Python.

00:54:18.120 --> 00:54:24.000
So if you're, I don't know, maybe your application is using, you're using

00:54:24.000 --> 00:54:29.680
CypherPG to connect to the database and those libraries are able to release

00:54:29.680 --> 00:54:31.440
the global interpreter block.

00:54:31.440 --> 00:54:37.800
So having multiple blocking threads on WSGI might be helpful, still be

00:54:37.800 --> 00:54:43.560
helpful because like all the code, which doesn't involve the GIL will

00:54:43.560 --> 00:54:45.480
be able to run in parallel.

00:54:45.480 --> 00:54:45.960
Right.

00:54:46.440 --> 00:54:50.120
Maybe one part, one thread, one request is waiting on a database call, which

00:54:50.120 --> 00:54:52.720
it hits the network, which releases the GIL, for example.

00:54:52.720 --> 00:54:53.080
Right.

00:54:53.080 --> 00:54:53.880
Exactly.

00:54:54.120 --> 00:54:54.360
Yeah.

00:54:54.360 --> 00:54:54.960
Okay.

00:54:54.960 --> 00:54:57.600
What about this loop optimizations?

00:54:57.600 --> 00:54:58.920
This opt, no op.

00:54:58.920 --> 00:55:01.320
Yeah, that's, that's.

00:55:01.320 --> 00:55:02.920
What kind of magic is in there?

00:55:02.920 --> 00:55:07.400
Uh, that's a bit complicated, meaning that, so I think like writing

00:55:07.400 --> 00:55:13.240
runnion was like super helpful for me, at least to understand like the

00:55:13.240 --> 00:55:16.280
internals of asyncIO in the Python world.

00:55:16.280 --> 00:55:23.000
And if I have to be honest, I don't really like how asyncIO is implemented

00:55:23.000 --> 00:55:24.720
behind the loop, but anyway.

00:55:24.720 --> 00:55:29.840
I feel like you have to juggle, you have to be so aware of what loop is running.

00:55:29.840 --> 00:55:31.200
Has a loop been created?

00:55:31.200 --> 00:55:32.160
Is there a different one?

00:55:32.160 --> 00:55:33.400
Have I got the wrong loop?

00:55:33.400 --> 00:55:36.480
Like all of that stuff, it should be utterly transparent.

00:55:36.480 --> 00:55:39.760
And I just, I should just tell Python, I want to run stuff in a loop.

00:55:39.760 --> 00:55:40.360
Yeah.

00:55:40.360 --> 00:55:44.680
You know, I don't want to, it's not like I'm managing the memory or juggling,

00:55:44.680 --> 00:55:48.720
you know, the GC, like, I feel like asyncIO should be the same.

00:55:48.720 --> 00:55:51.280
You should say, I want to run stuff asynchronously and maybe somewhere I've

00:55:51.280 --> 00:55:55.200
configured that, or maybe it's automatic or whatever, but just do any, you're

00:55:55.200 --> 00:55:59.600
always kind of like, you know, for example, if you talk to the database

00:55:59.600 --> 00:56:03.680
asynchronously at the start of your web app, and then you use FastAPI and you

00:56:03.680 --> 00:56:06.360
try to use it in your requests there, it'll say, well, you're on the wrong

00:56:06.360 --> 00:56:06.800
event loop.

00:56:06.800 --> 00:56:09.640
It's like, well, why do I care about this?

00:56:09.640 --> 00:56:11.360
Just run it on the loop.

00:56:11.360 --> 00:56:12.040
Like, you know what I mean?

00:56:12.040 --> 00:56:15.400
Like that's kind of, that's been a complaint of mine since three, five, but

00:56:15.400 --> 00:56:17.480
Hey, nobody asked me.

00:56:17.480 --> 00:56:17.800
So.

00:56:17.800 --> 00:56:18.520
Yeah.

00:56:18.600 --> 00:56:20.080
So yeah.

00:56:20.080 --> 00:56:24.960
And those, let's say optimizations are actually a few hockey parts.

00:56:24.960 --> 00:56:29.440
In fact, like I think like FastAPI doesn't work with loop optimization

00:56:29.440 --> 00:56:32.880
enabled with Granian because it skips.

00:56:32.880 --> 00:56:38.400
So those optimization just keeps like one of the first iterations into running

00:56:38.400 --> 00:56:39.320
asynchronous code.

00:56:39.320 --> 00:56:43.720
I think going more deeper than this in details would be.

00:56:43.720 --> 00:56:44.200
Yeah.

00:56:44.200 --> 00:56:44.560
Yeah.

00:56:44.560 --> 00:56:44.760
Okay.

00:56:44.760 --> 00:56:45.560
Not, not worth it.

00:56:45.560 --> 00:56:45.800
Right.

00:56:45.880 --> 00:56:50.600
Long and hard to follow, but let's just say it just keeps some steps

00:56:50.600 --> 00:56:52.200
into the task running in the other loop.

00:56:52.200 --> 00:56:52.680
Yeah.

00:56:52.680 --> 00:56:53.120
Okay.

00:56:53.120 --> 00:56:56.320
You can do things like specify the SSL certificates and stuff.

00:56:56.320 --> 00:56:57.760
This one right here is pretty excellent.

00:56:57.760 --> 00:57:00.800
I mean, I don't know who worked on that one, but I didn't work out, but I

00:57:00.800 --> 00:57:04.600
inspired, I requested this one as the right way to put that you can say the

00:57:04.600 --> 00:57:06.160
process name, which is nice.

00:57:06.160 --> 00:57:06.880
Yeah.

00:57:06.880 --> 00:57:07.440
Yeah.

00:57:07.440 --> 00:57:11.240
If you're running multiple sites all on Granian on the same server, so you can

00:57:11.240 --> 00:57:13.480
differentiate which one is using the memory again.

00:57:14.600 --> 00:57:18.000
And while we're looking at this, can I ask, can I propose an idea and just get

00:57:18.000 --> 00:57:19.400
your feedback on it and get your thoughts?

00:57:19.400 --> 00:57:25.800
What about a lifetime management type of feature where you say after 10,000

00:57:25.800 --> 00:57:31.080
requests, just recreate the worker or after an hour, recreate the worker

00:57:31.080 --> 00:57:32.320
or something like that?

00:57:32.320 --> 00:57:34.600
Is this a thing that is in any interest to you?

00:57:34.600 --> 00:57:40.400
I understand the need for that, especially for, I think it's like one of those

00:57:40.400 --> 00:57:45.720
requests that is based on the fact of using like WSGI or at least like it's

00:57:45.720 --> 00:57:48.760
coming more from the Django user land.

00:57:48.760 --> 00:57:57.800
So I think making a lifetime, that kind of check would be kind of hard in a sense

00:57:57.800 --> 00:58:02.240
that there's a lot like involved into the, you know, process management of

00:58:02.240 --> 00:58:05.960
Granian because like, you know, the Python process and then you have Python

00:58:05.960 --> 00:58:09.320
threads and then you have like the Rust threads and then you have like the

00:58:09.320 --> 00:58:14.360
runtimes and then reasoning of lifetime probably it's kind of hard.

00:58:14.360 --> 00:58:19.080
I think like the fixing like a maximum number of requests per worker is

00:58:19.080 --> 00:58:22.840
something it can be done, let's say pretty easily.

00:58:22.840 --> 00:58:27.080
That issue is like, it's opened by, there's an issue for that, like open by

00:58:27.080 --> 00:58:28.880
a few times, if I recall correctly.

00:58:28.880 --> 00:58:33.040
The thing is that like in the, let's say in the prioritization queue,

00:58:33.040 --> 00:58:33.840
it's not at the top.

00:58:34.000 --> 00:58:39.720
So let's say at the moment, like I'm talking with some people that propose

00:58:39.720 --> 00:58:45.360
their self to join as a contributor on Granian, but let's say at the moment,

00:58:45.360 --> 00:58:48.400
I'm still like a single main contributor.

00:58:48.400 --> 00:58:49.680
So yeah, sure.

00:58:49.680 --> 00:58:53.680
I need to make, you know, some priority queues into issues.

00:58:53.680 --> 00:58:55.240
I'll look after your wellbeing.

00:58:55.240 --> 00:58:55.560
Yeah.

00:58:55.560 --> 00:58:56.480
Yeah.

00:58:56.480 --> 00:59:01.760
I think like the one which is more requested right now is like the access log.

00:59:01.760 --> 00:59:02.320
Yeah.

00:59:02.520 --> 00:59:06.280
So I think like that would be the next one probably.

00:59:06.280 --> 00:59:06.800
Yeah.

00:59:06.800 --> 00:59:10.280
I think honestly, that's more important of the access log than this one.

00:59:10.280 --> 00:59:10.800
Yeah.

00:59:10.800 --> 00:59:14.760
There's something changed in one of my apps and it just all of a sudden

00:59:14.760 --> 00:59:17.040
slowly just keeps growing in memory.

00:59:17.040 --> 00:59:21.160
And I'm pretty sure I've not done anything to make those changes.

00:59:21.160 --> 00:59:24.760
And it's something in a third party library, data access

00:59:24.760 --> 00:59:26.320
database or something else.

00:59:26.320 --> 00:59:30.080
I don't know what it is, but it's just, and it's fine, but it's consumed so much

00:59:30.080 --> 00:59:35.760
memory and so I ended up setting up some other thing to just say, look, after like

00:59:35.760 --> 00:59:39.920
a day, just, you know, just give it a refresh, let it refresh itself.

00:59:39.920 --> 00:59:46.880
You know that with Sentry SDK now we have also profiling, so you can actually look

00:59:46.880 --> 00:59:51.720
into the stocks of memory allocations, even like live on your application.

00:59:51.720 --> 00:59:57.760
So if you need to debug something like that, you can try with Sentry.

00:59:57.760 --> 00:59:59.720
Like distributed tracing or something like that.

00:59:59.720 --> 01:00:00.000
Yeah.

01:00:00.200 --> 01:00:01.080
Or the APM stuff.

01:00:01.080 --> 01:00:05.240
No, I mean, distributed tracing is more like about chaining together, like

01:00:05.240 --> 01:00:07.560
different sources, like this is profiling, like.

01:00:07.560 --> 01:00:08.280
The APM.

01:00:08.280 --> 01:00:08.720
Yeah.

01:00:08.720 --> 01:00:09.040
Okay.

01:00:09.040 --> 01:00:09.320
Yeah.

01:00:09.320 --> 01:00:13.240
Flame graphs and stuff to see where does your application.

01:00:13.240 --> 01:00:17.320
Maybe I'll put it in because it's driving me crazy and I would love to just do a PR

01:00:17.320 --> 01:00:20.880
somewhere and just go, Hey guys, this changed, here's the problem.

01:00:20.880 --> 01:00:24.160
Or if it is my problem and I just like, there's nothing I really changed in the

01:00:24.160 --> 01:00:27.280
core of this thing, but it seems to have started going weird that maybe I don't

01:00:27.280 --> 01:00:28.920
know, but anyway, it would be great.

01:00:28.920 --> 01:00:29.720
I'll have a look at it.

01:00:29.720 --> 01:00:30.000
Thanks.

01:00:30.000 --> 01:00:30.600
All right.

01:00:30.600 --> 01:00:31.760
What's next for Granian?

01:00:31.760 --> 01:00:36.400
Yeah, I think like fulfilling a couple of feature requests, like the access log,

01:00:36.400 --> 01:00:43.040
like the worker, a max request or a few, let's say minor things in that sense.

01:00:43.040 --> 01:00:50.480
I think like in terms of major features, it's pretty solid at the moment as a

01:00:50.480 --> 01:00:56.960
server after, let's say the idea is like after these feature requests, the idea

01:00:57.000 --> 01:01:03.960
was to, I mean, it's just an idea at the moment, but I'd like to try to add some

01:01:03.960 --> 01:01:07.040
features to the RPSGI protocol.

01:01:07.040 --> 01:01:11.960
For example, we talked before about channels and WebSockets.

01:01:11.960 --> 01:01:17.960
So as I said before, like I find very annoying, like every time I want to make

01:01:17.960 --> 01:01:25.520
even just a chat room, I need to, you know, put Redis there and manage Redis

01:01:25.520 --> 01:01:29.760
and whatever, and add like that kind of complexity to my project.

01:01:29.760 --> 01:01:34.360
And so I was thinking about like embedding some broadcasting features

01:01:34.360 --> 01:01:41.040
into the RPSGI protocol, because, you know, while all other servers for Python

01:01:41.040 --> 01:01:46.400
are written in Python, and so they're like still bound to, you know, the process

01:01:46.400 --> 01:01:52.000
paradigm of Python on the rough side of things, that's not true anymore.

01:01:52.000 --> 01:01:52.600
So.

01:01:52.600 --> 01:01:53.280
Right.

01:01:53.400 --> 01:01:59.200
Yeah, it would be to have something to broadcast messages between processes

01:01:59.200 --> 01:02:01.640
and even different granular servers.

01:02:01.640 --> 01:02:02.320
So.

01:02:02.320 --> 01:02:03.000
Yeah, that's cool.

01:02:03.000 --> 01:02:03.520
Yeah.

01:02:03.520 --> 01:02:05.520
That's what I have on my table at the moment.

01:02:05.520 --> 01:02:07.280
All right.

01:02:07.280 --> 01:02:07.920
Well, excellent.

01:02:07.920 --> 01:02:09.280
And thanks for working on this.

01:02:09.280 --> 01:02:12.640
It's an excellent project and it's really cool to see like kind of the

01:02:12.640 --> 01:02:15.800
innovation, like you were saying just there, you know, if it's not in Python,

01:02:15.800 --> 01:02:19.160
if it could be in Rust, like what would we change that would make that more

01:02:19.160 --> 01:02:21.040
capable even for the Python people, right?

01:02:21.040 --> 01:02:22.040
Yeah, exactly.

01:02:22.080 --> 01:02:27.880
And I think it's like the, I think it's like the baseline philosophy of people

01:02:27.880 --> 01:02:34.200
like Samuel Colvin with the Pydantic project, like to, you know, to try to

01:02:34.200 --> 01:02:41.440
empower Python, like the most keeping like the simplicity and the syntax we

01:02:41.440 --> 01:02:48.440
all love about Python, but I think it's like a very good way of evolving

01:02:48.440 --> 01:02:50.480
even the Python language.

01:02:50.480 --> 01:02:51.800
Yeah, absolutely.

01:02:52.080 --> 01:02:55.480
You know, sometimes you'll hear people say Python is slow and then like in

01:02:55.480 --> 01:02:57.720
some sort of pure sense, that's true.

01:02:57.720 --> 01:03:00.080
But then, you know, you put it on top of things like gradient and all

01:03:00.080 --> 01:03:01.360
of a sudden it's awesome.

01:03:01.360 --> 01:03:01.640
Right.

01:03:01.640 --> 01:03:04.040
So thanks for playing your part in that.

01:03:04.040 --> 01:03:04.640
Thank you too.

01:03:04.640 --> 01:03:05.400
Yeah, you bet.

01:03:05.400 --> 01:03:06.640
And thanks for coming on the show.

01:03:06.640 --> 01:03:07.720
I'll see you next time.

01:03:07.720 --> 01:03:08.360
Thank you.

01:03:08.360 --> 01:03:08.840
Bye.

01:03:09.320 --> 01:03:13.120
This has been another episode of Talk Python to Me.

01:03:13.120 --> 01:03:15.000
Thank you to our sponsors.

01:03:15.000 --> 01:03:16.560
Be sure to check out what they're offering.

01:03:16.560 --> 01:03:17.960
It really helps support the show.

01:03:18.680 --> 01:03:22.520
It's time to stop asking relational databases to do more than they were

01:03:22.520 --> 01:03:27.400
made for and simplify complex data models with graphs, check out the

01:03:27.400 --> 01:03:33.080
sample FastAPI project and see what Neo4j native graph database can do for you.

01:03:33.080 --> 01:03:37.560
Find out more at talkpython.fm/neo4j.

01:03:37.560 --> 01:03:39.040
Want to level up your Python?

01:03:39.040 --> 01:03:41.720
We have one of the largest catalogs of Python video

01:03:41.720 --> 01:03:43.000
courses over at Talk Python.

01:03:43.000 --> 01:03:46.360
Our content ranges from true beginners to deeply advanced

01:03:46.360 --> 01:03:48.120
topics like memory and async.

01:03:48.360 --> 01:03:50.800
And best of all, there's not a subscription in sight.

01:03:50.800 --> 01:03:53.640
Check it out for yourself at training.talkpython.fm.

01:03:53.640 --> 01:03:55.840
Be sure to subscribe to the show.

01:03:55.840 --> 01:03:58.680
Open your favorite podcast app and search for Python.

01:03:58.680 --> 01:03:59.840
We should be right at the top.

01:03:59.840 --> 01:04:05.080
You can also find the iTunes feed at /iTunes, the Google Play feed at /play,

01:04:05.080 --> 01:04:09.200
and the direct RSS feed at /rss on talkpython.fm.

01:04:09.200 --> 01:04:12.240
We're live streaming most of our recordings these days.

01:04:12.240 --> 01:04:15.680
If you want to be part of the show and have your comments featured on the air,

01:04:15.840 --> 01:04:20.120
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:04:20.120 --> 01:04:22.200
This is your host, Michael Kennedy.

01:04:22.200 --> 01:04:23.440
Thanks so much for listening.

01:04:23.440 --> 01:04:24.480
I really appreciate it.

01:04:24.480 --> 01:04:26.480
Now get out there and write some Python code.

01:04:27.280 --> 01:04:47.280
[MUSIC]

