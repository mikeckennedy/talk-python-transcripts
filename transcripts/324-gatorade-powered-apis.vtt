WEBVTT

00:00:00.001 --> 00:00:03.460
Python is used to solve a large and varied set of problems.

00:00:03.460 --> 00:00:05.800
One of its core pillars is web APIs.

00:00:05.800 --> 00:00:08.260
Another one is ML and data science.

00:00:08.260 --> 00:00:13.880
Those two important pieces were brought together in an unexpected and yet magically futuristic

00:00:13.880 --> 00:00:18.220
way by Rod Senra's team working with the Gatorade Sports Science Institute.

00:00:18.220 --> 00:00:22.260
They created a patch that you wear while working out once or twice.

00:00:22.260 --> 00:00:27.060
It analyzes your perspiration, combines it with other factors like running distance, sleep

00:00:27.060 --> 00:00:28.100
quality, and more.

00:00:28.100 --> 00:00:33.060
Then it provides recommendations using Python about how to get more effective fitness.

00:00:33.060 --> 00:00:38.920
This is Talk Python to Me, episode 324, recorded July 8th, 2021.

00:00:38.920 --> 00:00:56.720
Welcome to Talk Python to Me, a weekly podcast on Python, the language, the libraries, the

00:00:56.720 --> 00:00:58.120
ecosystem, and the personalities.

00:00:58.120 --> 00:00:59.920
This is your host, Michael Kennedy.

00:00:59.920 --> 00:01:02.120
Follow me on Twitter where I'm @mkennedy.

00:01:02.120 --> 00:01:05.840
And keep up with the show and listen to past episodes at talkpython.fm.

00:01:05.840 --> 00:01:08.920
And follow the show on Twitter via at Talk Python.

00:01:08.920 --> 00:01:12.200
This episode is brought to you by Sentry and Linode.

00:01:12.200 --> 00:01:15.060
And the transcripts are brought to you by Assembly AI.

00:01:15.060 --> 00:01:17.700
Please check out what they're offering during their segments.

00:01:17.700 --> 00:01:19.180
It really helps support the show.

00:01:19.180 --> 00:01:21.700
Rod, welcome to Talk Python to Me.

00:01:21.700 --> 00:01:22.160
Thank you.

00:01:22.160 --> 00:01:23.260
Super to have you here.

00:01:23.260 --> 00:01:28.640
There's a lot of things you've been building for different companies through your work.

00:01:28.640 --> 00:01:30.340
That's going to be really fun to explore.

00:01:30.340 --> 00:01:35.480
I think one of the really neat things here is you're not just working for one company, working

00:01:35.480 --> 00:01:40.480
on one team the way it works, but you're kind of interacting with a bunch of different projects

00:01:40.480 --> 00:01:41.680
and types of technologies.

00:01:41.680 --> 00:01:45.980
So you'll have a good, broad perspective on what went well, what didn't, what you would

00:01:45.980 --> 00:01:46.820
change, and so on.

00:01:46.820 --> 00:01:47.320
That's true.

00:01:47.320 --> 00:01:52.800
Python is the one thing that stuck with me since 1997 across different companies, let's

00:01:52.800 --> 00:01:56.420
say like five different companies, two different continents.

00:01:56.420 --> 00:01:59.720
But Python was the one thing that remained the same.

00:01:59.720 --> 00:02:01.080
That's fantastic.

00:02:01.080 --> 00:02:02.520
A good choice indeed.

00:02:02.520 --> 00:02:09.160
Well, let's start this conversation by talking about your story and how you got into programming

00:02:09.160 --> 00:02:09.600
Python.

00:02:09.600 --> 00:02:12.180
Python, it sounds like you were one of the early adopters.

00:02:12.180 --> 00:02:13.580
What version of Python?

00:02:13.580 --> 00:02:15.600
That was probably a version one type of thing.

00:02:15.600 --> 00:02:17.780
It was 1.5.2.

00:02:17.780 --> 00:02:19.340
It was in 1997.

00:02:19.340 --> 00:02:27.720
At that time, I was almost finishing my undergraduate course in computer engineering, and I already

00:02:27.720 --> 00:02:30.900
engaged in my master's post-graduation course.

00:02:30.900 --> 00:02:31.600
What were you studying?

00:02:31.600 --> 00:02:32.380
What was your degree?

00:02:32.660 --> 00:02:35.860
Well, my undergraduate degree was computer engineering.

00:02:35.860 --> 00:02:39.980
But for the master's thesis, I was studying computational reflection.

00:02:39.980 --> 00:02:45.040
In the end, it's the line of research that led to Aspect J and other things.

00:02:45.040 --> 00:02:48.380
But it was all about object-oriented protocols.

00:02:48.380 --> 00:02:53.100
So how you organize object orientation in programming languages, those kind of things.

00:02:53.100 --> 00:02:53.420
Okay.

00:02:53.420 --> 00:02:53.820
Cool.

00:02:53.820 --> 00:02:57.080
And Aspect J, that's like aspect-oriented programming?

00:02:57.300 --> 00:02:57.720
Exactly.

00:02:57.720 --> 00:03:03.760
Aspect-oriented programming was like a byproduct of the research in computational reflection.

00:03:03.760 --> 00:03:09.980
At the time, we were, academically speaking, we were trying to figure out what can you do

00:03:09.980 --> 00:03:11.320
with reflection.

00:03:11.740 --> 00:03:17.660
Java was one of the languages that made it popular to do introspection and reflection

00:03:17.660 --> 00:03:18.580
in programming languages.

00:03:18.580 --> 00:03:22.320
Of course, we had that in Lisp since back to the 70s.

00:03:22.320 --> 00:03:26.660
But Java made it known to the wide world world.

00:03:26.660 --> 00:03:29.800
So then we became researching more formally.

00:03:29.800 --> 00:03:35.760
And I started probing supports for reflective programming in programming languages.

00:03:36.260 --> 00:03:40.560
And that meant not only Java, but at the time, Perl, Python, Tcl.

00:03:40.560 --> 00:03:45.500
And once I saw Python, it felt like a glove to my hands.

00:03:45.500 --> 00:03:47.560
And then I stuck with it.

00:03:47.560 --> 00:03:47.800
Yeah.

00:03:47.800 --> 00:03:48.800
Oh, that's really neat.

00:03:48.800 --> 00:03:53.200
Maybe you could just talk a little tiny bit about what reflection is for people listening

00:03:53.200 --> 00:03:57.500
who maybe haven't done a lot of Java or .NET.

00:03:57.500 --> 00:03:58.400
They have it as well.

00:03:58.860 --> 00:04:03.580
And in Python, we have it in the sense that you can go in and explore the types.

00:04:03.580 --> 00:04:05.560
And so, you know, give it an object.

00:04:05.560 --> 00:04:06.540
What if it's class?

00:04:06.540 --> 00:04:07.160
And like, what is it?

00:04:07.160 --> 00:04:07.720
It's meta class.

00:04:07.720 --> 00:04:09.700
And you can like dig into it and even change it.

00:04:09.700 --> 00:04:14.700
But I don't typically hear it referred to as reflection in the Python ecosystem.

00:04:14.700 --> 00:04:15.220
Right.

00:04:15.220 --> 00:04:15.620
Yeah.

00:04:15.620 --> 00:04:19.760
Introspection became a more common term used.

00:04:19.760 --> 00:04:26.000
But at the time, reflection was about creating programs that reason about programs.

00:04:26.000 --> 00:04:29.240
So it was about this meta level reasoning.

00:04:29.240 --> 00:04:32.940
And it was very popular to do non-functional aspects.

00:04:32.940 --> 00:04:39.340
So you want to write your code and the code has the functional aspects, what it do, how it

00:04:39.340 --> 00:04:40.640
like transform things.

00:04:40.640 --> 00:04:47.680
And then the non-functional aspects like logging, persistency, monitoring, those kinds of things.

00:04:47.680 --> 00:04:53.640
People were exploring how to detach, decouple those things from your actual program and do

00:04:53.640 --> 00:04:55.040
that on a separate layer.

00:04:55.040 --> 00:04:57.780
And that was what reflection was all about.

00:04:57.780 --> 00:05:05.900
It was about having as inputs your own code and as outputs changing the behavior of your program.

00:05:05.900 --> 00:05:11.260
And the way we attacked that at the time was by an interception mechanism.

00:05:11.260 --> 00:05:13.540
So Python always had that.

00:05:13.540 --> 00:05:19.700
I think they called the DOM buildry hook or something like that, where you could like intercept

00:05:19.700 --> 00:05:21.820
like anything that was happening there.

00:05:21.820 --> 00:05:29.620
We do have the bugging hook in the Sys module that allow us to like pause your computation and

00:05:29.620 --> 00:05:30.480
see what's happening.

00:05:30.480 --> 00:05:32.120
Other programming languages.

00:05:32.120 --> 00:05:38.280
And at the time we're talking about the 90s, the popular ones were statically compiled

00:05:38.280 --> 00:05:39.220
programming languages.

00:05:39.220 --> 00:05:39.540
Right.

00:05:39.540 --> 00:05:42.120
C, C++, they generally don't have this behavior.

00:05:42.120 --> 00:05:42.340
Yeah.

00:05:42.340 --> 00:05:48.520
Sometimes they had runtime type information when you compiled your source codes enabling that.

00:05:48.520 --> 00:05:48.980
That's right.

00:05:48.980 --> 00:05:50.580
I remember there was an RTTI.

00:05:50.580 --> 00:05:51.560
RTTI.

00:05:51.560 --> 00:05:54.000
And C++, but it was off by default.

00:05:54.000 --> 00:05:54.600
Exactly.

00:05:55.020 --> 00:05:58.780
But in the interpreted world, you had everything, right?

00:05:58.780 --> 00:06:01.240
You had the interpreter during runtime.

00:06:01.240 --> 00:06:07.280
Sometimes you had the compiler as well, which was true for Java, which was true for Python,

00:06:07.280 --> 00:06:11.320
Perl, all the interpreted dynamically languages.

00:06:11.320 --> 00:06:13.420
And then that became more of a thing.

00:06:13.420 --> 00:06:20.640
Of course, in time, people realized there were other ways to achieve the same goals, which

00:06:20.640 --> 00:06:26.580
were more effective because one of the main things with introspection and interception

00:06:26.580 --> 00:06:33.620
is that everything that is happening in your program, it's kind of being reified, delivered

00:06:33.620 --> 00:06:36.780
to this meta level and then handled as data.

00:06:36.780 --> 00:06:42.440
So that is like a major break in speed, right?

00:06:42.440 --> 00:06:48.740
So it was not the answer for everything, especially when you wanted to have like runtime performance.

00:06:49.180 --> 00:06:53.140
But for things that were offline batch or analysis, it was not a problem.

00:06:53.140 --> 00:06:59.080
And one thing that an exercise that I'd done at the time, which is kind of interesting, was

00:06:59.080 --> 00:07:02.660
to introduce a debugger during runtime.

00:07:02.660 --> 00:07:09.440
So because we had this reflection mechanism that works just like this, you could take possession

00:07:09.440 --> 00:07:15.460
of an object and then any interaction with these objects would go to its guardian angel,

00:07:15.460 --> 00:07:18.320
which I call the meta object of this object.

00:07:18.680 --> 00:07:20.840
And then the meta object decided what to do.

00:07:20.840 --> 00:07:28.360
To lie about what was happening, to just delegate back to that object down there, do something else,

00:07:28.360 --> 00:07:30.800
become a proxy, solve the computation.

00:07:30.800 --> 00:07:32.600
So you could do anything.

00:07:32.600 --> 00:07:39.720
And in that case, we could install a debugger just for a given class or a given instance of your program,

00:07:40.120 --> 00:07:45.800
and then propagate like a virus for anything either that class or instance touched.

00:07:45.800 --> 00:07:51.800
So that was kind of interesting, a new dimension of programming, but became more as an academic exercise.

00:07:51.800 --> 00:08:00.700
And the only thing that I remember that's kind of succeeded into the industry was aspect oriented programming of sorts.

00:08:00.700 --> 00:08:01.800
Well, that's very interesting.

00:08:01.940 --> 00:08:04.640
It seems to me a little bit like decorators.

00:08:04.640 --> 00:08:05.240
Yes.

00:08:05.240 --> 00:08:06.860
Decorators are wrappers.

00:08:06.860 --> 00:08:09.700
But the thing is, they are not transparent.

00:08:10.280 --> 00:08:21.260
So whenever you create a decorator or a proxy, what's happening is that the references you had to the original objects now need to point to the wrapper, to the decorator.

00:08:21.260 --> 00:08:21.680
Right?

00:08:22.060 --> 00:08:31.900
So the key insights for reflectional computation that we were exploring at the time was how do we make this proxy totally transparent?

00:08:31.900 --> 00:08:41.040
So if you have a pointer or a reference to an object before it became reflective, it would still be valid.

00:08:41.040 --> 00:08:47.980
So you can turn on and off those introspection mechanisms and interception mechanism, and it's totally transparent.

00:08:48.480 --> 00:08:52.120
So to achieve that, we had to change the interpreter.

00:08:52.120 --> 00:08:54.200
So that's how we've done it for Java.

00:08:54.200 --> 00:09:04.280
And that's how I was exploring at the time for Python itself and Perl, to change the interpreter, to add the hook in there and do transparent wrapping.

00:09:04.280 --> 00:09:04.560
Yeah.

00:09:04.560 --> 00:09:10.480
It seems like some of the new peps might make it possible to plug in now rather than actually change it.

00:09:10.480 --> 00:09:17.260
I know there's that JIT plugin that they're working in where you can intercept the method parsing compilation bits and stuff.

00:09:17.260 --> 00:09:18.180
I don't remember the number.

00:09:18.300 --> 00:09:18.440
Yeah.

00:09:18.440 --> 00:09:21.520
I haven't explored, like, doing it to modern Python.

00:09:21.520 --> 00:09:26.360
At the time, I did some exercises using the debug hook.

00:09:26.360 --> 00:09:26.540
Yeah.

00:09:26.540 --> 00:09:29.520
It kind of works, but it was kind of messy and super slow.

00:09:29.520 --> 00:09:31.880
So I kind of stopped.

00:09:31.880 --> 00:09:34.460
But it will be interesting to revisit that again.

00:09:34.460 --> 00:09:34.880
I'm sure.

00:09:35.220 --> 00:09:39.240
I do remember how interesting all the research was around that time.

00:09:39.240 --> 00:09:49.000
And I feel like a lot of what's happening now is it's getting a little more structured, a little less dynamic with things like decorators and other types of wrappers and inner functions and stuff.

00:09:49.000 --> 00:09:50.700
But yeah, quite an interesting time.

00:09:50.700 --> 00:09:52.040
So how about now?

00:09:52.040 --> 00:09:54.920
Maybe we can talk about what you're doing these days.

00:09:54.920 --> 00:09:57.920
Nowadays, I'm a technology director at Working Co.

00:09:57.920 --> 00:09:58.700
Working Co.

00:09:58.700 --> 00:09:58.740
Working Co.

00:09:58.740 --> 00:10:11.480
is a digital products company where we not only do designs and strategy, but we also do implementation and quality assurance for the projects that we take on.

00:10:11.480 --> 00:10:17.940
So that's what makes us different from just an agency, a design agency, because the founders of Working Co.

00:10:17.940 --> 00:10:26.160
realize that it's much better for the clients to hire a single entity to do the full digital products turnkey.

00:10:26.160 --> 00:10:30.780
And then we can make sure that whatever we design, it's possible to build.

00:10:30.780 --> 00:10:32.900
So that is the vision for Working Co.

00:10:32.900 --> 00:10:35.540
We were very successful, I must say.

00:10:35.540 --> 00:10:38.760
In a few years, Working Co. won many prizes.

00:10:38.960 --> 00:10:47.780
It became famous for the Virgin America app for booking passages with Virgin America, I guess, five or six years ago.

00:10:47.780 --> 00:10:52.380
But we're doing things for like Apple, Google, Chase, you name it.

00:10:52.380 --> 00:10:53.600
I know that involves a lot of Python.

00:10:53.600 --> 00:10:55.860
Does it involve other technologies?

00:10:55.860 --> 00:10:56.520
It's worth it.

00:10:56.520 --> 00:10:58.240
Probably other technologies as well, right?

00:10:58.240 --> 00:11:02.600
Somebody comes and says, well, we want this thing designed and four of our Java shops don't make it for Java.

00:11:02.600 --> 00:11:08.880
Whatever happens is usually there are projects that are just designed, projects that are designed plus front-end work.

00:11:08.880 --> 00:11:11.640
Like projects that go all the way through to back-end.

00:11:11.640 --> 00:11:17.240
Sometimes back-end is just like a mediator for some infrastructure that the clients already have.

00:11:17.240 --> 00:11:24.340
But there are other times where we have to do everything, like the full digital platform for the client.

00:11:24.340 --> 00:11:29.100
And in those cases, Python becomes a key technology for us.

00:11:29.100 --> 00:11:36.080
Because what Python gives you most, in my experience, is optimizing for development time, right?

00:11:36.080 --> 00:11:40.880
People are very much concerned about Python runtime efficiency.

00:11:40.880 --> 00:11:45.400
But the key problem is development efficiency, right?

00:11:45.400 --> 00:11:56.240
Most of the time, if it's a little bit slower, like in comparison, a Formula One car and a regular vehicle, one is much faster than the other.

00:11:56.240 --> 00:12:00.020
We don't need Formula One cars most of the time, right?

00:12:00.120 --> 00:12:00.500
That's right.

00:12:00.500 --> 00:12:01.820
So it's like fast enough.

00:12:01.820 --> 00:12:03.200
And that is the point.

00:12:03.200 --> 00:12:06.080
So for many things, Python is fast enough.

00:12:06.080 --> 00:12:10.700
But in terms of development time, Python is the Formula One vehicle.

00:12:10.700 --> 00:12:12.080
It's like super fast.

00:12:12.080 --> 00:12:14.040
It's super easy to throw things away.

00:12:14.040 --> 00:12:15.380
It's super easy to explore.

00:12:15.380 --> 00:12:18.680
It can touch every niche in computer size.

00:12:18.680 --> 00:12:20.380
And I kind of have...

00:12:20.380 --> 00:12:21.960
Yeah, exactly.

00:12:21.960 --> 00:12:23.460
It has PyPI, right?

00:12:23.460 --> 00:12:25.740
For example, you can install this and go.

00:12:25.940 --> 00:12:26.180
Exactly.

00:12:26.180 --> 00:12:32.800
So it was a key technology for us in those cases that we have an extremely agile cycle of development.

00:12:32.800 --> 00:12:36.660
Lots of changes because design was sometimes moving along the way.

00:12:36.660 --> 00:12:39.900
And we need to rebuild the backend infrastructure overnight.

00:12:39.900 --> 00:12:43.180
So because for those scenarios, it was key.

00:12:43.180 --> 00:12:50.680
I think the conversation around performance in Python is super interesting because there's just so many layers and variations.

00:12:50.680 --> 00:12:51.100
Yeah.

00:12:51.200 --> 00:12:53.100
And what are you trying to do?

00:12:53.100 --> 00:12:56.340
Well, if you're trying to do a tight loop that does math, guess what?

00:12:56.340 --> 00:12:57.460
Python's bad at that.

00:12:57.460 --> 00:12:58.760
But maybe you shouldn't be doing that.

00:12:58.760 --> 00:13:01.340
Maybe you should be using NumPy and the SciPy stuff.

00:13:01.340 --> 00:13:02.900
And then all of a sudden, it's C speed again.

00:13:02.900 --> 00:13:03.820
Yes.

00:13:03.820 --> 00:13:07.280
Maybe you're doing some data-driven web API.

00:13:07.280 --> 00:13:09.140
And it's like, well, it might be slow.

00:13:09.140 --> 00:13:15.400
Well, actually, what you're doing is you're orchestrating exchange of JSON and talking to a database server or cluster.

00:13:15.580 --> 00:13:21.660
And it's almost exactly the same speed as if it were written in C because you're mostly waiting on the database and waiting on the network.

00:13:21.660 --> 00:13:23.100
And there's all of those things.

00:13:23.100 --> 00:13:26.960
And then on top of it is this thing that you talk about that often gets ignored.

00:13:27.220 --> 00:13:40.940
There's a really interesting story that was recounted in Mike Driscoll's Python interviews book about the competition between Google Video and YouTube and how Google Video had like 100 C++ engineers.

00:13:40.940 --> 00:13:44.900
And YouTube, this little startup, had 20 Python developers.

00:13:45.260 --> 00:13:50.160
And YouTube was just blowing away all the Google engineers because they could add features faster.

00:13:50.160 --> 00:13:53.720
And if Google would do something, they could copy it, re-implement it really quickly.

00:13:53.720 --> 00:13:56.840
And so Google fixed the problem by buying YouTube.

00:13:56.840 --> 00:13:59.700
It's still Python to some degree there.

00:13:59.700 --> 00:14:01.500
So that's a really good point.

00:14:01.500 --> 00:14:01.780
Yeah.

00:14:01.780 --> 00:14:04.360
My experience, there are two factors.

00:14:04.360 --> 00:14:09.380
One factor that you just mentioned is having it under control when it grows.

00:14:09.380 --> 00:14:09.980
Right?

00:14:09.980 --> 00:14:12.060
So software is like a living thing.

00:14:12.060 --> 00:14:13.460
You start a project.

00:14:13.460 --> 00:14:14.960
It gets, it's born.

00:14:14.960 --> 00:14:16.300
It starts to grow.

00:14:16.300 --> 00:14:16.640
Right.

00:14:16.640 --> 00:14:19.460
Does it become a sequoia or does it become blackberry bushes?

00:14:19.460 --> 00:14:20.040
Exactly.

00:14:20.040 --> 00:14:25.260
This portion of Talk Python, I mean, is brought to you by Sentry.

00:14:25.260 --> 00:14:27.780
How would you like to remove a little stress from your life?

00:14:27.780 --> 00:14:32.860
Do you worry that users might be having difficulties or are encountering errors in your app right now?

00:14:32.860 --> 00:14:35.780
Do you even know it until they send that support email?

00:14:35.780 --> 00:14:41.160
How much better would it be to have the error and performance details immediately sent to you,

00:14:41.160 --> 00:14:47.060
including the call stack and values of local variables and the active user recorded in that report?

00:14:47.060 --> 00:14:50.160
With Sentry, this is not only possible, it's simple.

00:14:50.160 --> 00:14:53.920
In fact, we use Sentry on all the Talk Python web properties.

00:14:53.920 --> 00:15:00.560
We've actually fixed a bug triggered by a user and had the upgrade ready to roll out as we got their support email.

00:15:00.560 --> 00:15:02.280
That was a great email to write back.

00:15:02.280 --> 00:15:04.740
We saw your error and have already rolled out the fix.

00:15:04.740 --> 00:15:05.940
Imagine their surprise.

00:15:05.940 --> 00:15:08.160
Surprise and delight your users today.

00:15:08.160 --> 00:15:11.560
Create your Sentry account at talkpython.fm/sentry.

00:15:11.560 --> 00:15:17.820
And if you sign up with the code talkpython2021, it's good for two months of Sentry's team plan,

00:15:17.820 --> 00:15:22.860
which will give you up to 20 times as many monthly events as well as other features.

00:15:22.860 --> 00:15:27.820
So just use that code talkpython2021 as your promo code when you sign up.

00:15:29.020 --> 00:15:31.900
So it has this life cycle, right?

00:15:31.900 --> 00:15:36.960
At some point, depending on its history, it gets out of control.

00:15:36.960 --> 00:15:43.200
So if you didn't have the proper team, the proper guidance, it can become the problem.

00:15:43.200 --> 00:15:47.800
Not the problem it was supposed to solve, but the software itself becomes a problem.

00:15:48.160 --> 00:15:53.700
And then people tend to, oh, let's throw this away and get something else because this is unmanageable.

00:15:53.700 --> 00:15:58.700
And I don't think it's an intrinsic problem on any programming language or infrastructure.

00:15:58.700 --> 00:16:08.020
It's more between the matching of did the team that was doing this really master the technology at the time.

00:16:08.020 --> 00:16:12.540
If they do, it could be Fortran, COBOL, C++, or Python.

00:16:12.540 --> 00:16:14.040
You have good results.

00:16:14.040 --> 00:16:20.380
If they didn't, they might get into this one-side, one-way road in the opposite direction.

00:16:20.380 --> 00:16:22.640
Then they are screwed, right?

00:16:22.640 --> 00:16:24.340
So this is one thing.

00:16:24.340 --> 00:16:28.820
The other thing, it's all about flexibility and the performance that you mentioned.

00:16:28.820 --> 00:16:33.900
For example, in this latest project that we are tackling, the GX project, we have it all.

00:16:33.900 --> 00:16:38.460
We had CPU-bound problems that we are tackling, IO-bound problems.

00:16:38.460 --> 00:16:41.980
And in both cases, Python was behaving just fine.

00:16:41.980 --> 00:16:45.420
We have like 16,000 users right now.

00:16:45.420 --> 00:16:47.280
We have three API instances.

00:16:47.280 --> 00:16:58.680
And when it's a performance problem, we change the algorithm, we introduce caching, we're using MongoDB for scalability, and we have zero performance issues so far.

00:16:58.680 --> 00:17:04.060
But because we have the software under control, we know what's happening in there.

00:17:04.060 --> 00:17:05.720
Technology is not a mystery.

00:17:05.720 --> 00:17:12.040
Then it's easy to pinpoint what's wrong and then replace it for a new version fast.

00:17:12.040 --> 00:17:13.420
And that's it.

00:17:13.420 --> 00:17:14.640
It's bringing results.

00:17:14.640 --> 00:17:15.820
That's a fantastic point.

00:17:15.820 --> 00:17:20.580
You know, you've got the architectural considerations as well as just the raw technology, right?

00:17:20.580 --> 00:17:21.240
Oh yeah, for sure.

00:17:21.240 --> 00:17:22.200
It's a single thing.

00:17:22.200 --> 00:17:27.560
That's why I use the metaphor of like a living organism, because it's on an ecosystem.

00:17:27.560 --> 00:17:30.220
Your software is not an island anymore.

00:17:30.220 --> 00:17:37.280
In the past, we had like this release to the desktop, install, and it's all on your machine.

00:17:37.280 --> 00:17:43.580
But today, it's interacting with the operating system, with the cloud, with the user.

00:17:43.580 --> 00:17:45.100
So it's alive, right?

00:17:45.240 --> 00:17:46.600
It's a dynamic ecosystem.

00:17:46.600 --> 00:17:56.940
So it's all about those interactions and understanding the dynamics on each of these interfaces, and then optimizing for the Feng Shui, for the flow.

00:17:56.940 --> 00:17:57.320
Very cool.

00:17:57.320 --> 00:18:04.220
And I want to dive into this first API, because I think it's super interesting, and people are going to be really surprised by it, I'm sure.

00:18:04.220 --> 00:18:04.780
Oh, that's good.

00:18:04.860 --> 00:18:05.460
Yeah, it'll be fun.

00:18:05.460 --> 00:18:09.480
But before I do, I do want to ask you one more sort of big picture question.

00:18:09.480 --> 00:18:17.800
You're working with Work & Co., you're working with all these clients as this digital agency doing this end-to-end work, which I think makes a lot of sense.

00:18:17.800 --> 00:18:24.380
What is the trends for Python that you've seen across the last five years or so?

00:18:24.380 --> 00:18:24.880
I see.

00:18:24.880 --> 00:18:27.160
What has stood out to you from these conversations?

00:18:27.160 --> 00:18:30.160
Maybe you had five, ten years ago, you're having now, you're thinking about the future.

00:18:30.160 --> 00:18:37.760
The two things that are my reality, at least, and that doesn't mean like, it's a broad world that we have out there.

00:18:37.760 --> 00:18:39.120
So there are many cases, right?

00:18:39.120 --> 00:18:42.480
So I'll speak just from my experience in the last three years.

00:18:42.480 --> 00:18:45.100
So there are two things that come to mind.

00:18:45.100 --> 00:18:49.080
One of them is this mediator thing.

00:18:49.080 --> 00:18:55.660
So because everything is in the cloud, because you're not writing any more software from scratch,

00:18:55.660 --> 00:18:58.800
you have to do integration, like gluing.

00:18:58.800 --> 00:19:03.600
Python, back in the early days, became famous as a glue language.

00:19:03.600 --> 00:19:05.980
And it was kind of gluing things in the desktop.

00:19:05.980 --> 00:19:09.080
Now Python is gluing things in the cloud.

00:19:09.080 --> 00:19:15.180
Because Python is such a versatile language in terms of a huge ecosystem of libraries,

00:19:15.180 --> 00:19:19.300
because the language itself allows you to compute like anything,

00:19:19.300 --> 00:19:22.760
it became an excellent technology for a glue language.

00:19:22.760 --> 00:19:31.440
And for us, it's critical, because any project we're dealing with, okay, we have to talk to a database, for sure,

00:19:31.440 --> 00:19:35.400
but we also have to talk to a forecasting weather service.

00:19:35.400 --> 00:19:38.500
We have to talk to a push notification service.

00:19:38.500 --> 00:19:42.700
We have to talk to analytics system platform.

00:19:42.700 --> 00:19:44.600
So you need to send signals there.

00:19:44.600 --> 00:19:53.600
So this ecosystem thing is great for that, because you find the connectors, you find the drivers, you find examples.

00:19:53.600 --> 00:20:00.860
So all of that speeds up the cycle of development and gives you confidence that you achieve whatever you need in success.

00:20:01.120 --> 00:20:06.540
In terms of ecosystems, still, we're not talking about just the computer right now.

00:20:06.540 --> 00:20:09.900
So we did a project for Google, the new store in Google.

00:20:09.900 --> 00:20:11.960
There are some embedded devices there.

00:20:12.480 --> 00:20:18.640
So that's another niche, embedded systems, IoT, things for the television.

00:20:18.640 --> 00:20:22.340
We did things for Marriott, where it was like embedded on a setup box.

00:20:22.340 --> 00:20:25.680
So this is one thing that I think we're going to see more and more often.

00:20:25.680 --> 00:20:30.300
Now that we see like CPUs in your lamps, and people playing boom in their lamps.

00:20:30.300 --> 00:20:30.600
Right.

00:20:30.680 --> 00:20:33.580
The other thing, it's the data-driven aspect.

00:20:33.580 --> 00:20:38.740
So one of the flags that I carry at Working Co is the data-driven design.

00:20:38.740 --> 00:20:52.620
So data-driven design is like, okay, we are not doing design just based on the inspirational thing from designers and their creativity and their capacity for innovation, but anchor in data from the real world.

00:20:52.620 --> 00:21:05.580
Sometimes that approach goes all the way through conceptual design into the end product, which we are seeing with these machine learning, deep learning-based products.

00:21:05.580 --> 00:21:08.540
Email model in production behind Flask or something.

00:21:08.540 --> 00:21:09.060
Exactly.

00:21:09.060 --> 00:21:14.760
So that's another trend that Python is great, right?

00:21:15.140 --> 00:21:23.240
Not only for the business analytical aspects, but also for the pipelines to build models in production.

00:21:23.240 --> 00:21:23.660
Very neat.

00:21:23.660 --> 00:21:31.120
The way you described Python as a glue language is super interesting compared to the way it's traditionally been described.

00:21:31.120 --> 00:21:38.380
Traditionally, glue language meant something like, well, I've got a C library and I'm talking to Linux.

00:21:38.380 --> 00:21:48.480
And so I could write this stuff in Python that'll do some shell stuff with Linux and that it'll also like pull in the C API and just move that data from here to there and go.

00:21:48.480 --> 00:21:52.960
And it's come across a little bit as a second class thing.

00:21:52.960 --> 00:21:55.920
It's like the very best scripting language you can imagine.

00:21:55.920 --> 00:21:59.400
And it's kind of not perfect for apps, but well, we'll do this.

00:21:59.400 --> 00:22:07.920
But what you described was, we're going to take the database, we're going to take these APIs, we're going to take the web requests, we're going to glue that together.

00:22:07.920 --> 00:22:09.620
I mean, that is the application.

00:22:09.620 --> 00:22:20.100
And it's like, it's thinking, yeah, it's thinking of, well, really, what is a modern API app other than a thing that takes a little data from an inbound request,

00:22:20.220 --> 00:22:29.340
maybe pulls some, pushes something over to Celery, grab something out of the database, calls these APIs and bundles it back up as a response and sends it back with a status code.

00:22:29.340 --> 00:22:30.880
That's the entire application.

00:22:30.880 --> 00:22:35.180
And yet this idea of gluing these pieces together is a really interesting way to think of it.

00:22:35.180 --> 00:22:35.920
That's what I learned.

00:22:35.920 --> 00:22:39.360
It's about like gluing systems and gluing data.

00:22:39.780 --> 00:22:47.020
And of course, these things are connected, but sometimes you can have gluing data in a asynchronous way, right?

00:22:47.020 --> 00:22:52.820
In batch processing or local processing or for analysis or human interaction.

00:22:52.820 --> 00:22:55.580
But it's still like gluing data from several sources.

00:22:55.580 --> 00:22:59.800
And there's this other approach, which is like gluing live systems.

00:22:59.800 --> 00:23:05.560
And of course, data is flowing across them, but also the connectivity aspect is key, right?

00:23:05.560 --> 00:23:09.680
Can I authenticate and talk to all of these systems?

00:23:09.680 --> 00:23:12.300
In the way they expect to interchange information.

00:23:12.300 --> 00:23:23.540
The real power is how well does it perform that combination, not how well does that one millisecond versus two milliseconds in the actual WebView method runtime behave, right?

00:23:23.540 --> 00:23:24.020
Yes.

00:23:24.020 --> 00:23:25.700
It's super interesting to see it that way.

00:23:25.700 --> 00:23:30.040
All right, well, let's jump into the first API that we're going to talk about.

00:23:30.040 --> 00:23:30.380
Right.

00:23:30.380 --> 00:23:30.920
Yeah.

00:23:30.920 --> 00:23:35.600
So this has to do with Gatorade, which is the sports drink company.

00:23:35.960 --> 00:23:46.480
And they have created this really interesting idea of the quantified self for fitness here with this thing called the GX Sweat Patch.

00:23:46.480 --> 00:23:47.000
Exactly.

00:23:47.000 --> 00:23:49.900
This is something that blew my mind when I saw it first.

00:23:49.900 --> 00:23:50.260
Yes.

00:23:50.260 --> 00:23:52.280
This is something that is like really in the beginning.

00:23:52.280 --> 00:23:56.360
We launched this in production in March 1st this year.

00:23:56.360 --> 00:23:59.020
It has been in development since 2019.

00:23:59.760 --> 00:24:03.560
And the research inside Gatorade goes even far back.

00:24:03.560 --> 00:24:11.720
So what they are trying to do, Gatorade has this subunit called GSI, the Gatorade Sports Science Institute.

00:24:12.240 --> 00:24:19.860
I had the opportunity to visit one of their physical instances in Sarasota, Florida in 2020.

00:24:19.860 --> 00:24:27.900
And they do like amazing work there, like bridging sports science, like students, actual experiments.

00:24:27.900 --> 00:24:40.080
And they are helping to develop this concept of how do you bring some of the metrics used by high performance athletes to a more general, broad audience?

00:24:40.260 --> 00:24:40.340
Right.

00:24:40.340 --> 00:24:53.240
We've probably all seen pictures of Olympic athletes or, you know, pick your favorite sport athletes with a couple of doctors or researchers around with a clipboard and like a big breathing thing.

00:24:53.240 --> 00:24:58.120
And they're on like a workout bike or they're doing and they're like studying all these different things.

00:24:58.120 --> 00:24:58.640
Right.

00:24:58.640 --> 00:25:10.100
And they get really interesting feedback on, well, under this situation, this is where you're hitting your limits in cardio or in like breathing at altitude or something.

00:25:10.100 --> 00:25:16.060
And for the rest of us, we just put on shoes and run or, you know, get on a bike or whatever it is.

00:25:16.060 --> 00:25:16.980
And we just have no idea.

00:25:16.980 --> 00:25:29.100
In a specific case of the, what you're showing now on the screen, the sweat patch, this thing that you can put in your forearm and it's going to capture your sweat in your micro pores in your skin.

00:25:29.100 --> 00:25:32.260
And then you lead that sweat into two channels.

00:25:32.260 --> 00:25:37.220
One channel, which is the orange channel that fills up in a zigzag form.

00:25:37.220 --> 00:25:39.740
It's the volume of sweat you're producing.

00:25:39.740 --> 00:25:52.060
The other channel is a slightly bar on the lower side that will react in colors to reflect the amount of sodium that is in your sweat.

00:25:52.060 --> 00:26:06.820
And those two things, they will be super critical to understand how much fluid you're losing from your body while you're performing some sports activity and the concentration of sodium you're losing as well.

00:26:06.820 --> 00:26:16.000
Because sodium, as everybody knows, it's critical for the performance of muscles, the potassium sodium pump that exists and control all muscles.

00:26:16.480 --> 00:26:21.000
So learning about those things can help you improve your performance.

00:26:21.000 --> 00:26:27.740
And of course, this is more impactful if you are a professional athlete, but I think everybody can benefit from it.

00:26:27.740 --> 00:26:44.020
And the biggest challenge was to take that out of the lab where you mentioned, Michael, where you have an apparatus that is easier to capture all the signals and bring that out in the field where anybody can use under any conditions.

00:26:44.540 --> 00:26:48.280
And that was the challenge that we took up to help Gatorade to achieve that.

00:26:48.280 --> 00:26:53.220
And it's had a lot of obstacles for us to overcome.

00:26:53.220 --> 00:27:04.860
And Python was super helpful because not only it had the tools for us to build APIs, but also there's a ton of formulas that we need to compute to achieve that.

00:27:04.860 --> 00:27:12.800
And Python had NumPy, Pandas, and Stats, and all the tooling that we needed to make it happen.

00:27:12.900 --> 00:27:16.040
So let me just describe this really quickly for people who are watching.

00:27:16.040 --> 00:27:20.080
It's like a band-aid, maybe two and a half inches.

00:27:20.080 --> 00:27:21.540
Yeah, like four fingers.

00:27:21.540 --> 00:27:22.940
Three or four fingers, something like that.

00:27:22.940 --> 00:27:25.520
Maybe about the size of the palm of most people's hands.

00:27:25.520 --> 00:27:30.440
You stick it on to your arm and it changes these colors and reads out.

00:27:30.440 --> 00:27:35.380
And then you scan it with this iOS app and it gives you an analysis that you're talking about here.

00:27:35.380 --> 00:27:35.580
Yeah.

00:27:35.700 --> 00:27:36.060
Exactly.

00:27:36.060 --> 00:27:39.260
The app, of course, serves for other purposes as well.

00:27:39.260 --> 00:27:41.500
So you can like track your workouts.

00:27:41.500 --> 00:27:44.160
It does integrate multiple sources of information.

00:27:44.160 --> 00:27:46.060
Garmin, Strava, HealthKit.

00:27:46.060 --> 00:28:00.220
And then it creates this timeline of events in your day that understands if you're like doing multiple workouts a day, very early in the morning, very late on the evening, and how they interfere in each other.

00:28:00.220 --> 00:28:04.740
Because if they are too close apart, maybe you shouldn't drink anything between the two of them.

00:28:04.740 --> 00:28:08.140
If they are too far apart, maybe you need supplemental hydration.

00:28:08.140 --> 00:28:12.800
So all of those effects, we perform that analysis in Python at the back end.

00:28:12.800 --> 00:28:20.020
And the app becomes like the avatar that conveys that information to the athlete in real time.

00:28:20.020 --> 00:28:20.280
Yeah.

00:28:20.280 --> 00:28:24.920
When I first heard about this, I thought it specifically would just be like, well, Gatorade recommends this.

00:28:24.920 --> 00:28:26.500
So here's how much Gatorade you should buy.

00:28:26.500 --> 00:28:29.800
You should get the lime flavor, not the cool or whatever.

00:28:29.800 --> 00:28:36.040
But it takes in data from, like you said, like Apple HealthKit and Garmin and these other things as well.

00:28:36.040 --> 00:28:37.560
How do you get that data out of it?

00:28:37.620 --> 00:28:38.680
That's a great question.

00:28:38.680 --> 00:28:41.720
So the plan was to go as broad as possible.

00:28:41.720 --> 00:28:44.440
We even investigated Fitbit and other providers.

00:28:44.440 --> 00:28:49.180
But for the MVP, we went for three sources.

00:28:49.180 --> 00:28:53.000
Two external sources, Strava API and Garmin API.

00:28:53.000 --> 00:29:00.960
So if you're a Strava user or a Garmin user, you can, in a web view, connect to Garmin and Strava through our app.

00:29:00.960 --> 00:29:06.580
And then we created this data feed from Garmin and Strava into our system.

00:29:06.580 --> 00:29:07.580
Like some OAuth.

00:29:07.580 --> 00:29:09.440
Backend sort of API type of thing?

00:29:09.440 --> 00:29:10.020
Okay.

00:29:10.020 --> 00:29:10.200
Yeah.

00:29:10.200 --> 00:29:12.920
And then it starts popping up in the app.

00:29:12.920 --> 00:29:13.520
You don't need to.

00:29:13.520 --> 00:29:15.260
The app becomes a read-only thing.

00:29:15.260 --> 00:29:18.040
You just look into it and you perform your exercise.

00:29:18.040 --> 00:29:21.140
But the information comes by through the backend.

00:29:21.540 --> 00:29:22.540
So these are the main channels.

00:29:22.540 --> 00:29:22.860
So these are the main channels.

00:29:22.860 --> 00:29:32.700
But we also talk to Apple HealthKit, the platform in the iOS that consolidates information from multiple apps.

00:29:32.700 --> 00:29:34.400
Health related, of course.

00:29:34.400 --> 00:29:39.260
And then in that case, if you have like a sleep tracker or other sports tracker.

00:29:39.260 --> 00:29:40.620
For example, I use RunKeeper.

00:29:40.620 --> 00:29:43.020
So I go to that application.

00:29:43.020 --> 00:29:46.900
I allow that application to export information to HealthKit.

00:29:46.900 --> 00:29:50.500
And then, of course, Apple Health, the app, will see it.

00:29:50.500 --> 00:29:55.920
But also any other app registered as a reader for the HealthKit platform.

00:29:56.380 --> 00:30:04.900
And that's how we grab and consolidate all your activity, sleeping and workouts, into this single timeline.

00:30:04.900 --> 00:30:07.160
And then we provide recommendations on top of that.

00:30:07.160 --> 00:30:07.280
Right.

00:30:07.280 --> 00:30:10.300
So you might be able to correlate workout with sleep.

00:30:10.300 --> 00:30:10.540
Yes.

00:30:10.540 --> 00:30:11.940
How well you're sleeping or something like that.

00:30:11.940 --> 00:30:12.220
Yes.

00:30:12.220 --> 00:30:13.600
That's one of the things we do.

00:30:13.600 --> 00:30:14.980
That was one of the challenges.

00:30:15.520 --> 00:30:22.280
Dealing with this events timeline became this, we needed a time series database to do time series analysis.

00:30:22.280 --> 00:30:24.000
Because time is super relevant.

00:30:24.000 --> 00:30:25.660
We have to handle conflicts.

00:30:25.660 --> 00:30:30.200
Because you may have like many trackers reporting the same thing.

00:30:30.200 --> 00:30:34.060
So the same physical event comes as multiple digital events.

00:30:34.060 --> 00:30:39.620
Sometimes there are applications that break up a single event into multiple events.

00:30:39.620 --> 00:30:42.120
Sleep trackers typically do that.

00:30:42.120 --> 00:30:44.980
So for us, you have a single night of sleep.

00:30:45.280 --> 00:30:47.240
You go to bed and you wake up.

00:30:47.240 --> 00:30:47.500
Right.

00:30:47.500 --> 00:30:53.500
But actually what happens is multiple cycles of sleep that you wake up in the middle of night.

00:30:53.500 --> 00:30:58.300
But we don't handle them logically as multiple sleeping periods.

00:30:58.300 --> 00:31:00.580
For us, logically, it's a single sleeping period.

00:31:00.580 --> 00:31:03.340
So this is another thing we have to handle in the system.

00:31:03.340 --> 00:31:03.500
Yeah.

00:31:03.500 --> 00:31:05.860
It seems really useful, actually, the more I hear about it.

00:31:05.860 --> 00:31:09.560
So let's talk about some of the tech behind the scenes for this one.

00:31:09.560 --> 00:31:09.920
Cool.

00:31:09.920 --> 00:31:11.920
There's probably some data science side.

00:31:11.920 --> 00:31:14.420
There's obviously the API and database side.

00:31:14.580 --> 00:31:15.540
What do you got going on here?

00:31:15.540 --> 00:31:15.800
Okay.

00:31:15.800 --> 00:31:20.960
So in the beginning, we went down to GSSI, the Gateway Sports Science Institute.

00:31:20.960 --> 00:31:24.820
And together with their scientists, we started to create a model.

00:31:24.920 --> 00:31:28.160
Not only for the way the sweats patch works.

00:31:28.160 --> 00:31:33.380
The sweats patch was developed by a Boston company named Epicor, the physical patch.

00:31:33.380 --> 00:31:39.320
And also the driver that kind of captures the basic information from the patch.

00:31:39.320 --> 00:31:41.500
That is embedded on the mobile app.

00:31:41.880 --> 00:31:49.380
And then when you take a picture of the patch, we do some image processing and we extract the two bits of information that we want.

00:31:49.380 --> 00:31:50.380
The volume channel.

00:31:50.380 --> 00:31:52.940
That's probably something like Swift or something on the app, right?

00:31:53.160 --> 00:31:55.940
Today, it's a C Sharp Xamarin.

00:31:55.940 --> 00:31:59.440
But it was a modern restriction from PepsiCo.

00:31:59.440 --> 00:32:01.580
They were already using that technology.

00:32:01.580 --> 00:32:05.560
And it was supposed to be a framework cross-platform.

00:32:05.560 --> 00:32:11.360
So later, when we decide to go to Android, it would be a possibility to reuse that framework.

00:32:11.800 --> 00:32:14.920
So that was a constraint that we had to accommodate for.

00:32:14.920 --> 00:32:19.260
But those modules are Objective-C and Swift, for sure.

00:32:19.260 --> 00:32:20.040
They are native.

00:32:20.040 --> 00:32:20.320
Yeah.

00:32:20.320 --> 00:32:28.660
And so what we do after we have that, we have to translate whatever you read, which is your local sweat rate.

00:32:28.660 --> 00:32:30.720
How much your forearm is sweating.

00:32:30.720 --> 00:32:33.220
A single micropore in your forearm.

00:32:33.220 --> 00:32:39.700
And we have a statistical model developed by GSSI to translate that into your whole body sweat rate.

00:32:40.060 --> 00:32:47.140
So that is the first machine learning, statistical learning bit that is embedded on the system.

00:32:47.140 --> 00:32:51.460
And we need to take into consideration what's the weather like?

00:32:51.460 --> 00:32:53.120
What's your weight?

00:32:53.120 --> 00:32:55.060
What type of sports you are doing?

00:32:55.060 --> 00:32:55.920
What's the humidity?

00:32:55.920 --> 00:32:56.520
Yeah.

00:32:56.520 --> 00:32:59.760
Humidity we are not using right now because it's hard to capture.

00:32:59.760 --> 00:33:02.400
So we had to create a less accurate model.

00:33:02.400 --> 00:33:04.700
But for sure, humidity is critical.

00:33:04.700 --> 00:33:08.480
But it was a product decision to leave that one out.

00:33:08.860 --> 00:33:12.180
Because of the facility to grab the information, to capture that.

00:33:12.180 --> 00:33:12.740
Right, right.

00:33:12.740 --> 00:33:20.160
And once we have your whole body sweat rate, that acts as a crystal ball for future workouts.

00:33:20.160 --> 00:33:24.660
So when you're performing a new workout, you don't need to use the sweat patch again.

00:33:24.660 --> 00:33:33.300
You can use the sweat profile, the crystal ball, to predict, given the conditions of this new workout, how much you're going to sweat.

00:33:33.700 --> 00:33:36.020
And then base recommendations on that.

00:33:36.020 --> 00:33:46.680
So, of course, if there are some constraints that if they do not match, you have to do a new sweat test, create a new profile for those new conditions.

00:33:46.680 --> 00:33:50.420
For example, I create a patch for running and now I'm doing bike.

00:33:50.760 --> 00:33:51.960
So it's a different activity.

00:33:51.960 --> 00:33:54.180
It should be best if I create a new profile.

00:33:56.180 --> 00:33:58.940
This portion of Talk Python to me is sponsored by Linode.

00:33:58.940 --> 00:34:07.380
Visit talkpython.fm/Linode to see why Linode has been voted the top infrastructure as a service provider by both G2 and TrustRadius.

00:34:07.380 --> 00:34:14.740
From their award-winning support, which is offered 24, 7, 365 to every level of user, to the ease of use and setup,

00:34:14.740 --> 00:34:20.080
it's clear why developers have been trusting Linode for projects both big and small since 2003.

00:34:20.460 --> 00:34:30.020
To pull your entire application stack with Linode's one-click app marketplace or build it all from scratch and manage everything yourself with supported centralized tools like Terraform,

00:34:30.020 --> 00:34:40.660
Linode offers the best price-to-performance value for all compute instances, including GPUs as well as block storage, Kubernetes, and their upcoming bare metal release.

00:34:40.660 --> 00:34:48.420
Linode makes cloud computing fast, simple, and affordable, allowing you to focus on your projects, not your infrastructure.

00:34:48.420 --> 00:34:56.860
Visit talkpython.fm/Linode and sign up with your Google account, your GitHub account, or your email address, and you'll get $100 in credit.

00:34:56.860 --> 00:35:01.940
That's talkpython.fm/Linode, or just click the link in your podcast player's show notes.

00:35:01.940 --> 00:35:03.980
And thank them for supporting Talk Python.

00:35:03.980 --> 00:35:07.520
How does the app know what you're doing?

00:35:07.520 --> 00:35:08.120
Do you tell it?

00:35:08.120 --> 00:35:10.380
Just right now I'm doing this, so take a scan.

00:35:10.380 --> 00:35:11.380
You have two options.

00:35:11.380 --> 00:35:21.180
One of them, the app asks the user, when you're scheduling manually a workout, you can say, I'm planning to use a sweat patch on this particular workout, so be prepared.

00:35:21.180 --> 00:35:22.180
That's one option.

00:35:22.180 --> 00:35:28.220
The other option is, after you finish a workout, the app asks you, did you use a sweat patch?

00:35:28.220 --> 00:35:31.240
So if you did, let's go with the flow of scanning.

00:35:31.300 --> 00:35:42.260
If you're not, there is a fallback mechanism called way in, way out, where we can compare your rates and subtract them and see how much fluid you lost.

00:35:42.260 --> 00:35:46.500
The downside of this is that we do not capture sodium loss.

00:35:46.500 --> 00:35:48.340
So you cannot take sodium in consideration.

00:35:48.720 --> 00:35:53.100
So when it gets to the server side, what's the API framework?

00:35:53.100 --> 00:35:56.320
So the app is talking to the backend all the time.

00:35:56.320 --> 00:36:00.520
We kind of use the backend for frontend metaphor of sorts.

00:36:00.520 --> 00:36:09.160
So the API not only does the reasoning for the whole system, but sometimes it even helps the app a little bit with layout.

00:36:09.160 --> 00:36:24.160
So the app talks to the backend to get user profile, to get the timeline of events, and then it renders those timeline of events, captures additional information, for example, your motivation and your fatigue, and reports that information to the backend.

00:36:24.160 --> 00:36:28.300
The sweat scans and manually schedule workouts.

00:36:28.300 --> 00:36:30.840
Everything else happens at the backend.

00:36:30.840 --> 00:36:32.660
By everything else, what do we mean?

00:36:32.660 --> 00:36:34.460
Grabbing weather information.

00:36:34.460 --> 00:36:40.420
So translating your latitude and longitude into a temperature, if your workout was outdoor.

00:36:40.420 --> 00:36:41.420
One thing.

00:36:41.420 --> 00:36:49.420
Sending push, scheduling push notifications to remind you that you have this recommendation or there's an upcoming workout.

00:36:49.420 --> 00:36:50.540
Things like that.

00:36:50.540 --> 00:36:54.160
It also computes the local to whole body transformation.

00:36:54.160 --> 00:37:03.780
It manages your sweat profiles and it triggers some product recommendation engines that will tell you not only Gatorade products,

00:37:03.780 --> 00:37:09.400
but also general foods that could be suitable for your nutritional needs.

00:37:09.400 --> 00:37:18.880
So we can say, for example, if you need this amount of carbs, this amount of protein, maybe you should take a little bit of caffeine or casein.

00:37:18.880 --> 00:37:24.080
And then we give it a list of generic food like rice, coffee.

00:37:24.080 --> 00:37:28.220
And then you can plan accordingly to fulfill those recommendations.

00:37:28.220 --> 00:37:30.360
All of that comes from the backend.

00:37:30.360 --> 00:37:31.660
And the backend is Flask?

00:37:31.660 --> 00:37:33.340
The backend is Flask.

00:37:33.340 --> 00:37:38.120
We were in doubt in the beginning being between FastAPI and Flask.

00:37:38.120 --> 00:37:44.300
I wanted to fight the problem domain, not the technology.

00:37:44.300 --> 00:37:46.640
So I decided to go fully synchronous.

00:37:46.640 --> 00:37:49.720
And because in that case, it's super easy to debug.

00:37:49.720 --> 00:37:52.440
It's much less prone to like problems.

00:37:52.440 --> 00:37:54.560
I was not concerned with performance in the beginning.

00:37:54.960 --> 00:37:59.920
What we learned was that Flask was performance enough for all our needs.

00:38:00.420 --> 00:38:01.040
So that went well.

00:38:01.040 --> 00:38:02.280
So that went well.

00:38:02.280 --> 00:38:06.420
We had a separate API just for integrations with Garmin and Strava.

00:38:06.420 --> 00:38:13.680
After we entered production in March, we realized that the team was too small to maintain it.

00:38:13.720 --> 00:38:18.180
So we merged the two APIs into a single monolith.

00:38:18.180 --> 00:38:21.040
But those two APIs, one of them was asynchronous.

00:38:21.040 --> 00:38:24.140
So we did that asynchronous API with Quart.

00:38:24.580 --> 00:38:31.180
And that was the one talking to Garmin and Strava because that one was purely IO bound, not CPU bound.

00:38:31.180 --> 00:38:31.540
Right.

00:38:31.540 --> 00:38:36.140
You're entirely waiting on Strava and Garmin and the internet.

00:38:36.760 --> 00:38:41.260
And so you should be able to scale that many, many times out because all you're doing is waiting on their APIs.

00:38:41.260 --> 00:38:46.240
And you're completely at the mercy of their performance picture as well.

00:38:46.240 --> 00:38:46.500
Right.

00:38:46.500 --> 00:38:49.420
So Async makes a lot of sense, but it turns out it wasn't needed.

00:38:49.420 --> 00:38:50.000
Yeah.

00:38:50.000 --> 00:38:53.740
The thing that we realized was that, of course, there are tradeoffs.

00:38:53.740 --> 00:39:00.560
So if you go for a job interview and you present that as like a conceptual problem, I think the answer is no.

00:39:00.560 --> 00:39:01.520
Do it asynchronously.

00:39:01.520 --> 00:39:05.340
Do it as a separate API because then you can scale independently.

00:39:05.340 --> 00:39:08.420
You have better IO throughput, lower latency, etc.

00:39:08.420 --> 00:39:17.660
But in the real world, you have to balance all those things with the size of your team, the resources that you have, other external conditions.

00:39:17.660 --> 00:39:25.300
So in the end, we decided to consolidate everything into a single technology in a single stack because it was simpler.

00:39:25.300 --> 00:39:32.760
If we need to like to onboard new people trained instead of knowing Flask and Cart, now they only need to know a single framework.

00:39:33.340 --> 00:39:40.980
And because scalability was not a problem, we were using like Kubernetes in production and it's like horizontally scalable.

00:39:40.980 --> 00:39:47.580
We decided to reverse that and build a monolith, single stack, Flask all the way.

00:39:47.580 --> 00:39:49.040
And that's what we have today.

00:39:49.040 --> 00:39:49.560
How interesting.

00:39:49.680 --> 00:39:57.520
So you decided you can just solve it by running more worker processes for container and then just running more containers if you need to.

00:39:57.520 --> 00:39:57.840
Exactly.

00:39:57.840 --> 00:40:01.660
That was a better solve for the conditions we had in the project.

00:40:01.660 --> 00:40:02.840
I think that makes a lot of sense.

00:40:02.840 --> 00:40:15.000
There's so often these recommendations of using microservices, breaking stuff into a bunch of pieces, having just the right technology for just this slice of what you're doing.

00:40:15.000 --> 00:40:17.120
And then you've got your app.

00:40:17.120 --> 00:40:19.380
Your app is talking to the different services.

00:40:19.380 --> 00:40:21.160
Now you're trying to coordinate.

00:40:21.160 --> 00:40:23.400
It just gives me chills to even think about it.

00:40:23.620 --> 00:40:29.540
Releasing this through the Apple app approved process and coordinating that with the versions of multiple APIs.

00:40:29.540 --> 00:40:30.180
Exactly.

00:40:30.180 --> 00:40:31.560
That sounds so bad.

00:40:31.560 --> 00:40:33.440
It becomes a nightmare really fast.

00:40:33.440 --> 00:40:40.820
And in my mind, my experience is that microservices is an answer for a given team size.

00:40:40.820 --> 00:40:53.680
So if you have like 100 developers like, I don't know, or a thousand developers like Netflix or Shopify, then it makes every sense in the world to break it up in individual components because you have individual teams.

00:40:53.680 --> 00:40:55.380
Conway's law, right?

00:40:55.760 --> 00:41:02.040
The software you build reflects the architecture of the people in the company and how they build the software.

00:41:02.040 --> 00:41:05.680
But when you have a very tiny little team, the monolith is great.

00:41:05.680 --> 00:41:07.380
It simplifies everything.

00:41:07.380 --> 00:41:19.340
So that's like a lesson we learned that we kind of over-engineered in the beginning, trying to go with two APIs, and we took the route of bringing the monolith.

00:41:19.340 --> 00:41:21.860
I think that makes a lot of sense for small teams.

00:41:21.860 --> 00:41:31.520
And here's the thing, if you run into performance problems that really needs async stuff, you know, when you considered to use Flask and not FastAPI, FastAPI was brand new.

00:41:31.520 --> 00:41:44.160
And who knows if it would survive another six months or if it would go the way of other really promising projects like Jepronto or something, which as far as I could be wrong, but as far as I know, it hasn't gotten a ton of traction.

00:41:44.160 --> 00:41:47.860
It was really exciting for a while, and it just kind of fizzled out, right?

00:41:47.860 --> 00:41:48.240
Yes.

00:41:48.240 --> 00:41:49.100
You want to build on that.

00:41:49.100 --> 00:41:51.020
So I think Flask is a totally reasonable choice.

00:41:51.180 --> 00:41:57.660
But I guess what I was going to say is, you know, it's not that different if you need to re-translate that, if you're going to convert that to FastAPI.

00:41:57.660 --> 00:42:02.040
Like, that's a thing you as a team of a couple of people could do in a few days.

00:42:02.040 --> 00:42:02.340
Yes.

00:42:02.340 --> 00:42:03.460
And it would be fine.

00:42:03.460 --> 00:42:05.560
There were other, like, circumstances.

00:42:05.560 --> 00:42:11.000
For example, as a big fan of Talk Python to me, I watched the episode on FastAPI.

00:42:11.000 --> 00:42:12.940
I watched the episode on Pydantic.

00:42:13.460 --> 00:42:16.300
And I knew of the symbiosis between the two of them.

00:42:16.300 --> 00:42:22.180
But for us, we started with Kerberos as a schema validation technology.

00:42:22.180 --> 00:42:25.520
Which comes out of the Eve project from my friend Acola, by the way.

00:42:25.520 --> 00:42:25.700
Yeah.

00:42:25.840 --> 00:42:29.600
And we evolved into using Marshmallow, replacing Kerberos.

00:42:29.600 --> 00:42:31.520
We compared with Pydantic.

00:42:31.520 --> 00:42:37.920
And at the time, we didn't want to, like, extract Pydantic from FastAPI and use FastAPI with Marshmallow.

00:42:38.320 --> 00:42:43.960
So we went with Flask that was, like, not opinionated about what the schema should look like.

00:42:43.960 --> 00:42:46.300
And we went with Flask and Marshmallow.

00:42:46.300 --> 00:42:46.640
Nice.

00:42:46.640 --> 00:42:53.060
Some other interesting building blocks that you highlighted is Pint, P-I-N-T for units.

00:42:53.060 --> 00:42:54.600
Pint is super cool.

00:42:54.600 --> 00:42:55.960
Tell people a bit about Pint.

00:42:55.960 --> 00:42:56.500
Exactly.

00:42:56.500 --> 00:43:03.360
So one of the things that we're doing on this particular project was it's supposed to be international.

00:43:03.360 --> 00:43:05.960
And it's, like, heavy on the physics.

00:43:05.960 --> 00:43:09.800
So we're dealing with rates and concentrations.

00:43:09.800 --> 00:43:12.040
There's a lot of chemistry going on.

00:43:12.040 --> 00:43:17.500
We're talking about the metric system, U.S. customary, imperial systems.

00:43:17.500 --> 00:43:23.020
So converting between units was going to be a big part of the system.

00:43:23.020 --> 00:43:25.260
And then we find out about Pint.

00:43:25.260 --> 00:43:28.600
I was, like, in the Pint community for over 20 years.

00:43:28.600 --> 00:43:35.440
I shook hands with Guido von Russell in 2005 when I translated his tutorial to Portuguese.

00:43:35.820 --> 00:43:38.480
But I never heard of Pint in those 20 years.

00:43:38.480 --> 00:43:45.220
But when I had the need, I did a quick research and I found exactly the solution that we wanted.

00:43:45.220 --> 00:43:53.040
So Pint uses the excellent object orientation that we have in Python to transparently create

00:43:53.040 --> 00:43:55.400
this, like, new integers and floats.

00:43:55.400 --> 00:43:57.420
They're just not numbers.

00:43:57.420 --> 00:44:00.620
But they also have a unit together with them.

00:44:00.740 --> 00:44:01.620
It's so fantastic.

00:44:01.620 --> 00:44:04.560
Let me maybe describe this little example on the Pint homepage.

00:44:04.560 --> 00:44:13.720
So if I wanted to have three meters plus four centimeters, instead of saying three times 100 plus four or vice versa, you know, divide by 100.

00:44:13.720 --> 00:44:18.140
You have three times meter plus four times CM.

00:44:18.140 --> 00:44:21.660
And then what you get back is a quantity, which is 3.04 meters.

00:44:21.660 --> 00:44:22.380
It's fantastic.

00:44:22.380 --> 00:44:22.960
Exactly.

00:44:23.080 --> 00:44:27.140
You could even do something horrible like three meters plus seven inches if you had to.

00:44:27.140 --> 00:44:32.240
And it becomes even more powerful when you're talking about different kind of dimensions.

00:44:32.240 --> 00:44:42.220
For example, if I want a concentration and I'm going to like to divide mass per volume, and then I need to make sure that my calculation makes sense.

00:44:42.800 --> 00:44:44.820
So Pint allows you to do that.

00:44:44.820 --> 00:44:49.440
So you do those conversions and the units are preserved.

00:44:49.440 --> 00:44:52.560
And because the units are preserved, it's easier to test.

00:44:52.560 --> 00:44:53.960
It's easier to compute.

00:44:53.960 --> 00:45:00.500
So it's really a lifesaver that saves us a lot of time while coding this API.

00:45:00.500 --> 00:45:05.060
Yeah, this is not something that in my world I do anything with these days, really.

00:45:05.060 --> 00:45:07.220
But if I did, boy, I'd be all over Pint.

00:45:07.220 --> 00:45:07.940
That thing's cool.

00:45:07.940 --> 00:45:10.040
Also, there was Unit.

00:45:10.040 --> 00:45:10.840
Yes.

00:45:10.840 --> 00:45:20.460
I've also just recently heard about, and I don't know really how they can, UNYT, but this is also something similar in that regard as well.

00:45:20.460 --> 00:45:26.940
Yeah, we, at the time, and I'm talking about early 2020, we evaluated a couple.

00:45:26.940 --> 00:45:33.000
I don't remember if Unity we checked, but there were three others besides Pint.

00:45:33.000 --> 00:45:36.360
But in the end, Pint sound the most robust one.

00:45:36.360 --> 00:45:37.780
But I'll check Unity again.

00:45:37.780 --> 00:45:37.940
Yeah.

00:45:37.980 --> 00:45:41.300
I guess, what's your assessment now that you've been actually using Pint?

00:45:41.300 --> 00:45:41.620
It's good?

00:45:41.620 --> 00:45:42.460
We're super happy.

00:45:42.460 --> 00:45:47.020
If we have like zero issues with Pint, it saved our lives time and again.

00:45:47.020 --> 00:45:47.300
Yeah.

00:45:47.300 --> 00:45:49.380
Another one that you'll run into is Time.

00:45:49.380 --> 00:45:51.560
So you used Pendulum for that.

00:45:51.660 --> 00:45:57.040
I was even a little bit resistant in the beginning because I was using date time forever.

00:45:57.040 --> 00:46:01.900
And of course, members of my team were suggesting, hey, why don't we use Pendulum?

00:46:01.900 --> 00:46:03.500
It has a really nice interface.

00:46:03.500 --> 00:46:12.740
And the deal breaker for me was that the Pendulum object, it inherits from the regular daytime objects.

00:46:13.140 --> 00:46:14.900
So they are completely interchangeable.

00:46:14.900 --> 00:46:21.600
The one thing I didn't want to happen was to have like these two kind of libraries dealing with time.

00:46:21.600 --> 00:46:26.040
And in that case, daytime is standard in the standard Pint library.

00:46:26.040 --> 00:46:32.140
Something else external would be a cause of concern for me in my experience.

00:46:32.460 --> 00:46:34.200
But in that case, it was seamless.

00:46:34.200 --> 00:46:36.820
So I can use either Pendulum or daytime.

00:46:36.820 --> 00:46:41.100
It doesn't matter because they all inherit from the same root.

00:46:41.100 --> 00:46:42.580
So that was key.

00:46:42.580 --> 00:46:48.060
And to be honest, it was convenient, especially for time zones.

00:46:48.060 --> 00:46:56.680
But remember that that was before, I think it was on Python 3.9, that we had better support for time zones.

00:46:56.680 --> 00:47:00.700
And at least in the standard Python.

00:47:00.880 --> 00:47:06.460
And at that time, I think Pendulum was having a better way to handle with time zone conversion.

00:47:06.460 --> 00:47:09.440
That was key for us in terms of the solution.

00:47:09.440 --> 00:47:11.800
We never know where our athletes are going to be in the world.

00:47:11.800 --> 00:47:13.860
So that was the key reason.

00:47:13.860 --> 00:47:16.380
And we're happy with Pendulum.

00:47:16.380 --> 00:47:17.500
Yeah, this is super neat.

00:47:17.500 --> 00:47:22.960
You know, I didn't really put it together when I was looking at this before, but the time zone stuff is quite interesting.

00:47:22.960 --> 00:47:30.480
Like something that's always a challenge that I deal with is when I'm working with some of the web apps that I have,

00:47:30.500 --> 00:47:36.720
or other things, just where is the server versus where is the person accessing the server?

00:47:37.260 --> 00:47:40.540
And it turns out to be way more annoying than you think, right?

00:47:40.540 --> 00:47:44.540
Like another thing we're going to talk about is using MongoDB for the backend on this.

00:47:44.540 --> 00:47:45.320
And so am I.

00:47:45.320 --> 00:47:47.400
And I'm just a super fan of MongoDB.

00:47:47.400 --> 00:47:51.540
It's been such a nice way to make fast, easy to maintain apps.

00:47:51.720 --> 00:47:56.840
But it stores stuff at like UTC, whereas the server, I think, is in Eastern time zone.

00:47:56.840 --> 00:47:58.460
And I'm in the Pacific time zone.

00:47:58.460 --> 00:48:02.960
And so if I want to pull something up, so this event is going to happen then, or it happened at what time?

00:48:02.960 --> 00:48:06.100
It's not easy to say, well, that was an hour ago.

00:48:06.240 --> 00:48:08.780
Like something so simple as here's a list of activities.

00:48:08.780 --> 00:48:10.040
And this one was an hour ago.

00:48:10.040 --> 00:48:10.820
It's challenging.

00:48:10.820 --> 00:48:11.660
And this is really cool.

00:48:11.660 --> 00:48:16.700
So you can say, instead of daytime now, I can say pendulum.now and then pass in the base time zone.

00:48:16.700 --> 00:48:21.460
And I say, well, what is now in, you know, inbound time zone or something like that, right?

00:48:21.460 --> 00:48:22.760
Would be really, really nice.

00:48:22.760 --> 00:48:30.280
The strategy we took, which is kind of traditional strategy, is that at all the edges of the system, we convert to UTC.

00:48:30.280 --> 00:48:34.080
And inside, we're just reasoning on UTC.

00:48:34.080 --> 00:48:43.820
And only when we're kind of exporting information through this membrane of the system back to close to the user, then we translate back to their time zone.

00:48:43.820 --> 00:48:49.700
However, it gets tricky when we're talking about not real time, but nominal time.

00:48:49.700 --> 00:48:50.860
What is nominal time?

00:48:50.860 --> 00:48:54.220
For example, I wake up at 7 a.m.

00:48:54.220 --> 00:48:57.820
So 7 a.m. for me, it's a nominal time.

00:48:57.820 --> 00:49:00.600
It's not anchored on any place on Earth.

00:49:00.600 --> 00:49:04.020
It's like the time that I'm supposed to wake up.

00:49:04.020 --> 00:49:10.220
The nominal time becomes trickier because it's not anchored on a particular place.

00:49:10.220 --> 00:49:13.500
So you have to deal with those kind of things a little bit differently.

00:49:13.500 --> 00:49:19.280
But other than that, Pendle was very ergonomic in terms of their API.

00:49:19.280 --> 00:49:20.440
It's super easy.

00:49:20.440 --> 00:49:22.160
You can keep it on your mind.

00:49:22.160 --> 00:49:24.820
And it's compatible with date time.

00:49:24.820 --> 00:49:25.660
So it was a plus.

00:49:25.660 --> 00:49:26.440
We're happy.

00:49:26.560 --> 00:49:35.340
That's a really neat point because if you've got some other API that takes a date time, you can just pass in the Pendle time and it just, it is a date time.

00:49:35.340 --> 00:49:35.540
Yeah.

00:49:35.540 --> 00:49:35.860
Right?

00:49:35.860 --> 00:49:38.060
So you don't have to major, oh, I forgot to convert here.

00:49:38.060 --> 00:49:38.760
So it's broken.

00:49:38.760 --> 00:49:41.680
So the lander crashed into the ground because, you know, whatever.

00:49:41.680 --> 00:49:42.220
Exactly.

00:49:42.300 --> 00:49:44.580
All those units and conversion types are weird.

00:49:44.580 --> 00:49:44.820
Yeah.

00:49:44.820 --> 00:49:45.580
And the arithmetic.

00:49:45.580 --> 00:49:46.360
Right?

00:49:46.360 --> 00:49:50.360
So I think that is the other aspect that Pendle makes a little bit easier.

00:49:50.360 --> 00:50:03.340
The arithmetic one is like, as a day subtract minutes, this duality between a point in time and a delta that we do have on like the time and time delta and all the Python API.

00:50:03.340 --> 00:50:11.160
But Pendle also helps you in that sense to do those conversions in terms of like scale and arithmetic.

00:50:11.160 --> 00:50:13.000
So it was really interesting.

00:50:13.000 --> 00:50:13.280
Yeah.

00:50:13.280 --> 00:50:16.900
One quick thought I'll throw out there that because this was such a surprise to me.

00:50:16.900 --> 00:50:21.340
I just had, it's so undiscoverable, but it's good once you know it.

00:50:21.340 --> 00:50:21.560
Yeah.

00:50:21.560 --> 00:50:22.400
It's good to know it.

00:50:22.400 --> 00:50:23.460
Let's put it that way, at least.

00:50:23.460 --> 00:50:28.880
That when you're doing, forget Pendle for a minute, if you're just doing raw date times and time deltas.

00:50:28.880 --> 00:50:31.700
So time deltas always have a seconds, right?

00:50:31.700 --> 00:50:31.980
Yeah.

00:50:31.980 --> 00:50:36.120
So I create a time, a difference between two times or I take a time and add a time delta.

00:50:36.120 --> 00:50:38.500
I get a new time delta or you get new time.

00:50:38.500 --> 00:50:42.800
But if you have a time delta and it's in seconds, which is basically the only option you get.

00:50:42.800 --> 00:50:45.140
And you want to know, well, I need this in hours.

00:50:45.140 --> 00:50:48.080
I would always just go two total seconds divided by 60.

00:50:48.080 --> 00:50:48.660
Exactly.

00:50:48.660 --> 00:50:50.280
Divided by 60 again.

00:50:50.280 --> 00:50:56.880
What you can do is create another time delta and say time delta hours equals one and then divide one by the other.

00:50:56.880 --> 00:50:59.060
And then you get a number of hours.

00:50:59.120 --> 00:51:05.380
Or if you want like weeks, time delta is seven days and you divide your time delta by that and it'll give you the days.

00:51:05.380 --> 00:51:06.460
And that's really handy.

00:51:06.460 --> 00:51:09.320
But boy, is it hard to discover to know that that's possible.

00:51:09.640 --> 00:51:09.960
Exactly.

00:51:09.960 --> 00:51:13.480
And that's where I think Python shines as well.

00:51:13.480 --> 00:51:22.020
Because since the beginning, one of the arguments in favor of Python, it was when people said Python is pseudocode that runs.

00:51:22.020 --> 00:51:26.800
They were telling you Python brings you closer to the domain of the problem.

00:51:26.800 --> 00:51:27.380
Right.

00:51:27.780 --> 00:51:29.000
And that matters.

00:51:29.000 --> 00:51:31.740
Syntax sugar matters.

00:51:31.740 --> 00:51:36.860
Because the way you express software, it means you make less mistakes.

00:51:36.860 --> 00:51:39.420
So when you read it, you fully understand it.

00:51:39.420 --> 00:51:39.640
Yeah.

00:51:39.640 --> 00:51:41.660
It's easy to do a review.

00:51:41.660 --> 00:51:43.920
It's easy to do maintenance.

00:51:43.920 --> 00:51:45.960
It's easy to throw in and write it again.

00:51:45.960 --> 00:51:46.960
That matters.

00:51:47.520 --> 00:51:56.900
So it's not just about if you know the logic, if you know the theory, but in the way you express the logic and the theory matters a lot.

00:51:56.900 --> 00:51:57.300
Absolutely.

00:51:57.300 --> 00:51:57.980
Totally agree.

00:51:57.980 --> 00:51:58.560
All right.

00:51:58.560 --> 00:52:03.020
Let's talk one more element here on this one.

00:52:03.020 --> 00:52:05.880
And that's the database side of things.

00:52:05.880 --> 00:52:07.440
Why did you choose MongoDB?

00:52:07.440 --> 00:52:09.220
What's your experience working with it?

00:52:09.220 --> 00:52:10.000
That's a great question.

00:52:10.000 --> 00:52:10.540
That's an example.

00:52:10.540 --> 00:52:11.260
That's a great question.

00:52:11.260 --> 00:52:19.080
So I came while I was at the university, I was working with the database group and I had a lot of experience with like database.

00:52:19.080 --> 00:52:25.420
I played with object oriented database in 1993, the French object database called O2.

00:52:25.420 --> 00:52:29.220
As time went by, we had Zope and Zodb.

00:52:29.220 --> 00:52:31.120
I played a lot with Zodb.

00:52:31.120 --> 00:52:33.380
I even made a tiny little contribution to Zope.

00:52:33.380 --> 00:52:38.040
So I've been exposed to NoSQL before NoSQL became a thing.

00:52:38.040 --> 00:52:40.440
But of course, SQL was still there.

00:52:40.960 --> 00:52:44.980
But what we wanted was, again, development time.

00:52:44.980 --> 00:52:55.720
So as a director at Working Co., my main consideration is, can I make this project fit the budget and the schedule before I exactly know what we have to do?

00:52:55.720 --> 00:53:01.140
Because details will only be captured at the end of the conceptual design phase.

00:53:01.200 --> 00:53:06.000
But at that point in time, the money is defined, the schedule is set.

00:53:06.000 --> 00:53:13.240
So it's like, okay, I'll build the pyramids, but I don't know what's going to be like bringing those blocks of rock across the Nile.

00:53:13.760 --> 00:53:17.680
So because of that, I wanted to go for flexibility first.

00:53:17.680 --> 00:53:24.300
And going for a NoSQL database, it gives you speed in terms of development time, right?

00:53:24.300 --> 00:53:26.260
So you can put anything in there.

00:53:26.260 --> 00:53:34.280
Mongo is storing information in the same formats as the applications are consuming then, which today are like...

00:53:34.280 --> 00:53:37.100
You don't have that object relational impedance mismatch.

00:53:37.100 --> 00:53:38.600
You just have it's in Python.

00:53:38.600 --> 00:53:40.000
Now it's in Mongo.

00:53:40.000 --> 00:53:41.180
Now it's back in Python.

00:53:41.180 --> 00:53:43.440
It's the arms of the world.

00:53:43.440 --> 00:53:46.780
I always was let down by arms.

00:53:47.040 --> 00:53:54.420
Because in the beginning, when you know nothing, they are great because you don't need to learn the actual language of the database.

00:53:54.420 --> 00:54:05.320
After you evolve, they become a barrier because they are never as sophisticated as the data manipulation language of the database, right?

00:54:05.320 --> 00:54:08.040
And then you say, oh, why they don't support this and that?

00:54:08.040 --> 00:54:13.280
My challenge has been more operational with ORMs is they're pretty good.

00:54:13.280 --> 00:54:16.240
And a lot of times, if you have the right indexes, you know, the speed can be okay.

00:54:16.240 --> 00:54:23.280
If you make sure you do the joins instead of the lazy N plus one type of queries, you'll be okay.

00:54:23.280 --> 00:54:25.980
But you build up your classes and everything's easy.

00:54:25.980 --> 00:54:29.820
And then you want to add a field to a class.

00:54:29.820 --> 00:54:30.840
You want to create a relationship.

00:54:30.840 --> 00:54:32.540
Well, now you try to run your app.

00:54:32.540 --> 00:54:33.760
It doesn't just not work well.

00:54:33.760 --> 00:54:36.660
It fully crashes until you do a database migration.

00:54:36.660 --> 00:54:41.000
And are you doing that migration in production and staging and dev?

00:54:41.000 --> 00:54:47.420
And then what's the downtime story as you roll out the changes to your multiple servers that all got to talk to that database?

00:54:47.420 --> 00:54:48.180
It's like, ah.

00:54:48.180 --> 00:54:52.360
And for me, something like Mongo that is just so much more likely to adapt.

00:54:52.360 --> 00:54:57.400
Like I haven't run a database migration or anything like that for years.

00:54:57.400 --> 00:55:01.140
You know, people talk about Mongo for like it's web scale and it's all this data.

00:55:01.140 --> 00:55:01.960
And that's great.

00:55:01.960 --> 00:55:07.700
I mean, like my database probably has seven gigs of data for like talk by done training and the podcast.

00:55:07.700 --> 00:55:11.720
And that's a non-trivial amount of data, but it's not so much about the data.

00:55:11.720 --> 00:55:12.880
It's about the flexibility.

00:55:12.880 --> 00:55:19.320
Like it's easy to make it fast and it doesn't require DevOps at the extreme to do it well.

00:55:19.320 --> 00:55:19.680
You know?

00:55:19.680 --> 00:55:22.260
That is a great point because managing the database.

00:55:22.260 --> 00:55:23.360
I mentioned DevOps.

00:55:23.360 --> 00:55:29.680
So because Mongo, they also provide the Atlas service where you have like database as a service.

00:55:29.680 --> 00:55:33.420
That was key for us because then we can like forget about this.

00:55:33.420 --> 00:55:34.980
We simply connect to Atlas.

00:55:34.980 --> 00:55:36.140
They manage our cluster.

00:55:36.320 --> 00:55:38.540
They have the dashboards, everything in place.

00:55:38.540 --> 00:55:44.540
It was one click of a button to migrate from one version of Mongo to another version of Mongo.

00:55:44.540 --> 00:55:49.440
So those things are priceless when you're doing like quick-paced development.

00:55:49.440 --> 00:55:50.900
There was another reason though.

00:55:50.900 --> 00:55:55.040
In the beginning of this project, PepsiCo asked us to use Azure.

00:55:55.040 --> 00:56:02.220
So that meant we were doing our Python services within Azure and we had to do a database within Azure.

00:56:02.220 --> 00:56:07.460
And we went for CosmoDB because CosmoDB was compatible with Mongo.

00:56:07.460 --> 00:56:12.920
If at any point in time we needed to move out of CosmoDB, we would have Mongo as a fallback.

00:56:12.920 --> 00:56:14.560
And that's exactly what happened.

00:56:14.560 --> 00:56:19.120
So a couple of months, there were some political changes within PepsiCo.

00:56:19.360 --> 00:56:30.080
They decided to go like AWS out of Azure and then boom, we had MongoDB in Atlas and we had like the same cluster in AWS for Python.

00:56:30.080 --> 00:56:31.020
We were happy.

00:56:31.020 --> 00:56:31.560
Totally agree.

00:56:31.560 --> 00:56:32.460
Fantastic.

00:56:32.460 --> 00:56:38.300
So I know we're going to talk about a bunch of APIs, but we spent all our time talking about this one.

00:56:38.300 --> 00:56:38.860
Sure.

00:56:38.860 --> 00:56:44.040
But I think this is really a super interesting thing to dive into.

00:56:44.040 --> 00:56:48.740
We can touch on some of the other ones maybe a little bit, but I guess before we move off of this,

00:56:48.740 --> 00:56:51.980
like what's one of the big takeaways you took from this project here?

00:56:51.980 --> 00:56:53.240
Oh, that's such a big question.

00:56:53.240 --> 00:56:55.100
There are like many things.

00:56:55.100 --> 00:57:00.300
The biggest perhaps is at the core of the agile mindset.

00:57:00.300 --> 00:57:05.400
After you implement stuff, it's really when you start to understand the problem.

00:57:05.400 --> 00:57:11.640
It's really, really hard to kind of design on paper and then it just works.

00:57:11.640 --> 00:57:17.240
So what we did for this project was many, many cycles of software rewrite.

00:57:17.240 --> 00:57:32.360
When the project started back in 2019, like over the weekend, when they presented me the problem over the weekend, I was able to, on a Friday afternoon, Saturday and Sunday, to work on a tiny little full-blown solution.

00:57:32.360 --> 00:57:33.360
I had a timeline.

00:57:33.360 --> 00:57:35.360
I had a recommendation system.

00:57:35.360 --> 00:57:36.800
I had recommendations.

00:57:36.800 --> 00:57:47.680
It was kind of mockery a little bit, but I was able to cook that up in three days, show that to the clients and say, this is more or less what you're going to do.

00:57:47.680 --> 00:57:49.480
And they really understood what was in there.

00:57:49.860 --> 00:57:56.460
And then we threw all of that away and built like the new version, like on Troy, many cities built one on top of the other.

00:57:56.460 --> 00:57:58.500
So that's what happened on this API.

00:57:58.500 --> 00:58:02.360
Like we're doing microservices, like let's do Monolith.

00:58:02.360 --> 00:58:03.760
We're doing Cosmo.

00:58:03.760 --> 00:58:04.600
Let's do Mongo.

00:58:04.600 --> 00:58:06.360
We're doing Quartz.

00:58:06.360 --> 00:58:07.840
Let's just do Flask.

00:58:07.840 --> 00:58:08.920
We're doing Kerberos.

00:58:08.920 --> 00:58:10.140
Let's do Marshmallow.

00:58:10.300 --> 00:58:24.400
Being able to throw things away and kind of rebuild, refactor, the power of refactoring made us to have a system that's always performing, that's manageable, that's minimal technical debt.

00:58:24.400 --> 00:58:31.640
And I think that was the key learning that I was able to fully apply in this long-term projects, like two years.

00:58:31.640 --> 00:58:36.200
That is not common for a working coach to have this two long projects.

00:58:36.660 --> 00:58:39.960
Usually our project is like three months, six months, maybe a year.

00:58:39.960 --> 00:58:43.240
But in the case of Gatorade, it's a retainer project.

00:58:43.240 --> 00:58:45.520
We're for the long run with them.

00:58:45.520 --> 00:58:49.700
And in this case, you really need to evolve the platform.

00:58:49.700 --> 00:58:52.700
It's like maintenance-driven development.

00:58:52.700 --> 00:58:55.720
Does that actually give you a different mindset when you're creating?

00:58:55.720 --> 00:58:58.420
You're like, I am going to have to live with this.

00:58:58.420 --> 00:58:59.200
Not they.

00:58:59.200 --> 00:59:00.220
We're going to have to live with it.

00:59:00.220 --> 00:59:09.180
I think that is the most difference between what I consider seasoned developers and new developers.

00:59:09.180 --> 00:59:13.880
We have like junior developers that they are very competent.

00:59:13.880 --> 00:59:15.880
They are very capable.

00:59:15.880 --> 00:59:18.320
They master really quickly new technologies.

00:59:18.820 --> 00:59:30.860
But the difference is to fully understand the impacts of decisions, not just based on theory, but based on social events that may or may not happen, based on what the future may bring.

00:59:30.860 --> 00:59:33.740
And experience counts a lot in that sense.

00:59:33.740 --> 00:59:42.680
And the maintenance-driven development mindset, when you know you're the one that you're going to do the maintenance, changes things a lot.

00:59:42.680 --> 00:59:48.140
You think about stability, robustness, task coverage in a completely different way.

00:59:48.140 --> 00:59:52.200
I totally, it seems like it absolutely would if you're the one who's got to live with it.

00:59:52.200 --> 00:59:57.900
Because you go to some of these consulting projects and they're like, oh, we really want to use this specific database.

00:59:57.900 --> 01:00:00.120
We want to use this framework, but in this odd way.

01:00:00.120 --> 01:00:01.480
And you're like, well, they're the customer.

01:00:01.480 --> 01:00:02.200
They're always right.

01:00:02.200 --> 01:00:06.840
But if it's going to be you, you're like, yeah, we better build this the way that we're going to be happy in a year.

01:00:06.840 --> 01:00:15.100
You know, there's that, it reminds me of that funny quote, like, always code as if a person who ends up maintaining your code will be a violent cycle path.

01:00:15.100 --> 01:00:16.080
That's where you live, right?

01:00:16.080 --> 01:00:17.260
Very good. That's good advice.

01:00:17.260 --> 01:00:23.060
Yeah, a little bit morbid, but do think about that you'll have to live with it, I guess.

01:00:23.060 --> 01:00:27.080
And I think that talks to the trend they call boring codes, right?

01:00:27.080 --> 01:00:30.040
There's a bunch of like speeches and talks on the internet.

01:00:30.040 --> 01:00:32.360
People talk about, oh, right, boring codes.

01:00:32.360 --> 01:00:34.720
Codes are easy to understand, easy to do maintenance.

01:00:34.920 --> 01:00:45.500
It has this mindset that when you're learning things and you're not concerned about production stuff, you are much more bold to try new things, right?

01:00:45.500 --> 01:00:48.780
Because then the project is done, you move away.

01:00:48.780 --> 01:00:56.240
So there's no cost, there's no risk, there's no penalty for trying new stuff that may prove inadequate.

01:00:56.240 --> 01:01:05.380
But when your success measurement is considering the maintenance phase, the long-term success of the project, the mindset is a different one.

01:01:05.380 --> 01:01:08.020
It's what is stable, what's guaranteed.

01:01:08.340 --> 01:01:12.340
If you're chasing the shiny new thing, you could end up saying, well, I'm going to build this six-month project.

01:01:12.340 --> 01:01:13.140
I'll do that in React.

01:01:13.140 --> 01:01:14.480
And this one is going to be in Vue.

01:01:14.480 --> 01:01:15.560
And this one will be in Angular.

01:01:15.560 --> 01:01:17.920
And this is going to have this backend and that backend.

01:01:17.920 --> 01:01:22.380
And then all of a sudden, you end up maintaining every JavaScript front-end framework in the world.

01:01:22.380 --> 01:01:22.920
Exactly.

01:01:23.600 --> 01:01:25.820
And yeah, you don't want to be like that.

01:01:25.820 --> 01:01:28.760
I think the other thing you touched on is really interesting.

01:01:28.760 --> 01:01:37.920
One of the things that I try to preach a lot is it often doesn't matter too much how you get started so much as you get started on a project.

01:01:37.920 --> 01:01:40.800
I see a lot of people saying, you know, they'll get frozen.

01:01:40.800 --> 01:01:47.140
They're like, well, I just can't decide between Django and Flask or FastAPI or this or Postgres or Mongo.

01:01:47.140 --> 01:01:51.100
And they just, they think and they think and they think and they don't get anywhere.

01:01:51.100 --> 01:01:54.360
Like you highlighted with your, I did it over the weekend prototype.

01:01:54.360 --> 01:02:05.020
A lot of times those people who are stuck, if they just fully internalize, like you can just go on a path and then evolve it with refactoring and change it and throw it away and rewrite it with more knowledge.

01:02:05.020 --> 01:02:09.600
The time you spent worrying about what to do, you would already have a working example, probably.

01:02:09.600 --> 01:02:13.340
And then you have so much more information to build from and decide from.

01:02:13.340 --> 01:02:15.060
I think that's a really important takeaway.

01:02:15.060 --> 01:02:16.320
God is in the details.

01:02:16.720 --> 01:02:18.320
Nobody stumbles and mouthings.

01:02:18.320 --> 01:02:20.620
It's the little things that make your fault.

01:02:20.620 --> 01:02:21.800
That's a good quote.

01:02:21.800 --> 01:02:22.540
I like it.

01:02:22.540 --> 01:02:23.340
Nice.

01:02:23.340 --> 01:02:23.680
All right.

01:02:23.680 --> 01:02:34.060
Well, I think rather than diving into the other APIs that we're going to cover, I think maybe just this deep one into the DXSWet patches is probably a little bit more constructive and useful.

01:02:34.060 --> 01:02:36.040
So maybe we'll leave it here for the APIs.

01:02:36.040 --> 01:02:36.360
Cool.

01:02:36.360 --> 01:02:37.540
Really, really neat work.

01:02:37.540 --> 01:02:39.040
A lot of moving parts, right?

01:02:39.040 --> 01:02:40.080
You've got your mobile apps.

01:02:40.080 --> 01:02:41.580
You've got your mobile apps in Xamarin.

01:02:41.580 --> 01:02:43.600
You've got your ML models.

01:02:44.000 --> 01:02:49.360
You've got the APIs, the other external API integration, the other app integration.

01:02:49.360 --> 01:02:50.680
A lot of stuff going on here, right?

01:02:50.680 --> 01:02:52.140
So I think it's a pretty good case study.

01:02:52.140 --> 01:02:52.580
It is.

01:02:52.580 --> 01:03:04.320
One bit that we didn't mention, I'd like to really quickly mention, is that we have another engine for product recommendations that use constraint problem solving.

01:03:04.320 --> 01:03:10.180
And this was, we're reusing a module, a colleague of mine called Gustavo Niemeyer.

01:03:10.180 --> 01:03:13.980
He's a core developer for Python, now working for Canonical.

01:03:13.980 --> 01:03:17.380
And he was with me in Europython 2005.

01:03:17.380 --> 01:03:26.060
And on Europython 2005, he presented a Python module that now we're using to solve those constraint-based problem optimization.

01:03:26.060 --> 01:03:30.280
And that was really cool because it's a really powerful mechanism.

01:03:30.280 --> 01:03:35.800
And the problem we were solving was that you have all of these needs, right?

01:03:35.800 --> 01:03:40.620
Needs for carbs, needs for protein, needs for hydration, needs for electrolytes.

01:03:40.620 --> 01:03:45.620
And then you have all of these products that have different combinations of those elements.

01:03:45.620 --> 01:03:50.540
So what is the optimal amount of products and types of products?

01:03:50.540 --> 01:03:57.800
And what is the minimal amount that you need to kind of fulfill all your nutritional and hydrational needs?

01:03:57.800 --> 01:04:00.660
And for that, we use Python Constraint.

01:04:00.660 --> 01:04:05.740
There are other engines there, but we want it to be like fully Python solution.

01:04:05.740 --> 01:04:09.100
And that is another hint that I want to share with people.

01:04:09.100 --> 01:04:13.540
That is, it solves like a big problem and it's really easy to use.

01:04:13.540 --> 01:04:16.660
And this is Python-Constraint on PyPI?

01:04:16.660 --> 01:04:17.500
Yes, exactly.

01:04:17.500 --> 01:04:19.920
This one you have on screen, Python-Constraint.

01:04:19.920 --> 01:04:20.460
Looks really cool.

01:04:20.460 --> 01:04:22.220
It reminds me a little bit of linear programming.

01:04:22.220 --> 01:04:22.880
It is.

01:04:22.880 --> 01:04:32.200
The difference is, well, actually, you have linear programming like simplex, where you're kind of going into the plane and trying to optimize numerically.

01:04:32.200 --> 01:04:33.680
This is one kind of thing.

01:04:33.680 --> 01:04:39.420
This other one is more on exploring a discrete space of solutions.

01:04:39.500 --> 01:04:50.800
So you define your variables, the domain of values for each of these variables, and the constraints that validate, is this combination of values a solution to the problem or not?

01:04:50.800 --> 01:04:52.180
If not, it's refuse.

01:04:52.180 --> 01:04:54.200
So then it's a search space.

01:04:54.200 --> 01:04:54.500
Yeah.

01:04:54.500 --> 01:04:57.460
So there's like a chess problem, the rook.

01:04:57.460 --> 01:04:58.000
Exactly.

01:04:58.000 --> 01:05:01.060
Which clearly is not a continuous problem.

01:05:01.060 --> 01:05:01.800
It's a very discrete.

01:05:01.800 --> 01:05:06.180
The rook can be in one of, you know, 100 places or whatever on a chessboard, and that's it.

01:05:06.180 --> 01:05:07.020
Very cool.

01:05:07.020 --> 01:05:09.680
One final thing on this project here.

01:05:09.680 --> 01:05:14.220
Now that you've created it, how many people are keeping it going and working on it?

01:05:14.220 --> 01:05:16.100
What's the team size at the beginning and the end?

01:05:16.100 --> 01:05:22.120
I mean, we talked about the monolith versus microservices, but not really the details there that made you decide the monolith side.

01:05:22.220 --> 01:05:22.940
That's a great question.

01:05:22.940 --> 01:05:27.040
So first of all, all the time we're talking about the GX consumer.

01:05:27.040 --> 01:05:33.080
So for like you and me, we also have another app that talks to the same API called GX Teams.

01:05:33.080 --> 01:05:40.560
And the GX Teams is for practitioners, coaches, personals, that they are managing a group of athletes.

01:05:40.560 --> 01:05:44.060
So this is another thing that Gatorade launched, I guess, this month.

01:05:44.220 --> 01:05:48.600
Both apps are up to the same API that we call GX Rack Engine.

01:05:48.600 --> 01:05:55.420
So just for GX Rack Engine, our development team is today for people.

01:05:55.420 --> 01:06:01.520
It's me, Joo Gomes, Nicolas Moya, Rodrigo Merlo, and Sachari Moreno.

01:06:01.520 --> 01:06:02.920
So it's me plus four.

01:06:02.920 --> 01:06:05.020
That is the whole backend team.

01:06:05.020 --> 01:06:12.940
For frontend, for PM, strategy, business, product, then it's kind of gross, right?

01:06:13.300 --> 01:06:18.160
But the things that we talk about in the Python world, we're talking about five people.

01:06:18.160 --> 01:06:19.400
You know, that's super common.

01:06:19.400 --> 01:06:24.920
If we look at the Python developer survey from the PSF and we go down and look at the team size,

01:06:24.920 --> 01:06:30.040
the average team size, 75% of the time was two to seven people.

01:06:30.040 --> 01:06:32.280
Yeah, it's the pizza rule, right?

01:06:32.280 --> 01:06:32.760
Yeah.

01:06:32.760 --> 01:06:39.060
If you get out to what I would call the microservice side, you know, that's maybe 20 people or so.

01:06:39.060 --> 01:06:45.220
And 20 people or more on the team size is only 4% of all software developers doing Python.

01:06:45.220 --> 01:06:52.540
So keep that in balance when you hear about like, you know, how Netflix or Google or Instagram is doing some amazing thing, right?

01:06:52.540 --> 01:06:55.420
That context doesn't necessarily apply to like your context.

01:06:55.420 --> 01:06:55.780
Exactly.

01:06:55.780 --> 01:06:56.620
And they break down.

01:06:56.800 --> 01:07:01.620
I worked for global.com, which is the biggest news company in Brazil.

01:07:01.820 --> 01:07:08.780
We had a audience of 4 million people like daily going through like our websites, etc.

01:07:08.780 --> 01:07:13.140
And the teams internally, they were like four or five people.

01:07:13.140 --> 01:07:17.080
We none above seven because it becomes unmanageable.

01:07:17.420 --> 01:07:22.120
The communication overhead becomes so high that it's not worth it.

01:07:22.120 --> 01:07:22.800
Super interesting.

01:07:22.800 --> 01:07:25.940
And I think we're going to leave it there, but I'm going to ask you the two final questions.

01:07:25.940 --> 01:07:29.360
Before I do that, let me just call out a couple comments from the live stream.

01:07:29.360 --> 01:07:29.700
Go ahead.

01:07:29.700 --> 01:07:31.660
Black and White said, this video is so great to be frank.

01:07:31.660 --> 01:07:32.180
Thank you.

01:07:32.180 --> 01:07:33.440
And Vincent, hello, hello.

01:07:33.440 --> 01:07:34.660
Love your show.

01:07:34.660 --> 01:07:35.900
Keep up the work, please.

01:07:35.900 --> 01:07:37.180
All your guests are on point.

01:07:37.180 --> 01:07:37.680
Very interesting.

01:07:37.680 --> 01:07:37.960
Yeah.

01:07:37.960 --> 01:07:39.200
Thank you all for being here.

01:07:39.200 --> 01:07:39.900
That's great.

01:07:39.900 --> 01:07:40.760
All right, Rod.

01:07:40.760 --> 01:07:44.180
Working on these projects and others, you're going to write some Python code.

01:07:44.180 --> 01:07:45.580
What editor would you fire up?

01:07:45.580 --> 01:07:46.760
Well, that's a great question.

01:07:46.960 --> 01:07:48.400
So I'm a big fan of PyCharm.

01:07:48.400 --> 01:07:51.120
So I've been using PyCharm forever.

01:07:51.120 --> 01:07:57.960
It has some features that I kind of love, like class hierarchy, like usages of functions,

01:07:57.960 --> 01:07:59.720
the debugging.

01:07:59.720 --> 01:08:02.760
It's super well polished.

01:08:02.760 --> 01:08:05.180
So I use PyCharm for professional work.

01:08:05.180 --> 01:08:08.480
But having said that, I use everything else.

01:08:08.480 --> 01:08:12.360
So I dabble with Visual Studio Code, great tool.

01:08:12.360 --> 01:08:16.380
I use Vim a lot when I'm on the shell or doing stuff.

01:08:16.500 --> 01:08:19.300
And of course, I use Jupyter Notebooks as well.

01:08:19.300 --> 01:08:23.700
And sometimes I code stuff in Jupyter Notebooks, straight on Jupyter Notebooks.

01:08:23.700 --> 01:08:25.360
And it's like lots of code.

01:08:25.360 --> 01:08:26.180
All of those.

01:08:26.180 --> 01:08:26.620
Fantastic.

01:08:26.620 --> 01:08:27.900
I agree with all that.

01:08:27.900 --> 01:08:30.500
And notable PyPI package.

01:08:30.800 --> 01:08:32.820
Well, we mentioned like a couple there, right?

01:08:32.820 --> 01:08:37.320
Like Pint and Pendulum and Python Constrain.

01:08:37.320 --> 01:08:42.420
One that I heard in your show and I explored a little bit is called Rich.

01:08:42.840 --> 01:08:46.980
So I think it was Brad Cannon that mentioned Rich, but I'm not sure right now.

01:08:46.980 --> 01:08:49.960
But that was really awesome as well.

01:08:49.960 --> 01:08:50.800
Really interesting.

01:08:50.800 --> 01:08:52.740
So these are like my picks.

01:08:52.740 --> 01:08:53.100
Yeah.

01:08:53.100 --> 01:08:56.520
Rich is coming along as quite an interesting project.

01:08:56.520 --> 01:08:59.900
It's going, you know, Will there is doing such interesting work.

01:08:59.900 --> 01:09:04.980
And it just has super opened up what you can do in the terminal, I think, in a much more

01:09:04.980 --> 01:09:05.900
approachable way.

01:09:05.900 --> 01:09:07.440
Have you seen Textual?

01:09:07.440 --> 01:09:08.060
No, I haven't.

01:09:08.060 --> 01:09:11.620
I think that Textual is like a layout engine for Rich.

01:09:11.620 --> 01:09:12.460
Oh, that's cool.

01:09:12.460 --> 01:09:13.840
That is coming on here.

01:09:13.840 --> 01:09:19.280
So what you can do is you can break up your terminal and to have like a toolbar, like a

01:09:19.280 --> 01:09:22.280
left docking thing, a footer, and then a main area.

01:09:22.280 --> 01:09:25.080
And then you render into each of those with Rich.

01:09:25.080 --> 01:09:25.540
Fancy.

01:09:25.540 --> 01:09:30.320
You can do like even arrow keys and only like move the main window section.

01:09:30.320 --> 01:09:31.540
Oh, it's yeah.

01:09:31.540 --> 01:09:33.020
There's a lot of cool stuff going there.

01:09:33.020 --> 01:09:33.900
So super cool.

01:09:33.900 --> 01:09:34.140
Yeah.

01:09:34.140 --> 01:09:34.840
It's awesome.

01:09:34.840 --> 01:09:35.420
All right.

01:09:35.420 --> 01:09:36.820
Well, final call to action.

01:09:36.820 --> 01:09:41.460
What's your final advice for people building these APIs thinking about these decisions for

01:09:41.460 --> 01:09:42.040
their own projects?

01:09:42.180 --> 01:09:47.980
Well, one I already have given, it's like be hands on, like try it out, see how it feels,

01:09:47.980 --> 01:09:49.260
get your hands dirty.

01:09:49.260 --> 01:09:51.060
This is crucial in my mind.

01:09:51.060 --> 01:09:54.860
The other one is start thinking about maintenance driven development.

01:09:54.860 --> 01:10:01.400
So when you start, because even if it's not you, somebody will have to like give maintenance.

01:10:01.400 --> 01:10:09.120
So at least balance the costs and benefits of exploration and the advantages and downsides

01:10:09.120 --> 01:10:11.180
of reusing well-established technology.

01:10:11.900 --> 01:10:12.200
Right.

01:10:12.200 --> 01:10:15.740
Look for the Zen, the yin-yang, the balance on these forces.

01:10:15.740 --> 01:10:16.360
Good advice.

01:10:16.360 --> 01:10:17.360
Definitely second it.

01:10:17.360 --> 01:10:18.520
Rod, thanks for being on the show.

01:10:18.520 --> 01:10:19.540
Thank you so much, Michael.

01:10:19.540 --> 01:10:20.180
Yeah, you bet.

01:10:21.180 --> 01:10:23.820
This has been another episode of Talk Python to Me.

01:10:23.820 --> 01:10:26.280
Our guest on this episode was Rod Senra.

01:10:26.280 --> 01:10:30.500
It's been brought to you by Sentry and Linode and the transcripts are brought to you by Assembly

01:10:30.500 --> 01:10:30.900
AI.

01:10:30.900 --> 01:10:32.980
Take some stress out of your life.

01:10:32.980 --> 01:10:36.880
Get notified immediately about errors in your web applications with Sentry.

01:10:36.880 --> 01:10:42.520
Just visit hawkpython.fm slash Sentry and get started for free and use the promo code

01:10:42.520 --> 01:10:45.820
hawkpython2021 when you sign up.

01:10:46.500 --> 01:10:50.880
Simplify your infrastructure and cut your cloud bills in half with Linode's Linux virtual machines.

01:10:50.880 --> 01:10:54.240
Develop, deploy, and scale your modern applications faster and easier.

01:10:54.240 --> 01:10:59.220
Visit hawkpython.fm slash Linode and click the create free account button to get started.

01:10:59.220 --> 01:11:03.440
Transcripts for this and all of our episodes are brought to you by Assembly AI.

01:11:03.440 --> 01:11:06.120
Do you need a great automatic speech to text API?

01:11:06.120 --> 01:11:08.640
Get human level accuracy in just a few lines of code.

01:11:08.840 --> 01:11:11.500
Visit hawkpython.fm slash assembly AI.

01:11:11.500 --> 01:11:13.280
Want to level up your Python?

01:11:13.280 --> 01:11:17.320
We have one of the largest catalogs of Python video courses over at Talk Python.

01:11:17.320 --> 01:11:22.500
Our content ranges from true beginners to deeply advanced topics like memory and async.

01:11:22.500 --> 01:11:25.160
And best of all, there's not a subscription in sight.

01:11:25.160 --> 01:11:28.080
Check it out for yourself at training.talkpython.fm.

01:11:28.080 --> 01:11:32.760
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

01:11:32.760 --> 01:11:34.080
We should be right at the top.

01:11:34.500 --> 01:11:39.240
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

01:11:39.240 --> 01:11:43.440
and the direct RSS feed at /rss on talkpython.fm.

01:11:43.440 --> 01:11:46.860
We're live streaming most of our recordings these days.

01:11:46.860 --> 01:11:50.260
If you want to be part of the show and have your comments featured on the air,

01:11:50.260 --> 01:11:54.640
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

01:11:54.640 --> 01:11:56.540
This is your host, Michael Kennedy.

01:11:56.540 --> 01:11:57.840
Thanks so much for listening.

01:11:57.840 --> 01:11:59.000
I really appreciate it.

01:11:59.000 --> 01:12:00.900
Now get out there and write some Python code.

01:12:00.900 --> 01:12:21.500
I'll see you next time.

01:12:21.500 --> 01:12:51.480
Thank you.

