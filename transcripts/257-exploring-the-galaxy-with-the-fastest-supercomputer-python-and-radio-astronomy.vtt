WEBVTT

00:00:00.001 --> 00:00:04.900
With radio astronomy, we can look across many light years of distance and see incredible details

00:00:04.900 --> 00:00:11.540
such as the chemical makeup of a given region. Kevin Vincent and Rodrigo Tabar from ICRAR are

00:00:11.540 --> 00:00:16.600
using the world's fastest supercomputer, along with some sweet Python, to process the equivalent

00:00:16.600 --> 00:00:23.520
1,600 hours of standard definition YouTube video per second. This is Talk Python To Me,

00:00:23.520 --> 00:00:28.100
episode 257, recorded March 26, 2020.

00:00:28.100 --> 00:00:46.800
Welcome to Talk Python To Me, a weekly podcast on Python, the language, the libraries, the ecosystem,

00:00:46.800 --> 00:00:51.900
and the personalities. This is your host, Michael Kennedy. Follow me on Twitter where I'm @mkennedy.

00:00:51.900 --> 00:00:57.020
Keep up with the show and listen to past episodes at talkpython.fm, and follow the show on Twitter

00:00:57.020 --> 00:01:02.600
via at talkpython. This episode is brought to you by Linode and Clubhouse. Please check out what

00:01:02.600 --> 00:01:08.160
they're offering during their segments. It really helps support the show. Kevin Rodrigo, welcome to

00:01:08.160 --> 00:01:14.340
Talk Python To Me. Thanks, Mike. Great to have you guys both on the show. This topic is something that

00:01:14.340 --> 00:01:18.920
I'm both fascinated with and actually not very knowledgeable about, so it's awesome. And it has

00:01:18.920 --> 00:01:23.560
a really cool bunch of Python going on as well. So I think we're going to have a lot of fun talking

00:01:23.560 --> 00:01:27.460
about radio telescopes and just processing ridiculous amounts of data with it.

00:01:27.460 --> 00:01:29.140
Yeah, yeah. I think we were talking

00:01:29.140 --> 00:01:34.600
with Kevin about this the other day that we kind of lose sight of how big these numbers are, because

00:01:34.600 --> 00:01:40.120
if you are always within this realm, you don't realize that this is actually pretty big.

00:01:40.120 --> 00:01:43.520
Yeah, that's a bit of an understatement. So we'll definitely dig into all the data

00:01:43.520 --> 00:01:47.120
and everything that's going on. It's pretty impressive. It's

00:01:47.120 --> 00:01:52.680
certainly, well, I'll leave it until we get to it. But it's some crazy, crazy numbers that you

00:01:52.680 --> 00:01:58.200
all are doing. But before we get into that stuff, let's just start briefly with how you each got

00:01:58.200 --> 00:02:00.520
into programming Python. Maybe Kevin, you go first.

00:02:00.520 --> 00:02:07.800
I did my degree in physics back in the UK and then sort of drifted around doing various languages.

00:02:07.800 --> 00:02:14.980
I programmed in C, C++, Prologue, Lisp, Smalltalk. And from that, you can tell I'm quite old.

00:02:14.980 --> 00:02:24.500
When I came to join ICRA in 2009, Python is this de facto language for an awful lot of astronomy. So

00:02:24.500 --> 00:02:25.280
I learned Python.

00:02:25.280 --> 00:02:27.460
Yeah. What was that learning Python experience like?

00:02:27.460 --> 00:02:32.300
Piece of cake, really. It's much easier than Java and C++ because

00:02:32.300 --> 00:02:34.800
the syntax is just so much cleaner.

00:02:34.800 --> 00:02:39.240
Yeah, it is. And, you know, it sounds like you have experience with a lot of different languages,

00:02:39.240 --> 00:02:45.200
right? Like Scheme, Lisp, Smalltalk, C++. There's a lot of different examples. And so,

00:02:45.200 --> 00:02:49.620
you know, you come to Python and you're like, oh, this is a weird language. It doesn't have any line

00:02:49.620 --> 00:02:54.680
breaks or it doesn't really love the synth, like a lot of syntactical elements in there. But

00:02:54.680 --> 00:02:55.480
somehow...

00:02:55.480 --> 00:02:56.860
Where do I put my semi-colons?

00:02:56.860 --> 00:02:59.420
Yeah, I do.

00:02:59.420 --> 00:03:01.540
Learning not to semi-colons took a while.

00:03:01.540 --> 00:03:05.780
Yeah, I do find it funny that you can still write them if you just feel the need, you know?

00:03:05.780 --> 00:03:07.720
You're like, I just put them at the end. It's going to be okay.

00:03:07.720 --> 00:03:12.860
Yeah, praise be to IntelliJ or PyCharm because it tells you, you don't really need that.

00:03:12.860 --> 00:03:18.620
Yeah, exactly. If you really need that comfort blanket, I suspect you could turn off that code

00:03:18.620 --> 00:03:24.800
detection, code rule in PyCharm and just put the semi-colons. But you may not be accepted by your

00:03:24.800 --> 00:03:25.940
fellow Python programmers.

00:03:25.940 --> 00:03:27.340
From the bone.

00:03:27.340 --> 00:03:30.880
It's right. That's right. Rodrigo, how about you?

00:03:31.000 --> 00:03:36.180
Well, since very little, I always liked computers. So I decided to go and study a computer degree

00:03:36.180 --> 00:03:41.620
without really knowing exactly what computing was about, like about programming and all.

00:03:41.620 --> 00:03:48.280
So at junior, I started learning some languages and I became involved with astronomy. We had a group of

00:03:48.280 --> 00:03:53.780
students who were doing collaborations with some observators. I'm originally from Chile. And in Chile,

00:03:53.780 --> 00:03:59.080
there are many observatories because the conditions are so good for observing. So there was this group of

00:03:59.080 --> 00:04:04.260
students doing collaborations with some observatories in Chile. That's how I got basically into the business.

00:04:04.260 --> 00:04:28.700
So when I left uni, I moved into the European Southern Observatory headquarters in Germany. I worked over there for a couple of years and then moved here to ICRA in Australia to continue working in astronomy. In Python in particular, I started doing some more Python down here in Australia. I had done a couple of basic scripts before, but nothing much to it. And I really got into the weeds now.

00:04:29.360 --> 00:04:31.480
Because we were heavily using Python here.

00:04:31.480 --> 00:04:42.340
Well, yeah, that sounds really fun. And certainly Chile is one of those places where astronomy is, especially radio astronomy, right? Is that where Contact was filmed?

00:04:42.340 --> 00:04:48.420
No, Contact was filmed in the US, in New Mexico, close to Socorro, south of Albuquerque.

00:04:48.580 --> 00:04:53.780
It was set though, in like in that area, right? And that general, it was definitely South America somewhere.

00:04:53.780 --> 00:04:55.580
Maybe some parts of the movie.

00:04:55.580 --> 00:04:57.160
Arecibo, maybe? I think so.

00:04:57.160 --> 00:04:57.680
Oh, yeah.

00:04:57.680 --> 00:05:03.040
There might be a shot or two in Arecibo. That's in Puerto Rico? I forget.

00:05:03.040 --> 00:05:11.320
Okay. Yeah, yeah, yeah. Okay. Puerto Rico. Yeah. Okay. So it's not exactly the same one, but there's definitely with the mountains there, there's a bunch of observatories, right?

00:05:11.320 --> 00:05:21.720
Yes, yes. It's very heavy on the optical side as well. So for optical and radio astronomy, you have different set of requirements, if you want. For optical, you basically want like super, super clear skies.

00:05:21.720 --> 00:05:33.400
Whereas with radio telescopes, you can have clouds on still observant. So Chile, in the north of Chile, there's a huge desert, which is very, very dry. That's perfect for optical astronomy.

00:05:33.400 --> 00:05:42.160
Right, right, right, right. So yeah, I hadn't really thought about that. Of course, for optical stuff, the higher, the better, the clearer, the better.

00:05:42.160 --> 00:05:44.680
What are the requirements for radio telescopes?

00:05:44.960 --> 00:06:14.000
It depends on the frequency, the radio frequency that you're observing. If you are in the high frequencies is basically amount of water in the air. It's called PMW or PVW. I forget the term for optical astronomy is also for the lower frequencies of radio astronomy is our find the radio frequency interference, basically any device that is emitting radio frequency waves. So you want very isolated places for that.

00:06:14.000 --> 00:06:20.740
Okay, I see. As we'll learn, you can measure things like water and stuff very far away with radio telescopes, right?

00:06:20.740 --> 00:06:22.000
Yes, that's correct.

00:06:22.000 --> 00:06:27.520
So I suspect having like water in the air is a problem. You don't want that. That's interesting.

00:06:27.520 --> 00:06:43.040
I mean, it's how your microwave works, you know. A microwave agitates the water. It's the same sort of basic principle. In a millimeter band, that's why the ALMA telescope, which is in the Atacama Desert, as Rodrigo was saying, has to be so high.

00:06:43.040 --> 00:06:52.860
So there is no moisture there. Whereas the stuff we tend to work on generally can be down at sea level, almost or a little bit higher.

00:06:52.860 --> 00:07:00.800
Okay, interesting. And what do you guys do day to day? Are you both doing astronomy basically day to day? Or code for astronomy?

00:07:01.040 --> 00:07:08.680
Yeah, code for astronomy, pretty much. I mean, most of my work is helping more hardcore astronomers do things faster.

00:07:09.860 --> 00:07:19.980
So, for example, a group who were doing some optical work, it was taking 42 days to do something. They then passed it over to us and we got it down to 18 hours.

00:07:20.080 --> 00:07:24.260
That's awesome. That means you can do so much more science, right?

00:07:24.260 --> 00:07:29.580
Yeah. But there's a classic divide and conquer problem. Parallelize like mad.

00:07:29.580 --> 00:07:33.800
Although most of our astronomy tasks are embarrassingly parallel.

00:07:33.800 --> 00:07:39.280
We scatter and we don't really do a gather until the very end. That's it.

00:07:39.280 --> 00:07:48.180
I see. So it's almost like you could almost do individual computation on a per pixel basis, maybe? Or the equivalent of a per pixel basis?

00:07:48.180 --> 00:07:52.860
We tend to work in frequency channels more than pixels.

00:07:52.860 --> 00:08:01.300
But yes, so we would just process one particular or one band of frequencies on one machine, another band on another and another on another.

00:08:01.300 --> 00:08:09.800
Other work I do is quite a bit of machine learning work for detecting RFI, gravitational waves, doing corrections.

00:08:09.800 --> 00:08:19.780
We're actually now moving some of our astronomy work into ocean wave investigations and trying to look at whether we can correct the swell heights.

00:08:19.780 --> 00:08:23.320
So, you know, surfers know whether it's going to be a good day to go surfing.

00:08:23.320 --> 00:08:24.140
Right. Okay.

00:08:24.140 --> 00:08:34.160
Now, that would be a really unexpected consequence or outcome or capability from studying gravitational waves is better surf predictions.

00:08:34.160 --> 00:08:38.120
They're just waves. It's a propagation speed that's different.

00:08:38.120 --> 00:08:40.320
One's rather quick and one's not.

00:08:40.320 --> 00:08:42.080
Yeah, I guess so.

00:08:42.080 --> 00:08:47.780
Yeah, the whole gravitational wave detection stuff is some pretty cutting edge science and it's really interesting.

00:08:47.780 --> 00:08:51.160
And it's cool that you're using machine learning to try to understand that.

00:08:51.160 --> 00:08:53.340
We have a small group working on it.

00:08:53.340 --> 00:08:57.460
We've got devices in the proper detectors.

00:08:57.460 --> 00:09:00.760
So this is a very active area of research.

00:09:00.760 --> 00:09:02.940
There's a lot of groups around the world working on this.

00:09:02.940 --> 00:09:04.440
Yeah, I think it's kind of amazing.

00:09:04.660 --> 00:09:08.880
There's a lot of stuff with gravity oriented things in astronomy right now.

00:09:08.880 --> 00:09:13.420
We have the gravitational wave detection for the collisions of black holes.

00:09:13.420 --> 00:09:18.920
We have the first picture of black holes in the last year and a half or so, whenever that was.

00:09:18.920 --> 00:09:19.980
A lot going on around there.

00:09:19.980 --> 00:09:20.280
Yeah.

00:09:20.280 --> 00:09:22.100
And then, of course, the other thing is teaching.

00:09:23.880 --> 00:09:24.200
Sure.

00:09:24.200 --> 00:09:30.220
I guess if you're at a university, eventually, you might end up interacting with a student or two.

00:09:30.220 --> 00:09:30.760
Very cool.

00:09:30.760 --> 00:09:31.660
Unnecessary.

00:09:31.660 --> 00:09:33.740
All right.

00:09:33.740 --> 00:09:34.840
Rodrigo, what about you?

00:09:34.840 --> 00:09:35.860
Well, kind of similar.

00:09:36.700 --> 00:09:38.080
I'm a software person, right?

00:09:38.080 --> 00:09:39.420
Who became involved in astronomy.

00:09:39.420 --> 00:09:45.580
So I basically help astronomers to develop software in different languages for different purposes.

00:09:45.580 --> 00:09:48.860
So not only for radio astronomy, but also for optical astronomy.

00:09:48.860 --> 00:09:52.440
And also for, we have also a theoretical group.

00:09:52.440 --> 00:09:56.120
So people who do simulations of galaxy formation and such.

00:09:56.800 --> 00:09:58.740
So kind of all over the place.

00:09:58.740 --> 00:10:08.640
And we, not only me, but all the people in the group we specialize kind of in this area of helping astronomers build the software, deploy it, optimize it, and so on.

00:10:08.640 --> 00:10:13.680
How much do you end up helping them with standard software engineering things?

00:10:13.680 --> 00:10:16.240
Like, hey, hey, I need to teach you source control.

00:10:16.240 --> 00:10:17.640
This is Git and GitHub.

00:10:17.640 --> 00:10:19.700
Let's spend an hour talking about that.

00:10:19.700 --> 00:10:21.300
Or are they pretty much good to go?

00:10:21.300 --> 00:10:23.700
Yeah, it depends on the generation, I would say.

00:10:24.080 --> 00:10:28.500
So older generations are a bit harder to kind of, you know, move to that side.

00:10:28.500 --> 00:10:35.400
But newer people, like younger people, then come with all those concepts already kind of built in, right?

00:10:35.400 --> 00:10:38.600
They were born and GitHub was already there kind of thing.

00:10:38.600 --> 00:10:41.460
So you don't have to push that far.

00:10:41.460 --> 00:10:45.480
It's still mostly on the, maybe on the software design side of things.

00:10:45.480 --> 00:10:54.060
You know, how you structure your software, how you tackle that particular problem, how you organize the code, how you optimize things for your particular architecture.

00:10:54.060 --> 00:10:55.060
And so on.

00:10:55.060 --> 00:10:56.160
Okay, cool.

00:10:56.160 --> 00:11:02.200
And you're also working on this SKA construction, the Square Kilometer Array.

00:11:02.200 --> 00:11:03.020
Yes, yes.

00:11:03.020 --> 00:11:03.960
That's a whole topic.

00:11:03.960 --> 00:11:06.080
I guess we'll talk more about it later.

00:11:06.080 --> 00:11:12.440
But we are one of the main institutions that are working on the Square Kilometer Array project.

00:11:12.560 --> 00:11:13.800
Yeah, so it's interesting.

00:11:13.800 --> 00:11:30.440
I don't know if this works for light, but it does for radio, that if you put multiple detectors and sort of densely, but not actually connected to one giant antenna or something, you can put that together like a bigger detector, right?

00:11:30.440 --> 00:11:32.440
A bigger lens in the radio world.

00:11:33.000 --> 00:11:34.060
So that's the idea, right?

00:11:34.060 --> 00:11:35.360
Yes, and that's exactly the idea.

00:11:35.360 --> 00:11:36.380
It's called interferometry.

00:11:36.380 --> 00:11:48.300
You basically, if you have, say, three antennas, A, B, and C, what you do is you take measurements individually from A, from B, and C, and then you correlate every other pair.

00:11:48.300 --> 00:12:05.480
So you correlate the signals from A and B, from B and C, and from A and C, and you do that with a correlator, which is the one that is doing all this mixing of signals, and out goes one correlated signal, which is as if you have one big antenna.

00:12:05.480 --> 00:12:08.720
So that's what happens in radios for me.

00:12:08.720 --> 00:12:16.300
I think, I'm not sure, but I think in optical you can also do interferometry, but I'm not sure how the mechanism works in that sense.

00:12:16.300 --> 00:12:31.360
Cool. So this SKA project, this is the Square Kilometer Array, which is an international project that you all are working on involving 13 countries that are, I guess, full members of the project and four others who are just participating, right?

00:12:31.360 --> 00:12:32.200
Yeah, that's right.

00:12:32.200 --> 00:12:38.600
The Square Kilometer part is the collecting area because we're starting to run out of adjectives.

00:12:38.600 --> 00:12:43.080
There's things like the Very Large Array, there's the Extremely Large Telescope.

00:12:43.080 --> 00:12:44.820
Where do we go?

00:12:46.040 --> 00:12:46.860
Yes, exactly.

00:12:46.860 --> 00:12:52.020
It actually tells you what the collecting area of the final system is going to be.

00:12:52.020 --> 00:12:56.520
Now, we're going to be building this thing in two phases.

00:12:56.520 --> 00:13:03.340
Phase one will only be 10% of the final telescope, which means, I mean, it's being built in two countries.

00:13:03.340 --> 00:13:11.920
So the low-frequency component is coming to Australia, to Western Australia, and the mid-frequency is going into the Karoo in South Africa.

00:13:12.220 --> 00:13:24.380
So there'll be 196, 15-meter dishes in South Africa and 131,072 antennas in Western Australia.

00:13:24.940 --> 00:13:31.740
There's a fair bit of kit going out with a collectif of 650 million euros.

00:13:31.740 --> 00:13:33.060
650 million euros.

00:13:33.060 --> 00:13:35.820
Just for the first one.

00:13:35.820 --> 00:13:37.020
This is the first part, yeah.

00:13:37.020 --> 00:13:37.540
I don't know.

00:13:37.540 --> 00:13:42.860
131,000 antennas bringing in all this data.

00:13:42.860 --> 00:13:46.960
Yeah, that is a huge amount of antennas.

00:13:46.960 --> 00:13:48.940
And it's spread over a square kilometer.

00:13:48.940 --> 00:13:49.180
Well, it's a huge amount of data.

00:13:49.180 --> 00:13:50.200
Yeah.

00:13:50.200 --> 00:13:53.540
It's about 550 gigabytes a second.

00:13:53.540 --> 00:13:55.320
550 gigabytes a second.

00:13:55.640 --> 00:14:00.160
I don't really have a great way to understand that number, honestly.

00:14:00.160 --> 00:14:07.740
Like, you've got to think of, like, large cloud services, like YouTube or Netflix or something like that, right?

00:14:07.740 --> 00:14:08.140
Yeah.

00:14:08.140 --> 00:14:13.480
Just about 16,000 hours of standard definition YouTube every second.

00:14:13.480 --> 00:14:13.900
Wow.

00:14:14.100 --> 00:14:22.940
Yeah, or you can visualize it if you take your, you know, your hard drive, your 500 gigabyte hard drive, and you throw it, and you throw one of those every second, right?

00:14:22.940 --> 00:14:24.760
That's basically it.

00:14:24.760 --> 00:14:25.160
Yeah.

00:14:25.160 --> 00:14:27.200
That's a lot of data.

00:14:27.200 --> 00:14:28.900
Also, it takes a lot of power, right?

00:14:28.900 --> 00:14:29.620
Yeah.

00:14:29.620 --> 00:14:38.800
And that's one of the key things, because we would like to be as green as possible, but we've got a power cap on us at the moment of 5 megawatt.

00:14:38.800 --> 00:14:43.020
Biggest, most powerful system on the planet at the moment is 13 megawatts.

00:14:43.020 --> 00:14:46.460
So that's still a challenge we have to address.

00:14:46.460 --> 00:14:47.180
Yeah.

00:14:47.180 --> 00:14:50.480
You almost need your own power plant to power.

00:14:50.480 --> 00:14:58.420
Oh, well, we've got up at the Murchison Radio Observatory, the CSIRO, who've got a couple of megawatts of solar up there already.

00:14:58.420 --> 00:14:58.720
Yeah.

00:14:58.720 --> 00:14:59.200
Okay.

00:14:59.200 --> 00:15:04.800
Is it the blades that generate RFI, or is it the generators that generate the RFI?

00:15:04.800 --> 00:15:05.360
It's the generators.

00:15:05.360 --> 00:15:05.820
Yeah.

00:15:05.820 --> 00:15:06.240
Yeah.

00:15:06.240 --> 00:15:11.220
This portion of Talk Python To Me is brought to you by Linode.

00:15:11.420 --> 00:15:20.160
Whether you're working on a personal project or managing your enterprise's infrastructure, Linode has the pricing, support, and scale that you need to take your project to the next level.

00:15:20.160 --> 00:15:34.820
With 11 data centers worldwide, including their newest data center in Sydney, Australia, enterprise-grade hardware, S3-compatible storage, and the next-generation network, Linode delivers the performance that you expect at a price that you don't.

00:15:34.820 --> 00:15:50.880
Get started on Linode today with a $20 credit, and you get access to native SSD storage, a 40-gigabit network, industry-leading processors, their revamped cloud manager, cloud.linode.com, root access to your server, along with their newest API, and a Python CLI.

00:15:51.300 --> 00:16:21.280
Just visit talkpython.com.com.com.

00:16:21.280 --> 00:16:25.060
I think if I could just throw those out there really quick, if you guys could just comment on them.

00:16:25.060 --> 00:16:25.340
All right.

00:16:25.340 --> 00:16:28.520
One thing, these are facts about the final system.

00:16:28.520 --> 00:16:33.420
So this is where we will get to when we finish building it.

00:16:33.420 --> 00:16:34.000
Right.

00:16:34.440 --> 00:16:34.660
Okay.

00:16:34.660 --> 00:16:40.160
So, yeah, you're only talking, we're only really working on stage one now, and there's going to be some beyond that, right?

00:16:40.160 --> 00:16:40.640
Oh, yeah.

00:16:40.640 --> 00:16:41.600
Yeah.

00:16:41.600 --> 00:16:42.820
Awesome.

00:16:42.820 --> 00:16:51.440
So the next one, the next amazing fact is that the SKA central computer will have the processing power of 100 million PCs.

00:16:51.440 --> 00:16:56.560
Rodrigo, is that because there's a bunch of GPUs, or are there like really just a lot of CPUs in there?

00:16:56.560 --> 00:16:57.200
It's both.

00:16:57.200 --> 00:17:04.380
So the final design of the computer for the SKA is still not fully decided, but it's definitely going to be a mixture of both.

00:17:04.380 --> 00:17:04.920
Right.

00:17:04.920 --> 00:17:10.780
And, yeah, so all of this is based on the, we calculate how many computations we will need to do.

00:17:10.780 --> 00:17:13.380
Therefore, that kind of gives you the size.

00:17:13.380 --> 00:17:13.700
Wow.

00:17:13.700 --> 00:17:14.040
Okay.

00:17:14.040 --> 00:17:20.640
The next one is the dishes will produce 10 times as much data traffic as the global internet.

00:17:20.640 --> 00:17:21.280
Yes.

00:17:21.280 --> 00:17:22.820
That's crazy.

00:17:22.820 --> 00:17:23.540
Yeah, yeah.

00:17:23.540 --> 00:17:27.720
That's because you have so many dishes, right?

00:17:27.720 --> 00:17:28.100
Right.

00:17:28.100 --> 00:17:30.340
This is before it goes to the correlator, of course.

00:17:30.340 --> 00:17:38.460
Like what comes off the correlator, as Kevin was saying, is about half a terabyte per second, which is obviously not what the global internet traffic is.

00:17:38.460 --> 00:17:44.180
But what comes out of the individual antennas, yeah, it definitely is bigger than the internet traffic.

00:17:44.180 --> 00:17:44.500
Wow.

00:17:44.500 --> 00:17:49.800
And there's a bunch of fiber optic that brings it back to these correlators that then like process it and averaging.

00:17:49.800 --> 00:17:51.160
Yeah, exactly.

00:17:51.160 --> 00:17:52.180
Yeah, yeah.

00:17:52.180 --> 00:17:52.680
Yeah, crazy.

00:17:53.440 --> 00:17:59.400
And then I guess finally the aperture arrays could produce up to 100 times the global internet traffic.

00:17:59.400 --> 00:18:02.800
So, yeah, there's, I think this is a pretty interesting one.

00:18:02.800 --> 00:18:12.340
Honestly, the one that's most exciting to me is the one about the airport radar on a planet tens of light years away.

00:18:12.340 --> 00:18:13.900
That's what everyone is waiting for.

00:18:14.000 --> 00:18:23.520
There are only two planets that we know of at the moment that fit within that area that could potentially hold life, though.

00:18:23.520 --> 00:18:30.140
So, I mean, our nearest neighbor's alpha centauri, a proximus inside, has got two planets around it.

00:18:30.140 --> 00:18:35.760
But it's a red dwarf, which means that it's a red dwarf, which means that it's a red dwarf, which means that they're quite thirsty with lots of solar flares.

00:18:35.760 --> 00:18:41.640
So life as we know it would probably struggle to evolve there.

00:18:41.640 --> 00:18:49.220
You want a nice star like ours that's nice and sensible and not throw a huge amount of rubbish at us.

00:18:49.320 --> 00:18:53.640
Yeah, do you want to get like a cleansing radiation spray every 10 years or whatever?

00:18:53.640 --> 00:18:54.660
Yeah, that's right.

00:18:54.660 --> 00:18:56.420
It's not good for you.

00:18:56.420 --> 00:19:01.200
Yeah, there's probably not enough sunscreen to like help you with that one.

00:19:01.200 --> 00:19:02.440
I don't know.

00:19:03.120 --> 00:19:07.640
Yeah, that's one of the sad things for me about all of this space stuff.

00:19:07.640 --> 00:19:09.100
I really wish.

00:19:09.100 --> 00:19:16.600
It's just so big that it's just really challenging to actually explore it, interact with it, measure it.

00:19:16.600 --> 00:19:20.800
Like even if you do get measurements back, it's like, well, that was 100 years ago.

00:19:20.800 --> 00:19:23.800
It would take another 100 years to like send him a message.

00:19:23.800 --> 00:19:26.400
We've only got away four years.

00:19:26.400 --> 00:19:32.240
I mean, last year, year before, I took a bunch of primary school students.

00:19:32.240 --> 00:19:37.540
We taught the European Space Agency into lending us their dish at New North here.

00:19:37.540 --> 00:19:39.680
And we sent messages to Potsdam Center.

00:19:39.680 --> 00:19:47.360
All right, so wait 4.2 years or 4.2 years for it to get there for them to decide for it and send a reply back.

00:19:47.360 --> 00:19:49.200
So in about six years' time, we'll know.

00:19:49.200 --> 00:19:50.620
Yeah, that's not too bad, actually.

00:19:50.620 --> 00:19:51.280
Not too bad.

00:19:51.280 --> 00:19:52.820
Cool.

00:19:52.820 --> 00:20:02.720
So I guess maybe the next thing that's interesting to dig into before we get like fully into the programming side of things is just like what kind of questions are you guys trying to answer?

00:20:02.720 --> 00:20:10.460
I mean, it's super cool to have this giant radio telescope with 131,000 antennas together in this giant array.

00:20:10.460 --> 00:20:12.920
But you get some measurements off of it.

00:20:12.920 --> 00:20:14.080
Then what?

00:20:14.080 --> 00:20:18.140
Well, one of the things that we've been joking about, but it's the cradle of life.

00:20:18.140 --> 00:20:19.320
Are we alone?

00:20:19.660 --> 00:20:24.440
One of the things a radio telescope can see is molecules in space.

00:20:24.440 --> 00:20:29.060
We have water, hydrogen sulfide, ammonia, carbon monoxide.

00:20:29.580 --> 00:20:36.440
But we can also see things like methanol, glycolyl nitrate, which is a simple sugar, and amino acetyl nitrile.

00:20:36.440 --> 00:20:49.660
Now, if the clarionite, and you look up at the night sky, look at the constellation Orion, there's a nebula in there that has these chemicals floating in the planetary nebula.

00:20:50.780 --> 00:20:55.740
And that's precursor organic compounds to what basically we are.

00:20:55.740 --> 00:20:56.040
Yeah.

00:20:56.040 --> 00:20:57.340
Yeah, that's super cool.

00:20:57.340 --> 00:21:04.260
And if those gases and small particles coalesce into planets, those planets are going to have those things.

00:21:04.260 --> 00:21:06.420
Or asteroids that crash into planets, right?

00:21:06.480 --> 00:21:06.660
Yeah.

00:21:06.660 --> 00:21:18.640
I mean, the other thing we have to look for is things like galaxy evolution, testing cosmological models, looking for dark matter, dark energy, origins and evolutions of cosmic magnetism.

00:21:18.640 --> 00:21:21.760
We really don't know much about that at the moment.

00:21:21.760 --> 00:21:31.000
And one of the fun things is, in the epoch of re-ionization, I'll put my teeth back in, the epoch of re-ionization.

00:21:31.000 --> 00:21:37.080
After the Big Bang, we had everything being highly ionized gas.

00:21:37.080 --> 00:21:41.440
And then, about 300,000 years, it became neutral and dark.

00:21:41.440 --> 00:21:55.780
And then, slowly, as galaxies and quasars began to re-ionize things, stars started to appear, galaxies started to appear until about a billion years ago, when everything started to become transparent again.

00:21:55.780 --> 00:21:59.680
So, we want to go back and have a look at that time.

00:21:59.680 --> 00:22:08.800
And to do that, we need a huge collecting area, because radio photons are about 2 million times weaker than optical photons.

00:22:08.800 --> 00:22:14.740
Right. So, you've got to have something incredibly sensitive to go far enough back in time to see that kind of stuff, right?

00:22:14.740 --> 00:22:15.560
Yeah.

00:22:15.560 --> 00:22:26.880
These measurements that allow you to see things like hydrogen and water and carbon monoxide and so on, each molecule has its own signature in the radio wave.

00:22:26.880 --> 00:22:27.680
Yeah.

00:22:27.680 --> 00:22:31.420
I mean, it's in the spectra.

00:22:31.420 --> 00:22:34.420
So, we can look at the spectra and see, you know, there's a peak there.

00:22:34.420 --> 00:22:36.520
There's a line there.

00:22:36.520 --> 00:22:38.720
Well, that probably means it's being absorbed by something.

00:22:38.720 --> 00:22:39.840
This is something admitting.

00:22:39.840 --> 00:22:40.760
Right.

00:22:40.760 --> 00:22:51.320
So, you know, it's just spectroscopy, which is used in optical, x-ray, ultraviolet, infrared, radio.

00:22:51.320 --> 00:22:52.320
We all do it.

00:22:52.320 --> 00:22:52.600
Okay.

00:22:52.600 --> 00:22:53.100
Yeah.

00:22:53.100 --> 00:22:55.560
So, it's like NMR, far away.

00:22:55.560 --> 00:22:58.260
Yeah.

00:22:58.620 --> 00:23:06.460
And then, of course, you know, we look at the redshift to see how far away things are, because, you know, space time expanded, the radio waves stretched.

00:23:06.460 --> 00:23:06.720
Yeah.

00:23:06.720 --> 00:23:08.780
I guess you've got to compensate as well.

00:23:08.780 --> 00:23:12.680
We can then look for it and see how far away things are.

00:23:12.680 --> 00:23:13.120
Wow.

00:23:13.120 --> 00:23:16.260
It's really amazing that you can just send out radio waves and then get all this information.

00:23:16.260 --> 00:23:17.460
Oh, no, we're not sending.

00:23:17.460 --> 00:23:18.160
We're receiving.

00:23:18.160 --> 00:23:18.480
Yeah.

00:23:18.480 --> 00:23:18.740
Yes.

00:23:18.740 --> 00:23:19.000
Okay.

00:23:19.000 --> 00:23:19.520
Thank you.

00:23:19.520 --> 00:23:22.260
But it's like that you can measure these radio waves.

00:23:22.260 --> 00:23:22.640
Hmm.

00:23:22.640 --> 00:23:27.200
And just, you can basically see it, right?

00:23:27.200 --> 00:23:35.980
It's almost like as if you've got an optical telescope, but, you know, you're computing a visual representation for humans, right?

00:23:35.980 --> 00:23:36.260
Yeah.

00:23:36.260 --> 00:23:38.740
Except for it takes a lot longer.

00:23:39.080 --> 00:23:41.780
Speaking of all the computation stuff, let's dig into it.

00:23:41.780 --> 00:23:44.580
So, I know, Rodrigo, you're working a lot on this project.

00:23:44.580 --> 00:23:49.780
And so, you guys have got your hands on this pretty serious computer, right?

00:23:49.780 --> 00:23:50.140
Yes.

00:23:50.140 --> 00:24:02.560
So, the work that we did last year was about running simulations of all of this, but not only, you know, one or two computers, but at very big scales.

00:24:03.160 --> 00:24:15.480
Basically, to the biggest scale possible that we could achieve now and trying to come up with what the system will look like in 10 years when we actually have to run it at that scale, right?

00:24:15.480 --> 00:24:19.680
So, we teamed up with the Oak Ridge National Labs in the US.

00:24:19.680 --> 00:24:25.820
And they own, at the moment, the biggest, not the biggest, the fastest supercomputer in the world.

00:24:25.820 --> 00:24:26.600
It's called Summit.

00:24:27.440 --> 00:24:30.380
So, Summit has over 4,600 nodes.

00:24:30.380 --> 00:24:39.040
And on each node, you find six GPUs, six V100 NVIDIA cards, plus something like 160 cores.

00:24:39.040 --> 00:24:42.420
It's like each node on itself is a beast.

00:24:42.420 --> 00:24:45.540
And you have 4,600 of them, right?

00:24:45.540 --> 00:24:46.960
Right.

00:24:46.960 --> 00:24:48.180
We teamed up with Oak Ridge.

00:24:48.180 --> 00:24:51.100
We wanted to run a simulation on their computer.

00:24:51.100 --> 00:24:55.400
But, of course, they also wanted something kind of back, right?

00:24:55.400 --> 00:24:56.520
It wasn't a free launch.

00:24:57.080 --> 00:24:59.500
And we have been collaborating with them for a number of years.

00:24:59.500 --> 00:25:05.960
And one area of collaboration that we have been working on is using their ADOS2 library.

00:25:05.960 --> 00:25:13.640
I can dig into that in a second, but it's basically an IO framework for largely distributed programs using MPI.

00:25:13.640 --> 00:25:14.960
So, that was the deal.

00:25:14.960 --> 00:25:16.240
We got some time in Summit.

00:25:16.240 --> 00:25:22.020
We have an ex-PhD student of ours who is working right now over there.

00:25:22.020 --> 00:25:24.080
So, he was our main contact point.

00:25:24.080 --> 00:25:25.440
His name is Jason1.

00:25:25.440 --> 00:25:30.860
Yeah, we decided to run a couple of different experiments to test all these individual parts.

00:25:30.860 --> 00:25:38.740
So, the first experiment was to simulate an actual observation of an SKA-like telescope.

00:25:38.740 --> 00:25:41.920
And that was basically using the whole machine.

00:25:41.920 --> 00:25:51.320
We used almost all the nodes and all the GPUs in all of these nodes to simulate what the correlator would produce when observing, right?

00:25:51.580 --> 00:25:53.000
So, we're not simulating individual antennas.

00:25:53.000 --> 00:25:53.200
Right.

00:25:53.200 --> 00:25:55.620
We're just simulating the output of the correlator, right?

00:25:55.620 --> 00:26:04.180
The observation that we decided to simulate is exactly the epoch of ray ionization, which is one of these big use cases of the SKA.

00:26:04.840 --> 00:26:06.260
So, we decided to simulate that.

00:26:06.260 --> 00:26:13.420
We simulated the output of correlator as if it was correlating as many antennas as the SKA.

00:26:13.940 --> 00:26:21.560
The only aspect that we had to tune down a little bit is the number of frequency channels that we, double quotes, observe in our simulation.

00:26:21.560 --> 00:26:25.780
In the SKA, you can observe up to 64,000 channels.

00:26:26.000 --> 00:26:29.760
We simulated about 28,000, 29,000.

00:26:29.760 --> 00:26:31.660
Basically, one channel per GPU.

00:26:31.660 --> 00:26:32.240
Yeah.

00:26:32.240 --> 00:26:36.540
So, you had 27,000 GPUs running.

00:26:36.540 --> 00:26:36.860
Yes.

00:26:36.860 --> 00:26:37.540
Yeah, that's right.

00:26:37.540 --> 00:26:41.780
Full power for six hours to generate a portion.

00:26:41.780 --> 00:26:42.440
No, sorry.

00:26:42.440 --> 00:26:44.600
For three hours, simulating six hours of observation.

00:26:44.600 --> 00:26:45.080
Exactly.

00:26:45.080 --> 00:26:45.500
Yeah.

00:26:45.500 --> 00:26:46.640
Yeah, yeah, yeah.

00:26:46.640 --> 00:26:48.180
To generate all this data.

00:26:48.180 --> 00:26:49.960
Talk about the computing, right?

00:26:49.960 --> 00:26:58.600
It goes in and this data just comes screaming into this supercomputer and you have to distribute it out and basically do all this processing.

00:26:58.600 --> 00:27:02.400
Is it like image processing or is it like time series processing?

00:27:02.400 --> 00:27:04.060
What are you doing?

00:27:04.060 --> 00:27:09.320
In this first experiment, first of all, we generate the data in the supercomputer, right?

00:27:09.320 --> 00:27:12.760
So, we don't have to bring anything from any external source.

00:27:12.760 --> 00:27:19.900
We just generate the data on the GPUs and then we stream it out of the GPUs into the CPUs on each individual node.

00:27:19.900 --> 00:27:22.580
We did some data reduction.

00:27:22.580 --> 00:27:27.380
We basically took data from different channels and averaged it together.

00:27:27.380 --> 00:27:32.980
So, we did that at the local node level first.

00:27:32.980 --> 00:27:37.460
You know, the six GPUs, we coalesced into a single output signal.

00:27:37.460 --> 00:27:41.760
And then every six nodes, we did again another further reduction.

00:27:41.760 --> 00:27:45.980
This is something that would be similar to what you would be doing at the SKA.

00:27:45.980 --> 00:27:48.180
And that basically reduces the amount.

00:27:48.180 --> 00:27:54.600
There are, I guess, scientific reasons of when and when you don't want to do this kind of averaging.

00:27:54.600 --> 00:27:58.120
But for the epoch of rayonization, it's certainly something that you would do.

00:27:58.120 --> 00:28:04.940
So, we did this two-step averaging and then we brought the data immediately to disk.

00:28:04.940 --> 00:28:06.480
And that was the first experiment.

00:28:06.480 --> 00:28:07.460
It ran on its own.

00:28:07.460 --> 00:28:11.380
There was no further computation on that first experiment.

00:28:11.380 --> 00:28:11.820
Yeah.

00:28:11.820 --> 00:28:17.320
So, one of the things that's interesting is you guys are getting so much data that you can't write the raw data to disk.

00:28:17.320 --> 00:28:18.400
Yeah.

00:28:18.400 --> 00:28:21.480
So, you've kind of got to process it and filter it down and do this averaging.

00:28:21.480 --> 00:28:24.920
And then you can finally save that bit, which is probably still a lot of data.

00:28:24.920 --> 00:28:25.180
Yeah.

00:28:25.180 --> 00:28:25.440
Yeah.

00:28:25.440 --> 00:28:25.560
Yeah.

00:28:25.560 --> 00:28:32.980
So, for example, the data that we generated of the GPUs during those three hours was about 2.6 petabytes.

00:28:33.980 --> 00:28:37.200
And what we ended up on this was about 110 terabytes.

00:28:37.200 --> 00:28:38.020
Wow.

00:28:38.020 --> 00:28:38.580
So, yeah.

00:28:38.580 --> 00:28:39.620
And that's in three hours.

00:28:39.620 --> 00:28:39.960
Yeah.

00:28:39.960 --> 00:28:41.060
That's in three hours.

00:28:41.060 --> 00:28:41.560
Yeah.

00:28:41.560 --> 00:28:42.180
Yeah.

00:28:42.180 --> 00:28:43.160
That's in three hours.

00:28:43.240 --> 00:28:47.400
As I was saying, we decided to average on this particular case, but on the real thing.

00:28:47.400 --> 00:28:50.860
And you may actually need to write all that data into disk.

00:28:50.860 --> 00:28:55.000
And that's why we did some other experiments in that direction.

00:28:55.180 --> 00:29:00.300
So, when I think of what I'm visualizing is there's just like you're saving so much data.

00:29:00.300 --> 00:29:08.000
You know, if you have a power plant that runs on coal, there's like every day a giant train that brings in coal and it just is continuously going.

00:29:08.000 --> 00:29:13.320
I can almost imagine like you almost are just like constantly shipping in hard drives and plugging them in.

00:29:13.320 --> 00:29:14.720
Like, how do you deal with that?

00:29:14.720 --> 00:29:17.440
The truck of hard drives is here today.

00:29:17.440 --> 00:29:18.200
Quick, plug it in.

00:29:18.200 --> 00:29:18.800
It's getting full.

00:29:18.800 --> 00:29:22.120
Well, in the SKA, there will be a double buffer, basically.

00:29:22.540 --> 00:29:27.240
So, as you observe, you fill one of your buffers with all the incoming data.

00:29:27.240 --> 00:29:31.200
Once your observation finishes, you swap the buffers.

00:29:31.200 --> 00:29:35.080
The next observation can fill the other buffer while you process the first.

00:29:35.080 --> 00:29:40.220
During this later processing, again, reduce the amount of data by, again, orders of magnitude.

00:29:40.220 --> 00:29:41.560
And that's what this.

00:29:41.560 --> 00:29:44.180
So, I was talking before about the first experiment.

00:29:44.180 --> 00:29:46.680
Well, we did a second and a third.

00:29:46.680 --> 00:29:49.860
In the second experiment, we took the output of the first.

00:29:50.460 --> 00:29:52.820
And we effectively reduced it even further.

00:29:52.820 --> 00:30:01.300
So, the output of the first, which is basically this reduction of data from the correlator, gives you what we call in radio astronomy, visibilities.

00:30:01.300 --> 00:30:05.400
So, in radio astronomy, you don't observe pixels and images directly.

00:30:05.400 --> 00:30:09.760
You observe these visibilities that later on you have to actually image.

00:30:09.760 --> 00:30:11.820
You have to create an image from them.

00:30:12.200 --> 00:30:15.160
And that takes much longer, as Kevin was saying.

00:30:15.160 --> 00:30:16.860
It's a much complicated process.

00:30:16.860 --> 00:30:20.280
So, that's why you can do it a bit offline.

00:30:20.280 --> 00:30:22.300
And we did that during the second experiment.

00:30:22.300 --> 00:30:28.480
We took all the 110 terabytes of visibilities and we created images for each of the channels.

00:30:28.760 --> 00:30:32.680
So, if you have many images for each of the channels, you end up with an image cube.

00:30:32.680 --> 00:30:34.680
That's how they're called in the real astronomy.

00:30:34.680 --> 00:30:39.220
Or if you want, you can play it as a movie as you go across the different channels.

00:30:39.220 --> 00:30:44.520
And that image cube, it turned out to be like 3.3 gigabytes or something.

00:30:44.520 --> 00:30:47.080
Like, again, a massive reduction of data.

00:30:47.360 --> 00:30:50.000
Yeah, that starts to get to the level you can write that down.

00:30:50.000 --> 00:30:51.380
Yeah, yeah, yeah, exactly.

00:30:51.380 --> 00:30:52.660
But it's no problem, yeah.

00:30:52.660 --> 00:30:53.360
Yeah, exactly.

00:30:53.360 --> 00:30:57.600
And that you can also distribute across the world more easily through the internet.

00:30:57.600 --> 00:31:01.660
And again, in the SKA, there will be something like that.

00:31:01.660 --> 00:31:05.620
There will be the main computer that will do the main reductions.

00:31:05.620 --> 00:31:12.060
And after the main reductions are done, data is sent over to what are called the SKA regional centers.

00:31:12.060 --> 00:31:14.440
And that's where the final science will be done.

00:31:14.640 --> 00:31:22.600
Yeah, so it sounds a little bit like the Large Hadron Collider, which does a ton of computation and filtering and averaging and whatnot of the data.

00:31:22.600 --> 00:31:29.320
But then it streams a bunch out to probably places like Oak Ridge and other places where it gets further processed and further processed.

00:31:29.320 --> 00:31:32.420
It sounds like you might be doing something similar here in the end.

00:31:32.420 --> 00:31:33.320
Yeah, yeah, exactly.

00:31:33.320 --> 00:31:41.900
It's not about kind of reducing the amount of the size of the data, depending on your science use case, and then distributing that.

00:31:41.900 --> 00:31:43.500
So, let me ask you guys something.

00:31:43.840 --> 00:31:50.620
You're running the simulation on Summit in Oak Ridge, which is the fastest supercomputer in the world, or nearly so.

00:31:50.620 --> 00:31:52.240
What are you going to do in the real one?

00:31:52.240 --> 00:31:57.260
Like, are you going to build one of the largest supercomputers in Australia and then another one in South Africa?

00:31:57.260 --> 00:31:58.620
Is that pretty much what you have to do?

00:31:58.620 --> 00:31:59.840
Yes, I know.

00:31:59.840 --> 00:32:04.500
So, by the time, it won't be the fastest, right?

00:32:04.500 --> 00:32:04.840
Sure.

00:32:04.840 --> 00:32:06.280
Compared to current standards.

00:32:06.340 --> 00:32:08.000
We'll do it on our iPhones by then.

00:32:08.000 --> 00:32:08.500
I mean, what is it?

00:32:08.500 --> 00:32:09.320
Yeah, exactly.

00:32:09.320 --> 00:32:11.520
Everyone will collaborate a little bit.

00:32:11.520 --> 00:32:13.400
No, what's the plan for dealing with this?

00:32:13.400 --> 00:32:18.940
Because it sounds like you've got to move a serious bit of compute next to this system.

00:32:19.120 --> 00:32:19.280
Yeah.

00:32:19.520 --> 00:32:25.980
So, the plan is effectively run something in the order, if I'm not mistaken, of 100 perapholops.

00:32:26.360 --> 00:32:33.640
I think 150 perapholops is the size of the supercomputer that should be built, which is kind of comparable to what Summit is doing now.

00:32:33.640 --> 00:32:36.040
When is the time frame for this?

00:32:36.480 --> 00:32:38.220
About 10 years, give or take.

00:32:38.220 --> 00:32:43.180
This portion of Talk Python To Me is sponsored by Clubhouse.

00:32:43.180 --> 00:32:50.220
Clubhouse is a fast and enjoyable project management platform that breaks down silos and brings teams together to ship value, not features.

00:32:50.220 --> 00:32:58.060
Great teams choose Clubhouse because they get flexible workflows where they can easily customize workflow state for teams or projects of any size.

00:32:58.060 --> 00:33:03.260
Advanced filtering, quickly filtering by project or team to see how everything is progressing.

00:33:03.980 --> 00:33:09.640
And effective sprint planning, setting their weekly priorities with iterations and then letting Clubhouse run the schedule.

00:33:09.640 --> 00:33:14.140
All of the core features are completely free for teams with up to 10 users.

00:33:14.140 --> 00:33:21.180
And as Talk Python listeners, you'll get two free months on any paid plan with unlimited users and access to the premium features.

00:33:21.180 --> 00:33:22.340
So get started today.

00:33:22.340 --> 00:33:26.560
Just click the Clubhouse link in your podcast player show notes or on the episode page.

00:33:28.580 --> 00:33:36.620
It'd be fun to dig into some of the Python code and some of the architecture that you guys had to put in place to make this happen, right?

00:33:36.620 --> 00:33:40.340
So a lot of these types of systems, they have a lot of C++ in place.

00:33:40.340 --> 00:33:48.700
They also have a lot of interesting Python going on, I'm sure, in the data science visualization side, but also maybe more in the core of the system.

00:33:48.860 --> 00:33:49.100
Yeah.

00:33:49.100 --> 00:33:53.360
First, I should probably mention the execution framework that we use for this.

00:33:53.360 --> 00:34:00.980
So instead of running things with MPI, we have been using an execution framework that we developed at ICRA, our institute.

00:34:00.980 --> 00:34:02.200
It's called the Liujia.

00:34:02.200 --> 00:34:04.980
Kind of difficult to pronounce, even more difficult to write.

00:34:04.980 --> 00:34:07.300
But I will give you a link to that.

00:34:07.300 --> 00:34:07.940
Yeah, super.

00:34:08.060 --> 00:34:19.980
The view of this execution framework is a bit like Dask, which people are more familiar with, in the sense that you build a graph with your computations, and then you execute that graph in a number of workers, right?

00:34:19.980 --> 00:34:27.480
Now, the big difference between Dask and the Liujia, our execution framework, is that Dask is very dynamic in its nature.

00:34:27.480 --> 00:34:34.820
You can bring workers up and down, and then the scheduler will dynamically adjust the load to what you have available, right?

00:34:35.780 --> 00:34:42.120
Whereas the Liujia is more designed for the SKA case in particular, but it's still pre-generic.

00:34:42.120 --> 00:34:47.260
But one of the main design decisions was to work with a static deployment.

00:34:47.260 --> 00:34:57.940
So instead of trying to be dynamic in nature and try to move data from here to there and restart the computation here and whatever, we try to be very static.

00:34:57.940 --> 00:35:02.260
Because moving data from one place to another is a very expensive operation.

00:35:02.600 --> 00:35:11.300
If the compute is what's expensive and the data is not that bad, moving it around to balance the compute and getting that to happen is really important.

00:35:11.300 --> 00:35:15.520
But when you have so much data that it's more than the internet.

00:35:15.520 --> 00:35:16.520
Yeah.

00:35:16.520 --> 00:35:20.260
You don't want to be moving around the internet data.

00:35:20.260 --> 00:35:24.440
You're already at probably near a limit of moving it around just to get it somewhere.

00:35:24.980 --> 00:35:29.780
So, like, you know, combinatorially passing it around is not really what you're after.

00:35:29.780 --> 00:35:30.240
Exactly.

00:35:30.240 --> 00:35:30.680
Yeah.

00:35:30.680 --> 00:35:40.500
So instead of focusing on that dynamism that that gives you, we focus on having very good schedule up front of your computations.

00:35:40.500 --> 00:35:43.540
So you know exactly how long each one is going to take.

00:35:43.540 --> 00:35:46.180
You know exactly how much data is going to be where.

00:35:46.960 --> 00:35:48.580
And you keep it like that, basically.

00:35:48.580 --> 00:35:49.500
That sounds very cool.

00:35:49.500 --> 00:35:50.520
That's the main difference.

00:35:50.520 --> 00:35:56.020
And we have been developing this in a prototype fashion, but now using it in real life world as well.

00:35:56.020 --> 00:35:58.460
We used it for this summit demonstration.

00:35:59.000 --> 00:36:08.960
So all the things that we run, all this big simulation, all the processes that we have to spawn and so on, all these 4,600 nodes, we did it using our execution framework.

00:36:08.960 --> 00:36:18.100
And just to give a very quick overlook, the execution framework is using 0MQ to send messages between the different entities.

00:36:18.100 --> 00:36:20.380
And they're called managers and node managers.

00:36:20.780 --> 00:36:28.640
So we send events across the different node managers and we use 0RPC, which is an RPC framework built on top of 0MQ.

00:36:28.640 --> 00:36:34.740
We use that to also do a couple of remote calls between different node managers.

00:36:34.740 --> 00:36:37.860
All the scheduling of the graph is done using Python.

00:36:37.860 --> 00:36:44.740
There is some interfacing with the Metis library, which is written in C, but there is a Python wrapper for that already.

00:36:44.740 --> 00:36:45.040
Right.

00:36:45.040 --> 00:36:46.860
But the rest is all Python.

00:36:46.860 --> 00:36:48.840
0MQ looks really interesting.

00:36:48.840 --> 00:36:52.120
And I haven't done anything with it, but it has a nice Python library.

00:36:52.120 --> 00:36:52.360
Yeah.

00:36:52.360 --> 00:36:52.620
Yeah.

00:36:52.620 --> 00:36:52.900
Yeah.

00:36:52.900 --> 00:36:53.940
It's very, very nice.

00:36:53.940 --> 00:36:55.120
By ZMQ, right?

00:36:55.120 --> 00:36:55.660
Yes.

00:36:55.660 --> 00:36:56.020
Yeah.

00:36:56.020 --> 00:36:56.660
That's right.

00:36:56.660 --> 00:36:57.040
Yeah.

00:36:57.040 --> 00:37:01.460
It seems like something that would be really useful if you're sending a lot of messages around and whatnot.

00:37:01.460 --> 00:37:16.920
And then something I had not even heard of, which you had brought up, is 0RPC, which, so it basically sends messages out over 0MQ and then waits for a response or something like that, kind of to come back as another message?

00:37:16.920 --> 00:37:17.680
Yeah, exactly.

00:37:17.680 --> 00:37:18.180
Is that how?

00:37:18.420 --> 00:37:18.900
Okay.

00:37:18.900 --> 00:37:21.620
It's what you would expect from an RPC framework, right?

00:37:21.620 --> 00:37:30.160
You can get a reference on a remote object and invoke methods and get replies, pass down parameters and so on.

00:37:30.160 --> 00:37:33.020
And all of that then travels through 0MQ.

00:37:33.020 --> 00:37:41.580
I think it's using message pack for the serialization and then 0MQ for the actual networking.

00:37:42.580 --> 00:37:47.760
And on top of that, I think 0RPC has findings for different languages.

00:37:47.760 --> 00:37:52.920
So you can also do inter-language RPC with 0RPC.

00:37:52.920 --> 00:37:53.300
Right.

00:37:53.300 --> 00:37:54.220
Okay.

00:37:54.220 --> 00:37:56.580
Well, that looks really interesting.

00:37:56.580 --> 00:38:05.720
And to me, one of the big challenges it sounds like of programming this system is it's just so big and so distributed that you really need these layers.

00:38:05.720 --> 00:38:09.260
You know, you talk to this sort of, okay, I'm going to talk to the 0RPC.

00:38:09.520 --> 00:38:17.080
It talks to 0MQ, which then might talk to this distributed scheduling service that then figures out how stuff actually runs, right?

00:38:17.080 --> 00:38:18.760
Like there's just layer after layer.

00:38:18.760 --> 00:38:20.460
Is that a big challenge?

00:38:20.460 --> 00:38:20.980
Definitely.

00:38:21.300 --> 00:38:21.480
Yeah.

00:38:21.480 --> 00:38:21.840
Yeah.

00:38:21.840 --> 00:38:26.020
You have to try to keep, as you were saying, all your layers as clean as possible.

00:38:26.020 --> 00:38:34.320
Before we even settled on 0RPC, we also tried other RPC frameworks like Pyro4 and the remember which else.

00:38:34.320 --> 00:38:40.400
So on top of, you know, having to build layer on top of layer, we also have to support different ones at the same time.

00:38:40.400 --> 00:38:45.140
I think we still have the support there and you can kind of turn it on, but it's not really what we use.

00:38:45.140 --> 00:38:46.120
We just use 0RPC.

00:38:46.340 --> 00:38:46.780
Yeah, sure.

00:38:46.780 --> 00:38:52.680
Another interesting library that you guys have and you actually maintain is iJSON.

00:38:52.680 --> 00:38:53.320
Yes.

00:38:53.320 --> 00:38:56.360
We use and maintain iJSON as CRC32C.

00:38:56.360 --> 00:39:06.080
So iJSON, briefly described, is a way to iterate over very long JSON streams of data without having a big memory consumption.

00:39:06.080 --> 00:39:11.360
So you parse, parse, parse the JSON iteratively and you get kind of parsing events out of that.

00:39:11.360 --> 00:39:14.620
Well, there are different parsing levels.

00:39:14.740 --> 00:39:21.860
You can have like full objects and you can kind of query and what kind of objects do you want to get from your JSON stream and so on.

00:39:21.860 --> 00:39:23.920
And all of that is on iteratively.

00:39:23.920 --> 00:39:33.900
So you get like an iterator, you know, we are preparing version 3.0 and in that one you will get asynchronous iterables as well if you are in the asyncIO world.

00:39:34.300 --> 00:39:42.360
And we got into this because we were, again, dealing with very big computational graphs, which we express as JSON content.

00:39:42.360 --> 00:39:45.560
That's how we transmit this from one site to another.

00:39:45.560 --> 00:39:46.020
Yeah.

00:39:46.020 --> 00:39:50.840
And the last thing you want to do is like load gigabytes of JSON and deserialize it.

00:39:50.840 --> 00:39:51.640
Yeah, yeah, exactly.

00:39:51.860 --> 00:39:56.640
I just want these sub items here and then the rest of the time I don't care about.

00:39:56.640 --> 00:39:58.620
Or maybe I just want the first one.

00:39:58.620 --> 00:39:59.820
Like a first would be fine.

00:39:59.820 --> 00:40:02.080
Even if there's 10 million, just give me the first.

00:40:02.080 --> 00:40:02.980
Yeah, yeah, exactly.

00:40:02.980 --> 00:40:04.440
Yeah, JSON is super cool.

00:40:04.440 --> 00:40:07.800
And I think people, there's probably a lot of people who could take that and use it.

00:40:07.800 --> 00:40:12.500
You know, I was just, I had someone in the office hours for my online courses saying,

00:40:12.760 --> 00:40:18.240
I'm working with something that's a huge amount of data, something like Google BigQuery or something like that.

00:40:18.240 --> 00:40:21.720
It was like, it's too hard to load up all of this at once.

00:40:21.720 --> 00:40:23.340
So I got to take little bits and load it.

00:40:23.340 --> 00:40:26.400
And like, well, you know, have you thought about IJSON, right?

00:40:26.400 --> 00:40:27.260
That'd be really cool.

00:40:27.260 --> 00:40:29.880
And use a process like that or something along those lines.

00:40:29.880 --> 00:40:30.600
Yeah.

00:40:30.600 --> 00:40:36.320
You know, the other thing I kind of touched on it just a minute ago, but maybe you could speak a little bit more to it, you guys.

00:40:36.320 --> 00:40:42.020
Something that just amazes me in general, but this is such a big scale of it that I think it's even

00:40:42.020 --> 00:40:51.760
more interesting is a lot of times how we develop code in the small and then deploy it to somewhere in the cloud in a much, much bigger,

00:40:51.760 --> 00:40:56.060
more complex system than maybe we're used to working on.

00:40:56.060 --> 00:41:01.500
So, you know, the example that comes to mind for me is like, there's some developer at a coffee shop.

00:41:01.500 --> 00:41:07.140
They're working on, you know, a MacBook Air or something completely weak like that, right?

00:41:07.140 --> 00:41:10.740
And they're running a single instance of like a dev server.

00:41:11.280 --> 00:41:12.820
And then they push something to GitHub.

00:41:12.820 --> 00:41:15.580
It automatically gets picked up by CICD.

00:41:15.580 --> 00:41:22.680
It pushed over and it kicks off, you know, like a whole new version of some giant app running in a Kubernetes cluster across,

00:41:22.680 --> 00:41:26.060
who knows, 10 servers and a bunch of nodes and pods and so on.

00:41:26.060 --> 00:41:29.360
And then it's like, I'm going to be able to do this thing.

00:41:29.360 --> 00:41:34.620
And then like, it's scaled out to this huge system for you guys.

00:41:34.620 --> 00:41:36.080
Like, how does that work?

00:41:36.080 --> 00:41:36.380
Right.

00:41:36.380 --> 00:41:37.600
How do you debug this thing?

00:41:37.600 --> 00:41:41.040
How do you reason about like, it's little algorithms that are running.

00:41:41.600 --> 00:41:42.600
Can you set a break?

00:41:42.600 --> 00:41:44.100
Anything, right?

00:41:44.100 --> 00:41:45.440
Is that like a thing that you can do?

00:41:45.440 --> 00:41:47.360
Or is that like just literally too much?

00:41:47.360 --> 00:41:48.480
It's just, it's impossible.

00:41:48.480 --> 00:41:54.280
Can you, do you have like a Kubernetes cluster locally that allows you to kind of simulate this?

00:41:54.340 --> 00:41:56.480
Or do you have to program on the giant thing?

00:41:56.480 --> 00:41:59.060
No, you don't need to program on the giant thing.

00:41:59.340 --> 00:42:06.620
So for all these summit experiments, we started, as you were saying, like on the small, on our own laptop computers.

00:42:06.620 --> 00:42:08.860
I, and also different platforms.

00:42:08.860 --> 00:42:15.380
I usually run a Linux machine, but some, some people in our team or most people in our team use Macs.

00:42:15.380 --> 00:42:17.660
Yeah, we started on the very small.

00:42:17.660 --> 00:42:22.560
And for that, you have to make sure that on the very small scale, you know exactly what's going on.

00:42:22.560 --> 00:42:30.040
And you know that everything is working as you expect, so you don't have unexpected errors, unexpected troubles in the future, right?

00:42:30.040 --> 00:42:30.240
Right.

00:42:30.240 --> 00:42:36.300
For example, when, when developing Deluge, we have a very good test coverage for all the code base.

00:42:36.300 --> 00:42:40.080
And we run all the tests, you know, without internet connection on a single node.

00:42:40.080 --> 00:42:44.340
Because at that scale, you have to make sure that it's working, that everything is working fine.

00:42:44.340 --> 00:42:48.560
And from then on, you start kind of escalating and testing more complex things.

00:42:48.560 --> 00:42:50.320
But you have to have a very solid foundation.

00:42:50.640 --> 00:42:56.480
That's true for, for the development of Deluge, but also for the development of the code that we use in the Summit demonstration.

00:42:56.480 --> 00:43:08.080
Besides, again, on our laptops, then we went into, you know, a server that had one GPU, then a small cluster with two, three nodes that had a couple of GPUs on each.

00:43:08.080 --> 00:43:13.220
The Summit system in Oak Ridge, it's a Power 9 system.

00:43:13.220 --> 00:43:14.620
It's not an Intel system.

00:43:15.360 --> 00:43:21.040
Again, we, before jumping into Summit, we jumped into a cloud provider in the US that offers Power 9 machines.

00:43:21.040 --> 00:43:23.780
We made sure that everything worked there in a single node.

00:43:23.780 --> 00:43:29.900
Little by little, you start tackling problems as they come before hitting the full machine.

00:43:29.900 --> 00:43:30.240
Yeah.

00:43:30.320 --> 00:43:38.440
And I guess for you guys, there's another level of challenging where the machine itself, you can't just go to it.

00:43:38.440 --> 00:43:45.600
It's not like I could go to the cloud now and ask for a Kubernetes cluster if I'm willing to pay for a little bit of it.

00:43:45.600 --> 00:43:47.640
And I could just do that whenever I want.

00:43:47.740 --> 00:43:51.440
But I suspect this large computer is pretty much booked out.

00:43:51.440 --> 00:43:55.380
And you can't just get it whenever you want to make it go full power, right?

00:43:55.380 --> 00:43:56.020
Yeah.

00:43:56.020 --> 00:44:00.720
Well, first of all, there are all the kind of the paperwork involved, you know, in getting permission and so on.

00:44:00.720 --> 00:44:02.720
They have to send you a physical key.

00:44:02.720 --> 00:44:07.500
So they sent me a physical key from the US into Australia that I have to use when I log into the computer.

00:44:07.500 --> 00:44:11.360
So, yeah, it's not your everyday AWS systems, right?

00:44:11.360 --> 00:44:11.960
Yeah.

00:44:12.100 --> 00:44:16.300
And once there, all the systems work with queues.

00:44:16.300 --> 00:44:19.080
So you submit your jobs into a queue.

00:44:19.080 --> 00:44:22.200
And then the queue schedule decides what runs when.

00:44:22.200 --> 00:44:25.140
So, yeah, you're competing with a lot of people.

00:44:25.140 --> 00:44:29.100
Depending on how many resources you're asking, you will be delayed or not and so on.

00:44:29.100 --> 00:44:29.340
Yeah.

00:44:29.340 --> 00:44:33.060
But in Summit itself, we also started scaling little by little.

00:44:33.060 --> 00:44:36.840
We started with experiments with 6 no's, 10 no's, 60 no's.

00:44:36.840 --> 00:44:40.420
And little by little, we, again, started finding more and more problems.

00:44:40.720 --> 00:44:42.420
You know, things that you never really think about.

00:44:42.420 --> 00:44:49.260
Or very, very transient errors that only happen when you are spawning, you know, tens of thousands of processes.

00:44:49.260 --> 00:44:50.400
And one of them fails.

00:44:50.400 --> 00:44:54.340
And you didn't see it before because you didn't spawn as many processes before.

00:44:54.340 --> 00:44:56.940
Yeah, those are tricky to catch.

00:44:56.940 --> 00:44:57.820
Yeah, yeah.

00:44:57.820 --> 00:45:00.260
You're not in control at that point, right?

00:45:00.260 --> 00:45:02.320
Your control was it's like up and running.

00:45:02.320 --> 00:45:03.120
Everything's fine.

00:45:03.120 --> 00:45:04.400
Now your code runs, right?

00:45:04.400 --> 00:45:04.660
Yeah.

00:45:04.660 --> 00:45:09.280
And it's only once you find those errors that you can start to reason about them.

00:45:09.340 --> 00:45:11.080
And that's also very difficult, right?

00:45:11.080 --> 00:45:19.300
You cannot just go and attach yourself to thousands of processes at the same time and kind of step the back through them.

00:45:19.300 --> 00:45:21.480
You have to set a break point on Summit.

00:45:21.560 --> 00:45:29.260
Yeah, you will have to log a lot of stuff and then reason very heavily about what could be the possible cost.

00:45:29.260 --> 00:45:31.580
So we caught a lot of those.

00:45:31.580 --> 00:45:35.480
And then the final bit was the stress on the file system.

00:45:36.260 --> 00:45:41.600
So all of these clusters, they usually have a central file system that is shared across the cluster.

00:45:41.600 --> 00:45:50.600
But obviously, as you use more nodes, you are putting more stress into the central file system when reading and writing data, right?

00:45:50.600 --> 00:45:52.420
So that becomes a problem.

00:45:52.420 --> 00:45:52.860
Yeah.

00:45:52.860 --> 00:45:53.720
Yeah.

00:45:54.220 --> 00:46:01.920
So what was it like when you basically hit enter to submit the job for the 27,000 GPUs?

00:46:01.920 --> 00:46:05.740
Were you like, we better get it right.

00:46:06.080 --> 00:46:08.040
Yeah, we all assembled into a room.

00:46:08.040 --> 00:46:10.080
We did a countdown and we hit enter.

00:46:10.080 --> 00:46:10.360
Yeah.

00:46:10.360 --> 00:46:17.700
We basically had one shot doing the full simulation because we were given a time allocation of 20,000 node hours.

00:46:18.080 --> 00:46:22.660
We knew that in the big experiment, we were going to be using about 15,000.

00:46:22.660 --> 00:46:26.720
So it was either going to work or not, right?

00:46:26.720 --> 00:46:27.460
But it did.

00:46:27.460 --> 00:46:28.600
It did?

00:46:28.600 --> 00:46:33.200
So all the gradual scaling up, all the testing, it all worked.

00:46:33.200 --> 00:46:33.520
It paid off.

00:46:33.520 --> 00:46:34.120
It paid off.

00:46:34.120 --> 00:46:34.780
It paid off.

00:46:34.780 --> 00:46:35.580
Yeah.

00:46:35.580 --> 00:46:42.740
Did you get like a weird news report in Tennessee that it was suddenly hotter a little bit that day than they expected?

00:46:42.740 --> 00:46:45.040
I wouldn't be surprised.

00:46:46.800 --> 00:46:49.040
Like there's a warm breeze coming from the east.

00:46:49.040 --> 00:46:49.920
I don't know what that is.

00:46:49.920 --> 00:46:52.480
But yeah, that thing must have been really screaming.

00:46:52.480 --> 00:46:53.460
That's quite something.

00:46:53.460 --> 00:46:53.860
All right.

00:46:53.860 --> 00:46:56.880
So I guess we could probably wrap it up in terms of time.

00:46:56.880 --> 00:46:58.500
But this is super interesting.

00:46:58.500 --> 00:47:01.360
So maybe you guys could just tell us maybe some of the lessons learned.

00:47:01.360 --> 00:47:03.040
We kind of touched on them a little bit, right?

00:47:03.040 --> 00:47:05.060
This like scale it up a bit at a time.

00:47:05.060 --> 00:47:06.600
But what are some of the lessons you all learned?

00:47:06.600 --> 00:47:07.160
Yeah.

00:47:07.160 --> 00:47:10.940
For me, it was, I think it was the full process mostly.

00:47:10.940 --> 00:47:14.460
I also maybe learned a bit about Summit in particular.

00:47:14.700 --> 00:47:19.720
But it was more the process of scaling all this exercise up.

00:47:19.720 --> 00:47:22.060
That was really challenging.

00:47:22.060 --> 00:47:27.300
It really stressed the importance of having very solid foundations before you take the next step.

00:47:27.300 --> 00:47:33.120
Because otherwise, if you are kind of giving steps in the dark, you will continue hitting walls.

00:47:33.120 --> 00:47:33.480
Sure.

00:47:33.800 --> 00:47:34.460
Kevin, how about you?

00:47:34.460 --> 00:47:36.680
I'll reiterate what Rariko said.

00:47:36.680 --> 00:47:40.640
I mean, a lot of the early work with Deloji, obviously, is Test Monkey.

00:47:40.640 --> 00:47:48.260
There's a big project called Chili's, which is a very deep observation using the telescope in Socorro.

00:47:48.260 --> 00:47:49.780
So four years.

00:47:49.780 --> 00:47:51.940
And we did all of that on the Amazon cloud.

00:47:52.080 --> 00:47:57.160
And slowly build it up using a different software stack slightly.

00:47:57.160 --> 00:47:59.800
We didn't have all the problems with the GPUs.

00:47:59.800 --> 00:48:04.660
But we would start with two or three nodes, parallelize it.

00:48:04.660 --> 00:48:05.400
Does this work?

00:48:05.400 --> 00:48:06.640
Are we getting what we want?

00:48:06.640 --> 00:48:09.440
And then slowly wind it up.

00:48:09.440 --> 00:48:13.680
So, I mean, it doesn't sound much now when we compare it to Summit.

00:48:14.020 --> 00:48:17.220
I used to run it about 200 down by four nodes.

00:48:17.220 --> 00:48:17.720
Okay.

00:48:17.720 --> 00:48:18.320
Very cool.

00:48:18.320 --> 00:48:23.180
Now, I guess let's wrap it up with the final two questions for you guys.

00:48:23.180 --> 00:48:27.180
And you're welcome to throw out some of your own that you're maintaining or pick a different one.

00:48:27.180 --> 00:48:31.060
But how about, yeah, notable PyPI package?

00:48:31.060 --> 00:48:31.760
We'll start with that one.

00:48:31.760 --> 00:48:32.160
Notify.

00:48:32.160 --> 00:48:33.320
Notify.

00:48:33.320 --> 00:48:33.760
All right.

00:48:33.760 --> 00:48:34.100
Awesome.

00:48:34.100 --> 00:48:34.360
Yeah.

00:48:34.360 --> 00:48:37.560
I'm sure that's a foundation of a huge amount of work that you all are doing.

00:48:37.560 --> 00:48:37.980
Yeah.

00:48:37.980 --> 00:48:43.840
I think I will do some more stressing on iJSON just because I maintain it.

00:48:43.980 --> 00:48:45.760
And because there is this new version coming.

00:48:45.760 --> 00:48:46.860
So, yeah.

00:48:46.860 --> 00:48:47.420
Go out.

00:48:47.420 --> 00:48:48.480
Try it.

00:48:48.480 --> 00:48:49.380
It's pretty cool.

00:48:49.380 --> 00:48:49.660
Yeah.

00:48:49.660 --> 00:48:55.580
It looks really, really useful whenever you have a ton of, like, very large JSON or you need to not load it into memory.

00:48:55.580 --> 00:48:58.680
One I picked up from your other podcast is Typer.

00:48:58.680 --> 00:49:01.560
That's beautiful for writing command line interfaces.

00:49:01.560 --> 00:49:02.300
Oh, yeah.

00:49:02.300 --> 00:49:03.160
Typer is great.

00:49:03.160 --> 00:49:04.860
I think we covered that on Python Bytes.

00:49:04.860 --> 00:49:05.260
That's right.

00:49:05.260 --> 00:49:05.500
Yeah.

00:49:05.500 --> 00:49:06.280
That's right.

00:49:06.280 --> 00:49:07.200
So, Cracker.

00:49:07.200 --> 00:49:08.080
Thank you for that one.

00:49:08.080 --> 00:49:08.940
Yeah.

00:49:08.940 --> 00:49:09.620
You're welcome.

00:49:09.620 --> 00:49:10.120
That's super.

00:49:10.120 --> 00:49:10.760
All right.

00:49:10.760 --> 00:49:13.360
Now, when you all are writing some Python code or really any code,

00:49:13.520 --> 00:49:14.620
what editor are you using?

00:49:14.620 --> 00:49:15.180
PyCharm.

00:49:15.180 --> 00:49:15.620
PyCharm.

00:49:15.620 --> 00:49:15.880
All right.

00:49:15.880 --> 00:49:17.660
I use Eclipsed.

00:49:17.660 --> 00:49:21.480
I've been using Eclipsed for the last, like, 15 years for writing Java, C++, Python.

00:49:21.480 --> 00:49:25.880
So, Eclipsed in Python comes with PyDev, which is the...

00:49:25.880 --> 00:49:26.080
All right.

00:49:26.080 --> 00:49:27.960
You get PyDev and that adds it in, right?

00:49:27.960 --> 00:49:29.240
Yeah.

00:49:29.240 --> 00:49:34.200
But on the other way around, I used IntelliJ prior to going to ICRA.

00:49:34.200 --> 00:49:35.420
So, I just...

00:49:35.420 --> 00:49:37.600
You know, it has a nice look and feel.

00:49:37.600 --> 00:49:38.280
Yeah, it does.

00:49:38.280 --> 00:49:38.940
Yeah.

00:49:38.940 --> 00:49:41.560
It's a pretty easy transition from IntelliJ over to PyCharm.

00:49:41.560 --> 00:49:42.380
All right, you guys.

00:49:42.860 --> 00:49:46.000
That's probably a good place to leave it or get short on time.

00:49:46.000 --> 00:49:47.360
But thank you for sharing.

00:49:47.360 --> 00:49:48.180
This is super interesting.

00:49:48.180 --> 00:49:49.720
Final call to action.

00:49:49.720 --> 00:49:52.420
People want to learn more about the SKA.

00:49:52.420 --> 00:49:56.260
They want to learn about some of these libraries you're working on, more about radio astronomy.

00:49:56.260 --> 00:49:57.200
What do you tell them?

00:49:57.200 --> 00:49:59.580
There is also a lot of material out there, too.

00:49:59.580 --> 00:50:03.240
If you're interested in the topic, there's tons of material.

00:50:03.240 --> 00:50:07.700
Just go to the SKA telescope organization website, to the ICRA website.

00:50:07.700 --> 00:50:14.480
I'm sure in YouTube, it will be full of videos as well to learn about all these different concepts.

00:50:14.480 --> 00:50:14.920
Cool.

00:50:14.920 --> 00:50:15.520
All right.

00:50:15.520 --> 00:50:17.260
Well, thank you both for being here.

00:50:17.260 --> 00:50:18.640
This was a lot of fun.

00:50:18.640 --> 00:50:22.080
And I really enjoyed learning about radio telescopes.

00:50:22.080 --> 00:50:26.420
And I didn't even realize, Rodrigo, that you are the maintainer of iJSON,

00:50:26.540 --> 00:50:27.800
which is a nice little bonus.

00:50:27.800 --> 00:50:28.180
Very cool.

00:50:28.180 --> 00:50:28.580
Yeah.

00:50:28.580 --> 00:50:28.780
Yeah.

00:50:28.780 --> 00:50:32.540
Well, I took over just last year, I believe.

00:50:32.540 --> 00:50:34.800
So I'm not the original creator.

00:50:34.800 --> 00:50:38.900
I just became the maintainer after I started kind of contributing more to it.

00:50:38.900 --> 00:50:39.200
Super.

00:50:39.200 --> 00:50:40.620
Well, thank you, Rodrigo.

00:50:40.620 --> 00:50:41.180
Thank you, Kevin.

00:50:41.180 --> 00:50:42.580
Have a great day.

00:50:42.580 --> 00:50:43.200
Yeah, you too.

00:50:43.200 --> 00:50:43.460
Bye.

00:50:43.460 --> 00:50:43.980
Bye.

00:50:43.980 --> 00:50:44.160
Bye.

00:50:44.160 --> 00:50:47.920
This has been another episode of Talk Python To Me.

00:50:47.920 --> 00:50:52.000
Our guests on this episode have been Rodrigo Tabar and Kevin Vinson.

00:50:52.000 --> 00:50:54.720
And it's been brought to you by Linode and Clubhouse.

00:50:55.880 --> 00:50:59.560
Start your next Python project on Linode's state-of-the-art cloud service.

00:50:59.560 --> 00:51:03.880
Just visit talkpython.fm/Linode, L-I-N-O-D-E.

00:51:03.880 --> 00:51:07.180
You'll automatically get a $20 credit when you create a new account.

00:51:07.180 --> 00:51:12.620
Clubhouse is a fast and enjoyable project management platform that breaks down silos

00:51:12.620 --> 00:51:15.180
and brings teams together to ship value, not features.

00:51:15.180 --> 00:51:16.900
Fall in love with project planning.

00:51:16.900 --> 00:51:19.980
Visit talkpython.fm/Clubhouse.

00:51:20.980 --> 00:51:22.520
Want to level up your Python?

00:51:22.520 --> 00:51:27.340
If you're just getting started, try my Python Jumpstart by Building 10 Apps course.

00:51:27.340 --> 00:51:32.420
Or if you're looking for something more advanced, check out our new async course that digs into

00:51:32.420 --> 00:51:35.480
all the different types of async programming you can do in Python.

00:51:35.480 --> 00:51:39.440
And of course, if you're interested in more than one of these, be sure to check out our

00:51:39.440 --> 00:51:40.120
everything bundle.

00:51:40.260 --> 00:51:42.040
It's like a subscription that never expires.

00:51:42.040 --> 00:51:44.180
Be sure to subscribe to the show.

00:51:44.180 --> 00:51:46.600
Open your favorite podcatcher and search for Python.

00:51:46.600 --> 00:51:47.820
We should be right at the top.

00:51:47.820 --> 00:51:52.640
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:51:52.640 --> 00:51:56.800
and the direct RSS feed at /rss on talkpython.fm.

00:51:57.360 --> 00:51:58.880
This is your host, Michael Kennedy.

00:51:58.880 --> 00:52:00.380
Thanks so much for listening.

00:52:00.380 --> 00:52:01.440
I really appreciate it.

00:52:01.440 --> 00:52:03.180
Now get out there and write some Python code.

00:52:03.180 --> 00:52:22.540
I really appreciate it.

