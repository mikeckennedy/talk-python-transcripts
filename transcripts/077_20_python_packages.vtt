WEBVTT

00:00:00.001 --> 00:00:06.960
Many of you write to me and tell me how you appreciate the way my guests and I highlight a particular Python package at the end of each episode.

00:00:06.960 --> 00:00:10.340
Well, if you enjoy that little segment, you're going to love this episode.

00:00:10.340 --> 00:00:16.480
This week, you'll meet Caleb Hadding, who wrote a great book called 20 Python Libraries You Aren't Using But Should.

00:00:16.480 --> 00:00:25.460
He and I spent an hour digging into all the very powerful and interesting packages you probably haven't heard of, but will be super excited to use after you learn about them.

00:00:25.860 --> 00:00:31.760
This is Talk Python To Me, episode 77, recorded September 20th, 2016.

00:00:51.720 --> 00:01:03.100
Welcome to Talk Python To Me, a weekly podcast on Python, the language, the libraries, the ecosystem, and the personalities.

00:01:03.100 --> 00:01:07.220
This is your host, Michael Kennedy. Follow me on Twitter where I'm @mkennedy.

00:01:07.220 --> 00:01:13.700
Keep up with the show and listen to past episodes at talkpython.fm and follow the show on Twitter via at Talk Python.

00:01:14.700 --> 00:01:17.920
This episode is brought to you by Capital One and Intel.

00:01:17.920 --> 00:01:22.500
Thank them both for sponsoring the show by checking out what they're offering during their segments.

00:01:22.500 --> 00:01:26.640
Hey, everyone. I have a quick message for you before we get to Caleb and his book.

00:01:26.640 --> 00:01:33.020
In addition to writing this book for O'Reilly, Caleb also wrote a screencast course on Cython.

00:01:33.020 --> 00:01:36.280
And it looks to be one of the better Cython courses out there.

00:01:36.280 --> 00:01:42.800
So when he's talking about Cython, if you're really interested in what he's up to, be sure to check out his course, which is linked in the show notes.

00:01:43.020 --> 00:01:46.620
And O'Reilly agreed to give away a free copy of his course.

00:01:46.620 --> 00:01:49.900
All you have to do to be eligible is be a friend of the show.

00:01:49.900 --> 00:01:56.340
So be sure to visit talkpython.fm, click on friends of the show, enter your email address, and you'll be eligible to win.

00:01:56.340 --> 00:01:58.220
Now, let's talk to Caleb.

00:01:58.220 --> 00:02:00.720
Caleb, welcome to the show.

00:02:00.720 --> 00:02:02.660
Hi, Michael. It's great to be here.

00:02:02.660 --> 00:02:04.920
Yeah, I'm super excited to talk to you.

00:02:04.920 --> 00:02:09.220
We've got some really cool stuff around a book, a free e-book that you did.

00:02:09.220 --> 00:02:11.040
And I found it super interesting.

00:02:11.040 --> 00:02:12.740
So I think everyone else will.

00:02:12.740 --> 00:02:17.140
Basically, we're going to take the last question I always put at the end of my podcast.

00:02:17.140 --> 00:02:18.660
What's your favorite PyPI package?

00:02:18.660 --> 00:02:22.340
And turn that into an entire episode and just go deep on that idea, right?

00:02:22.340 --> 00:02:22.860
Okay.

00:02:22.860 --> 00:02:24.860
So before we get to that, though, let's start at the beginning.

00:02:24.860 --> 00:02:27.340
Where do you get into programming and Python, that sort of thing?

00:02:27.740 --> 00:02:29.240
Yeah, great question.

00:02:29.240 --> 00:02:32.820
So one of the other podcasts I listen to is the C++ podcast.

00:02:32.820 --> 00:02:38.600
And just about every guest on that show says that they started programming assembler in grade school.

00:02:38.600 --> 00:02:39.980
That was not my story.

00:02:39.980 --> 00:02:43.380
I didn't get into programming at all in school or high school.

00:02:43.380 --> 00:02:47.260
I started really as a hobby in university while I was studying chemical engineering,

00:02:47.260 --> 00:02:51.680
which is kind of an odd thing to do as a hobby when you're doing something completely different.

00:02:51.680 --> 00:02:55.180
But as the years went on, I kind of got more and more into programming.

00:02:55.180 --> 00:02:58.980
And it turned out that I did my master's degree in process control,

00:02:58.980 --> 00:03:01.380
which is like a subset of chemical engineering.

00:03:01.380 --> 00:03:03.140
And that was all in MATLAB.

00:03:03.140 --> 00:03:06.340
So it was pretty much all a programmed course.

00:03:06.340 --> 00:03:08.940
And that's really how I got into programming.

00:03:08.940 --> 00:03:12.560
And I learned that I really did not like MATLAB very much at all.

00:03:12.560 --> 00:03:16.180
Yeah, I spent some time there.

00:03:16.180 --> 00:03:17.060
I can sympathize.

00:03:17.060 --> 00:03:19.500
I don't love the .m files, no.

00:03:19.500 --> 00:03:21.900
Yeah, I got to know it really, really well.

00:03:21.900 --> 00:03:26.100
And yeah, I decided that I did not really want to carry that forward.

00:03:26.100 --> 00:03:30.380
And it was really when I started working in the first or second year that I started working.

00:03:30.380 --> 00:03:33.480
I started learning a couple of languages outside of work.

00:03:33.480 --> 00:03:36.320
And the one that I really tried to focus on was Java.

00:03:36.320 --> 00:03:40.740
And I signed up for a fairly expensive certification course.

00:03:40.740 --> 00:03:45.000
I think Java was around 1.2, version 1.2 or 1.3 or something at the time.

00:03:45.640 --> 00:03:51.480
And halfway through that course, I came across Andrew Kuchling's Python tutorial at the time,

00:03:51.480 --> 00:03:53.580
which I think was for Python 1.5.

00:03:53.580 --> 00:03:56.360
And it just blew my mind.

00:03:56.360 --> 00:04:02.860
I kind of had the realization that I couldn't possibly use Java anymore to do the kind of work,

00:04:02.860 --> 00:04:06.000
like data analysis work that I was doing, because it was so easy in Python.

00:04:06.000 --> 00:04:11.240
It was just a complete waste of time to develop all of these object-oriented structures around

00:04:11.240 --> 00:04:14.160
fairly simple data pipeline processing tasks.

00:04:14.300 --> 00:04:16.000
Yeah, that makes a lot of sense.

00:04:16.000 --> 00:04:18.180
I mean, Java has so much formality.

00:04:18.180 --> 00:04:22.780
And maybe, let's say it's maybe good for large applications.

00:04:22.780 --> 00:04:23.580
Maybe.

00:04:23.580 --> 00:04:23.940
Exactly.

00:04:23.940 --> 00:04:25.960
But it certainly doesn't make sense for small ones, right?

00:04:25.960 --> 00:04:26.680
Like you're talking about.

00:04:26.680 --> 00:04:27.740
Yeah, absolutely.

00:04:27.740 --> 00:04:31.200
There's definitely a place for Java for very large programs.

00:04:31.680 --> 00:04:37.780
But for the kind of things that I was doing, and especially for shorter programs involving data pipeline processing,

00:04:37.780 --> 00:04:41.300
Java is just way more than what you need to get the job done.

00:04:41.300 --> 00:04:43.540
And that was pretty much the end of Java for me.

00:04:43.540 --> 00:04:44.800
I never finished that course.

00:04:45.200 --> 00:04:46.500
I really got stuck into Python.

00:04:46.500 --> 00:04:48.100
And this was around 2001.

00:04:48.100 --> 00:04:49.880
So quite a few years ago.

00:04:49.880 --> 00:04:52.560
And then I watched Python become Python 2.

00:04:52.560 --> 00:04:55.020
And 2.4 was a big one for me.

00:04:55.020 --> 00:04:56.920
I used that for quite a long time.

00:04:56.920 --> 00:04:57.580
And so on.

00:04:57.580 --> 00:04:59.900
So yeah, that's pretty much how I got into Python.

00:04:59.900 --> 00:05:03.340
But along the way, I did use quite a few other languages fairly heavily.

00:05:03.980 --> 00:05:10.160
Fortran I used quite a bit as well because large chunks of the scientific world still use Fortran.

00:05:10.160 --> 00:05:12.620
I have written new Fortran 77 code.

00:05:12.620 --> 00:05:14.580
I have added that to the world.

00:05:14.580 --> 00:05:15.880
Oh my gosh.

00:05:15.880 --> 00:05:16.840
That's awesome.

00:05:16.840 --> 00:05:17.200
Yeah.

00:05:17.200 --> 00:05:20.920
And Delphi I used for quite a few years.

00:05:20.920 --> 00:05:25.940
My career has moved into and out of software development and into chemical engineering.

00:05:25.940 --> 00:05:30.260
I've kind of straddled both worlds for the past 15 years or so.

00:05:30.620 --> 00:05:38.600
And I did a stint as a software engineer in the hospitality industry for writing hotel administration software for about four years.

00:05:38.600 --> 00:05:45.120
And that was heavily using Delphi, the IDE from what used to be Borland and then became Embarcadero.

00:05:45.120 --> 00:05:47.900
So I got to know that language really, really well as well.

00:05:47.900 --> 00:05:50.360
Pretty much as well as I know Python, I would say.

00:05:50.360 --> 00:05:52.020
That's very interesting to me.

00:05:52.020 --> 00:05:55.780
I kind of regard Delphi and Python as almost polar opposites in many ways.

00:05:55.780 --> 00:05:59.580
A GUI is very easy in the one, not quite as easy in the other.

00:06:00.180 --> 00:06:01.540
Deployment is extremely easy in the one.

00:06:01.540 --> 00:06:03.520
Deployment is kind of difficult in the other.

00:06:03.520 --> 00:06:04.620
And so on.

00:06:04.620 --> 00:06:10.040
There are many parallels where I kind of see Delphi and Python as direct opposites.

00:06:10.040 --> 00:06:13.540
Another good one is the GIL, the global interpreter lock, which I think is really fascinating.

00:06:13.540 --> 00:06:21.040
In the Delphi world, for many years, one of the things that developers asked for over and over again was thread safety in the library.

00:06:21.500 --> 00:06:25.480
Because it was one of the huge talking points.

00:06:25.480 --> 00:06:35.320
They wanted the containers and the structures inside the library to be thread safe because it was too easy to get race conditions in threads because you could just spawn native threads and have them clobber each other's memory layer.

00:06:36.160 --> 00:06:42.400
And it's really fascinating to me that the exact inverse argument gets made in the Python world.

00:06:42.400 --> 00:06:43.520
That is funny.

00:06:43.520 --> 00:06:48.300
The presence of thread safety is the problem because it slows your code down.

00:06:48.300 --> 00:06:58.300
So, yeah, it's really interesting to be able to have a depth of knowledge in multiple programming communities because you kind of get a sense of maybe what is really important and what is spurious.

00:06:58.800 --> 00:07:00.620
Everything is a set of trade-offs.

00:07:00.620 --> 00:07:01.240
Yeah, exactly.

00:07:01.240 --> 00:07:01.780
That's the thing.

00:07:01.780 --> 00:07:02.600
That's what I was thinking.

00:07:02.600 --> 00:07:04.560
Nothing is accidental.

00:07:04.560 --> 00:07:06.940
Things are designed the way they are for good reasons.

00:07:06.940 --> 00:07:10.440
And they may not always be the best fit for every particular situation.

00:07:10.440 --> 00:07:11.140
Right.

00:07:11.140 --> 00:07:13.340
You learn a language that maybe it's not obvious initially.

00:07:13.340 --> 00:07:14.680
You don't know the history or whatever.

00:07:14.680 --> 00:07:19.680
But there was probably some deep thought that went into at least all the popular programming languages.

00:07:19.680 --> 00:07:22.780
Those things have evolved with lots of thought over time.

00:07:22.780 --> 00:07:23.120
Absolutely.

00:07:23.120 --> 00:07:23.760
Yeah.

00:07:23.760 --> 00:07:24.240
Yeah.

00:07:24.240 --> 00:07:24.680
Nice.

00:07:24.680 --> 00:07:25.160
Okay.

00:07:25.260 --> 00:07:31.140
Well, so a lot of Delphi, a lot of Python, a lot of scientific programming.

00:07:31.140 --> 00:07:33.940
What are you doing with Python and programming today?

00:07:33.940 --> 00:07:34.880
Like, what's your day job?

00:07:34.880 --> 00:07:35.660
Good point.

00:07:35.660 --> 00:07:41.800
So, I can give you a quick two-minute, well, one minute, let's say, run through of the things I've done.

00:07:41.800 --> 00:07:48.180
So, I started in chemical engineering with doing a lot of simulation work using off-the-shelf tools for that.

00:07:48.180 --> 00:07:52.340
And as time progressed, I started moving more towards the problems where there were no off-the-shelf tools.

00:07:52.340 --> 00:07:53.580
And for those, you have to write code.

00:07:54.100 --> 00:07:55.860
And I began using a lot of Fortran.

00:07:55.860 --> 00:07:57.700
Then I started incorporating Python into that.

00:07:57.700 --> 00:08:02.280
And then I took a break from engineering and went into software development where I used Delphi.

00:08:02.280 --> 00:08:04.700
But I also used Python as well for web development.

00:08:04.700 --> 00:08:12.860
Then I went back into engineering and I started writing simulation software for cold gasification, which is what brought me to Australia.

00:08:12.860 --> 00:08:24.660
And what's interesting about that job was for the first time, I really decided to use Python for the entire system, which means all of the number crunching stuff as well.

00:08:24.660 --> 00:08:26.540
And that's where Cython really came into the picture for me.

00:08:26.680 --> 00:08:39.980
I made the decision to use a full Python stack for that simulation work because it seemed to me that Cython was mature enough, really, to be able to give you the speed that you need to solve these mathematical problems in the background.

00:08:39.980 --> 00:08:42.280
And that definitely proved to be the case.

00:08:42.280 --> 00:08:43.740
It was a good choice on my part.

00:08:43.740 --> 00:08:47.500
Cython is not so much a break from Python, really, as an extension.

00:08:47.500 --> 00:08:53.180
But it gives you all of the native speed and control over the memory layout that you need if you want to make fast code.

00:08:53.180 --> 00:08:55.280
So I spent a couple of years doing that.

00:08:55.280 --> 00:08:55.580
Yeah.

00:08:55.580 --> 00:08:59.980
Would you say it's a little analogous to, like, inline assembler and C++ or something like that?

00:08:59.980 --> 00:09:02.700
You're like, just if this one loop could be faster.

00:09:02.700 --> 00:09:04.320
Let me just do this part fast.

00:09:04.320 --> 00:09:06.020
I think I would disagree with that.

00:09:06.020 --> 00:09:06.360
Okay.

00:09:06.360 --> 00:09:07.980
I began with that in mind.

00:09:07.980 --> 00:09:11.840
It's easy to look at it that way, but Cython is so much more than inline assembler.

00:09:11.840 --> 00:09:15.000
There's another way to look at it, which is you can write.

00:09:15.000 --> 00:09:18.060
You can get all the benefits of C by writing what looks like Python.

00:09:18.060 --> 00:09:21.980
And in one or two places, you just add some types onto a couple of variables.

00:09:21.980 --> 00:09:24.980
And you can get a hundredfold increase in speed.

00:09:24.980 --> 00:09:31.320
So whereas inline assembler is much more of a niche application of a different technology.

00:09:31.320 --> 00:09:34.040
Unless you can read assembler really easily, which I can't.

00:09:34.040 --> 00:09:35.020
Yeah, neither can I.

00:09:35.020 --> 00:09:36.840
Having inline assembler, yeah.

00:09:36.840 --> 00:09:42.360
Where Cython is not like that, by and large, Cython is as easy to read as Python.

00:09:42.360 --> 00:09:44.820
There are a couple of things that are different in the layout.

00:09:45.000 --> 00:09:48.740
But overall, you would find Cython as easy to read as Python.

00:09:48.740 --> 00:09:49.280
Okay.

00:09:49.280 --> 00:09:50.420
Sounds good.

00:09:50.420 --> 00:09:51.900
So back to what you're doing today.

00:09:51.900 --> 00:09:52.340
Yeah.

00:09:52.340 --> 00:09:56.220
So I've been working for the past couple of months on a contract for GPS tracking, which

00:09:56.220 --> 00:09:57.900
has also been using a full Python stack.

00:09:57.900 --> 00:10:01.540
And I was very lucky in that they were willing to go straight to Python 3.5.

00:10:01.860 --> 00:10:07.720
So I've been writing async I.O. code in Python 3.5 since February, which I feel very fortunate

00:10:07.720 --> 00:10:09.620
to have had that opportunity.

00:10:09.620 --> 00:10:16.500
And yeah, I'm starting a new job tomorrow from the date of this recording, working for a company

00:10:16.500 --> 00:10:19.460
called Console, which was formerly called IIX.

00:10:20.460 --> 00:10:25.500
And yeah, I believe my title has something to do with network orchestration, which is going

00:10:25.500 --> 00:10:28.040
to be a whole new thing again for me to learn.

00:10:28.040 --> 00:10:29.280
That is quite a shift.

00:10:29.280 --> 00:10:30.100
But that's really cool.

00:10:30.100 --> 00:10:33.680
And Python, of course, plays a super important role in that space.

00:10:33.680 --> 00:10:34.880
So it makes a lot of sense.

00:10:34.880 --> 00:10:36.100
Excellent.

00:10:36.100 --> 00:10:36.860
Yeah, absolutely.

00:10:36.860 --> 00:10:41.740
One of the big benefits of Python, just as a technology choice, is that you can use it

00:10:41.740 --> 00:10:42.440
just about every way.

00:10:42.740 --> 00:10:44.400
Yeah, that actually is really important.

00:10:44.400 --> 00:10:46.380
It's really important.

00:10:46.380 --> 00:10:51.320
Yeah, so I think that's a wide range of background and experiences.

00:10:51.320 --> 00:10:57.720
And it gives you a nice overview of the ecosystem and the standard library and all the different

00:10:57.720 --> 00:11:02.720
ways that Python makes you efficient, productive, and so on.

00:11:02.720 --> 00:11:04.340
And so you wrote a really cool book.

00:11:04.340 --> 00:11:05.740
You wrote it for O'Reilly, right?

00:11:05.740 --> 00:11:07.120
Yeah, that's right.

00:11:07.120 --> 00:11:09.040
Yeah, as a free e-book, I think.

00:11:09.700 --> 00:11:14.980
And it's called 20 Python Libraries You Aren't Using But Should.

00:11:14.980 --> 00:11:17.420
And I thought it was a really nice survey.

00:11:17.420 --> 00:11:19.320
Very BuzzFeed-y title.

00:11:19.320 --> 00:11:21.100
You know what?

00:11:21.100 --> 00:11:26.500
Anytime it starts with 10 or 20 or the seven things you should never say, you know it's

00:11:26.500 --> 00:11:26.880
a BuzzFeed.

00:11:26.880 --> 00:11:30.980
But it really is succinct and it lives up to the name.

00:11:30.980 --> 00:11:31.440
It's good.

00:11:31.440 --> 00:11:33.580
The idea for the book came from O'Reilly.

00:11:33.580 --> 00:11:38.220
Susan Conant at O'Reilly suggested it to me and asked if I would be willing to write

00:11:38.220 --> 00:11:38.480
the book.

00:11:38.480 --> 00:11:43.740
So the title was established before I got to the project and then I provided the content.

00:11:43.740 --> 00:11:47.960
Yeah, but the original working title was 10 Python Libraries You Aren't Using But Should.

00:11:47.960 --> 00:11:50.100
And I couldn't stop at 10.

00:11:50.100 --> 00:11:55.480
And in fact, if you count the major featured packages, there are 20.

00:11:55.480 --> 00:11:59.960
But you'll see throughout the text of the document that I refer to a whole bunch of other libraries

00:11:59.960 --> 00:12:01.740
as well in footnotes.

00:12:01.880 --> 00:12:03.380
Yeah, I thought that was interesting.

00:12:03.380 --> 00:12:08.860
Yeah, we'll talk about the 20 major ones and maybe even touch on some of the ones that you pull in.

00:12:08.860 --> 00:12:14.500
Like, for example, one of the web service bits, the implementation of the web service uses a few

00:12:14.500 --> 00:12:18.460
other libraries that we can talk about later, but they're not actually part of the 20, right?

00:12:18.520 --> 00:12:23.840
So there's, I feel like you get a really good, well-rounded view of what's out there.

00:12:24.240 --> 00:12:28.080
I was quite cautious about writing the book because it's a fairly contentious thing.

00:12:28.080 --> 00:12:32.400
The choices, the technology choices that people make, many people can be quite passionate about

00:12:32.400 --> 00:12:32.860
those things.

00:12:32.860 --> 00:12:37.620
And the brief for the book was, we want you to focus on libraries that other people don't know

00:12:37.620 --> 00:12:38.200
about yet.

00:12:38.680 --> 00:12:40.720
So that means I have to leave things out.

00:12:40.720 --> 00:12:43.960
And it also means that I have to leave things out that may be fairly popular, which means

00:12:43.960 --> 00:12:48.280
there might be quite a widespread degree of support for libraries that I'm not going to

00:12:48.280 --> 00:12:48.680
be mentioning.

00:12:48.680 --> 00:12:51.720
So I was somewhat apprehensive about that.

00:12:51.720 --> 00:12:56.820
So the libraries that I tried to focus on were things specifically that may not have much

00:12:56.820 --> 00:12:59.580
exposure, which is a very interesting idea for the book.

00:12:59.580 --> 00:13:04.380
I can't include things that are too niche that they could not be used for much, you know,

00:13:04.380 --> 00:13:05.640
very low applicability.

00:13:05.820 --> 00:13:10.440
But at the same time, I did not want to include things that were very well known because that

00:13:10.440 --> 00:13:11.780
defeats the purpose of the book.

00:13:11.780 --> 00:13:14.100
So I found it quite challenging to pitch it.

00:13:14.100 --> 00:13:16.760
It's the ones you aren't using, not the ones that you are, right?

00:13:16.760 --> 00:13:17.760
Exactly.

00:13:17.760 --> 00:13:18.160
Yeah.

00:13:18.160 --> 00:13:18.640
Yeah.

00:13:18.640 --> 00:13:22.060
It is a challenging one to go, okay, let's strip off that.

00:13:22.060 --> 00:13:25.080
Like if you say, what is the most popular library to do?

00:13:25.080 --> 00:13:29.080
You almost have to say, okay, well, except for that one, what else can we do?

00:13:29.080 --> 00:13:29.940
But I...

00:13:29.940 --> 00:13:30.560
Yeah, exactly.

00:13:30.560 --> 00:13:32.720
And I thought about that when I read the title.

00:13:32.720 --> 00:13:36.520
I'm like, oh, is this going to be a bunch of niche things that are like second fiddle

00:13:36.520 --> 00:13:38.280
to the stuff that you actually should be using?

00:13:38.280 --> 00:13:39.680
But no, I think it was really good.

00:13:39.680 --> 00:13:44.820
So maybe we could start by talking about the ones that everybody has installed already.

00:13:44.820 --> 00:13:46.540
That's the stuff that comes in the standard library.

00:13:46.540 --> 00:13:50.200
So you have, in the first chapter, you said, hey, look, there's a bunch of stuff you're

00:13:50.200 --> 00:13:51.140
not using that's built in.

00:13:51.140 --> 00:13:55.980
Developers with experience do tend to look in the standard library first because they've

00:13:55.980 --> 00:14:00.140
been burned by carrying extra dependencies, which after a couple of years may not be as

00:14:00.140 --> 00:14:00.780
well maintained.

00:14:00.780 --> 00:14:04.380
The impression that I have is that more experienced developers tend to lean more heavily on the

00:14:04.380 --> 00:14:05.900
standard library when choosing technology.

00:14:05.900 --> 00:14:10.760
Even if some of the time there may be other third-party packages that might be a better

00:14:10.760 --> 00:14:10.980
fit.

00:14:10.980 --> 00:14:12.400
That's a decision that gets made.

00:14:12.400 --> 00:14:13.120
That's really a trade-off.

00:14:13.120 --> 00:14:14.120
And I do the same.

00:14:14.120 --> 00:14:20.340
When I have to deploy an application to production and I know that this is a core service, I tend

00:14:20.340 --> 00:14:24.740
to lean more heavily on choosing things out of the standard library when possible, as opposed

00:14:24.740 --> 00:14:26.120
to adding third-party dependencies.

00:14:26.420 --> 00:14:31.300
Whereas newer developers tend to get whatever is the latest and greatest on PyPy and run

00:14:31.300 --> 00:14:31.640
with that.

00:14:31.640 --> 00:14:37.160
So what seems to me to be the case is that more experienced developers have a much better

00:14:37.160 --> 00:14:39.400
and deeper knowledge of what is available in the standard library.

00:14:39.400 --> 00:14:44.480
So even though the book was intended to be focused on third-party libraries only, I did

00:14:44.480 --> 00:14:50.420
want to squeeze in some of the absolute must-have, must-know standard library options, like the

00:14:50.420 --> 00:14:53.260
collections package, which is the first section in this chapter.

00:14:53.260 --> 00:14:59.840
If you watch any of Raymond Hittinger's talks, he plugs the collections module heavily, as

00:14:59.840 --> 00:15:01.820
well he should, because it's awesome.

00:15:01.820 --> 00:15:06.020
Yeah, I do feel strongly about that, that people really should know more about what's in the

00:15:06.020 --> 00:15:06.580
standard library.

00:15:06.580 --> 00:15:12.200
And my original version of the book had more of it in, but we decided that we wanted to focus

00:15:12.200 --> 00:15:13.580
the book more on the third-party stuff.

00:15:13.580 --> 00:15:15.480
So it got trimmed down.

00:15:15.480 --> 00:15:15.920
Sure.

00:15:15.920 --> 00:15:17.520
I think that makes a lot of sense.

00:15:17.520 --> 00:15:18.600
Yeah, that makes a lot of sense.

00:15:18.940 --> 00:15:23.760
Partly, I mean, there's nobody who is the advocate for the thing in the standard library.

00:15:23.760 --> 00:15:24.480
It's just built in.

00:15:24.480 --> 00:15:28.960
But when somebody makes their open source library, they set up some GitHub Pages thing, and they've

00:15:28.960 --> 00:15:30.000
got some cool logo.

00:15:30.000 --> 00:15:33.900
And, you know, like it's, there's somebody promoting it in a sense.

00:15:33.900 --> 00:15:35.100
And so I can see that.

00:15:35.100 --> 00:15:35.940
Yeah.

00:15:35.940 --> 00:15:39.520
So a couple of the things that you talked about in the collection library, one of them, which

00:15:39.520 --> 00:15:42.640
I think is pretty interesting and timely, is ordered dict.

00:15:43.060 --> 00:15:43.300
Yeah.

00:15:43.300 --> 00:15:48.080
So what's interesting about this section is that it may become redundant in December.

00:15:48.080 --> 00:15:54.300
I don't know if you've been following the discussions on the Python dev mailing list, but the new

00:15:54.300 --> 00:16:00.400
dictionary in Python 3.6, which I think the release date for the final version is December, the

00:16:00.400 --> 00:16:01.660
dictionary is going to become ordered.

00:16:01.660 --> 00:16:06.580
Whether that is going to be advertised as a requirement for the language spec, or whether

00:16:06.580 --> 00:16:09.420
that's just going to be an implementation detail remains to be seen.

00:16:09.420 --> 00:16:10.740
But yeah.

00:16:11.600 --> 00:16:12.080
Sure.

00:16:12.080 --> 00:16:12.940
Yeah.

00:16:12.940 --> 00:16:19.040
And so every now and then you'll see people building special dictionaries for Python that

00:16:19.040 --> 00:16:20.080
are ordered.

00:16:20.080 --> 00:16:25.660
For example, the MongoDB library exchanges dictionaries at serialization, and the changing of order

00:16:25.660 --> 00:16:29.480
causes more rights on the server for documents than if it doesn't.

00:16:29.480 --> 00:16:32.780
And so they may went and created their own, and we've got this order dict.

00:16:32.780 --> 00:16:36.520
So what's some of the problems you run into with like the regular dictionary?

00:16:36.520 --> 00:16:38.580
Or like, why do you care about ordering, I guess?

00:16:38.580 --> 00:16:43.180
The main use case for ordering that I've come across is usually when processing things that

00:16:43.180 --> 00:16:47.720
are really mappings in a sequence, and they need to be processed in the sequence in which

00:16:47.720 --> 00:16:48.140
they appear.

00:16:48.140 --> 00:16:52.860
So I think the example I gave in the text is, yeah, and a common example is processing lines

00:16:52.860 --> 00:16:54.760
in a file where the lines map to something else.

00:16:54.760 --> 00:17:00.400
And you want to serialize them or persist them in some way, retaining the order that they appeared

00:17:00.400 --> 00:17:02.060
in the original list.

00:17:02.060 --> 00:17:05.520
Right, like maybe like a CSV you're going to load and you're going to say look up by

00:17:05.520 --> 00:17:07.040
like some ID, which is a column.

00:17:07.040 --> 00:17:10.740
If you write it back, you want to be able to save it the same order and not have to maintain

00:17:10.740 --> 00:17:12.220
like two data structures or something.

00:17:12.220 --> 00:17:12.780
Yeah.

00:17:12.780 --> 00:17:13.820
Yeah, that's right.

00:17:13.820 --> 00:17:14.180
Exactly.

00:17:14.180 --> 00:17:14.800
Okay.

00:17:14.800 --> 00:17:21.800
So there is right now in all the versions of Python, the collections.order dict, which is

00:17:21.800 --> 00:17:23.560
a specialized dictionary that solves this problem.

00:17:23.560 --> 00:17:29.780
It just so happens if you live right out at the very edge of new Python, you might not need

00:17:29.780 --> 00:17:32.000
that in December, but a lot of people don't live there.

00:17:32.000 --> 00:17:32.580
Right.

00:17:32.580 --> 00:17:34.280
So I think it's still totally relevant.

00:17:34.280 --> 00:17:34.800
Yes.

00:17:34.800 --> 00:17:38.700
And from the discussions that I've been seeing on the Python dev mailing list, it probably

00:17:38.700 --> 00:17:40.300
is going to remain in the library.

00:17:40.300 --> 00:17:46.560
What the latest that I've seen is that the order of keyword arguments in function calls is

00:17:46.560 --> 00:17:48.160
going to be guaranteed to be maintained.

00:17:48.160 --> 00:17:54.660
But the requirement for normal dictionaries to be ordered may not be a specification of the

00:17:54.660 --> 00:17:59.180
language spec, which means that other implementations of Python may not need to maintain that.

00:17:59.180 --> 00:17:59.920
Right.

00:17:59.920 --> 00:18:00.220
Okay.

00:18:00.220 --> 00:18:01.120
So that's quite interesting.

00:18:01.120 --> 00:18:05.180
One of the caveats that I mentioned about order dict towards the end of the section with

00:18:05.180 --> 00:18:10.540
the big red triangle is beware creation with keyword arguments, which is exactly this problem.

00:18:10.540 --> 00:18:15.780
When you create an order dict and you supply keyword arguments as you would with maybe a regular

00:18:15.780 --> 00:18:21.260
dictionary, the problem is that the order is maintained with your specification because the

00:18:21.260 --> 00:18:24.200
keyword arguments first get created as a regular dictionary before they get created as

00:18:24.200 --> 00:18:24.940
an order dictionary.

00:18:25.360 --> 00:18:27.820
And that's going to be changing for sure in 3.6.

00:18:27.820 --> 00:18:28.400
Okay.

00:18:28.400 --> 00:18:29.220
Oh, excellent.

00:18:29.220 --> 00:18:29.800
That's good to know.

00:18:29.800 --> 00:18:30.020
Yeah.

00:18:30.020 --> 00:18:36.180
Because that happens at the call site before the order dict class ever gets any information.

00:18:36.180 --> 00:18:39.420
It's just given a dictionary and it can do what it can do, but it's too late.

00:18:39.420 --> 00:18:41.140
The order has already changed, right?

00:18:41.140 --> 00:18:42.040
Yeah, exactly.

00:18:42.040 --> 00:18:42.600
That's right.

00:18:42.820 --> 00:18:49.060
And I think the other guarantee is that the dunder dict entry in classes is also going

00:18:49.060 --> 00:18:51.500
to have a guarantee of the order being maintained.

00:18:51.500 --> 00:18:56.460
Even though it's implemented as a regular dictionary, what the language spec requires and what actually

00:18:56.460 --> 00:18:58.060
happens in practice are two different things.

00:18:58.060 --> 00:19:03.140
So the developers of Python are trying to maintain the language spec as a spec even for other implementations

00:19:03.140 --> 00:19:08.760
besides CPython, which is difficult to kind of keep in your head when all you work on is CPython,

00:19:08.760 --> 00:19:10.280
which is largely the case for me.

00:19:10.280 --> 00:19:16.120
But yeah, they're dealing with bigger problems than just whatever goes into CPython.

00:19:16.120 --> 00:19:20.140
Yeah, that's an interesting thing to keep in mind because we often just think of CPython

00:19:20.140 --> 00:19:25.460
equals Python language, but there's a lot of other implementations and extensions and forks

00:19:25.460 --> 00:19:25.860
and whatnot.

00:19:26.600 --> 00:19:27.420
Yeah, yeah, exactly.

00:19:27.420 --> 00:19:43.600
Capital One has a special message for you.

00:19:43.600 --> 00:19:46.040
They need Python pros who love to work with data.

00:19:46.040 --> 00:19:50.640
Put your Python experience at work at Capital One and help them use data to make life better

00:19:50.640 --> 00:19:51.740
for millions of customers.

00:19:51.740 --> 00:19:56.580
Capital One is employing the latest tools and approaches to do data analytics and data science

00:19:56.580 --> 00:19:57.680
from the ground up.

00:19:57.680 --> 00:20:01.560
They're smart, creative professionals who love to explore new ways to interact with data.

00:20:01.560 --> 00:20:06.140
They're interested in figuring out novel, advanced Python techniques and even more interested

00:20:06.140 --> 00:20:09.000
in finding more people who will help them do that.

00:20:09.000 --> 00:20:12.500
When you join their state-of-the-art Python community, you'll work with people you really

00:20:12.500 --> 00:20:15.180
like, people who might be listening to this podcast right now.

00:20:15.180 --> 00:20:17.500
Relentless innovation is their way of life.

00:20:17.500 --> 00:20:19.040
Make it yours at Capital One.

00:20:19.040 --> 00:20:24.320
Visit jobs.capitalone.com slash talkpython to learn more and apply today.

00:20:24.320 --> 00:20:34.300
So another one I would say is also one of, if I had to pick the most useful thing to come

00:20:34.300 --> 00:20:38.020
out of the collections library, I would say it's probably named tuple, which you highlight

00:20:38.020 --> 00:20:38.740
in your book as well.

00:20:38.740 --> 00:20:39.500
Yeah, yeah.

00:20:39.500 --> 00:20:40.100
Named tuple.

00:20:40.100 --> 00:20:42.160
Named tuple is kind of interesting.

00:20:42.380 --> 00:20:46.900
I have recently started using it directly when creating tuple structures.

00:20:46.900 --> 00:20:50.940
But most of my experience with named tuple really has been converting old code that used

00:20:50.940 --> 00:20:55.120
regular tuples into using named tuples just to improve the maintainability aspect of that.

00:20:55.120 --> 00:20:57.840
And it is very powerful in that respect.

00:20:58.020 --> 00:21:00.080
Yeah, it doesn't change the performance much.

00:21:00.080 --> 00:21:07.120
And it's an easy thing you can do because named tuples are compatible with the existing code,

00:21:07.120 --> 00:21:09.500
but they definitely add a layer of maintainability, right?

00:21:09.500 --> 00:21:14.720
So if you have a regular tuple and it's three things and you need to put some new item in the

00:21:14.720 --> 00:21:20.480
middle to make it four, well, the code that was going, you know, T bracket two now is not

00:21:20.480 --> 00:21:22.220
true, not accurate anymore, right?

00:21:22.340 --> 00:21:27.320
But if you could refer to them by the names, the property names, that's fantastic, which

00:21:27.320 --> 00:21:28.280
is what named tuples adds.

00:21:28.280 --> 00:21:28.600
Great.

00:21:28.600 --> 00:21:30.460
Yeah, that is a good one.

00:21:30.460 --> 00:21:30.860
Yeah.

00:21:30.860 --> 00:21:33.900
One that I've done a lot less with is Context Lib.

00:21:33.900 --> 00:21:35.080
What's the story of that?

00:21:35.080 --> 00:21:37.900
Ah, so what did you think of my example?

00:21:37.900 --> 00:21:42.660
Just for the listeners, the example that I gave, the code snippet under Context Lib, is

00:21:42.660 --> 00:21:45.880
creating a simple context manager that measures the time.

00:21:45.880 --> 00:21:50.920
Well, it records the time before and after the execution of the body of the context manager

00:21:50.920 --> 00:21:54.340
and then gives you a way to calculate the performance of that section.

00:21:54.340 --> 00:21:58.520
I haven't gotten much feedback about the book yet because it is fairly new and I was curious

00:21:58.520 --> 00:22:00.280
what your opinion was.

00:22:00.280 --> 00:22:06.400
Well, I got to say, it did take me a moment of going back and let me look at this context

00:22:06.400 --> 00:22:07.440
manager implementation.

00:22:07.440 --> 00:22:11.160
It's just only three lines of code.

00:22:11.160 --> 00:22:16.180
I can just, you know, basically the idea is you create a context manager instance by calling

00:22:16.180 --> 00:22:20.620
this method and it will, when it enters, capture the start time.

00:22:20.620 --> 00:22:25.240
When you leave the width block or suite, it captures the end time and then it tells you

00:22:25.240 --> 00:22:26.700
how much time had passed.

00:22:26.700 --> 00:22:29.440
And so the implementation is T equals get the perf counter.

00:22:30.540 --> 00:22:31.900
T zero equals perf counter.

00:22:31.900 --> 00:22:41.860
Yield a lambda, which does a computation and then compute the value that is actually used

00:22:41.860 --> 00:22:42.680
in the lambda above.

00:22:42.680 --> 00:22:46.120
And that, I was a little bit taken aback by that.

00:22:46.120 --> 00:22:46.680
It was interesting.

00:22:46.680 --> 00:22:47.160
Yeah.

00:22:47.160 --> 00:22:50.040
I was worried that it was perhaps a little bit too complex.

00:22:50.040 --> 00:22:53.460
And I didn't want to, the fact that the use of the lambda, I didn't want the use of the

00:22:53.460 --> 00:22:57.640
lambda to overshadow the demonstration of how the context manager works.

00:22:57.640 --> 00:23:03.140
But basically where the yield comes in is where the body of the context manager gets executed.

00:23:03.140 --> 00:23:07.820
And if you return something from the yield, that's pretty much what you get at the end

00:23:07.820 --> 00:23:11.060
of the line when you say with timing as thing.

00:23:11.060 --> 00:23:13.960
The thing is what gets yielded out of the context manager.

00:23:13.960 --> 00:23:19.860
And the little bit of cleverness in this particular example is that the lambda is a closure over

00:23:19.860 --> 00:23:22.400
the namespace inside the timing function.

00:23:22.400 --> 00:23:26.320
So it captures the storage location of T one and T zero.

00:23:26.320 --> 00:23:31.240
So only when you evaluate the lambda later, do the values of T one and T zero actually

00:23:31.240 --> 00:23:31.700
get used.

00:23:31.700 --> 00:23:31.960
Yeah.

00:23:31.960 --> 00:23:33.020
It's quite clever.

00:23:33.020 --> 00:23:33.300
Yeah.

00:23:33.300 --> 00:23:33.880
Yeah.

00:23:33.880 --> 00:23:36.280
This particular example is not imaginary.

00:23:36.280 --> 00:23:37.300
I use it quite a lot.

00:23:37.300 --> 00:23:37.840
Yeah.

00:23:37.840 --> 00:23:38.140
It's nice.

00:23:38.140 --> 00:23:42.240
I appreciated it because it made me think and stop and not just read.

00:23:42.240 --> 00:23:42.440
Yep.

00:23:42.440 --> 00:23:42.720
Okay.

00:23:42.720 --> 00:23:43.020
Yep.

00:23:43.020 --> 00:23:43.320
Okay.

00:23:43.320 --> 00:23:44.200
Oh, wait a minute.

00:23:44.200 --> 00:23:44.900
Not necessarily.

00:23:44.900 --> 00:23:45.260
Okay.

00:23:45.520 --> 00:23:46.240
What's going on?

00:23:46.240 --> 00:23:47.220
And you know, that was cool.

00:23:47.220 --> 00:23:48.980
Like it's nice when code makes you do that.

00:23:48.980 --> 00:23:52.560
If it's not just because you're confused and it's too messy or whatever.

00:23:52.560 --> 00:23:53.180
It's cool.

00:23:53.180 --> 00:23:53.580
Yeah.

00:23:53.580 --> 00:23:59.840
My editor at O'Reilly, Dawn Shanafelt, she was really good about making sure that each of

00:23:59.840 --> 00:24:01.260
these steps were explained in more detail.

00:24:01.260 --> 00:24:03.920
And the editors at O'Reilly are really good.

00:24:03.920 --> 00:24:08.460
They can pick up based on the style of your writing, whether you think you've explained it

00:24:08.460 --> 00:24:09.320
sufficiently or not.

00:24:09.460 --> 00:24:13.980
And they can prod you to say, are you sure you've explained this, but it seems like you

00:24:13.980 --> 00:24:15.940
were a bit terse, perhaps add a few more points.

00:24:15.940 --> 00:24:19.680
So all these bullets and points on the side where everything is spelled out in great detail,

00:24:19.680 --> 00:24:21.260
that wasn't driven by me.

00:24:21.260 --> 00:24:22.400
That was driven by the editors.

00:24:22.400 --> 00:24:24.760
They're really, really good at what they do.

00:24:24.760 --> 00:24:25.320
Yeah.

00:24:25.320 --> 00:24:29.140
You did a good job as a team of breaking down what the steps meant.

00:24:29.140 --> 00:24:29.300
Yeah.

00:24:29.300 --> 00:24:29.640
That's cool.

00:24:29.640 --> 00:24:36.460
So the other thing that you, that was built in was the concurrent.futures module in Python

00:24:36.460 --> 00:24:36.800
3.

00:24:36.800 --> 00:24:43.140
And I thought that was a really interesting way to think about sort of a unifying API between

00:24:43.140 --> 00:24:45.680
process-based parallelism and thread-based parallelism.

00:24:45.680 --> 00:24:46.120
Yeah.

00:24:46.120 --> 00:24:50.560
I wanted to push that point because I think that's, that is the underutilized aspect of

00:24:50.560 --> 00:24:55.080
concurrent on futures is that it gives you this, this really easy lever to switch paradigms.

00:24:55.080 --> 00:24:58.620
For some processes, thread-based programming is valuable.

00:24:58.620 --> 00:25:02.320
And for others, process-based parallelism is, is equally valuable.

00:25:02.320 --> 00:25:05.100
And you get the same interface really just about.

00:25:05.600 --> 00:25:09.440
So you can switch between those two paradigms really quite easily after the fact, which is

00:25:09.440 --> 00:25:09.980
really interesting.

00:25:09.980 --> 00:25:15.200
Usually for complex code involving parallelism, you end up with a structure that is hard to

00:25:15.200 --> 00:25:17.660
change to fit it in a different paradigm unless you do a rewrite.

00:25:17.660 --> 00:25:22.700
And the fact that concurrent.futures gives you the same API for both thread-based work and

00:25:22.700 --> 00:25:25.460
process-based work is a really cool superpower.

00:25:25.880 --> 00:25:26.880
Yeah, it totally is.

00:25:26.880 --> 00:25:32.020
And maybe, you know, it definitely is a simplification because when you start talking about threading,

00:25:32.020 --> 00:25:34.780
there's so many edge cases and interesting variations.

00:25:34.780 --> 00:25:40.720
But maybe the general rule of thumb is if you spend most of your time waiting on the network,

00:25:40.720 --> 00:25:45.880
then thread-based parallelism is probably good, especially if you're sharing a lot of data as

00:25:45.880 --> 00:25:46.100
well.

00:25:46.720 --> 00:25:50.300
And if you're doing a lot of computational stuff because of the GIL and you're not using

00:25:50.300 --> 00:25:54.680
Cython or something, then, you know, you can't really parallelize that very much.

00:25:54.680 --> 00:26:00.180
So multiprocessing and multiple processes for that is maybe a much better way to go.

00:26:00.560 --> 00:26:06.800
But yeah, with the thread pool executor and what was the other one called?

00:26:06.800 --> 00:26:09.540
The process pool executor.

00:26:09.540 --> 00:26:11.900
Those two have exactly the same API.

00:26:11.900 --> 00:26:15.780
And so if you write your code against those instead of directly against multiprocessing and

00:26:15.780 --> 00:26:20.140
directly against the thread API, you literally change your import statement and it changes

00:26:20.140 --> 00:26:23.740
where stuff runs and how, which is pretty cool that you try it out.

00:26:23.740 --> 00:26:25.000
Yeah, that's really good.

00:26:25.000 --> 00:26:30.440
One comment that I also want to make is if I make the choice between whether to use threads

00:26:30.440 --> 00:26:33.540
or whether to use processes, it's not because of the GIL.

00:26:33.540 --> 00:26:38.520
Because as you mentioned, Cython lets you drop the global interpreter lock.

00:26:38.520 --> 00:26:40.620
That's not an issue for me.

00:26:40.620 --> 00:26:46.160
I can write my number crunching code in Cython and use Python's normal threads and still access

00:26:46.160 --> 00:26:46.800
all of the cores.

00:26:46.800 --> 00:26:50.660
The distinction for me between whether to use process-based parallelism or thread-based is

00:26:50.660 --> 00:26:54.360
really about whether I need to use, I need to be able to access the entire memory space

00:26:54.360 --> 00:26:55.180
in the process.

00:26:55.180 --> 00:27:00.160
So that is the main distinction about whether things are okay to be separated by process or whether

00:27:00.160 --> 00:27:05.180
I really need the entire memory space to be accessible by all of the parallel parts of

00:27:05.180 --> 00:27:05.620
execution.

00:27:05.620 --> 00:27:10.860
So if that is the case, for example, if the batch of work that you need to operate on has

00:27:10.860 --> 00:27:15.680
to all fit in the same memory space inside a process and you need to work on different sections

00:27:15.680 --> 00:27:18.080
of memory concurrently, then I would use threads.

00:27:18.080 --> 00:27:23.000
The presence of a global interpreter lock, while it's interesting, is not really a bottleneck

00:27:23.000 --> 00:27:27.400
anymore in CPython because of Cython, because it makes it so easy to drop the GIL.

00:27:27.660 --> 00:27:27.880
Right.

00:27:27.880 --> 00:27:28.200
Awesome.

00:27:28.200 --> 00:27:28.700
Okay.

00:27:28.700 --> 00:27:28.960
Yeah.

00:27:28.960 --> 00:27:30.020
That's a really interesting point.

00:27:30.020 --> 00:27:32.020
And we will definitely be coming back to Cython.

00:27:32.020 --> 00:27:37.640
But if you're working on some data structure that is really large and the threads are updating

00:27:37.640 --> 00:27:41.760
multiple parts of it at the same time, then yeah, you want to keep that in the same process

00:27:41.760 --> 00:27:42.060
space.

00:27:42.060 --> 00:27:43.020
Yeah, absolutely.

00:27:43.020 --> 00:27:46.380
It's really difficult to make that work with process-based parallelism.

00:27:46.680 --> 00:27:50.080
I have been looking at ways of doing that, and I would like to find more about that,

00:27:50.080 --> 00:27:54.740
about using memory mapped files to share memory between processes.

00:27:54.740 --> 00:27:56.540
But I don't have much experience with that yet.

00:27:56.540 --> 00:27:58.560
That's something that I would like to get into more.

00:27:58.560 --> 00:28:00.860
Yeah, that would possibly be a solution.

00:28:00.860 --> 00:28:03.600
But yeah, I don't know what the performance looks like.

00:28:03.600 --> 00:28:04.320
It's interesting.

00:28:04.320 --> 00:28:05.220
Okay.

00:28:05.220 --> 00:28:05.620
Yeah, me neither.

00:28:05.620 --> 00:28:07.060
All right.

00:28:07.400 --> 00:28:09.920
So the next one that was built in was logging.

00:28:09.920 --> 00:28:13.020
You said, you know, look, it's time to get over the print statement.

00:28:13.020 --> 00:28:16.520
If you're trying to actually do debugging stuff, don't just spread it out.

00:28:16.520 --> 00:28:18.880
Like, it's almost the same as you do logging, but you get a lot more.

00:28:18.880 --> 00:28:19.520
Yeah.

00:28:19.520 --> 00:28:23.540
So the experience that I have, this is quite a few years now.

00:28:23.540 --> 00:28:27.800
The experience is I write out a new module or a new script using print statements.

00:28:28.800 --> 00:28:32.980
And a couple of hours later or a couple of days later, it becomes something that I actually want to use and depend on.

00:28:32.980 --> 00:28:36.240
And then I go back through the same code and I change all the print statements to logging statements.

00:28:36.240 --> 00:28:40.880
And yeah, for the last couple of years, I've now just gotten into the habit of just beginning with logging.

00:28:40.880 --> 00:28:48.180
You just put in the boilerplate, the setup line, and then creating your logger, and then you just run with that.

00:28:48.180 --> 00:28:50.000
Yeah, it's pretty straightforward, right?

00:28:50.000 --> 00:28:56.880
You import logging, you call logging.getlogger, and then you can say logger.debug, logger.info, warning.

00:28:57.280 --> 00:28:59.200
And I agree with your sentiment.

00:28:59.200 --> 00:29:08.840
You know, where I find it, I'll be totally happy with print for a while, and then I want to make the code that I was playing with a library and not an application.

00:29:08.840 --> 00:29:09.600
Right.

00:29:09.600 --> 00:29:10.060
Yeah.

00:29:10.060 --> 00:29:14.620
And then all those print statements, it's like super hard to make them go away or to configure them.

00:29:14.620 --> 00:29:15.380
It's just like, ah.

00:29:15.380 --> 00:29:16.840
All right.

00:29:16.840 --> 00:29:17.620
Just a removal.

00:29:17.620 --> 00:29:18.300
Just a removal.

00:29:18.300 --> 00:29:18.700
Yeah.

00:29:18.700 --> 00:29:19.900
So logging, excellent.

00:29:19.900 --> 00:29:25.540
Another one that I really like in this space, although this is the built-in ones, is I really like logbook.

00:29:25.840 --> 00:29:27.720
I think logbook is a nice external one.

00:29:27.720 --> 00:29:30.060
But like you said, having stuff built in is great.

00:29:30.060 --> 00:29:30.340
Okay.

00:29:30.340 --> 00:29:31.620
That's a good tip.

00:29:31.620 --> 00:29:32.720
I didn't know that I'm going to make it.

00:29:32.720 --> 00:29:34.580
Yeah, I think that's Armin Roeniger.

00:29:34.580 --> 00:29:37.460
I can't entirely remember, but I have to look.

00:29:37.460 --> 00:29:38.160
It's really good.

00:29:38.160 --> 00:29:39.240
Okay.

00:29:39.240 --> 00:29:40.320
Let's see.

00:29:40.680 --> 00:29:47.000
So another thing that you might want to do is run something on a scheduled basis, right?

00:29:47.000 --> 00:29:53.680
Like every five minutes, I want to do this thing, or exactly on the hour, I want something to happen.

00:29:53.680 --> 00:29:57.520
And the OSes have built-in ways to do this.

00:29:57.520 --> 00:30:01.360
And I mean, I guess you could like spawn a thread or something to watch.

00:30:01.360 --> 00:30:03.820
But there's some cool stuff built in for that, right?

00:30:03.820 --> 00:30:04.700
Yeah, that's right.

00:30:04.700 --> 00:30:07.820
So you're talking about the shared module, S-C-H-E-D.

00:30:07.820 --> 00:30:12.920
This is a really good example of how you have to be aware of your biases.

00:30:13.360 --> 00:30:17.760
For people who only ever work on POSIX systems or Linux, for example, right?

00:30:17.760 --> 00:30:18.900
Cron is always there.

00:30:18.900 --> 00:30:20.620
It does what it does really well.

00:30:20.620 --> 00:30:23.780
There's a wealth of information available on the internet for how to use Cron.

00:30:23.780 --> 00:30:28.300
So it seems bizarre that there would be this thing in Python that does exactly the same job.

00:30:28.300 --> 00:30:30.760
But the thing is, Cron doesn't run on Windows.

00:30:30.760 --> 00:30:32.060
Windows uses a separate system.

00:30:32.060 --> 00:30:38.160
However, because Python includes the shared module, you can get the same or very similar functionality

00:30:38.160 --> 00:30:41.260
to what you might get in Cron or the Windows task scheduler.

00:30:41.760 --> 00:30:43.680
With a cross-platform Python module.

00:30:43.680 --> 00:30:49.680
And that's really, really powerful if you're writing some service or library that needs to do these jobs on a timer.

00:30:49.680 --> 00:30:52.180
Or at a particular time of the day or so on.

00:30:52.180 --> 00:30:57.060
I look at shared as a really great example of what Python provides in terms of cross-platform support

00:30:57.060 --> 00:31:02.640
for getting this kind of functionality, but in a cross-platform way where you can use the same code base on multiple platforms.

00:31:02.640 --> 00:31:04.180
Yeah, and it's really nice.

00:31:04.180 --> 00:31:09.400
And you basically set up the scheduler and you give it a priority and a frequency.

00:31:09.400 --> 00:31:12.840
And then you say, and call this function whenever it's time.

00:31:12.840 --> 00:31:18.860
And you can do that in either a elapsed time, like 10 minutes from now or every five minutes from now.

00:31:18.860 --> 00:31:19.380
Something like that.

00:31:19.380 --> 00:31:25.160
Or you can do it on a more, like once a minute exactly at the minute.

00:31:25.160 --> 00:31:25.640
Right?

00:31:25.640 --> 00:31:26.380
Yeah.

00:31:26.380 --> 00:31:27.000
Nice.

00:31:27.340 --> 00:31:31.920
Yeah, you can control completely when the target time is, or happens to be.

00:31:31.920 --> 00:31:41.520
I can definitely see Shred becoming a part of the robotization, I guess, of the internet in a big way.

00:31:41.520 --> 00:31:46.760
Automating things and creating bots and timers and work queues and so on.

00:31:46.940 --> 00:31:53.380
Yeah, it's beautiful if you've got some embedded device running your Python code and needs to get home every now and then.

00:31:53.380 --> 00:31:54.200
Just set that up, right?

00:31:54.200 --> 00:31:54.720
Yeah.

00:31:54.720 --> 00:31:55.580
Yeah, absolutely.

00:31:55.580 --> 00:31:56.740
Nice.

00:31:56.740 --> 00:32:00.040
I see we've got to the end of the standard library section.

00:32:00.040 --> 00:32:00.380
We have?

00:32:00.380 --> 00:32:01.100
There was one.

00:32:01.100 --> 00:32:01.640
Yeah.

00:32:01.640 --> 00:32:09.680
There was an additional one that I had in an earlier draft of the book, but we dropped it because it was too short, I guess.

00:32:09.680 --> 00:32:11.400
And that's shlex.

00:32:11.400 --> 00:32:24.740
There's a module called shlex in the standard library, which I wanted to include for no other reason than it has a split function, which will split strings like the normal split, except that it will retain quotes around sections.

00:32:24.740 --> 00:32:32.600
So you can group chunks of words with quotes, just like you might imagine shell processing would process your commands.

00:32:32.600 --> 00:32:35.900
If you put quotes around sections of things, then it treats those as one thing.

00:32:35.900 --> 00:32:40.620
So the shlex module in the standard library has a split function that does that for you as well.

00:32:40.620 --> 00:32:41.700
Oh, nice.

00:32:41.700 --> 00:32:47.380
Yeah, you can almost escape the things you're putting on by putting in quotes.

00:32:47.380 --> 00:32:47.960
Okay.

00:32:47.960 --> 00:32:48.780
Yeah, awesome.

00:32:48.780 --> 00:32:50.960
You don't have to do any quote processing yourself.

00:32:50.960 --> 00:32:52.500
It's already in the standard library.

00:32:52.500 --> 00:32:53.460
Yeah, excellent.

00:32:53.460 --> 00:32:55.580
Okay, very nice.

00:32:55.580 --> 00:33:00.220
So that was sort of the look inside of what's in the box if you just have Python.

00:33:00.220 --> 00:33:05.880
And then you said, all right, let's look outside at external packages and why not start with a better way to install packages?

00:33:05.880 --> 00:33:07.060
Yeah, absolutely.

00:33:07.060 --> 00:33:24.900
So for anyone who doesn't know about Flit and you found that the normal process for creating and publishing a Python package to be arduous, Flit absolutely is the thing that you need to look at because it automates, for simple packages, it automates almost entirely everything that you need to do.

00:33:25.400 --> 00:33:27.520
It's by Thomas Klaver.

00:33:27.520 --> 00:33:30.820
He's very active in the Python scientific community.

00:33:30.820 --> 00:33:33.480
And yeah, I think it's just awesome.

00:33:33.640 --> 00:33:37.100
I'm using Flit at the moment for several of my own smaller projects.

00:33:37.100 --> 00:33:37.760
Yeah, it's cool.

00:33:37.760 --> 00:33:52.100
So if you want to submit something to PyPI, you have to create a setup PY with a lot of various settings, you know, set the license in the right way so people can discover it and who's the author and where's the documentation and what version it is, all those kinds of things.

00:33:53.040 --> 00:34:03.880
And if you install Flit, you can basically say, I'd like to initialize this package and it just lets you, it basically takes you through a Q&A and then it generates the things it needs to upload your package, right?

00:34:03.880 --> 00:34:04.520
That's right.

00:34:04.520 --> 00:34:04.720
Yeah.

00:34:04.720 --> 00:34:05.780
And the Q&A is pretty short.

00:34:05.780 --> 00:34:07.900
I think it's four questions or something like that.

00:34:07.900 --> 00:34:13.240
If you, another good tip is the cookie cutter project by Audrey Roy Greenfeld.

00:34:13.240 --> 00:34:18.420
And there's a cookie cutter project for creating a skeleton for a Python package.

00:34:18.720 --> 00:34:24.120
And it's quite eye-opening when you, when you run the cookie cutter and you see how many files it creates in a folder.

00:34:24.120 --> 00:34:30.480
There's a manifest.in and there are several other extra files that are used just to, just to create and publish your package.

00:34:30.480 --> 00:34:32.360
Whereas Flit does away with all of that.

00:34:32.360 --> 00:34:33.880
You've really just got the Flit.ini.

00:34:33.880 --> 00:34:34.540
Nice.

00:34:34.540 --> 00:34:36.400
And you can get your package on PyPI.

00:34:36.400 --> 00:34:40.420
And it's quite, quite simple stuff in the INI file.

00:34:40.420 --> 00:34:41.740
It's not outrageous, right?

00:34:41.740 --> 00:34:42.600
Yeah, exactly.

00:34:42.600 --> 00:34:43.140
Nice.

00:34:43.140 --> 00:34:48.140
And so then you can say things like Flit wheel upload, and it'll just take whatever active package.

00:34:48.140 --> 00:34:53.680
package you happen to be in with the version specified in the files and just package it up and send it, right?

00:34:53.680 --> 00:34:54.580
Yeah, exactly.

00:34:54.580 --> 00:34:58.180
I haven't tried Flit yet for packages with extensions.

00:34:58.180 --> 00:35:03.360
So, yeah, I don't want to say that it can do that as well, because I just haven't tried that myself.

00:35:03.360 --> 00:35:05.980
But that's something that I do want to dig into as well.

00:35:05.980 --> 00:35:06.620
Yeah, absolutely.

00:35:06.620 --> 00:35:07.020
Okay.

00:35:07.020 --> 00:35:16.140
Well, another thing that is very common is to create some kind of shell utility or app that has some kind of terminal output.

00:35:16.140 --> 00:35:27.000
And there's not a lot of facilities in the standard library for, like, Keller output and nice sort of antsy style graphics, if you will.

00:35:27.140 --> 00:35:31.060
So, one of the things you talked about is Colorama, which I thought was pretty cool.

00:35:31.060 --> 00:35:32.020
I've looked at it a few times.

00:35:32.020 --> 00:35:35.060
Yeah, I feel very strongly about Colorama.

00:35:35.060 --> 00:35:43.500
And the reason is because we, generally speaking, we write software for people, for other people or for ourselves.

00:35:43.500 --> 00:35:46.420
And you see the output from software, particularly in the terminal.

00:35:46.420 --> 00:35:47.840
You have to deal with that a lot.

00:35:47.840 --> 00:35:59.380
And I think that making that output friendlier and easy to read and easy to understand context, but, for example, by using green for good and red for bad, makes it a lot easier to use programs, really.

00:35:59.380 --> 00:36:08.360
If we have to write software that works in the terminal as opposed to writing graphical user interfaces, there's no reason why we can't make that output appear better.

00:36:08.360 --> 00:36:15.340
The prompt toolkit is another good library for making interactive user interfaces in the terminal.

00:36:15.960 --> 00:36:22.440
And I didn't cover that in the book, but I think later we come to the PT Python interpreter, alternative interpreter.

00:36:22.440 --> 00:36:23.500
So, we'll get to that later.

00:36:23.500 --> 00:36:24.980
But that is part of this.

00:36:24.980 --> 00:36:30.240
The use of color, I strongly believe, can help to make better user interfaces on the command line.

00:36:30.240 --> 00:36:31.360
Oh, I totally agree with you.

00:36:31.360 --> 00:36:31.720
Yeah.

00:36:31.720 --> 00:36:32.400
Yeah.

00:36:32.400 --> 00:36:37.060
What makes Colorama so great is that they completely abstract away, again, platform differences.

00:36:37.060 --> 00:36:45.340
So, your code that uses Colorama will use the correct antsy codes in a bash shell, but when you're writing it in a Windows command prompt,

00:36:45.580 --> 00:36:47.640
it will also use the correct color codes for that environment.

00:36:47.640 --> 00:36:49.500
So, I think that's really powerful.

00:36:49.500 --> 00:36:52.220
You're not really committing to a particular platform by using Colorama.

00:36:52.220 --> 00:36:59.020
And it is a well-maintained package that I think support goes back to 2.64 and they include 3.5 as well.

00:36:59.020 --> 00:36:59.440
Nice.

00:36:59.440 --> 00:37:05.660
And you said also that you recommended Color Log as a way to add coloring to your log messages.

00:37:05.660 --> 00:37:08.680
So, like, warning is one color, error is another, and so on.

00:37:09.200 --> 00:37:10.080
Yeah, exactly.

00:37:10.080 --> 00:37:16.260
And it's two or three lines, and you get that functionality, and all your existing logging messages will just get those colors.

00:37:16.260 --> 00:37:23.020
It's a really easy drop-in replacement just to make sure that you have colorization for all the different logging levels of your logging messages.

00:37:23.020 --> 00:37:24.360
Yeah, I think it's great.

00:37:24.360 --> 00:37:26.560
You see something red go by, you know, obviously.

00:37:26.560 --> 00:37:27.720
Pay attention, right?

00:37:27.720 --> 00:37:28.440
It's great.

00:37:28.600 --> 00:37:29.340
Exactly, yeah.

00:37:29.340 --> 00:37:31.140
Or bold red, I see, for critical.

00:37:31.140 --> 00:37:33.360
Yeah, absolutely.

00:37:33.360 --> 00:37:41.180
So, another thing that you talked about on the terminal, the CLI, is accepting arguments.

00:37:41.180 --> 00:37:46.280
So, built-in, we have argpars, but there's maybe some better ways.

00:37:46.280 --> 00:37:48.780
And one of the ways you recommended was the Begins library.

00:37:48.780 --> 00:37:49.340
Yeah.

00:37:49.660 --> 00:37:50.220
What's Begins?

00:37:50.220 --> 00:37:54.780
Begins is a library that I first heard about at PyCon Australia in 2014.

00:37:54.780 --> 00:37:59.520
The author, Aaron Isles, gave a very strong demonstration of Begins.

00:37:59.520 --> 00:38:08.020
And it struck me at that time how much you can really do with Python if you exploit all the features of the language that are available to you.

00:38:08.360 --> 00:38:19.100
So, the point that I made in the book was that Begins, just from the perspective of an API design, is extremely aggressive with exploiting everything that Python provides to you.

00:38:19.100 --> 00:38:30.160
And, for example, the annotation, the variable annotation format in the function definitions, Begins uses those annotations for the docstrings of each of your parameters so that you don't have to add that anywhere else.

00:38:30.540 --> 00:38:38.560
And I really like the way the Begins API was designed to give you as much functionality as possible for as little input from you.

00:38:38.560 --> 00:38:40.340
I like that trade-off very much.

00:38:40.340 --> 00:38:41.060
Yeah.

00:38:41.060 --> 00:38:41.740
It's really nice.

00:38:41.740 --> 00:38:51.600
What I have heard from many people, though, is that they much prefer a slightly more rigorous specification format like what you can get now in the click library.

00:38:52.520 --> 00:39:00.520
And docopt also gets a lot of love, which is another way of creating your command line interface by, not docopt, I forget the name now.

00:39:00.520 --> 00:39:07.220
But there's another library where you can write out the help message of your CLI tool.

00:39:07.220 --> 00:39:07.600
Yeah.

00:39:07.600 --> 00:39:08.780
And it'll do it in reverse.

00:39:08.780 --> 00:39:10.420
It's basically the reverse of Begins.

00:39:10.420 --> 00:39:11.440
I think that is docopt.

00:39:11.440 --> 00:39:12.040
Yeah.

00:39:12.040 --> 00:39:12.720
Oh, okay.

00:39:12.720 --> 00:39:13.320
It is docopt.

00:39:13.320 --> 00:39:13.560
Yeah.

00:39:13.560 --> 00:39:15.280
So, it's the reverse of Begins.

00:39:15.280 --> 00:39:20.500
You write out your help message that will be printed when the user types help, and then it infers what all your parameters are.

00:39:20.920 --> 00:39:22.180
That is also fairly popular.

00:39:22.180 --> 00:39:27.760
Even so, I have found that for my own small scripts, Begins gets me going much, much faster.

00:39:27.760 --> 00:39:32.500
And even subcommands are very, very easy to enable.

00:39:32.500 --> 00:39:32.920
Right.

00:39:32.920 --> 00:39:34.200
So, basically, you have some method.

00:39:34.200 --> 00:39:36.400
You want to give some kind of CLI to it.

00:39:36.400 --> 00:39:41.200
It takes some parameters, and you just give it a decorator or a subcommand decorator.

00:39:41.200 --> 00:39:44.660
And now it is accessible, and it's part of the help text and all that.

00:39:44.660 --> 00:39:45.420
That's correct.

00:39:45.420 --> 00:39:45.660
Yeah.

00:39:45.660 --> 00:39:45.960
Yeah.

00:39:45.960 --> 00:39:46.380
Excellent.

00:39:46.380 --> 00:40:06.540
We all love Python for its tremendous productivity benefits, but getting the best performance takes some work.

00:40:06.540 --> 00:40:10.680
What if you could get out-of-the-box, easy access to high-performance Python?

00:40:11.380 --> 00:40:14.320
Intel distribution for Python developers delivers just that.

00:40:14.320 --> 00:40:28.280
Get close to 100 times better performance for certain functions when using NumPy, SciPy, scikit-learn, linked with optimized native libraries like Intel Math Kernel Library, access efficient multi-threading, and Python projects like Numba and Scithon.

00:40:28.640 --> 00:40:34.880
Try the Intel distribution for Python and experience performance today at talkpython.fm/Intel.

00:40:34.880 --> 00:40:42.440
And profile your Python and native C, C++ applications for performance hotspots with Intel VTune amplifier.

00:40:42.440 --> 00:40:44.840
With Intel, it's all about performance.

00:40:52.780 --> 00:40:53.400
All right.

00:40:53.400 --> 00:40:53.420
All right.

00:40:53.420 --> 00:40:57.460
So let's move into the GUIs, the graphical interfaces.

00:40:57.460 --> 00:41:05.420
And one of the first things that you talked about is creating interactive, dynamic graphs and things like that.

00:41:05.420 --> 00:41:12.080
And while Matplotlib plays a big role there, you also talked about PyQT graph.

00:41:12.080 --> 00:41:14.600
Why did you pick that over, say, Matplotlib?

00:41:14.600 --> 00:41:20.420
The primary reason why I have selected PyQT graph over Matplotlib is for interactivity.

00:41:20.420 --> 00:41:27.360
It's hard to imagine that you could have a highly performant charting library for Python, but that is exactly what PyQT graph is.

00:41:27.360 --> 00:41:31.260
It's based on QT as the widget toolkit that runs in the back end.

00:41:31.260 --> 00:41:34.140
But the interactivity is really good.

00:41:34.140 --> 00:41:39.440
You can have graphs that draw spectra running at 50 frames a second quite easily.

00:41:39.440 --> 00:41:42.800
And you can drag and zoom and pan all the while the animation is happening.

00:41:43.600 --> 00:41:48.220
So you could have a data stream where you're plotting the data as it comes through live.

00:41:48.220 --> 00:41:48.860
Oh, wow.

00:41:48.860 --> 00:41:51.980
Whereas with Matplotlib, that degree of interactivity is not really there.

00:41:51.980 --> 00:41:52.680
I see.

00:41:52.680 --> 00:41:54.800
It's not because of a lack of ability.

00:41:54.800 --> 00:42:04.780
It's because Matplotlib has been designed towards producing publication-ready type charts in a similar way to what Matlab's charting facilities were designed.

00:42:04.780 --> 00:42:09.080
Whereas PyQT graph has been approached with a whole different use case in mind.

00:42:09.440 --> 00:42:21.780
So in my chemical engineering work, PyQT graph has been very valuable for me to be able to plot live data and then examine it in real time, pan and zoom and move my moving data sets around.

00:42:21.780 --> 00:42:22.420
That's awesome.

00:42:22.660 --> 00:42:27.660
Yeah, if that was all that PyQT graph provided, that would already be enough.

00:42:27.660 --> 00:42:29.800
And that was my largest use case for it.

00:42:29.800 --> 00:42:39.900
But it has a fairly feature-complete widget library in the background that lets you plot, not plot, but create widgets on the fly for arbitrary Python data structures.

00:42:40.280 --> 00:42:44.500
So you can get input cells and sliders and so on that can manipulate your data.

00:42:44.500 --> 00:42:47.100
And PyQT graph provides all of that as well.

00:42:47.100 --> 00:42:47.920
Yeah, that's excellent.

00:42:47.920 --> 00:42:52.720
Yeah, if you want to embed some kind of like live data thing into your app, it sounds really cool for that.

00:42:52.720 --> 00:42:54.280
Yeah, it definitely is a good choice.

00:42:54.280 --> 00:42:58.780
And especially if you're already using PyQT, PyQT graph is a drop-in replacement.

00:42:58.780 --> 00:42:59.360
Yeah.

00:42:59.520 --> 00:43:03.680
You can add its chart windows as a widget inside your existing PyQT app.

00:43:03.680 --> 00:43:04.520
Yeah, that's really great.

00:43:04.520 --> 00:43:12.740
And there's a lot of interesting talk around PySide coming back to the same company that does Qt.

00:43:12.740 --> 00:43:18.840
And that's, yeah, it sounds like it's going to be a real, like this is a vibrant growing area.

00:43:18.840 --> 00:43:19.400
So that's great.

00:43:19.400 --> 00:43:22.340
Yeah, I've got my eye on the resurgence of PySide as well.

00:43:22.340 --> 00:43:23.300
Yeah, cool.

00:43:23.300 --> 00:43:25.360
Yeah, I'm totally, totally excited for that.

00:43:25.980 --> 00:43:32.720
So then the next thing that you talked about was one way to build your apps is using these graphical frameworks.

00:43:32.720 --> 00:43:38.780
But a very popular one, even using CSS front-end frameworks like Bootstrap and stuff, is web development.

00:43:38.780 --> 00:43:45.720
So there's another interesting library that lets you have Python logic in a desktop application,

00:43:45.720 --> 00:43:48.880
but actually presents the user interface through a GUI.

00:43:48.880 --> 00:43:50.020
You want to tell us about that?

00:43:50.020 --> 00:43:55.720
Yeah, so I also included PyWebView, which is something that I found while doing the research for the book.

00:43:55.720 --> 00:43:57.620
It's not something that I had used before.

00:43:57.620 --> 00:44:03.360
But I was blown away at how such a powerful tool exists, and it could not be better known.

00:44:03.360 --> 00:44:07.980
Most people know about the Electron framework and the Chrome-embreaded framework,

00:44:07.980 --> 00:44:14.260
which can also make these desktop apps that rely on the WebKit engine to provide the visualization layer.

00:44:14.260 --> 00:44:20.380
The interesting thing about PyWebView is that it doesn't require you to bundle something like Electron with your app.

00:44:20.380 --> 00:44:22.180
It just uses the native browser.

00:44:22.180 --> 00:44:22.740
I see.

00:44:22.740 --> 00:44:23.700
Which is really amazing.

00:44:23.700 --> 00:44:24.360
That is amazing.

00:44:24.360 --> 00:44:25.380
Is it cross-platform?

00:44:25.460 --> 00:44:26.800
Yeah, it's cross-platform.

00:44:26.800 --> 00:44:35.000
So it will use Internet Explorer or Edge on Windows, and it'll use the WebView widget on OSX, which is what powers Safari,

00:44:35.000 --> 00:44:37.680
and then on Linux it will use whatever is native there.

00:44:37.680 --> 00:44:38.160
Interesting.

00:44:38.160 --> 00:44:42.360
Yeah, I may be pushing up to the edge of the things I've actually played with.

00:44:42.360 --> 00:44:52.580
But the Electron stuff, in order to implement that and put the logic in it, that's JavaScript, right?

00:44:52.660 --> 00:44:53.200
Correct.

00:44:53.200 --> 00:44:56.580
So if you want to have, well, no, not necessarily.

00:44:56.580 --> 00:45:08.100
So if you just imagine a normal web application where you have your front-end layer that runs what we would say as in the browser with your CSS and your HTML and your JavaScript,

00:45:08.100 --> 00:45:15.160
and then you have your back-end layer, which provides an API that receives REST calls or whatever, which we would typically write in Python.

00:45:15.620 --> 00:45:19.260
You do exactly the same thing, but you just package it in one bundle as a desktop application.

00:45:19.260 --> 00:45:19.620
Nice.

00:45:19.880 --> 00:45:29.440
So from the perspective of the viewer, with PyWebView in particular, you don't really know that you're in a browser because you don't have all the same features and trimmings and buttons and menus that you get in a browser.

00:45:29.440 --> 00:45:33.800
All you really get is the WebView window, and then you get to put in there whatever you want.

00:45:33.800 --> 00:45:35.820
But you can power that with all these same technologies.

00:45:35.820 --> 00:45:42.060
So you can specify the layout of your screen using HTML and style it with CSS.

00:45:42.060 --> 00:45:49.980
And if you want some interactivity in the graphical layer itself, then you would have to write that with JavaScript as you would with a normal web application.

00:45:49.980 --> 00:46:01.060
But your Python, that can provide much of the logic and back-end processing of what your use interface is advertising, can also run alongside that application on your desktop.

00:46:01.060 --> 00:46:07.100
So from the perspective of a user of such an application, they would be oblivious to the fact that Python was being used at all.

00:46:07.100 --> 00:46:08.280
Yeah, it looks really interesting.

00:46:08.760 --> 00:46:13.400
And I kind of prefer CSS and HTML for GUI design.

00:46:13.400 --> 00:46:15.940
So I may have to try this out.

00:46:15.940 --> 00:46:17.180
Definitely worth looking into.

00:46:17.180 --> 00:46:18.940
I definitely recommend it.

00:46:18.940 --> 00:46:29.140
In the example that I used, I also used another Python library called Dominate, which allows you to create the HTML DOM and structures within the DOM directly from inside Python code.

00:46:29.140 --> 00:46:32.060
But that was just me being too cute, I guess.

00:46:32.060 --> 00:46:32.680
Just because you can.

00:46:32.680 --> 00:46:33.040
You can also.

00:46:33.040 --> 00:46:34.320
Yeah, exactly.

00:46:34.520 --> 00:46:38.080
You can just write your HTML and CSS out as you normally wouldn't load that.

00:46:38.080 --> 00:46:38.940
And that works fine.

00:46:38.940 --> 00:46:39.200
Right.

00:46:39.200 --> 00:46:40.160
So you would.

00:46:40.160 --> 00:46:47.320
Could you do something like have like a Chameleon or Jinja 2 template and something like that and pull that in?

00:46:47.320 --> 00:46:48.060
Yeah, absolutely.

00:46:48.060 --> 00:46:48.720
Okay.

00:46:48.720 --> 00:46:49.300
Definitely.

00:46:49.300 --> 00:46:49.960
No question.

00:46:49.960 --> 00:46:59.680
And the big benefit of PyWebView over using Electron is, again, that you don't have to distribute a fairly large browser engine alongside your app.

00:46:59.680 --> 00:47:00.300
Yeah.

00:47:00.740 --> 00:47:01.100
Excellent.

00:47:01.100 --> 00:47:10.860
If you can find a way to bundle just the Python parts of your app, when you run it, it will use the native web widget of your target operating system.

00:47:10.860 --> 00:47:11.480
Excellent.

00:47:11.480 --> 00:47:11.820
Okay.

00:47:12.900 --> 00:47:13.900
I really like that one.

00:47:13.900 --> 00:47:16.060
And I definitely want to have a look at it as well.

00:47:16.060 --> 00:47:21.200
So moving on to sort of the systems management, system tool stuff.

00:47:21.200 --> 00:47:27.920
The first one you brought up was an example of something I was trying to do in one of my online classes that I was building.

00:47:27.920 --> 00:47:33.940
And I'm like, oh, why is this so hard in the built-in process stuff?

00:47:34.060 --> 00:47:36.620
And that's about managing processes with PSUtil.

00:47:36.620 --> 00:47:37.360
Yeah.

00:47:37.360 --> 00:47:46.740
So worry no more because there's a library called PSUtil that does everything you could possibly want in terms of accessing information about the system and more.

00:47:47.140 --> 00:48:03.060
I have a feeling that PSUtil is going to be bad for the business for many monitoring companies, server monitoring frameworks, because it's so easy to run PSUtil in a daemon on your server and get it to send information back to you about which process is consuming how much memory.

00:48:03.380 --> 00:48:14.060
If your particular application is misbehaving in some way or if the system itself has started to change how it is supposed to be operating, PSUtil makes all of that really easy.

00:48:14.060 --> 00:48:21.580
I reckon in a day or two, you could probably whip something up that can give you as good performance monitoring as what you could get from a cloud provider currently.

00:48:21.580 --> 00:48:22.140
Okay.

00:48:22.140 --> 00:48:22.540
Wow.

00:48:22.540 --> 00:48:23.280
Yeah.

00:48:23.280 --> 00:48:27.240
You can ask for things like, what's the CPU percent on the system?

00:48:27.240 --> 00:48:31.920
And if you have like eight cores, it'll give you an array of eight floating point numbers that are percents.

00:48:32.040 --> 00:48:34.720
And you can say, what is the current process that I'm in?

00:48:34.720 --> 00:48:35.880
How much memory is it using?

00:48:35.880 --> 00:48:36.760
And things like that.

00:48:36.760 --> 00:48:37.240
It's great.

00:48:37.240 --> 00:48:37.760
Yeah.

00:48:37.760 --> 00:48:40.760
And you can access all the other processes as well.

00:48:40.760 --> 00:48:44.960
You can get similar information from all of them, from everything that's operating on your system.

00:48:44.960 --> 00:48:45.700
Yeah.

00:48:45.700 --> 00:48:46.220
Nice.

00:48:46.220 --> 00:48:50.200
So that was for watching processes and system stuff.

00:48:50.200 --> 00:48:56.660
Another thing that people often have to do is they have to watch a directory for when a file either changes or a new file arrives.

00:48:56.660 --> 00:48:59.360
Like somebody's uploaded some new CSV file.

00:48:59.360 --> 00:49:01.900
We've got to ingest it and do work on that.

00:49:01.900 --> 00:49:05.040
And you talked about a thing called a watchdog for that.

00:49:05.040 --> 00:49:05.700
Yeah.

00:49:05.700 --> 00:49:06.800
Have you used that before?

00:49:06.800 --> 00:49:08.440
I've not, but it sounds really cool.

00:49:08.440 --> 00:49:15.320
And like the others you brought up, it's very nice that it's cross-platform, even though that implementation is quite different on the different OSs.

00:49:15.320 --> 00:49:16.180
Yeah, that's right.

00:49:16.180 --> 00:49:23.460
And just like psutil, it abstracts away some fairly complex work into a very nice, very easy to use API.

00:49:23.460 --> 00:49:25.100
That is, again, cross-platform.

00:49:25.100 --> 00:49:35.840
One of my requirements for selection in the book throughout is that every library had to work in a fairly easy way on all the three big target platforms.

00:49:35.840 --> 00:49:38.280
So they should all be cross-platform.

00:49:38.860 --> 00:49:48.280
And watchdog probably does the best job of hiding platform differences away because these notification systems are quite different on each of the target platforms.

00:49:48.280 --> 00:49:51.220
And luckily, you don't have to worry about that whatsoever.

00:49:51.220 --> 00:49:53.100
It completely hides away those differences.

00:49:53.100 --> 00:49:57.500
And as you said, it gives you a way to monitor a particular directory for any changes.

00:49:57.500 --> 00:49:58.400
Yeah, it's really nice.

00:49:58.400 --> 00:50:03.680
So you just create a class driving from some built-in monitor event handler type of thing.

00:50:03.680 --> 00:50:08.860
And you say, call this function when you create one or call this one when a function is modified.

00:50:08.860 --> 00:50:11.280
And then you can just tell it to start observing.

00:50:11.280 --> 00:50:14.140
And it actually does that in the background on a background thread, right?

00:50:14.140 --> 00:50:14.840
Yeah, that's right.

00:50:14.840 --> 00:50:15.740
Yeah, very cool.

00:50:15.740 --> 00:50:23.160
So the other one you talked about, you alluded to before, is ptpython.

00:50:23.420 --> 00:50:26.620
Which I've not played with this, but I'm thinking this is getting installed.

00:50:26.620 --> 00:50:31.220
Because this is, I really don't love the REPL that much, the built-in one.

00:50:31.220 --> 00:50:32.160
But this is cool.

00:50:32.160 --> 00:50:33.080
I need to check this out.

00:50:33.080 --> 00:50:34.020
So tell us about it.

00:50:34.020 --> 00:50:44.580
Yeah, so ptpython is based on another Python library called Prompt Toolkit, which is a toolkit for making user interfaces in the shell or in a command line view.

00:50:45.660 --> 00:50:55.800
And ptpython is a replacement Python interpreter, but it's supercharged for editing and editing history and bringing back previous functions and changing them.

00:50:55.800 --> 00:51:02.220
And it has color support and a whole bunch of other features as well, which I could not get to in the discussion.

00:51:02.220 --> 00:51:08.100
I pretty much the first thing that I install after updating PEP and setup tools in a new virtual env is ptpython.

00:51:08.100 --> 00:51:12.700
And that's the interpreter that I use for doing any of that interactive kind of work.

00:51:12.700 --> 00:51:13.960
Yeah, it makes a ton of sense.

00:51:13.960 --> 00:51:22.560
Like, for example, if you, one of the things that drives me crazy in the REPL is I'll type out like a function or an if statement or a loop more likely.

00:51:22.560 --> 00:51:27.020
And then I'll either make a mistake or I want to run it again slightly differently.

00:51:27.020 --> 00:51:28.860
And then you've got to up arrow.

00:51:28.860 --> 00:51:35.320
Like, okay, I know I'm going to up arrow five times and hit enter and then like sort of unroll the history so I can get back.

00:51:35.320 --> 00:51:36.720
And then I got to remember the line I changed.

00:51:36.720 --> 00:51:40.860
And like this one, if you say, I want to go back to some multi-line thing I worked on,

00:51:40.860 --> 00:51:46.020
it actually pulls up the multi-line thing right there, which is already makes it worthwhile.

00:51:46.020 --> 00:51:49.120
Plus the color and the auto-completion and all that.

00:51:49.120 --> 00:51:49.460
That's great.

00:51:49.460 --> 00:51:50.180
Yeah, that's right.

00:51:50.180 --> 00:51:53.900
And so when you press up arrow and you get that multi-line statement that you did earlier,

00:51:53.900 --> 00:51:56.020
I use the VI key bindings.

00:51:56.020 --> 00:51:57.340
And that all works.

00:51:57.340 --> 00:51:58.840
I can go to the top of the line, go down.

00:51:58.840 --> 00:52:01.460
I can DD to delete a line or yank and paste.

00:52:02.580 --> 00:52:05.840
So if you're used to Emacs, they have Emacs key binding support.

00:52:05.840 --> 00:52:08.360
And if you're used to VI, you can enable VI key binding support.

00:52:08.360 --> 00:52:18.400
And you get the power or much of the power of those keystrokes and commands inside every single line that you edit and enter inside PtPython.

00:52:18.400 --> 00:52:21.160
Which is so much better than the built-in.

00:52:21.160 --> 00:52:22.920
Yeah, that's fantastic.

00:52:22.920 --> 00:52:28.980
If you run in a split screen in your terminal where you have, for example, your editor in the top half and a command line on the bottom half.

00:52:28.980 --> 00:52:34.900
If you run PtPython in the bottom half, what's really interesting is if the key bindings match the editor that you're using,

00:52:34.900 --> 00:52:40.420
you almost begin to feel like you're working in one environment because the key bindings work in your editor.

00:52:40.420 --> 00:52:43.880
And then when you jump to the REPL, it works there as well the same way.

00:52:43.880 --> 00:52:44.940
So that's really nice.

00:52:44.940 --> 00:52:46.900
I work like that almost continuously.

00:52:46.900 --> 00:52:48.000
Oh, that's really nice.

00:52:48.600 --> 00:52:49.300
Yeah, I like it.

00:52:49.300 --> 00:52:50.840
I'm definitely going to install it and check it out.

00:52:50.840 --> 00:52:58.920
The next thing is moving on to the web APIs and HTTP services and so on is something I had not heard of,

00:52:58.920 --> 00:53:00.820
but it's very nice.

00:53:00.820 --> 00:53:02.920
It's called Hug for building APIs.

00:53:02.920 --> 00:53:03.560
Yeah.

00:53:03.560 --> 00:53:12.100
So just like we discussed earlier with Begins, what I really, really liked about Hug is how they try to maximally exploit the features of Python

00:53:12.100 --> 00:53:17.380
to make as simple as possible use interface for you as a programmer to implement an API.

00:53:17.760 --> 00:53:28.200
I have had experience before with the Django REST framework, which is an awesome industrial strength, very well designed, very sturdy and robust REST framework.

00:53:28.200 --> 00:53:30.020
So I recommend that one strongly.

00:53:30.020 --> 00:53:32.160
Flask also has a good REST framework.

00:53:32.160 --> 00:53:33.960
Those are not bad choices at all.

00:53:33.960 --> 00:53:37.540
But I did have the impression that very few people knew about Hug.

00:53:37.880 --> 00:53:43.880
And for simpler kinds of applications, I think Hug makes it extremely easy to get a REST interface up.

00:53:43.880 --> 00:53:44.300
Yeah.

00:53:44.300 --> 00:53:47.880
And it's very service oriented, right?

00:53:47.880 --> 00:53:56.380
It's not looking like some web framework that also happens to allow machines to talk to it and return JSON.

00:53:56.940 --> 00:54:08.900
Like, for example, to take a function and make it a return JavaScript for get requests, you just say at Hug.get and you give it that decorator or a post or whatever, right?

00:54:08.900 --> 00:54:11.100
And you make it a API.

00:54:11.600 --> 00:54:12.100
Yeah, exactly.

00:54:12.100 --> 00:54:13.260
And you're done pretty much.

00:54:13.260 --> 00:54:17.040
And you get the documentation because it auto generates that from your function declarations.

00:54:17.040 --> 00:54:22.020
And versioning is also pretty easy to add, which I had in the later section.

00:54:22.320 --> 00:54:22.540
Yeah.

00:54:22.540 --> 00:54:35.660
So basically, if you make a request to the base URL for the host that's running the Hug service, it will actually describe all the services and how you talk to them and what's the inputs, the outputs, everything.

00:54:35.660 --> 00:54:37.820
And like you said, you can put versioning on it.

00:54:37.820 --> 00:54:47.080
So basically, you don't have to go and change everything about your methods and try to somehow bolt versioning on.

00:54:47.080 --> 00:54:50.580
You can just say in your decorator, this is for version two of the API.

00:54:51.020 --> 00:54:55.340
It also does argument conversion and stuff like that, right?

00:54:55.340 --> 00:54:56.080
That's right.

00:54:56.080 --> 00:54:56.300
Yeah.

00:54:56.300 --> 00:54:56.900
Nice.

00:54:56.900 --> 00:54:57.840
So, cool.

00:54:57.840 --> 00:55:00.180
It helps in the documentation, I guess, as well.

00:55:00.180 --> 00:55:04.820
If you say, here's an integer and its name is this, like the documentation can say, hey, it takes an integer called this.

00:55:04.820 --> 00:55:05.580
Nice.

00:55:05.580 --> 00:55:06.300
Yeah.

00:55:06.300 --> 00:55:07.140
Yeah, absolutely.

00:55:07.140 --> 00:55:12.520
Documentation, particularly for things like this, it's really a pain to write by hand.

00:55:12.520 --> 00:55:14.040
And no one should ever do that.

00:55:14.040 --> 00:55:20.340
Definitely, you want to use a tool that makes it really easy to produce documentation and to keep the documentation up to date.

00:55:20.660 --> 00:55:21.560
That's the key part, right?

00:55:21.560 --> 00:55:25.300
Keep it up to date because it's easy to create it and then just leave it.

00:55:25.300 --> 00:55:26.580
You know what?

00:55:26.580 --> 00:55:28.020
Well, I guess that changed.

00:55:28.020 --> 00:55:28.180
Yeah.

00:55:28.180 --> 00:55:30.040
Sorry, that documentation was wrong.

00:55:30.040 --> 00:55:30.660
Yeah.

00:55:30.660 --> 00:55:32.160
Nice.

00:55:32.160 --> 00:55:32.420
Okay.

00:55:32.420 --> 00:55:40.400
So, one of the things that's pretty challenging, I think, let me rephrase that, is more challenging than I think it should be, is working with dates in Python.

00:55:40.400 --> 00:55:44.000
And so, you have some cool libraries to work with that that you've found.

00:55:44.000 --> 00:55:44.740
That's right.

00:55:44.880 --> 00:55:48.800
So, the first option that I had there is not that unknown, I guess.

00:55:48.800 --> 00:55:53.880
Many people who have had to deal with dates and times have used Arrow for several years now.

00:55:53.880 --> 00:56:03.600
And the key thing about Arrow, or at least the key thing for me, I guess, is that it does away with this idea of having naive date times and so-called aware date times.

00:56:03.960 --> 00:56:08.740
Aware date times are date time objects that carry with them the time zone that they apply to.

00:56:08.740 --> 00:56:13.260
And naive date time objects do not have the time zone information attached.

00:56:13.260 --> 00:56:19.120
And, yeah, things get really out of hand if you start mixing and matching those without an awareness of what you're doing.

00:56:19.680 --> 00:56:31.060
And just by using Arrow, because it uses aware date time objects everywhere, simply by using Arrow, it means that you can avoid a certain class of problems where you're mixing up dates and times incorrectly.

00:56:31.060 --> 00:56:32.520
Yeah, and you run into weird problems.

00:56:32.520 --> 00:56:37.860
Like, if you try to subtract two date times, normally you get a time delta.

00:56:37.860 --> 00:56:42.540
But if one of them is time zone aware and one's not, then it will crash, right?

00:56:42.540 --> 00:56:43.700
So, no, you can't subtract these.

00:56:43.700 --> 00:56:45.160
Yeah, that's right.

00:56:45.460 --> 00:56:52.600
And worse is when you don't get crashes and you do arithmetic operations and the results that you're getting are not what you think you're getting.

00:56:52.600 --> 00:56:56.660
For example, in one part of your code base, you might call the now function.

00:56:56.660 --> 00:56:59.280
So, daytime.now, and then you get a time object.

00:56:59.280 --> 00:57:04.560
And in a different part of your code base, you call a very similarly named function called UTCnow.

00:57:04.560 --> 00:57:12.020
The problem is that the one gives you the time as it is in the UTC time zone, but without a time zone object attached.

00:57:12.680 --> 00:57:15.800
And the first one gives you the time as it is now, but in your local time zone.

00:57:15.800 --> 00:57:24.740
And the problem is that as a programmer, depending on the context of the code, you may perceive those two values to mean literally this moment in time right now.

00:57:24.740 --> 00:57:26.460
But the values are vastly different.

00:57:26.460 --> 00:57:29.140
They're obviously different by the extent of the times and differences.

00:57:29.140 --> 00:57:32.760
And so, when you do operations on them, you get very strange results.

00:57:32.760 --> 00:57:37.600
Or results that seem strange to you because of the assumptions you've made about what now actually means.

00:57:37.600 --> 00:57:38.500
Right.

00:57:38.580 --> 00:57:41.640
So, by using aware datetimes, you don't have those problems anymore.

00:57:41.640 --> 00:57:45.980
The time deltas that you obtain by doing operations between these are always correct.

00:57:45.980 --> 00:57:46.520
Yeah.

00:57:46.520 --> 00:57:57.560
So, even if one is from .now and others .utcnow, it knows to normalize those to some common time zone before it does math.

00:57:57.560 --> 00:57:58.060
Right?

00:57:58.060 --> 00:58:05.360
Like, if it wants to look how far apart they are, I would say, no, those are actually, you know, either the same or like one millisecond apart or something like that.

00:58:05.360 --> 00:58:06.280
Yeah, absolutely.

00:58:06.280 --> 00:58:07.000
Nice.

00:58:07.000 --> 00:58:10.320
So, that's coming from the universe into now.

00:58:10.320 --> 00:58:15.320
Into, you know, bringing in the time and working with it.

00:58:15.320 --> 00:58:22.640
The next library you talked about is about pulling time that's been saved already into a bunch of different formats and processing that.

00:58:22.640 --> 00:58:25.000
Because parsing time can be super challenging.

00:58:25.000 --> 00:58:27.940
I was talking on the previous episode with Anna Schneider.

00:58:28.060 --> 00:58:31.340
They were pulling together data sources from all these different utilities.

00:58:31.340 --> 00:58:35.180
And they said they have many, many different formats for time.

00:58:35.180 --> 00:58:38.340
That there are over 700 different formats for time out there.

00:58:38.340 --> 00:58:41.640
So, trying to just like deal with all that stuff is super painful.

00:58:41.640 --> 00:58:47.240
So, pars datetime, which is what you talked about, really actually does an amazing job of that.

00:58:47.240 --> 00:58:48.580
Even for human type stuff.

00:58:48.580 --> 00:58:49.660
Yeah, that's right.

00:58:49.800 --> 00:58:52.640
And this is another library that I discovered while doing the research for the book.

00:58:52.640 --> 00:58:53.880
I had not used this one before.

00:58:53.880 --> 00:58:56.840
I tried several libraries like this, but I was amazed.

00:58:56.840 --> 00:59:04.880
In the section of this book, I give some examples where parsed datetime is used to parse fairly typical looking datetime strings.

00:59:05.120 --> 00:59:13.200
But in the second half of the section, there's much more natural language type string sets that it also parses and does really well.

00:59:13.200 --> 00:59:20.820
I had a lot of fun doing the section because I tried to find ways of writing my statement of what day it was in very different ways, in very strange ways.

00:59:20.820 --> 00:59:22.080
And it seemed to get all of them.

00:59:22.080 --> 00:59:23.780
Right.

00:59:23.780 --> 00:59:24.120
Yeah.

00:59:24.120 --> 00:59:29.460
The last option that I had in my list was a string that said two weeks and three days in the future.

00:59:29.460 --> 00:59:31.400
And pass datetime correctly parsed that.

00:59:31.400 --> 00:59:32.420
I know.

00:59:32.420 --> 00:59:33.120
It's so amazing.

00:59:33.120 --> 00:59:33.720
Pretty amazing.

00:59:33.720 --> 00:59:43.760
Like when I had in mind of what would work, you know, you'll say, look, you can give it like 2016-07-16 or 7-16-2016.

00:59:43.760 --> 00:59:44.960
These types of things.

00:59:44.960 --> 00:59:46.760
And then I'll actually parse those all correctly.

00:59:46.760 --> 00:59:49.140
But then you started to get more interesting.

00:59:49.140 --> 00:59:53.020
And you said like yesterday, 10 minutes from now, three days ago.

00:59:53.020 --> 00:59:54.180
And it just totally got all this.

00:59:54.180 --> 00:59:56.340
And then you got to the most outrageous one, like you said.

00:59:56.340 --> 00:59:58.580
Two weeks and three days in the future.

00:59:58.580 --> 00:59:59.740
That's awesome.

00:59:59.740 --> 01:00:00.980
Yeah, it's pretty cool.

01:00:00.980 --> 01:00:03.600
I would really want to use this in an upcoming project.

01:00:03.600 --> 01:00:04.960
I just need to find the right project.

01:00:04.960 --> 01:00:07.140
Yeah, it's really good.

01:00:07.140 --> 01:00:10.540
I have my PyPI package and I'm looking for the project in which to use it.

01:00:10.540 --> 01:00:11.240
Exactly.

01:00:11.240 --> 01:00:15.080
And I think I confused Arrow with parsed at time.

01:00:15.080 --> 01:00:20.600
Arrow has the ability to give you like human relative time.

01:00:21.320 --> 01:00:27.940
So you can say on any arrow time, you can say humanize and it'll say just now, ask it again a little bit later.

01:00:27.940 --> 01:00:34.080
It'll say seconds ago or two hours ago or two hours in the future or something like that, which is really nice.

01:00:34.080 --> 01:00:35.400
Yeah, that's awesome.

01:00:35.640 --> 01:00:37.620
And the multilingual support is really good as well.

01:00:37.620 --> 01:00:42.820
I see that as being hugely valuable in web services and web development.

01:00:42.820 --> 01:00:43.760
No, I totally agree.

01:00:43.760 --> 01:00:51.520
Then the last part that you looked at, you said, okay, let's, these are all very purpose focused packages that we've talked about.

01:00:51.520 --> 01:00:55.500
Parsing date, time or scheduling something to recur every so often.

01:00:55.500 --> 01:00:59.400
But there's a couple of general purpose libraries that you talked about.

01:00:59.400 --> 01:01:05.240
And the first one, Boltons, is from a multi-time guest on the show, Mahmoud Hashabi.

01:01:05.240 --> 01:01:09.060
And he put that out there from the guys at PayPal, which was great.

01:01:09.060 --> 01:01:11.240
So you want to talk a little bit about what's good with Boltons?

01:01:11.240 --> 01:01:12.220
Yeah, for sure.

01:01:12.220 --> 01:01:17.460
The first thing, though, is that what's quite interesting to me, if you compare Python to some other languages,

01:01:17.460 --> 01:01:21.920
is because the standard library is so big and it covers a lot of ground,

01:01:22.000 --> 01:01:25.700
it's quite rare to find general purpose libraries in the Python ecosystem.

01:01:25.700 --> 01:01:27.300
I thought that was quite interesting.

01:01:27.300 --> 01:01:31.260
Boltons is one of the few ones that I did manage to find,

01:01:31.260 --> 01:01:37.460
where the intention is literally just to be a general purpose library for use in very, very different spheres.

01:01:37.460 --> 01:01:43.440
Most of the packages that you get on the package index are dedicated towards a singular purpose, usually,

01:01:43.440 --> 01:01:47.060
to perform some function, like all the other libraries that we've looked at.

01:01:47.060 --> 01:01:49.580
So I really thought that was interesting in doing the research,

01:01:49.700 --> 01:01:52.580
that there are not very many general purpose libraries.

01:01:52.580 --> 01:01:59.420
And my conclusion is that that must be because the standard library covers already most of the general purpose type of things that you need to do.

01:01:59.420 --> 01:02:00.780
I agree that that's probably true.

01:02:00.780 --> 01:02:08.540
I wonder if another reason, a secondary reason, is that it's pretty easy to bring in a bunch of small libraries.

01:02:09.040 --> 01:02:14.320
It's not like you've got to download and get the header files and the lib files and the right, you know,

01:02:14.320 --> 01:02:17.420
just statically linking and all that kind of stuff that you have to normally deal with.

01:02:17.420 --> 01:02:21.980
It's if you just pip install and import a bunch of stuff, you're good to go.

01:02:21.980 --> 01:02:25.740
So maybe it's also easier to have small libraries possibly.

01:02:25.740 --> 01:02:29.100
But yeah, I think you're right that because a lot of stuff is built in,

01:02:29.100 --> 01:02:33.660
a lot of people maybe put their energies towards fixing built-in stuff.

01:02:33.700 --> 01:02:36.340
And it's just, you know, it's a 25-year-old standard library, right?

01:02:36.340 --> 01:02:38.640
It's pretty polished at this point.

01:02:38.640 --> 01:02:39.820
I think you make a lot of sense.

01:02:39.820 --> 01:02:45.400
It also makes a nice parallel with the Node ecosystem where, similarly, there aren't too many general purpose libraries.

01:02:45.400 --> 01:02:50.840
And that's probably because it's so easy to bring in a lot of smaller libraries to make up the feature set you require.

01:02:50.840 --> 01:02:51.620
Yeah, absolutely.

01:02:52.340 --> 01:02:54.780
So maybe we could just really quickly touch on a few of the things.

01:02:54.780 --> 01:02:59.560
So one of the things that's in there that's pretty nice is the caching functionality.

01:02:59.560 --> 01:03:01.620
So you start out with cache utils.

01:03:01.620 --> 01:03:02.600
That's right.

01:03:02.600 --> 01:03:09.660
So the killer feature of the cache functionality in Boltons is the way that you can share a cache among multiple function calls.

01:03:09.660 --> 01:03:13.960
It's not that easy to do with the LRU cache that you get in the standard library.

01:03:13.960 --> 01:03:16.200
It's in the functools module.

01:03:16.200 --> 01:03:18.980
So you have to import functools.lrucache.

01:03:19.100 --> 01:03:25.260
The one that you get in Boltons is very easy to share amongst many different function calls as a decorator.

01:03:25.260 --> 01:03:29.800
That is the main attraction for me to use the cache in Boltons versus the one in the standard library.

01:03:29.800 --> 01:03:32.340
The LRI cache is also kind of interesting.

01:03:32.340 --> 01:03:38.520
I had to stretch a little bit to come up with an application to use both caches in the same code base.

01:03:38.520 --> 01:03:42.160
It's definitely good to keep an eye on the LRI cache.

01:03:42.160 --> 01:03:42.680
Yeah.

01:03:42.680 --> 01:03:43.060
Okay.

01:03:43.060 --> 01:03:44.100
And let's see.

01:03:44.100 --> 01:03:46.980
There was some other stuff that I thought was pretty interesting in there.

01:03:46.980 --> 01:03:51.900
One of them you had talked about was the at exit function, which I'd never used the at exit function.

01:03:51.900 --> 01:03:52.340
Yeah.

01:03:52.340 --> 01:03:54.320
The at exit function is pretty neat.

01:03:54.320 --> 01:03:58.040
You can basically set something up to run when it exits.

01:03:58.040 --> 01:03:58.600
Right.

01:03:58.600 --> 01:03:58.860
Yeah.

01:03:58.860 --> 01:04:03.320
So if you want to save some data structures and reload them at startup, you can just register these.

01:04:03.320 --> 01:04:05.540
Here's the shutdown functions to make sure you run.

01:04:05.540 --> 01:04:05.940
That's cool.

01:04:05.940 --> 01:04:06.780
Yeah, exactly.

01:04:06.780 --> 01:04:12.600
Another stuff that was in there that was nice was the iter tools that would give you like windowed chunked data.

01:04:12.600 --> 01:04:20.420
So for example, you talked about displaying that data interactively using PyQt graph.

01:04:20.420 --> 01:04:23.800
You could maybe combine that with the windowed iter tool.

01:04:23.800 --> 01:04:30.340
The iter tool is a windowed iter behavior and take some sort of stream of data and always show the last 50 pieces of the data,

01:04:30.340 --> 01:04:31.760
like in a few lines of code, right?

01:04:31.760 --> 01:04:32.760
Yeah, absolutely.

01:04:32.760 --> 01:04:33.260
For sure.

01:04:33.260 --> 01:04:41.920
The chunking and the chunked iter and the windowed iter, in my opinion, they're much better than the recipes that the standard library gives in its iter tools documentation,

01:04:41.920 --> 01:04:48.940
which I see as a fairly clunky way of piecing together building blocks from iter tools to get these same effects.

01:04:48.940 --> 01:04:53.780
I think it would make a pretty good addition to the standard library to have this chunked iter and windowed iter functions.

01:04:54.040 --> 01:04:59.320
Yeah, it's very possible that eventually some of these just become consumed into the standard library over time.

01:04:59.320 --> 01:04:59.700
It's great.

01:04:59.700 --> 01:05:02.960
You also have, there's also some nice debugging tools.

01:05:02.960 --> 01:05:04.720
That was cool.

01:05:04.720 --> 01:05:09.580
So you can say, yeah, PDB on signal, for example.

01:05:09.580 --> 01:05:10.940
How would you use that?

01:05:10.940 --> 01:05:16.020
Yeah, so you can attach this PDB on signal function inside your running application.

01:05:16.280 --> 01:05:23.640
And then by default, a keyboard interrupt handler will automatically be added to your program so that when a crash does occur,

01:05:23.640 --> 01:05:30.640
or when you, not a crash, but when you control C to stop your program, your program can stop at that point in a debug session.

01:05:30.640 --> 01:05:36.860
So for example, with a long running loop, if it's taking too long and you're wondering whether the program is doing the correct thing,

01:05:36.860 --> 01:05:40.140
or perhaps you suspect that it is no longer doing the correct thing,

01:05:40.140 --> 01:05:45.220
you can control C and you can get a debug prompt inside the loop wherever you sent the signal.

01:05:45.720 --> 01:05:46.500
Yeah, that's awesome.

01:05:46.500 --> 01:05:48.520
Just, that could be pretty handy in the right situation.

01:05:48.520 --> 01:05:50.880
Yeah, if you're wondering what the heck is this process doing?

01:05:50.880 --> 01:05:54.040
Is it stuck talking to the database, stuck talking to the web service?

01:05:54.040 --> 01:05:55.200
Is it just broken?

01:05:55.200 --> 01:05:57.020
Yeah, let's have a look, right?

01:05:57.020 --> 01:05:58.480
Yeah.

01:05:58.480 --> 01:05:59.340
Yeah, very nice.

01:05:59.340 --> 01:06:03.000
Okay, so let's, let's almost at the end so we should wrap it up.

01:06:03.000 --> 01:06:07.740
But the last major piece that you talk about in the general libraries is Cython.

01:06:07.740 --> 01:06:15.160
Yeah, so this 20 Libraries book actually came about as a follow on from an earlier video screencast series

01:06:15.160 --> 01:06:17.960
that I did for O'Reilly, which was on Cython.

01:06:17.960 --> 01:06:25.620
It's a huge five and a half hour long set of 75 videos covering how to get into Cython and how to start using it.

01:06:25.620 --> 01:06:26.280
That sounds great.

01:06:26.280 --> 01:06:28.820
I'll be sure to link to it from the show notes for everyone.

01:06:28.820 --> 01:06:29.500
Yeah, sure.

01:06:29.640 --> 01:06:30.400
I'll give you the link.

01:06:30.400 --> 01:06:45.140
And yeah, Cython, I think, has started now to gain some, some mindshare in the Python community, but not that many people are still using it yet, because it does introduce some things that are more complex than what you usually have to deal with in a Python package.

01:06:45.220 --> 01:06:46.960
For example, compiling with C extensions.

01:06:46.960 --> 01:06:57.580
However, Cython, among many other things, Cython can give the average Python programmer two key things that have, that have long been desired.

01:06:57.680 --> 01:07:06.220
The first one is Cython can speed up hotspots inside your source code easily affect a hundred or more if we're talking about basic math computation.

01:07:06.220 --> 01:07:09.960
A hundred times is not something to take lightly.

01:07:09.960 --> 01:07:15.140
It's the difference between, you know, running for a hundred days or running for one day for a very big long running process.

01:07:15.160 --> 01:07:28.440
And the second thing that Cython can give you, again, for the right kind of situation, which might be mathematical computation, is an easy way to run your threads on different CPUs without the global interpreter lock interfering in any way whatsoever.

01:07:28.440 --> 01:07:36.880
Something that I tweeted just yesterday was, there seems to be a misconception in some circles that you need OpenMP support to use parallelization in Cython.

01:07:36.880 --> 01:07:37.980
And that's not the case.

01:07:38.060 --> 01:07:46.120
You can get pretty good parallelization just with normal Python threads, as long as inside your Cython functions where you want to enable that, you release the GIL.

01:07:46.120 --> 01:07:46.600
Right.

01:07:46.600 --> 01:07:49.120
And there's a way you can even do that with context managers, right?

01:07:49.120 --> 01:07:51.680
You can say with no GIL or something like that, right?

01:07:51.680 --> 01:07:52.760
That's exactly right.

01:07:52.760 --> 01:07:52.960
Yeah.

01:07:52.960 --> 01:07:59.720
So for me as a Python programmer now in the situation that I'm in, the GIL is not really that big a problem for me.

01:07:59.720 --> 01:08:02.160
It depends on the details of the situation.

01:08:02.360 --> 01:08:14.740
But for heavy math computation, where I want to be able to access all the cores, and I simultaneously want my code to run faster than it normally might just with a plain CPython interpreter, Cython gives me both of those things in the same package.

01:08:14.740 --> 01:08:15.980
It sounds really great.

01:08:15.980 --> 01:08:24.280
I've not had a chance to do enough scientific work, but I can see it even being useful outside of scientific computational stuff.

01:08:24.280 --> 01:08:37.540
For example, if you're writing, let's just say I'm writing some kind of ORM or something, and I'm spending a ton of time taking objects off the stream and the data layer and actually turning those into objects.

01:08:37.540 --> 01:08:43.640
And just that processing there is like some big hotspot if I do a query that returns 100,000 records.

01:08:43.640 --> 01:08:46.300
Maybe that loop could be written in Cython.

01:08:46.300 --> 01:08:46.920
Is that right?

01:08:47.060 --> 01:08:47.680
Yeah, absolutely.

01:08:47.680 --> 01:08:59.740
So a good example is something that I've been doing at work for the past week, which is converting our protocol buffer code away from using Google's protocol buffer implementation to using a new tool called Pyrobuff.

01:08:59.740 --> 01:09:12.140
Pyrobuff is itself written in Cython, and it generates a PYX file for you to use as your object implementation of the protocol buffer rather than just using your normal Python-based implementation of the protocol buffer.

01:09:12.440 --> 01:09:19.020
I'm not going to go into what the protocol buffers are, but basically it's exactly what you were saying, object serialization that you shuffle between two places.

01:09:19.020 --> 01:09:23.220
And Cython has been used to create the protocol buffer using Pyrobuff.

01:09:23.220 --> 01:09:32.800
But in addition to that, I use the object, the particular object that that process generates inside another Cython file, which I can then use directly with no overhead from the Python interpreter.

01:09:32.800 --> 01:09:33.640
Yeah, that's great.

01:09:33.640 --> 01:09:34.520
That's really cool.

01:09:34.520 --> 01:09:35.820
All right.

01:09:35.820 --> 01:09:40.460
So you've definitely given me a broader view of where Cython is applicable, and that's cool.

01:09:40.460 --> 01:09:45.180
So let's round it out with one final awesome thing that you point out.

01:09:45.180 --> 01:09:55.620
And that's a GitHub repository or project that is just a huge collection of stuff like this that people have found awesome.

01:09:55.620 --> 01:09:58.720
Like here's all the awesome Python packages for OCR.

01:09:58.720 --> 01:10:01.620
Here's the awesome ones for e-commerce and so on.

01:10:01.620 --> 01:10:02.900
And that's awesome Python on GitHub.

01:10:02.900 --> 01:10:03.520
Yeah.

01:10:03.520 --> 01:10:08.740
Awesome Python is so awesome that many of the other language communities have now begun to copy it.

01:10:08.740 --> 01:10:15.260
So you can also find awesome Go and awesome Ruby and many of the other variations.

01:10:15.260 --> 01:10:16.680
Very cool.

01:10:16.680 --> 01:10:17.200
Very cool.

01:10:17.200 --> 01:10:20.920
So, Kayla, this has been really interesting.

01:10:20.920 --> 01:10:29.840
I learned a lot from your book and not necessarily many of the pieces that we talked about, but maybe even the ones that we didn't get a chance to cover.

01:10:30.160 --> 01:10:38.360
There's a bunch of other interesting packages that we're using in conjunction with your demos that I'll leave it just vague.

01:10:38.360 --> 01:10:44.420
And people can go check out the book, which at least a little while ago you could get as a free e-book from O'Reilly.

01:10:44.420 --> 01:10:45.360
I'll link to it.

01:10:45.360 --> 01:10:46.820
But highly recommended.

01:10:46.820 --> 01:10:49.440
I think it was time well spent to go through it.

01:10:49.440 --> 01:10:49.840
So thanks.

01:10:50.180 --> 01:10:50.440
Okay.

01:10:50.440 --> 01:10:51.320
Yeah, my pleasure.

01:10:51.320 --> 01:10:51.740
Yeah.

01:10:51.740 --> 01:10:58.340
So let me ask you, as I always do everyone, but it's a bit of a bigger list to pick from.

01:10:58.340 --> 01:11:00.160
What's your favorite PyPI package?

01:11:00.160 --> 01:11:06.340
If you have one out of all the books that you would say, like, okay, this is the thing people should take away if they're not going to get the book.

01:11:06.700 --> 01:11:11.680
My pick for the PyPI package is pretty much anything inside the Bware project.

01:11:11.680 --> 01:11:18.920
I very strongly feel that the contributions that Russell is making are very positive for the Python community and they're forward looking.

01:11:18.920 --> 01:11:24.920
The things that he's working on in the Bware project are things that we need to have happen in our community and our space.

01:11:24.920 --> 01:11:32.140
So for anyone who's thinking about finding a project online that they want to contribute to, maybe get a little bit of experience, that is a great place to go.

01:11:32.140 --> 01:11:40.140
There's the Togo framework, which is intended to be used as a way of writing platform-native graphical user applications in Python.

01:11:40.140 --> 01:11:45.540
But there are a whole bunch of other smaller projects that you can adopt and get into and dive in and play with the details.

01:11:45.540 --> 01:11:51.760
There are projects for running Python on iOS, projects for running Python on Android, and a bunch of different other features.

01:11:52.200 --> 01:12:01.040
He also has a project for packaging up Python for deployment to target machines, which is another issue that many people in Python feel has been, I guess, under-addressed.

01:12:01.040 --> 01:12:02.260
The issue of deployment.

01:12:02.260 --> 01:12:06.400
Yeah, I definitely think it's under-addressed for desktop spaces, absolutely.

01:12:06.400 --> 01:12:07.100
Absolutely.

01:12:07.100 --> 01:12:07.800
For sure.

01:12:07.800 --> 01:12:09.220
Or mobile, for that matter.

01:12:09.220 --> 01:12:12.060
But anywhere but the web or just your shell, I guess.

01:12:12.060 --> 01:12:13.020
Yeah.

01:12:13.020 --> 01:12:14.380
Yeah, okay, very cool.

01:12:14.380 --> 01:12:15.100
That's great.

01:12:15.100 --> 01:12:15.920
Check that one out.

01:12:15.920 --> 01:12:16.820
So, Beware.

01:12:16.820 --> 01:12:18.540
The name of the project is Beware.

01:12:18.540 --> 01:12:21.840
If you're looking for something to work on, you could do much worse than that project.

01:12:22.140 --> 01:12:23.740
If you're writing some code, what editor do you use?

01:12:23.740 --> 01:12:24.880
Yeah, that's a great question.

01:12:24.880 --> 01:12:26.840
So, I've been doing this a while now.

01:12:26.840 --> 01:12:28.800
And for most of those years, I've been using Vim.

01:12:28.800 --> 01:12:35.400
And since January, I've started using PyCharm because the scales have tipped the balance for me.

01:12:35.400 --> 01:12:42.200
And the features that PyCharm now provides outweigh what I can do to the best of my knowledge with Vim configuration.

01:12:42.200 --> 01:12:45.800
So, yeah, I'm now writing my Python code in PyCharm.

01:12:45.800 --> 01:12:46.460
All right.

01:12:46.460 --> 01:12:47.120
You and me both.

01:12:47.120 --> 01:12:48.180
I love that one as well.

01:12:48.180 --> 01:12:48.620
That's great.

01:12:48.620 --> 01:12:49.200
Yep.

01:12:49.580 --> 01:12:49.860
All right.

01:12:49.860 --> 01:12:51.720
Final call to action for listeners out there.

01:12:52.160 --> 01:12:56.300
First of all, check out the Beware project and contribute to that if you're looking to write some code.

01:12:56.300 --> 01:12:57.040
Anything else?

01:12:57.040 --> 01:12:57.760
Get your book.

01:12:57.760 --> 01:12:58.440
Where do they get it?

01:12:58.440 --> 01:12:59.500
Oh, you can get the book at O'Reilly.

01:12:59.500 --> 01:13:02.980
I think if you search for 20 Python libraries you aren't using, that should be enough.

01:13:02.980 --> 01:13:04.100
Google will find it for you.

01:13:04.100 --> 01:13:06.200
And of course, then there's my Cython course as well.

01:13:06.200 --> 01:13:09.400
If you do want to get more into Cython, you can check out my course.

01:13:09.560 --> 01:13:13.980
As far as I know, I think it's the only video course currently available for Cython.

01:13:13.980 --> 01:13:15.480
But I might be wrong about that.

01:13:15.480 --> 01:13:16.920
But that's something else to check out.

01:13:16.920 --> 01:13:32.000
And then maybe the last thing I would mention is just as a general comment, sometimes you see on forums like Reddit and other places, there's a lot of dissatisfaction with some of the decisions that the core Python development team make regarding certain features in the language and what gets included and what gets excluded and so on.

01:13:32.000 --> 01:13:40.640
And I would encourage people to follow the newsletters and the mailing lists to see a bit more about the discussions that go into these decisions.

01:13:40.640 --> 01:13:46.560
The core team has many, many difficult and complex issues to deal with regarding the features that they include or exclude.

01:13:46.560 --> 01:13:52.080
And before I started the mailing list for Python Dev, I had the same thoughts about, you know, why was this designed that way?

01:13:52.080 --> 01:13:53.000
Why didn't they include that?

01:13:53.000 --> 01:13:53.780
Why is that not done?

01:13:53.780 --> 01:14:01.420
But once you begin to follow the mailing list and you start to see the discussions and the complexities that they have to deal with, for example, in the pip project, that's another good example.

01:14:01.700 --> 01:14:07.680
Once you begin to see the complexities that these teams are dealing with, you begin to understand why the decisions get made in the way that they do.

01:14:07.680 --> 01:14:18.480
So I just want to make a point there that if anyone feels dissatisfied with what the core Python team has been doing, get involved and find out more about why the decisions are getting made in particular ways.

01:14:18.480 --> 01:14:19.660
Yeah, I think that's great advice.

01:14:19.660 --> 01:14:24.520
Certainly looking at how the trade-offs are being chosen is definitely important.

01:14:24.520 --> 01:14:28.560
Thank you so much for sharing your book and all this research you did.

01:14:28.560 --> 01:14:29.400
It's really helpful.

01:14:29.400 --> 01:14:30.200
Sure, my pleasure.

01:14:30.380 --> 01:14:32.040
I think people should, they should check out the book.

01:14:32.040 --> 01:14:32.960
They'll definitely enjoy it.

01:14:32.960 --> 01:14:34.120
Thanks for being on the show.

01:14:34.120 --> 01:14:35.040
Yeah, thanks, Michael.

01:14:35.040 --> 01:14:35.280
Great.

01:14:35.280 --> 01:14:35.680
You bet.

01:14:35.680 --> 01:14:35.880
Bye.

01:14:35.880 --> 01:14:36.740
Okay, bye.

01:14:36.740 --> 01:14:41.120
This has been another episode of Talk Python To Me.

01:14:41.120 --> 01:14:43.620
Today's guest has been Caleb Hadding.

01:14:43.620 --> 01:14:47.160
And this episode has been sponsored by Capital One and Intel.

01:14:47.160 --> 01:14:48.940
Thank you both for supporting the show.

01:14:48.940 --> 01:14:53.120
Are you a data scientist or Python developer who loves data?

01:14:53.520 --> 01:15:01.980
If you're looking for a place to work on data science with truly big data that can affect millions of lives, then head on over to jobs.capitalone.com.com.

01:15:01.980 --> 01:15:07.180
And check out the wide range of jobs that Capital One is trying to fill right now.

01:15:07.180 --> 01:15:13.440
The Intel distribution for Python delivers the high-performance Intel C libraries built right into Python.

01:15:13.440 --> 01:15:19.480
Get close to 100 times better performance for certain functions when using NumPy, SciPy, and scikit-learn.

01:15:19.800 --> 01:15:22.740
Check them out at talkpython.fm/Intel.

01:15:22.740 --> 01:15:25.760
Are you or a colleague trying to learn Python?

01:15:25.760 --> 01:15:30.420
Have you tried books and videos that just left you bored by covering topics point by point?

01:15:30.420 --> 01:15:39.000
Well, check out my online course, Python Jumpstart, by building 10 apps at talkpython.fm/course to experience a more engaging way to learn Python.

01:15:39.000 --> 01:15:46.380
And if you're looking for something a little more advanced, try my Write Pythonic Code course at talkpython.fm/pythonic.

01:15:46.880 --> 01:15:53.620
You'll find the show notes and links from this episode at talkpython.fm/episode slash show slash 77.

01:15:53.620 --> 01:15:56.380
Be sure to subscribe to the show.

01:15:56.380 --> 01:15:58.580
Open your favorite podcatcher and search for Python.

01:15:58.580 --> 01:15:59.820
We should be right at the top.

01:15:59.820 --> 01:16:09.140
You can also find the iTunes feed at /itunes, Google Play feed at /play, and direct RSS feed at /rss on talkpython.fm.

01:16:09.400 --> 01:16:14.220
Our theme music is Developers, Developers, Developers by Corey Smith, who goes by Smix.

01:16:14.220 --> 01:16:20.920
Corey just recently started selling his tracks on iTunes, so I recommend you check it out at talkpython.fm/music.

01:16:20.920 --> 01:16:26.280
You can browse his tracks he has for sale on iTunes and listen to the full-length version of the theme song.

01:16:26.280 --> 01:16:28.340
This is your host, Michael Kennedy.

01:16:28.340 --> 01:16:29.620
Thanks so much for listening.

01:16:29.620 --> 01:16:30.800
I really appreciate it.

01:16:30.800 --> 01:16:32.960
Smix, let's get out of here.

01:16:32.960 --> 01:16:54.520
Stay tuned.

01:16:54.520 --> 01:16:55.240
Don't put it on the ground.

01:16:55.240 --> 01:17:25.220
Thank you.

