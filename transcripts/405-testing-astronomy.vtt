WEBVTT

00:00:00.001 --> 00:00:04.820
So you know about dependencies and testing, right? If you're going to talk to your database in your

00:00:04.820 --> 00:00:09.760
app, you have to decide how to approach that with your test. There are a lot of solid options you

00:00:09.760 --> 00:00:15.720
might pick from, and they vary by goals. Do you mock out the dB layer for isolation, or do you use

00:00:15.720 --> 00:00:22.900
a test dB to make it as real as possible? Or do you even just punt and use the real dB for expediency?

00:00:22.900 --> 00:00:29.840
What if your dependency was a huge array of radio telescopes in a rack of hundreds of bespoke

00:00:29.840 --> 00:00:36.140
servers? That's the challenge on deck for today, where we discuss testing radio astronomy with

00:00:36.140 --> 00:00:41.840
pytest and our guest, James Smith. He's a digital signal processing engineer at the South African

00:00:41.840 --> 00:00:47.540
Radio Astronomy Observatory and has some great stories and tips to share. This is Talk Python

00:00:47.540 --> 00:00:51.960
to Me, episode 405, recorded February 13th, 2023.

00:00:59.680 --> 00:01:10.900
Welcome to Talk Python to Me, a weekly podcast on Python. This is your host, Michael Kennedy. Follow

00:01:10.900 --> 00:01:17.820
me on Mastodon, where I'm @mkennedy and follow the podcast using @talkpython, both on fosstodon.org.

00:01:17.820 --> 00:01:22.560
Be careful with impersonating accounts on other instances. There are many. Keep up with the show

00:01:22.560 --> 00:01:28.920
and listen to over seven years of past episodes at talkpython.fm. We've started streaming most of our

00:01:28.920 --> 00:01:34.780
episodes live on YouTube. Subscribe to our YouTube channel over at talkpython.fm/youtube to get

00:01:34.780 --> 00:01:40.800
notified about upcoming shows and be part of that episode. This episode of Talk Python To Me is brought

00:01:40.800 --> 00:01:46.060
to you by Typy. They're here to take on the challenge of rapidly transforming a Bayer algorithm in Python

00:01:46.060 --> 00:01:53.260
into a full-fledged decision support system. Check them out at talkpython.fm/Typy, T-A-I-P-Y.

00:01:53.260 --> 00:01:59.620
And it's brought to you by Sentry. Don't let those errors go unnoticed. Use Sentry. Get started at

00:01:59.620 --> 00:02:04.600
Talk Python.fm slash Sentry. James, welcome to Talk Python to Me.

00:02:04.600 --> 00:02:09.160
Normally, I talk Python to computers, Michael, but this would be a first. You are a human, right?

00:02:09.280 --> 00:02:14.400
I am. Well, you know, you got to ask ChatGCP about that. We'll see. There's a lot of people who are

00:02:14.400 --> 00:02:19.120
interested in talking about Python. When I first put this podcast together, I thought, well, who's

00:02:19.120 --> 00:02:23.320
going to be the target audience? I thought people were really into Python. Like people will make

00:02:23.320 --> 00:02:27.280
things like Flask and stuff. And they're just, you know, it's kind of a big part of the world,

00:02:27.280 --> 00:02:32.300
but there's a ton of people who are scientists or just curious about programming who listen as well.

00:02:32.300 --> 00:02:37.520
So it really surprised me how many people you can talk Python to and how much they seem to appreciate it.

00:02:37.700 --> 00:02:43.220
So it's cool. Indeed. Yeah. But I also spend a fair amount of time talking Python to computers as well.

00:02:43.220 --> 00:02:46.200
Sometimes more fun, sometimes more frustrating. You never know.

00:02:46.200 --> 00:02:53.380
Yes, we're familiar with that. I'm sure. I'm sure. Well, you have this extra angle of it's not just

00:02:53.380 --> 00:03:01.000
talking to pure software, right, that lives in an internet API vacuum, but you have physical things,

00:03:01.000 --> 00:03:07.480
many, many physical things in radio astronomy and large arrays of telescopes and receivers and

00:03:07.480 --> 00:03:10.780
as we're going to talk about lots of different things. And I think that's one of the really

00:03:10.780 --> 00:03:17.680
interesting aspects of this episode to talk to you is Python against real world things out there and

00:03:17.680 --> 00:03:23.680
real time as well. Perhaps sort of to jump back and put the listeners in a bit of context. I work at

00:03:23.680 --> 00:03:28.900
the South African Radio Astronomy Observatory. Our sort of primary project is called Meerkat. It's a

00:03:28.900 --> 00:03:35.620
precursor of one of the world's biggest radio telescopes, which is planned. So the project is called SKA.

00:03:35.620 --> 00:03:40.020
So it stands for Square Kilometer Array, which refers to the size of the collecting area of the

00:03:40.020 --> 00:03:44.980
telescope that will eventually be built. It's in its beginning stages now. And that has a lot of moving

00:03:44.980 --> 00:03:51.980
parts right from the actual antennas that are pointing into the sky and recording radio emissions

00:03:51.980 --> 00:03:57.360
from the universe somewhere through down to the point where a scientist actually sits down with the data

00:03:57.360 --> 00:04:03.080
product in order to analyze and to write his paper that he's hoping to publish and win his Nobel Prize.

00:04:04.280 --> 00:04:10.600
And so everything from the beginning of the end there needs some software control. And Python is the

00:04:10.600 --> 00:04:13.260
sort of weapon of choice for all of those applications.

00:04:13.260 --> 00:04:17.620
Yeah, it's pretty interesting to see what you're going to talk about. You gave a couple of

00:04:17.620 --> 00:04:21.020
presentations at PyCon South Africa. Is that right?

00:04:21.020 --> 00:04:23.540
That's right. Yes. Last year.

00:04:23.540 --> 00:04:28.200
Yeah, fantastic. And people all, of course, link to those in the show notes and people can check them

00:04:28.200 --> 00:04:33.320
out. You got a lot of cool graphics and stuff there. And the fact that you built this real time

00:04:33.420 --> 00:04:40.220
aspect involving Python, which is not its normal use, perhaps, I think is really something that

00:04:40.220 --> 00:04:44.800
we're going to have a good time talking about as well as just how do you test something like a large

00:04:44.800 --> 00:04:51.260
receiver array rather than, you know, is the user logged in in the database? Yes or no. And let's

00:04:51.260 --> 00:04:55.560
mock that out, right? This is both, I think, very similar and yet very different, right?

00:04:56.060 --> 00:05:01.080
Yes, it can be. And there's a lot that you can do, but there's also some interesting gotchas,

00:05:01.080 --> 00:05:06.060
which we can talk about there. So, I mean, I don't know where you want to start.

00:05:06.060 --> 00:05:10.240
Let's get a real quick introduction with you before we get too far down in this topic. And so,

00:05:10.240 --> 00:05:15.400
tell people how you got into programming and astronomy and all that kind of stuff.

00:05:15.400 --> 00:05:20.480
Well, programming, well, both of those have become, both of those started out as hobbies and they've

00:05:20.480 --> 00:05:25.620
sort of become my job, which means I don't do them as a hobby anymore, which is always fun. When I was

00:05:25.620 --> 00:05:29.700
younger in school, I made the mistake during a summer holiday of telling my dad that I was bored.

00:05:29.700 --> 00:05:36.340
And so, yeah, he handed me a book and this book was programming in C, I think, I forget exactly.

00:05:36.340 --> 00:05:41.360
And being young and naive, I thought this was a great idea and started working my way through it.

00:05:41.360 --> 00:05:47.520
So, since then, I've been programming more or less continuously. It was sort of the mid to late

00:05:47.520 --> 00:05:52.220
2000s that Python started to become more prominent and I picked that up and haven't looked back.

00:05:52.220 --> 00:05:57.340
Astronomy was also another hobby. In my student days, I spent many South African,

00:05:57.340 --> 00:06:03.780
cold South African nights looking at the stars. And then a job opportunity opened up at Sereo to do

00:06:03.780 --> 00:06:09.140
electronic engineering, which was the field that I trained in university. That was about seven years

00:06:09.140 --> 00:06:14.920
ago. And so I've been combining these sort of programming and electronic engineering and my

00:06:14.920 --> 00:06:19.840
astronomy hobby, which has shifted now into radio instead of optical. But yeah, I basically come from

00:06:19.840 --> 00:06:26.160
that. Fantastic. I remember getting a book in C thinking, oh, I'm going to learn programming and then

00:06:26.160 --> 00:06:30.100
read it like, okay, this, when I was pretty young, I was like, okay, this is a little bit much divide

00:06:30.100 --> 00:06:34.360
off at the moment, but came back to you as well. But that's how it was, right? We used to get books

00:06:34.360 --> 00:06:40.300
pre-internet, YouTube, and where you just fired up and say, teach me programming in the next half

00:06:40.300 --> 00:06:45.460
hour. With listings of code and you have to type them in and then you miss a semicolon somewhere

00:06:45.460 --> 00:06:49.600
and scratch your head for half a day. That's right. But I think that was a good preparation

00:06:49.600 --> 00:06:53.580
though. I mean, as great as Python is, it is somewhat high level. And I think it's helpful to

00:06:53.580 --> 00:06:58.020
have a sort of a, even if you don't often work at that level, to have an understanding of what's going

00:06:58.020 --> 00:07:02.020
on at a slightly lower level than what the computer is doing. It's valuable to have that experience,

00:07:02.020 --> 00:07:06.800
but I'm also, even though I did it professionally for a couple of years, happy that I'm not,

00:07:06.800 --> 00:07:10.960
I don't have to continuously work at that level, right? You can just be so more productive in

00:07:10.960 --> 00:07:17.000
a higher level language like Python. Indeed. Totally. Yeah. So I think you introduced this a

00:07:17.000 --> 00:07:21.600
little bit, but tell people about Seraro, this project, how'd you get to that place?

00:07:21.740 --> 00:07:27.820
Yeah. Seraro, well, I got there by responding to a job advert and, you know, interviewing and what

00:07:27.820 --> 00:07:33.880
have you. Seraro sort of started out as a response to the international kind of scientific project to

00:07:33.880 --> 00:07:38.880
build a square kilometer array telescope. The idea is to make it the most sensitive radio telescope that

00:07:38.880 --> 00:07:43.600
has ever been built. And when you're doing that kind of project, you want to build it in an ideal

00:07:43.600 --> 00:07:48.360
setting, just like optical telescopes. If you want to do proper science, you want to do it far away

00:07:48.360 --> 00:07:52.000
from cities where there's no light pollution. Similarly, radio telescopes, you want to do them

00:07:52.000 --> 00:07:56.960
where there's no radio interference. So cell phones, TV signals, wifi, that kind of stuff.

00:07:56.960 --> 00:08:02.280
The Southern hemisphere also has a bit of an advantage in that we can see parts of the galaxy that the

00:08:02.280 --> 00:08:07.400
Northern hemisphere can't. And so as this project progressed, various sites were identified.

00:08:07.400 --> 00:08:12.580
And ultimately the decision was made to put part of the telescope in South Africa and part of it in

00:08:12.580 --> 00:08:17.580
Australia. And Seraro is really the, just the organization around developing the South African

00:08:17.580 --> 00:08:20.320
part of that telescope. That's where we are.

00:08:20.320 --> 00:08:25.920
It's a very cool project. I think a square kilometer array of telescope, that's pretty impressive,

00:08:25.920 --> 00:08:31.600
right? And also something that's much easier to do with radio than with optical, I would imagine.

00:08:31.600 --> 00:08:37.240
Yes. When it comes to telescopes, bigger is better, but there reaches a point of where building a bigger

00:08:37.240 --> 00:08:43.000
one becomes expensive and very difficult. And so a trick that you can use in radio is called

00:08:43.000 --> 00:08:48.240
interferometry. So if you measure your radio waves at different points and you measure them in phase

00:08:48.240 --> 00:08:53.620
with each other or what they call coherently, then you can get away with making a lot of smaller

00:08:53.620 --> 00:08:58.700
telescopes to build up the same kind of area, which will give you the same effect as a bigger one,

00:08:58.700 --> 00:09:03.520
but much cheaper because you can do a lot of, a lot of smaller, cheaper telescopes. If that in a nutshell

00:09:03.520 --> 00:09:08.420
is really why, why these telescope arrays exist. It's very difficult to do that with optical telescopes

00:09:08.420 --> 00:09:13.840
because the wavelength is so short, the frequency is so high that getting, getting the, it is possible,

00:09:13.840 --> 00:09:18.180
it can be done, but getting the signal coherent or in phase is very, very difficult.

00:09:18.180 --> 00:09:18.580
I see.

00:09:18.580 --> 00:09:19.720
That's why we do it in radio.

00:09:19.720 --> 00:09:24.220
Yeah. You don't have much time. There's not much of a gap between how you've got to coordinate the

00:09:24.220 --> 00:09:27.000
signals across the radio, but it's even worse in optical. I see.

00:09:27.160 --> 00:09:32.680
Exactly. Exactly. Nice. So people who listened to the episode about imaging the black hole,

00:09:32.680 --> 00:09:37.260
we talked a lot about that. So, you know, I don't necessarily need to think we need to cover

00:09:37.260 --> 00:09:42.860
too much depth about it. But one thing I think that people might find interesting is I think,

00:09:42.860 --> 00:09:47.200
remember from your talk that you said, this is part, some of the work that you're doing is part

00:09:47.200 --> 00:09:51.800
of the deep space network for communicating with, is that right? With NASA.

00:09:51.800 --> 00:09:54.980
South African radio astronomy has its origins in the deep space network.

00:09:55.440 --> 00:09:58.880
So if you're trying to communicate with spacecraft that are outside of earth orbit,

00:09:58.880 --> 00:10:03.460
you need a very powerful, something that looks a bit like a radio telescope in much,

00:10:03.460 --> 00:10:07.320
except that you're transmitting as well, because you need to be able to talk to the,

00:10:07.320 --> 00:10:12.940
you know, Voyager or your Mars rover that's out there in space, but very inconveniently for

00:10:12.940 --> 00:10:18.000
scientific purposes, the earth rotates. So for about a third of the day, if you have a telescope

00:10:18.000 --> 00:10:23.720
in California, for example, I think is where one of NASA's big ones are, you know, half of the

00:10:23.720 --> 00:10:28.260
day you can't really talk to your, to your spaceships. NASA built a network of telescopes

00:10:28.260 --> 00:10:32.920
around the world. And, and one was in Australia and one was here in South Africa. And some of the

00:10:32.920 --> 00:10:38.680
early Mars missions were actually used the telescope in South Africa for, for communication. But that was,

00:10:38.680 --> 00:10:42.740
I think in the seventies, I forget my history exactly, but they got a better one in Spain.

00:10:42.940 --> 00:10:47.800
And so the one in, the one in South Africa was kind of converted into a facility just for science.

00:10:47.800 --> 00:10:54.160
And that's been operated by our national research foundation, which evolved into Sareo for the last

00:10:54.160 --> 00:10:56.840
sort of few years. And that's what kind of gave us our leg up.

00:10:56.840 --> 00:11:00.400
Yeah, exactly. It was already built and it was there. And they're like, you know what,

00:11:00.400 --> 00:11:04.460
instead of just let it put it on mothballs, why don't you guys do science with it? Right? That's cool.

00:11:04.640 --> 00:11:08.500
And, and we've been using it quite well since then. They've done, I wouldn't say groundbreaking

00:11:08.500 --> 00:11:12.600
science. I don't know that any Nobel prizes have happened, but we have, we have some good radio

00:11:12.600 --> 00:11:16.640
astronomers originally from South Africa that have used data from this telescope. So yeah.

00:11:16.640 --> 00:11:22.860
Excellent. All right. Let's talk about first the, the real time aspect, this thing that you focus

00:11:22.860 --> 00:11:28.940
on called the correlator, right? And maybe, maybe give us this side of the story. Cause I, I think this

00:11:28.940 --> 00:11:32.760
alone is, is pretty interesting and what you've built here with Python, you and your team.

00:11:32.760 --> 00:11:38.800
So from a conceptual point of view in the episode a few weeks ago, where you interviewed Dr. Sarah

00:11:38.800 --> 00:11:44.200
Asun, I don't know if I'm pronouncing her name correctly. The Event Horizon telescope worked by pointing

00:11:44.200 --> 00:11:49.000
different telescopes around the world at the same object or all radio to all, shall I say,

00:11:49.000 --> 00:11:54.860
all radio telescopes arrays, whether they're very long baseline, like what she used or much shorter

00:11:54.860 --> 00:12:00.040
have something called a correlator. And this is the thing that basically combines the signals from

00:12:00.040 --> 00:12:06.620
the individual telescopes in a way that is a, that enables downstream users, scientists to actually

00:12:06.620 --> 00:12:12.200
make sense of this data. So in order for that to work, the data needs to be in phase. It needs to be

00:12:12.200 --> 00:12:17.220
coherent. And at very long baselines, they do this by having each station, having their, their, their very

00:12:17.220 --> 00:12:20.000
own atomic clock to generate very precise reference signals.

00:12:20.000 --> 00:12:24.540
So as a reminder for people, maybe didn't hear that episode is, you know, the earth is curved as we

00:12:24.540 --> 00:12:31.120
all know, hopefully, and the radio waves come in and as it hits that sphere, they hit the different

00:12:31.120 --> 00:12:35.500
parts of the array. The more spread out, it is even more exaggerated, but it hits the different parts

00:12:35.500 --> 00:12:41.360
of the array at different times. So you have to offset those back in the signal to say, well, it came in at

00:12:41.360 --> 00:12:45.880
this angle, and it came in at this time. And the speed of light says this one is, you know, a nanosecond

00:12:45.880 --> 00:12:51.560
behind that one. So you got to figure out how to realign those. So it looks like a flat surface that they hit

00:12:51.560 --> 00:12:57.020
all simultaneously to look like a single picture, right? So that's the job. That's basically the job of this thing.

00:12:57.300 --> 00:13:02.340
So partially, you can do the first bit with just with geometry, we know what the rotation of the earth

00:13:02.340 --> 00:13:07.460
is, we know where our different telescopes are. And so we can calculate roughly what the time difference

00:13:07.460 --> 00:13:11.780
will be. The job of the correlator is once you've got those signals, and you've applied your sort of

00:13:11.780 --> 00:13:17.580
rough delay offset to each of those signals, the correlator will find the correlations between the

00:13:17.580 --> 00:13:22.060
incoming signals, simply by multiplying the signals together. Mathematically, it's not terribly

00:13:22.060 --> 00:13:27.040
complicated. It's really just multiplication, you know, of each pair of antennas. But it's with that,

00:13:27.040 --> 00:13:31.160
you may remember your from your high school mathematics, the trigonometric identity,

00:13:31.160 --> 00:13:35.560
when you apply to when you multiply two sine waves together, you get a sum and a difference

00:13:35.560 --> 00:13:41.080
product. And it's a similar kind of concept applying to not not just to abstract sine waves,

00:13:41.080 --> 00:13:46.820
but to radio waves that are at various frequencies. The main engineering challenge is just doing this

00:13:46.820 --> 00:13:53.240
fast enough for practical purposes. So in the in the example of the event horizon telescope with very

00:13:53.240 --> 00:13:56.960
long baseline interferometry, it's not possible to do it in real time, because

00:13:56.960 --> 00:14:00.780
your individual elements are just too far apart, you can't get all the data together.

00:14:01.080 --> 00:14:06.460
Not for math, but because the actual data quantity getting them all back and forth across the world is

00:14:06.460 --> 00:14:22.220
too hard. Exactly. So there's specialized hardware that takes those signals and writes them basically just straight onto hard drives. Then these hard drives are physically taken to a central location. I think Sarah did talk about that in her episode.

00:14:22.380 --> 00:14:26.700
Yeah, I think it was Boston and maybe Cambridge and London, something.

00:14:26.700 --> 00:14:28.580
One was in Europe, yes.

00:14:28.580 --> 00:14:30.180
No, it was Max Planck Institute in Germany is what it was, I believe.

00:14:30.180 --> 00:14:32.720
That's right. Yeah. One was in the States. One was in Europe.

00:14:34.860 --> 00:15:04.840
This portion of Talk Python To Me is brought to you by TypePy. TypePy is the next generation open source Python application builder. With TypePy, you can turn data and AI algorithms into full web apps in no time. Here's how it works. You start with a bare algorithm written in Python. You then use TypePy's innovative tool set that enables Python developers to build interactive end user applications quickly. There's a visual designer to develop highly interactive GUIs ready for production. And for inbound data streams, you can program

00:15:04.840 --> 00:15:34.660
against the TypePy core layer as well. TypePy core provides intelligent pipeline management, data caching, and scenario and cycle management facilities. That's it. You'll have transformed a bare algorithm into a full-fledged decision support system for end users. TypePy is pure Python and open source, and you install it with a simple pip install TypePy. For large organizations that need fine-grained control and authorization around their data, there is a paid TypePy Enterprise Edition. But the TypePy core and GUI described above,

00:15:34.660 --> 00:15:46.900
is completely free to use. Learn more and get started by visiting talkpython.fm/taipy. That's T-A-I-P-Y. The links in your show notes. Thank you to TypePy for sponsoring the show.

00:15:46.900 --> 00:16:00.400
Yes, and so, and then the same, well, similar equipment does the reverse process. It reads the data off, and then it basically batch processes it. This happens in software, so you cross-multiply all of the signals together.

00:16:00.660 --> 00:16:12.200
That's great if you have a limited number of telescopes, up to a few dozen or so, as with Event Horizon Telescope. In the Meerkat case, we've got 64 of them, and we're building a few more.

00:16:12.200 --> 00:16:19.800
And as it becomes the full square kilometer array, we're going to be talking about hundreds or possibly even thousands of individual telescope elements.

00:16:20.260 --> 00:16:23.800
So recording everything onto a hard drive at that data rate becomes impractical.

00:16:23.800 --> 00:16:27.260
So the approach that we take is we use what we call a real-time correlator.

00:16:27.260 --> 00:16:34.540
It processes and reduces the data as a sort of first stage in real-time, live, before recording to the disk.

00:16:34.540 --> 00:16:37.640
And as a part of that step, we integrate for a little while.

00:16:37.760 --> 00:16:47.300
So if you think about it from point of view, if you've done some photography at nighttime, you want to do a long exposure, so you open your camera shutter for a long time to get the more signal.

00:16:47.300 --> 00:16:48.560
It's very similar to that.

00:16:48.560 --> 00:16:52.660
So we would integrate over, you know, half a second or a second or, you know, eight seconds.

00:16:53.040 --> 00:17:05.520
And that gives you a much reduced, there's still a lot of data that comes out of the other side, but it's much, much smaller than if you were recording straight onto hard drives from the telescope, the way that they do in Event Horizon Telescope.

00:17:05.520 --> 00:17:06.520
Right. That is interesting.

00:17:06.520 --> 00:17:10.040
I guess it is just like taking a picture, just a different frequency, right?

00:17:10.040 --> 00:17:11.220
But same basic idea?

00:17:11.220 --> 00:17:12.420
Exactly. Exactly.

00:17:12.420 --> 00:17:15.660
Nice. And so there's a lot of data coming through here.

00:17:15.660 --> 00:17:21.980
You talked about how Event Horizon couldn't even ship it around the world quick enough or, you know, even though they were very, very far apart and pretty remote.

00:17:22.140 --> 00:17:23.600
But there's a lot of data here.

00:17:23.600 --> 00:17:26.420
And so maybe give people a sense of the data center.

00:17:26.420 --> 00:17:27.240
Excuse me.

00:17:27.240 --> 00:17:28.800
Give people a sense of the data center.

00:17:28.800 --> 00:17:35.160
And like, you've got this array of, I don't remember how many of these correlator server U1 slices you've got.

00:17:35.160 --> 00:17:35.260
Yeah, no, no.

00:17:35.260 --> 00:17:38.700
But it's not just one corner, PC in the corner, is it?

00:17:38.700 --> 00:17:39.700
No, no.

00:17:39.700 --> 00:17:43.220
Although with the way the technology progresses, maybe one day.

00:17:43.220 --> 00:17:43.720
No.

00:17:43.720 --> 00:17:49.480
So our current generation correlator uses an FPGA-based computing platform.

00:17:49.480 --> 00:17:50.580
We call it Scarab.

00:17:50.860 --> 00:17:55.540
There's a bit of a tradition to name radio astronomy compute things after insects.

00:17:55.860 --> 00:17:57.880
So the previous generation one was called Roach.

00:17:57.880 --> 00:17:59.380
This one is called Scarab.

00:17:59.380 --> 00:18:00.780
They stand for something.

00:18:01.260 --> 00:18:04.820
Configurable open architecture for computing hardware, I think, was the Roach.

00:18:04.820 --> 00:18:08.220
And Scarab, the first three letters are SKA.

00:18:08.220 --> 00:18:09.240
Yeah, there we go.

00:18:09.240 --> 00:18:10.120
There's the Scarab.

00:18:10.120 --> 00:18:14.120
And what that is, is an FPGA is a field programmable gate array.

00:18:14.120 --> 00:18:20.300
So it's a little piece of reconfigurable silicon that has, it's like having a hardware accelerated signal processing.

00:18:20.500 --> 00:18:23.840
It's very fast and it's wired straight into Ethernet for interconnect.

00:18:23.840 --> 00:18:29.940
So in our data center in the Karoo in South Africa, we've got about 280 of these individual Scarabs.

00:18:29.940 --> 00:18:33.680
And each of them has a role to play in the signal processing pipeline.

00:18:33.680 --> 00:18:40.100
They talk to each other via Ethernet and they're controlled by a central master controller computer that runs Python.

00:18:40.340 --> 00:18:46.540
So it uses an asynchronous little routine to coordinate the activities of each of these Scarabs.

00:18:46.540 --> 00:18:50.460
The processing parameters need to be updated from time to time.

00:18:50.460 --> 00:18:56.960
So, for example, as the Earth turns, the geometric delay between a given pair of telescopes will change slightly.

00:18:56.960 --> 00:19:06.620
And so that gets updated periodically in the Scarab so that it can carry on processing the data at the full rate that the telescope is taking data in.

00:19:06.620 --> 00:19:12.000
So to give you an idea of that, each telescope is producing data at about 35 gigabit per second.

00:19:12.000 --> 00:19:13.560
35 gigabit a second?

00:19:13.560 --> 00:19:13.980
Yeah.

00:19:13.980 --> 00:19:14.960
Times 64.

00:19:14.960 --> 00:19:15.520
Yeah.

00:19:15.520 --> 00:19:17.140
Yeah, that's a lot of data.

00:19:17.140 --> 00:19:23.240
After the processing, the other end of the correlator, so we get about four or five gigabit per second.

00:19:23.240 --> 00:19:26.360
So that's reduced due to kind of the long exposure effect.

00:19:26.360 --> 00:19:27.760
It's averaged over a few seconds.

00:19:27.760 --> 00:19:30.920
So it's four or five gigabit per second out the other end.

00:19:30.920 --> 00:19:36.660
And then that gets stored on hard drives for processing and imaging so that scientists can do their science later on.

00:19:36.660 --> 00:19:39.160
But that's the initial stage of the signal processing pipeline.

00:19:39.160 --> 00:19:39.600
Yeah.

00:19:39.600 --> 00:19:42.640
So you've got 64 of these running in concert.

00:19:42.640 --> 00:19:46.460
What does uptime in DevOps look like for you all?

00:19:46.460 --> 00:19:52.040
Is this continuously 24 hours a day recording or is it offline for a certain number of hours?

00:19:52.300 --> 00:19:53.460
Yes, it is.

00:19:53.460 --> 00:19:57.520
And the limiting factor, I'm happy to say, is usually not the correlator.

00:19:57.520 --> 00:20:00.800
We don't need all 280 scarabs to run.

00:20:00.800 --> 00:20:04.180
We can run with about 190 of them with full science capability.

00:20:04.180 --> 00:20:05.700
So there is capacity for spares.

00:20:05.700 --> 00:20:09.940
And when you have a system with this many moving parts, there is downtime.

00:20:09.940 --> 00:20:13.400
You know, people actually need to go and change the oil in the motors on the telescope

00:20:13.400 --> 00:20:16.280
and routine maintenance kinds of things like that.

00:20:16.280 --> 00:20:23.980
I don't remember our numbers exactly, but I believe it's above 75% of the time that the telescope is busy and doing science.

00:20:23.980 --> 00:20:24.800
This is more recent.

00:20:24.800 --> 00:20:29.440
It's only in the last sort of few years that the technology platform has become a bit more mature.

00:20:29.440 --> 00:20:32.660
In the early stages, it was really still sort of engineering commissioning.

00:20:32.660 --> 00:20:37.720
But I think we're using above 75% of time now for actual science observations.

00:20:37.720 --> 00:20:41.100
That's pretty impressive for considering all the pieces involved.

00:20:41.100 --> 00:20:46.100
And one of these scarabs, each one is basically assigned to an individual telescope, part of the array?

00:20:46.100 --> 00:20:46.680
Partially.

00:20:46.680 --> 00:20:50.640
So the first one will do what is called channelization.

00:20:50.640 --> 00:20:56.140
So it's much easier to operate on narrow signals of, you know, very close to a sine wave.

00:20:56.140 --> 00:20:59.960
So the telescope will sample a little bit more than a gigahertz width of bandwidth.

00:20:59.960 --> 00:21:03.580
And that will be chopped up into, you know, a few thousand channels.

00:21:03.580 --> 00:21:07.060
Then those channels will get sort of dished out.

00:21:07.060 --> 00:21:14.380
And another scarab later on will cross multiply the corresponding frequency channels from every single telescope together.

00:21:14.380 --> 00:21:16.180
So this architecture is called FX.

00:21:16.180 --> 00:21:21.320
So first frequency channelization, then cross correlation, pardon me.

00:21:21.320 --> 00:21:27.420
Before you get your ultimate, well, product which gets stored in the archive and on which then further science process.

00:21:27.420 --> 00:21:30.580
Yeah, people start to ask questions and draw graphs and things.

00:21:30.580 --> 00:21:31.340
Exactly.

00:21:31.340 --> 00:21:41.040
Yeah. So one of the parts that you employ to make this run fast is, I think you said you use CUDA cores on NVIDIA GPUs or something like that.

00:21:41.040 --> 00:21:42.300
Is that right? Do I remember this correctly?

00:21:42.300 --> 00:21:43.180
Yes, that's right.

00:21:43.180 --> 00:21:51.520
So the scarab that you showed on the screen, that's our previous but current generation correlators is working on that platform.

00:21:51.520 --> 00:21:52.900
It has its pros and cons.

00:21:52.900 --> 00:21:54.520
It's kind of a bespoke piece of hardware.

00:21:54.520 --> 00:21:59.300
It is reconfigurable, but there are not that many customers for this particular board.

00:21:59.300 --> 00:22:06.380
The problem with doing your own hardware is that it takes a lot of time, particularly if you're an organization that you want to do science.

00:22:06.380 --> 00:22:13.240
So for the next expansion of Meerkat, to build more antennas, we need more processing capability to be able to handle more bandwidth.

00:22:13.640 --> 00:22:19.480
We've kind of figured out that where they are now, GPUs can do the work.

00:22:19.480 --> 00:22:22.840
GPUs have actually been powerful enough to do the work for a while now.

00:22:22.840 --> 00:22:30.460
The problem has actually been the memory bandwidth to actually get your data from your telescope onto your GPU to do the number crunching.

00:22:30.900 --> 00:22:32.220
So for scarab, it was very easy.

00:22:32.220 --> 00:22:35.960
It has some 40 gigabit Ethernet, and that's wired straight into the FPGA.

00:22:35.960 --> 00:22:38.600
So there's no operating system taking its time.

00:22:38.600 --> 00:22:41.240
There's no PCI Express that needs to be negotiated.

00:22:41.240 --> 00:22:44.280
The data just comes straight off the network and it can do its processing.

00:22:44.280 --> 00:22:48.580
Previously, computers were not fast enough to get the numbers on and off the card.

00:22:48.980 --> 00:22:59.480
But since PCIe 4 has become a thing and sort of the GeForce RTX 3000 series cards, which we're using PCIe 4, we could do it on GPUs now.

00:22:59.480 --> 00:23:01.280
So we haven't deployed one yet.

00:23:01.280 --> 00:23:03.800
What I spoke about is the prototype that we've developed.

00:23:03.800 --> 00:23:07.120
That's part Python and part CUDA, right?

00:23:07.120 --> 00:23:08.180
Yes, yes.

00:23:08.180 --> 00:23:10.380
So the CUDA is actually quite small.

00:23:10.380 --> 00:23:14.020
As I mentioned earlier, the processing is quite simple.

00:23:14.020 --> 00:23:17.200
So there's a stage for channelizing.

00:23:17.540 --> 00:23:19.660
So that uses a piece of math called a Fourier transform.

00:23:19.660 --> 00:23:23.360
And there's been years of research going into that to make it very computationally efficient.

00:23:23.360 --> 00:23:24.040
It's very fast.

00:23:24.040 --> 00:23:27.060
The other part is simply multiplying lots of numbers together.

00:23:27.060 --> 00:23:29.340
And that's something that GPUs are really, really good at.

00:23:29.340 --> 00:23:37.440
So we've made good use of technology advances driven by things like AI and machine learning, which relies on really large matrix multiplications.

00:23:37.440 --> 00:23:40.120
So we just piggyback off of that technology.

00:23:40.120 --> 00:23:44.120
And the bonus is we don't have to develop our own hardware anymore, which is nice.

00:23:44.120 --> 00:23:45.980
And those things are only getting faster, right?

00:23:45.980 --> 00:23:53.680
If you could have done it on a 3070 or whatever, an NVIDIA 3070, then, you know, it's getting faster and going to get easier and easier as things go.

00:23:53.680 --> 00:23:58.460
You might need a small power generator to run one of those cards these days.

00:23:58.460 --> 00:23:59.480
They're kind of insane.

00:23:59.480 --> 00:24:02.600
But the 30 series are a little bit easier than the 40 series.

00:24:02.600 --> 00:24:07.100
To give you an idea, in our prototype system, we're using 3070 Ti's at the moment.

00:24:07.360 --> 00:24:09.860
And one of those GPUs does the work of four scarabs.

00:24:09.860 --> 00:24:10.280
Wow.

00:24:10.280 --> 00:24:13.000
So it's the rate that technology moves forward.

00:24:13.000 --> 00:24:16.000
To be fair, the scarab is about six or seven years old.

00:24:16.000 --> 00:24:17.460
It was revolutionary at the time.

00:24:17.460 --> 00:24:20.600
But, you know, commercial technology has moved forward a lot.

00:24:20.600 --> 00:24:21.780
Yeah, it sure has.

00:24:21.780 --> 00:24:23.600
You talked, just a bit of a sidebar.

00:24:23.600 --> 00:24:29.980
You talked about one of the challenges being getting the data in and out of the GPUs from a bandwidth perspective.

00:24:30.040 --> 00:24:39.280
Do things like systems on a chip and this Apple unified memory, where the bandwidth, the memory of the CPU is the memory of the GPU.

00:24:39.280 --> 00:24:41.480
Does that, have you guys considered playing with that?

00:24:41.480 --> 00:24:42.100
Is that interesting?

00:24:42.100 --> 00:24:44.320
We have had a look.

00:24:44.320 --> 00:24:48.660
That's, so Apple's model is something that's not really reached mainstream yet.

00:24:48.660 --> 00:24:54.640
And Apple doesn't really sell a computer in a form factor that would be amenable to employment in a data center environment.

00:24:54.640 --> 00:24:54.960
Yeah.

00:24:54.960 --> 00:24:57.340
You'd have to put a bunch of minis on their edge or something.

00:24:57.340 --> 00:24:57.660
Yeah.

00:24:57.660 --> 00:24:58.320
Exactly.

00:24:58.320 --> 00:24:58.660
Yes.

00:24:58.840 --> 00:25:03.960
So it's something that we've got an eye on, but we haven't got a usable kind of hardware prototype at this point.

00:25:03.960 --> 00:25:06.500
We're currently using AMD EPYC platforms.

00:25:06.500 --> 00:25:09.960
They have lots of PCIe lanes and lots of memory channels.

00:25:09.960 --> 00:25:15.040
So that lets you get data on and off, you know, from your network to your GPU very quickly.

00:25:15.040 --> 00:25:19.760
Advances such as direct memory addressing and other such things.

00:25:19.760 --> 00:25:21.760
I forget all the terminology now.

00:25:21.760 --> 00:25:27.060
But basically, the faster that you can get it off the, into the GPU's RAM so that the GPU can do its thing, the better.

00:25:27.060 --> 00:25:27.300
Yeah.

00:25:27.300 --> 00:25:27.360
Yeah.

00:25:27.360 --> 00:25:35.640
It's an interesting trade-off to consider because the GPUs, even in the new higher-end Apple stuff, is still quite a bit slower than NVIDIA.

00:25:36.120 --> 00:25:37.540
But the memory is instant.

00:25:37.540 --> 00:25:41.080
So like there's, you know, where does that trade-off cross the line?

00:25:41.080 --> 00:25:43.520
It's going to be interesting as this kind of architecture evolves.

00:25:43.520 --> 00:25:44.140
Yeah.

00:25:44.140 --> 00:25:45.620
We've definitely got eyes on that.

00:25:45.620 --> 00:25:47.200
And we'll see how it goes.

00:25:47.200 --> 00:25:47.460
All right.

00:25:47.460 --> 00:25:51.840
For doing the CUDA stuff, what's the Python side look like?

00:25:51.840 --> 00:25:53.760
Is that, what library is she using and stuff?

00:25:53.920 --> 00:26:01.520
So the Python, that's got to kind of do, so the GPUs are very good at crunching numbers, but, you know, they're not very good at anything else.

00:26:01.520 --> 00:26:06.180
So there's a lot of steps in that for a GPU to be able to do all of those calculations.

00:26:06.180 --> 00:26:11.460
You have a high-speed network, 100 gigabit, 200 gigabit, that's very fast.

00:26:11.540 --> 00:26:18.980
And so you need software to be able to, you know, run your network stack, receive data, and that comes into system RAM.

00:26:18.980 --> 00:26:21.600
You need to be able to DMA it into the GPU's memory.

00:26:21.600 --> 00:26:29.760
You need to be able to know when the work is finished so that you can copy the data back, packet that up in Ethernet packets again, and send it out.

00:26:29.760 --> 00:26:33.860
And so there's a lot of things that we use in Python to enable that.

00:26:33.860 --> 00:26:48.300
The first and most sort of obvious one would be a library called PyCuda, which allows you to wrap up CUDA functions in a nice Python handle and interact with your GPU in a way that's, you know, more amenable to Python code.

00:26:48.300 --> 00:26:49.080
There we go.

00:26:49.080 --> 00:26:49.720
That's the one.

00:26:49.720 --> 00:26:50.380
Yeah, very cool.

00:26:50.380 --> 00:26:59.100
So the other one, the thing that you've got to think about carefully then is coordinating your activities where your GPU is executing.

00:26:59.280 --> 00:27:04.000
PyCuda calls the streams, if you're working in an OpenCL kind of abstraction, it calls it command queues.

00:27:04.000 --> 00:27:06.820
So they work almost like threads on a computer.

00:27:06.820 --> 00:27:16.380
So you need to have some sort of way of coordinating so that when you start one calculation, you've got to make sure that the data is there, that it can work on it.

00:27:16.380 --> 00:27:20.600
And similarly, you don't want to start copying it back before the calculation is finished.

00:27:20.600 --> 00:27:23.020
So PyCuda makes this quite easy.

00:27:23.020 --> 00:27:25.740
You could use, I think, NVIDIA calls it events.

00:27:25.860 --> 00:27:34.100
But they're basically semaphores and markers to help you to coordinate between your different threads for sending, processing and receiving data from the GPU.

00:27:34.100 --> 00:27:37.340
And similarly getting it off the network and onto the network again.

00:27:37.340 --> 00:27:37.760
Yeah.

00:27:37.760 --> 00:27:38.940
PyCuda looks great.

00:27:38.940 --> 00:27:43.540
Another thing you spoke about that was pretty interesting is your use of async and await.

00:27:43.540 --> 00:27:49.300
Do all the network stuff, which I think is, it's a clearly a good choice and fits right here.

00:27:49.380 --> 00:27:53.260
But I feel like a lot of people don't consider it fast enough or good enough.

00:27:53.260 --> 00:27:54.900
Network, but not just that.

00:27:54.900 --> 00:27:55.860
Also the GPU.

00:27:55.860 --> 00:27:58.440
You have a few functions and they're running loops.

00:27:58.440 --> 00:28:03.880
So the way that we've structured our code and you can, you can, we've got, I'll send, I'll share a link with you.

00:28:03.880 --> 00:28:06.820
There's documentation in Read the Docs as well explaining this.

00:28:07.080 --> 00:28:12.220
But we have one loop that just waits for traffic to come in off the network, bundles it up.

00:28:12.220 --> 00:28:16.280
And this is kind of one of the trick things you, you need to do things in batches.

00:28:16.280 --> 00:28:22.000
If you involve the Python interpreter, every time a packet hits the neck, then it'll end up being very slow.

00:28:22.000 --> 00:28:29.480
So we have a lower level library written in C++ that batches up a whole chunk in the order of about 100 or 200 megabytes worth of data.

00:28:29.860 --> 00:28:34.040
And you use that await keyword to let you know when there's a chunk of data ready.

00:28:34.040 --> 00:28:35.440
So when there's a chunk of data ready.

00:28:35.440 --> 00:28:35.800
I see.

00:28:35.800 --> 00:28:41.220
You wait until enough is buffered up and then you pull it back on the resume or whatever.

00:28:41.220 --> 00:28:41.500
Okay.

00:28:41.500 --> 00:28:42.040
Exactly.

00:28:42.040 --> 00:28:44.220
So you, you, you mark that for upload.

00:28:44.220 --> 00:28:48.980
You put an event in the, in the stream or the command queue and let that run.

00:28:48.980 --> 00:28:51.720
And then in the next, you're busy, you're using the await.

00:28:51.720 --> 00:28:53.040
So you're waiting for that event.

00:28:53.040 --> 00:28:56.000
And when you see that, you know that the data is uploaded to the GPU.

00:28:56.000 --> 00:29:02.880
You trigger the processing, whichever processing task needs to happen and put another event and then pass it onto the next.

00:29:02.880 --> 00:29:05.240
So the third loop waits for that final event.

00:29:05.240 --> 00:29:11.840
When it sees it, it knows that the processing is done and you can initiate the copy of the GPU RAM back to the system.

00:29:11.840 --> 00:29:15.740
And then you can send the transmit that out on the network.

00:29:15.740 --> 00:29:17.800
So those two things working in tandem.

00:29:17.800 --> 00:29:18.180
Yeah.

00:29:18.180 --> 00:29:23.200
I didn't expect the GPU to have a, this async interface, but it does make a lot of sense.

00:29:23.200 --> 00:29:25.540
There's a lot of, a lot of parallels in a GPU.

00:29:25.840 --> 00:29:28.260
I don't think that it's natively in PyCuda.

00:29:28.260 --> 00:29:30.520
I think that's a wrapper that we've done around it.

00:29:30.520 --> 00:29:35.020
It's been a little while since I've touched that particular code, but there's no reason that you can't do that at all.

00:29:35.020 --> 00:29:37.520
And it's an approach that we find has been very, very useful.

00:29:37.520 --> 00:29:37.820
Okay.

00:29:37.820 --> 00:29:44.220
But your assessment overall is that async and await Pythons, asyncio has been a solid choice for this whole platform.

00:29:44.220 --> 00:29:48.000
It's been, I've seen this approach used in other places as well.

00:29:48.000 --> 00:29:53.340
Even since before asyncio has been part of core Python using things like Flask or Tornado.

00:29:53.340 --> 00:29:55.620
So the approach, it's a very good approach.

00:29:55.620 --> 00:29:56.460
It's very helpful.

00:29:56.460 --> 00:30:01.380
Debugging async stuff when it goes wrong is a little bit more tricky, but when it works, it works very, very well.

00:30:01.620 --> 00:30:02.320
Yeah, that's for sure.

00:30:02.320 --> 00:30:05.200
You get the Heisenbugs keeping in the science space.

00:30:05.200 --> 00:30:05.500
Okay.

00:30:05.500 --> 00:30:06.280
So.

00:30:06.280 --> 00:30:07.160
Exactly.

00:30:07.340 --> 00:30:12.460
Quick audience question, I think it's going to be interesting before we move on to the testing of this whole system.

00:30:12.460 --> 00:30:20.360
So out in the audience, Slalwak asks, what do you think about simple distributed radio astronomy experiments for like citizen science?

00:30:20.360 --> 00:30:21.380
Are they possible?

00:30:21.380 --> 00:30:22.980
That's a very good question.

00:30:22.980 --> 00:30:24.140
Yes, they are.

00:30:24.140 --> 00:30:29.680
It's possible to do amateur radio astronomy using a relatively affordable STR dongles.

00:30:29.680 --> 00:30:31.780
STR standing for software defined radio.

00:30:31.780 --> 00:30:33.700
It's been a little while since I've looked at this.

00:30:33.700 --> 00:30:36.540
I must confess, as I've mentioned earlier, since I do this professionally,

00:30:36.700 --> 00:30:38.660
I don't bother with it that much as a hobby anymore.

00:30:38.660 --> 00:30:40.500
You have a square kilometer array you're building.

00:30:40.500 --> 00:30:41.940
You don't worry too much about it.

00:30:41.940 --> 00:30:43.840
I've got a big telescope at work.

00:30:43.840 --> 00:30:45.060
I don't need a small one at home.

00:30:45.060 --> 00:30:46.160
You can do science.

00:30:46.160 --> 00:30:51.840
It's difficult in most practical cases because most people live in cities where there's a lot of interference.

00:30:51.840 --> 00:30:52.240
Yeah.

00:30:52.240 --> 00:30:53.560
But it definitely can be done.

00:30:53.560 --> 00:30:59.820
One of the fun projects that I've seen has been using a satellite dish like what you would connect satellite TV,

00:30:59.820 --> 00:31:03.580
but with a little bit of electronic knowledge and you don't need a degree.

00:31:03.580 --> 00:31:05.720
You can just be on a hobbyist level to do that.

00:31:05.800 --> 00:31:07.660
You can build a square law receiver.

00:31:07.660 --> 00:31:09.900
So it's very much just, is there signal on?

00:31:09.900 --> 00:31:10.420
Isn't there?

00:31:10.420 --> 00:31:12.460
You're not going to be decoding any TV streams.

00:31:12.460 --> 00:31:15.700
But you can measure, for example, the temperature of the sun using this.

00:31:15.700 --> 00:31:22.200
And you can measure its angular dimensions by simply pointing it and then letting the sun drift through a few times.

00:31:22.200 --> 00:31:22.700
Yeah.

00:31:22.700 --> 00:31:24.920
So there are fun projects that can be done.

00:31:24.920 --> 00:31:28.560
As to say whether it can be useful as citizen science.

00:31:28.560 --> 00:31:33.720
In other words, useful from a scientific point of view over more than just something interesting to do.

00:31:33.720 --> 00:31:35.000
I'd have to go and have a look.

00:31:35.180 --> 00:31:36.360
I'm not 100% sure.

00:31:36.360 --> 00:31:39.660
It's very difficult to get meaningful results without very, very expensive equipment.

00:31:39.660 --> 00:31:42.940
That's why we've got such expensive facilities being built.

00:31:45.060 --> 00:31:48.160
This portion of Talk Python To Me is brought to you by Sentry.

00:31:48.160 --> 00:31:51.040
How would you like to remove a little stress from your life?

00:31:51.040 --> 00:31:57.020
Do you worry that users may be encountering errors, slowdowns, or crashes with your app right now?

00:31:57.020 --> 00:32:00.080
Would you even know it until they sent you that support email?

00:32:00.480 --> 00:32:04.840
How much better would it be to have the error or performance details immediately sent to you,

00:32:04.840 --> 00:32:10.480
including the call stack and values of local variables and the active user recorded in the report?

00:32:10.480 --> 00:32:13.900
With Sentry, this is not only possible, it's simple.

00:32:13.900 --> 00:32:17.460
In fact, we use Sentry on all the Talk Python web properties.

00:32:17.460 --> 00:32:24.020
We've actually fixed a bug triggered by a user and had the upgrade ready to roll out as we got the support email.

00:32:24.020 --> 00:32:26.000
That was a great email to write back.

00:32:26.000 --> 00:32:29.380
Hey, we already saw your error and have already rolled out the fix.

00:32:29.600 --> 00:32:30.820
Imagine their surprise.

00:32:30.820 --> 00:32:33.020
Surprise and delight your users.

00:32:33.020 --> 00:32:37.080
Create your Sentry account at talkpython.fm/sentry.

00:32:37.080 --> 00:32:40.520
And if you sign up with the code talkpython, all one word,

00:32:40.520 --> 00:32:44.100
it's good for two free months of Sentry's business plan,

00:32:44.100 --> 00:32:48.760
which will give you up to 20 times as many monthly events as well as other features.

00:32:48.760 --> 00:32:53.160
Create better software, delight your users, and support the podcast.

00:32:53.160 --> 00:32:58.120
Visit talkpython.fm/sentry and use the coupon code talkpython.

00:32:58.720 --> 00:33:03.840
One thing you did point out, I can't remember which in the two talks it was,

00:33:03.840 --> 00:33:09.060
but you did say that you can go and rent at least optical telescopes remotely, right?

00:33:09.060 --> 00:33:09.560
Yes.

00:33:09.560 --> 00:33:15.440
Most optical telescopes are operated remotely, but a lot of ones that are commercially available as well,

00:33:15.440 --> 00:33:20.200
head over to telescopes.com, and you can buy ones that can be electronically controlled.

00:33:20.200 --> 00:33:24.020
And those you can do interesting, is it telescopes or telescope.com?

00:33:24.020 --> 00:33:24.320
Wow.

00:33:24.320 --> 00:33:25.320
Yeah, that's the one.

00:33:25.320 --> 00:33:27.380
You can buy ones that are electronically controlled.

00:33:27.380 --> 00:33:27.680
Okay.

00:33:27.680 --> 00:33:29.760
Those can actually be useful for citizen science.

00:33:29.760 --> 00:33:36.080
There's a lot of, for example, astronomy organizations that do regular observations of variable stars or winery stars,

00:33:36.080 --> 00:33:38.960
and they rely a lot on data submitted by amateurs.

00:33:38.960 --> 00:33:43.640
While any particular observation will not necessarily be that useful,

00:33:43.640 --> 00:33:49.660
but in aggregate, thousands of these observations are very helpful for doing the science that they would be doing then.

00:33:49.660 --> 00:33:51.860
That could typically be run by university faculty,

00:33:51.860 --> 00:33:57.960
and over, you know, they would aggregate these observations over long periods of time from different locations to...

00:33:57.960 --> 00:33:59.360
Yeah, that sounds like a cool research project.

00:33:59.360 --> 00:34:02.080
...to draw some scientific conclusions about what's happening with these stars.

00:34:02.080 --> 00:34:02.460
Very neat.

00:34:02.500 --> 00:34:03.140
It's a good question, though.

00:34:03.140 --> 00:34:04.760
Yeah, it is. Indeed. Thanks.

00:34:04.760 --> 00:34:08.180
So let's talk about the testing side.

00:34:08.180 --> 00:34:10.080
From my sort of engineering background,

00:34:10.080 --> 00:34:13.740
one of the sort of key questions that you've got to ask as an engineer is,

00:34:13.740 --> 00:34:16.440
if you have specifications for a system to build, to design,

00:34:16.440 --> 00:34:20.220
at what point do you know that it's doing the thing that it's expected to do?

00:34:20.220 --> 00:34:22.740
So you've got a certain set of user requirements.

00:34:22.740 --> 00:34:27.900
The user needs to be able to have this level of sensitivity and this level of bandwidth and, you know, accuracy.

00:34:27.900 --> 00:34:30.200
Less than this much noise or something, yeah?

00:34:30.200 --> 00:34:31.880
Exactly. In terms of hard numbers.

00:34:32.300 --> 00:34:37.700
So you need to have some sort of way to prove that the system that you've designed and built is going to meet those specifications.

00:34:37.700 --> 00:34:40.880
And so testing is a fundamental part of that.

00:34:40.880 --> 00:34:45.840
Sometimes you can prove by analysis, you know, just by using maths and showing, you know,

00:34:45.840 --> 00:34:47.380
this is what the system is designed to do.

00:34:47.380 --> 00:34:51.560
But the first prize is if you can run a test and say, look, we've got a controlled set of inputs,

00:34:51.560 --> 00:34:56.560
we can measure the outputs, and we can determine from this that the system is doing what we said it is doing,

00:34:56.880 --> 00:34:58.540
and how well it is, how well it is.

00:34:58.540 --> 00:35:02.680
So, you know, what the noise level is or what the sensitivity is, whatever the case is.

00:35:02.840 --> 00:35:08.980
And that's something that is often a little bit neglected in scientific projects, particularly astronomy.

00:35:09.120 --> 00:35:10.740
That's the one that I've got experience with.

00:35:10.740 --> 00:35:12.520
Other fields I've seen as well.

00:35:12.520 --> 00:35:16.020
Often physicists and astronomers are very, very clever, and they're trained in a lot of fields.

00:35:16.020 --> 00:35:19.580
They tend to build their own instruments and hardware and write their own software.

00:35:19.580 --> 00:35:22.820
It has a kind of amateurish aspect to it sometimes.

00:35:22.820 --> 00:35:24.860
Not universally, but this is the tendency.

00:35:25.020 --> 00:35:29.160
Until it's more or less doing what the researcher wants, and then he carries on.

00:35:29.160 --> 00:35:32.880
So many a software project has been written by a PhD student.

00:35:32.880 --> 00:35:38.000
He's generated some results and, you know, published his paper, gotten his PhD.

00:35:38.000 --> 00:35:43.340
That's very difficult to scrutinize because the code is written by someone and the logic lives in someone's head.

00:35:43.340 --> 00:35:49.880
And so I'm kind of keen on this concept of testing because I think it adds a level of rigor and transparency to the scientific process.

00:35:49.880 --> 00:36:02.740
Because if I've got tests in place, then anyone can come along and look at how I've tested my instrument and, you know, criticize or evaluate whether it actually does what I say it does when I publish my research.

00:36:02.740 --> 00:36:05.280
So I think the concept is really important.

00:36:05.280 --> 00:36:06.100
I do too.

00:36:06.100 --> 00:36:16.400
And it's in open source, one of the important signals that people use when they go and look at a package they might consider, like PyCuda or Pandas or whatever,

00:36:16.980 --> 00:36:21.720
is does this thing have tests as part of its design, right?

00:36:21.720 --> 00:36:27.720
If I'm going to depend on somebody else's library or if I'm a maintainer and I create a library and someone's going to send me a PR,

00:36:27.720 --> 00:36:33.180
how do I know whether their changes that they're suggesting to me broke something I didn't see coming, right?

00:36:33.180 --> 00:36:42.680
And having unit tests or some kind of test typically driven with pytest for Python is a really important, not just supporting pillar of that project,

00:36:42.780 --> 00:36:48.840
but also a signal to others from the outside, like this thing, people care about this, they've verified it, they want to keep it strong.

00:36:48.840 --> 00:36:54.900
And it sounds to me like this might also be really important for science in the same way.

00:36:54.900 --> 00:36:59.860
You talked about people coming to review your work or to try to reproduce it.

00:36:59.920 --> 00:37:08.540
And if they see the test and they can run the test, it communicates something additional rather than just, well, I thought a lot about it and here's my graph.

00:37:08.540 --> 00:37:09.460
Exactly, yes.

00:37:09.460 --> 00:37:16.140
We want to do groundbreaking science and we want to be able to say that when we make observations that what we're seeing is real science

00:37:16.140 --> 00:37:20.160
and it's not just some sort of anomaly that we found in the telescope signal chain.

00:37:20.260 --> 00:37:30.660
And the presence of good tests helps with that because then, you know, we have rigorous testing that we can say, look, this is the performance characteristics of our system.

00:37:30.660 --> 00:37:34.820
You know, it gives a little bit of extra confidence in your scientific results that way.

00:37:34.820 --> 00:37:35.180
Indeed.

00:37:35.180 --> 00:37:39.180
So how does this look different than like testing Flask or something, right?

00:37:39.180 --> 00:37:46.780
Because it's not exactly the same and you maybe are leaning on it a little bit more to communicate more information, not just pass or fail.

00:37:46.780 --> 00:37:47.940
There are a few things.

00:37:47.940 --> 00:37:53.520
In one sense, we do use unit tests in the same way that a lot of open source projects do.

00:37:53.520 --> 00:37:59.440
Just, you know, does each individual component of my module do the thing that I've designed it to do?

00:37:59.440 --> 00:38:06.500
But if you go a little bit beyond that, the same sort of philosophy and application can be applied to systems as a whole.

00:38:06.500 --> 00:38:16.840
If you have a complicated system with a lot of different parts talking to each other, it can be tricky to a change that you make might not break if you look at it in isolation.

00:38:17.260 --> 00:38:19.120
But does those interfaces still work?

00:38:19.120 --> 00:38:23.040
If you're unit testing something, often you mock out whatever's at the end.

00:38:23.040 --> 00:38:29.220
So you pretend that you'll get a real response from a website when you do an API call.

00:38:29.220 --> 00:38:34.100
But if you've touched the code that actually handles that API call, then your unit test is not going to pick that up.

00:38:34.460 --> 00:38:40.240
So we've got a relatively rigorous process for what one might call integration testing.

00:38:40.240 --> 00:38:50.980
So an entire system gets set up in a simulated environment, but an input like it might get from a real telescope and, you know, the ability to watch that output.

00:38:50.980 --> 00:38:52.760
And so we do that on a regular basis.

00:38:52.760 --> 00:38:58.840
We spin up an entire correlator in a system in the lab, give it a deterministic input.

00:38:59.020 --> 00:39:04.520
And so we can measure the output and, you know, determine whether or not it meets the criteria.

00:39:04.520 --> 00:39:05.200
Yeah, cool.

00:39:05.200 --> 00:39:16.280
Is this like a software emulator in Docker or is this an actual one of your 1U FPGA things that's dedicated to this integration testing?

00:39:16.400 --> 00:39:17.120
It can be both.

00:39:17.120 --> 00:39:18.140
It can be both.

00:39:18.140 --> 00:39:23.220
So we've used the same approach to testing the old Scarab correlator.

00:39:23.220 --> 00:39:26.600
One of the Scarabs can be configured to emulate a telescope.

00:39:26.600 --> 00:39:34.060
So it can produce a signal similar to what a telescope might be, except not having astronomical signals in the data.

00:39:34.060 --> 00:39:43.500
It would have a deterministic signal such as, you know, a normal frequency tone or just white noise, depending on what kind of test we want to run on the correlator itself.

00:39:43.500 --> 00:39:45.440
You don't replay the wow signal to it?

00:39:45.440 --> 00:39:49.760
We could, but it's faster just to generate signals.

00:39:49.760 --> 00:39:52.520
You're not going to get with a strongly deterministic signal.

00:39:52.520 --> 00:39:57.360
In other words, if you know exactly what you're putting in, you can see what you're getting out as well.

00:39:57.360 --> 00:40:01.140
The wow signal, not as useful for determining the noise level.

00:40:01.140 --> 00:40:02.060
Yes, exactly.

00:40:02.060 --> 00:40:03.340
More fun, not as useful.

00:40:03.340 --> 00:40:03.640
Yeah.

00:40:04.600 --> 00:40:16.080
So one of the things you did is you changed some of the output from pytest to be more representative of talking about how you've met your requirements and stuff.

00:40:16.080 --> 00:40:17.880
Maybe tell folks about how that works.

00:40:17.880 --> 00:40:20.000
Yeah, that was an interesting exercise.

00:40:20.000 --> 00:40:26.220
Soraya uses a process called systems engineering, which was developed in Bell Labs, I think in the 40s.

00:40:26.220 --> 00:40:27.260
It was quite a while ago.

00:40:27.260 --> 00:40:30.620
And it's been strongly influenced by the sort of military processes.

00:40:31.160 --> 00:40:38.080
People in a software environment would recognize it as like a waterfall pattern where you'd have a big design up front.

00:40:38.080 --> 00:40:47.580
So you'd have a lengthy analysis of what the requirements of your system are and, you know, allocated different performance characteristics to different components.

00:40:47.580 --> 00:40:55.540
And once you've done with the design, you need reams and reams of documentation to prove that your design meets the specifications as well.

00:40:55.540 --> 00:40:59.440
Graphs, tables, pictures, numbers, all of these kinds of things.

00:40:59.440 --> 00:41:04.160
pytest and other packages, there are other ones, but pytest is the one that we've used.

00:41:04.160 --> 00:41:05.860
It has a much more simple output.

00:41:05.860 --> 00:41:08.540
In other words, it'll give you lots of details.

00:41:08.540 --> 00:41:10.960
If something goes wrong, it'll give you a stack trace.

00:41:10.960 --> 00:41:17.560
It'll give you, you know, debug information of what the variables were at the time that there was a problem or that the assertion didn't meet.

00:41:17.560 --> 00:41:18.800
But if everything passes.

00:41:18.800 --> 00:41:20.200
It's all green.

00:41:20.200 --> 00:41:21.340
Okay, we're good to go.

00:41:21.340 --> 00:41:26.360
You know, like, okay, the sensitivity is better than X, but how much better, you know?

00:41:26.360 --> 00:41:29.160
And, you know, how does that vary with frequency?

00:41:29.160 --> 00:41:33.600
These kinds of things, what we'd like to know and what we'd like to be able to present to the various stakeholders

00:41:33.600 --> 00:41:35.520
that are interested in the performance of the telescope.

00:41:35.520 --> 00:41:36.620
We have a system.

00:41:36.620 --> 00:41:38.740
Okay, you need to zoom out a little bit there.

00:41:38.740 --> 00:41:47.120
And for those of you who are watching on YouTube, I do apologize for the, it's difficult to put code on a screen in a way that's not going to put your audience to sleep.

00:41:47.120 --> 00:41:51.060
Yeah, and I just grabbed this off of your talk just so we had something to, like, kind of be concrete about.

00:41:51.600 --> 00:41:55.680
You have this interesting reporting aspect that runs along with your test for sure.

00:41:55.880 --> 00:41:56.120
Yes.

00:41:56.120 --> 00:41:59.000
So pytest has a plugin called Report Log.

00:41:59.380 --> 00:42:08.140
And that, if you sort of squint at it and look a little bit carefully, it allows you to kind of record metadata as you're going along.

00:42:08.140 --> 00:42:10.260
So things that are happening in your test.

00:42:10.260 --> 00:42:12.380
So there's several things happening at once here.

00:42:12.380 --> 00:42:17.460
And maybe if I could just take a step back, this test that you've got up is the test of linearity.

00:42:17.720 --> 00:42:22.740
So what does that mean is that if I put in a signal, X, and I get an output, Y.

00:42:22.740 --> 00:42:25.820
So if I put in a signal, 2X, I should get 2Y as the output.

00:42:25.820 --> 00:42:28.060
So they should be directly proportional to the other.

00:42:28.060 --> 00:42:32.740
And if there's, if they're not, then there's a non-linearity of some sort in the system.

00:42:32.740 --> 00:42:36.600
No system is perfectly linear, so there will be some sort of margin for error.

00:42:36.600 --> 00:42:40.100
We don't have a specific spec on this particular linearity test.

00:42:40.100 --> 00:42:42.620
It's a quick one to run because it takes only a few minutes.

00:42:42.620 --> 00:42:46.960
And it can give us a sort of a first eyeball of, are things working as we expect them to do.

00:42:47.300 --> 00:42:53.540
pytest, if for those of you who are not familiar with it, the tests are written in the same syntax as Python functions,

00:42:53.540 --> 00:42:57.400
except where the inputs of the function are either parameters or fixtures.

00:42:57.400 --> 00:43:01.640
So parameters can be, if there's a parameter space over which your test will run.

00:43:01.640 --> 00:43:05.980
So in our case, for example, different numbers of frequency channels, different numbers of antennas.

00:43:05.980 --> 00:43:07.560
This one isn't parameterized.

00:43:07.560 --> 00:43:09.220
It uses only a few fixtures.

00:43:09.220 --> 00:43:16.440
The fixtures are things to ensure that you have a test that is reproducible.

00:43:16.880 --> 00:43:20.400
So in this case, the correlator fixture gives us a correlator.

00:43:20.400 --> 00:43:23.120
It spins up in the test cluster that we've got in our lab.

00:43:23.520 --> 00:43:28.480
And it gives, so the typing today gives you the hint that we're getting a remote control.

00:43:28.480 --> 00:43:32.680
So that little correlator object there gives us the ability to communicate with it and control it.

00:43:32.680 --> 00:43:34.940
The next one is a receiver.

00:43:34.940 --> 00:43:42.900
So that's, you know, what if a correlator is running, you need to be able to receive what it's outputting so that you can compare it against whatever the spec is.

00:43:42.980 --> 00:43:45.060
And the third one is the PDF report.

00:43:45.060 --> 00:43:47.280
So the name is a bit of a misnomer.

00:43:47.280 --> 00:43:52.140
Initially, I, so that little fixture is written using module called PyLatex.

00:43:52.140 --> 00:43:53.980
So shout out, shout out to the authors of that one.

00:43:53.980 --> 00:43:54.900
It's very useful.

00:43:55.400 --> 00:44:01.440
And the best way to generate, you can generate PDFs directly from Python, but it's very low level and it's difficult.

00:44:01.440 --> 00:44:07.180
So we use LaTeX as a kind of intermediate step to do the typesetting and PDF generation for that.

00:44:07.180 --> 00:44:16.580
So with that, you can focus on actually just getting the content and then use LaTeX to arrange things and typeset and make sure that there's, you know, the lines wrap over and what have you.

00:44:16.580 --> 00:44:17.840
Ultimately, they're there.

00:44:17.840 --> 00:44:21.620
The output will be a PDF with a report of the test as it's run.

00:44:21.620 --> 00:44:23.380
So this is the configuration that we ran.

00:44:23.380 --> 00:44:24.500
These are the steps that we followed.

00:44:24.500 --> 00:44:25.760
And these are our results.

00:44:25.760 --> 00:44:28.900
Version two of that uses an intermediate product.

00:44:28.900 --> 00:44:34.960
So instead of outputting a PDF straight away, we just serialize the data and put it into a little JSON dictionary.

00:44:34.960 --> 00:44:39.120
The reason for that is sometimes in LaTeX, you've got to tweak your formatting or something like that.

00:44:39.120 --> 00:44:44.120
And it would be nice to not have to rerun the entire test just to change the font or, you know, update a heading.

00:44:44.120 --> 00:44:46.120
And so there's actually an intermediate step.

00:44:46.120 --> 00:44:51.320
And then there's another step just later that takes that JSON, parses it and generates the PDF later.

00:44:51.320 --> 00:44:51.560
Right.

00:44:51.560 --> 00:44:53.800
Well, you can also ask questions about it, right?

00:44:53.800 --> 00:44:59.940
You can analyze the test JSON and, you know, maybe draw averages over time.

00:44:59.940 --> 00:45:04.000
Or here's how much it's varied as we've evolved our system, right?

00:45:04.000 --> 00:45:05.280
Not just pass, fail.

00:45:05.280 --> 00:45:06.400
What did this one look like?

00:45:06.400 --> 00:45:07.760
So JSON's pretty good.

00:45:08.080 --> 00:45:15.100
When you incorporate this with other CI, CD tools, you get up actions or Jenkins or whatever the case is, you can do this repeatedly.

00:45:15.100 --> 00:45:20.640
And then you have records of over time, you know, how your system has evolved versus, you know, what changes you've made.

00:45:20.640 --> 00:45:27.120
And it makes it much easier to reason about and, you know, understand the performance of your system and how it changes over time.

00:45:27.360 --> 00:45:28.020
I think that's really neat.

00:45:28.020 --> 00:45:30.520
I don't see that being done very often at all.

00:45:30.520 --> 00:45:38.060
And I think it's easy to look at this little bit of code that you put up in your presentation and say, oh, okay, well, that's pytest.

00:45:38.060 --> 00:45:39.200
And now here's a fixture and so on.

00:45:39.200 --> 00:45:48.120
But, like, if you think about what those fixtures are doing, one of those fixtures maybe is controlling one of those 1U FPGA machines to set it up, right?

00:45:48.120 --> 00:45:55.120
And then the other one is in our, there's a lot of power and stuff going on with these little, you know, here's a variable we call the correlator.

00:45:55.860 --> 00:45:56.300
Exactly.

00:45:56.300 --> 00:45:56.880
Yeah.

00:45:56.880 --> 00:45:57.860
So you're right.

00:45:57.860 --> 00:46:01.960
There is a lot of code hidden behind here, but it's code that you're going to run every time.

00:46:01.960 --> 00:46:05.020
So it doesn't matter what test you're doing, you're going to want to spin up a correlator.

00:46:05.020 --> 00:46:09.320
And whether it's, you know, an FPGA or a GPU doesn't really matter.

00:46:09.320 --> 00:46:15.880
You want to run through the same sort of steps so that your test is repeatable and that the result corresponds to the input that you give it.

00:46:15.880 --> 00:46:24.240
And so the pytest fixtures are great for that because once they allow you to get the boring stuff done, once you're confident that you're doing it right, then you can just keep doing it.

00:46:24.360 --> 00:46:26.780
You use the same correlator fixture for every test.

00:46:26.960 --> 00:46:34.920
And if there's an update, if something changes, if there's a change to the hardware that you need or the protocol that you communicate with them, then you can update it just in one place.

00:46:34.920 --> 00:46:38.220
And all your tests will benefit from that update straight away.

00:46:38.220 --> 00:46:38.480
Yeah.

00:46:38.480 --> 00:46:40.700
It's a very powerful aspect of pytest.

00:46:41.560 --> 00:46:43.160
You've taken it to quite a level here.

00:46:43.160 --> 00:46:53.240
One of the things that I kind of wanted to, when I did the talk last year that I wanted to put forward is that, you know, these concepts of testing, you can apply them to real world systems as well.

00:46:53.240 --> 00:46:57.500
So if you can talk to it, then you can use pytest to test it.

00:46:57.500 --> 00:47:07.740
If you can talk to it over the network, a serial cable or, you know, USB or something like that, you can test actual hardware, make it do things, you know, so that you can qualify it.

00:47:07.740 --> 00:47:16.880
It doesn't, it's not just restricted to, you know, little toy pieces of software, you know, your flask or your tornado or abstract conceptual things that live in the cloud somewhere.

00:47:16.880 --> 00:47:18.860
It can actually translate to real world things.

00:47:18.980 --> 00:47:19.040
Yeah.

00:47:19.040 --> 00:47:28.160
People say when they talk about tests and stuff, they say, well, look, it is, sometimes I say it is your documentation or it is the way you verify things are working.

00:47:28.160 --> 00:47:37.920
But when you get to the engineering and the science level and you're trying to verify physical things and stuff, it's cool to see how far you can push it to maybe even answer that question better.

00:47:37.920 --> 00:47:38.520
Right.

00:47:38.600 --> 00:47:40.760
Like with this reporting, for example, over time.

00:47:40.760 --> 00:47:43.480
I think it makes it more transparent as well.

00:47:43.480 --> 00:47:49.040
We, in the open source community, we like to quote Linus's law a lot, we say, with enough eyeballs, all bugs are shallow.

00:47:49.040 --> 00:47:52.280
But if we're honest with ourselves, like not everyone is going to go and read the code.

00:47:52.280 --> 00:47:52.520
Yeah.

00:47:52.600 --> 00:48:05.300
But on the other hand, if you, if you can see, you know, a graph of, you know, this is the frequency response of the system, that makes it much easier for interested parties to actually interrogate and say, look, you know, is this good or is it lacking in some aspects?

00:48:05.300 --> 00:48:15.900
So from that point of view, I think it just increases the transparency and allows not only yourself, but the sort of the general, the wider scientific community to have more confidence in the, in the performance of your telescope.

00:48:15.900 --> 00:48:17.900
Makes it more approachable too, I think.

00:48:17.900 --> 00:48:18.280
Exactly.

00:48:18.500 --> 00:48:18.620
Yeah.

00:48:18.620 --> 00:48:23.560
People maybe wouldn't read a unit test and what the heck are they supposed to make out of it anyway?

00:48:23.560 --> 00:48:28.060
You know, they may well look at a graph that was generated by the unit test, right?

00:48:28.060 --> 00:48:28.520
Exactly.

00:48:28.520 --> 00:48:28.840
Yeah.

00:48:28.840 --> 00:48:39.400
And this is, it's much more, it's much easier for me to parse as well because, you know, I get to the office in the morning and, you know, the CI run is done overnight and I can see at a glance, you know, are things working the way that they should?

00:48:39.400 --> 00:48:39.700
Yeah.

00:48:39.700 --> 00:48:40.020
Cool.

00:48:40.020 --> 00:48:46.620
What has been the reaction from other scientists and engineers when you talk to them about this?

00:48:46.620 --> 00:48:48.220
How's this perceived more broadly?

00:48:48.400 --> 00:48:49.680
It's been relatively positive.

00:48:49.680 --> 00:48:56.520
Scientists want to know when they can get time on the telescope and then I have to tell them, well, there's a committee that evaluates scientific proposals.

00:48:56.520 --> 00:48:58.480
We can't short circuit that, unfortunately.

00:48:58.480 --> 00:49:14.600
Beercat has gotten a lot of attention from, well, scientists who are interested in radio astronomy, particularly fields like pulsars and another of our sort of clients is possibly the wrong word, but is the project called Breakthrough Listen.

00:49:14.740 --> 00:49:16.700
If you've heard of SETI, it's the same crowd.

00:49:16.700 --> 00:49:16.980
Okay.

00:49:16.980 --> 00:49:19.480
That are trying to search for extraterrestrial intelligence.

00:49:19.480 --> 00:49:22.560
Sometimes they're interested in these kinds of things, sometimes not.

00:49:22.560 --> 00:49:25.920
Often it's a much shorter question of like, is it working and can I get some of the data?

00:49:25.920 --> 00:49:26.220
Yeah.

00:49:26.360 --> 00:49:33.980
If the answer of those two is yes and they start looking at the data, then, you know, this performance figures and test results are sometimes more interesting to them.

00:49:33.980 --> 00:49:34.200
Sure.

00:49:34.340 --> 00:49:36.020
But generally, generally, it's quite well received.

00:49:36.020 --> 00:49:37.940
It seems like a cool idea to me.

00:49:37.940 --> 00:49:44.040
Do you have, you know, time on telescopes is really precious and rare, hard to come by.

00:49:44.040 --> 00:49:48.160
The more powerful the telescope, I imagine, the more contention there is for that time.

00:49:48.400 --> 00:49:57.860
Is there a bunch of simulation and software and things that people can hand out to these folks that they can work with beforehand so they become more prepared?

00:49:58.360 --> 00:49:58.920
Yes.

00:49:58.920 --> 00:50:04.280
And, well, it mostly consists, it depends on what you're interested in.

00:50:04.280 --> 00:50:16.100
Meerkat is an interesting architecture in that there are some of the clients that have hardware right on site that are subscribing to data and processing it in real time and Breakthrough Listen is one of them.

00:50:16.100 --> 00:50:18.800
You know, they're interested in very, very fast transient stuff.

00:50:18.800 --> 00:50:21.800
Other scientists are more, they're not in as much of a hurry.

00:50:22.180 --> 00:50:28.500
They're more interested in the end result, the output of the correlator that has been through several stages of pre-processing.

00:50:28.500 --> 00:50:30.560
And it depends on what kind of science that they're doing.

00:50:30.560 --> 00:50:37.600
And so, as with most telescopes, certainly, but scientific instruments in general, we keep all of the data from observations of past.

00:50:37.600 --> 00:50:39.500
Typically, there's an embargo on that.

00:50:39.500 --> 00:50:48.340
So it could be a period of 12 to 24 months to allow the originating scientist of the observation enough time to do his analysis and publish his papers.

00:50:48.680 --> 00:50:54.160
But once that is lifted, then that data is available to basically anyone who wants to use it.

00:50:54.160 --> 00:50:59.600
So all they need to do is contact us and we can give them access to historical data sets.

00:50:59.600 --> 00:51:04.100
And they can begin to test their algorithms on actual historical observations.

00:51:04.100 --> 00:51:05.260
Yeah, that seems good.

00:51:05.260 --> 00:51:05.680
Excellent.

00:51:05.680 --> 00:51:06.220
All right.

00:51:06.220 --> 00:51:10.040
Quick question, follow-up question here before we kind of wrap things up.

00:51:10.040 --> 00:51:12.040
James asks, what happens to the raw data?

00:51:12.040 --> 00:51:15.000
Talking about coming out of the correlator, I suppose, received.

00:51:15.120 --> 00:51:20.080
How much of it is captured and stored versus processed down and then storing the result?

00:51:20.080 --> 00:51:20.400
Okay.

00:51:20.400 --> 00:51:26.720
So, as I mentioned earlier, each telescope generates data at about 35 gigabits per second.

00:51:26.720 --> 00:51:29.700
That is impractical to store.

00:51:29.700 --> 00:51:34.220
We have logic on site that will buffer up a few seconds worth of data.

00:51:34.220 --> 00:51:37.840
And then they have algorithms that are searching through it for interesting things.

00:51:38.220 --> 00:51:41.700
And if there's something that they notice, there's a mechanism to dump that to disk.

00:51:41.700 --> 00:51:43.300
So just a few seconds at a time.

00:51:43.300 --> 00:51:44.900
And that happens a few times a year.

00:51:44.900 --> 00:51:48.560
Generally, the most interesting pieces are a little bit more downstream.

00:51:48.560 --> 00:51:53.540
So 35 gigabits per second times 64 is a large number.

00:51:53.540 --> 00:51:59.120
So that's north of two terabits per second that the antennas themselves generate.

00:51:59.120 --> 00:52:03.500
The output of a 64 antenna correlator is about four gigabits per second.

00:52:03.500 --> 00:52:08.540
You could ingest that on a Mac mini if you somehow had a USB 4 to...

00:52:08.540 --> 00:52:11.400
Just somewhere there to keep plugging and unplugging drives really quickly, yeah.

00:52:11.400 --> 00:52:12.100
To ethernet.

00:52:12.100 --> 00:52:13.620
Yeah, you'd need to do it pretty quickly.

00:52:13.620 --> 00:52:14.720
But that is practical.

00:52:14.720 --> 00:52:17.000
That we have a storage cluster.

00:52:17.000 --> 00:52:20.180
So we have one on site in the desert in South Africa.

00:52:20.180 --> 00:52:22.500
It's relatively small, only about five petabytes.

00:52:22.500 --> 00:52:23.940
But that acts as a cache.

00:52:24.020 --> 00:52:29.560
And then there is a fiber link to Cape Town where we have a data center with a much larger archive.

00:52:29.560 --> 00:52:31.300
That uses an object store.

00:52:31.300 --> 00:52:33.000
I believe it's Ceph.

00:52:33.000 --> 00:52:34.520
It was also an open source thing.

00:52:34.520 --> 00:52:37.840
And I'm speaking a little bit outside of my expertise now.

00:52:37.840 --> 00:52:39.820
But that data is retained then.

00:52:39.820 --> 00:52:43.820
Well, so far in perpetuity, we haven't gotten to the stage where we start deleting old data yet.

00:52:43.820 --> 00:52:46.060
So we've got all of the observations that we've ever run.

00:52:46.060 --> 00:52:47.820
And they range in size.

00:52:47.820 --> 00:52:49.320
It depends on the observation.

00:52:49.320 --> 00:52:50.840
But sometimes they're a few gigabytes.

00:52:50.840 --> 00:52:54.080
And sometimes they're sort of many terabytes in size.

00:52:54.080 --> 00:52:55.060
Yeah, it's a lot of data.

00:52:55.060 --> 00:52:57.420
You wouldn't store the two terabit per second, though.

00:52:57.420 --> 00:52:58.060
That's too much.

00:52:58.060 --> 00:52:59.860
I don't know what we're doing with that.

00:52:59.860 --> 00:53:01.700
That's one of the reasons that the correlator exists.

00:53:01.700 --> 00:53:04.640
To sort of get that down to a manageable, useful level.

00:53:04.640 --> 00:53:05.540
Yeah, indeed.

00:53:05.540 --> 00:53:06.240
All right.

00:53:06.240 --> 00:53:11.040
Well, anything else you want to add that we haven't talked about briefly about this testing side of things?

00:53:11.040 --> 00:53:12.220
Have we covered it pretty well?

00:53:12.220 --> 00:53:18.300
The one thing that we haven't kind of talked about is we talked a little bit about earlier about how critical the performance of this is.

00:53:18.420 --> 00:53:23.920
And one of the things that testing has really enabled is for us to optimize the performance of the system.

00:53:23.920 --> 00:53:26.160
And in a way that's, I think, not immediately obvious.

00:53:26.160 --> 00:53:36.720
If you have a first naive implementation of your signal processing algorithm that's easy to read, easy to reason about, it's not likely to be the fastest possible way to process the data.

00:53:36.720 --> 00:53:37.900
But it's good to have that.

00:53:37.900 --> 00:53:40.600
And then once you have that, then you can write a test for it.

00:53:40.600 --> 00:53:45.760
So you can compare a known input to a known output and see if your maths is correct.

00:53:45.760 --> 00:53:52.860
That way, when you iterate, perhaps we can change the memory access patterns or, you know, improve the coordination between the threads.

00:53:52.860 --> 00:53:56.220
It's very easy when you do that to make a mistake and start messing up your results.

00:53:56.220 --> 00:54:00.160
But when you have a unit test and you start messing up results, it can catch it straight away.

00:54:00.560 --> 00:54:15.320
So having that testing in place allows us a little bit of, you know, room to experiment to really push this to the limits of what these GPUs are capable of doing in terms of increasing bandwidth or, you know, more antennas that we can process or, you know, all these kinds of things.

00:54:15.320 --> 00:54:16.320
Yeah.

00:54:16.320 --> 00:54:17.720
And you, I mean, you mentioned regressions earlier.

00:54:17.720 --> 00:54:19.140
That's so an excellent thing.

00:54:19.140 --> 00:54:25.800
So you're working on another part of a system and something breaks that, you know, having these tests in place will let you know, we've messed something up.

00:54:25.800 --> 00:54:28.500
Let's revert back and be a little bit more careful next time.

00:54:28.500 --> 00:54:32.840
So I think it's just a great concept in industry, in science, in academia.

00:54:32.840 --> 00:54:36.760
Everyone would benefit from having more embedded tests in place.

00:54:36.760 --> 00:54:37.920
It's not a panacea.

00:54:38.200 --> 00:54:45.100
You're not going to anticipate all possible failure modes in your tests, but it definitely helps catch many of the obvious ones.

00:54:45.100 --> 00:54:45.380
Yeah.

00:54:45.380 --> 00:54:46.120
Good advice.

00:54:46.120 --> 00:54:47.880
Testing science is tricky.

00:54:47.880 --> 00:54:50.480
It's usually a stream of numbers in some way.

00:54:50.480 --> 00:54:52.220
It's not, yes, there was a user.

00:54:52.220 --> 00:54:53.400
No, it came back none.

00:54:53.400 --> 00:54:54.360
Or there was an exception.

00:54:54.360 --> 00:54:56.520
It's still shooting out a bunch of numbers.

00:54:56.520 --> 00:54:58.060
Are they good?

00:54:58.060 --> 00:54:58.940
Maybe they're better.

00:54:58.940 --> 00:54:59.480
I don't know.

00:54:59.480 --> 00:54:59.700
Right.

00:54:59.700 --> 00:55:07.540
But having systems in place to record them, to test them, to say if it matches this curve within some tolerance, it's still good.

00:55:07.540 --> 00:55:07.960
Yes.

00:55:07.960 --> 00:55:13.200
It's really important in those areas because it's so hard to look at it and know what the deal is.

00:55:13.200 --> 00:55:13.660
Exactly.

00:55:13.660 --> 00:55:15.520
And I mean, so it is a team effort.

00:55:15.520 --> 00:55:20.940
There's not necessarily any one person that's going to have the experience to do all of these things.

00:55:20.940 --> 00:55:28.980
So the person who is a very experienced systems engineer who will know the methods by which we can evaluate the performance is not necessarily going to be the best coder.

00:55:28.980 --> 00:55:32.480
So that's why we have a large team in order to pull all of these things in.

00:55:32.480 --> 00:55:33.340
So, yes.

00:55:33.340 --> 00:55:33.600
Yeah.

00:55:33.600 --> 00:55:35.640
So shout out to my colleagues at Sorayao.

00:55:35.640 --> 00:55:36.940
We're doing good work.

00:55:37.080 --> 00:55:38.280
At least I like to think we are.

00:55:38.280 --> 00:55:39.340
It sure seems like it.

00:55:39.340 --> 00:55:39.760
Cool.

00:55:39.760 --> 00:55:40.000
All right.

00:55:40.000 --> 00:55:43.400
Well, we're about out of time to talk more about this.

00:55:43.400 --> 00:55:45.660
So let me ask you the final two questions before you get out of here.

00:55:45.660 --> 00:55:52.300
If you're going to write some Python code for this crazy big system you've built, what editor do you use?

00:55:52.300 --> 00:55:53.140
I'm a bit old school.

00:55:53.140 --> 00:55:54.440
I basically just use Vim.

00:55:54.440 --> 00:55:54.740
Vim.

00:55:54.740 --> 00:55:55.140
Right on.

00:55:55.200 --> 00:55:57.100
I feel most comfortable in the terminal.

00:55:57.100 --> 00:55:58.920
So no fancy GUIs for me.

00:55:58.920 --> 00:55:59.160
Yeah.

00:55:59.160 --> 00:55:59.580
There you go.

00:55:59.580 --> 00:56:01.900
And then notable PyPI package.

00:56:01.900 --> 00:56:03.440
Do you want to give a shout out to?

00:56:03.440 --> 00:56:05.960
Well, a couple of ones that I've already mentioned.

00:56:05.960 --> 00:56:07.180
pytest is very important.

00:56:07.180 --> 00:56:11.720
PyCuda has also been critical in our work so far.

00:56:11.720 --> 00:56:12.520
So, yeah.

00:56:12.520 --> 00:56:13.320
Shout out to those two.

00:56:13.320 --> 00:56:15.900
Thanks to the open source community for providing that for us.

00:56:15.980 --> 00:56:23.480
Yeah, it's really cool how much of these general open source projects are supporting science and other types of exploration.

00:56:23.480 --> 00:56:23.880
Cool.

00:56:23.880 --> 00:56:24.160
Yeah.

00:56:24.160 --> 00:56:25.600
Okay, final call to action.

00:56:25.600 --> 00:56:29.680
People are interested in maybe adopting some of your practices.

00:56:29.680 --> 00:56:32.880
Maybe they want to learn more about how you did this reporting in pytest.

00:56:32.880 --> 00:56:37.480
Or even as someone in the audience asks, you know, can they get access?

00:56:37.480 --> 00:56:40.060
How do they get access to the data sets potentially?

00:56:40.060 --> 00:56:41.300
You know, what do you tell them?

00:56:41.300 --> 00:56:42.180
The data sets.

00:56:42.180 --> 00:56:45.180
Well, I hope you have a very big hard drive on your laptop.

00:56:45.520 --> 00:56:48.460
If you go to seraya.ac.za, there'll be a contact page.

00:56:48.460 --> 00:56:52.500
And if you can send us a question and we'll make sure that it gets to the right person.

00:56:52.500 --> 00:56:56.780
I'm not sure what the procedure is for access for people outside.

00:56:56.780 --> 00:57:00.720
I can get to it when I want to, but then I'm inside the organization.

00:57:00.720 --> 00:57:01.860
So start with an email.

00:57:01.860 --> 00:57:04.720
But if you ask the question on our contact page, yeah.

00:57:04.720 --> 00:57:06.360
And then we'll send you to the right place.

00:57:06.360 --> 00:57:11.900
To learn more, I'll put the GitHub link to the software for the correlator.

00:57:11.900 --> 00:57:15.240
It's all there and the documentation is relatively good.

00:57:15.280 --> 00:57:20.900
If there's something that's missing, you're welcome to just raise an issue on the GitHub repo and then we'll see how we can help.

00:57:20.900 --> 00:57:21.260
Excellent.

00:57:21.260 --> 00:57:24.480
Well, thanks for sharing your story and keep up the good work.

00:57:24.480 --> 00:57:25.320
Michael, yeah.

00:57:25.320 --> 00:57:25.880
Thanks very much.

00:57:25.880 --> 00:57:27.280
It's been great to be here.

00:57:27.280 --> 00:57:28.560
Yeah, it has been great to talk to you.

00:57:28.560 --> 00:57:29.020
See you later.

00:57:29.020 --> 00:57:29.520
Cheers.

00:57:30.560 --> 00:57:33.420
This has been another episode of Talk Python to Me.

00:57:33.420 --> 00:57:35.240
Thank you to our sponsors.

00:57:35.240 --> 00:57:36.840
Be sure to check out what they're offering.

00:57:36.840 --> 00:57:38.280
It really helps support the show.

00:57:38.280 --> 00:57:46.740
Type I is here to take on the challenge of rapidly transforming a bare algorithm in Python into a full-fledged decision support system for end users.

00:57:46.900 --> 00:57:52.260
Get started with Type I core and GUI for free at talkpython.fm/type I.

00:57:52.680 --> 00:57:53.740
T-A-I-P-Y.

00:57:53.740 --> 00:57:55.820
Take some stress out of your life.

00:57:55.820 --> 00:58:01.600
Get notified immediately about errors and performance issues in your web or mobile applications with Sentry.

00:58:01.600 --> 00:58:06.600
Just visit talkpython.fm/sentry and get started for free.

00:58:06.600 --> 00:58:10.180
And be sure to use the promo code TALKPYTHON, all one word.

00:58:10.180 --> 00:58:11.740
Want to level up your Python?

00:58:12.140 --> 00:58:15.780
We have one of the largest catalogs of Python video courses over at Talk Python.

00:58:15.780 --> 00:58:20.960
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:58:20.960 --> 00:58:23.620
And best of all, there's not a subscription in sight.

00:58:23.620 --> 00:58:26.540
Check it out for yourself at training.talkpython.fm.

00:58:26.540 --> 00:58:31.220
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.

00:58:31.220 --> 00:58:32.520
We should be right at the top.

00:58:32.520 --> 00:58:41.900
You can also find the iTunes feed at /itunes, the Google Play feed at /play, and the direct RSS feed at /rss on talkpython.fm.

00:58:41.900 --> 00:58:45.320
We're live streaming most of our recordings these days.

00:58:45.320 --> 00:58:53.140
If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

00:58:53.140 --> 00:58:55.000
This is your host, Michael Kennedy.

00:58:55.000 --> 00:58:56.300
Thanks so much for listening.

00:58:56.300 --> 00:58:57.460
I really appreciate it.

00:58:57.460 --> 00:58:59.360
Now get out there and write some Python code.

00:58:59.360 --> 00:59:20.200
I'll see you next time.

