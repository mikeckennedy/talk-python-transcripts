WEBVTT

00:00:00.001 --> 00:00:03.880
If you're a fan of Python's async and await keywords and the powers they unlock,

00:00:03.880 --> 00:00:09.240
then this episode is for you. We have Timo Furrer here to share a whole bunch of async

00:00:09.240 --> 00:00:14.960
IO related Python packages. Timo runs the awesome asyncio list and he and I picked

00:00:14.960 --> 00:00:21.440
out some of our favorites to share with you. This is Talk Python episode 389 recorded November 3rd,

00:00:21.440 --> 00:00:22.560
2022.

00:00:22.560 --> 00:00:41.020
Welcome to Talk Python To Me, a weekly podcast on Python. This is your host, Michael Kennedy.

00:00:41.020 --> 00:00:46.140
Follow me on Mastodon where I'm @mkennedy and follow the podcast using @talkpython,

00:00:46.140 --> 00:00:52.080
both on fosstodon.org. Be careful with impersonating accounts on other instances. There are many.

00:00:52.080 --> 00:00:57.120
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.

00:00:57.120 --> 00:01:02.800
We've started streaming most of our episodes live on YouTube. Subscribe to our YouTube channel over

00:01:02.800 --> 00:01:08.540
at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.

00:01:08.540 --> 00:01:14.180
This episode is sponsored by Microsoft for Startups Founders Hub. Check them out at

00:01:14.180 --> 00:01:20.260
Talk Python.fm slash Founders Hub to get early support for your startup. And it's brought to you by

00:01:20.260 --> 00:01:26.920
Sentry. Don't let those errors go unnoticed. Use Sentry. Get started at talkpython.fm/sentry.

00:01:26.920 --> 00:01:33.280
Transcripts for this episode are sponsored by Assembly AI, the API platform for state-of-the-art

00:01:33.280 --> 00:01:39.420
AI models that automatically transcribe and understand audio data at a large scale. To learn more,

00:01:39.420 --> 00:01:43.360
visit talkpython.fm/assemblyai. Hey, Timo.

00:01:43.360 --> 00:01:44.060
Hello, Michael.

00:01:44.060 --> 00:01:47.960
Hey, it's great to be here with you. I'm super excited to talk about Async Python.

00:01:48.100 --> 00:01:52.780
Yeah, same. Good to be here. You know, we've spoken a little bit through GitHub. I think it's

00:01:52.780 --> 00:01:57.960
odd, but also kind of awesome how many connections are made through places like that, right? Like,

00:01:57.960 --> 00:02:02.940
we've never met in person, but we previously chatted about some Async things on GitHub.

00:02:02.940 --> 00:02:07.320
Yeah, it's always nice to kind of see the same people again, which you met like online,

00:02:07.320 --> 00:02:10.020
in a call or something, talk about something. It's pretty cool.

00:02:10.080 --> 00:02:13.120
And that's why I really enjoy going to conferences because you're like, oh yeah,

00:02:13.120 --> 00:02:15.580
you're the person I've been talking to for six months now.

00:02:15.580 --> 00:02:16.000
Absolutely.

00:02:16.000 --> 00:02:21.960
Yeah. Cool. Well, I'm super excited to talk about all the awesome Async Python things that you've

00:02:21.960 --> 00:02:26.640
curated. Before that though, let's just get into your background. What's your story? How'd you get

00:02:26.640 --> 00:02:27.440
into programming in Python?

00:02:27.760 --> 00:02:32.920
Yeah. So I started programming, I think when I was around 10 years old, I, at the time I was

00:02:32.920 --> 00:02:38.300
exploring at an offline computer from my parents, which didn't have a lot of like things on it,

00:02:38.300 --> 00:02:43.020
but there were a few applications. And one of those were, I think it's called front page,

00:02:43.020 --> 00:02:45.840
like Microsoft front page and publisher, which is like,

00:02:45.920 --> 00:02:49.760
Yes. It was like Microsoft Word for creating websites. It was insane.

00:02:49.760 --> 00:02:54.340
Yeah, exactly. So I was like playing around with this and just, you know, exploring whatever was

00:02:54.340 --> 00:02:58.720
there because I didn't have any internet. And yeah, that's how I got interested in like how things are

00:02:58.720 --> 00:03:05.060
built in a computer. And at some point I got internet, I kind of browsed around to see like how

00:03:05.060 --> 00:03:11.200
these websites really work like. And yeah, that's how I got into PHP and HTML and did some website stuff.

00:03:11.200 --> 00:03:15.440
Couldn't you open a website in front page? Couldn't you like point it at a URL and say,

00:03:15.540 --> 00:03:19.400
open this and it would pull down the HTML, like into the editor? I think I remember.

00:03:19.400 --> 00:03:20.660
I don't really remember.

00:03:20.660 --> 00:03:24.920
What a weird piece of software that was. Sorry, I don't need to do it. I'm just thinking back of like

00:03:24.920 --> 00:03:26.740
the early web was a weird time.

00:03:26.740 --> 00:03:32.600
I more use publisher than I use front page because it was more complex for me at the time. And I didn't

00:03:32.600 --> 00:03:37.460
really have any documentation or tutorials. So I, yeah, it was more like fiddling around and

00:03:37.460 --> 00:03:40.080
getting something to work and something to happen.

00:03:40.080 --> 00:03:41.780
Cool. So you found your way to PHP.

00:03:41.780 --> 00:03:45.160
Yeah. Then I went to PHP, did some very basic websites,

00:03:45.160 --> 00:03:50.240
like guest books and these kinds of things with PHP, but nothing, nothing really big.

00:03:50.240 --> 00:03:54.280
And then after mandatory school years here in Switzerland, I started an apprenticeship

00:03:54.280 --> 00:03:59.140
at Roche. It's a pharmaceutical company. So if you, if you've done any PCR tests lately,

00:03:59.140 --> 00:04:04.400
you probably have done that on an instrument of them. And there I was in a team where we did

00:04:04.400 --> 00:04:10.140
hardware simulation testing for software, which is running on these instruments. And all these,

00:04:10.340 --> 00:04:15.040
like the testing framework around the simulation was in Python. And that's basically how I,

00:04:15.040 --> 00:04:21.180
I would start in Python. Yes. It's mostly like testing code and providing frameworks in Python

00:04:21.180 --> 00:04:22.340
for testing.

00:04:22.340 --> 00:04:27.420
That's cool. That's a neat way where you can connect your code to physical things,

00:04:27.420 --> 00:04:28.220
you know, testing.

00:04:28.420 --> 00:04:32.840
Yeah. It's super nice. Like lab equipment and stuff. The simulation at the time, it also had

00:04:32.840 --> 00:04:38.760
some 3D visualization. So you could see motors moving around and kind of, you know, see pipelines

00:04:38.760 --> 00:04:44.160
colliding and these kinds of things, which was pretty awesome for me at the time because it was my first

00:04:44.160 --> 00:04:48.860
job basically. And yeah, it was super cool. It was super cool. We also built with Python,

00:04:49.080 --> 00:04:53.940
like a distributed testing framework or testing system, kind of like you would have in Jenkins

00:04:53.940 --> 00:04:57.020
these days or, or any other CI system.

00:04:57.020 --> 00:05:00.880
Yeah. They probably don't have as easy integration to actual hardware.

00:05:00.880 --> 00:05:05.920
Now, when I pushed to this branch, I wanted to fire up that robot. Oh, okay.

00:05:05.920 --> 00:05:11.620
Exactly. And also like a huge problem is like error case testing. Like you can't just break a needle

00:05:11.620 --> 00:05:17.440
in an instrument while, when you're running something, because either you get hurt or it just costs you a

00:05:17.440 --> 00:05:21.840
thousand dollars just for breaking something for testing. So you need some kind of simulation to

00:05:21.840 --> 00:05:22.760
actually do that.

00:05:22.760 --> 00:05:25.520
Yeah. Very fun. How about now? What are you up to now?

00:05:25.520 --> 00:05:30.340
Yeah. I started a new job at GitLab. I'm a senior backend engineer in the

00:05:30.340 --> 00:05:36.460
configure group. And what we're doing is we provide Kubernetes integration for GitLab, GitLab projects

00:05:36.460 --> 00:05:42.040
and groups, these kinds of things, and also are responsible for the infrastructure as code features

00:05:42.040 --> 00:05:47.100
like the Terraform estate backend and the Terraform provider, which also I've been

00:05:47.100 --> 00:05:52.460
maintaining for a year now. That's just like an outside contributor. Yeah. But this is mostly go.

00:05:52.460 --> 00:05:59.820
If maybe, you know, Ruby is a big player in GitLab. So the entire GitLab rep was mainly a Ruby and

00:05:59.820 --> 00:06:00.560
Rails application.

00:06:00.560 --> 00:06:06.780
Give us the elevator pitch on GitLab. Is it, I should use GitLab instead of GitHub or something else?

00:06:06.780 --> 00:06:09.640
Or what, what's the value proposition for GitLab?

00:06:09.640 --> 00:06:13.280
It's a good question. What do you see here also on the screen is that it's called the

00:06:13.280 --> 00:06:19.840
one DevOps platform. So it provides much more feature, I think, than, than GitHub in terms of like front planning

00:06:19.840 --> 00:06:25.860
to production, then monitoring an application, get like all these insights, which you cannot really do on GitHub.

00:06:25.860 --> 00:06:31.920
So you have all, yep. You basically have features for all the DevOps lifecycle stages.

00:06:31.920 --> 00:06:36.740
And here, for example, you see the very Fiverr. You have a very powerful pipeline integration.

00:06:37.060 --> 00:06:43.160
The open source world is happening on GitHub, but a lot of enterprises are using GitLab these days for

00:06:43.160 --> 00:06:44.660
developing their applications.

00:06:44.660 --> 00:06:49.680
Yeah. It's definitely an important piece of, piece of the puzzle out there. And how long have you been

00:06:49.680 --> 00:06:50.020
at GitLab?

00:06:50.020 --> 00:06:53.820
Just one month. Actually, today marks my one month being at GitLab.

00:06:53.820 --> 00:06:57.920
Wow. So you're probably, yeah, you're probably just starting to get comfortable with like how stuff

00:06:57.920 --> 00:06:59.840
works and how you deploy things and so on.

00:06:59.840 --> 00:07:02.980
Exactly. It was a lot of onboarding, but I've been contributing before.

00:07:03.060 --> 00:07:08.200
So not everything was new enough in using GitLab as a user. So it wasn't that hard, I would say.

00:07:08.200 --> 00:07:11.600
Cool. All right. Well, let's go ahead and jump into your project.

00:07:11.600 --> 00:07:12.140
Sure.

00:07:12.140 --> 00:07:17.860
It's one of these awesome lists, and it's about one of my favorite aspects of Python because it

00:07:17.860 --> 00:07:23.540
async.io, async and await, they let you write such neat software that really takes advantage of

00:07:23.540 --> 00:07:28.300
latency. And when other parts of the system are busy, you can just keep on going without

00:07:28.300 --> 00:07:35.320
rethinking how your code works all that much. So I'm a super fan of async and await and Python and all the

00:07:35.320 --> 00:07:39.180
languages that use it, I suppose, because I just like the idea. But, you know, tell us about your project

00:07:39.180 --> 00:07:42.400
and maybe first start with like, what the heck is an awesome list anyway?

00:07:42.400 --> 00:07:48.800
An awesome list is just a curated list of projects or whatever the awesome list is about. It could be

00:07:48.800 --> 00:07:54.740
recipes or whatever. And it's just trying to collect awesome pieces of that thing. In this case,

00:07:54.840 --> 00:08:01.480
async.io, which are async.io packages or projects, and you basically showcase them to the readers and

00:08:01.480 --> 00:08:06.740
they could, you know, take inspiration for the next project stack or can just explore like what's out

00:08:06.740 --> 00:08:14.400
there and what people feel that is awesome. And yeah, I mean, I'm not an expert in all of these by far.

00:08:14.400 --> 00:08:21.260
So I'm more like librarian off the list and rely on people contributing actually their awesome

00:08:21.260 --> 00:08:23.780
projects or ideas or whatever.

00:08:23.780 --> 00:08:29.260
Yeah, neither, just as a disclaimer, a front, neither of us are, you know, maintainers of all these

00:08:29.260 --> 00:08:34.240
projects or like we're not super experts. It's more of a survey of all the cool things. And I do think

00:08:34.240 --> 00:08:39.220
that's one of the really cool powers of the awesome list. You know, I remember the first time I found

00:08:39.220 --> 00:08:44.100
awesome Python. I was like, wow, look at all these things I didn't even know existed, right? It's,

00:08:44.100 --> 00:08:49.120
it's not necessarily that you use the awesome list to make a decision about what you use,

00:08:49.120 --> 00:08:53.440
but it, it's like a good starting point for research, depending on whatever area,

00:08:53.440 --> 00:08:57.520
like you've broken your list into stuff about databases and about networking and about web

00:08:57.520 --> 00:09:01.400
frameworks. And as we'll see, and you know, you go to that section you're interested in,

00:09:01.400 --> 00:09:04.640
you're like, oh, here's my 10 research projects to figure out what I want to do.

00:09:04.800 --> 00:09:08.400
I think it's also nice to just, you know, once in a while browse through it and see like where,

00:09:08.400 --> 00:09:12.420
where the ecosystem is at and like what new things have been popping up. So.

00:09:12.420 --> 00:09:17.520
So another thing I think maybe is worth touching on, I get the sense, although I'm not a hundred

00:09:17.520 --> 00:09:22.280
percent sure, cause I'm asking you now that these things that get put there, they don't,

00:09:22.280 --> 00:09:28.340
it's not an exhaustive list. It's more of a things that the community thinks reaches some threshold for

00:09:28.340 --> 00:09:32.780
interestingness. So under the PRs, I see you got a new one an hour ago.

00:09:33.000 --> 00:09:41.220
Yeah. So under the PRs that you have a please vote before these are accepted because like what

00:09:41.220 --> 00:09:45.880
it means to accept a PR is really to add a line to a read me. It's not like a super,

00:09:45.880 --> 00:09:50.760
oh boy, how does this affect our overall performance? Like there's not a lot of considerations in that

00:09:50.760 --> 00:09:54.580
regard, but the question is sort of, let's talk about whether it belongs on the list, right?

00:09:54.580 --> 00:09:56.300
How do things make it on your list?

00:09:56.300 --> 00:10:01.480
It's a very good question. And I never been really strict about these rules and maybe I should be,

00:10:01.480 --> 00:10:08.060
I don't know, but I usually put this please vote label on pull requests just to see if people are

00:10:08.060 --> 00:10:13.360
interested in this. Usually I also check things like the stars. When was the last contribution?

00:10:13.360 --> 00:10:18.300
Like how many, how many contributors are there? Because if we put something here on the list and

00:10:18.300 --> 00:10:23.180
then people start using it and we burn out some maintainers of a library, we just wanted to do,

00:10:23.180 --> 00:10:26.660
you know, publish something. Yeah. I don't know if that would be a good idea, right?

00:10:26.660 --> 00:10:30.460
Right. And on the other end of the spectrum, you've got, you know, maybe there are people

00:10:30.460 --> 00:10:35.380
who publish something just for the heck of it, but there's one person they've touched it two years

00:10:35.380 --> 00:10:39.600
ago and you know, it's, it's not necessarily something you want to recommend if there's five

00:10:39.600 --> 00:10:44.940
stars and no one using it. And is it really going to be good enough? Okay, cool. So I'm guessing it's

00:10:44.940 --> 00:10:49.580
open for people to go and do more PRs and suggest more things if they listen to the show and they're

00:10:49.580 --> 00:10:51.980
like, but you forgot about this awesome thing.

00:10:51.980 --> 00:10:58.080
Yeah. If people are listening and have something awesome, please create a pull request. Always great to

00:10:58.080 --> 00:11:02.760
have some addition. Yeah. Cool. All right. Well, let's, let's go through it. So I think we'll just

00:11:02.760 --> 00:11:08.060
take it section by section or topic by topic. And I know you pulled out a couple of things that are

00:11:08.060 --> 00:11:11.680
interesting to you. I grabbed a couple as well and we'll just, just touch on them, you know,

00:11:11.680 --> 00:11:16.800
kind of work on that awareness and cover the broad spectrum of what's available. So we'll take it,

00:11:16.800 --> 00:11:21.360
I guess the top section that you have here, probably the most important section I would say

00:11:21.360 --> 00:11:26.080
is web frameworks, right? There's some interesting ones. First of all, it's kind of notable. The

00:11:26.080 --> 00:11:30.960
ones that are not there yet, maybe actually, maybe there's some PRs that should be making their way

00:11:30.960 --> 00:11:36.320
there. The really traditional web frameworks that people think about are not there, right? We don't

00:11:36.320 --> 00:11:42.140
see Flask directly, although through court it's there, which is kind of its full async implementation.

00:11:42.140 --> 00:11:49.180
Django is not listed. Bottle, Pyramid, bunch of these older ones, but the really hot new ones are here,

00:11:49.180 --> 00:11:52.900
right? Like we've got FastAPI and Sanic and some of the others as well.

00:11:52.900 --> 00:11:57.940
I guess people are just probably more excited about those and then, you know, they're kind of hyped

00:11:57.940 --> 00:12:03.900
and at those and that's probably why they end up here and not having like Pyramid or the older ones.

00:12:03.900 --> 00:12:08.940
Yeah. Well, Pyramid doesn't have an async version, but you know, it's interesting that Django does.

00:12:08.940 --> 00:12:14.320
And I think maybe somebody should do a PR for Django now that it actually properly supports all the way

00:12:14.320 --> 00:12:17.800
to the database layer. But, you know, until recently it didn't. And what's notable,

00:12:17.800 --> 00:12:23.240
I think about all of these frameworks that are here on the web one and pretty much for many of the

00:12:23.240 --> 00:12:31.160
others as well, is not just they have a capability to do async, but they were kind of born to be async,

00:12:31.160 --> 00:12:31.760
right?

00:12:31.760 --> 00:12:36.480
Yeah, you're right. And I think also some of them, I mean, they're all, they're not all on the same

00:12:36.480 --> 00:12:43.620
level, I would say. Like we have Starlet, which may be like a very lightweight framework that others

00:12:43.620 --> 00:12:49.180
kind of build on top, like FastAPI, which, you know, Starlette may be more comparable to Quartz

00:12:49.180 --> 00:12:54.440
than Quartz is to FastAPI, right? So you have these kind of different layers where people could build

00:12:54.440 --> 00:12:56.760
upon and, you know, so it's some variety there.

00:12:56.760 --> 00:13:02.200
Yeah. And you've got a couple of WebSocket style ones in here as well. They're maybe not full frameworks,

00:13:02.200 --> 00:13:07.840
but they work in that regard. Yeah. So, you know, notable to me here, certainly, I mean,

00:13:07.840 --> 00:13:13.340
FastAPI is definitely taking the world by storm. It only came out a couple of years ago and it's

00:13:13.340 --> 00:13:19.880
already got 50,000 GitHub stars and that's close to what Flask and Django have. It's certainly a popular

00:13:19.880 --> 00:13:22.420
one. Yeah. Have you got any chance to play with FastAPI?

00:13:22.640 --> 00:13:29.600
I do. Yeah. Or I did. At my last job, we built some applications on top of FastAPI. And we also,

00:13:29.600 --> 00:13:35.560
at Roche, we opened source one, which is kind of nice. I always liked the, like the FastAPI experience

00:13:35.560 --> 00:13:40.440
overall. Like, you know, the documentation is super nice. I think Sebastian did a great job in also

00:13:40.440 --> 00:13:47.280
taking the extra mile to explain more general concepts than FastAPI, like introduction to AsyncIO

00:13:47.280 --> 00:13:52.660
and these kinds of things, which the others do not have. They don't need to, but it's just that you

00:13:52.660 --> 00:13:57.400
can see that they really care about the community and the users of FastAPI to make it very easy to

00:13:57.400 --> 00:14:03.160
put something into production. It definitely stands out in that regard, for sure. So FastAPI is notable.

00:14:03.160 --> 00:14:09.640
I also think another one worth giving a shout out to is Starlit. Now, Starlit is not as popular,

00:14:09.640 --> 00:14:16.440
right? Having 7,000 GitHub stars. Not that this is like a popularity contest, but it gives you a sense of

00:14:16.440 --> 00:14:22.500
like how many people are using it, right? And so Starlit is its own web framework, but it is also

00:14:22.500 --> 00:14:27.720
something that can be used for the building blocks of other web frameworks, which I think is unusual

00:14:27.720 --> 00:14:32.560
for, you know, Flask isn't like, well, take us apart and just use us. Don't actually use Flask or,

00:14:32.560 --> 00:14:38.800
you know, but FastAPI itself actually is built on Starlit. So much of what people love about FastAPI,

00:14:38.800 --> 00:14:41.800
they actually love it about Starlit. It's just kind of like a pass-through.

00:14:41.800 --> 00:14:47.860
Yeah, I think for a lot of things, FastAPI is just a pass-through to Starlit. And that's what I

00:14:47.860 --> 00:14:53.920
meant before with a lot of people are like comparing RCD block posts like FastAPI versus

00:14:53.920 --> 00:14:59.860
Flask or Quart and these kinds of things. But it's an unfair comparison because they're like Starlit and Quart,

00:14:59.860 --> 00:15:05.240
I think they're meant to be extended into something like going from the microframe or to your,

00:15:05.240 --> 00:15:11.520
like that application afterwards. And I think you will have, and they'll start using FastAPI if you

00:15:11.520 --> 00:15:15.380
need all of these features. Then, you know, it depends on the use case, I guess.

00:15:15.560 --> 00:15:21.320
Very cool to learn about that one. Also, Sanic. I hadn't really been tracking Sanic until recent.

00:15:21.320 --> 00:15:25.980
I had been and then kind of didn't pay too much attention. But this is a pretty popular framework,

00:15:25.980 --> 00:15:31.460
16,000 stars. And yeah, it's kind of got its own philosophy. It's a little bit like Starlit,

00:15:31.460 --> 00:15:32.460
actually, in its style.

00:15:32.460 --> 00:15:37.940
I've never used it. I've seen it around, but I never really looked into it. So what is it that

00:15:37.940 --> 00:15:39.760
it has a different style? What do you mean?

00:15:39.840 --> 00:15:43.820
Well, so many of the web frameworks, that's a great question. So many of the web frameworks

00:15:43.820 --> 00:15:48.440
these days are like, we're a brand new web framework. We look just like Flask, except,

00:15:48.440 --> 00:15:54.260
you know, we're just like Flask, but we're API oriented and we come with auto documentation.

00:15:54.260 --> 00:15:58.700
We're just like Flask, but we do this other slightly different thing. You know, they're,

00:15:58.700 --> 00:16:04.180
they're all like, you create an app and then you say app.get or app.route on your,

00:16:04.180 --> 00:16:09.660
and you kind of build up out of a blueprint or API router style of like separator, right?

00:16:09.660 --> 00:16:15.380
This, there's so many of these new web frameworks that are highly inspired by Flask,

00:16:15.380 --> 00:16:21.500
but they don't carry over the same runtime. They carry over kind of the shell API concepts,

00:16:21.500 --> 00:16:27.300
right? And Sanic is not so much like that. So if you go and check out Sanic, they have like a good

00:16:27.300 --> 00:16:31.220
getting started. Let's see if I can pull up an example. They have a huge button that says,

00:16:31.220 --> 00:16:37.020
get started. Maybe I should click that. So if you look at the way that, that it works is you just

00:16:37.020 --> 00:16:41.860
create functions. Here's, they're using this app.get. So I saw some, I believe that were,

00:16:41.860 --> 00:16:47.420
you just say, here's a function, here's its URL, go and call it, right? Where it's a little more

00:16:47.420 --> 00:16:53.740
assemble it back together. But yeah, anyway, it's, it's an interesting web framework as well,

00:16:53.740 --> 00:16:57.280
a little bit different. And it's, I think it's really nice that there's all these

00:16:57.740 --> 00:17:00.580
people attempting different perspectives on solving the same problem.

00:17:00.580 --> 00:17:04.400
It's cool. And it probably depending on the use case, one suits you better than the other. I mean,

00:17:04.400 --> 00:17:08.340
it's not that FastAPI just because it had so many stars that it's always the best choice,

00:17:08.340 --> 00:17:12.980
right? Maybe Quark is better for your use case because you want something very minimalistic or

00:17:12.980 --> 00:17:15.300
something you can extend in your own ways.

00:17:15.460 --> 00:17:20.460
Yeah. And some of these like Sanic just added this ability to have background workers that are managed.

00:17:20.460 --> 00:17:26.040
So you don't have to go all the way to like a salary worker type of infrastructure, just the web

00:17:26.040 --> 00:17:30.880
framework will manage it. And I believe Starlette also has that. Yeah. I guess one more thing to give a

00:17:30.880 --> 00:17:37.420
shout out to is the stuff from the Encode folks. There's a lot of those appearing here. So they've got

00:17:37.420 --> 00:17:42.600
Starlet, they've got HTTPX and UVicorn, right? Once you get one of these frameworks, you got to run it,

00:17:42.600 --> 00:17:47.400
right? Yeah. And probably it's one of the most popular for production, I think.

00:17:47.400 --> 00:17:51.940
At least that's what we've been using and we've been super happy. I mean, yeah. Word's great.

00:17:51.940 --> 00:17:56.240
In fact, if you use it with uv loop. Yeah. uv loop will make an appearance a little bit later

00:17:56.240 --> 00:18:02.900
as well. But yeah, I've been using UVicorn for production also. I'm loving it. Okay. And I guess

00:18:02.900 --> 00:18:08.680
also one thing I'll put into the show notes here is I can't remember which framework had this that I

00:18:08.680 --> 00:18:14.100
pulled it up. It might've been Sanic or Starlet, one of those two, but they created a filter across

00:18:14.100 --> 00:18:19.920
the tech and power web framework benchmarks that just highlight the Python ones, right? Cause there's

00:18:19.920 --> 00:18:26.760
how many, 290 frameworks in this. I don't really care what this obscure rust, super lightweight thing

00:18:26.760 --> 00:18:31.120
does because it's not a full web framework and I will never use it and so on. So it's kind of

00:18:31.120 --> 00:18:36.320
interesting to compare just the like raw basic ones or whatever. But if people are,

00:18:36.320 --> 00:18:40.000
doesn't necessarily matter too much, but if you kind of want to get a sense of what performance

00:18:40.000 --> 00:18:45.160
looks like across all of these, you know, here's a, I'll put a link to the tech and power benchmarks.

00:18:45.160 --> 00:18:48.620
I don't know. What do you think about these things? Does this influence you to see, oh,

00:18:48.620 --> 00:18:51.980
Sanic is above FastAPI or do you not care?

00:18:51.980 --> 00:18:57.460
It's nice to see those comparison and kind of see how the theory optimization in these

00:18:57.460 --> 00:19:02.360
frameworks can translate to, to practice. But in the real world, I would say that it doesn't

00:19:02.360 --> 00:19:06.460
really matter too much because it's probably your business logic, which is slowing you down.

00:19:06.460 --> 00:19:06.800
Yes.

00:19:06.800 --> 00:19:13.020
And these kinds of things or latency to your database or whatever, and not the framework itself. So

00:19:13.020 --> 00:19:16.560
I would take those with a grain of salt.

00:19:16.560 --> 00:19:21.740
Yeah. It's kind of like asking, well, if I have a tight loop and I increment a number,

00:19:21.740 --> 00:19:26.120
how fast can I do that? Like, okay, well, sure. C++ is super fast for that, but that's not what

00:19:26.120 --> 00:19:30.780
real software does. Real software interacts with all these things. And like that difference you

00:19:30.780 --> 00:19:34.660
think is so huge is like a little marginal bit over the real work.

00:19:34.660 --> 00:19:41.180
This portion of Talk Python To Me is brought to you by Microsoft for Startups Founders Hub.

00:19:41.180 --> 00:19:47.120
Starting a business is hard. By some estimates, over 90% of startups will go out of business in

00:19:47.120 --> 00:19:52.700
just their first year. With that in mind, Microsoft for Startups set out to understand what startups

00:19:52.700 --> 00:19:57.680
need to be successful and to create a digital platform to help them overcome those challenges.

00:19:57.680 --> 00:20:03.560
Microsoft for Startups Founders Hub was born. Founders Hub provides all founders at any stage

00:20:03.560 --> 00:20:09.620
with free resources to solve their startup challenges. The platform provides technology benefits,

00:20:09.620 --> 00:20:15.360
access to expert guidance and skilled resources, mentorship and networking connections, and much

00:20:15.360 --> 00:20:21.440
more. Unlike others in the industry, Microsoft for Startups Founders Hub doesn't require startups to be

00:20:21.440 --> 00:20:27.900
investor backed or third party validated to participate. Founders Hub is truly open to all.

00:20:27.900 --> 00:20:32.700
So what do you get if you join them? You speed up your development with free access to GitHub and

00:20:32.700 --> 00:20:38.600
Microsoft cloud computing resources and the ability to unlock more credits over time. To help your startup

00:20:38.600 --> 00:20:44.240
innovate, Founders Hub is partnering with innovative companies like OpenAI, a global leader in AI research

00:20:44.240 --> 00:20:49.960
and development to provide exclusive benefits and discounts. Through Microsoft for Startups Founders Hub,

00:20:50.100 --> 00:20:54.760
becoming a founder is no longer about who you know. You'll have access to their mentorship network,

00:20:54.760 --> 00:21:00.940
giving you a pool of hundreds of mentors across a range of disciplines and areas like idea validation,

00:21:00.940 --> 00:21:06.020
fundraising, management and coaching, sales and marketing, as well as specific technical stress

00:21:06.020 --> 00:21:11.140
points. You'll be able to book a one-on-one meeting with the mentors, many of whom are former founders

00:21:11.140 --> 00:21:16.720
themselves. Make your idea a reality today with the critical support you'll get from Founders Hub.

00:21:16.720 --> 00:21:21.440
To join the program, just visit talkpython.fm/foundershub, all one word,

00:21:21.440 --> 00:21:24.960
No links in your show notes. Thank you to Microsoft for supporting the show.

00:21:26.720 --> 00:21:43.440
Yeah. And I would also say that most of the people don't actually need that speed. If you may need it, you may also choose another language or, you know, if this really is a thing for you, then yeah, I don't know if this micro optimizations between Sanic and FastAPI really brings you much benefit.

00:21:43.440 --> 00:21:46.160
I would certainly say pick the API that makes you happy.

00:21:46.160 --> 00:21:46.160
Exactly.

00:21:46.160 --> 00:21:54.160
The programming API and the framework that makes you happy and just go with that. Yeah. Good advice. All right, let's see. Are we on to our next section? We are message queues.

00:21:54.160 --> 00:22:02.880
Yeah, I haven't been a big user of any of these. I've been using the MQP one a while ago, so I don't really know where it's at these days.

00:22:02.880 --> 00:22:14.560
Message queues are interesting. They're a way to add crazy scalability. If you've got a lot of stuff that takes a while, but you don't need the answer right away. They're pretty interesting, but I just haven't needed them much myself either.

00:22:14.560 --> 00:22:26.880
I did not too long ago speak with Min Reagan Kelly about zero MQ and Python, and apparently they're doing a lot of cool stuff for powering Jupyter with zero MQ.

00:22:27.600 --> 00:22:34.460
It's way more interesting than I initially kind of in my mind gave it credit for. But yeah, it's a cool project.

00:22:34.460 --> 00:22:37.100
So they're hosting Jupyter or what do they do?

00:22:37.100 --> 00:22:51.660
They're using for something for like the client server communication. I thought that it's been, that's what I think I remember, but it's been like quite a long while since I talked to them about it. But yeah, we've got the AMQP one. That's the one you talked about, right?

00:22:51.660 --> 00:23:08.660
Yes. It's the one you would use if you use rapid MQ, for example. Right. You started using the AMQP protocol and then that's where you can use this library in particular. Right. You have the PI ZMQ. That's the zero MQ one I was talking about. And then some others, one for like Apache Kafka, for example.

00:23:08.660 --> 00:23:24.000
But again, anytime you're talking, these are usually separate processes, sometimes on separate machines. You're doing network comms. Like if you, if you have the word I'm talking over a network, then async and await. I mean, asyncio, like what does the IO stand for? Right.

00:23:24.000 --> 00:23:36.420
And then I think point being also here is that you have asyncio libraries for pretty much all message queues out there these days. I mean, we, every time I looked and looked for a library, it was, so something was out there and you could use.

00:23:36.420 --> 00:23:53.140
All right. Let's move on to the next one, which is the database stuff. So I think this is another area where you spend, you're, especially in the web apps, you're spending a lot of time waiting. So thinking about your asynchronous database driver is super important, right?

00:23:53.140 --> 00:24:12.080
Yeah, absolutely. And I think it's not too long ago when there wasn't really good support for asyncio and databases. It's great to see that a lot of projects are now supporting it. And also you mentioned Django, which has it all the way to the, I'm not a Django user, so I don't really know. I also guess that's a huge deal.

00:24:12.080 --> 00:24:23.080
Yeah. I mean, that was the main blocker, I believe is the Django ORM didn't have an async interface. And I think it was 4.1, again, not doing a ton of Django myself either, but I think Django 4.1, which just came out.

00:24:23.080 --> 00:24:26.060
It kind of completed the whole cycle and added that.

00:24:26.060 --> 00:24:26.520
Very cool.

00:24:26.520 --> 00:24:30.040
Yeah. So what database drivers stand out on this list for you?

00:24:30.040 --> 00:24:43.520
Well, I think asyncpgA is a very popular one if you use Postgres. I've been using it and usually you don't really see much about them actually, because you may use SQLAlchemy on top of these drivers.

00:24:43.520 --> 00:24:43.980
Right.

00:24:43.980 --> 00:24:47.900
So as an end user, you may not have seen them, but you may have used them.

00:24:48.000 --> 00:24:56.880
The only way you might see them is you put the async connection string into SQLAlchemy and it complains that it doesn't have this package. Like, well, I guess I got to install that. Here we go. Right.

00:24:56.880 --> 00:24:57.300
Exactly.

00:24:57.300 --> 00:25:11.420
Yeah. Yeah. So certainly the asyncpg one, I think is pretty interesting. This one is from the EdgeDB folks, right? From, is that Magic, I believe? Yeah. Magic Stack, like Yuri and crew over there.

00:25:11.420 --> 00:25:18.400
So the same people that do uv loop, right? He did a lot of the original asyncio work in Python itself, I believe.

00:25:18.400 --> 00:25:24.500
Yeah. I think there's also a nice, interesting Talk Python To Me episode about with Yuri, I think.

00:25:24.500 --> 00:25:25.080
It was some.

00:25:25.080 --> 00:25:41.000
Yeah. I think I spoke to him in the, about a year ago as well. And that was a great chat. Yeah. Let's see what else stands out to me here. So motor, if you're doing MongoDB, then motor is often the building block, much like asyncpg would be the building block for SQLAlchemy's async.

00:25:41.000 --> 00:25:45.560
The motor is the building block for a lot of the Python MongoDB async libraries.

00:25:45.560 --> 00:25:47.640
Yeah. I also noticed that for Redis.

00:25:47.640 --> 00:25:48.480
Which one is that?

00:25:48.480 --> 00:25:49.440
The Redis Pi.

00:25:49.440 --> 00:26:06.840
Yeah, exactly. So I noticed a week ago or something that these IO Redis was included into the official Redis Pi library. I don't know when that happened. May have been a while ago, but I still think it's nice to have another separate package, but like the same package you have the sync API for.

00:26:06.840 --> 00:26:18.100
And you can kind of use similar APIs so that you don't have to like rethink everything. If you want to switch to async, it just makes it easier to migrate if you want to also move back for some reason.

00:26:18.100 --> 00:26:33.600
I agree. Some of these have both APIs, like for example, SQLAlchemy, you can create an async setup connection string engine sequence, or you can do a synchronous one. And depending on what you're doing, you might like this utility doesn't want to be async.

00:26:33.740 --> 00:26:48.520
So we're just going to go and use the sync API, but your web app or API might want the async version. Let's see a couple more notables here. The Piccolo one, I think is pretty interesting because I really think the query syntax for this one is quite expressive.

00:26:49.000 --> 00:26:53.300
Have you played with Piccolo? I have not, but I still admire its query style.

00:26:53.300 --> 00:27:16.460
I recently checked it out though. And I also have the same impression that the query syntax is super nice because compared to others like Prisma, I also looked at lately and while they have type safety with like type sticks, you know, here you actually have the Python symbols or variables you can use, which is, I think, a little bit nicer than having strings, even though they can't be all the completed.

00:27:16.460 --> 00:27:34.980
Yeah. And you get, and when you do refactoring, like it understands what's going on. So for just for people listening, for example, to do a select statement, I would say a weight because it's async band would be the class you say band dot select, then band type dot name, and then where dot where band dot popularity greater than 100.

00:27:34.980 --> 00:27:55.120
A lot of these ORMs and ODMs have like janky syntax to push operations into it. So for example, in Mongo Engine, you would say popularity underscore GT equals 100. So popularity greater than 100, but it's, you're saying equals, you don't want equals, you want the greater than symbol, right?

00:27:55.140 --> 00:28:00.920
This is like exactly the same meaning in SQL as it is in Python, which I just really like that.

00:28:00.920 --> 00:28:09.480
Yeah. And it's also super cool if you're, you know, entering a code base and you see these kind of things, because even if you don't know Piccolo, like he would understand what's going on.

00:28:09.480 --> 00:28:10.100
Yeah, exactly.

00:28:10.100 --> 00:28:13.320
Which I think is a good aspect of a nice API.

00:28:13.480 --> 00:28:24.220
It is. So Brandon out in the audience has a question says, so we can use asyncpg in place of psycopg two? I don't, I haven't done enough with this, but what are your thoughts?

00:28:24.220 --> 00:28:27.040
I'm not sure if the latter one really is async.

00:28:27.040 --> 00:28:32.040
Yeah, I think the deal is the latter one, psycopg two is not async.

00:28:32.040 --> 00:28:32.320
Yeah.

00:28:32.320 --> 00:28:46.280
And so that's what say SQLAlchemy would use if you had created a synchronous connection. But if you wanted to do the async version, then you would have to use the asyncpg foundation for it, basically. I think that's my understanding, but I do more MongoDB than Postgres.

00:28:46.280 --> 00:28:51.680
I think so too, but I wouldn't really know because I've always or lately been using async only.

00:28:51.680 --> 00:28:53.720
So yeah, exactly.

00:28:53.720 --> 00:29:00.620
It's not the only thing you would have to change, right? You would also have to adapt your code and put the weights here and there and make your code async.

00:29:00.620 --> 00:29:04.340
Like you can't just replace the query string and then expect it to work.

00:29:04.340 --> 00:29:08.360
So one other one here that I think is probably noteworthy to put in the database drivers.

00:29:08.360 --> 00:29:13.620
And I'd like to hear your thoughts on this as well. Is the AIO SQLite?

00:29:13.620 --> 00:29:14.080
Yeah.

00:29:14.080 --> 00:29:22.260
On one hand, interesting because SQLite doesn't really do much concurrency. So you're like, well, that's silly. Like, why would I ever want to use AIOs?

00:29:22.260 --> 00:29:24.980
You know, like the asyncio with it if it doesn't really do that.

00:29:24.980 --> 00:29:37.420
But if you're writing a web API or website or something that uses SQLAlchemy and you want to on dev use SQLite just for like a simple test and you want to use Postgres in production, well, guess what?

00:29:37.420 --> 00:29:44.220
Your async code will fail to run on SQLAlchemy unless you have AIO SQLite as the foundation like we just talked about.

00:29:44.360 --> 00:29:49.940
So it kind of allows you to still test your code and run it, even though you wouldn't necessarily directly use it.

00:29:49.940 --> 00:29:53.940
Yeah. I think we've always been using AIO SQLite for testing purposes.

00:29:53.940 --> 00:29:58.900
Super nice because you can use like in-memory databases and don't need to worry about the setup too much.

00:29:58.900 --> 00:30:00.380
And it just works basically.

00:30:00.640 --> 00:30:03.140
I need to be careful though for a few features.

00:30:03.140 --> 00:30:03.460
Yeah.

00:30:03.460 --> 00:30:07.160
Because it's not exactly a match, right?

00:30:07.160 --> 00:30:07.620
Exactly.

00:30:07.620 --> 00:30:15.640
So we had the case where, you know, it didn't, it worked in testing and in CI and then broken production because, yeah, or testing against Postgres.

00:30:15.640 --> 00:30:18.280
All right. Let's move on to the networking section.

00:30:18.280 --> 00:30:20.540
So what stands out? There's not that many of this one.

00:30:20.540 --> 00:30:23.100
This is not overwhelming, like the database thing, right?

00:30:23.100 --> 00:30:31.620
Yeah. I think probably a lot of people know is HTTPX, which is a super nice requests-like package for making HTTP calls.

00:30:31.620 --> 00:30:40.800
It has a similar ATI and the good thing, or what I really like is that you can use it in sync and async and the API looks pretty much the same.

00:30:40.800 --> 00:30:46.100
So if you want to switch from sync to async, I think it's a delight to use it.

00:30:46.100 --> 00:30:50.880
You can just say HTTPX.get just like you can with requests, which is great.

00:30:50.880 --> 00:30:54.580
And then if you want the async version, do they have an async example?

00:30:54.580 --> 00:30:55.700
It's super easy to quick.

00:30:55.700 --> 00:30:59.560
I think you just create like an async client and then call the same functions on it.

00:30:59.560 --> 00:30:59.940
Yes.

00:30:59.940 --> 00:31:00.440
That's cool.

00:31:00.440 --> 00:31:06.080
Much like requests where you create like a client, you just say, or a client session, I guess it's called.

00:31:06.080 --> 00:31:10.360
You say create an async client, then you await the client.get.

00:31:10.360 --> 00:31:10.640
Yeah.

00:31:10.640 --> 00:31:20.660
It's always interesting to me how libraries decide to add on async and, and I mean, we phrase that, a synchronous and a non-synchronous.

00:31:20.660 --> 00:31:24.520
Synchronous version, like the both variants into the same library, right?

00:31:24.520 --> 00:31:24.920
Mm-hmm.

00:31:24.920 --> 00:31:26.320
Do you see people doing that successfully?

00:31:26.320 --> 00:31:28.940
Like, do you see any patterns that you really like when they do that?

00:31:28.940 --> 00:31:33.200
I think I actually like how HTTPX is implemented in those regards.

00:31:33.200 --> 00:31:41.500
I didn't think much in the code base, but like you have the same like protocols for the, for the API so that you can reuse them easily.

00:31:41.500 --> 00:31:42.840
And then you kind of interchanged it.

00:31:42.840 --> 00:31:44.920
I think the transport layer in this case.

00:31:44.920 --> 00:31:45.380
Yeah.

00:31:45.380 --> 00:31:45.980
It's super nice.

00:31:45.980 --> 00:31:55.280
But for my own libraries, it always bothered me to, that there is no really nice API to provide both in like the same function.

00:31:55.280 --> 00:31:59.820
Like you couldn't reuse the function name in an async version or the method name, right?

00:31:59.820 --> 00:32:01.360
You need to have another class.

00:32:02.520 --> 00:32:04.100
But I guess that's just how it is.

00:32:04.100 --> 00:32:06.780
You know, I think a lot of these probably grow up.

00:32:06.780 --> 00:32:09.400
They come into existence to be one or the other.

00:32:09.400 --> 00:32:11.660
And then they're like, all right, well, we kind of want to have both.

00:32:11.660 --> 00:32:12.580
So how do we add it?

00:32:12.580 --> 00:32:24.180
And if personally, if I was going to start from the very beginning, I would like to see what they're doing just for the synchronous version of HTTPX, where you just say HTTPX.get.

00:32:24.440 --> 00:32:34.920
Instead of saying import HTTPX, you'd have to say from like HTTPX synchronous import HTTPX or from HTTPX async import HTTPX.

00:32:34.920 --> 00:32:39.400
And then it's just exactly the same API, but you have to await everything versus not await.

00:32:39.400 --> 00:32:39.780
I don't know.

00:32:39.780 --> 00:32:47.040
I think there's like if you said we'll control it at the import level and then what you get is either all awaitable or it's all blocking.

00:32:47.040 --> 00:32:48.020
It would be a nice pattern.

00:32:48.020 --> 00:32:48.400
Yeah.

00:32:48.400 --> 00:32:51.160
By the way, could you await this get?

00:32:51.160 --> 00:32:51.880
Not really.

00:32:51.880 --> 00:32:56.000
Or is there like a, you always need a client that you want to have async support?

00:32:56.000 --> 00:33:00.960
I'm pretty sure for HTTPX, you have to create the client and then you have to create an async client.

00:33:00.960 --> 00:33:01.740
Then you can await it.

00:33:01.740 --> 00:33:03.240
I've also seen other APIs.

00:33:03.240 --> 00:33:11.740
You have get, then you have like a get underscore async, but I kind of, I kind of don't like that since you could just do one import statement, you know, and fix it.

00:33:11.740 --> 00:33:12.920
So I don't know.

00:33:12.920 --> 00:33:18.760
It's really, as I'm going through all these, these examples that you've curated, I'm thinking like, okay, some of these have both APIs.

00:33:18.760 --> 00:33:21.020
Like, how are they making that clear to people?

00:33:21.020 --> 00:33:21.440
Right.

00:33:21.620 --> 00:33:23.440
What else is noteworthy on that list?

00:33:23.440 --> 00:33:26.180
I think maybe we could just super quick touch on it.

00:33:26.180 --> 00:33:28.620
You've got an async SSH library.

00:33:28.620 --> 00:33:29.900
Like literally that's its name.

00:33:29.900 --> 00:33:32.320
And a DNS and a ping, right?

00:33:32.320 --> 00:33:33.120
I haven't either.

00:33:33.120 --> 00:33:39.800
It's nice to have like here at least to have some, well, if you want to do a ping, like it may not be obvious what to use.

00:33:40.080 --> 00:33:41.580
So I think it's a good one.

00:33:41.580 --> 00:33:43.880
So I think it's a good one or at least people consider it a good one.

00:33:43.880 --> 00:33:45.760
So I think it's, it's nice adding those to the list.

00:33:45.760 --> 00:33:53.440
So there are a few like niche libraries on the list, which wouldn't make a huge, like they wouldn't get many votes probably if you do this because.

00:33:53.680 --> 00:33:55.200
They're not broadly useful.

00:33:55.200 --> 00:33:58.120
You're like, oh my goodness, I've been building a DNS system.

00:33:58.120 --> 00:33:59.920
I'm so glad I found AIO DNS.

00:33:59.920 --> 00:34:06.300
But actually some of the frameworks, like I believe HTTPX uses that under the covers.

00:34:06.300 --> 00:34:07.160
Pretty sure.

00:34:07.240 --> 00:34:12.760
Something I played with recently was like using AIO DNS under the covers to make its work a little more asynchronous.

00:34:12.760 --> 00:34:13.880
Yeah, it will make sense.

00:34:13.880 --> 00:34:14.540
Excellent.

00:34:14.540 --> 00:34:14.940
All right.

00:34:14.940 --> 00:34:16.400
Tell us about the testing story.

00:34:16.400 --> 00:34:25.400
I mean, here of the ones we see on the screen, there's IOMOC, there's AsyncTest, pytestAsyncIO, A-Responses and AIO-Responses.

00:34:25.400 --> 00:34:28.560
And I've been only using pytestAsyncIO, to be honest.

00:34:28.560 --> 00:34:38.880
And it basically gives you the, like a decorator to mark your Asyncpytest or your test as Async so that they run in an event loop.

00:34:38.880 --> 00:34:43.220
There is also now a mode you can set in the configuration where you don't need that marker.

00:34:43.220 --> 00:34:50.880
So you would, if you have a test, like you would say AsyncTest underscore some underscore AsyncIO code, and then your normal test code.

00:34:50.880 --> 00:34:55.560
And you would decorate this function with a pytest mark AsyncIO decorator.

00:34:56.060 --> 00:34:58.700
But yeah, it's not, I think, not necessary.

00:34:58.700 --> 00:35:05.360
These days you could configure it to have it in auto mode, where it basically just detects always a coroutine.

00:35:05.360 --> 00:35:07.300
I'd schedule it on the event loop.

00:35:07.300 --> 00:35:16.620
Yeah, and this is not about trying to say, well, I've got a bunch of AsyncTest functions, so let's try to run them all in parallel, like Xtest or Xdist or any of those types of things.

00:35:16.620 --> 00:35:21.260
It's just, I have some function I want to call and test its result.

00:35:21.260 --> 00:35:22.860
It's Async, so I have to await it.

00:35:22.860 --> 00:35:27.740
In order to await it, the test function itself must be Async, and then how do I run it, right?

00:35:27.740 --> 00:35:28.520
Like, now what?

00:35:28.520 --> 00:35:37.560
I think the other way would be kind of cumbersome to create an event loop every time and then schedule your coroutine in there and pytest AsyncIO, which just does that for you.

00:35:37.700 --> 00:35:41.100
Sure, you could do it, but it would make the code not look normal.

00:35:41.100 --> 00:35:44.800
It'd be like all these weird things you have to do to like Async to Syncify.

00:35:44.800 --> 00:35:48.520
And we'll see some frameworks that might even do something in that regard for you.

00:35:48.520 --> 00:35:49.920
But this is really nice.

00:35:49.920 --> 00:35:55.560
It just seems like if you're testing code that is Async, clearly this is something like this is what you want.

00:35:55.840 --> 00:35:56.740
Also, mocking.

00:35:56.740 --> 00:36:00.440
I hadn't really thought about mocking Async methods, but I guess you need some.

00:36:00.440 --> 00:36:01.340
I've done this.

00:36:01.340 --> 00:36:03.140
I haven't used this IOMock.

00:36:03.140 --> 00:36:09.880
So there is, I think even in UnitestMock, there's an AsyncMock class which you can use.

00:36:09.880 --> 00:36:12.360
I'm not really sure why you would need this.

00:36:12.360 --> 00:36:13.920
This has changed six years ago.

00:36:13.920 --> 00:36:20.320
I wonder if the asynchronous mocking capabilities were not in the framework itself when this got created.

00:36:20.320 --> 00:36:23.860
And then probably like, you know what, we should just be able to test our own stuff.

00:36:23.860 --> 00:36:24.780
So let's fix that.

00:36:24.780 --> 00:36:25.980
Yeah, I'm guessing.

00:36:25.980 --> 00:36:27.160
Okay, pretty nice.

00:36:27.160 --> 00:36:30.560
You mentioned uv loop before in one of the sections.

00:36:30.560 --> 00:36:34.660
This is maybe the only section that has a single item in it, but it's a big one.

00:36:34.660 --> 00:36:35.520
UV loop, right?

00:36:35.520 --> 00:36:35.880
Yes.

00:36:35.880 --> 00:36:36.620
For alternate loops.

00:36:36.620 --> 00:36:37.200
Yeah, exactly.

00:36:37.200 --> 00:36:42.240
So you could use, if you're on AsyncIO, you can just use the one which is in like CPython.

00:36:42.240 --> 00:36:43.540
You could just use that.

00:36:43.540 --> 00:36:49.360
But there is other implementation like this uv loop, which is based on LiveUV, which is another

00:36:49.360 --> 00:36:50.580
events loop in C.

00:36:50.580 --> 00:36:54.940
And it just is super fast compared to the built-in implementation.

00:36:54.940 --> 00:36:57.780
I think it's for production use cases.

00:36:57.780 --> 00:37:03.360
It's so nice because in order to use it, a lot of times if it's just literally installed in

00:37:03.360 --> 00:37:04.900
the environment, things will use it.

00:37:04.900 --> 00:37:08.420
Like I believe UVicorn will use it if it finds it and some other things.

00:37:08.420 --> 00:37:10.400
You don't even have to say, please use it.

00:37:10.400 --> 00:37:11.280
It's just like, oh, it's available.

00:37:11.280 --> 00:37:11.780
Let's go.

00:37:11.780 --> 00:37:16.520
And if for some reason you need to explicitly use it, like in your code, you just say UV

00:37:16.520 --> 00:37:16.820
loop.

00:37:16.820 --> 00:37:21.980
You say asyncIO.setEventLoopPolicy and you pass over the uv loop policy class.

00:37:21.980 --> 00:37:24.260
And now the rest of your program just uses that.

00:37:24.260 --> 00:37:25.080
It's really nice.

00:37:25.080 --> 00:37:29.120
And don't really know how many other like alternative implementations actually.

00:37:29.120 --> 00:37:29.760
Yeah, I don't either.

00:37:29.760 --> 00:37:30.960
But it's really nice.

00:37:30.960 --> 00:37:33.400
And it basically bundles up, as you said, LiveUV.

00:37:33.400 --> 00:37:35.300
They've got some nice performance graphs.

00:37:35.300 --> 00:37:38.480
It says uv loop makes asyncIO two to four times faster.

00:37:38.480 --> 00:37:42.920
Who wouldn't want your asyncIO code to just go two to four times faster with no effort?

00:37:42.920 --> 00:37:43.220
Yeah.

00:37:43.220 --> 00:37:45.680
And it's super easy to install and use.

00:37:45.680 --> 00:37:48.320
So there's no really downside to that.

00:37:48.320 --> 00:37:50.680
Mario has a totally reasonable question.

00:37:51.080 --> 00:37:54.460
Why wouldn't uv loop just be the standard ASyncIO implementation then?

00:37:54.460 --> 00:37:55.100
What's the catch?

00:37:55.100 --> 00:38:01.680
Well, I don't know what the catch is, but I could assume that it's easier to change outside of

00:38:01.680 --> 00:38:03.680
the CPython development cycle.

00:38:04.180 --> 00:38:06.420
And probably that could be one of the reasons.

00:38:06.420 --> 00:38:06.920
I don't know.

00:38:06.920 --> 00:38:07.500
I don't agree.

00:38:07.500 --> 00:38:08.320
That's a good idea.

00:38:08.320 --> 00:38:12.920
Also, you know, do you want Python itself to take on LiveUV?

00:38:12.920 --> 00:38:13.460
I'm sorry.

00:38:13.460 --> 00:38:13.740
Yeah.

00:38:13.740 --> 00:38:15.960
LiveUV as a C dependency.

00:38:15.960 --> 00:38:22.260
And then third, when I played with uv loop originally, it's been a few years, it didn't

00:38:22.260 --> 00:38:23.560
work at all on Windows.

00:38:23.560 --> 00:38:27.940
Like its implementation of LiveUV was a, for whatever reason, it just wouldn't install

00:38:27.940 --> 00:38:28.400
on Windows.

00:38:28.500 --> 00:38:31.700
And that obviously is a breaking change or a stopper.

00:38:31.700 --> 00:38:36.540
So maybe even if it works on Windows, maybe there's like some obscure place where Python

00:38:36.540 --> 00:38:42.640
runs, but LiveUV won't, you know, think of like some small device like a Raspberry Pi

00:38:42.640 --> 00:38:43.000
or whatever.

00:38:43.000 --> 00:38:43.480
I don't know.

00:38:43.480 --> 00:38:44.000
Yeah.

00:38:44.000 --> 00:38:48.260
And I think we're coming down to the discussion you had before about the benchmarking again,

00:38:48.260 --> 00:38:51.980
that maybe not everyone actually wants this feed or needs this feed.

00:38:51.980 --> 00:38:52.320
Yeah.

00:38:52.320 --> 00:38:55.940
Maybe it's just for like a very optimized production use cases.

00:38:55.940 --> 00:38:58.260
And you actually need this four times faster.

00:38:58.260 --> 00:39:01.680
And for all the other use cases, maybe it's your code that is slow anyways.

00:39:01.680 --> 00:39:03.260
You don't really care too much.

00:39:03.260 --> 00:39:03.460
Yeah.

00:39:03.460 --> 00:39:09.320
There was a discussion about a few years ago about why is requests not just built into

00:39:09.320 --> 00:39:10.320
Python, right?

00:39:10.320 --> 00:39:16.140
They're like, well, there's URL stuff in there, but it's way less obvious how to use it compared

00:39:16.140 --> 00:39:23.180
to just request.get done and response.json when you get your response back and whatnot.

00:39:23.180 --> 00:39:26.680
And they debated that at the core dev summit.

00:39:26.680 --> 00:39:31.640
And they decided if we put requests into CPython, kind of like you were saying, is it will,

00:39:31.640 --> 00:39:35.760
it'll actually slow the progress and the evolution of requests itself.

00:39:35.760 --> 00:39:40.180
And they wanted to keep this nice library, its own thing that could go at its own pace.

00:39:42.740 --> 00:39:45.800
This portion of Talk Python To Me is brought to you by Sentry.

00:39:45.800 --> 00:39:48.680
How would you like to remove a little stress from your life?

00:39:48.680 --> 00:39:54.360
Do you worry that users may be encountering errors, slowdowns, or crashes with your app right

00:39:54.360 --> 00:39:54.680
now?

00:39:54.680 --> 00:39:57.720
Would you even know it until they sent you that support email?

00:39:57.720 --> 00:40:02.480
How much better would it be to have the error or performance details immediately sent to you,

00:40:02.480 --> 00:40:07.800
including the call stack and values of local variables and the active user recorded in the

00:40:07.800 --> 00:40:08.120
report?

00:40:08.580 --> 00:40:11.540
With Sentry, this is not only possible, it's simple.

00:40:11.540 --> 00:40:15.100
In fact, we use Sentry on all the Talk Python web properties.

00:40:15.100 --> 00:40:20.640
We've actually fixed a bug triggered by a user and had the upgrade ready to roll out as we

00:40:20.640 --> 00:40:21.660
got the support email.

00:40:21.660 --> 00:40:23.640
That was a great email to write back.

00:40:23.640 --> 00:40:27.020
Hey, we already saw your error and have already rolled out the fix.

00:40:27.020 --> 00:40:28.440
Imagine their surprise.

00:40:28.440 --> 00:40:30.660
Surprise and delight your users.

00:40:30.660 --> 00:40:34.720
Create your Sentry account at talkpython.fm/sentry.

00:40:34.940 --> 00:40:40.200
And if you sign up with the code talkpython, all one word, it's good for two free months

00:40:40.200 --> 00:40:45.480
of Sentry's business plan, which will give you up to 20 times as many monthly events as

00:40:45.480 --> 00:40:46.400
well as other features.

00:40:46.400 --> 00:40:50.800
Create better software, delight your users, and support the podcast.

00:40:50.800 --> 00:40:55.780
Visit talkpython.fm/sentry and use the coupon code talkpython.

00:40:58.280 --> 00:40:59.300
Yeah, makes sense.

00:40:59.300 --> 00:41:04.920
I think there, I also heard that the security there, it's easier to patch the library in

00:41:04.920 --> 00:41:11.160
like on PyPI and make people an update than shipping a hotfix release or whatever of Python

00:41:11.160 --> 00:41:12.540
to fix those security issues.

00:41:12.540 --> 00:41:13.020
Absolutely.

00:41:13.020 --> 00:41:18.420
And Brandon just says, I just learned that FastAPI starlet use uv loop by default.

00:41:18.420 --> 00:41:20.560
Yeah, that's what I, that's one of the things I was thinking of.

00:41:20.560 --> 00:41:24.400
If it's installed in the virtual environment and it has access to it, it'll just take it and

00:41:24.400 --> 00:41:24.580
go.

00:41:24.580 --> 00:41:26.840
No need to make any changes there.

00:41:27.340 --> 00:41:27.820
All right, awesome.

00:41:27.820 --> 00:41:32.320
So that's just one, the one thing in the alternate loop section, but quite, quite neat

00:41:32.320 --> 00:41:32.660
indeed.

00:41:32.660 --> 00:41:35.380
And then there's got to be a miscellaneous, right?

00:41:35.380 --> 00:41:36.500
There's got to be a utils.

00:41:36.500 --> 00:41:37.980
There's got to be a helpers.

00:41:37.980 --> 00:41:40.640
There's got to be something that's just like, well, what the heck is this?

00:41:40.640 --> 00:41:43.280
Tell us about the grab bag at the end here.

00:41:43.280 --> 00:41:46.120
Yeah, there's a few here, which I find very interesting.

00:41:46.120 --> 00:41:52.180
The first one here is Iocham, which adds a CSV style concurrency feature.

00:41:52.180 --> 00:41:56.400
So if you've, if you've done some Go programming, you came across channels, I

00:41:56.400 --> 00:42:01.080
would say this IO gen brings these kinds of patterns into Async IO.

00:42:01.380 --> 00:42:07.320
So basically what you will have is you can create a channel and then you can have multiple

00:42:07.320 --> 00:42:12.820
coroutines like a producer and a consumer listening and writing to this channel and you can have

00:42:12.820 --> 00:42:13.960
it buffered or not.

00:42:13.960 --> 00:42:19.520
And these kinds of things can select on multiple channels and react on incoming data and these

00:42:19.520 --> 00:42:19.960
kinds of things.

00:42:19.960 --> 00:42:26.000
So it's just another, other way to communicate between your coroutines than what you would probably do with the built-in

00:42:26.000 --> 00:42:26.340
mechanisms.

00:42:26.340 --> 00:42:26.700
Sure.

00:42:26.700 --> 00:42:33.400
And a lot of those patterns are incredibly hard to get just right with the event signaling and all those things.

00:42:33.400 --> 00:42:33.520
Yes.

00:42:33.720 --> 00:42:36.360
And so if you can just hook it in, then it's good to go.

00:42:36.360 --> 00:42:39.000
You could probably make this work with queues and events.

00:42:39.000 --> 00:42:39.640
Yes.

00:42:39.760 --> 00:42:42.480
And then all these, but it's nice to have the abstraction.

00:42:42.480 --> 00:42:43.040
Yeah.

00:42:43.040 --> 00:42:43.460
Of these.

00:42:43.460 --> 00:42:44.020
Exactly.

00:42:44.020 --> 00:42:45.360
These primitives.

00:42:45.560 --> 00:42:45.680
Yeah.

00:42:45.680 --> 00:42:50.540
It's sort of equivalent to saying, well, you've got a HTTP server built into Python itself.

00:42:50.540 --> 00:42:51.740
Like, why do you need Flask?

00:42:51.740 --> 00:42:53.240
No, no, no, no.

00:42:53.240 --> 00:42:55.160
No, we don't want to do this.

00:42:55.160 --> 00:43:01.560
Other notable ones here, like one that stood out to me is AIO cache, which is pretty straightforward.

00:43:01.560 --> 00:43:02.760
It's like just a cache, right?

00:43:02.760 --> 00:43:06.140
Add, get, set, even has a cool increment and so on.

00:43:06.140 --> 00:43:12.160
But it's Async IO and it talks to Redis, Memcache, Redis and Memcache, MessagePack, a bunch of

00:43:12.160 --> 00:43:13.880
different capabilities it has, right?

00:43:13.880 --> 00:43:14.200
Yeah.

00:43:14.200 --> 00:43:15.000
It looks super cool.

00:43:15.080 --> 00:43:15.760
I haven't used it.

00:43:15.760 --> 00:43:19.920
But yeah, it's nice that you can just switch out the backends and use something else.

00:43:19.920 --> 00:43:24.300
Also, the API looks very straightforward with like just .set, .get.

00:43:24.300 --> 00:43:29.820
It's pretty straightforward to, you know, await a cache.get or await a cache.set.

00:43:29.820 --> 00:43:30.020
Yeah.

00:43:30.020 --> 00:43:32.880
It seems like a real nice, real nice API.

00:43:32.880 --> 00:43:39.560
The decorators will look interesting so that you can cache our coroutines, probably.

00:43:39.560 --> 00:43:40.460
Yeah, exactly.

00:43:40.460 --> 00:43:42.820
That's just, that I didn't really catch that before you.

00:43:42.820 --> 00:43:43.040
Right.

00:43:43.140 --> 00:43:46.300
So people are probably familiar with the func tools.

00:43:46.300 --> 00:43:47.120
LRU cache.

00:43:47.120 --> 00:43:48.080
LTS cache.

00:43:48.080 --> 00:43:49.480
The LRU cache.

00:43:49.480 --> 00:43:49.680
Yes.

00:43:49.680 --> 00:43:52.300
I'm like, oh, there's a, it's not a T. LRU cache.

00:43:52.300 --> 00:43:52.760
Thank you.

00:43:52.760 --> 00:43:54.080
But this is that idea.

00:43:54.080 --> 00:43:57.700
But instead of saying, well, where you cache that is in memory, as you just say, cache

00:43:57.700 --> 00:43:59.660
equals Redis, which is like, wait a minute.

00:43:59.820 --> 00:44:00.120
Okay.

00:44:00.120 --> 00:44:01.020
That's cool.

00:44:01.020 --> 00:44:01.960
That's really cool.

00:44:01.960 --> 00:44:02.420
It's cool.

00:44:02.420 --> 00:44:06.980
Just make sure the latency is lower than actually your execution time.

00:44:06.980 --> 00:44:08.920
But yeah, it looks very nice.

00:44:08.920 --> 00:44:10.520
That's a really good point.

00:44:10.520 --> 00:44:14.440
Like if you call this a bunch of times and the Redis is far away, like it actually might

00:44:14.440 --> 00:44:15.140
just be slower.

00:44:15.140 --> 00:44:15.600
Yeah.

00:44:15.800 --> 00:44:17.460
But the CPU will be nice and low.

00:44:17.460 --> 00:44:18.280
So you'll be fine.

00:44:18.280 --> 00:44:19.020
You'll be fine.

00:44:19.020 --> 00:44:19.200
Yes.

00:44:19.460 --> 00:44:20.420
This is a cool project.

00:44:20.420 --> 00:44:26.800
Another one that I really like, I think adds some important capabilities is AIO files.

00:44:26.800 --> 00:44:27.820
Tell us about that one.

00:44:27.820 --> 00:44:28.040
Yeah.

00:44:28.040 --> 00:44:33.280
It basically provides you, say, file API support like you have with normal, like open

00:44:33.280 --> 00:44:36.860
and these kinds of functions and do it async with asyncio.

00:44:36.860 --> 00:44:42.320
But I'm not sure if I read it here, but I think on some platforms like Linux, it's hard

00:44:42.320 --> 00:44:45.960
to actually implement this correctly with like ePoll and stuff.

00:44:45.960 --> 00:44:48.700
I don't know if you know more about this, but I heard it.

00:44:48.700 --> 00:44:53.040
It's not really a big benefit actually to run it async.

00:44:53.040 --> 00:44:53.240
Yeah.

00:44:53.240 --> 00:44:54.120
I don't know either.

00:44:54.120 --> 00:44:58.960
What it claims here is it doesn't try to, I don't think it tries to do fancy work with

00:44:58.960 --> 00:45:01.400
truly hooking into asynchronous stuff in the file.

00:45:01.400 --> 00:45:04.520
So it just says, it's just going to run it on a background thread basically.

00:45:04.520 --> 00:45:05.160
Oh yeah.

00:45:05.160 --> 00:45:07.560
So it probably creates like a worker thread.

00:45:07.560 --> 00:45:10.660
And whenever you ask to read it, just in the back, it goes open.

00:45:10.660 --> 00:45:16.000
And then when you say a wait read, it's just on that thread, it maybe sets an event and

00:45:16.000 --> 00:45:16.960
then does a read or something.

00:45:16.960 --> 00:45:19.540
I don't know, a little bit of like juggling background threads.

00:45:19.540 --> 00:45:20.440
But yeah.

00:45:20.440 --> 00:45:24.100
So it, in a sense, it may make it actually timely bit slower.

00:45:24.100 --> 00:45:29.300
But if you're doing an API and the API has got to read or write a big file, that could be

00:45:29.300 --> 00:45:29.580
a problem.

00:45:29.580 --> 00:45:33.480
The other one is, you know, we'll see this in a couple of things we're discussing in

00:45:33.480 --> 00:45:33.980
this section.

00:45:34.400 --> 00:45:35.400
So it's a lot of things that we're talking about.

00:45:35.400 --> 00:45:35.400
It could be a lot of things that we're talking about.

00:45:35.400 --> 00:45:35.400
It could be a lot of things that we're talking about.

00:45:35.400 --> 00:45:35.400
It could be a lot of things that we're talking about.

00:45:35.400 --> 00:45:35.400
It could be a lot of things that we're talking about.

00:45:35.400 --> 00:45:35.400
It could be a lot of things that we're talking about.

00:45:35.400 --> 00:45:36.400
It could be a lot of things that we're talking about.

00:45:36.400 --> 00:45:37.400
It could be a lot of things that we're talking about.

00:45:37.400 --> 00:45:39.400
user slash whatever.

00:45:39.400 --> 00:45:45.280
But it could be backslash backslash network server backslash network drive, right?

00:45:45.280 --> 00:45:50.800
It could be very, very slow where all of a sudden, you know, unlocking that, that access

00:45:50.800 --> 00:45:52.000
is a huge deal.

00:45:52.000 --> 00:45:52.440
Yeah.

00:45:52.440 --> 00:45:52.880
Yeah.

00:45:52.880 --> 00:45:54.380
Does this actually support us?

00:45:54.380 --> 00:45:55.720
talking network files?

00:45:55.720 --> 00:45:56.320
Oh, yeah.

00:45:56.320 --> 00:45:57.480
With multiple drive here.

00:45:57.480 --> 00:45:57.980
Okay.

00:45:57.980 --> 00:45:58.720
Yeah, exactly.

00:45:58.720 --> 00:45:58.980
Yeah.

00:45:58.980 --> 00:46:02.620
Like what the thing you're talking to might actually be far away, you know?

00:46:02.620 --> 00:46:03.620
Yeah, exactly.

00:46:03.620 --> 00:46:08.960
It does say handling local disk files, but I bet if you mapped it in your OS, it wouldn't

00:46:08.960 --> 00:46:09.960
know, you know?

00:46:09.960 --> 00:46:10.960
Yeah, probably would work.

00:46:10.960 --> 00:46:11.960
Yeah.

00:46:11.960 --> 00:46:14.960
What I also like here, there is also an IO path.

00:46:14.960 --> 00:46:15.960
Yes.

00:46:15.960 --> 00:46:19.960
Which, that one actually looks maybe even cooler, right?

00:46:19.960 --> 00:46:20.960
Yeah.

00:46:20.960 --> 00:46:27.000
I think a lot of people are using pathlet these days and IO path basically gives you an async

00:46:27.000 --> 00:46:31.960
path type, which you can just wrap around your strings or path objects.

00:46:31.960 --> 00:46:35.880
And you get the same methods, but just, you can evade them basically.

00:46:35.880 --> 00:46:41.200
So you can, you can have your path.open, path.exist and you have, need to use an upgrade.

00:46:41.200 --> 00:46:42.140
This is for you.

00:46:42.140 --> 00:46:46.780
I don't know here how it's implemented, if it's also using background threads or if it

00:46:46.780 --> 00:46:48.060
doesn't match it.

00:46:48.060 --> 00:46:52.600
Does it actually hook into the true IO completion ports and all that kind of business?

00:46:52.600 --> 00:46:52.860
Yeah.

00:46:52.860 --> 00:46:53.540
Yeah.

00:46:53.540 --> 00:46:54.440
So this is really cool.

00:46:54.440 --> 00:46:57.340
So you could create, we all know about path from pathlib.

00:46:57.340 --> 00:46:58.300
It's super neat.

00:46:58.600 --> 00:47:01.100
And you can ask it questions like, does it exist?

00:47:01.100 --> 00:47:03.380
Or, you know, create this directory?

00:47:03.380 --> 00:47:05.220
Or is it a directory?

00:47:05.220 --> 00:47:09.780
Or you can actually say, read bytes, write bytes, read text.

00:47:09.780 --> 00:47:13.520
There's a lot of things that you would do with a context manager that become just one-liners

00:47:13.520 --> 00:47:14.200
with pathlib.

00:47:14.200 --> 00:47:18.460
And this async pathlets, you make all those asynchronous, you're like, await pathlet exists,

00:47:18.460 --> 00:47:20.340
await write bytes, and so on.

00:47:20.340 --> 00:47:24.580
And the cool thing is there really, I think, try to be a drop-in replacement for pathlib

00:47:24.580 --> 00:47:26.460
in the asyncio world.

00:47:26.460 --> 00:47:31.460
So if you've been having a code base or have been using pathlib in an async code base, it's

00:47:31.460 --> 00:47:34.880
super easy to just switch to an async version of pathlib.

00:47:34.880 --> 00:47:35.440
Oh, excellent.

00:47:35.440 --> 00:47:37.180
It says the implementation here.

00:47:37.180 --> 00:47:37.700
Let's see.

00:47:37.700 --> 00:47:39.100
Does it tell us?

00:47:39.100 --> 00:47:41.640
It inherits from pure path, which is cool.

00:47:41.640 --> 00:47:46.740
So you could use it as an argument to some of these, some of the pieces that will take path

00:47:46.740 --> 00:47:47.660
objects directly.

00:47:47.660 --> 00:47:53.440
It takes advantage of lib AIO for asyncio on Linux, which is probably where you care

00:47:53.440 --> 00:47:55.960
most about performance because that's where your server is, right?

00:47:55.960 --> 00:47:56.380
Yeah.

00:47:56.380 --> 00:48:00.840
I don't know anything about lib AIO, but that's probably some sort of native type thing going

00:48:00.840 --> 00:48:01.100
on there.

00:48:01.100 --> 00:48:04.040
Like Linux native asynchronous IO access library.

00:48:04.040 --> 00:48:05.340
Yeah, that's okay.

00:48:05.340 --> 00:48:07.420
So maybe this is not just a little bit better.

00:48:07.420 --> 00:48:11.520
Yeah, maybe it's not just a little bit better than AO files because, well, you can work with

00:48:11.520 --> 00:48:15.020
path objects, but it has like an OS level implementation as well.

00:48:15.020 --> 00:48:15.640
That's pretty cool.

00:48:15.640 --> 00:48:16.100
All right.

00:48:16.220 --> 00:48:16.700
I'm using it.

00:48:16.700 --> 00:48:18.300
I'm using it.

00:48:18.300 --> 00:48:18.840
It looks good.

00:48:18.840 --> 00:48:19.100
Yeah.

00:48:19.100 --> 00:48:21.080
That looks like, those are all the ones that jumped out at me.

00:48:21.080 --> 00:48:26.220
Those, those two that you called out there, those cache and the files or the, and the path

00:48:26.220 --> 00:48:26.760
history, I guess.

00:48:26.760 --> 00:48:28.800
Anything else worth mentioning real quick?

00:48:28.800 --> 00:48:29.180
I think so.

00:48:29.180 --> 00:48:33.700
I mean, the misc one is just a miscellaneous package in the miscellaneous packages, I would

00:48:33.700 --> 00:48:33.940
say.

00:48:33.940 --> 00:48:38.320
So yeah, when I saw that, I thought this is probably the longer thing, maybe it's in there.

00:48:38.320 --> 00:48:44.760
It's like the meta, meta miscellaneous, it's like the, or miscellaneous squared or something

00:48:44.760 --> 00:48:45.160
like that.

00:48:45.220 --> 00:48:45.440
That's right.

00:48:45.440 --> 00:48:48.480
A bunch of random helper things in there.

00:48:48.480 --> 00:48:48.840
That's cool.

00:48:48.840 --> 00:48:49.760
Then you have some stuff.

00:48:49.760 --> 00:48:51.100
Let me just go real quickly flip through.

00:48:51.100 --> 00:48:56.180
Like there's some stuff on writing, like tutorials and articles, and then some video talks about

00:48:56.180 --> 00:48:57.820
Async.io in there, right?

00:48:57.820 --> 00:48:58.980
I think there are good ones.

00:48:59.100 --> 00:49:02.860
I think a lot of them are actually from David Beasley.

00:49:02.860 --> 00:49:03.480
I'm not sure.

00:49:03.480 --> 00:49:03.660
Yeah.

00:49:03.660 --> 00:49:08.900
David Beasley has done some cool stuff with kind of recreating Async.io live in the early

00:49:08.900 --> 00:49:09.280
days.

00:49:09.280 --> 00:49:09.760
Yeah.

00:49:09.760 --> 00:49:11.620
And then Yuri, who we spoke about.

00:49:11.620 --> 00:49:12.140
Yeah.

00:49:12.140 --> 00:49:16.520
If you really want to know like how you can think about like a mental model of Async.io,

00:49:16.520 --> 00:49:18.960
I think these are very good talks.

00:49:18.960 --> 00:49:20.280
She's better understand.

00:49:20.280 --> 00:49:20.840
Absolutely.

00:49:20.840 --> 00:49:21.480
Cool.

00:49:21.620 --> 00:49:22.700
I don't know about this guy though.

00:49:22.700 --> 00:49:23.620
All right.

00:49:23.620 --> 00:49:29.680
The last thing you closed it out with is alternative implementations to Async.io, not just like

00:49:29.680 --> 00:49:34.440
a tool you can use within Async.io, but there's Curio and Trio are like probably the big two

00:49:34.440 --> 00:49:34.880
there, right?

00:49:34.880 --> 00:49:39.020
I think Curio, I think it's from David Beasley as well, but I don't think it's maintained

00:49:39.020 --> 00:49:41.620
really, but I think it's been a nice experiment.

00:49:41.620 --> 00:49:45.180
And at the time I looked at it, it was kind of minimal in the implementation.

00:49:45.180 --> 00:49:49.660
So you could kind of digest and see how something would be done like Async.io.

00:49:49.660 --> 00:49:50.060
Okay.

00:49:50.060 --> 00:49:52.420
There's Trio, which I think is still out there.

00:49:52.420 --> 00:49:58.900
And that's also why any.io exists probably because it kind of, you can use any.io as a

00:49:58.900 --> 00:50:04.040
front end for Trio or Async.io and add some more high level features on top of Async.io.

00:50:04.040 --> 00:50:04.320
Yeah.

00:50:04.320 --> 00:50:09.800
I recently had Alex from Any.io, Creative Any.io on there and just real quick shout out

00:50:09.800 --> 00:50:14.180
for some of the things I thought was cool over there is it could run on top of Async.io or

00:50:14.180 --> 00:50:15.160
Trio, which is cool.

00:50:15.160 --> 00:50:23.380
It also has some really interesting aspects for like converting threads into converting regular

00:50:23.380 --> 00:50:27.420
functions into awaitable things by running them on other threads.

00:50:27.420 --> 00:50:30.920
And it can either do that on a thread or it can even do that on a sub process.

00:50:30.920 --> 00:50:36.560
So you can like go and say await run process and then you get its value back, right?

00:50:36.560 --> 00:50:43.940
Or you could do that with sort of multi-processing or even create a asynchronous for loop over

00:50:43.940 --> 00:50:47.200
the output stream, like standard out of some process.

00:50:47.200 --> 00:50:49.200
I could have used this a few times in the past.

00:50:49.680 --> 00:50:50.400
Yes, I know.

00:50:50.400 --> 00:50:53.040
Like this is really, really neat to be able to do that.

00:50:53.040 --> 00:50:56.860
And the other thing is the synchronization primitives like events and semaphores.

00:50:56.860 --> 00:51:01.520
There's, he says, I haven't tried it out really, but they're supposed to be a little bit less

00:51:01.520 --> 00:51:05.640
likely to get deadlocks or race conditions because you can't, they're not reentrant basically.

00:51:05.640 --> 00:51:06.020
Okay.

00:51:06.020 --> 00:51:06.660
Nice.

00:51:06.780 --> 00:51:06.940
Yeah.

00:51:06.940 --> 00:51:10.380
So there's a cool bunch of cool little helper type things in the IO there.

00:51:10.380 --> 00:51:12.220
But well, that's pretty much it.

00:51:12.220 --> 00:51:16.880
I think for, for the list, that was a lot, but a lot of good stuff.

00:51:16.880 --> 00:51:17.780
A lot of awesome stuff.

00:51:17.780 --> 00:51:18.240
Wouldn't you say?

00:51:18.240 --> 00:51:18.700
Yeah.

00:51:18.840 --> 00:51:21.340
And I'm sure there's more awesome stuff out there.

00:51:21.340 --> 00:51:23.260
Like the Esco live one we've covered.

00:51:23.260 --> 00:51:26.720
You added one five minutes before the, before the talk.

00:51:26.720 --> 00:51:30.180
Because I was going through, because I was going through, I'm like, oh yeah, this one,

00:51:30.180 --> 00:51:31.160
like I was looking at motor.

00:51:31.160 --> 00:51:32.780
I'm like, oh, well, the stuff built on motor.

00:51:32.780 --> 00:51:33.680
There's some good ones there.

00:51:33.680 --> 00:51:35.980
Let's throw those in and people can vote for them if they want.

00:51:35.980 --> 00:51:40.440
But yeah, there's, I'm sure that people listening, if they maintain one of these libraries

00:51:40.440 --> 00:51:44.220
or they're big fans and use one a lot that's not on the list, you know, go make a PR,

00:51:44.220 --> 00:51:44.480
right?

00:51:44.480 --> 00:51:45.040
Absolutely.

00:51:45.040 --> 00:51:45.360
Yeah.

00:51:45.360 --> 00:51:50.440
I also plan to add some more automation so that we can, for example, check for dead

00:51:50.440 --> 00:51:50.820
links.

00:51:50.820 --> 00:51:55.300
It would also be nice to kind of catch outdated libraries, like the, which one, like the IO

00:51:55.300 --> 00:51:56.560
mock we've seen before.

00:51:56.560 --> 00:51:57.420
Yes, exactly.

00:51:57.420 --> 00:52:00.760
Like, you know, if it hasn't been touched in six years, it probably isn't needed anymore,

00:52:00.760 --> 00:52:01.080
right?

00:52:01.080 --> 00:52:01.720
Could fade.

00:52:01.720 --> 00:52:02.280
Exactly.

00:52:02.280 --> 00:52:02.800
Awesome.

00:52:02.800 --> 00:52:07.060
I mean, this is a great resource and I sort of shouted out the popularity of some of

00:52:07.060 --> 00:52:07.880
these projects to give us.

00:52:07.880 --> 00:52:10.620
And it's like, your list has got 3.7 thousand stars.

00:52:10.620 --> 00:52:11.840
Like that's pretty awesome.

00:52:11.840 --> 00:52:13.640
That's a lot of people who got value from it.

00:52:13.640 --> 00:52:13.980
It is.

00:52:14.220 --> 00:52:18.140
And I can only recommend to, to look at these lists, you know, whatever list it is, there,

00:52:18.140 --> 00:52:21.240
there are gems in there and it's kind of nice to discover them.

00:52:21.240 --> 00:52:21.940
Yeah, absolutely.

00:52:21.940 --> 00:52:23.840
Really quick out in the audience.

00:52:23.840 --> 00:52:26.960
Mato's logic says starlit, I'm sorry.

00:52:26.960 --> 00:52:33.080
Star light is an async framework built on top of star lit and Pydantic, which is a good

00:52:33.080 --> 00:52:33.560
candidate.

00:52:33.560 --> 00:52:38.100
I didn't actually give a shout out to it, but I thought, oh no, it's not on there.

00:52:38.100 --> 00:52:38.300
Okay.

00:52:38.300 --> 00:52:42.480
Well, PRs, PRs are accepted and reviewed star light.

00:52:42.480 --> 00:52:43.120
There you go.

00:52:43.120 --> 00:52:43.980
Cool.

00:52:43.980 --> 00:52:44.500
All right.

00:52:44.500 --> 00:52:49.160
Timo, this is really excellent project here and a ton of people are getting value from it.

00:52:49.160 --> 00:52:50.300
So thanks for putting it together.

00:52:50.300 --> 00:52:50.620
Yeah.

00:52:50.620 --> 00:52:53.560
Thanks to all the people who, who suggested the awesome stuff.

00:52:53.680 --> 00:52:56.060
So I'm, as I said, merely the maintainer of the list.

00:52:56.060 --> 00:52:59.120
So keep them coming and we'll make it even better.

00:52:59.120 --> 00:52:59.500
Excellent.

00:52:59.500 --> 00:53:00.360
All right.

00:53:00.360 --> 00:53:02.280
Before we get out of here, final two questions.

00:53:02.280 --> 00:53:06.800
I feel like you could just randomly pick one from your list, but the notable PyPI part

00:53:06.800 --> 00:53:08.160
project you want to give a shout out to?

00:53:08.280 --> 00:53:11.220
I think it's not even on there, but this, it will be tenacity.

00:53:11.220 --> 00:53:11.980
Oh yeah.

00:53:11.980 --> 00:53:12.900
Tenacity is good.

00:53:12.900 --> 00:53:13.440
Yeah.

00:53:13.440 --> 00:53:15.580
It's a library for retrying stuff.

00:53:15.580 --> 00:53:17.460
I think it has async.

00:53:17.460 --> 00:53:19.120
I'm pretty sure it has async.

00:53:19.120 --> 00:53:19.500
Okay.

00:53:19.500 --> 00:53:20.440
Let's see.

00:53:20.440 --> 00:53:22.800
But it makes it super nice if you have like network.

00:53:22.800 --> 00:53:24.200
Async retries.

00:53:24.200 --> 00:53:24.800
There you go.

00:53:24.800 --> 00:53:25.080
Yeah.

00:53:25.080 --> 00:53:28.360
So it's, it's even the same decorator, which is cool from an API perspective.

00:53:28.360 --> 00:53:31.340
I don't even think you have to import something else, like something differently.

00:53:31.340 --> 00:53:31.740
Right.

00:53:31.740 --> 00:53:35.480
Because you can actually inspect the function, which is being decorated and you can decide what

00:53:35.480 --> 00:53:35.820
to run.

00:53:35.820 --> 00:53:36.840
Pretty cool.

00:53:37.020 --> 00:53:41.840
I suggest you use it if you, if you want to retry something or have like unstable endpoints

00:53:41.840 --> 00:53:42.300
or whatever.

00:53:42.300 --> 00:53:42.860
Yeah.

00:53:42.860 --> 00:53:44.440
And all the features you need to call it.

00:53:44.440 --> 00:53:45.980
This is a great library.

00:53:45.980 --> 00:53:51.600
You know, if you were consuming someone else's API and that thing is flaky, you know, what

00:53:51.600 --> 00:53:52.260
are you supposed to do?

00:53:52.260 --> 00:53:52.460
Right.

00:53:52.460 --> 00:53:56.660
You, you've got to call it potentially, but you can't count it always working.

00:53:56.660 --> 00:54:00.440
I've run into that problem on a lot of my projects as well.

00:54:00.440 --> 00:54:04.920
And I've either done something like tenacity where you just say, retry it with some kind of

00:54:04.920 --> 00:54:10.560
exponential back off or I'll go through and cash it in my database and say, I'm going to

00:54:10.560 --> 00:54:10.980
try it.

00:54:10.980 --> 00:54:14.860
If it fails, I'm going to go get it from the database and go, it might be a little bit stale,

00:54:14.860 --> 00:54:19.220
but at least this, you know, if it's something kind of stable, like a currency lookup, like,

00:54:19.220 --> 00:54:24.200
okay, an hour ago, the dollar to Swiss francs, the lookup was this.

00:54:24.200 --> 00:54:28.080
And it might not be perfect, but it's better than just going 500 server error.

00:54:28.080 --> 00:54:34.260
I don't know how many like wire loops I've written in my life to kind of check a timeout

00:54:34.260 --> 00:54:36.780
and then retry and sleep and these kind of things.

00:54:36.780 --> 00:54:41.280
And it's hard to get this right because, you know, you want to catch termination of the,

00:54:41.280 --> 00:54:43.380
of the program and cancel these things.

00:54:43.380 --> 00:54:45.380
So it's nice to have a library for all.

00:54:45.380 --> 00:54:45.840
Yeah, cool.

00:54:45.840 --> 00:54:49.020
And the fact that they support async is like perfectly blends in.

00:54:49.020 --> 00:54:50.880
You should add it to the news as well.

00:54:50.980 --> 00:54:51.160
Yeah.

00:54:51.160 --> 00:54:51.460
Yeah.

00:54:51.460 --> 00:54:53.200
Actually it would belong there, wouldn't it now?

00:54:53.200 --> 00:54:53.860
All right.

00:54:53.860 --> 00:54:57.540
And then the other question is if you're going to write some Python code, what editor are you

00:54:57.540 --> 00:54:58.180
using these days?

00:54:58.180 --> 00:54:59.420
These days, VS Code.

00:54:59.420 --> 00:55:02.020
It's important though that it has been key bindings.

00:55:02.020 --> 00:55:04.120
I've been an end user for quite some time.

00:55:04.120 --> 00:55:05.880
So I certainly need that.

00:55:05.880 --> 00:55:06.280
Yeah.

00:55:06.280 --> 00:55:09.360
But VS Code is my editor to go these days.

00:55:09.360 --> 00:55:09.840
All right.

00:55:09.840 --> 00:55:10.980
Final call to action.

00:55:10.980 --> 00:55:13.620
People are interested in your awesome list.

00:55:13.620 --> 00:55:14.320
What do you tell them?

00:55:14.320 --> 00:55:16.040
Please contribute to your awesome ideas.

00:55:16.040 --> 00:55:16.940
Make a PR.

00:55:16.940 --> 00:55:20.960
Also, if you have ideas around automation, please send them our way.

00:55:20.960 --> 00:55:24.180
Create a pull request or, you know, and achieve your nice.

00:55:24.180 --> 00:55:26.680
As a maintainer, that's a very welcome thing, right?

00:55:26.680 --> 00:55:27.420
It is.

00:55:27.420 --> 00:55:29.460
Find things you don't have to maintain, I'm sure.

00:55:29.460 --> 00:55:30.680
Absolutely.

00:55:30.680 --> 00:55:31.880
Awesome.

00:55:31.880 --> 00:55:32.400
All right.

00:55:32.400 --> 00:55:33.620
Well, thanks so much for being here.

00:55:33.620 --> 00:55:34.800
Thanks everyone to listen.

00:55:34.800 --> 00:55:35.220
Thank you.

00:55:35.220 --> 00:55:35.520
Bye.

00:55:35.520 --> 00:55:35.940
Bye.

00:55:35.940 --> 00:55:36.300
Bye.

00:55:37.560 --> 00:55:40.360
This has been another episode of Talk Python To Me.

00:55:40.360 --> 00:55:42.200
Thank you to our sponsors.

00:55:42.200 --> 00:55:43.800
Be sure to check out what they're offering.

00:55:43.800 --> 00:55:45.220
It really helps support the show.

00:55:45.220 --> 00:55:47.360
Starting a business is hard.

00:55:47.360 --> 00:55:53.460
Microsoft for Startups, Founders Hub, provides all founders at any stage with free resources

00:55:53.460 --> 00:55:55.960
and connections to solve startup challenges.

00:55:55.960 --> 00:56:00.480
Apply for free today at talkpython.fm/founders hub.

00:56:00.940 --> 00:56:02.680
Take some stress out of your life.

00:56:02.680 --> 00:56:08.160
Get notified immediately about errors and performance issues in your web or mobile applications with

00:56:08.160 --> 00:56:08.480
Sentry.

00:56:08.480 --> 00:56:13.460
Just visit talkpython.fm/sentry and get started for free.

00:56:13.460 --> 00:56:17.060
And be sure to use the promo code talkpython, all one word.

00:56:17.060 --> 00:56:18.760
Want to level up your Python?

00:56:18.760 --> 00:56:22.820
We have one of the largest catalogs of Python video courses over at Talk Python.

00:56:22.820 --> 00:56:27.980
Our content ranges from true beginners to deeply advanced topics like memory and async.

00:56:27.980 --> 00:56:30.660
And best of all, there's not a subscription in sight.

00:56:30.660 --> 00:56:33.580
Check it out for yourself at training.talkpython.fm.

00:56:33.580 --> 00:56:35.460
Be sure to subscribe to the show.

00:56:35.460 --> 00:56:38.240
Open your favorite podcast app and search for Python.

00:56:38.240 --> 00:56:39.560
We should be right at the top.

00:56:39.560 --> 00:56:44.700
You can also find the iTunes feed at /itunes, the Google Play feed at /play,

00:56:44.700 --> 00:56:48.920
and the direct RSS feed at /rss on talkpython.fm.

00:56:48.920 --> 00:56:52.340
We're live streaming most of our recordings these days.

00:56:52.340 --> 00:56:55.760
If you want to be part of the show and have your comments featured on the air,

00:56:55.760 --> 00:57:00.140
be sure to subscribe to our YouTube channel at talkpython.fm/youtube.

00:57:00.140 --> 00:57:02.020
This is your host, Michael Kennedy.

00:57:02.020 --> 00:57:03.320
Thanks so much for listening.

00:57:03.320 --> 00:57:04.500
I really appreciate it.

00:57:04.500 --> 00:57:06.400
Now get out there and write some Python code.

00:57:06.400 --> 00:57:27.200
I'll see you next time.

