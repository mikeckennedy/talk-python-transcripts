WEBVTT

00:00:00.000 --> 00:00:03.720
Hey, YouTube, how you doing?


00:00:03.720 --> 00:00:04.980
Happy to see you all here.


00:00:04.980 --> 00:00:08.520
Thanks for joining the live show either live or coming in and watching afterwards.


00:00:08.520 --> 00:00:09.520
Hi, Dylan.


00:00:09.520 --> 00:00:11.120
Hey, how's it going, Michael?


00:00:11.120 --> 00:00:14.000
Hey, it's good to have you here on the podcast.


00:00:14.000 --> 00:00:15.000
Yeah, thanks.


00:00:15.000 --> 00:00:16.000
Yeah.


00:00:16.000 --> 00:00:17.000
You ready to kick this thing off?


00:00:17.000 --> 00:00:18.000
Yeah, let's do it.


00:00:18.000 --> 00:00:19.000
Let's do it.


00:00:19.000 --> 00:00:21.400
Very happy to be here.


00:00:21.400 --> 00:00:24.480
Dylan, welcome to Talk Bythenemy.


00:00:24.480 --> 00:00:26.200
Yes, thank you.


00:00:26.200 --> 00:00:30.800
I am a fan, have listened to a lot of episodes and big podcast fan.


00:00:30.800 --> 00:00:32.500
So I'm happy to be on here.


00:00:32.500 --> 00:00:33.360
Thanks.


00:00:33.360 --> 00:00:34.580
Yeah, I'm sure you are.


00:00:34.580 --> 00:00:40.960
Your specialty is in the realm of turning voice into words.


00:00:40.960 --> 00:00:48.920
So yeah, I bet you do a lot of studying of media like podcasts or videos and so on.


00:00:48.920 --> 00:00:49.200
Right.


00:00:49.200 --> 00:00:49.980
Yeah.


00:00:49.980 --> 00:00:51.440
You know, it's, it's actually funny.


00:00:51.440 --> 00:00:53.920
There's, so I started the company.


00:00:53.920 --> 00:00:59.400
I started assembly like four years ago and there was this one audio file that I always


00:00:59.400 --> 00:01:01.480
used to test our speech recognition models on.


00:01:01.480 --> 00:01:04.840
It was this Al Gore TED talk from like 2007, I think.


00:01:04.840 --> 00:01:09.840
And I've almost memorized like parts of that TED talk because I've just tested it so many


00:01:09.840 --> 00:01:10.840
times.


00:01:10.840 --> 00:01:13.440
It's actually still part of our end-to-end test suite.


00:01:13.440 --> 00:01:14.440
It's in there.


00:01:14.440 --> 00:01:18.960
It's like a legacy kind of founder thing that's like in the code still.


00:01:18.960 --> 00:01:19.960
Yeah.


00:01:19.960 --> 00:01:20.960
Yeah.


00:01:20.960 --> 00:01:27.440
It is kind of funny, especially now that we're like 30 people at the company and I'll see some


00:01:27.440 --> 00:01:34.160
of the newer engineers writing tests around that Al Gore file still. And it makes me laugh


00:01:34.160 --> 00:01:39.760
because there's no real reason I picked that. It was just something easy that came to me.


00:01:39.760 --> 00:01:43.040
Yeah, you get started. I just got to grab some audio, hear something, right?


00:01:43.040 --> 00:01:48.720
Yeah, exactly. So yeah, definitely have also listened to a ton of podcasts. And


00:01:50.160 --> 00:01:55.040
I was with, we just started releasing models


00:01:55.040 --> 00:01:55.880
for different languages,


00:01:55.880 --> 00:01:58.220
and I was with someone from our team last week,


00:01:58.220 --> 00:02:00.240
and I heard this phone call,


00:02:00.240 --> 00:02:03.260
and this foreign language, people screaming on this.


00:02:03.260 --> 00:02:04.560
I was like, "What are you listening to?"


00:02:04.560 --> 00:02:05.400
(laughing)


00:02:05.400 --> 00:02:07.040
And it is funny, as an audio company,


00:02:07.040 --> 00:02:09.820
you get sometimes data from customers,


00:02:09.820 --> 00:02:13.000
and it's like, you have to listen to it.


00:02:13.000 --> 00:02:13.940
Yeah, yeah.


00:02:13.940 --> 00:02:17.400
- Yeah, I bet there's some interesting stories in there,


00:02:17.400 --> 00:02:18.440
for sure. - Yeah, yeah.


00:02:18.440 --> 00:02:22.440
Well, we're very privacy conscious, so not too many.


00:02:22.440 --> 00:02:32.040
But yeah, there was just on the verge, there was just an article about a different speech to text company.


00:02:32.040 --> 00:02:37.880
I don't know if you've seen this, that there was some suspicious stuff going on.


00:02:37.880 --> 00:02:39.320
Here, let me see if I can find it.


00:02:39.320 --> 00:02:39.820
I think.


00:02:39.820 --> 00:02:43.720
What was it called?


00:02:43.720 --> 00:02:50.320
It was otter, otter.ai, which I'm not asking you to speak on them, but


00:02:50.320 --> 00:03:00.020
um, this journalist, otter.ai scares or a minor that cloud transcription


00:03:00.020 --> 00:03:01.280
isn't completely private.


00:03:01.280 --> 00:03:05.760
Um, but yeah, so we can talk, talk a little bit.


00:03:05.760 --> 00:03:07.040
Yeah, we'll get it.


00:03:07.040 --> 00:03:13.120
Basically there was a conversation about, Uyghurs in China or something like


00:03:13.120 --> 00:03:20.120
And then they unprompted reached out to the person who was in the conversation and said,


00:03:20.120 --> 00:03:23.120
"Could you tell us the nature of why you had to speak about this?"


00:03:23.120 --> 00:03:24.120
No way.


00:03:24.120 --> 00:03:25.120
They're like, "What?"


00:03:25.120 --> 00:03:27.120
That is crazy.


00:03:27.120 --> 00:03:28.120
Yeah.


00:03:28.120 --> 00:03:29.120
That is crazy.


00:03:29.120 --> 00:03:34.120
Or a little concerned about why you're addressing the content of our conversation.


00:03:34.120 --> 00:03:41.120
Yeah. There's a lot of that suspicion around, there's some conspiracy theories right around.


00:03:41.120 --> 00:03:44.920
It was right around like, oh, does your phone like listen to you while you're around?


00:03:44.920 --> 00:03:48.800
And does it ambiently listen to you and then use that data to remarket to you?


00:03:48.800 --> 00:03:51.000
And I was talking to someone about this recently.


00:03:51.000 --> 00:03:56.320
I know nothing about the location-based advertising world, but sometimes I'll be talking about


00:03:56.320 --> 00:04:02.560
something and then I'll see ads for it on my phone or if I'm on Instagram or something.


00:04:02.560 --> 00:04:06.640
And someone told me it's probably more based on like the location that you're in and the


00:04:06.640 --> 00:04:09.080
other data that they have about you.


00:04:09.080 --> 00:04:12.640
You were at your friend's house, your friend just searched for that, then told you about


00:04:12.640 --> 00:04:13.640
it.


00:04:13.640 --> 00:04:14.640
Exactly.


00:04:14.640 --> 00:04:17.160
And now they're probably also, yeah, exactly.


00:04:17.160 --> 00:04:22.440
It's probably, I think the reality of that is that it's actually more terrifying than


00:04:22.440 --> 00:04:23.760
if they were just listening to you.


00:04:23.760 --> 00:04:24.760
Yeah.


00:04:24.760 --> 00:04:28.880
That they can piece together this shadow reality of you that matches reality so well.


00:04:28.880 --> 00:04:29.880
Yup.


00:04:29.880 --> 00:04:30.880
Yup.


00:04:30.880 --> 00:04:31.880
Yeah.


00:04:31.880 --> 00:04:34.200
Like your friend just bought this thing and you went over and then, so maybe you're interested


00:04:34.200 --> 00:04:37.160
in this thing because you're probably told you about it or something.


00:04:37.160 --> 00:04:38.160
Yeah.


00:04:38.160 --> 00:04:39.160
It is really crazy.


00:04:39.160 --> 00:04:40.200
It is really crazy.


00:04:40.200 --> 00:04:43.040
I haven't paid too much attention to all the changes


00:04:43.040 --> 00:04:44.720
that are happening around like,


00:04:44.720 --> 00:04:46.840
I know I listened to some podcast,


00:04:46.840 --> 00:04:49.200
I think on the Wall Street Journal about


00:04:49.200 --> 00:04:51.160
like the big change that Google is making around that


00:04:51.160 --> 00:04:54.280
tracking and how a lot of people are up in arms about that.


00:04:54.280 --> 00:04:57.880
And it was saying something how like they're gonna have,


00:04:57.880 --> 00:05:00.120
and sorry if I'm derailing whatever plan we had.


00:05:00.120 --> 00:05:01.600
- You're derailing in a way that I'm like


00:05:01.600 --> 00:05:03.880
super passionate about because it's so crazy.


00:05:03.880 --> 00:05:04.720
But yeah.


00:05:04.720 --> 00:05:07.640
- Yeah, it's so interesting.


00:05:07.640 --> 00:05:11.200
They said that there's, I'm probably butchering this,


00:05:11.200 --> 00:05:13.360
but something how like for each user,


00:05:13.360 --> 00:05:16.000
they're just gonna have like six like categories about you.


00:05:16.000 --> 00:05:18.660
And then one of them is gonna be randomly inserted


00:05:18.660 --> 00:05:21.400
as to somehow anonymize your profile.


00:05:21.400 --> 00:05:24.320
And I just thought, yeah, it was super weird to hear


00:05:24.320 --> 00:05:25.320
about how they're doing that.


00:05:25.320 --> 00:05:27.520
And like what the meeting was internally


00:05:27.520 --> 00:05:28.800
that came up with that idea.


00:05:28.800 --> 00:05:30.280
You know, so I'm like, well,


00:05:30.280 --> 00:05:32.480
let's just throw a random category on there.


00:05:32.480 --> 00:05:34.400
Yeah.


00:05:34.400 --> 00:05:36.660
- It's so, you know, my,


00:05:36.660 --> 00:05:39.420
without going too far into this.


00:05:39.420 --> 00:05:44.060
My thoughts are, we're faced or we're presented


00:05:44.060 --> 00:05:45.900
with a false dichotomy.


00:05:45.900 --> 00:05:50.260
Either you can have horrible, creepy, tracking,


00:05:50.260 --> 00:05:53.380
advertising, shadow things like we talked about,


00:05:53.380 --> 00:05:56.740
or you can let the creators and the sites


00:05:56.740 --> 00:05:58.980
that make the services you love die.


00:05:58.980 --> 00:06:00.820
And those are not the two,


00:06:00.820 --> 00:06:03.660
there are more choices than two in this world, right?


00:06:03.660 --> 00:06:10.180
For example, you could have some kind of ad that is related to what is on the page rather


00:06:10.180 --> 00:06:11.980
than who is coming to the page.


00:06:11.980 --> 00:06:14.020
You don't necessarily have to retarget me.


00:06:14.020 --> 00:06:18.460
Like for example, right here on this podcast, I'm going to tell people about, I'm not sure


00:06:18.460 --> 00:06:23.460
without looking at the schedule, what the advertisers are for this episode, but I am


00:06:23.460 --> 00:06:29.540
going to tell people about that and it is exactly related to the content of this show.


00:06:29.540 --> 00:06:33.900
It's not that I found out that Sarah from Illinois


00:06:33.900 --> 00:06:35.660
did this Google search and visited this page,


00:06:35.660 --> 00:06:36.900
so now we're going to show it.


00:06:36.900 --> 00:06:42.020
No, there's so many sites, like this one here on The Verge.


00:06:42.020 --> 00:06:44.500
You could have ads for Assembly AI.


00:06:44.500 --> 00:06:47.180
And it would be-- maybe you don't actually want to do this one.


00:06:47.180 --> 00:06:49.580
But things like this.


00:06:49.580 --> 00:06:53.140
It would be totally reasonable to put an ad for speech


00:06:53.140 --> 00:06:57.180
to text companies on there that requires no targeting


00:06:57.180 --> 00:07:00.620
and no evil shadow companies.


00:07:00.620 --> 00:07:02.540
And there's, you know, like we can go on and on,


00:07:02.540 --> 00:07:04.580
but there are many ways like that, right?


00:07:04.580 --> 00:07:07.380
That don't require this false dichotomy


00:07:07.380 --> 00:07:08.700
that is being presented to us.


00:07:08.700 --> 00:07:11.200
So hopefully we don't end up with either of those


00:07:11.200 --> 00:07:13.620
'cause I don't think those are the best options


00:07:13.620 --> 00:07:15.140
or the only options.


00:07:15.140 --> 00:07:17.980
- Yeah, it's weird how that's kind of how things developed,


00:07:17.980 --> 00:07:21.580
you know, to where we are now.


00:07:21.580 --> 00:07:24.420
Yeah, but I agree with you.


00:07:24.420 --> 00:07:26.060
- Everyone's looking for like,


00:07:26.060 --> 00:07:32.860
Okay, well, if we do retargeting, we can get 2% better returns and no one's worried about,


00:07:32.860 --> 00:07:34.860
well, what happens to society?


00:07:34.860 --> 00:07:36.940
That's actually what I was going to say.


00:07:36.940 --> 00:07:42.580
It's all about the high growth society that we have where we need to maximize growth and


00:07:42.580 --> 00:07:43.580
maximize returns.


00:07:43.580 --> 00:07:45.260
And I mean, I understand this acutely.


00:07:45.260 --> 00:07:49.020
I'm the CEO of a startup, so I get it.


00:07:49.020 --> 00:07:55.340
But yeah, it's when it's growth over everything, you end up with things like what you said,


00:07:55.340 --> 00:07:57.920
going proves it to our returns 2%.


00:07:57.920 --> 00:07:59.800
So let's do this, but you don't think about


00:07:59.800 --> 00:08:01.320
what the trade offs will be.


00:08:01.320 --> 00:08:02.160
Yeah.


00:08:02.160 --> 00:08:02.980
- Absolutely.


00:08:02.980 --> 00:08:04.760
All right, well, thanks for that diversion.


00:08:04.760 --> 00:08:06.040
I know it was great.


00:08:06.040 --> 00:08:09.200
But let's, before we get beyond it,


00:08:09.200 --> 00:08:11.200
let me just get your background real quick.


00:08:11.200 --> 00:08:12.320
How do you get into programming


00:08:12.320 --> 00:08:15.280
and I'm gonna mix it up a little and machine learning.


00:08:15.280 --> 00:08:16.960
- Yeah, yeah, definitely.


00:08:16.960 --> 00:08:19.320
Do you want the long story or the short story?


00:08:19.320 --> 00:08:20.160
- Intermediate.


00:08:20.160 --> 00:08:21.640
- Intermediate, great.


00:08:22.640 --> 00:08:27.940
So the intermediate story is that I started a company when I was in college, just like


00:08:27.940 --> 00:08:30.520
a college startup thing.


00:08:30.520 --> 00:08:35.520
And at the time, was very limited in my programming knowledge.


00:08:35.520 --> 00:08:39.080
I had done some basic like HTML when I was a kid.


00:08:39.080 --> 00:08:45.120
I was really into like, Counter Strike and Call of Duty.


00:08:45.120 --> 00:08:49.440
And yeah, I would like sell up like private servers.


00:08:49.440 --> 00:08:56.020
I don't know how I got into this, but I read these servers and I would remote Windows


00:08:56.020 --> 00:09:02.400
desktop into them and set up private Counter-Strike servers and then sell those and set up a basic


00:09:02.400 --> 00:09:08.600
website for it with HTML and CSS.


00:09:08.600 --> 00:09:12.400
My brother was super into computers, so he was always into computers.


00:09:12.400 --> 00:09:15.360
And then in college, got into startups.


00:09:15.360 --> 00:09:19.240
And I think programming and startups are really connected.


00:09:19.240 --> 00:09:25.180
So through that, learned how to code, learned how to program, started attending Python meetups


00:09:25.180 --> 00:09:30.000
in Washington, DC, where I went to school.


00:09:30.000 --> 00:09:35.440
And that's how I met Matt McKay, who we had a mutual connection.


00:09:35.440 --> 00:09:40.200
So I attended a bunch of meetups, learned how to program and then got really into it.


00:09:40.200 --> 00:09:47.320
But I think what I found myself more interested in was the more like meaty programming problems,


00:09:47.320 --> 00:09:54.200
like, I guess, like algorithm type problems. And that kind of naturally led me to like,


00:09:54.200 --> 00:09:59.160
machine learning and NLP. And then kind of just like took off from there, because I found that


00:09:59.160 --> 00:10:05.720
I was really interested in, in machine learning and, and, and like different NLP problems.


00:10:05.720 --> 00:10:14.280
Those are obviously the really hard ones. You know, it's, yeah, especially probably,


00:10:14.280 --> 00:10:17.080
- When was this that you were doing it?


00:10:17.080 --> 00:10:21.280
- This is maybe like 2013, 2014.


00:10:21.280 --> 00:10:26.160
- Yeah, so the early days of when that was becoming real.


00:10:26.160 --> 00:10:31.160
I remember feeling like all this AI and text to speech


00:10:31.160 --> 00:10:34.080
or speech to text rather type of stuff was very much


00:10:34.080 --> 00:10:38.880
like fusion, like 30 years out, always 30.


00:10:38.880 --> 00:10:40.640
Like it's gonna come eventually,


00:10:40.640 --> 00:10:43.000
but people are doing weird stuff in Lisp


00:10:43.000 --> 00:10:45.040
And it doesn't seem to be doing much of anything at all.


00:10:45.040 --> 00:10:46.040
You know, and then all of a sudden...


00:10:46.040 --> 00:10:48.840
I've played around with some Perl, some like Perl scripts, you know?


00:10:48.840 --> 00:10:49.840
Yeah.


00:10:49.840 --> 00:10:53.240
And then all of a sudden we end up with like amazing speech attacks.


00:10:53.240 --> 00:10:58.320
We end up with self-driving cars, like something clicked and it all came to life.


00:10:58.320 --> 00:10:59.320
Yeah.


00:10:59.320 --> 00:11:00.320
Yeah.


00:11:00.320 --> 00:11:01.560
It's kind of crazy, especially over the last couple of years.


00:11:01.560 --> 00:11:09.960
I think what's really interesting is that a lot of the advances in like self-driving


00:11:09.960 --> 00:11:15.320
cars and NLP and speech to text, they're all based on similar machine learning algorithms.


00:11:15.320 --> 00:11:22.880
So, like the transformer, which is a really popular type of neural network, that came


00:11:22.880 --> 00:11:28.840
out was initially applied towards just NLP, like text language modeling related tasks.


00:11:28.840 --> 00:11:33.680
Now that's shown to be super powerful for speech as well.


00:11:33.680 --> 00:11:38.680
Whereas classical machine learning, there are still these underlying algorithms like


00:11:38.680 --> 00:11:44.040
support vector machines or other types of underlying algorithms. But a lot of the work


00:11:44.040 --> 00:11:48.440
was around the data. And so how can you extract better features for this type of data? And you


00:11:48.440 --> 00:11:55.080
had to be... I remember when I was getting into speech recognition, I bought this speech


00:11:55.080 --> 00:12:01.000
recognition textbook. And this is a while ago. And it was around really understanding phonemes,


00:12:01.000 --> 00:12:05.240
and how different things are spoken, and how the human speech is spoken. And now,


00:12:06.280 --> 00:12:07.480
You don't need to know about that.


00:12:07.480 --> 00:12:08.960
You just get a bunch of audio data


00:12:08.960 --> 00:12:10.440
and you train these big neural networks


00:12:10.440 --> 00:12:11.280
and they figure that out.


00:12:11.280 --> 00:12:13.080
- You don't have to understand British accents


00:12:13.080 --> 00:12:15.040
and American accents, you just give it a bunch of,


00:12:15.040 --> 00:12:16.600
give it a mix, right?


00:12:16.600 --> 00:12:17.800
- Yeah, yeah, exactly.


00:12:17.800 --> 00:12:22.580
But it is crazy to see where things have gotten


00:12:22.580 --> 00:12:25.440
over the last couple of years in particular.


00:12:25.440 --> 00:12:29.080
Yeah, so when I was starting out,


00:12:29.080 --> 00:12:30.680
neural networks were there,


00:12:30.680 --> 00:12:33.600
but they were a lot more basic and you didn't have,


00:12:33.600 --> 00:12:35.360
like there's a lot more compute resources now,


00:12:35.360 --> 00:12:38.360
more mature libraries like TensorFlow and PyTorch.


00:12:38.360 --> 00:12:42.640
I think I went to like one of the first TensorFlow meetups


00:12:42.640 --> 00:12:46.120
that they had, or not meetups, like developer days


00:12:46.120 --> 00:12:48.320
or whatever down at the Google conference.


00:12:48.320 --> 00:12:50.020
So it's like so new still.


00:12:50.020 --> 00:12:51.740
Yeah, it's so new.


00:12:51.740 --> 00:12:54.840
- Yeah, it's easy to forget just a while ago.


00:12:54.840 --> 00:12:55.680
- It is.


00:12:55.680 --> 00:12:58.200
- But that all this stuff didn't even exist, right?


00:12:58.200 --> 00:12:59.560
- Yeah, absolutely.


00:12:59.560 --> 00:13:02.960
- So you mentioned assembly AI?


00:13:02.960 --> 00:13:04.760
That's what you're doing these days, right?


00:13:04.760 --> 00:13:09.880
Yeah, so I am the founder of a company called Assembly AI.


00:13:09.880 --> 00:13:16.960
We create APIs that can automatically transcribe and understand audio data.


00:13:16.960 --> 00:13:23.560
So we have APIs for automatic speech to text of audio files, live audio streams, and then


00:13:23.560 --> 00:13:30.280
APIs that can also summarize audio content, do content moderation on top of audio content,


00:13:30.280 --> 00:13:37.480
topics, what we call like audio intelligence APIs. And so we have a lot of startups and


00:13:37.480 --> 00:13:45.240
enterprises using our APIs to build the way we call it like applications on top of audio data,


00:13:45.240 --> 00:13:51.720
whether it's like content moderation of a social platform or speeding up workflows like I'm sure


00:13:51.720 --> 00:13:56.440
you have where you take a podcast recording and transcribe it so you can make it more shareable


00:13:57.160 --> 00:14:00.040
or extract pieces of it to make it more shareable.


00:14:00.040 --> 00:14:00.880
Yeah.


00:14:00.880 --> 00:14:02.440
- Exactly, yeah.


00:14:02.440 --> 00:14:07.280
Basically for me, it's a CLI command that runs Python


00:14:07.280 --> 00:14:11.640
against your API, against a remote MP3 file,


00:14:11.640 --> 00:14:14.200
and then, you know, magic outcome.


00:14:14.200 --> 00:14:17.360
- That's the great thing about podcast hosts


00:14:17.360 --> 00:14:18.920
that are also programmers.


00:14:18.920 --> 00:14:20.880
Like I've talked to a few and they're all like,


00:14:20.880 --> 00:14:22.840
there's a bunch that are non-programmers


00:14:22.840 --> 00:14:24.020
and they use these different services,


00:14:24.020 --> 00:14:26.440
but every podcast host that I've talked to


00:14:26.440 --> 00:14:29.240
that's a programmer, they have their own CLIs


00:14:29.240 --> 00:14:31.240
and Python scripts that they're running.


00:14:31.240 --> 00:14:35.880
- Yeah, there's a whole series of just CLIs


00:14:35.880 --> 00:14:38.840
and other commands to do the workflow.


00:14:38.840 --> 00:14:43.000
I do wanna just give a quick statement, disclaimer.


00:14:43.000 --> 00:14:44.400
So if you go over to the transcripts,


00:14:44.400 --> 00:14:46.560
or possibly I suspect if you listen


00:14:46.560 --> 00:14:47.400
at the beginning of this episode,


00:14:47.400 --> 00:14:50.240
it'll say that it's sponsored by Assembly AI.


00:14:50.240 --> 00:14:54.400
This episode is not part of that sponsorship.


00:14:54.400 --> 00:14:56.240
This is just, you and I got to know each other,


00:14:56.240 --> 00:14:57.360
You're doing interesting stuff.


00:14:57.360 --> 00:15:00.740
You've been on some other shows that I've heard that the conversation was interesting.


00:15:00.740 --> 00:15:03.160
So invited you on this.


00:15:03.160 --> 00:15:04.740
Thank you for sponsoring the show.


00:15:04.740 --> 00:15:07.360
But just to point out, this is not actually part of that.


00:15:07.360 --> 00:15:10.660
But with the transcripts that we do have on the show,


00:15:10.660 --> 00:15:15.360
the last year or so are basically generated from you guys, which is pretty cool.


00:15:15.360 --> 00:15:18.440
Yeah. Yeah. And we don't even need to talk about assembly that much.


00:15:18.440 --> 00:15:21.140
This podcast, we could talk about other things.


00:15:21.140 --> 00:15:25.960
Yeah. So one of the things I want to talk about


00:15:25.960 --> 00:15:27.920
- And maybe what's on the screen here


00:15:27.920 --> 00:15:30.560
gives a little bit of a hint of being TensorFlow,


00:15:30.560 --> 00:15:33.360
is why do you think Python is popular


00:15:33.360 --> 00:15:35.960
for machine learning startups in general?


00:15:35.960 --> 00:15:38.980
I feel that I'm not as deep in that space as you,


00:15:38.980 --> 00:15:40.680
but looking in from the outside,


00:15:40.680 --> 00:15:42.960
I guess I would say it feels very much like Python


00:15:42.960 --> 00:15:45.640
is the primary way which a lot of


00:15:45.640 --> 00:15:47.720
this machine learning stuff is done.


00:15:47.720 --> 00:15:50.120
- Yeah, yeah, that's a good point.


00:15:50.120 --> 00:15:55.120
So like why that is, I think outside of machine learning,


00:15:55.120 --> 00:15:59.120
Outside of machine learning, even, I think Python's just such a popular language because


00:15:59.120 --> 00:16:07.360
it's so easy to build with compared to like PHP or C# and like even JavaScript. Like when I learned


00:16:07.360 --> 00:16:12.240
to code, I started with Python because the syntax was easy to understand. There were a lot of good


00:16:12.240 --> 00:16:18.560
resources. And then there's kind of this like snowball effect where more people know Python,


00:16:18.560 --> 00:16:23.680
there's more tutorials about Python, there's more libraries about Python, and it's just more popular


00:16:23.680 --> 00:16:27.040
- Yeah, this insights, you'll be pulling this up.


00:16:27.040 --> 00:16:29.680
- Yeah, if people, I mean, I've talked about this a lot,


00:16:29.680 --> 00:16:32.520
right, but if you pull up the stack overflow trends


00:16:32.520 --> 00:16:34.680
for the most popular programming languages,


00:16:34.680 --> 00:16:38.320
there's only one that is going dramatically up


00:16:38.320 --> 00:16:41.520
out of, what is this, 10 languages or something?


00:16:41.520 --> 00:16:43.480
And yeah, it's so--


00:16:43.480 --> 00:16:45.280
- It's just so much more popular.


00:16:45.280 --> 00:16:46.120
- Yeah, it is.


00:16:46.120 --> 00:16:49.980
It's so interesting how it's really sort of taken off.


00:16:49.980 --> 00:16:53.120
And it wasn't, you know, back in when you got started


00:16:53.120 --> 00:16:56.620
when I got started back in this general area of 2012, 20--


00:16:56.620 --> 00:16:58.620
- What was the number one language then?


00:16:58.620 --> 00:17:01.920
- The number one then was, what is that?


00:17:01.920 --> 00:17:03.420
- C#. - C#.


00:17:03.420 --> 00:17:08.620
But you got to keep in mind, this is a little bit of a historical bias of Stack Overflow.


00:17:08.620 --> 00:17:11.620
Stack Overflow was started by Jeff Atwood and Joel Spivolsky,


00:17:11.620 --> 00:17:13.620
who came out of the .NET space.


00:17:13.620 --> 00:17:18.120
And so when they created it, its initial traction was in C# and VB.


00:17:18.120 --> 00:17:22.120
But over time, clearly, it's become where programmers go, obviously.


00:17:22.120 --> 00:17:26.280
So yeah, yeah, I got a bit with a grain of salt, but that that was the number one back


00:17:26.280 --> 00:17:27.280
in the early days.


00:17:27.280 --> 00:17:28.280
Another founder legacy.


00:17:28.280 --> 00:17:29.280
Yes, exactly.


00:17:29.280 --> 00:17:36.440
So I agree that it's absolutely generally popular and I think there's some interesting


00:17:36.440 --> 00:17:37.800
reasons for that.


00:17:37.800 --> 00:17:41.200
Yeah, so approachable, but it's not a toy, right?


00:17:41.200 --> 00:17:45.520
A lot of approachable languages are toy languages and a lot of non toy languages are hard to


00:17:45.520 --> 00:17:46.520
approach.


00:17:46.520 --> 00:17:48.280
That's a good point.


00:17:48.280 --> 00:17:49.280
That's a good point.


00:17:49.280 --> 00:17:56.000
Yeah, like for me, it was very easy to get started with Python.


00:17:56.000 --> 00:17:57.880
So I taught myself how to program.


00:17:57.880 --> 00:18:05.720
I went to college, I studied economics, so I did not study programming in college, computer


00:18:05.720 --> 00:18:06.720
science.


00:18:06.720 --> 00:18:09.440
And the first language I started to try to learn was PHP.


00:18:09.440 --> 00:18:13.280
And I bought this huge PHP textbook and made it halfway through and I was like, "What is


00:18:13.280 --> 00:18:14.640
going on?"


00:18:14.640 --> 00:18:20.900
And I just, I gave up and then tried again with Python later and it was so much easier.


00:18:20.900 --> 00:18:24.820
And then I also wonder how much of this is like for the machine learning libraries in


00:18:24.820 --> 00:18:30.220
specific like you have these macro trends where a lot of the data science boot camps


00:18:30.220 --> 00:18:33.300
that have been so popular, like there's like scikit-learn.


00:18:33.300 --> 00:18:34.540
I know we have a tab up there.


00:18:34.540 --> 00:18:40.560
There's like NumPy and I forget what, NLTK is one of the popular NLP libraries.


00:18:40.560 --> 00:18:44.160
So there were a lot of libraries in Python in the early,


00:18:44.160 --> 00:18:46.400
like when I was getting into NLP,


00:18:46.400 --> 00:18:49.800
I worked a lot with NLTK and like SciPy


00:18:49.800 --> 00:18:51.280
and scikit-learn and NumPy.


00:18:51.280 --> 00:18:54.560
And I think a lot of work was done around there.


00:18:54.560 --> 00:18:58.880
And so people that were doing data science


00:18:58.880 --> 00:19:00.280
or doing some type of machine learning


00:19:00.280 --> 00:19:01.560
were already in Python.


00:19:01.560 --> 00:19:04.400
And then now you have like PyTorch and TensorFlow


00:19:04.400 --> 00:19:06.840
and it's just like kind of cemented like, okay,


00:19:06.840 --> 00:19:09.880
you know, the machine learning libraries today,


00:19:09.880 --> 00:19:12.880
popular ones there. You work with them in Python.


00:19:12.880 --> 00:19:18.720
Yeah. You want to give us your thoughts on those? We've got TensorFlow and PyTorch and


00:19:18.720 --> 00:19:22.520
probably scikit-learn as well. Those are the traditional ones. We've got some newer ones


00:19:22.520 --> 00:19:23.840
like Hugging Face.


00:19:23.840 --> 00:19:25.880
Yeah. Yeah. They're a cool company.


00:19:25.880 --> 00:19:33.540
Maybe give us a survey of how you see the ML space, the libraries that people might


00:19:33.540 --> 00:19:34.540
choose from.


00:19:34.540 --> 00:19:37.660
So when we started the company, everything was in TensorFlow.


00:19:37.660 --> 00:19:41.820
And I think-- - When was that?


00:19:41.820 --> 00:19:44.300
- Back in like late 2017.


00:19:44.300 --> 00:19:45.140
- Okay.


00:19:45.140 --> 00:19:46.560
- Yeah, late 2017.


00:19:46.560 --> 00:19:50.980
Everything was in TensorFlow.


00:19:50.980 --> 00:19:54.340
And actually, I don't know what year PyTorch came out.


00:19:54.340 --> 00:19:56.500
I don't even know if it was out back then.


00:19:56.500 --> 00:19:57.820
Or maybe it was like just internally.


00:19:57.820 --> 00:19:59.260
- Yeah, it's pretty new, yeah.


00:19:59.260 --> 00:20:00.100
- Yeah.


00:20:00.100 --> 00:20:04.100
So TensorFlow was definitely, they got started early.


00:20:04.100 --> 00:20:07.300
I think their docs and the framework


00:20:07.300 --> 00:20:09.380
just got kind of complicated over the years.


00:20:09.380 --> 00:20:12.260
And then it sort of rebooted with TensorFlow 2.0,


00:20:12.260 --> 00:20:17.620
and then there was Keras that was popular.


00:20:17.620 --> 00:20:19.220
It kind of got pulled in.


00:20:19.220 --> 00:20:22.340
Now I think-- so we switched everything over to PyTorch


00:20:22.340 --> 00:20:25.220
in the last year or two.


00:20:25.220 --> 00:20:27.660
A big reason for that was that--


00:20:27.660 --> 00:20:30.540
and we actually put out this article on our blog comparing


00:20:30.540 --> 00:20:31.580
PyTorch and TensorFlow.


00:20:31.580 --> 00:20:40.020
And we have this chart where we show the percentage of papers that are released, where the code


00:20:40.020 --> 00:20:48.420
for the paper is in PyTorch versus TensorFlow. And it's a huge, huge difference. Most of


00:20:48.420 --> 00:20:55.540
the latest research gets implemented. Yeah, here it is. If you go down to one of... So


00:20:55.540 --> 00:20:59.340
this is, yeah, Hugging Face. Can you keep going? Yeah, research papers. Yeah, go up


00:20:59.340 --> 00:21:03.480
So it shows like the fraction of papers.


00:21:03.480 --> 00:21:09.100
And so what we're showing here for the people that are listening is like a graph that shows


00:21:09.100 --> 00:21:16.020
the percentage of papers that are built using PyTorch versus TensorFlow over time.


00:21:16.020 --> 00:21:22.740
Yeah, when you started it was what is this six, seven percent PyTorch and the balance


00:21:22.740 --> 00:21:25.340
being TensorFlow when you started the company.


00:21:25.340 --> 00:21:27.780
And now it's 75% PyTorch.


00:21:27.780 --> 00:21:30.780
That's a very large change.


00:21:30.780 --> 00:21:31.780
Yeah.


00:21:31.780 --> 00:21:32.780
Really dramatic change.


00:21:32.780 --> 00:21:38.860
If PyTorch was a company, it'd be probably raising a lot of money.


00:21:38.860 --> 00:21:44.460
But I think one of the reasons we picked PyTorch is because a lot of the newer research was


00:21:44.460 --> 00:21:46.140
being implemented in PyTorch first.


00:21:46.140 --> 00:21:50.380
There were examples in PyTorch, and so it was easier to get...


00:21:50.380 --> 00:21:51.380
They have it on their tagline.


00:21:51.380 --> 00:21:56.940
I have to quote them, "From research to production."


00:21:56.940 --> 00:22:04.380
It was easier to get more exotic advanced neural networks into production and actually


00:22:04.380 --> 00:22:08.580
start training models with those different types of layers or operations or loss functions


00:22:08.580 --> 00:22:11.020
that were released in these different papers.


00:22:11.020 --> 00:22:15.500
So we started using PyTorch and we kind of haven't looked back.


00:22:15.500 --> 00:22:21.620
Well if you're tracking all the research and trying to build a cutting edge startup around


00:22:21.620 --> 00:22:26.220
ML, you don't want to wait for this to make its way to other frameworks.


00:22:26.220 --> 00:22:28.140
If you want to just grab it and go.


00:22:28.140 --> 00:22:30.260
So that's where the research is being done.


00:22:30.260 --> 00:22:31.260
That helps a lot.


00:22:31.260 --> 00:22:32.260
Right?


00:22:32.260 --> 00:22:33.260
Right.


00:22:33.260 --> 00:22:34.260
Exactly.


00:22:34.260 --> 00:22:35.260
Yeah.


00:22:35.260 --> 00:22:36.260
Exactly.


00:22:36.260 --> 00:22:38.500
You can get, just get up and running a lot faster with the newer research.


00:22:38.500 --> 00:22:42.740
And so most companies that I talk to now, they're all using PyTorch.


00:22:42.740 --> 00:22:46.860
I think PyTorch is definitely like the more popular framework.


00:22:46.860 --> 00:22:53.100
There's some new ones coming out that have people excited, but still like from what I


00:22:53.100 --> 00:22:54.500
can sense PyTorch is.


00:22:54.500 --> 00:22:58.500
If someone was going to get started today, I would tell them to start with PyTorch.


00:22:58.500 --> 00:22:59.500
Yeah.


00:22:59.500 --> 00:23:00.500
Okay.


00:23:00.500 --> 00:23:01.500
I think TensorFlow is also...


00:23:01.500 --> 00:23:02.500
Who runs PyTorch?


00:23:02.500 --> 00:23:03.500
Yeah, go ahead.


00:23:03.500 --> 00:23:04.500
Sorry, who runs PyTorch?


00:23:04.500 --> 00:23:06.500
I think it was released by Facebook, right?


00:23:06.500 --> 00:23:07.500
Yeah.


00:23:07.500 --> 00:23:08.500
And then TensorFlow, that's Google, right?


00:23:08.500 --> 00:23:09.500
Google, yeah.


00:23:09.500 --> 00:23:10.500
Yeah.


00:23:10.500 --> 00:23:15.380
And I think Google's tried to tie TensorFlow into their Cloud ML products, so train your


00:23:15.380 --> 00:23:20.300
models on Google Cloud and use their TPUs in the cloud.


00:23:20.300 --> 00:23:25.840
And there's probably some business cases behind that, but I feel like it may have made the


00:23:25.840 --> 00:23:33.300
developer experience worse because it's trying to give back to Google.


00:23:33.300 --> 00:23:40.340
Whereas PyTorch isn't trying to get you to train your models on Facebook Cloud or something.


00:23:40.340 --> 00:23:41.660
What's the story with hugging face?


00:23:41.660 --> 00:23:44.500
People probably wouldn't use Facebook Cloud if that existed nowadays.


00:23:44.500 --> 00:23:49.300
I don't know if you'd want to host your data in MetaCloud.


00:23:49.300 --> 00:23:55.140
cloud. You can only do it in VR. What's the story with Hugging Face?


00:23:55.140 --> 00:24:01.460
So Hugging Face is a cool, it's actually, so this is a company actually, and they have,


00:24:01.460 --> 00:24:06.380
it's kind of hard to even explain. It's like, you can basically get access to a bunch of


00:24:06.380 --> 00:24:11.700
different pre-trained models really quickly through Hugging Face. And so if you want to,


00:24:11.700 --> 00:24:18.660
a lot of work around NLP now is like how familiar with like self-supervised learning or like


00:24:18.660 --> 00:24:21.100
base models for NLP. How familiar with that?


00:24:21.100 --> 00:24:27.540
So the idea is to have a, like a general model and then apply some sort of


00:24:27.540 --> 00:24:31.260
transfer learning to build up a more specialized one without training from


00:24:31.260 --> 00:24:31.980
scratch. Is that


00:24:31.980 --> 00:24:36.540
exactly? Yeah. And that general model is really just trained to like learn


00:24:36.540 --> 00:24:41.580
representations of the data. So it's, it's not even really trained, like with


00:24:41.580 --> 00:24:45.100
us, our particular like NLP task, it's just like trained to learn


00:24:45.340 --> 00:24:51.020
representations of data. And then with those representations that it learns, you can then say,


00:24:51.020 --> 00:24:56.940
like, "Okay, I'm going to train you towards this specific task with some labeled data in a


00:24:56.940 --> 00:25:03.340
supervised manner." And so there are some really popular open source base models, foundation


00:25:03.340 --> 00:25:10.460
models, like BERT is one. There's a bunch of others. But you can easily get... Like load up


00:25:10.460 --> 00:25:15.220
up BERT basically and fine tune it on your data with HuggingFace.


00:25:15.220 --> 00:25:21.020
So if you're trying to get a model up and running quickly in like the NLP,


00:25:21.020 --> 00:25:24.780
like the text domain, you can do that pretty easily with HuggingFace.


00:25:24.780 --> 00:25:25.380
Okay.


00:25:25.380 --> 00:25:26.180
Interesting.


00:25:26.180 --> 00:25:29.100
So it's less like, if you want to like build your own neural network from


00:25:29.100 --> 00:25:33.820
scratch, like inputs to outputs, implement your own loss function, all


00:25:33.820 --> 00:25:36.540
that, you know, you would do that in PyTorch.


00:25:36.540 --> 00:25:38.900
If you want to try to just like quickly fine tune


00:25:38.900 --> 00:25:42.620
or for a specific task that you're trying to solve,


00:25:42.620 --> 00:25:45.700
you know, you could still go like the PyTorch route,


00:25:45.700 --> 00:25:48.980
but it would just be faster to go tugging base.


00:25:48.980 --> 00:25:51.260
So they've seen a lot of adoption there.


00:25:51.260 --> 00:25:55.020
And then scikit-learn is kind of like the old school


00:25:55.020 --> 00:25:59.700
library that's been around forever with like--


00:25:59.700 --> 00:26:01.140
- The OG, yeah, for sure.


00:26:01.140 --> 00:26:01.980
- The OG, yeah.


00:26:01.980 --> 00:26:03.300
Like if you want to do stuff with like support vector


00:26:03.300 --> 00:26:06.100
machines or random forest or like caterers neighbors,


00:26:06.100 --> 00:26:12.580
Um, you know, this is scikit-learn is, is, probably still really popular in that.


00:26:12.580 --> 00:26:13.180
Yeah.


00:26:13.180 --> 00:26:14.500
For those different use cases.


00:26:14.500 --> 00:26:18.340
I do think that scikit-learn being used quite a bit still.


00:26:18.340 --> 00:26:25.300
Um, yeah, maybe in the research, the academic, if you go take a course on


00:26:25.300 --> 00:26:27.860
it, you know, probably there's a lot of stuff on this, I would guess.


00:26:27.860 --> 00:26:28.620
Yeah.


00:26:28.620 --> 00:26:30.460
Like there's a lot of times where, I mean, you don't really


00:26:30.460 --> 00:26:31.820
need to build a neural network.


00:26:31.820 --> 00:26:37.580
I mean, there's parts of our stack that are like basic machine learning, like statistical models.


00:26:37.580 --> 00:26:43.100
And if you can get away with it, it's a lot easier to train and you don't need as much data and


00:26:43.100 --> 00:26:49.660
it's easier to deploy. So like a lot of like recommendation type models or, and sometimes


00:26:49.660 --> 00:26:54.540
SVMs are just like good enough. SVMs, support vector machines are just good enough for


00:26:54.540 --> 00:26:57.420
a task that you might want to have. So-


00:26:58.780 --> 00:27:04.380
for a lightweight Netflix recommendation or YouTube recommendation, not like the high-end


00:27:04.380 --> 00:27:09.020
stuff that I'm sure they're actually doing. Something like that. That kind of recommendation


00:27:09.020 --> 00:27:14.620
engine, yeah. Something basic. Although I actually am kind of underwhelmed with the Netflix and


00:27:14.620 --> 00:27:20.540
YouTube recommendations are very good. Netflix recommendations and Prime recommendations,


00:27:20.540 --> 00:27:23.820
I'm kind of underwhelmed by. You would think that- I agree.


00:27:23.820 --> 00:27:29.900
Yeah, yeah. They, they, it's still so hard to find things to watch sometimes on those platforms.


00:27:29.900 --> 00:27:38.460
It is. And YouTube, interestingly, seems to have an end. So if you scroll down through YouTube,


00:27:38.460 --> 00:27:41.980
like 10 pages, it'll start showing you like, well, it seems like we're out of options here,


00:27:41.980 --> 00:27:45.100
we'll show you 10 from this one channel, and then we'll just kind of stop it. Like,


00:27:45.100 --> 00:27:49.740
I know you got a lot of videos, you could just keep recommending. So I'm pretty sure if you


00:27:49.740 --> 00:27:54.700
you would keep recommending. There's stuff down here, but yeah, I agree. It's interesting.


00:27:54.700 --> 00:28:01.140
I feel like it's gotten better too. My YouTube consumption has really picked up over the


00:28:01.140 --> 00:28:05.140
last year, I would say. There are recommendation algorithms and I don't know if it's just more


00:28:05.140 --> 00:28:11.220
content being created or maybe it's just a personal thing for me. And there was some


00:28:11.220 --> 00:28:16.620
thing on Hacker News too about YouTube comments that one of the founders of Stripe posted


00:28:16.620 --> 00:28:18.300
are generally very positive.


00:28:18.300 --> 00:28:21.540
And there's really good comments on YouTube, too.


00:28:21.540 --> 00:28:23.820
So they've definitely also come up


00:28:23.820 --> 00:28:27.180
with ways to classify comments as being high value or not,


00:28:27.180 --> 00:28:28.580
and then put those up top.


00:28:28.580 --> 00:28:32.420
And nowadays, those models are definitely


00:28:32.420 --> 00:28:35.540
used with something like some big neural networks


00:28:35.540 --> 00:28:37.140
and transformer.


00:28:37.140 --> 00:28:40.580
Because those neural networks, they're


00:28:40.580 --> 00:28:43.220
so much better at understanding context.


00:28:43.220 --> 00:28:46.380
and like SVMs, you have to still,


00:28:46.380 --> 00:28:48.580
for a lot of these classical machine learning approaches,


00:28:48.580 --> 00:28:50.660
like feed it hand labeled data,


00:28:50.660 --> 00:28:54.660
but the neural networks, yeah,


00:28:54.660 --> 00:28:57.940
they're really good for those language tasks now.


00:28:57.940 --> 00:28:59.200
- Yeah, absolutely.


00:28:59.200 --> 00:29:02.100
Christopher out in the audience has a question.


00:29:02.100 --> 00:29:03.100
That's kind of interesting.


00:29:03.100 --> 00:29:05.340
Does it make sense to start with scikit-learn


00:29:05.340 --> 00:29:06.900
if, for example, you're trying to predict


00:29:06.900 --> 00:29:09.900
when a production machine is not out of tolerance


00:29:09.900 --> 00:29:12.220
yet is trending to be.


00:29:12.220 --> 00:29:14.940
- Is that like--


00:29:14.940 --> 00:29:17.340
- If you're like monitoring like a data center


00:29:17.340 --> 00:29:19.220
for maybe VMs, I'm guessing.


00:29:19.220 --> 00:29:22.820
- Like your RAM or like memory is going high


00:29:22.820 --> 00:29:27.820
or like some statistic is like predictive


00:29:27.820 --> 00:29:30.340
that this VM--


00:29:30.340 --> 00:29:31.820
- Failure is coming, yeah, something like that.


00:29:31.820 --> 00:29:33.500
- Failure is coming, yeah.


00:29:33.500 --> 00:29:34.900
And the question was, is it SVM?


00:29:34.900 --> 00:29:36.540
Or scikit-learn, good to start with.


00:29:36.540 --> 00:29:37.860
Yeah, I would actually probably say


00:29:37.860 --> 00:29:41.700
that's where you want to go with something like scikit-learn.


00:29:41.700 --> 00:29:46.220
Because there's probably very clear-cut patterns.


00:29:46.220 --> 00:29:50.060
I would say if you're unsure of what the pattern is,


00:29:50.060 --> 00:29:52.580
then a neural network is good because a neural network can,


00:29:52.580 --> 00:29:54.740
in theory, like you're feeding it raw data


00:29:54.740 --> 00:29:56.140
and it's learning the pattern.


00:29:56.140 --> 00:29:59.140
But if you know what the pattern is, like, OK,


00:29:59.140 --> 00:30:02.420
there's probably these signals that if a human was just


00:30:02.420 --> 00:30:04.300
sitting there looking at it all day,


00:30:04.300 --> 00:30:06.420
would be able to tell this system is probably


00:30:06.420 --> 00:30:11.580
going to go down, then you just can train an SVM or some type of classical machine learning


00:30:11.580 --> 00:30:17.620
model with scikit-learn to be able to do those predictions with pretty high accuracy.


00:30:17.620 --> 00:30:20.860
And then you've got a super lightweight model.


00:30:20.860 --> 00:30:23.580
You don't need much training data to train it.


00:30:23.580 --> 00:30:28.020
Because you're not trying to build something that's like super generalizable to like all


00:30:28.020 --> 00:30:30.260
systems or like all AWS instances.


00:30:30.260 --> 00:30:32.260
It's probably something unique to your system.


00:30:32.260 --> 00:30:36.020
But I would say that's kind of where the difference is.


00:30:36.020 --> 00:30:38.220
And then it's a lot easier too,


00:30:38.220 --> 00:30:40.580
'cause if you're trying to build like a neural net,


00:30:40.580 --> 00:30:42.980
it's like, well, what type, how many layers,


00:30:42.980 --> 00:30:46.740
what kind of like optimization schedule,


00:30:46.740 --> 00:30:48.820
like learning rate, there's all these hyper parameters


00:30:48.820 --> 00:30:50.360
and things you have to figure out.


00:30:50.360 --> 00:30:51.480
You still have to do that too


00:30:51.480 --> 00:30:53.740
for classical machine learning to a degree,


00:30:53.740 --> 00:30:58.540
but if your problem's not that difficult,


00:30:58.540 --> 00:31:03.540
it's not as fancy nowadays, but it gets the job done.


00:31:04.980 --> 00:31:08.220
- Yeah, I suspect you could come up with some predictors


00:31:08.220 --> 00:31:11.900
and then like monitor them for in this model,


00:31:11.900 --> 00:31:15.420
whereas opposed to here's an image that is a breast scan,


00:31:15.420 --> 00:31:16.540
does it have cancer or not, right?


00:31:16.540 --> 00:31:19.100
Like, we don't really know what we're looking for,


00:31:19.100 --> 00:31:21.740
but there probably is a pattern that could be pulled out


00:31:21.740 --> 00:31:23.580
by a neural network.


00:31:23.580 --> 00:31:25.720
- Exactly, yeah, that's a great point.


00:31:25.720 --> 00:31:28.600
And, you know, like we're trying to build


00:31:28.600 --> 00:31:30.740
some predictive scaling for our API right now,


00:31:30.740 --> 00:31:33.600
because one of the problems with,


00:31:33.600 --> 00:31:37.460
or challenges of a startup that's doing


00:31:37.460 --> 00:31:39.660
machine learning in production is,


00:31:39.660 --> 00:31:41.860
we deploy like hundreds of GPUs


00:31:41.860 --> 00:31:44.900
and thousands of CPU cores into production every day


00:31:44.900 --> 00:31:48.100
at peak load, and you have to be able to scale to demand.


00:31:48.100 --> 00:31:51.820
And if you overscale at that size,


00:31:51.820 --> 00:31:54.340
then there's just huge costs that come with that.


00:31:54.340 --> 00:31:57.220
If you underscale, there's bad performance for end users.


00:31:57.220 --> 00:32:00.980
And so we've done a ton of work around like auto scaling


00:32:00.980 --> 00:32:03.140
and trying to optimize models and production


00:32:03.140 --> 00:32:03.980
and things like that.


00:32:03.980 --> 00:32:07.260
And now we're trying to do some predictive scaling.


00:32:07.260 --> 00:32:08.500
And for that, for example,


00:32:08.500 --> 00:32:11.300
we probably do something super simple with like scikit-learn.


00:32:11.300 --> 00:32:13.940
We wouldn't do a neural net for that.


00:32:13.940 --> 00:32:15.620
- Yeah, the scaling sounds like solving


00:32:15.620 --> 00:32:17.700
basically a similar issue.


00:32:17.700 --> 00:32:18.540
- Yeah, yeah.


00:32:18.540 --> 00:32:19.980
- As understanding failure, right?


00:32:19.980 --> 00:32:21.300
- Yeah, exactly, exactly.


00:32:21.300 --> 00:32:23.460
- The lack of scaling sometimes is kind of,


00:32:23.460 --> 00:32:24.820
the result is failure.


00:32:24.820 --> 00:32:27.940
So they're somewhat related together.


00:32:27.940 --> 00:32:30.420
All right, you talked about running stuff in production


00:32:30.420 --> 00:32:34.500
and there's obviously two aspects for machine learning


00:32:34.500 --> 00:32:38.300
companies and startups and teams and products


00:32:38.300 --> 00:32:39.980
that are very different than say,


00:32:39.980 --> 00:32:41.220
the kind of stuff I do, right?


00:32:41.220 --> 00:32:43.100
Like I've got APIs that are running,


00:32:43.100 --> 00:32:44.140
we've got mobile apps,


00:32:44.140 --> 00:32:45.740
we've got people taking the courses,


00:32:45.740 --> 00:32:47.460
but all of that stuff is like,


00:32:47.460 --> 00:32:50.020
one, it's always the same, right?


00:32:50.020 --> 00:32:52.500
It's, we put stuff up and people will use it


00:32:52.500 --> 00:32:53.660
and consume it and so on.


00:32:53.660 --> 00:32:56.860
but for you all, you've got the training


00:32:56.860 --> 00:32:58.980
and almost the R&D side of things


00:32:58.980 --> 00:33:01.180
that you've got to worry about working on and scaling,


00:33:01.180 --> 00:33:03.340
and then you've got the productionizing.


00:33:03.340 --> 00:33:07.180
So maybe tell us a little bit about how you,


00:33:07.180 --> 00:33:10.220
what do you guys use for training?


00:33:10.220 --> 00:33:13.100
Yeah, maybe start with the training side.


00:33:13.100 --> 00:33:15.020
- Yeah, the training side,


00:33:15.020 --> 00:33:17.460
it's basically like impossible to use the big clouds for that


00:33:17.460 --> 00:33:20.380
because it would just be prohibitively expensive,


00:33:20.380 --> 00:33:21.540
at least for what we do.


00:33:21.540 --> 00:33:24.660
So we train like these huge neural nets


00:33:24.660 --> 00:33:27.380
for speech recognition and different NLP tasks.


00:33:27.380 --> 00:33:32.380
And we're training them across like 48, 64 GPUs,


00:33:32.380 --> 00:33:35.420
like really powerful GPUs.


00:33:35.420 --> 00:33:39.940
- I've got the GeForce 3090, which is a beast.


00:33:39.940 --> 00:33:41.620
Do you know what kind you're using?


00:33:41.620 --> 00:33:45.940
- Yeah, so we use a lot of V100s, like A100s.


00:33:45.940 --> 00:33:49.380
And we rent, basically what we do


00:33:49.380 --> 00:33:54.060
is we rent dedicated machines from a provider.


00:33:54.060 --> 00:33:59.060
And each machine, we're able to pick the specs that we want,


00:33:59.060 --> 00:34:01.740
like how many GPUs, what cards, how much RAM,


00:34:01.740 --> 00:34:03.900
what kind of CPU we want on there.


00:34:03.900 --> 00:34:06.320
So we're able to pick the specs that we want.


00:34:06.320 --> 00:34:10.860
And we found that that's been the best way to do it


00:34:10.860 --> 00:34:13.980
because big clouds, yeah, if you're running


00:34:13.980 --> 00:34:17.340
a dozen, dozens of GPU,


00:34:17.340 --> 00:34:20.240
of the most expensive types of GPUs for weeks on end.


00:34:20.240 --> 00:34:24.300
You could do that if you had one training run


00:34:24.300 --> 00:34:25.940
you wanted to do, but a lot of times


00:34:25.940 --> 00:34:27.860
you have to train a model halfway through,


00:34:27.860 --> 00:34:30.100
it doesn't work well, you have to restart,


00:34:30.100 --> 00:34:33.540
or it finishes training and the results are not that good


00:34:33.540 --> 00:34:34.940
and you learn something, so you have to go back


00:34:34.940 --> 00:34:37.180
and start over, and now what we're doing


00:34:37.180 --> 00:34:39.540
is buying a bunch of our own compute.


00:34:39.540 --> 00:34:41.460
My dream is to have some closet somewhere


00:34:41.460 --> 00:34:45.700
with just tons of GPUs and our own mini data center


00:34:45.700 --> 00:34:50.900
the R&D because if things go down, when you're training a model, you check point it as you


00:34:50.900 --> 00:34:57.940
go. So if your program crashes or your server crashes, you can resume training. Whereas


00:34:57.940 --> 00:35:03.700
for production workloads, we use AWS for that because things can't go down. And I don't


00:35:03.700 --> 00:35:07.940
think we'd want to take on our own competency of hosting our own production infrastructure.


00:35:07.940 --> 00:35:16.260
But for the R&D stuff, we are looking into just buying a ton versus renting because it'd


00:35:16.260 --> 00:35:19.380
be a lot more cost efficient.


00:35:19.380 --> 00:35:24.500
And instead of basically paying each year for the same compute, you just buy it once


00:35:24.500 --> 00:35:28.660
and then you just pay for the electricity and server hosting costs and maintenance costs


00:35:28.660 --> 00:35:30.980
that come with that.


00:35:30.980 --> 00:35:34.420
Maybe find a big office building and offer to heat it for free in the winter by just


00:35:34.420 --> 00:35:35.780
running it on the inside.


00:35:35.780 --> 00:35:39.020
Yeah, there's this like, you can run like NVIDIA SMI,


00:35:39.020 --> 00:35:41.020
I don't know if you can play around with GPUs at all,


00:35:41.020 --> 00:35:44.020
but like, you can see what the temperature is of the GPU.


00:35:44.020 --> 00:35:46.080
And like, sometimes, you know, if I'm,


00:35:46.080 --> 00:35:47.600
I remember a while ago when I was training


00:35:47.600 --> 00:35:49.140
some of these models, I would just like,


00:35:49.140 --> 00:35:51.440
look at what the temperature is during training.


00:35:51.440 --> 00:35:53.980
And yeah, they get so hot and these data centers


00:35:53.980 --> 00:35:56.380
have to have all this, all these special cooling


00:35:56.380 --> 00:35:59.840
infrastructure to keep the machines down.


00:35:59.840 --> 00:36:02.700
- Yeah, to the extent that some of them,


00:36:02.700 --> 00:36:07.020
- Yeah, to the extent that people are creating


00:36:07.020 --> 00:36:10.340
underwater data center, like nodes


00:36:10.340 --> 00:36:11.220
and putting them down there


00:36:11.220 --> 00:36:13.820
and just letting the ocean be the heat sink.


00:36:13.820 --> 00:36:17.780
- Yeah, maybe we can buy some land in like,


00:36:17.780 --> 00:36:21.260
you know, Antarctica and put our stuff there.


00:36:21.260 --> 00:36:24.380
That's really the GitHub, like the Arctic code thing.


00:36:24.380 --> 00:36:25.380
I forget what it's called.


00:36:25.380 --> 00:36:28.740
- Yeah, the Arctic code vault, yes.


00:36:28.740 --> 00:36:29.700
- Yeah, yeah.


00:36:29.700 --> 00:36:31.380
So we could do something like that for our GPUs.


00:36:31.380 --> 00:36:32.900
When we get bigger, that's the dream.


00:36:32.900 --> 00:36:34.360
That's my dream.


00:36:34.360 --> 00:36:37.440
So yeah, so we train,


00:36:37.440 --> 00:36:40.880
I think we have like,


00:36:40.880 --> 00:36:42.820
I think somewhere like maybe like 200,


00:36:42.820 --> 00:36:47.040
like GPUs that we use just for R&D and training


00:36:47.040 --> 00:36:48.500
and we're getting a lot more.


00:36:48.500 --> 00:36:50.660
'Cause you don't wanna be,


00:36:50.660 --> 00:36:53.420
a lot of times there's like scheduling bottlenecks.


00:36:53.420 --> 00:36:56.260
So two researchers wanna run a model


00:36:56.260 --> 00:36:59.020
and need a bunch of compute to be able to do that.


00:36:59.020 --> 00:37:00.780
And they're both good ideas.


00:37:00.780 --> 00:37:02.820
You don't want to have to wait four weeks


00:37:02.820 --> 00:37:06.860
for someone to run their model because compute is taken.


00:37:06.860 --> 00:37:10.300
So we're trying to unblock those scheduling conflicts


00:37:10.300 --> 00:37:11.740
by just getting more compute.


00:37:11.740 --> 00:37:16.340
And for the production side, yeah,


00:37:16.340 --> 00:37:18.580
we deploy everything in AWS right now


00:37:18.580 --> 00:37:22.020
and onto smaller GPUs.


00:37:22.020 --> 00:37:25.260
'Cause a lot of our models do inference on GPU still.


00:37:25.260 --> 00:37:27.900
Some of our models do inference on CPU.


00:37:27.900 --> 00:37:28.740
- Oh, interesting.


00:37:28.740 --> 00:37:33.180
you evaluate the stuff, it still uses GPUs even after the right.


00:37:33.180 --> 00:37:39.180
Okay, correct. Yeah, I mean, there's, we could run it on CPU, but it's just not as


00:37:39.180 --> 00:37:44.100
parallelizable as running it on GPUs. There's a lot of work that we could


00:37:44.100 --> 00:37:50.420
probably do to get it really efficient so that, you know, we're running it on like


00:37:50.420 --> 00:37:55.180
as few CPU cores as possible. But one of the problems is like, almost like every


00:37:55.180 --> 00:37:58.020
like three to four months, we're like throwing out the current neural network


00:37:58.020 --> 00:37:59.820
architecture and using a different one that


00:37:59.820 --> 00:38:01.260
is giving us better results.


00:38:01.260 --> 00:38:04.060
Sometimes we'll make the model bigger,


00:38:04.060 --> 00:38:06.520
or there'll be a small tweak in the model architecture that


00:38:06.520 --> 00:38:07.460
yields better results.


00:38:07.460 --> 00:38:09.500
But a lot of times, it's like, OK, we've


00:38:09.500 --> 00:38:12.340
kind of iterated within this architecture as much as we can.


00:38:12.340 --> 00:38:15.600
And now to get the next accuracy bump,


00:38:15.600 --> 00:38:17.740
we have to go to a new architecture.


00:38:17.740 --> 00:38:19.660
We're undergoing that right now.


00:38:19.660 --> 00:38:23.300
We released-- one of our newer speech recognition models


00:38:23.300 --> 00:38:26.020
we released, I think, like three months ago.


00:38:26.020 --> 00:38:28.380
And the results are really good, but now we


00:38:28.380 --> 00:38:30.860
have one that is looking a lot better,


00:38:30.860 --> 00:38:33.100
and it'd be like a completely different architecture.


00:38:33.100 --> 00:38:34.860
And so it's just that trade-off of,


00:38:34.860 --> 00:38:38.460
do you spend a bunch of time optimizing the current model


00:38:38.460 --> 00:38:42.520
that you have and trying to prune the neural network


00:38:42.520 --> 00:38:46.180
and do all these optimizations to get it really small?


00:38:46.180 --> 00:38:48.580
Or do you just spend that research effort


00:38:48.580 --> 00:38:52.780
and that energy focused on finding the next accuracy gain?


00:38:52.780 --> 00:38:57.300
And because we're trying to win customers and grow our revenue,


00:38:57.300 --> 00:38:59.460
it's just, all right, let's just focus on the next model.


00:38:59.460 --> 00:39:03.460
And when we have a big enough team or when we can focus on it,


00:39:03.460 --> 00:39:06.480
we'll work on making the models smaller and more


00:39:06.480 --> 00:39:10.900
compute efficient and less costly to run.


00:39:10.900 --> 00:39:13.860
But right now, yeah, our speech recognition model,


00:39:13.860 --> 00:39:16.660
that does inference on a GPU.


00:39:16.660 --> 00:39:20.420
There's a couple of our NLP-related models,


00:39:20.420 --> 00:39:21.900
like our content moderation model


00:39:21.900 --> 00:39:23.780
that does inference on a GPU.


00:39:23.780 --> 00:39:26.260
And then there's like our automatic punctuation


00:39:26.260 --> 00:39:27.980
and casing restoration model,


00:39:27.980 --> 00:39:29.780
like that runs on a CPU,


00:39:29.780 --> 00:39:31.300
'cause that's not as compute intense.


00:39:31.300 --> 00:39:34.640
And so it really varies, yeah.


00:39:34.640 --> 00:39:37.140
But to your point-- - It's pretty interesting.


00:39:37.140 --> 00:39:38.340
- Sorry, go ahead.


00:39:38.340 --> 00:39:39.180
- Yeah, as you say,


00:39:39.180 --> 00:39:41.020
it's pretty interesting to think about


00:39:41.020 --> 00:39:44.860
how you're optimizing the software stack


00:39:44.860 --> 00:39:47.980
and the algorithms and the libraries and whatnot.


00:39:48.980 --> 00:39:52.660
when you're not doing something that's changing so quickly,


00:39:52.660 --> 00:39:54.500
you know, if it's working,


00:39:54.500 --> 00:39:57.180
you can kind of just leave it alone, right?


00:39:57.180 --> 00:39:59.260
Like I've got some APIs,


00:39:59.260 --> 00:40:02.140
I think they're built either in Pyramid or Flask.


00:40:02.140 --> 00:40:04.740
Sure, it'd be nicer to rebuild them in FastAPI,


00:40:04.740 --> 00:40:06.820
but they're working fine.


00:40:06.820 --> 00:40:08.900
I'm just like, I have no reason to touch them.


00:40:08.900 --> 00:40:09.740
- Right.


00:40:09.740 --> 00:40:11.220
- So I don't, there's not a,


00:40:11.220 --> 00:40:13.580
like a huge step jump I'm going to take.


00:40:13.580 --> 00:40:17.540
They're not under extreme load or anything, right?


00:40:17.540 --> 00:40:18.380
- Yeah.


00:40:18.380 --> 00:40:20.140
in your world, right?


00:40:20.140 --> 00:40:22.700
The out, there's so much innovation happening


00:40:22.700 --> 00:40:27.140
around the models that you do have to think about that.


00:40:27.140 --> 00:40:28.780
So how do you work that trade off?


00:40:28.780 --> 00:40:30.420
How do you like, well, could we get more


00:40:30.420 --> 00:40:32.580
out of what we've got or should we abandon it


00:40:32.580 --> 00:40:33.540
and start over, right?


00:40:33.540 --> 00:40:36.220
Because it's something, it is nice to have a very polished


00:40:36.220 --> 00:40:38.180
and well-known thing as well.


00:40:38.180 --> 00:40:40.700
- Definitely, and every time we throw out our architecture


00:40:40.700 --> 00:40:42.700
and implement a new architecture,


00:40:42.700 --> 00:40:44.500
you've now got to figure out how to run that architecture


00:40:44.500 --> 00:40:46.940
at scale and you don't want to have any hiccups


00:40:46.940 --> 00:40:50.080
for your current customers or users of your API,


00:40:50.080 --> 00:40:54.080
which sometimes happens because these models are so big


00:40:54.080 --> 00:40:56.160
that you can't just write this monolith service


00:40:56.160 --> 00:40:59.440
that sits on a GPU and does everything.


00:40:59.440 --> 00:41:01.540
You have to break it up into a bunch of component parts


00:41:01.540 --> 00:41:04.060
to let it, so that you can run it efficiently at scale.


00:41:04.060 --> 00:41:05.920
So there's like eight, nine microservices


00:41:05.920 --> 00:41:10.760
for a single model 'cause you break out, okay,


00:41:10.760 --> 00:41:13.360
all these different parts and try to get it running


00:41:13.360 --> 00:41:14.980
really efficiently in parallel.


00:41:16.280 --> 00:41:19.800
But it does beg the question of how do you build good CI/CD workflows


00:41:19.800 --> 00:41:22.840
and good DevOps workflows to get models into production quickly?


00:41:22.840 --> 00:41:25.880
And this is something that we're working on right now


00:41:25.880 --> 00:41:27.880
and trying to solve.


00:41:27.880 --> 00:41:29.880
Because a lot of times we have better models,


00:41:29.880 --> 00:41:32.920
and we sit on them for two, three weeks because


00:41:32.920 --> 00:41:35.800
we have to get them into staging, we have to do load testing,


00:41:35.800 --> 00:41:38.600
see if there's anything with scaling that has to change


00:41:38.600 --> 00:41:40.600
because the model profile is different.


00:41:40.600 --> 00:41:45.480
Are there any weird edge cases that we didn't check or see during testing?


00:41:45.480 --> 00:41:50.480
So it slows down the rate of development because you have,


00:41:50.480 --> 00:41:54.600
it's hard to do CI/CD.


00:41:54.600 --> 00:41:57.840
It's not like you just, okay, run these tests,


00:41:57.840 --> 00:41:59.460
the code works, go.


00:41:59.460 --> 00:42:03.120
There's like compute profile changes that happen.


00:42:03.120 --> 00:42:04.920
And so maybe you need a different instance type


00:42:04.920 --> 00:42:06.240
or you need to--


00:42:06.240 --> 00:42:08.720
- Right, it uses less CPU but way more RAM.


00:42:08.720 --> 00:42:10.840
So if you actually deploy it, it's gonna crash or something.


00:42:10.840 --> 00:42:11.960
Okay, got it. - Exactly.


00:42:11.960 --> 00:42:14.120
And then doing that at scale, you have to,


00:42:15.120 --> 00:42:16.820
like profile that and do load testing.


00:42:16.820 --> 00:42:18.100
And so really we're trying to figure out


00:42:18.100 --> 00:42:19.820
how to get these models into production faster.


00:42:19.820 --> 00:42:23.500
And I think the whole like ML ops world is so


00:42:23.500 --> 00:42:27.620
in its infancy, you know, around things like that.


00:42:27.620 --> 00:42:30.740
And it's a lot of work.


00:42:30.740 --> 00:42:31.780
Yeah, it's a lot of work.


00:42:31.780 --> 00:42:35.600
So for us, the trade-off though is always like,


00:42:35.600 --> 00:42:38.760
you know, our customers and developers,


00:42:38.760 --> 00:42:40.260
they just want better results


00:42:40.260 --> 00:42:41.900
and always more accurate results.


00:42:41.900 --> 00:42:46.260
And so we just always are working on pushing our models,


00:42:46.260 --> 00:42:47.900
making them more accurate.


00:42:47.900 --> 00:42:50.100
If we can iterate within a current architecture, great.


00:42:50.100 --> 00:42:52.360
Like sometimes you can just make the model bigger


00:42:52.360 --> 00:42:54.040
or make a small change


00:42:54.040 --> 00:42:55.940
and then you get a lot of accuracy improvements.


00:42:55.940 --> 00:42:58.700
And it's just like what we call like a drop-in update


00:42:58.700 --> 00:42:59.820
where no code changes.


00:42:59.820 --> 00:43:02.440
It's just literally like the model that you're loading


00:43:02.440 --> 00:43:03.280
is just different.


00:43:03.280 --> 00:43:06.460
And then it's just more accurate.


00:43:06.460 --> 00:43:07.980
- Right, that's easy, yeah.


00:43:07.980 --> 00:43:10.900
- That's the dream, you know, it's just a drop-in.


00:43:10.900 --> 00:43:13.860
But that's maybe like 30% of updates.


00:43:13.860 --> 00:43:16.940
Like the other 70% are, okay, you've got a new architecture


00:43:16.940 --> 00:43:19.280
or it's got a pretty different compute profile.


00:43:19.280 --> 00:43:22.860
So it uses a lot more RAM or it's a lot slower to load


00:43:22.860 --> 00:43:23.680
in the beginning.


00:43:23.680 --> 00:43:28.280
So we need to scale earlier because instances come online


00:43:28.280 --> 00:43:29.660
later and become healthy later.


00:43:29.660 --> 00:43:32.700
So there's all these like things you have to think about.


00:43:32.700 --> 00:43:35.300
- Yeah, the whole DevOps side of this sounds way more


00:43:35.300 --> 00:43:37.340
interesting and involved than I first thought.


00:43:37.340 --> 00:43:38.980
- Yeah, yeah, it's painful too.


00:43:38.980 --> 00:43:44.180
I mean, we were like, I can't explain how many like graphs we have in data dog, just


00:43:44.180 --> 00:43:49.260
like monitoring things all day and like how luckily I don't have to work on that anymore.


00:43:49.260 --> 00:43:50.260
That was very stressful.


00:43:50.260 --> 00:43:51.260
And I was like, owning infrastructure.


00:43:51.260 --> 00:43:54.980
Now we have people that are better at it than me.


00:43:54.980 --> 00:43:57.100
We had like two DevOps people start on Monday.


00:43:57.100 --> 00:44:00.380
But yeah, like DevOps is a huge, huge piece of this.


00:44:00.380 --> 00:44:01.820
Yeah, that's quite interesting.


00:44:01.820 --> 00:44:04.020
I do want to circle back to one real quick thing.


00:44:04.020 --> 00:44:07.460
You talked about buying your own GPUs for training and people might have everything


00:44:07.460 --> 00:44:13.940
and like who would want to go and get their own hardware in the day of AWS?


00:44:13.940 --> 00:44:15.460
One day, whatever, right?


00:44:15.460 --> 00:44:20.420
Like it just seems crazy, but there's certainly circumstances like here's an example that I


00:44:20.420 --> 00:44:21.460
recently thought about.


00:44:21.460 --> 00:44:24.260
So there's a place called Mac Stadium where you get Macs in the cloud.


00:44:24.260 --> 00:44:25.140
Hey, how cool, right?


00:44:25.140 --> 00:44:27.940
So maybe you want to have like something you could do with extra things.


00:44:27.940 --> 00:44:29.700
And well, what does it cost?


00:44:29.700 --> 00:44:34.820
Well, for a Mac mini M1, it's $132 a month.


00:44:36.020 --> 00:44:37.900
Is that high or low?


00:44:37.900 --> 00:44:40.300
- Well, the whole device, if you were to buy it,


00:44:40.300 --> 00:44:42.740
costs $700.


00:44:42.740 --> 00:44:44.060
- Yeah, yeah.


00:44:44.060 --> 00:44:47.860
- I suspect that even though the GPUs are expensive,


00:44:47.860 --> 00:44:49.100
there's probably something where


00:44:49.100 --> 00:44:51.740
if you really utilize it extensively,


00:44:51.740 --> 00:44:54.700
it actually makes, it stops making sense


00:44:54.700 --> 00:44:57.340
in ways that people might not expect.


00:44:57.340 --> 00:45:00.220
- Yeah, that, to buy it, you mean, right?


00:45:00.220 --> 00:45:01.780
Like it stops making sense to rent it, yeah.


00:45:01.780 --> 00:45:04.240
- It stops making sense to rent it in the cloud, yeah.


00:45:04.240 --> 00:45:06.440
- Yeah, I mean, we spent a crazy amount of money


00:45:06.440 --> 00:45:08.520
renting GPUs in the cloud.


00:45:08.520 --> 00:45:12.500
And it's like, okay, if we had a bunch of money


00:45:12.500 --> 00:45:15.240
to make a CapEx purchase, right?


00:45:15.240 --> 00:45:16.520
Like just shell out a bunch of money


00:45:16.520 --> 00:45:17.820
to buy a bunch of hardware up front,


00:45:17.820 --> 00:45:19.900
it'd be so much better in the long run.


00:45:19.900 --> 00:45:22.480
'Cause it is similar to the example you made about,


00:45:22.480 --> 00:45:25.160
if you don't have a lot of cash,


00:45:25.160 --> 00:45:28.000
then you're only gonna use a Mac for a couple months.


00:45:28.000 --> 00:45:29.160
- Right, you need it for two weeks,


00:45:29.160 --> 00:45:30.440
then it doesn't make sense to buy it.


00:45:30.440 --> 00:45:33.040
Yeah, you pay the $100 and you're good to go.


00:45:33.040 --> 00:45:35.680
- Right, right, or if you don't have like 2K,


00:45:35.680 --> 00:45:38.620
and then you just rent it,


00:45:38.620 --> 00:45:41.360
and it's like, if you don't have the money to buy a house,


00:45:41.360 --> 00:45:42.580
you rent an apartment, right?


00:45:42.580 --> 00:45:44.400
Like things like that.


00:45:44.400 --> 00:45:49.080
So there are definitely benefits.


00:45:49.080 --> 00:45:50.960
And I think for a lot of,


00:45:50.960 --> 00:45:55.200
I think for most models, you don't need crazy compute.


00:45:55.200 --> 00:45:57.000
Like you could get away with,


00:45:57.000 --> 00:46:00.880
you could buy a desktop device that has like two GPUs,


00:46:00.880 --> 00:46:03.960
or you could rent a dedicated machine


00:46:03.960 --> 00:46:06.600
or still do it on AWS if you're using like one or two GPUs


00:46:06.600 --> 00:46:08.840
and it wouldn't be insane.


00:46:08.840 --> 00:46:10.840
So if you're just starting out,


00:46:10.840 --> 00:46:12.820
you know, all those options are fine.


00:46:12.820 --> 00:46:17.800
But if you're trying to do like big models


00:46:17.800 --> 00:46:21.960
or train a bunch of parallel, you need more compute.


00:46:21.960 --> 00:46:25.100
And yeah, you could like,


00:46:25.100 --> 00:46:26.200
definitely it doesn't make sense


00:46:26.200 --> 00:46:27.480
to use the big clouds for that.


00:46:27.480 --> 00:46:29.720
There's a bunch of dedicated providers


00:46:29.720 --> 00:46:32.920
that you can rent dedicated machines from


00:46:32.920 --> 00:46:35.000
and just pay a monthly fee,


00:46:35.000 --> 00:46:37.000
regardless of how much you use it.


00:46:37.000 --> 00:46:41.920
And it's a lot more efficient for companies to do that.


00:46:41.920 --> 00:46:42.760
- Interesting.


00:46:42.760 --> 00:46:48.320
Give me your thoughts on sort of CapEx versus OpEx


00:46:48.320 --> 00:46:51.880
for ML startups rather than, I don't know,


00:46:51.880 --> 00:46:54.680
it's some other SaaS service


00:46:54.680 --> 00:46:56.840
that doesn't have such computational stuff.


00:46:57.720 --> 00:47:01.560
CapEx being you got to buy a whole bunch of machines and GPUs and stuff versus


00:47:01.560 --> 00:47:04.840
OpEx of like, what's going to cost this much to run the cloud.


00:47:04.840 --> 00:47:10.040
I feel like things are more possible because you can get the stuff in the


00:47:10.040 --> 00:47:15.320
cloud, prove an idea and then get investors without going, well, you know,


00:47:15.320 --> 00:47:18.000
let's go to friends and family and get 250,000 for GPUs.


00:47:18.000 --> 00:47:19.400
And if it doesn't work, we'll just do Bitcoin.


00:47:19.400 --> 00:47:20.400
Yeah.


00:47:20.400 --> 00:47:20.920
Yeah.


00:47:20.920 --> 00:47:21.120
Yeah.


00:47:21.120 --> 00:47:21.320
Yeah.


00:47:21.320 --> 00:47:22.440
Definitely.


00:47:22.440 --> 00:47:24.000
I mean, we started in the cloud, right?


00:47:24.000 --> 00:47:32.520
And so like first models we trained were K80s, on K80s and AWS took like a month to train.


00:47:32.520 --> 00:47:35.300
Yeah, it was terrible.


00:47:35.300 --> 00:47:41.080
So we started in the cloud and then now that we're fortunate to have like more investment


00:47:41.080 --> 00:47:43.440
in the company, we can make these CapEx purchases.


00:47:43.440 --> 00:47:48.600
But yeah, I mean, the operating expenses of running an ML startup are also like crazy,


00:47:48.600 --> 00:47:57.880
payroll and AWS are our biggest expenses because you run so much compute and it's super expensive.


00:47:57.880 --> 00:48:06.280
And what I talk about and what we talk about is there's nothing fundamental about what


00:48:06.280 --> 00:48:11.600
we're doing that makes that the case. It just goes back to that point of do you spend a


00:48:11.600 --> 00:48:17.200
couple months optimizing your models, bringing compute costs down, or do you just focus on


00:48:17.200 --> 00:48:23.440
new architecture and kind of pay your way to get to the future, like this growth versus, yeah.


00:48:23.440 --> 00:48:29.040
And we're like a venture-backed company. So there's expectations around our growth and all


00:48:29.040 --> 00:48:34.560
that. So we just focus on like, okay, let's just get to the next milestone and not focus too much


00:48:34.560 --> 00:48:40.640
on bringing those costs down because there's the opportunity cost of doing that. But eventually


00:48:40.640 --> 00:48:46.880
we'll have to. Yeah. It's a little bit of the ML equivalent of


00:48:46.880 --> 00:48:51.880
of sort of the growth,


00:48:51.880 --> 00:48:54.280
you can lose money to just grab users.


00:48:54.280 --> 00:48:55.120
- Oh yeah.


00:48:55.120 --> 00:48:58.920
- Yeah, that sort of gain capabilities, right?


00:48:58.920 --> 00:49:01.080
- It is, yeah, it is 100%.


00:49:01.080 --> 00:49:02.800
- And then you'll figure out how to do it efficiently


00:49:02.800 --> 00:49:04.840
once you kind of find your way.


00:49:04.840 --> 00:49:05.720
Okay.


00:49:05.720 --> 00:49:07.600
- And I'll give you like a tangible example.


00:49:07.600 --> 00:49:12.080
I mean, like we've been adding a lot of customers


00:49:12.080 --> 00:49:13.240
and developers on the API


00:49:13.240 --> 00:49:16.280
and there's always like new scaling problems that come up.


00:49:16.280 --> 00:49:19.040
And sometimes we're just like, look,


00:49:19.040 --> 00:49:21.140
let's just scale the whole system up.


00:49:21.140 --> 00:49:23.360
It's gotta be inefficient, there's gotta be waste,


00:49:23.360 --> 00:49:26.220
but like, let's scale it up and then we'll like,


00:49:26.220 --> 00:49:29.520
fine tune the auto scaling to bring it down over time.


00:49:29.520 --> 00:49:34.240
Versus like having to step into like a more perfect


00:49:34.240 --> 00:49:36.960
auto scaling scenario that wouldn't cost as much,


00:49:36.960 --> 00:49:39.560
but there'd be bumps along the way.


00:49:39.560 --> 00:49:43.200
And so we just like scaled everything up recently


00:49:43.200 --> 00:49:45.760
to buy us time to go work on figuring out


00:49:45.760 --> 00:49:47.920
to improve some of these like auto scaling.


00:49:47.920 --> 00:49:51.360
Yeah, yeah, you could spend two weeks trying to figure out the right way to go


00:49:51.360 --> 00:49:55.240
to production, or you could spend just more money, get it to work.


00:49:55.240 --> 00:50:00.800
And then, cause you, you might not be sure with the, like the multiple month


00:50:00.800 --> 00:50:04.560
life cycle of some of these things, is this actually going to be the way we


00:50:04.560 --> 00:50:05.160
want to stick with?


00:50:05.160 --> 00:50:07.720
So let's not spend two weeks optimizing it first.


00:50:07.720 --> 00:50:08.520
Right.


00:50:08.520 --> 00:50:09.920
Um, very interesting.


00:50:09.920 --> 00:50:13.360
And I mean, like, look, not every company can make that decision.


00:50:13.360 --> 00:50:17.760
Like if you are bootstrapped or you're trying to get off the ground, which like a lot of companies are.


00:50:17.760 --> 00:50:22.600
You do have to make those, like, you can't just pay your way to the future.


00:50:22.600 --> 00:50:23.440
Um, yeah.


00:50:23.440 --> 00:50:28.160
So I'm a big fan of a bootstraps companies and finding your way.


00:50:28.160 --> 00:50:38.640
I don't think that necessarily just, you know, set a ton of money on fire is the only way forward, but if you have backers already, then they would prefer you to move faster.


00:50:38.640 --> 00:50:39.280
I suspect.


00:50:39.280 --> 00:50:40.440
Correct.


00:50:40.440 --> 00:50:40.760
Yeah.


00:50:40.760 --> 00:50:41.240
Correct.


00:50:41.240 --> 00:50:41.600
Correct.


00:50:41.600 --> 00:50:49.200
Like I always was self-conscious about our operating costs as an ML company, because


00:50:49.200 --> 00:50:54.720
they're high compared to other SaaS companies where you don't have heavy compute.


00:50:54.720 --> 00:51:06.600
But the investors we work with, they get that like, "Okay, there's nothing fundamental about


00:51:06.600 --> 00:51:08.240
this that requires those costs to be high.


00:51:08.240 --> 00:51:10.760
You just have to spend time on bringing them down."


00:51:10.760 --> 00:51:12.920
And there's a clear path.


00:51:12.920 --> 00:51:18.320
It's not like Uber where it's like the path to bring cost down or self-driving cars because


00:51:18.320 --> 00:51:20.500
it's expensive to employ humans.


00:51:20.500 --> 00:51:25.680
That's so far down the road.


00:51:25.680 --> 00:51:29.800
But for us, it's like, "Okay, we need to just spend three months making these models more


00:51:29.800 --> 00:51:33.560
efficient and they'll run a lot cheaper."


00:51:33.560 --> 00:51:35.560
But it's, yeah, that trade-off.


00:51:35.560 --> 00:51:37.840
But I love bootstrap companies too.


00:51:37.840 --> 00:51:38.840
I mean, just a different way to do it.


00:51:38.840 --> 00:51:40.040
- Something special about like,


00:51:40.040 --> 00:51:41.560
you're actually making a profit,


00:51:41.560 --> 00:51:45.800
you're actually the customers and people paying for something.


00:51:45.800 --> 00:51:46.960
- And the answer to, yeah.


00:51:46.960 --> 00:51:49.440
- Yeah, and the freedom for sure.


00:51:49.440 --> 00:51:51.600
So you probably saw me messing around with the screen here


00:51:51.600 --> 00:51:53.320
to pull up this raspberry pi thing.


00:51:53.320 --> 00:51:55.600
There's a question out in the audience says,


00:51:55.600 --> 00:51:57.960
could you do this kind of stuff on a raspberry pi?


00:51:57.960 --> 00:52:01.400
And like a standard raspberry pi, I suspect absolutely no.


00:52:01.400 --> 00:52:03.400
But have you ever seen that there are water cooled


00:52:03.400 --> 00:52:05.120
raspberry pi clusters?


00:52:05.120 --> 00:52:05.960
Are you aware of these things?


00:52:05.960 --> 00:52:07.680
- I have not seen that.


00:52:07.680 --> 00:52:08.520
That is crazy.


00:52:08.520 --> 00:52:09.960
Is that insane?


00:52:09.960 --> 00:52:11.560
- That's insane.


00:52:11.560 --> 00:52:13.760
What kind of compute are they getting on that?


00:52:13.760 --> 00:52:14.600
- You know what?


00:52:14.600 --> 00:52:18.600
It's pretty comparable to a MacBook Pro on this.


00:52:18.600 --> 00:52:21.680
And they've got eight water-cooled raspberry pies


00:52:21.680 --> 00:52:23.040
in a cluster.


00:52:23.040 --> 00:52:24.880
And it's really an amazing device.


00:52:24.880 --> 00:52:26.840
But if you look back at,


00:52:26.840 --> 00:52:30.480
you know, you sort of consider it like a single PC


00:52:30.480 --> 00:52:35.480
with a basic Nvidia card or a MacBook Pro


00:52:35.480 --> 00:52:37.160
or something like that.


00:52:37.160 --> 00:52:38.960
That's still pretty far from what you guys need.


00:52:38.960 --> 00:52:40.880
Like how many GPUs did you say you were using


00:52:40.880 --> 00:52:42.160
to train your models?


00:52:42.160 --> 00:52:43.080
Tons, like a hundred?


00:52:43.080 --> 00:52:45.320
- Yeah, like 64 for the bigger ones.


00:52:45.320 --> 00:52:46.840
Yeah, in parallel.


00:52:46.840 --> 00:52:47.660
Yeah.


00:52:47.660 --> 00:52:49.960
- Yeah, these are not small GPUs.


00:52:49.960 --> 00:52:51.840
So I suspect-- - I don't think that would work.


00:52:51.840 --> 00:52:55.960
- I'm gonna maybe throw it out there for you and say,


00:52:55.960 --> 00:52:58.280
probably no, maybe for the scikit-learn type stuff,


00:52:58.280 --> 00:52:59.880
but not for what you're doing, not the--


00:52:59.880 --> 00:53:01.640
- Yeah, not for training,


00:53:01.640 --> 00:53:04.480
but you could do inference on a Raspberry Pi.


00:53:04.480 --> 00:53:07.540
Like you could squeeze a model down super tiny,


00:53:07.540 --> 00:53:10.120
like what they do to get some models onto your phones


00:53:10.120 --> 00:53:12.640
and run that on a Raspberry Pi.


00:53:12.640 --> 00:53:14.760
You get the model small enough.


00:53:14.760 --> 00:53:18.220
The accuracy might not be great, but like you could do it.


00:53:18.220 --> 00:53:20.600
Oh, there's a lot of stuff happening around the edge.


00:53:20.600 --> 00:53:22.360
Like I think a lot of that Siri.


00:53:22.360 --> 00:53:26.040
- The edge compute, the sort of ML on device type stuff.


00:53:26.040 --> 00:53:28.320
- Yup, like a lot of the speech recognition on your phone


00:53:28.320 --> 00:53:29.920
now happens on device.


00:53:29.920 --> 00:53:32.600
Yeah, and not-


00:53:32.600 --> 00:53:33.620
- It's sort of related to this,


00:53:33.620 --> 00:53:38.620
- Like the new M1 chips and even the chips in the Apple phones


00:53:38.620 --> 00:53:43.220
before then come with neural engines built in,


00:53:43.220 --> 00:53:45.180
like multi-core neural engines.


00:53:45.180 --> 00:53:46.820
Interesting for Edge stuff again,


00:53:46.820 --> 00:53:51.660
but not really gonna let you do the training


00:53:51.660 --> 00:53:53.020
and stuff like that, right?


00:53:53.020 --> 00:53:57.620
- Yeah, yeah, like I haven't done much iOS development,


00:53:57.620 --> 00:53:59.100
but I know there's like SDKs now


00:53:59.100 --> 00:54:01.640
to kind of like get your neural networks on device


00:54:01.640 --> 00:54:06.280
and make use of these, like the hardware on the phone.


00:54:06.280 --> 00:54:09.800
And definitely if you're trying to deploy your stuff


00:54:09.800 --> 00:54:13.440
on the edge, there's a lot more resources available to you.


00:54:13.440 --> 00:54:14.920
- It's a really good experience.


00:54:14.920 --> 00:54:17.640
Cause having, you know, you speak to your assistant


00:54:17.640 --> 00:54:20.600
or you do something and it says thinking, thinking like,


00:54:20.600 --> 00:54:21.800
okay, well that, I don't want that.


00:54:21.800 --> 00:54:22.640
Like, I'll just go through it.


00:54:22.640 --> 00:54:23.800
If I got to wait 10 seconds.


00:54:23.800 --> 00:54:25.360
- Right.


00:54:25.360 --> 00:54:26.200
- Yeah.


00:54:26.200 --> 00:54:27.160
- So it happens immediately.


00:54:27.160 --> 00:54:28.760
And there's the privacy aspect too.


00:54:28.760 --> 00:54:30.000
- Yeah, absolutely.


00:54:30.000 --> 00:54:31.080
The privacy is great.


00:54:31.080 --> 00:54:34.760
Yeah, like the wake word on the Alexa, I don't know if you know this, but like the wake words


00:54:34.760 --> 00:54:39.160
like on the Alexa device, like they happen locally. That runs locally. Although I've


00:54:39.160 --> 00:54:45.800
heard that when you say Alexa, they verify it in the cloud with a more powerful model.


00:54:45.800 --> 00:54:50.760
Because sometimes it'll trigger and then shut off. I don't know if you've ever seen that happen.


00:54:50.760 --> 00:54:54.200
Yeah, it's a little spin around and go, "Ah, no, that wasn't right."


00:54:54.200 --> 00:54:59.080
Yeah, exactly. I think what's happening is that they're sending the wake word to the cloud to


00:54:59.080 --> 00:55:01.240
to verify, like, did you actually say Alexa?


00:55:01.240 --> 00:55:04.620
Probably the local models below some certain confidence


00:55:04.620 --> 00:55:06.480
level, it sends it up to the cloud.


00:55:06.480 --> 00:55:09.400
And then the cloud verifies like, yes, start processing.


00:55:09.400 --> 00:55:13.760
But it is much faster from a latency perspective.


00:55:13.760 --> 00:55:18.160
Although with 5G, I don't know if like, you know,


00:55:18.160 --> 00:55:21.120
like mobile internet is so much faster now.


00:55:21.120 --> 00:55:22.240
- It's getting pretty crazy.


00:55:22.240 --> 00:55:23.780
Yeah, absolutely.


00:55:23.780 --> 00:55:26.400
- Yeah, sometimes I'll be somewhere where my wifi is slow


00:55:26.400 --> 00:55:28.840
and I'll just tether my phone and it's like faster.


00:55:28.840 --> 00:55:31.080
- If I'm not at my house, I usually do that.


00:55:31.080 --> 00:55:33.000
If I go to a coffee shop or an airport,


00:55:33.000 --> 00:55:34.480
I'm like, there's a very low chance


00:55:34.480 --> 00:55:36.720
that the wifi here is better than my 5G tether.


00:55:36.720 --> 00:55:40.880
- Yeah, exactly, exactly, exactly.


00:55:40.880 --> 00:55:41.960
- Chuck Woody in the audience


00:55:41.960 --> 00:55:44.460
has a real interesting question, I think,


00:55:44.460 --> 00:55:47.880
that you can speak to because you're


00:55:47.880 --> 00:55:50.280
in this space right now, living it.


00:55:50.280 --> 00:55:53.440
What do investors look at when considering an AI startup


00:55:53.440 --> 00:55:55.080
or maybe, yeah, AI startup,


00:55:55.080 --> 00:55:57.920
not just specifically speech to text?


00:55:57.920 --> 00:55:58.960
Yeah, it's a good question.


00:55:58.960 --> 00:56:01.080
I think it really depends on,


00:56:01.080 --> 00:56:04.000
like, are you building like a vertical application


00:56:04.000 --> 00:56:05.120
that makes use of AI?


00:56:05.120 --> 00:56:07.480
So you're building some like, you know,


00:56:07.480 --> 00:56:12.240
like call center optimization software


00:56:12.240 --> 00:56:13.680
where there's like AI under the hood,


00:56:13.680 --> 00:56:17.580
but you're using it to power this like business use case


00:56:17.580 --> 00:56:22.580
versus are you building some like infrastructure AI company?


00:56:22.580 --> 00:56:26.920
Like we're us, like we're building APIs for speech to text


00:56:26.920 --> 00:56:32.680
or if you're building a company that's exposing like APIs for NLP or different types of tasks.


00:56:32.680 --> 00:56:36.880
I think it varies what they look at.


00:56:36.880 --> 00:56:40.760
I am not an expert in like fundraising or AI startups.


00:56:40.760 --> 00:56:43.040
I want to make that very clear.


00:56:43.040 --> 00:56:45.240
So maybe don't take my advice to you.


00:56:45.240 --> 00:56:50.760
But you've done it successfully, which is, I mean, there are people who claim to be experts


00:56:50.760 --> 00:56:55.000
but are not currently running a successful backed company.


00:56:55.000 --> 00:57:00.600
I wouldn't put too much of a caveat there. Yeah. I think we just got lucky with meeting


00:57:00.600 --> 00:57:06.200
some of the right people that have helped us. But I think it's like, yeah, are you doing


00:57:06.200 --> 00:57:11.400
something innovative on the model side? Do you have some innovation on the architecture side?


00:57:11.400 --> 00:57:19.880
I actually don't really think the whole data moat is that strong of an argument personally,


00:57:19.880 --> 00:57:22.040
because there's just so much data on the internet now.


00:57:23.320 --> 00:57:28.280
Data moat being like, we run Gmail so we can scan everybody's email. That gives us a competitive


00:57:28.280 --> 00:57:35.880
advantage of knowing. Yeah, exactly. I don't know. You might get a slight advantage, but there's so


00:57:35.880 --> 00:57:42.840
much data on the internet and there's so many innovations happening around. Look at GPT-3


00:57:42.840 --> 00:57:48.600
that OpenAI put out. That was just trained on crazy amounts, a huge model trained on crazy


00:57:48.600 --> 00:57:54.280
amounts of public domain data on the internet works so well across so many different tasks.


00:57:54.280 --> 00:58:01.880
So even if you had a data moat for a specific task, it's arguable that GPT-3 could beat you


00:58:01.880 --> 00:58:09.880
at that task. So I think it depends what you're doing, but I don't personally buy into the whole


00:58:09.880 --> 00:58:16.520
data moat thing that much. Because even for us, we're able to build some of the best speech to


00:58:16.520 --> 00:58:18.560
to text models in the world.


00:58:18.560 --> 00:58:22.920
And we don't have this like secret source of data.


00:58:22.920 --> 00:58:26.140
You know, we just have a lot of innovation on the model side


00:58:26.140 --> 00:58:30.480
and there's tons of data in the public domain


00:58:30.480 --> 00:58:31.740
that you can access now.


00:58:31.740 --> 00:58:34.600
So I think it's really about like,


00:58:34.600 --> 00:58:38.740
are you building some type of application


00:58:38.740 --> 00:58:41.880
that is making the lives of like a customer,


00:58:41.880 --> 00:58:46.120
developer, some startup like easier leveraging AI?


00:58:46.120 --> 00:58:48.960
Solving a problem that people pay money to solve.


00:58:48.960 --> 00:58:49.240
Yeah.


00:58:49.240 --> 00:58:50.360
Yeah, exactly.


00:58:50.360 --> 00:58:50.880
Exactly.


00:58:50.880 --> 00:58:54.200
Cause I actually think it's more about like the distribution of the tech


00:58:54.200 --> 00:58:56.000
you're building versus the tech itself.


00:58:56.000 --> 00:59:01.920
So like, are you packaging it up and it easy to use API or is like the,


00:59:01.920 --> 00:59:08.000
cause like imagine you're selling something to like podcast hosts that uses AI.


00:59:08.000 --> 00:59:12.240
I mean, the AI could be amazing, but if like the user interface sucks, you know,


00:59:12.240 --> 00:59:15.000
like you're, you're not going to do, you're going to make a post request over


00:59:15.000 --> 00:59:19.080
to this and you put this header in and like, it's gonna like, here's how you do paging


00:59:19.080 --> 00:59:23.360
and like, no, no, here's the library in your language, you call the one function, things


00:59:23.360 --> 00:59:27.440
happen, right? Like how presentable or straightforward do you make it? Right?


00:59:27.440 --> 00:59:32.360
Right. Because I actually think, you know, that that's a huge piece of it. Are you are


00:59:32.360 --> 00:59:37.720
you making it easier? Are you making is the distribution around the technology you're


00:59:37.720 --> 00:59:44.480
creating? Like really powerful? And and like, do you have good ideas around that? So I think


00:59:44.480 --> 00:59:48.240
a combination of those things. But to be honest, I think really depends on what you're building


00:59:48.240 --> 00:59:53.360
and what the product is or what you're doing, because it varies. Like really, it varies a lot.


00:59:53.360 --> 01:00:01.360
Yeah. There's also the part that we as developers don't love to think about,


01:00:01.360 --> 01:00:08.880
but the marketing and awareness and growth and traction, right? You could say, look, here's the


01:00:08.880 --> 01:00:13.680
most amazing model we have. Well, we haven't actually got any users yet, but that is a really


01:00:13.680 --> 01:00:19.280
hard sell for investors unless they absolutely see, you know, this has huge potential, right?


01:00:19.280 --> 01:00:25.320
But if you're like, look, we've got this much monthly number of users, and here's the way


01:00:25.320 --> 01:00:30.480
we're going to start to up, you know, create a premium offering and yeah, right. Yeah,


01:00:30.480 --> 01:00:36.320
that's something we're not particularly skilled at as developers, but that's, that's a non


01:00:36.320 --> 01:00:38.280
trivial part of any tech startup, right?


01:00:38.280 --> 01:00:42.000
Oh, yeah. And I think as a developer to you kind of like shy away from wanting to work


01:00:42.000 --> 01:00:46.240
on that because it's so much easier to just write code or build a new feature versus like


01:00:46.240 --> 01:00:51.400
go solve this hard marketing problem or marketing sales like you've got to have them even if


01:00:51.400 --> 01:00:52.400
you're bad at it.


01:00:52.400 --> 01:00:53.400
Yeah.


01:00:53.400 --> 01:00:54.400
Yeah.


01:00:54.400 --> 01:00:55.880
We're fortunate that we get to market to developers.


01:00:55.880 --> 01:00:59.720
So like I enjoy it.


01:00:59.720 --> 01:01:04.360
You know and because you get like to talk to developers all the time.


01:01:04.360 --> 01:01:06.040
But yeah that's a huge piece of it too.


01:01:06.040 --> 01:01:07.040
Definitely.


01:01:07.040 --> 01:01:08.040
Definitely.


01:01:08.040 --> 01:01:09.040
It's got all come together.


01:01:09.040 --> 01:01:10.040
Yeah.


01:01:10.040 --> 01:01:12.120
Let's wrap this up a little bit.


01:01:12.120 --> 01:01:13.500
We're getting sort of near the end,


01:01:13.500 --> 01:01:17.220
but let's talk about you've got this idea,


01:01:17.220 --> 01:01:19.060
you've got your models, you've got your libraries,


01:01:19.060 --> 01:01:21.360
you've trained them up using your GPUs.


01:01:21.360 --> 01:01:23.420
Now you wanna offer it as an API.


01:01:23.420 --> 01:01:26.660
Like how do you go to production


01:01:26.660 --> 01:01:29.220
with a machine learning model and do something interesting?


01:01:29.220 --> 01:01:30.540
You wanna talk about how that's worked.


01:01:30.540 --> 01:01:31.380
I know you talked a little bit


01:01:31.380 --> 01:01:32.820
about running the cloud and whatnot,


01:01:32.820 --> 01:01:37.220
but like, do you offer as an API over Flask


01:01:37.220 --> 01:01:38.980
or do you run it on cloud?


01:01:38.980 --> 01:01:39.820
Like, what are you doing there?


01:01:39.820 --> 01:01:41.100
Are they Lambda functions?


01:01:41.100 --> 01:01:42.980
You know, what's your world look like?


01:01:42.980 --> 01:01:46.060
- So we have asynchronous APIs where you send in


01:01:46.060 --> 01:01:48.940
an audio file and then we send you a webhook


01:01:48.940 --> 01:01:50.620
when it's done processing.


01:01:50.620 --> 01:01:53.140
And then we have real-time APIs over WebSocket


01:01:53.140 --> 01:01:55.020
where you're streaming audio and you're getting stuff back


01:01:55.020 --> 01:01:56.900
over a WebSocket in real-time.


01:01:56.900 --> 01:02:00.740
The real-time stuff's a lot more challenging to build.


01:02:00.740 --> 01:02:01.980
- I'm sure it is.


01:02:01.980 --> 01:02:06.020
- Yeah, the async stuff, really what happens is we have,


01:02:06.940 --> 01:02:10.480
So one of our main APIs was built in Tornado.


01:02:10.480 --> 01:02:11.880
I don't know if you, yeah.


01:02:11.880 --> 01:02:12.720
- Yeah.


01:02:12.720 --> 01:02:13.540
- Like it's like-


01:02:13.540 --> 01:02:15.020
- The early, early async-


01:02:15.020 --> 01:02:15.860
- Yeah.


01:02:15.860 --> 01:02:17.300
- Enabled Python web framework


01:02:17.300 --> 01:02:19.680
before asyncio was officially a thing.


01:02:19.680 --> 01:02:20.780
- Yep.


01:02:20.780 --> 01:02:24.300
So I built the first version of the API in Tornado.


01:02:24.300 --> 01:02:27.340
So it's kind of like still in Tornado for that reason.


01:02:27.340 --> 01:02:29.620
A lot of the newer things or newer microservices


01:02:29.620 --> 01:02:33.000
are built in FastAPI or Flask.


01:02:33.000 --> 01:02:36.380
And so for the asynchronous API,


01:02:36.380 --> 01:02:38.980
what happens is like you're making a post request,


01:02:38.980 --> 01:02:41.140
the API is really just like a CRUD app.


01:02:41.140 --> 01:02:46.000
It's storing a record of the request that you made


01:02:46.000 --> 01:02:48.600
with all the parameters that you turned on or turn off.


01:02:48.600 --> 01:02:50.700
And then that goes into a database,


01:02:50.700 --> 01:02:54.020
some worker that's like the orchestrator


01:02:54.020 --> 01:02:56.220
is constantly looking at that database and is like,


01:02:56.220 --> 01:02:58.840
okay, there's some new work to be done.


01:02:58.840 --> 01:03:01.060
And then kicks off all these different jobs


01:03:01.060 --> 01:03:02.580
to all these different microservices,


01:03:02.580 --> 01:03:06.900
some over queues, some over HTTP,


01:03:06.900 --> 01:03:08.980
collects everything back, orchestrates


01:03:08.980 --> 01:03:10.420
what can be done in parallel, what


01:03:10.420 --> 01:03:13.060
depends on what to be done first.


01:03:13.060 --> 01:03:18.700
When that's all done, all the asynchronous background jobs,


01:03:18.700 --> 01:03:21.060
the orchestrator pushes the final result back


01:03:21.060 --> 01:03:23.940
into our primary database.


01:03:23.940 --> 01:03:25.980
And then that triggers you getting a webhook


01:03:25.980 --> 01:03:30.020
with the final result. So that's, in a nutshell,


01:03:30.020 --> 01:03:32.380
what the architecture looks like for the asynchronous


01:03:32.380 --> 01:03:36.340
workloads, there's like tons of different microservices all with different


01:03:36.340 --> 01:03:42.100
instance types and different compute requirements, some GPU,


01:03:42.100 --> 01:03:46.620
some CPU, some, you know, like all different scaling policies.


01:03:46.620 --> 01:03:52.100
And that's really where the hard part is. And that's,


01:03:52.100 --> 01:03:56.540
that's kind of like the basic overview of how the asynchronous stuff works in


01:03:56.540 --> 01:03:57.380
production.


01:03:57.380 --> 01:03:59.500
Yeah. Yeah. Very cool. Yeah.


01:03:59.620 --> 01:04:03.740
Are you seeing Postgres or MySQL or something like that?


01:04:03.740 --> 01:04:05.880
- Postgres for the primary DB.


01:04:05.880 --> 01:04:09.780
Because we're on AWS, we use DynamoDB for a couple things


01:04:09.780 --> 01:04:13.460
like a febrile records we need to keep around for,


01:04:13.460 --> 01:04:15.820
like when you send something in, it goes to DynamoDB


01:04:15.820 --> 01:04:19.500
and that's where we like keep track of basically


01:04:19.500 --> 01:04:23.540
like your request and what parameters you had on and off.


01:04:23.540 --> 01:04:24.980
That kicks off a bunch of things.


01:04:24.980 --> 01:04:26.700
But the primary DB is Postgres.


01:04:26.700 --> 01:04:28.140
Yeah, I think there's like at this point,


01:04:28.140 --> 01:04:30.940
like it's getting pretty large.


01:04:30.940 --> 01:04:34.580
There's like a few billion records in there.


01:04:34.580 --> 01:04:36.460
- Yeah.


01:04:36.460 --> 01:04:38.820
- 'Cause we process like a couple million audio files a day


01:04:38.820 --> 01:04:40.180
with the API.


01:04:40.180 --> 01:04:42.780
And sometimes I'll read on Hacker News,


01:04:42.780 --> 01:04:45.940
like these, I think like GitHub went down at one point


01:04:45.940 --> 01:04:48.780
because like they couldn't increment


01:04:48.780 --> 01:04:51.540
the primary key values any higher.


01:04:51.540 --> 01:04:54.380
- It's 64 is overflowing, we're done.


01:04:54.380 --> 01:04:55.220
- Yeah, yeah, yeah.


01:04:55.220 --> 01:04:56.040
- Something like that, yeah.


01:04:56.040 --> 01:04:57.180
- I'm in the back of my mind,


01:04:57.180 --> 01:05:01.420
I hope we're thinking about something like that, because that would be really bad if


01:05:01.420 --> 01:05:03.020
we came up against something like that.


01:05:03.020 --> 01:05:04.020
Yeah.


01:05:04.020 --> 01:05:09.340
Do you store the audio content in the database or do they go in like some kind of bucket,


01:05:09.340 --> 01:05:11.120
some object storage thing?


01:05:11.120 --> 01:05:19.260
So we're unique in that we don't store a copy of your audio data for privacy reasons for


01:05:19.260 --> 01:05:20.260
you.


01:05:20.260 --> 01:05:26.600
So you send something in, it's stored ephemerally, like in the memory of the machine that's processing


01:05:26.600 --> 01:05:31.840
your file and then what's stored is the transcription text encrypted at rest because you need to


01:05:31.840 --> 01:05:34.580
be able to make a get request to the API to fetch it.


01:05:34.580 --> 01:05:38.560
But then you can follow up with a delete request to permanently delete the transcription text


01:05:38.560 --> 01:05:39.800
from our database as well.


01:05:39.800 --> 01:05:45.680
So we try to like keep no record of the data that you're processing, because like we want


01:05:45.680 --> 01:05:50.080
to be really privacy focused and sensitive.


01:05:50.080 --> 01:05:55.080
You can, like some customers will toggle on


01:05:55.080 --> 01:05:57.920
that we keep some of their data


01:05:57.920 --> 01:05:59.600
to continuously improve the models,


01:05:59.600 --> 01:06:02.560
but by default, we don't store anything.


01:06:02.560 --> 01:06:04.840
- Yeah, that's really cool.


01:06:04.840 --> 01:06:07.800
- Yeah. - That's good for privacy.


01:06:07.800 --> 01:06:11.040
It's also good for you all because there's just less stuff


01:06:11.040 --> 01:06:12.400
that you have to be nervous about


01:06:12.400 --> 01:06:13.440
when you're trying to fall asleep.


01:06:13.440 --> 01:06:14.520
You're like, what if somebody broke in


01:06:14.520 --> 01:06:15.360
and got all the audio?


01:06:15.360 --> 01:06:16.440
Oh, wait, we don't have the audio.


01:06:16.440 --> 01:06:18.240
Okay, so that's not a thing they could get.


01:06:18.240 --> 01:06:19.880
You know, like things like that, right?


01:06:19.880 --> 01:06:24.880
Yeah, yeah, it's definitely, definitely.


01:06:24.880 --> 01:06:26.200
I hadn't thought about that before,


01:06:26.200 --> 01:06:27.640
but I'm imagining now what that would be.


01:06:27.640 --> 01:06:29.080
- Well, now you're gonna be nervous


01:06:29.080 --> 01:06:30.760
'cause there's probably other stuff, but that's all good.


01:06:30.760 --> 01:06:34.600
- Yeah, yeah, now you got me thinking in that space.


01:06:34.600 --> 01:06:36.280
Like, what are those things we need to lock up?


01:06:36.280 --> 01:06:39.920
No, we're mostly a team of engineers.


01:06:39.920 --> 01:06:44.040
So I think of the 30 people, 70% are engineers


01:06:44.040 --> 01:06:46.920
with a lot more experience than me.


01:06:46.920 --> 01:06:49.400
So we're doing everything by the book.


01:06:49.400 --> 01:06:50.520
- Yeah, of course. - Especially with the business


01:06:50.520 --> 01:06:51.720
that we're in, yeah.


01:06:51.720 --> 01:06:52.880
- Yeah, of course.


01:06:52.880 --> 01:06:54.360
- Yeah.


01:06:54.360 --> 01:06:56.960
- All right, Dylan, I think we're out of time,


01:06:56.960 --> 01:06:57.960
if not out of topic.


01:06:57.960 --> 01:07:02.240
So let's maybe wrap this up a little bit


01:07:02.240 --> 01:07:05.800
with the final two questions and some packages and stuff.


01:07:05.800 --> 01:07:07.720
So if you're gonna work on some Python code,


01:07:07.720 --> 01:07:10.240
what editor are you using these days?


01:07:10.240 --> 01:07:12.080
- I'm still using Sublime.


01:07:12.080 --> 01:07:14.240
- Right on.


01:07:14.240 --> 01:07:16.280
- Do you, what do you use? - One of the OG easy ones.


01:07:16.280 --> 01:07:20.640
- I'm mostly PyCharm if I wanna just open a single file


01:07:20.640 --> 01:07:22.440
and look at it, I'll probably use VS Code for that.


01:07:22.440 --> 01:07:24.920
That's probably just, you know, I wanna open that thing,


01:07:24.920 --> 01:07:26.800
not have all the project ideas around it,


01:07:26.800 --> 01:07:30.240
but if I'm doing proper work, probably PyCharm these days.


01:07:30.240 --> 01:07:31.800
- Yeah, yeah, that makes sense.


01:07:31.800 --> 01:07:34.080
- Yeah, and then notable PyPI projects,


01:07:34.080 --> 01:07:35.280
some library out there.


01:07:35.280 --> 01:07:36.760
I mean, you've already talked about it,


01:07:36.760 --> 01:07:38.240
like TensorFlow and some others,


01:07:38.240 --> 01:07:39.520
but anything out there you're like,


01:07:39.520 --> 01:07:41.600
oh, we should definitely check this out?


01:07:41.600 --> 01:07:43.640
- Let me think.


01:07:46.200 --> 01:07:47.760
not on all PyFive projects.


01:07:47.760 --> 01:07:55.000
I would check out Hugging Face if you haven't yet.


01:07:55.000 --> 01:07:56.400
It's pretty cool library.


01:07:56.400 --> 01:07:57.960
Yeah, pretty cool library.


01:07:57.960 --> 01:08:00.760
- Yeah, Hugging Face seems like a really interesting idea.


01:08:00.760 --> 01:08:03.080
I wanna give a quick shout out to one as well.


01:08:03.080 --> 01:08:04.160
I don't know if you've seen this.


01:08:04.160 --> 01:08:09.160
Have you seen PLS, please, as an LS replacement?


01:08:09.160 --> 01:08:11.520
Chris May told me about this yesterday.


01:08:11.520 --> 01:08:14.080
Told me and Brian for Python Bytes.


01:08:14.080 --> 01:08:14.920
Check this out.


01:08:14.920 --> 01:08:19.480
It's a new LLS that has icons and it's all developer focused.


01:08:19.480 --> 01:08:21.280
So if you've got a virtual environment,


01:08:21.280 --> 01:08:23.040
it'll show that separately.


01:08:23.040 --> 01:08:28.040
If you've got a Python file, it has a Python icon.


01:08:28.040 --> 01:08:30.600
The things that appear in the list are controlled somewhat


01:08:30.600 --> 01:08:33.640
by the gitignore file and other things like that.


01:08:33.640 --> 01:08:36.800
And you can even do a more detailed listing


01:08:36.800 --> 01:08:39.160
where it'll show the git status of the various files.


01:08:39.160 --> 01:08:40.280
Isn't that crazy?


01:08:40.280 --> 01:08:41.120
- That's really cool.


01:08:41.120 --> 01:08:43.760
- Yeah, so that's a Python library PLS.


01:08:43.760 --> 01:08:44.600
- PLS, that's awesome.


01:08:44.600 --> 01:08:45.800
- I'll check that one out.


01:08:45.800 --> 01:08:47.360
- Yeah, we'll check that out.


01:08:47.360 --> 01:08:48.520
- Yeah.


01:08:48.520 --> 01:08:51.520
- All right, Dylan, thank you so much for being on the show.


01:08:51.520 --> 01:08:55.880
It's really cool to get this look into running ML stuff


01:08:55.880 --> 01:08:58.000
in production and whatnot.


01:08:58.000 --> 01:08:59.280
You wanna give us a final call?


01:08:59.280 --> 01:09:00.120
Yeah, you bet.


01:09:00.120 --> 01:09:01.160
You wanna give us a final call to action?


01:09:01.160 --> 01:09:04.860
People are interested in sort of maybe doing an ML startup


01:09:04.860 --> 01:09:08.400
or even if they wanna do things with Assembly AI.


01:09:08.400 --> 01:09:11.680
- Yeah, so if you wanna check out our APIs


01:09:11.680 --> 01:09:13.400
for automatic speech to text,


01:09:13.400 --> 01:09:16.520
You can go to our website, assemblyai.com,


01:09:16.520 --> 01:09:17.880
get a free API token.


01:09:17.880 --> 01:09:19.600
You don't have to talk to anyone.


01:09:19.600 --> 01:09:20.800
You can start playing around.


01:09:20.800 --> 01:09:22.260
There's a lot of Python code samples


01:09:22.260 --> 01:09:25.720
that you can grab to get up and running pretty quickly.


01:09:25.720 --> 01:09:29.000
And then, yeah, if you're interested in ML startups,


01:09:29.000 --> 01:09:32.160
I think that, like, one of the things


01:09:32.160 --> 01:09:35.040
that I always recommend is if you wanna go


01:09:35.040 --> 01:09:38.920
like the funding route,


01:09:38.920 --> 01:09:42.080
definitely check out Y Combinator as a place to apply


01:09:42.080 --> 01:09:44.040
because that really helped us get off the ground.


01:09:44.040 --> 01:09:47.720
They help you out with like a lot of credits around GPUs


01:09:47.720 --> 01:09:50.040
and resources and it helps a lot.


01:09:50.040 --> 01:09:50.880
That helped us a lot.


01:09:50.880 --> 01:09:53.480
- Were you in the 2017 cohort?


01:09:53.480 --> 01:09:55.480
- Yeah, 2017.


01:09:55.480 --> 01:09:59.760
So it was super helpful and I would highly recommend that.


01:09:59.760 --> 01:10:04.080
There's also just a big community of other like ML people


01:10:04.080 --> 01:10:05.680
that you can get access to through that.


01:10:05.680 --> 01:10:07.240
So that really helped


01:10:07.240 --> 01:10:10.520
and I would recommend people check that out.


01:10:10.520 --> 01:10:13.160
How about if I don't want to go VC funded?


01:10:13.160 --> 01:10:14.040
Oh, one more.


01:10:14.040 --> 01:10:19.880
Yeah, so one more is also an online accelerator called Pioneer.


01:10:19.880 --> 01:10:23.960
I don't know if you've heard of this, but that's also a good one to check out too.


01:10:23.960 --> 01:10:28.280
If you don't want to go the accelerator route, then I would say,


01:10:28.280 --> 01:10:37.080
really it's just about getting a model working good enough to close your first customer and then


01:10:37.080 --> 01:10:38.480
and then just keep iterating.


01:10:38.480 --> 01:10:42.040
So don't get caught up in reaching state of the art


01:10:42.040 --> 01:10:45.760
or in the research,


01:10:45.760 --> 01:10:49.280
just think of the MVP model that you need to build


01:10:49.280 --> 01:10:50.760
to go win your first customer


01:10:50.760 --> 01:10:52.600
and then keep going from there.


01:10:52.600 --> 01:10:54.080
- Yeah, awesome.


01:10:54.080 --> 01:10:56.080
All right, well, thanks for sharing all your experience


01:10:56.080 --> 01:10:57.320
and for being here.


01:10:57.320 --> 01:10:59.440
- Yeah, yeah, thanks for having me on, this was fun.


01:10:59.440 --> 01:11:00.360
- Yeah, you bet, it was.


01:11:00.360 --> 01:11:01.840
Bye. - Cool, all right, bye.

