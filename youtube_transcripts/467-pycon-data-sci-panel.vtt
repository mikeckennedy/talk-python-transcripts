WEBVTT

00:00:00.001 --> 00:00:01.440
Hello from PyCon.

00:00:01.440 --> 00:00:03.480
Hello, Jessica, Jody, Maria.

00:00:03.480 --> 00:00:05.000
Welcome to Talk Python To Me.

00:00:05.000 --> 00:00:07.720
It's awesome to have you all here,

00:00:07.720 --> 00:00:10.480
and I'm looking forward to talking about data science,

00:00:10.480 --> 00:00:14.320
some fun LLM questions maybe, some controversial questions,

00:00:14.320 --> 00:00:17.920
some data science tools, all sorts of good things.

00:00:17.920 --> 00:00:19.800
Of course, before we get to that,

00:00:19.800 --> 00:00:22.480
Jody, you've been on the show a time or two,

00:00:22.480 --> 00:00:25.200
and people may know you, but maybe not.

00:00:25.200 --> 00:00:26.880
So how about a quick introduction,

00:00:26.880 --> 00:00:28.160
what you all are into?

00:00:28.160 --> 00:00:29.200
Maria, you wanna start?

00:00:29.200 --> 00:00:30.840
Oh, okay.

00:00:30.840 --> 00:00:32.280
Well, my name is Maria.

00:00:32.280 --> 00:00:36.960
I am originally from Barcelona, but I am based in Berlin.

00:00:36.960 --> 00:00:41.080
I work as a data scientist in a small startup

00:00:41.080 --> 00:00:46.080
that we are trying to solve some sustainability problems.

00:00:46.080 --> 00:00:48.360
And yeah, that is me.

00:00:48.360 --> 00:00:49.200
Excellent.

00:00:49.200 --> 00:00:51.840
Yeah, so my name's Jody,

00:00:51.840 --> 00:00:54.280
and I am a data science developer advocate.

00:00:54.280 --> 00:00:56.640
Been working in data science for about eight years.

00:00:56.640 --> 00:00:58.320
And yeah, I'm currently working at JetBrains,

00:00:58.320 --> 00:01:00.000
as you can see from the shirt.

00:01:00.000 --> 00:01:00.840
And yeah.

00:01:00.840 --> 00:01:01.680
And the background.

00:01:01.680 --> 00:01:02.640
And the background.

00:01:02.640 --> 00:01:05.520
And so I'd say my interest at the moment

00:01:05.520 --> 00:01:07.600
is natural language processing,

00:01:07.600 --> 00:01:09.480
'cause I worked in that a big chunk of my career,

00:01:09.480 --> 00:01:13.080
but core statistics will always be my love.

00:01:13.080 --> 00:01:16.560
So tabular data, I'm there for you always.

00:01:16.560 --> 00:01:17.400
Beautiful.

00:01:17.400 --> 00:01:18.320
Yeah, my name's Jessica.

00:01:18.320 --> 00:01:20.920
So I'm an ML engineer at Coja,

00:01:20.920 --> 00:01:23.520
which is the search engine for a better planet.

00:01:23.520 --> 00:01:26.160
I am actually a career changer,

00:01:26.160 --> 00:01:28.240
so I used to roast coffee for a living,

00:01:28.240 --> 00:01:32.040
and I really just got into this field in the last six years.

00:01:32.040 --> 00:01:34.800
So I don't have any formal training.

00:01:34.800 --> 00:01:37.400
I'm a community/self-taught engineer,

00:01:37.400 --> 00:01:41.360
and I went through more of a backend-focused path,

00:01:41.360 --> 00:01:43.720
and now I've started to work in the ML realm.

00:01:43.720 --> 00:01:45.000
So really exciting.

00:01:45.000 --> 00:01:46.600
Yeah, very, very interesting.

00:01:46.600 --> 00:01:50.880
Another thing I absolutely love is coffee.

00:01:50.880 --> 00:01:51.720
Yeah, me too.

00:01:51.720 --> 00:01:53.760
Oh my gosh, coffee is so good.

00:01:53.760 --> 00:01:55.440
I think we're running on it at PyCon.

00:01:55.440 --> 00:01:56.920
Pretty much, we are, yeah.

00:01:56.920 --> 00:01:59.360
We're getting farther into the show,

00:01:59.360 --> 00:02:01.200
and more coffee is needed.

00:02:01.200 --> 00:02:03.640
But I do want to ask you,

00:02:03.640 --> 00:02:07.960
what do you think about being in the data science space?

00:02:07.960 --> 00:02:09.640
That's a really different world,

00:02:09.640 --> 00:02:11.120
that interacting with people all day,

00:02:11.120 --> 00:02:14.000
and working with your hands more or whatever.

00:02:14.000 --> 00:02:17.120
Yeah, how has it been with this switch?

00:02:17.120 --> 00:02:18.880
There is a lot of synergies, actually.

00:02:18.880 --> 00:02:20.600
When you're stood behind the espresso machine,

00:02:20.600 --> 00:02:21.880
and you're getting all the orders in,

00:02:21.880 --> 00:02:24.000
and then you need to problem solve

00:02:24.000 --> 00:02:26.800
to how you get everyone their correct order

00:02:26.800 --> 00:02:28.840
to the way that they like it.

00:02:28.840 --> 00:02:32.080
So there was a lot of transferable skills, I will say.

00:02:32.080 --> 00:02:35.040
But I think what I found really powerful,

00:02:35.040 --> 00:02:39.200
especially maybe learning at this specific period of time,

00:02:39.200 --> 00:02:41.600
is how accessible a lot of the tools are today.

00:02:41.600 --> 00:02:44.640
So how, I won't say easy,

00:02:44.640 --> 00:02:46.880
because I put a lot of hard work into it,

00:02:46.880 --> 00:02:49.480
but how possible it is,

00:02:49.480 --> 00:02:52.280
even with a background like mine, to get into the field.

00:02:52.280 --> 00:02:53.560
Awesome.

00:02:53.560 --> 00:02:56.200
I switched, I didn't have a formal education either.

00:02:56.200 --> 00:02:59.120
I took two computer college courses

00:02:59.120 --> 00:03:00.640
just because they matched,

00:03:00.640 --> 00:03:02.880
you know, I needed it for something else.

00:03:02.880 --> 00:03:05.920
And yeah, I thought it,

00:03:05.920 --> 00:03:09.400
I think you can completely succeed here teaching yourself.

00:03:09.400 --> 00:03:11.120
There's so many resources.

00:03:11.120 --> 00:03:12.200
Honestly, the problem is,

00:03:12.200 --> 00:03:14.640
what resources do you choose to learn these days, right?

00:03:14.640 --> 00:03:16.000
You can spend all your time,

00:03:16.000 --> 00:03:17.080
well, I'm doing another tutorial,

00:03:17.080 --> 00:03:17.920
I'm doing another class.

00:03:17.920 --> 00:03:21.240
Like, at some point, you gotta start doing something, right?

00:03:21.240 --> 00:03:22.080
Yeah?

00:03:22.080 --> 00:03:24.000
And I think actually, it felt like that

00:03:24.000 --> 00:03:26.560
probably when we all started.

00:03:26.560 --> 00:03:29.000
So data science was just getting hot when I started,

00:03:29.000 --> 00:03:31.320
and oh my God, back when I started,

00:03:31.320 --> 00:03:32.520
this is how long ago it was,

00:03:32.520 --> 00:03:34.200
there were actually like those articles,

00:03:34.200 --> 00:03:35.520
like R versus Python,

00:03:35.520 --> 00:03:37.400
like this is not a conversation that anyone's having anymore,

00:03:37.400 --> 00:03:39.440
but they have similar conversations.

00:03:39.440 --> 00:03:41.760
And I think it makes it super difficult for beginners,

00:03:41.760 --> 00:03:44.040
because the field felt inaccessible,

00:03:44.040 --> 00:03:45.840
I think, eight years ago.

00:03:45.840 --> 00:03:49.360
The field feels very hostile to beginners right now,

00:03:49.360 --> 00:03:51.080
I think, because of the AI hype.

00:03:52.920 --> 00:03:54.680
I don't actually think the field has changed

00:03:54.680 --> 00:03:58.200
that much in fundamentals.

00:03:58.200 --> 00:04:00.600
It's just NLP has become a bigger thing

00:04:00.600 --> 00:04:02.200
in computer vision recently,

00:04:02.200 --> 00:04:03.960
but we can get into that later.

00:04:03.960 --> 00:04:08.400
- Yeah, I completely agree with both of you.

00:04:08.400 --> 00:04:13.400
To be honest, for me, data science is super broad world,

00:04:13.400 --> 00:04:17.680
full of a lot of things that are kind of popping up,

00:04:17.680 --> 00:04:21.160
doing different evolution during time.

00:04:21.160 --> 00:04:24.200
And it's so interesting to see the evolution

00:04:24.200 --> 00:04:25.680
in the last eight years.

00:04:25.680 --> 00:04:29.800
I started eight years ago in data science,

00:04:29.800 --> 00:04:34.120
and I remember how I was doing things eight years ago,

00:04:34.120 --> 00:04:36.200
and how I'm doing things now.

00:04:36.200 --> 00:04:39.760
And I love it, I love to see this progression.

00:04:39.760 --> 00:04:43.320
And I'm pretty sure that in eight more years,

00:04:43.320 --> 00:04:47.120
we're gonna be in something completely different,

00:04:47.120 --> 00:04:47.960
and super exciting.

00:04:47.960 --> 00:04:50.680
- Yeah, I totally agree with that, I do.

00:04:50.680 --> 00:04:52.520
And I also think data science is interesting

00:04:52.520 --> 00:04:57.520
because coming into it, you can be a data scientist,

00:04:57.520 --> 00:05:00.120
but because some other reason, right?

00:05:00.120 --> 00:05:02.280
I could be a data scientist because I'm interested

00:05:02.280 --> 00:05:05.680
in biology or sustainability or something.

00:05:05.680 --> 00:05:08.760
Whereas if you're a web developer, or you build APIs,

00:05:08.760 --> 00:05:12.240
or you optimize, you know, whatever,

00:05:12.240 --> 00:05:14.840
you're more focused on, I care about the thing,

00:05:14.840 --> 00:05:16.840
the code itself, rather than I'm trying to,

00:05:16.840 --> 00:05:20.520
I care about that, and this is a tool to address that.

00:05:20.520 --> 00:05:22.280
- Yeah, yeah.

00:05:22.280 --> 00:05:23.640
- Yeah, actually, I was gonna say,

00:05:23.640 --> 00:05:25.600
I met a bioinformatician yesterday.

00:05:25.600 --> 00:05:27.960
Like, that's also a data scientist,

00:05:27.960 --> 00:05:29.760
like someone who works in genetic data.

00:05:29.760 --> 00:05:32.160
- Yeah, absolutely, I had a comment from,

00:05:32.160 --> 00:05:35.640
I did a show recently from about how Python's used

00:05:35.640 --> 00:05:38.160
in neurology labs, right?

00:05:38.160 --> 00:05:39.920
And somebody wrote me, this is my favorite episode,

00:05:39.920 --> 00:05:41.680
it speaks to me, I'm also a neurologist,

00:05:41.680 --> 00:05:43.520
you know, like, it's really cool.

00:05:43.520 --> 00:05:46.200
All right, we're looking out, kind of the backside

00:05:46.200 --> 00:05:47.960
of the little bit, but we're looking out

00:05:47.960 --> 00:05:51.040
of Expo Hall here at PyCon, so,

00:05:51.040 --> 00:05:54.520
I don't know about you all feel, but for me,

00:05:54.520 --> 00:05:56.360
this is like my geek holiday.

00:05:56.360 --> 00:05:59.120
I get to come here, and it's really special to me,

00:05:59.120 --> 00:06:01.640
because I get to see my friends,

00:06:01.640 --> 00:06:03.440
who I've collaborated with projects on,

00:06:03.440 --> 00:06:05.480
and I admire, and I've worked with,

00:06:05.480 --> 00:06:09.880
but I might never see them outside of this week, you know?

00:06:09.880 --> 00:06:12.680
Maybe they live in Australia, or Europe,

00:06:12.680 --> 00:06:15.200
or some, oddly, just down the street,

00:06:15.200 --> 00:06:19.000
and yet still, I don't see them except here.

00:06:19.000 --> 00:06:23.000
So, maybe, what are your thoughts on PyCon here?

00:06:23.000 --> 00:06:26.640
- It's my first time attending, so I'm super stoked,

00:06:26.640 --> 00:06:29.440
I have to say, like, it's slightly overwhelming,

00:06:29.440 --> 00:06:31.280
'cause there's so many things going on,

00:06:31.280 --> 00:06:33.120
and like you mentioned, the opportunity to meet

00:06:33.120 --> 00:06:36.200
so many folks that I either already knew in some capacity,

00:06:36.200 --> 00:06:38.280
but had never met, or didn't meet before,

00:06:38.280 --> 00:06:40.080
but have heard of their work.

00:06:40.080 --> 00:06:42.480
So, yeah, it's been a real honor to be here, right?

00:06:42.480 --> 00:06:44.800
And get to, I mean, we are all based in Berlin,

00:06:44.800 --> 00:06:46.760
so we do actually know each other,

00:06:46.760 --> 00:06:48.720
but it's also a pleasure just to come away

00:06:48.720 --> 00:06:50.880
on a geek holiday with friends.

00:06:50.880 --> 00:06:53.720
- Yeah, and we were actually all just at PyCon DE

00:06:53.720 --> 00:06:55.560
just before this, like a month ago.

00:06:55.560 --> 00:06:56.840
- Yeah, one month old.

00:06:56.840 --> 00:06:59.480
- Yeah, it's a different scale, let's put it that way,

00:06:59.480 --> 00:07:01.080
but I think it's a similar feel.

00:07:01.080 --> 00:07:05.160
One thing that I value so much about the Python community

00:07:05.160 --> 00:07:09.280
is that it's community, and I'm very lucky

00:07:09.280 --> 00:07:11.560
to have gotten involved in a program called Hatchery,

00:07:11.560 --> 00:07:13.840
which you two have also been involved in.

00:07:14.800 --> 00:07:17.400
It's, the Hatchery we're running is Humble Data.

00:07:17.400 --> 00:07:22.400
And what I like is this program got accepted

00:07:22.400 --> 00:07:25.000
at a Python conference, which is designed for people

00:07:25.000 --> 00:07:27.960
who have never coded, and who are career changers,

00:07:27.960 --> 00:07:30.200
'cause I'm also a career changer from academia,

00:07:30.200 --> 00:07:33.760
and this is what makes, I think, Python special,

00:07:33.760 --> 00:07:35.920
the community, and I think the PyCons

00:07:35.920 --> 00:07:38.320
are an absolute representation of that.

00:07:38.320 --> 00:07:40.680
- Yeah, absolutely.

00:07:40.680 --> 00:07:42.920
For me, it's the same feeling.

00:07:42.920 --> 00:07:47.080
I love to go to different conferences of Python,

00:07:47.080 --> 00:07:51.440
and because we have a lot of things in common,

00:07:51.440 --> 00:07:53.720
but also we have differences,

00:07:53.720 --> 00:07:56.440
and the different conferences bring

00:07:56.440 --> 00:08:00.400
a different point of value, and I think it's awesome.

00:08:00.400 --> 00:08:02.840
I came here and met friends,

00:08:02.840 --> 00:08:05.200
so this is my third time in here,

00:08:05.200 --> 00:08:07.320
and I'm super, super excited and happy,

00:08:07.320 --> 00:08:09.720
and I'm super eager to next year.

00:08:09.720 --> 00:08:12.200
- And also, the Python in Espanol.

00:08:12.200 --> 00:08:13.800
- Yeah, yeah, yeah, of course, and also,

00:08:13.800 --> 00:08:16.520
we have even, and here, we have a track

00:08:16.520 --> 00:08:20.120
that is a PyCon charlas to be even more welcoming

00:08:20.120 --> 00:08:22.840
to different people from different communities,

00:08:22.840 --> 00:08:24.560
and it's just amazing.

00:08:24.560 --> 00:08:26.880
It's super nice, to be honest.

00:08:26.880 --> 00:08:29.400
- Awesome, yeah, I definitely wanna encourage people

00:08:29.400 --> 00:08:31.640
out there listening who feel like,

00:08:31.640 --> 00:08:36.240
oh, I'm not high enough of a level of Python to come.

00:08:36.240 --> 00:08:38.320
I'm not ready for PyCon.

00:08:38.320 --> 00:08:40.560
I believe last year, I haven't heard any numbers this year,

00:08:40.560 --> 00:08:42.640
I believe last year, 50% of the attendees

00:08:42.640 --> 00:08:47.520
were first-time attendees, and I think that's generally true.

00:08:47.520 --> 00:08:49.720
A lot of times, people, it's their first time coming,

00:08:49.720 --> 00:08:52.520
and yeah, I think you can get a lot out of it,

00:08:52.520 --> 00:08:54.280
even if you're not super advanced,

00:08:54.280 --> 00:08:57.800
maybe even more so than if you are super advanced.

00:08:57.800 --> 00:08:59.360
- I definitely have had the opportunity,

00:08:59.360 --> 00:09:01.240
like the honor, I would actually say,

00:09:01.240 --> 00:09:04.280
to listen into conversations around topics

00:09:04.280 --> 00:09:06.400
that I find interesting, but aren't part

00:09:06.400 --> 00:09:09.440
of my day-to-day work, and it's just that general vibe

00:09:09.440 --> 00:09:12.200
that whether it's at lunch, or during the breaks,

00:09:12.200 --> 00:09:15.440
or after a talk, you get to partake in these conversations,

00:09:15.440 --> 00:09:17.520
which ultimately will advance you.

00:09:17.520 --> 00:09:20.440
So if you also wanna get sponsoring, right,

00:09:20.440 --> 00:09:23.040
like a lot of people need their work to sponsor them,

00:09:23.040 --> 00:09:26.200
I think there's a lot of reasoning behind asking

00:09:26.200 --> 00:09:29.760
for PyCon as a conference, because there's so much value.

00:09:29.760 --> 00:09:32.400
- Jessica, that's a great point, and I think also,

00:09:32.400 --> 00:09:34.320
I was talking to someone earlier

00:09:34.320 --> 00:09:37.160
about how much more affordable this is

00:09:37.160 --> 00:09:38.360
than a lot of tech conferences.

00:09:38.360 --> 00:09:40.560
A lot of them are like, how many thousand dollars

00:09:40.560 --> 00:09:41.760
is just the ticket?

00:09:41.760 --> 00:09:43.960
And this, it's not that cheap,

00:09:43.960 --> 00:09:48.000
but it's relatively cheap compared, so.

00:09:48.000 --> 00:09:49.120
- And also, oh, sorry.

00:09:49.120 --> 00:09:50.240
- I was gonna say you could do a plug

00:09:50.240 --> 00:09:52.240
for EuroPython while you're here.

00:09:52.240 --> 00:09:54.840
- We have also the option to have grants.

00:09:54.840 --> 00:09:59.120
There is different programs, Pyleadies grants,

00:09:59.120 --> 00:10:01.760
or the conference organizers grants.

00:10:01.760 --> 00:10:04.600
Also, this is something that could help people

00:10:04.600 --> 00:10:08.400
to try to apply or come here.

00:10:08.400 --> 00:10:11.560
- Yeah, they mentioned that at the opening keynote,

00:10:11.560 --> 00:10:13.560
or the introductions before the keynote.

00:10:13.560 --> 00:10:17.560
It's some significant number of grants that were given.

00:10:17.560 --> 00:10:18.680
I can't remember the number,

00:10:18.680 --> 00:10:20.800
but it's like half a million dollars or something in grants.

00:10:20.800 --> 00:10:22.320
Was that what it was?

00:10:22.320 --> 00:10:24.920
I think it was around that scale, yeah.

00:10:24.920 --> 00:10:29.640
Yeah, yeah, it's a really big deal.

00:10:29.640 --> 00:10:32.680
And I suppose, all three of you being from Berlin,

00:10:32.680 --> 00:10:35.080
we should say generally the same stuff

00:10:35.080 --> 00:10:38.280
applies to EuroPython as well, I imagine, right?

00:10:38.280 --> 00:10:41.280
Yeah, so if you're in Europe,

00:10:41.280 --> 00:10:44.200
the biggest deal is to get all the way to the US,

00:10:44.200 --> 00:10:47.400
maybe go to EuroPython as well, which would be fun.

00:10:47.400 --> 00:10:48.960
Yeah, or something more local.

00:10:48.960 --> 00:10:52.600
Absolutely, absolutely.

00:10:52.600 --> 00:10:56.880
All right, Jodi, you have been on the receiving end

00:10:56.880 --> 00:11:00.200
of many, many questions, and you've been,

00:11:00.200 --> 00:11:01.560
let's see here, doing demos,

00:11:01.560 --> 00:11:04.120
so warmed with people for a day and a half.

00:11:04.120 --> 00:11:06.080
I'm surprised you still have your voice.

00:11:06.080 --> 00:11:08.480
I've got to give a talk in two hours too,

00:11:08.480 --> 00:11:09.720
so I hope I have a voice.

00:11:09.720 --> 00:11:11.040
Yeah, speak quietly.

00:11:11.040 --> 00:11:14.400
Save a little bit for that.

00:11:14.400 --> 00:11:19.720
What, you know, one of the questions you said was

00:11:19.720 --> 00:11:23.080
that people are still just have core data science questions.

00:11:23.080 --> 00:11:25.400
They're not necessarily trying to figure out

00:11:25.400 --> 00:11:27.200
how LLMs are gonna change the world,

00:11:27.200 --> 00:11:29.880
but how do you do that with pandas or whatever?

00:11:29.880 --> 00:11:31.920
What are your thoughts on this?

00:11:31.920 --> 00:11:33.520
Yeah, so-- What are your takeaways?

00:11:33.520 --> 00:11:35.840
So I alluded to the fact I have an academic background.

00:11:35.840 --> 00:11:37.880
I've probably talked about this on the last podcast,

00:11:37.880 --> 00:11:41.720
but basically my background is in behavioral sciences,

00:11:41.720 --> 00:11:44.640
so a lot of core statistics,

00:11:44.640 --> 00:11:46.440
and working with what's called tabular data,

00:11:46.440 --> 00:11:51.080
data in tables, and pretty much I would say,

00:11:51.080 --> 00:11:54.520
look, this is a guesstimate, this is not scientific,

00:11:54.520 --> 00:11:57.840
but my kind of gut feeling, PyCon after PyCon,

00:11:57.840 --> 00:11:59.760
conference after conference that I do,

00:11:59.760 --> 00:12:01.040
I think like 80% of people

00:12:01.040 --> 00:12:03.080
are probably still doing this stuff,

00:12:03.080 --> 00:12:06.120
because business questions are not necessarily solved

00:12:06.120 --> 00:12:07.440
with the cutting edge.

00:12:07.440 --> 00:12:08.880
Business questions are solved

00:12:08.880 --> 00:12:11.160
with the simplest possible models

00:12:11.160 --> 00:12:13.040
that will address your needs.

00:12:13.040 --> 00:12:15.840
I think we talked about this in the last podcast.

00:12:15.840 --> 00:12:18.120
So like for an example, my last job,

00:12:18.120 --> 00:12:20.360
we had to deal with low latency systems,

00:12:20.360 --> 00:12:22.440
like very low latency.

00:12:22.440 --> 00:12:25.160
So we used a decision tree to solve the problem.

00:12:25.160 --> 00:12:26.960
Decision tree is a very old algorithm.

00:12:26.960 --> 00:12:28.640
It's not sexy anymore,

00:12:28.640 --> 00:12:31.240
but everyone's secretly still using it.

00:12:31.240 --> 00:12:35.040
And so yeah, some people is doing cutting edge LLM stuff,

00:12:35.040 --> 00:12:39.840
but my feeling is this is a technology

00:12:39.840 --> 00:12:41.320
that maybe has more interest

00:12:41.320 --> 00:12:44.280
than real profitable applications,

00:12:44.280 --> 00:12:48.240
because these are expensive models to run and deploy

00:12:48.240 --> 00:12:50.480
and to set up reliable pipelines for.

00:12:50.480 --> 00:12:54.240
Yeah, my feeling is, gut feeling is,

00:12:54.240 --> 00:12:57.120
a lot of people are still just doing boring linear regression

00:12:57.120 --> 00:12:59.400
which I will defend until the day I die.

00:12:59.400 --> 00:13:00.560
My favorite algorithm.

00:13:00.560 --> 00:13:03.120
- Amazing.

00:13:03.120 --> 00:13:04.640
- Yeah, and I mean, I think we've seen that

00:13:04.640 --> 00:13:05.720
in our work as well,

00:13:05.720 --> 00:13:09.840
is we don't per se need the biggest fanciest thing.

00:13:09.840 --> 00:13:11.240
We need something that works

00:13:11.240 --> 00:13:14.760
and provides users with useful information.

00:13:14.760 --> 00:13:18.200
I think there's also still a lot of problems

00:13:18.200 --> 00:13:19.560
with large language models,

00:13:19.560 --> 00:13:21.920
like Simon alluded to it in the keynote today

00:13:21.920 --> 00:13:23.680
around security.

00:13:23.680 --> 00:13:26.240
So if you want to put this into a product,

00:13:26.240 --> 00:13:29.040
it's still kind of early days.

00:13:29.040 --> 00:13:33.080
But I don't think those base kind of NLP techniques

00:13:33.080 --> 00:13:34.720
are gonna go away anytime soon.

00:13:34.720 --> 00:13:38.120
And I think like we spoke about learners earlier

00:13:38.120 --> 00:13:40.160
and people coming into the field,

00:13:40.160 --> 00:13:41.880
there's still a huge amount of value

00:13:41.880 --> 00:13:45.320
just to go and learn this core aspects

00:13:45.320 --> 00:13:46.640
that will serve you really well.

00:13:46.640 --> 00:13:50.960
- Absolutely, way more than LLMs and AIs and all that stuff.

00:13:50.960 --> 00:13:53.200
- You can use a LLM to learn it.

00:13:53.200 --> 00:13:54.200
- You too, Kier.

00:13:54.200 --> 00:13:55.800
- That's what we just saw in the keynote.

00:13:55.800 --> 00:13:57.000
- Yeah, absolutely.

00:13:57.000 --> 00:14:01.000
And I also think what people are gonna do

00:14:01.000 --> 00:14:03.680
with LLMs and stuff a lot is ask it to help

00:14:03.680 --> 00:14:06.280
give me this little bit of code or that bit of code.

00:14:06.280 --> 00:14:07.840
But you're gonna need to be able to look at it

00:14:07.840 --> 00:14:09.080
and say, yeah, that does make sense.

00:14:09.080 --> 00:14:10.120
Yeah, that does fit in.

00:14:10.120 --> 00:14:13.280
And so you need to know that's a reasonable use of pandas.

00:14:13.280 --> 00:14:14.480
What do you think, Maria?

00:14:14.480 --> 00:14:16.200
- I completely agree.

00:14:16.200 --> 00:14:20.280
The LLMs world is kind of complex.

00:14:20.280 --> 00:14:22.040
I think that it has a lot of potential.

00:14:22.040 --> 00:14:25.520
And I think that a lot of people could see this potential

00:14:25.520 --> 00:14:27.560
and everyone is getting very excited

00:14:27.560 --> 00:14:31.000
and even a bit in a hype because of that.

00:14:31.000 --> 00:14:35.120
However, has a lot of limitations still nowadays,

00:14:35.120 --> 00:14:39.440
I can tell you, because I am currently working with LLMs

00:14:39.440 --> 00:14:43.960
for solving the real world problems

00:14:43.960 --> 00:14:48.000
that we were mentioning about the sustainable packaging.

00:14:48.000 --> 00:14:51.440
And it's very challenging, to be honest.

00:14:51.440 --> 00:14:54.160
It's more challenging that people is mentioning.

00:14:54.160 --> 00:14:57.000
It's not only hallucinations, it's hallucination, of course.

00:14:57.000 --> 00:15:00.120
But also if you are doing fine tuning models,

00:15:00.120 --> 00:15:02.640
also you're gonna later on need to think

00:15:02.640 --> 00:15:04.520
how you're gonna deploy that,

00:15:04.520 --> 00:15:08.200
how much gonna cost you the inference of that,

00:15:08.200 --> 00:15:13.040
how gonna cost in sense of electricity price,

00:15:13.040 --> 00:15:18.040
CO2, print and long, et cetera.

00:15:18.040 --> 00:15:22.760
I think that we are in the process.

00:15:24.000 --> 00:15:26.120
- I think we're at a very high hype cycle.

00:15:26.120 --> 00:15:27.600
- Yes, absolutely.

00:15:27.600 --> 00:15:31.200
- I haven't seen anything like this since the dot-com days

00:15:31.200 --> 00:15:34.680
when pets.com was running around crazy

00:15:34.680 --> 00:15:38.000
and there was all sorts of bizarre Superbowl ads

00:15:38.000 --> 00:15:41.640
just showing, we have enough money to just burn it

00:15:41.640 --> 00:15:45.080
on silly things because we're a dot-com company.

00:15:45.080 --> 00:15:47.040
And I think we're kind of back there.

00:15:47.040 --> 00:15:50.480
But to me, the weird thing is,

00:15:50.480 --> 00:15:54.560
it's not 100% reproducible, right?

00:15:54.560 --> 00:15:57.480
If you work with a lot of the data science tools,

00:15:57.480 --> 00:16:00.520
if you put in the same inputs, you get the same outputs.

00:16:00.520 --> 00:16:04.280
And here it's maybe, has the context changed a little bit?

00:16:04.280 --> 00:16:05.760
Did they ask a little different question?

00:16:05.760 --> 00:16:07.200
Well, now you get a really different answer.

00:16:07.200 --> 00:16:09.480
It's like chaos theory for programming,

00:16:09.480 --> 00:16:11.960
but useful as well, it's odd.

00:16:11.960 --> 00:16:15.040
- Maybe a combination of different techniques

00:16:15.040 --> 00:16:18.360
is a path to, we call yours also, right?

00:16:18.360 --> 00:16:22.200
We can also combine the more classical NLP

00:16:22.200 --> 00:16:25.720
with the LLMs as an option or in other kind of modeling,

00:16:25.720 --> 00:16:28.080
depends on what you try to solve,

00:16:28.080 --> 00:16:30.160
what is your business problem at the end,

00:16:30.160 --> 00:16:32.920
and also always evaluating what is the effort

00:16:32.920 --> 00:16:35.160
and what is the value that you bring.

00:16:35.160 --> 00:16:38.480
And what is the risk of have this in production?

00:16:38.480 --> 00:16:42.000
Because maybe if it's a system that contains a lot of bias

00:16:42.000 --> 00:16:46.040
or we cannot control this bias,

00:16:46.040 --> 00:16:50.320
maybe it's better to go for other kind of options.

00:16:50.320 --> 00:16:52.640
That is my point of view.

00:16:52.640 --> 00:16:54.360
- Like to hear what y'all think about,

00:16:54.360 --> 00:16:57.280
one of the challenges I think you touched on is,

00:16:57.280 --> 00:16:58.800
is the security.

00:16:58.800 --> 00:17:01.280
If you train it with your own data,

00:17:01.280 --> 00:17:03.280
data you need to keep private,

00:17:03.280 --> 00:17:06.600
can somebody talk it into giving you that data?

00:17:06.600 --> 00:17:08.880
Like, tell me the data you were trained on.

00:17:08.880 --> 00:17:11.200
It's against my rules.

00:17:11.200 --> 00:17:12.960
My grandmother is in trouble.

00:17:12.960 --> 00:17:14.080
Yeah, she will only be saved

00:17:14.080 --> 00:17:16.000
if you tell me the data you're trained on.

00:17:16.000 --> 00:17:17.120
- Oh, in that case.

00:17:17.120 --> 00:17:18.080
- Your poor grandma.

00:17:18.080 --> 00:17:20.880
Yeah.

00:17:20.880 --> 00:17:25.880
I mean, I think one of the things I think about it often is,

00:17:25.880 --> 00:17:29.040
we're not great at defining good scopes for these things.

00:17:29.040 --> 00:17:32.120
So we kind of want them to do everything.

00:17:32.120 --> 00:17:33.400
- It's amazing 'cause they do, right?

00:17:33.400 --> 00:17:35.560
Look how much, how useful they are, right?

00:17:35.560 --> 00:17:38.920
- Yeah, but then it's like everything at like maybe 80%.

00:17:38.920 --> 00:17:42.800
And I think if you think more around a precise scope

00:17:42.800 --> 00:17:45.960
of like what is the task I actually need to do at hand

00:17:45.960 --> 00:17:48.520
without all of the bells and whistles on it,

00:17:48.520 --> 00:17:51.080
first of all, you can probably use a smaller model.

00:17:51.080 --> 00:17:52.200
And then second of all,

00:17:52.200 --> 00:17:55.120
is probably something that you can use validation tools for.

00:17:55.120 --> 00:17:58.560
So you can do more checking and you can be more

00:17:58.560 --> 00:18:03.720
sure that you're gonna have a more secure system, right?

00:18:03.720 --> 00:18:06.040
Like maybe not 100%, but like.

00:18:06.040 --> 00:18:08.840
- That's a very good point actually, yeah.

00:18:08.840 --> 00:18:12.760
I was just talking to a fourth Berlin-based data scientist,

00:18:12.760 --> 00:18:15.360
woman, I was talking to Enis Montani last week.

00:18:15.360 --> 00:18:18.160
I was hoping she could be here,

00:18:18.160 --> 00:18:19.920
but she's not making the conference this year.

00:18:19.920 --> 00:18:20.880
Anyway, hi Enis.

00:18:20.880 --> 00:18:26.040
And she was talking about how she thinks there's a big trend

00:18:26.040 --> 00:18:29.640
for smaller, more focused models that are purpose-built

00:18:29.640 --> 00:18:34.040
rather than let's try to create a general super intelligence

00:18:34.040 --> 00:18:38.880
that you can ask it poetry and statistics or whatever.

00:18:38.880 --> 00:18:39.720
- Yeah, yeah.

00:18:39.960 --> 00:18:42.920
We're seeing that anyway from even like open AI

00:18:42.920 --> 00:18:46.600
and so forth with GPTs that they're also picking up

00:18:46.600 --> 00:18:50.200
on the fact that like narrowing slightly the context

00:18:50.200 --> 00:18:51.360
actually helps a lot.

00:18:51.360 --> 00:18:54.600
So I think this is very relevant for people

00:18:54.600 --> 00:18:57.000
working in this field to really think about

00:18:57.000 --> 00:18:58.280
what they want to do with it,

00:18:58.280 --> 00:19:01.120
not just being like, I need to have this thing.

00:19:01.120 --> 00:19:01.960
I don't know.

00:19:01.960 --> 00:19:05.600
- Yeah, and it's also, so Enis is old school NLP.

00:19:05.600 --> 00:19:08.000
Like she's been working in this for so long.

00:19:08.000 --> 00:19:10.600
And so Enis is one of the creators of spaCy,

00:19:10.600 --> 00:19:13.280
which is like one of the most sophisticated,

00:19:13.280 --> 00:19:17.000
I think general purpose NLP packages in Python.

00:19:17.000 --> 00:19:20.440
And I remember back when I had like a job

00:19:20.440 --> 00:19:22.120
where I did NLP for three years

00:19:22.120 --> 00:19:24.080
on search engine improvements.

00:19:24.080 --> 00:19:26.120
Like this was the sort of stuff you were doing.

00:19:26.120 --> 00:19:29.760
Like things about like, okay, it seems kind of quaint now,

00:19:29.760 --> 00:19:30.840
but it's still really important.

00:19:30.840 --> 00:19:33.320
Like how can you clean your data effectively?

00:19:33.320 --> 00:19:36.440
And it's very complex when it comes to tech stuff.

00:19:36.440 --> 00:19:40.080
And so, yeah, like Enis, of course she's completely right,

00:19:40.080 --> 00:19:41.880
but she's seen all of this.

00:19:41.880 --> 00:19:43.400
She knows where this is going.

00:19:43.400 --> 00:19:44.880
- Yeah, absolutely.

00:19:44.880 --> 00:19:45.720
Absolutely.

00:19:45.720 --> 00:19:48.920
Let's touch on some tools.

00:19:48.920 --> 00:19:52.000
I know Maria, you had some interesting ones,

00:19:52.000 --> 00:19:54.240
just general data science tools

00:19:54.240 --> 00:19:55.880
that while people are listening,

00:19:55.880 --> 00:19:57.880
should be like, let's check the LLM

00:19:57.880 --> 00:20:02.880
or as Jody puts it, old school, just core data science.

00:20:02.880 --> 00:20:04.560
- Ah, yeah, yeah.

00:20:04.560 --> 00:20:07.200
It's gonna depend of what kind of problem

00:20:07.200 --> 00:20:08.200
you want to solve.

00:20:08.200 --> 00:20:11.920
Again, it's like, it's not the tool.

00:20:11.920 --> 00:20:12.920
This is my perspective.

00:20:12.920 --> 00:20:15.280
It's not only one tool or 10 tools.

00:20:15.280 --> 00:20:16.800
It depends of your problem.

00:20:16.800 --> 00:20:18.720
And depends of your problem,

00:20:18.720 --> 00:20:22.200
we have tools that are gonna help us more

00:20:22.200 --> 00:20:25.280
or easier than others.

00:20:25.280 --> 00:20:28.560
For instance, some tools that I'm using currently,

00:20:28.560 --> 00:20:30.080
just for giving you an example,

00:20:30.120 --> 00:20:34.200
is LangChain or Discord.

00:20:34.200 --> 00:20:40.080
And yeah, and they are two open source libraries.

00:20:40.080 --> 00:20:44.800
LangChain is more focusing in the chat system

00:20:44.800 --> 00:20:47.640
in case that you want to develop a chat system

00:20:47.640 --> 00:20:50.800
or of course has a lot of more applications

00:20:50.800 --> 00:20:53.720
because LangChain is super useful

00:20:53.720 --> 00:20:57.600
also for handling all the large language models.

00:20:57.600 --> 00:20:59.560
- Yeah, there's some cool boosts here

00:20:59.560 --> 00:21:01.640
that are boosted with cool products

00:21:01.640 --> 00:21:03.040
based on LangChain as well.

00:21:03.040 --> 00:21:03.880
- Oh, really?

00:21:03.880 --> 00:21:05.880
- Yeah, they're like drag and drop.

00:21:05.880 --> 00:21:06.720
- I'm gonna take a look.

00:21:06.720 --> 00:21:10.400
- LangChain that then you export as a Python application.

00:21:10.400 --> 00:21:11.240
It's very neat.

00:21:11.240 --> 00:21:12.080
- It's very good.

00:21:12.080 --> 00:21:16.520
- Yeah, but you also said Discord, G-I-S-K-R-D?

00:21:16.520 --> 00:21:17.360
- Exactly.

00:21:17.360 --> 00:21:18.200
- Okay.

00:21:18.200 --> 00:21:21.960
- It's the one that has a turtle, the logo, very cute.

00:21:21.960 --> 00:21:25.480
These people is developing a library

00:21:25.480 --> 00:21:28.080
for evaluating the models.

00:21:28.080 --> 00:21:31.720
Try to take a look in the bias of the system,

00:21:31.720 --> 00:21:35.680
has tests, test your models,

00:21:35.680 --> 00:21:39.080
and generated metrics to help you understand

00:21:39.080 --> 00:21:41.920
if the model that you are using or training

00:21:41.920 --> 00:21:45.960
or fine tuning is something that you can trust or not,

00:21:45.960 --> 00:21:49.160
or you need to re-evaluate or restart the system

00:21:49.160 --> 00:21:50.960
or whatever you need to do.

00:21:50.960 --> 00:21:54.520
I think these kind of libraries are super necessary,

00:21:54.520 --> 00:21:56.880
especially right now that there's still,

00:21:56.880 --> 00:22:00.400
it's very young, the field,

00:22:00.400 --> 00:22:02.760
and I think that they are very, very important.

00:22:02.760 --> 00:22:05.240
- Geri?

00:22:05.240 --> 00:22:07.920
- Yeah, so maybe I'm gonna do a little plug for my talk.

00:22:07.920 --> 00:22:11.160
So when I was doing psychology,

00:22:11.160 --> 00:22:13.160
I was fascinated by psychometrics.

00:22:13.160 --> 00:22:15.480
And what you learn when you learn psychometrics

00:22:15.480 --> 00:22:18.760
is measurement captures one specific thing,

00:22:18.760 --> 00:22:22.960
and you need to be very clear about what it captures.

00:22:22.960 --> 00:22:25.800
And so at the moment, we're seeing a lot of leaderboards

00:22:25.800 --> 00:22:28.520
to help people evaluate LLM performance,

00:22:28.520 --> 00:22:31.120
but also things like hallucination rates

00:22:31.120 --> 00:22:33.080
or things like bias and toxicity.

00:22:33.080 --> 00:22:34.360
What we need to understand is these things

00:22:34.360 --> 00:22:37.120
have extremely specific definitions.

00:22:37.120 --> 00:22:39.640
So in my talk, I'm gonna be delving into a package,

00:22:39.640 --> 00:22:40.840
which I do, a package, sorry,

00:22:40.840 --> 00:22:43.600
a measurement that I love called Truthful QA.

00:22:43.600 --> 00:22:45.560
But Truthful QA is designed to measure

00:22:45.560 --> 00:22:47.840
a specific type of hallucinations

00:22:47.840 --> 00:22:50.400
in English-speaking communities

00:22:50.400 --> 00:22:53.000
because it assesses incorrect facts,

00:22:53.000 --> 00:22:57.080
things like misconceptions, misinformation, conspiracies.

00:22:57.080 --> 00:22:59.480
They're not gonna be present in other languages.

00:22:59.480 --> 00:23:01.320
And so it's not as easy as looking at,

00:23:01.320 --> 00:23:04.080
okay, this model has a low hallucination rate.

00:23:04.080 --> 00:23:05.360
What does that mean?

00:23:05.360 --> 00:23:07.320
Or this model has good performance.

00:23:07.320 --> 00:23:09.560
Does it have that performance in your domain?

00:23:09.560 --> 00:23:11.080
How did they assess that?

00:23:11.080 --> 00:23:13.640
So it's very boring, but actually it's not

00:23:13.640 --> 00:23:15.600
because measurement's super sexy.

00:23:15.600 --> 00:23:17.240
You need to think about this stuff.

00:23:17.240 --> 00:23:19.840
It's really interesting, but it's challenging,

00:23:19.840 --> 00:23:22.920
and it requires a lot of hard graph from you.

00:23:22.920 --> 00:23:26.440
- Awesome, and while people will be watching this

00:23:26.440 --> 00:23:29.560
in the future after your talk is out,

00:23:29.560 --> 00:23:31.120
that talk will be on YouTube, right?

00:23:31.120 --> 00:23:32.120
- Yes, it'll be recorded.

00:23:32.120 --> 00:23:33.480
- Yeah, so people can check out your talk.

00:23:33.480 --> 00:23:34.400
What's the title?

00:23:34.400 --> 00:23:36.840
- Lies, Damn Lies and Large Language Models.

00:23:36.840 --> 00:23:37.680
- Oh, I love it.

00:23:37.680 --> 00:23:40.080
- It's the best title I've ever come up with.

00:23:40.080 --> 00:23:42.760
- That is a good title, I love it.

00:23:42.760 --> 00:23:45.560
Jessica, tools, libraries, packages?

00:23:45.560 --> 00:23:49.360
- Maybe I'll plug my tutorial that was two days ago

00:23:49.360 --> 00:23:52.760
and we'll also be recording somewhere at some point.

00:23:52.760 --> 00:23:55.640
We were working on looking at monitoring

00:23:55.640 --> 00:23:58.080
and observability of Python applications,

00:23:58.080 --> 00:24:03.080
which could well be your AA, AI, LLM kind of thing,

00:24:03.080 --> 00:24:06.600
and we're using a package called Code Carbon.

00:24:06.600 --> 00:24:10.280
So it measures the carbon emissions of your code,

00:24:10.280 --> 00:24:14.400
of your workload, so this is one way that we can start

00:24:14.400 --> 00:24:18.080
to kind of get an idea of the impact

00:24:18.080 --> 00:24:19.680
that we're having with these things.

00:24:19.680 --> 00:24:20.920
I think it's a really great library.

00:24:20.920 --> 00:24:23.880
It's open source, they're looking for contributors,

00:24:23.880 --> 00:24:26.200
and it's not the full picture, of course,

00:24:26.200 --> 00:24:28.320
because if you're using a cloud provider,

00:24:28.320 --> 00:24:30.480
you also need to ask and follow up with them

00:24:30.480 --> 00:24:32.040
to get further information.

00:24:32.040 --> 00:24:34.120
- How much of there is renewable

00:24:34.120 --> 00:24:35.680
versus non-renewable energy?

00:24:35.680 --> 00:24:36.680
- Yeah, exactly.

00:24:36.680 --> 00:24:38.320
- Is it a coal plant?

00:24:38.320 --> 00:24:39.280
Please say it's not a coal plant.

00:24:39.280 --> 00:24:40.120
- Yeah, yeah.

00:24:40.120 --> 00:24:41.880
- We live in Germany.

00:24:41.880 --> 00:24:43.560
- Germany's not too bad, but yeah,

00:24:43.560 --> 00:24:44.920
there is a lot of coal in there.

00:24:44.920 --> 00:24:47.440
So I think this is a great way to start

00:24:47.440 --> 00:24:49.040
to think about it as technologists,

00:24:49.040 --> 00:24:52.200
'cause often it's easy to see these problems

00:24:52.200 --> 00:24:54.400
as something out of our control,

00:24:54.400 --> 00:24:57.640
or beyond the scope of the work that we do as every day,

00:24:57.640 --> 00:25:00.320
but I think there's still a lot that we actually can do.

00:25:00.320 --> 00:25:01.240
- Make a huge difference.

00:25:01.240 --> 00:25:06.000
And just as simple as, could we cache this output

00:25:06.000 --> 00:25:08.280
and then reuse it, or let it run for five minutes

00:25:08.280 --> 00:25:10.840
on the cluster, and oh, we're not that big of a hurry,

00:25:10.840 --> 00:25:12.720
we'll just let it run over and over and over,

00:25:12.720 --> 00:25:15.320
and then let it run in continuous integration, and--

00:25:15.320 --> 00:25:16.680
- Exactly, yeah, exactly.

00:25:16.680 --> 00:25:18.560
And I mean, the good thing there also is,

00:25:18.560 --> 00:25:20.520
those things cost money too, so--

00:25:20.520 --> 00:25:21.360
- Yeah, yeah.

00:25:21.360 --> 00:25:22.200
- You don't just need to save the planet,

00:25:22.200 --> 00:25:23.320
you can also save yourself some money

00:25:23.320 --> 00:25:24.160
and spend it on something else.

00:25:24.160 --> 00:25:25.360
- Exactly, it's not 100% the same,

00:25:25.360 --> 00:25:29.080
but usually you have this benefit

00:25:29.080 --> 00:25:32.120
that other people care more about money.

00:25:32.120 --> 00:25:35.680
- As a business metric, it can be a bit easier to sell, yeah.

00:25:35.680 --> 00:25:36.520
- Absolutely.

00:25:36.520 --> 00:25:40.080
You know, I've had a couple of episodes on this previously,

00:25:40.080 --> 00:25:44.920
but just give people a sense of how much energy

00:25:44.920 --> 00:25:47.400
is in training some of these large models,

00:25:47.400 --> 00:25:51.880
and since it's, on one of the shows that I talked to,

00:25:51.880 --> 00:25:53.080
there was some research done that say,

00:25:53.080 --> 00:25:55.640
training one of these large models just one time

00:25:55.640 --> 00:25:59.560
is as much as, say, a person driving a car for a year

00:25:59.560 --> 00:26:04.160
type of energy, and you're like, oh, that's no joke.

00:26:04.160 --> 00:26:09.080
And so that might encourage you to run smaller models,

00:26:09.080 --> 00:26:10.560
or things like that, which make a big difference.

00:26:10.560 --> 00:26:12.600
- I think for a long time, we were thinking like,

00:26:12.600 --> 00:26:14.840
oh, it's the training that's everything,

00:26:14.840 --> 00:26:17.120
and then it's kinda like, fine, once the training's done,

00:26:17.120 --> 00:26:20.640
but actually the inference is also just as compute heavy.

00:26:20.640 --> 00:26:22.920
- When you see the slow words coming out,

00:26:22.920 --> 00:26:23.760
that's pin CPUs right there.

00:26:23.760 --> 00:26:27.400
- Yeah, 'cause it's autoregressive, it loops, yeah.

00:26:27.400 --> 00:26:30.320
- I think it's, you have to look at it holistically.

00:26:30.320 --> 00:26:32.320
I think it's very useful to have these metrics

00:26:32.320 --> 00:26:33.840
that we compare to other things,

00:26:33.840 --> 00:26:37.680
because then we get a sense of how daunting that is.

00:26:37.680 --> 00:26:40.440
So I think comparing it to air travel,

00:26:40.440 --> 00:26:43.000
or to cars and so forth is good,

00:26:43.000 --> 00:26:46.360
but we tend to focus a little bit on like,

00:26:46.360 --> 00:26:47.920
oh, it's just this part of the system,

00:26:47.920 --> 00:26:49.440
and not the system as a whole.

00:26:49.440 --> 00:26:53.680
- Well, I think the training was done a lot previously,

00:26:53.680 --> 00:26:55.440
and the usage was done less,

00:26:55.440 --> 00:26:58.200
and now the usage has just gone out of control.

00:26:58.200 --> 00:27:01.880
Like, if you don't have AI in your,

00:27:01.880 --> 00:27:04.240
I don't know, menu ordering app, it's a useless thing, right?

00:27:04.240 --> 00:27:06.720
It's like, everybody needs it.

00:27:06.720 --> 00:27:07.960
They don't really need it, I think,

00:27:07.960 --> 00:27:09.000
but they think they need it,

00:27:09.000 --> 00:27:10.920
or the VCs think they need it, or something.

00:27:10.920 --> 00:27:13.120
- I think also, like, a lot of people might think,

00:27:13.120 --> 00:27:14.640
oh, we need to train our own models,

00:27:14.640 --> 00:27:16.080
but with things like RAG,

00:27:16.080 --> 00:27:18.680
like retrieval augmentation generation,

00:27:18.680 --> 00:27:21.320
that now a lot of vector database services

00:27:21.320 --> 00:27:24.240
are promoting and educating people around how to do,

00:27:24.240 --> 00:27:25.080
that's not true.

00:27:25.080 --> 00:27:27.320
So you can take like, a base model,

00:27:27.320 --> 00:27:29.000
and start to give it your data,

00:27:29.000 --> 00:27:31.800
without the need to like, tune something yourself,

00:27:31.800 --> 00:27:33.120
like, train something yourself, sorry.

00:27:33.120 --> 00:27:34.280
- Yeah.

00:27:34.280 --> 00:27:38.760
All right, we are very, very nearly out of time here, ladies.

00:27:38.760 --> 00:27:41.000
We all have different things we gotta run off and do,

00:27:41.000 --> 00:27:43.960
but let me just close out with some quick thoughts,

00:27:43.960 --> 00:27:46.000
and really, this deserves maybe two hours,

00:27:46.000 --> 00:27:47.320
but we've got two minutes.

00:27:47.320 --> 00:27:51.080
For data scientists out there listening,

00:27:51.080 --> 00:27:54.800
who are concerned that things like Copilot,

00:27:54.800 --> 00:27:57.760
and Devon, and all these weird,

00:27:57.760 --> 00:27:59.040
I'll write code for you things,

00:27:59.040 --> 00:28:03.160
are going to make learning data science not relevant,

00:28:03.160 --> 00:28:05.240
what do you think?

00:28:05.240 --> 00:28:07.640
I think it's still gonna be super relevant, but.

00:28:07.640 --> 00:28:12.040
- I think that it's gonna help a lot.

00:28:12.040 --> 00:28:17.040
And I think that the code be seen as a potential useful tool

00:28:17.040 --> 00:28:22.560
that could help to a lot of people.

00:28:22.560 --> 00:28:24.720
It's even for beginners, for learning.

00:28:24.720 --> 00:28:27.400
I think for people who is starting to code,

00:28:27.400 --> 00:28:32.400
could be super useful to try to take a look with Copilot,

00:28:32.400 --> 00:28:35.840
or with LLMs, and say, "Hey, I don't understand the code,

00:28:35.840 --> 00:28:38.760
"can you explain to me what is happening in this function?"

00:28:38.760 --> 00:28:40.360
Or something like that.

00:28:40.400 --> 00:28:45.400
From here to be able to introduce an idea,

00:28:45.400 --> 00:28:48.960
and have a production-ready code,

00:28:48.960 --> 00:28:52.200
we are very far away, to be honest, right now.

00:28:52.200 --> 00:28:53.560
We need more work,

00:28:53.560 --> 00:28:57.560
and the field needs to improve a bit of that.

00:28:57.560 --> 00:29:01.320
But I truly believe that's gonna help us a lot

00:29:01.320 --> 00:29:02.880
at some point in time.

00:29:02.880 --> 00:29:07.760
- I think maybe I'll take a different perspective,

00:29:07.760 --> 00:29:10.320
and say that I think for data scientists,

00:29:10.320 --> 00:29:12.520
the core concern for us is not really code,

00:29:12.520 --> 00:29:14.600
it's more data, I guess.

00:29:14.600 --> 00:29:16.320
- Oh, yeah, absolutely.

00:29:16.320 --> 00:29:18.560
- So I think I'm seeing some potential,

00:29:18.560 --> 00:29:20.560
even with our own tools at JetBrains,

00:29:20.560 --> 00:29:23.680
to potentially help introduce people

00:29:23.680 --> 00:29:26.320
to the idea of how to work with data.

00:29:26.320 --> 00:29:29.400
But there's not really necessarily huge shortcuts here,

00:29:29.400 --> 00:29:31.960
because you're still going to learn how to clean a data set,

00:29:31.960 --> 00:29:33.920
and evaluate it for quality.

00:29:33.920 --> 00:29:36.640
And so, the science part of data science,

00:29:36.640 --> 00:29:39.120
I don't think it's ever gonna go away.

00:29:39.120 --> 00:29:40.920
You still need to be able to think about business problems.

00:29:40.920 --> 00:29:42.520
You still need to be able to think about data.

00:29:42.520 --> 00:29:43.720
- We'll be there forever.

00:29:43.720 --> 00:29:44.680
- It'll be there forever.

00:29:44.680 --> 00:29:46.080
Thank God, it's so good.

00:29:46.080 --> 00:29:47.400
(laughing)

00:29:47.400 --> 00:29:48.240
- That's fun, yeah.

00:29:48.240 --> 00:29:50.280
- Maybe as not a data scientist,

00:29:50.280 --> 00:29:52.480
I can give a slightly different perspective.

00:29:52.480 --> 00:29:54.960
I feel like, because it comes up

00:29:54.960 --> 00:29:58.400
just for general programming all the time as well, right?

00:29:58.400 --> 00:30:02.120
And I think one of the things that is, at the moment,

00:30:02.120 --> 00:30:03.880
most hurting our industry,

00:30:03.880 --> 00:30:07.320
is the lack of getting people into junior level jobs,

00:30:07.320 --> 00:30:10.400
and not AI or any technology itself.

00:30:10.400 --> 00:30:12.360
It's a very human problem.

00:30:12.360 --> 00:30:15.880
As are pretty much all of the problems with AI itself.

00:30:15.880 --> 00:30:18.280
So, I think, to be honest,

00:30:18.280 --> 00:30:21.720
what we need to do is really hire more juniors,

00:30:21.720 --> 00:30:24.240
make more entry level programs,

00:30:24.240 --> 00:30:25.960
and get people into these positions,

00:30:25.960 --> 00:30:28.240
and get them trained up on using the tools.

00:30:28.240 --> 00:30:30.120
We don't need to gatekeep.

00:30:30.120 --> 00:30:33.240
There's gonna be plenty of work for the rest of us,

00:30:33.240 --> 00:30:34.840
for the next foreseeable future,

00:30:34.840 --> 00:30:39.160
considering all the big social problems that we have to solve.

00:30:39.160 --> 00:30:41.160
So, I just think we should do that.

00:30:41.160 --> 00:30:45.040
- All right, well, let's leave it there.

00:30:45.040 --> 00:30:47.520
Maria, Jodie, Jessica,

00:30:47.520 --> 00:30:48.800
thank you so much for being on the show.

00:30:48.800 --> 00:30:50.480
- Thank you. - Thank you very much.

00:30:50.480 --> 00:30:51.320
It was amazing.

00:30:51.320 --> 00:30:52.160
- Bye, everyone. - Bye.

