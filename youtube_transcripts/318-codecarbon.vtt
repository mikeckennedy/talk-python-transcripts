WEBVTT

00:00:00.000 --> 00:00:07.440
>> Everyone out there in the live stream, welcome, welcome.


00:00:07.440 --> 00:00:09.400
Thank you for being here.


00:00:09.400 --> 00:00:12.800
Put your comments, thoughts, feedback into the live chat and we'll try to make it part


00:00:12.800 --> 00:00:14.640
of the show.


00:00:14.640 --> 00:00:19.680
And with that, hello Boris, Victor, Jonathan, you all ready to start the podcast?


00:00:19.680 --> 00:00:20.680
>> Yeah.


00:00:20.680 --> 00:00:21.680
>> Ready to go?


00:00:21.680 --> 00:00:23.320
>> Yeah, thanks for having us.


00:00:23.320 --> 00:00:24.320
>> All right.


00:00:24.320 --> 00:00:25.320
Cool.


00:00:25.320 --> 00:00:29.280
Boris, Victor, Jonathan, welcome to Talk Python To Me.


00:00:29.280 --> 00:00:30.280
Thanks for having us.


00:00:30.280 --> 00:00:31.280
Glad to be here.


00:00:31.280 --> 00:00:33.280
It's great to be here with you.


00:00:33.280 --> 00:00:34.280
Welcome, everyone.


00:00:34.280 --> 00:00:35.280
Yeah.


00:00:35.280 --> 00:00:39.520
Hey, you all are doing really important work, and I'm super excited to talk to you about


00:00:39.520 --> 00:00:40.520
it.


00:00:40.520 --> 00:00:46.200
So we're going to talk about machine learning, how much Carbon is being used for training


00:00:46.200 --> 00:00:50.120
machine learning models and things like that.


00:00:50.120 --> 00:00:55.000
And some cool tools you built over at CodeCarbon.io and that collaboration you got going on there.


00:00:55.000 --> 00:00:58.120
But before we get into all those sides of the stories,


00:00:58.120 --> 00:01:00.640
let's just start with yours.


00:01:00.640 --> 00:01:01.520
Jonathan, you want to go first?


00:01:01.520 --> 00:01:03.680
How'd you get into Python?


00:01:03.680 --> 00:01:05.920
- Sure, yeah, thanks for having us, Michael.


00:01:05.920 --> 00:01:06.800
My name's John Wilson.


00:01:06.800 --> 00:01:08.480
I'm an assistant, excuse me,


00:01:08.480 --> 00:01:10.160
associate professor of environmental studies


00:01:10.160 --> 00:01:11.440
at Haverford College.


00:01:11.440 --> 00:01:12.840
I'm actually an environmental scientist.


00:01:12.840 --> 00:01:14.800
So I was brought in to kind of consult


00:01:14.800 --> 00:01:17.520
from the environmental side of this project,


00:01:17.520 --> 00:01:18.800
but I have a secret history


00:01:18.800 --> 00:01:21.520
as a computer science undergraduate


00:01:21.520 --> 00:01:27.680
back in the dark ages, learning to code on C, C++, and Java.


00:01:27.680 --> 00:01:29.840
And yeah, so I was brought in to provide


00:01:29.840 --> 00:01:32.440
that environmental perspective on the project.


00:01:32.440 --> 00:01:35.140
And having a little bit of a coding background,


00:01:35.140 --> 00:01:37.920
despite how rusty it is, has been pretty helpful


00:01:37.920 --> 00:01:40.640
at thinking some of these connections


00:01:40.640 --> 00:01:43.040
through between computational issues


00:01:43.040 --> 00:01:44.400
and environmental issues.


00:01:44.400 --> 00:01:46.080
Yeah, I can imagine.


00:01:46.080 --> 00:01:49.560
Did you find Python to be pretty welcoming, given a C background


00:01:49.560 --> 00:01:50.360
and stuff?


00:01:50.360 --> 00:01:51.120
Oh, gosh, yeah.


00:01:51.120 --> 00:01:53.440
I learned back in the bad old days of,


00:01:53.440 --> 00:01:54.880
not bad old days, I shouldn't say that,


00:01:54.880 --> 00:01:57.920
Scheme, things like that, a little bit more challenging.


00:01:57.920 --> 00:02:00.080
- Yeah, that's one of the first languages I had to learn


00:02:00.080 --> 00:02:02.040
for a few CS classes I took.


00:02:02.040 --> 00:02:03.200
I was like, "We're gonna start with Scheme."


00:02:03.200 --> 00:02:05.640
I'm like, "Anything but this.


00:02:05.640 --> 00:02:07.640
"Give me something mainstream, please."


00:02:07.640 --> 00:02:12.400
- Yeah, sometimes I feel like the sort of older person


00:02:12.400 --> 00:02:15.820
telling the kids these days about how we had to walk uphill


00:02:15.820 --> 00:02:19.520
both ways in the snow to learn programming.


00:02:19.520 --> 00:02:20.920
And it's much, much easier.


00:02:20.920 --> 00:02:23.120
And one of the things I like about Python


00:02:23.120 --> 00:02:25.640
is it's really accessible to people from different fields.


00:02:25.640 --> 00:02:28.680
You get into it from aspects of natural sciences,


00:02:28.680 --> 00:02:30.680
but even people who are in the digital humanities


00:02:30.680 --> 00:02:32.800
are using it for language processing


00:02:32.800 --> 00:02:33.640
and things like that.


00:02:33.640 --> 00:02:35.520
It's super flexible, which is really neat.


00:02:35.520 --> 00:02:37.160
- Yeah, it's really impressive what people


00:02:37.160 --> 00:02:38.880
in those different fields are doing,


00:02:38.880 --> 00:02:40.600
how they can bring that in.


00:02:40.600 --> 00:02:41.440
Boris, how about yourself?


00:02:41.440 --> 00:02:43.000
How'd you get into Python?


00:02:43.000 --> 00:02:46.080
- I actually discovered Python during my master degree,


00:02:46.080 --> 00:02:49.880
and I got a math teacher that introduced us to Python


00:02:49.880 --> 00:02:54.760
because he used Python for his own thesis.


00:02:54.760 --> 00:02:59.660
And I had one stuff to do,


00:02:59.660 --> 00:03:01.520
which was implementing RSA encryption,


00:03:01.520 --> 00:03:06.080
and I didn't want to do it because math was not my forte.


00:03:06.080 --> 00:03:11.080
So instead I did some encryption inside images in Python,


00:03:11.080 --> 00:03:13.880
and I fell in love with Python.


00:03:13.880 --> 00:03:15.480
- Wow, fantastic.


00:03:15.480 --> 00:03:16.320
Victor.


00:03:16.320 --> 00:03:21.200
- I discovered this taking a data science class


00:03:21.200 --> 00:03:23.040
in, when was that?


00:03:23.040 --> 00:03:25.360
2014, I think it was.


00:03:25.360 --> 00:03:27.840
So that's really, I really entered Python


00:03:27.840 --> 00:03:31.440
through the data science perspective.


00:03:31.440 --> 00:03:35.400
And then I took a course in general web development


00:03:35.400 --> 00:03:37.440
and we used Django.


00:03:37.440 --> 00:03:38.720
- Oh, right, nice.


00:03:38.720 --> 00:03:40.560
- And so it's been, yeah, so it's been really like


00:03:40.560 --> 00:03:42.620
the main language I've been using.


00:03:43.800 --> 00:03:47.840
I was taught CS with Java and so on.


00:03:47.840 --> 00:03:52.840
So I was never a computer science fan.


00:03:52.840 --> 00:03:58.940
I liked math and I found Python to be really flexible


00:03:58.940 --> 00:03:59.800
in that regard.


00:03:59.800 --> 00:04:01.280
You can do math super easily


00:04:01.280 --> 00:04:03.220
without getting lost in translation.


00:04:03.220 --> 00:04:06.000
- Yeah, one of the things that just came out


00:04:06.000 --> 00:04:10.160
is one of the new Texas instruments, the TI-84 calculator.


00:04:10.160 --> 00:04:13.200
They have a, you can now program it with Python.


00:04:13.200 --> 00:04:16.200
So that's kind of interesting now that it's one of the old,


00:04:16.200 --> 00:04:21.080
the old calculators that everyone's probably used


00:04:21.080 --> 00:04:23.560
going through math and whatnot is now sort of,


00:04:23.560 --> 00:04:26.000
you know, more in the modern space.


00:04:26.000 --> 00:04:26.840
- Yeah. - Yeah.


00:04:26.840 --> 00:04:29.560
- I have a friend who, sorry, go ahead Boris.


00:04:29.560 --> 00:04:32.280
- I think my first program was on my TI


00:04:32.280 --> 00:04:37.480
because I was bored in math course and I cannot follow.


00:04:37.480 --> 00:04:39.360
So instead I wrote some programs.


00:04:40.360 --> 00:04:44.100
- Yeah, that's not a terrible way to spend your time.


00:04:44.100 --> 00:04:48.360
All right, so yeah, let's go ahead and talk about


00:04:48.360 --> 00:04:50.580
the main, get to the main subject here.


00:04:50.580 --> 00:04:54.800
So let's start by just setting the stage.


00:04:54.800 --> 00:04:58.260
There's an interesting article here that came out,


00:04:58.260 --> 00:05:01.220
this is not even that new, it's 2019,


00:05:01.220 --> 00:05:03.500
and it's in the MIT Technology Review.


00:05:03.500 --> 00:05:06.940
So that gives it probably a little more


00:05:06.940 --> 00:05:09.140
than just some random blog says this,


00:05:09.140 --> 00:05:11.820
And it's got a big picture of a data center.


00:05:11.820 --> 00:05:15.780
And the title of the article by Karen Ho is,


00:05:15.780 --> 00:05:20.140
"Training a single AI model can emit as much carbon


00:05:20.140 --> 00:05:22.860
as five cars throughout their lifetime."


00:05:22.860 --> 00:05:25.540
So that sounds pretty horrible,


00:05:25.540 --> 00:05:28.820
but we also know that machine learning


00:05:28.820 --> 00:05:31.040
has a lot of value to society,


00:05:31.040 --> 00:05:33.900
a lot of important things that it can do.


00:05:33.900 --> 00:05:35.660
So here's where we are,


00:05:35.660 --> 00:05:37.500
and this seems like a good place


00:05:37.500 --> 00:05:40.780
to start the conversation for what you all are doing.


00:05:40.780 --> 00:05:43.580
- I think one of the,


00:05:43.580 --> 00:05:46.940
I have a mixed feeling about this article.


00:05:46.940 --> 00:05:49.140
I think one of the great things it did is


00:05:49.140 --> 00:05:53.980
raise a lot of attention and awareness about this topic.


00:05:53.980 --> 00:05:57.740
I think a lot of approximations were made


00:05:57.740 --> 00:06:01.980
and it was not, the goal here is not to criticize authors,


00:06:01.980 --> 00:06:05.700
but rather to say that in the meantime,


00:06:05.700 --> 00:06:12.220
things have evolved and our understanding has, I think, been a little more precise.


00:06:12.220 --> 00:06:17.260
Also because people are building tools that measure it, instead of estimate.


00:06:17.260 --> 00:06:22.860
So there's that, definitely. And we hope that helps. But it's also like one of the things


00:06:22.860 --> 00:06:28.380
you need to put in perspective is that the kind of model they're looking at is not necessarily


00:06:28.380 --> 00:06:33.580
your everyday model. Someone can just train on their local computer or even like, even


00:06:33.580 --> 00:06:41.580
Even in academia, it's hard to get your hands on such large clusters and the number of GPUs


00:06:41.580 --> 00:06:42.580
used and so on.


00:06:42.580 --> 00:06:48.900
So I just want to put that in perspective that even if those numbers were accurate,


00:06:48.900 --> 00:06:53.720
and they are not, but I mean, it's a ballpark.


00:06:53.720 --> 00:06:58.580
It's not like every data scientist you'll meet and every AI researcher you'll meet is


00:06:58.580 --> 00:07:05.620
is going to have something in that level of complexity


00:07:05.620 --> 00:07:07.860
that they train every day.


00:07:07.860 --> 00:07:11.820
>>I have over here a sim racing setup for some sim racing I do.


00:07:11.820 --> 00:07:16.500
And it has a GeForce 2070 in it.


00:07:16.500 --> 00:07:18.580
It would have to run a very long time


00:07:18.580 --> 00:07:21.060
to emit this much carbon, right?


00:07:21.060 --> 00:07:24.420
You've got to have the necessary money and compute resources


00:07:24.420 --> 00:07:28.100
to even get there, right?


00:07:28.100 --> 00:07:36.060
Yeah. I don't remember exactly the setup that they're looking at in this paper, but typically


00:07:36.060 --> 00:07:44.620
the modern language models that you hear about, like, "Oh, OpenAI has a new NLP model and


00:07:44.620 --> 00:07:50.020
like GPT-3, and it's that number of billion of parameters." They train those things on


00:07:50.020 --> 00:07:54.740
hundreds and hundreds of machines for a very long time. This is not something we can do


00:07:54.740 --> 00:07:59.380
it costs millions of dollars in investment up front.


00:07:59.380 --> 00:08:02.660
And then just using those things is super expensive.


00:08:02.660 --> 00:08:06.500
So while I think we should be careful,


00:08:06.500 --> 00:08:08.660
it's not like the whole field is like that.


00:08:08.660 --> 00:08:09.620
- Yeah, that's a good point.


00:08:09.620 --> 00:08:10.580
That's a very good point.


00:08:10.580 --> 00:08:13.140
I recall there was some cancer research


00:08:13.140 --> 00:08:14.820
that needed to answer some big problem.


00:08:14.820 --> 00:08:18.180
And there was an article where they spun up


00:08:18.180 --> 00:08:20.900
something like 6,000 virtual machines


00:08:20.900 --> 00:08:23.700
across AWS clusters for an hour


00:08:23.700 --> 00:08:27.340
and had it go crazy to answer some protein folding question


00:08:27.340 --> 00:08:29.380
or something like that.


00:08:29.380 --> 00:08:32.580
That would use a lot of energy, but it's extremely, extremely


00:08:32.580 --> 00:08:34.140
rare as well.


00:08:34.140 --> 00:08:36.580
On the other hand, if you create that model


00:08:36.580 --> 00:08:39.900
and it solves cancer, well, people


00:08:39.900 --> 00:08:41.940
drive cars all the time for less valuable reasons


00:08:41.940 --> 00:08:45.180
than curing cancer.


00:08:45.180 --> 00:08:47.620
Yeah, I think just to build on what Victor said,


00:08:47.620 --> 00:08:49.460
I think there was something really valuable


00:08:49.460 --> 00:08:51.340
about this article coming out.


00:08:51.340 --> 00:08:56.340
I think for a long time, there's been attention that's been paid to the sort of environmental


00:08:56.340 --> 00:08:58.820
toll of supply chains in computing.


00:08:58.820 --> 00:09:03.540
People have talked a lot about where minerals come from.


00:09:03.540 --> 00:09:07.100
And I think one of the things that was really interesting about this article was with the


00:09:07.100 --> 00:09:11.740
approximations, it got people thinking about the question that kind of animates our collaboration,


00:09:11.740 --> 00:09:17.420
which is when you're doing any kind of energy intensive computational issue, you might want


00:09:17.420 --> 00:09:20.380
to think about where your electrons come from.


00:09:20.380 --> 00:09:23.780
actually powering the hardware that you're using to do this.


00:09:23.780 --> 00:09:26.820
And I think this article did a really nice job of focusing


00:09:26.820 --> 00:09:29.100
attention that there are some really energy intensive


00:09:29.100 --> 00:09:32.660
projects that, in particular ways,


00:09:32.660 --> 00:09:35.260
if they're located in particular locations,


00:09:35.260 --> 00:09:37.860
they can have a really large environmental cost that


00:09:37.860 --> 00:09:40.060
isn't really transparent to the user,


00:09:40.060 --> 00:09:41.500
for the person training the model.


00:09:41.500 --> 00:09:42.000
Yeah.


00:09:42.000 --> 00:09:44.260
Well, I don't want to go down this road just yet.


00:09:44.260 --> 00:09:46.840
I want to keep talking about the more high level a little bit.


00:09:46.840 --> 00:09:51.000
But if the people who did this very expensive model,


00:09:51.000 --> 00:09:51.840
if they just said,


00:09:51.840 --> 00:09:55.140
"I'm gonna pick the closest AWS data center to me,"


00:09:55.140 --> 00:09:56.580
that rather than,


00:09:56.580 --> 00:10:01.580
"Let me find the data center by just flipping a switch


00:10:01.580 --> 00:10:05.700
"and say, no, no, maybe the one up in Prinville, Oregon


00:10:05.700 --> 00:10:07.520
"by the dam would be better than the one


00:10:07.520 --> 00:10:10.620
"by the coal factory," for example, right?


00:10:10.620 --> 00:10:12.260
Like that's something they could easily do


00:10:12.260 --> 00:10:14.860
and it maybe doesn't change anything for them, right?


00:10:15.780 --> 00:10:19.140
It's not always the case, because when you have, for example, health data and so on,


00:10:19.140 --> 00:10:27.420
like there are legislations, but definitely like if you can, like, and there's more than


00:10:27.420 --> 00:10:33.340
just the money at stake here, and it's probably going to be a marginal change because the


00:10:33.340 --> 00:10:37.580
prices tend to be not equal, but kind of uniform still.


00:10:37.580 --> 00:10:40.260
I think it's another decision item.


00:10:40.260 --> 00:10:41.260
Yeah.


00:10:41.260 --> 00:10:44.860
Boris, you got any thoughts on this article before we move on?


00:10:44.860 --> 00:10:54.940
Yeah, I think it came with a good to highlight a serious issue and if people want to improve it,


00:10:54.940 --> 00:11:01.900
as most of my manager told me, if you want to improve it you must measure it before. So we are


00:11:01.900 --> 00:11:11.820
there to give a start of an answer to and give them action how to improve the cut carbon emission


00:11:11.820 --> 00:11:17.580
on training models. Hopefully to not train less models but train better models.


00:11:17.580 --> 00:11:24.140
Yeah, so one thing... Yeah, go ahead. Yeah, just one little thing. It's an IBM maybe


00:11:24.140 --> 00:11:29.580
caricaturing, but I think the intent is the same. I think, for example, this is part of what


00:11:29.580 --> 00:11:38.300
the recent Google paper about... led by David Patterson on training neural networks and their


00:11:38.300 --> 00:11:45.260
environmental impact. This is one of the things they say. It's quite a dense paper and a lot of


00:11:45.260 --> 00:11:49.580
metrics and so on. But one of the things they say is like, if you don't want people caricaturing


00:11:49.580 --> 00:11:54.540
your numbers and putting approximations out there, well, you'd better publish those numbers yourself.


00:11:54.540 --> 00:12:02.300
Right? And you need tools to do that. So if you're Google or if you're close to the


00:12:02.300 --> 00:12:07.740
infrastructure that you use, it's easier. It's even better if you have access to the plugs.


00:12:07.740 --> 00:12:11.740
But that's not the case of everyone, right?


00:12:11.740 --> 00:12:15.740
Right. So you're saying if you could put something to actually measure


00:12:15.740 --> 00:12:19.740
the electricity going through the wire instead of


00:12:19.740 --> 00:12:23.740
some approximation, you're in a better place to know the answer.


00:12:23.740 --> 00:12:27.740
Definitely. That's where I think, and we might be


00:12:27.740 --> 00:12:31.740
a little ahead of your schedule, but we might get there still.


00:12:31.740 --> 00:12:35.740
That's where Carbon comes into play. This is why we


00:12:35.740 --> 00:12:42.040
we want to create this tool. This is a user-facing product. And I think it's very important to


00:12:42.040 --> 00:12:50.240
highlight that. It is not intended to be the solution for a data center. This is not something


00:12:50.240 --> 00:12:56.960
that we think should be deployed as a cloud provider or if you own your own infrastructure.


00:12:56.960 --> 00:13:02.560
If you want to have centralized number, there are alternatives out there. Things like Scaphandre.


00:13:02.560 --> 00:13:05.200
on a scaphander, I don't know how you say that,


00:13:05.200 --> 00:13:06.600
it's a French word, anyway.


00:13:06.600 --> 00:13:08.160
It's out there on GitHub, you can find it


00:13:08.160 --> 00:13:10.040
by just looking this way, but like,


00:13:10.040 --> 00:13:11.440
the role here is like, as a user,


00:13:11.440 --> 00:13:13.880
what can you do if you don't have those numbers?


00:13:13.880 --> 00:13:14.840
- Right. - Do you do nothing,


00:13:14.840 --> 00:13:18.040
or do you try to have, to at least have the start


00:13:18.040 --> 00:13:22.480
of an estimation, and maybe start the conversation


00:13:22.480 --> 00:13:25.960
with your organization or your provider?


00:13:25.960 --> 00:13:28.240
- Yeah, fantastic, and you guys are putting


00:13:28.240 --> 00:13:29.600
some really concrete things out there


00:13:29.600 --> 00:13:31.080
for Python developers.


00:13:31.080 --> 00:13:33.640
Two quick high-level comments.


00:13:33.640 --> 00:13:36.120
One, Corey Adkins from the live stream says,


00:13:36.120 --> 00:13:39.400
"Would it be the same or worse for quantum computers?"


00:13:39.400 --> 00:13:45.040
- Okay, I'm gonna talk out of my depth here.


00:13:45.040 --> 00:13:50.040
So the first, like the best and second use, I don't know.


00:13:50.040 --> 00:13:54.400
And then to go beyond that,


00:13:54.400 --> 00:13:56.520
like my understanding of computers


00:13:56.520 --> 00:13:57.680
is that they do very different things


00:13:57.680 --> 00:14:04.960
you can't just compare the computations made on classical computers with the things quantum


00:14:04.960 --> 00:14:11.120
computers are intended for. I think intrinsically because of the state of that technology, it


00:14:11.120 --> 00:14:16.640
is extremely energy intensive, just because you usually have to pull things down to a


00:14:16.640 --> 00:14:26.240
few millikelvins or something like that. So that may be transitory. I'm not sure. I don't


00:14:26.240 --> 00:14:27.080
I don't want to talk too much about that.


00:14:27.080 --> 00:14:29.360
- I don't know about that either.


00:14:29.360 --> 00:14:30.840
Yeah, I was thinking the same thing.


00:14:30.840 --> 00:14:33.720
Just yesterday, Google had Google I/O


00:14:33.720 --> 00:14:38.100
and they talked about building clusters


00:14:38.100 --> 00:14:41.400
of qubit sort of supercomputer type things.


00:14:41.400 --> 00:14:45.360
And apparently they've got to cool it down so much


00:14:45.360 --> 00:14:47.440
that it's some of the coldest places


00:14:47.440 --> 00:14:49.380
in the universe inside those.


00:14:49.380 --> 00:14:50.220
So on one hand,


00:14:50.220 --> 00:14:52.640
if quantum computers can do the math super quick,


00:14:52.640 --> 00:14:54.500
it doesn't take a lot of time to run them


00:14:54.500 --> 00:14:55.340
to get the answer.


00:14:55.340 --> 00:14:56.160
But on the other,


00:14:56.160 --> 00:14:58.960
you've got to keep them that cold, that can't be free.


00:14:58.960 --> 00:15:02.680
- But it's a very critical kind of map, right?


00:15:02.680 --> 00:15:06.040
And not all problems are translatable


00:15:06.040 --> 00:15:08.400
from the classical formulation


00:15:08.400 --> 00:15:10.560
to a quantum compatible formulation.


00:15:10.560 --> 00:15:13.960
And I think, I'm not sure,


00:15:13.960 --> 00:15:17.280
I think there are problems that we can solve easily


00:15:17.280 --> 00:15:19.600
on our classical computers that would be very hard,


00:15:19.600 --> 00:15:23.600
if not theoretically impossible to run on quantum computers.


00:15:23.600 --> 00:15:25.920
And it's like, it's a different tool


00:15:25.920 --> 00:15:28.880
and it's not intended for the same problems.


00:15:28.880 --> 00:15:31.600
So I think it's hard to compare.


00:15:31.600 --> 00:15:32.440
- Yeah.


00:15:32.440 --> 00:15:34.720
Makes sense.


00:15:34.720 --> 00:15:38.280
- I would even say that you will still have some parts


00:15:38.280 --> 00:15:43.280
of the model training that won't run on quantum computers


00:15:43.280 --> 00:15:44.680
because that doesn't make sense,


00:15:44.680 --> 00:15:47.160
like preprocessing data, getting data


00:15:47.160 --> 00:15:49.680
from a different data source,


00:15:49.680 --> 00:15:53.360
mapping them to a common format, exporting your model,


00:15:53.360 --> 00:15:55.760
creating Docker images, servers,


00:15:55.760 --> 00:16:00.120
that there will still be part of the model training process


00:16:00.120 --> 00:16:04.300
that won't run on those quantum computers.


00:16:04.300 --> 00:16:05.860
- Yeah.


00:16:05.860 --> 00:16:08.640
Another thing I think is worth pointing out


00:16:08.640 --> 00:16:12.240
is it's the training of the models that is expensive,


00:16:12.240 --> 00:16:15.520
but to use them to get an answer, it's pretty quick, right?


00:16:15.520 --> 00:16:18.240
That's pretty low cost.


00:16:18.240 --> 00:16:20.480
- It depends on what you're using it for, right?


00:16:20.480 --> 00:16:28.400
So if you have a user-facing model that's going to serve thousands of requests per second,


00:16:28.400 --> 00:16:34.600
then deploying it for a year might be more energy-intensive than training it for three


00:16:34.600 --> 00:16:35.600
days.


00:16:35.600 --> 00:16:39.160
We all know the machine learning lifecycle is not just like you train one model and you


00:16:39.160 --> 00:16:41.360
succeed and, well, hooray, right?


00:16:41.360 --> 00:16:46.120
You usually have a lot of iterations, building the models, looking for hyperparameters and


00:16:46.120 --> 00:16:53.580
But even if that takes six months and your model stays online for months or years and


00:16:53.580 --> 00:16:56.800
serving thousands of people, it's not obvious.


00:16:56.800 --> 00:16:58.800
It might even be worse.


00:16:58.800 --> 00:17:03.280
Not worse, more energy intensive to infer.


00:17:03.280 --> 00:17:07.320
Yeah, I guess it depends how many times you run it.


00:17:07.320 --> 00:17:15.480
Another thought, there's a lot of places creating models, like you talked about, was it GPT-3?


00:17:15.480 --> 00:17:19.760
and whatnot that are training the models


00:17:19.760 --> 00:17:21.640
and letting people use them.


00:17:21.640 --> 00:17:24.680
Do you see that as a thing that might be useful


00:17:24.680 --> 00:17:28.080
and helpful as having these pre-created pre-trained models?


00:17:28.080 --> 00:17:30.600
Like I know Microsoft has a bunch of pre-trained models


00:17:30.600 --> 00:17:31.960
with their cognitive services


00:17:31.960 --> 00:17:35.680
and Apple has their ML stuff like baked into their devices


00:17:35.680 --> 00:17:38.000
that you don't have to train, you can just use.


00:17:38.000 --> 00:17:42.240
Are the problems being solved


00:17:42.240 --> 00:17:44.200
and the data being understood usually too general


00:17:44.200 --> 00:17:48.920
Or is that something we can make use of?


00:17:48.920 --> 00:17:53.920
- I think pre-trained models as the advantage to keep,


00:17:53.920 --> 00:17:56.280
as you are training a model once,


00:17:56.280 --> 00:18:01.280
the cost emission of the model during training


00:18:01.280 --> 00:18:03.920
is amortized for each usage.


00:18:03.920 --> 00:18:06.360
So more user you have,


00:18:06.360 --> 00:18:10.720
the more the part of the training emission is low.


00:18:11.760 --> 00:18:15.420
But usually, you still have to tune the model a bit,


00:18:15.420 --> 00:18:17.740
so you still have to train it,


00:18:17.740 --> 00:18:22.300
and you're using energy even for prediction.


00:18:22.300 --> 00:18:25.580
So yes, and no.


00:18:25.580 --> 00:18:28.740
I'm going to also do the transition to throw the ball


00:18:28.740 --> 00:18:31.820
to Jonathan for something I think we shouldn't forget


00:18:31.820 --> 00:18:33.900
when we talk about these gains in efficiency,


00:18:33.900 --> 00:18:37.580
which is the Jevons paradox and the fact


00:18:37.580 --> 00:18:41.220
that if you create something that is cheaper to use


00:18:41.220 --> 00:18:47.460
and more people use it, then the overall impact is it lower.


00:18:47.460 --> 00:18:49.980
And I think this is something we tend to forget when we talk


00:18:49.980 --> 00:18:52.700
about massive improvements-- or not even massive,


00:18:52.700 --> 00:18:55.660
just like this is something that is, I think,


00:18:55.660 --> 00:18:58.340
hard to grasp and anticipate when


00:18:58.340 --> 00:19:00.620
you think about technological advances


00:19:00.620 --> 00:19:02.740
under the constraint of climate change.


00:19:02.740 --> 00:19:06.940
But this rebound effect, I think,


00:19:06.940 --> 00:19:11.100
is something we should plan for and not just think, well,


00:19:11.100 --> 00:19:15.460
If you have cheaper models, but more people can use them,


00:19:15.460 --> 00:19:18.740
I think it's not that obvious that it's an overall gain


00:19:18.740 --> 00:19:19.780
in terms of energy.


00:19:19.780 --> 00:19:23.220
Then you can talk about all the societal consequences


00:19:23.220 --> 00:19:26.820
and the advances in cancer research, for instance.


00:19:26.820 --> 00:19:32.020
But I think it's really hard to have a definitive answer.


00:19:32.020 --> 00:19:34.700
Yeah, just to build on what Victor said,


00:19:34.700 --> 00:19:35.860
it really is a difficult--


00:19:35.860 --> 00:19:38.380
this is a classic environmental conundrum, right?


00:19:38.380 --> 00:19:40.820
when you, you know, the classic example


00:19:40.820 --> 00:19:42.820
of the Jevons paradox is, you know,


00:19:42.820 --> 00:19:45.960
adding more roads leads to more traffic


00:19:45.960 --> 00:19:47.900
because more people believe that there's more space


00:19:47.900 --> 00:19:48.860
for them to drive.


00:19:48.860 --> 00:19:50.660
And so you've seen this over and over again


00:19:50.660 --> 00:19:51.960
in all sorts of different contexts


00:19:51.960 --> 00:19:53.580
that when you build these tools,


00:19:53.580 --> 00:19:58.580
more people will use them and that can end up costing more


00:19:58.580 --> 00:20:00.180
than not building them in the first place.


00:20:00.180 --> 00:20:02.780
So I think this is something to really be aware of,


00:20:02.780 --> 00:20:05.740
you know, as we're sort of democratizing


00:20:05.740 --> 00:20:07.260
these kinds of tools.


00:20:07.260 --> 00:20:12.860
there's a real pro here, there's some real strengths of having these tools easily accessible


00:20:12.860 --> 00:20:19.020
and that can be used. But one has to worry about the potential costs of having


00:20:19.020 --> 00:20:24.940
all these tools being employed, in particular being employed in all sorts of different


00:20:24.940 --> 00:20:31.740
kind of sub-energy grids around the world. Not all grids are connected up to solar panels.


00:20:31.740 --> 00:20:38.180
You know many are connected, you know to coal-fired power plants and yeah, we cannot wait. It's not it's not today. Is it?


00:20:38.180 --> 00:20:41.120
Yeah, not yet. Not yet one would hope but


00:20:41.120 --> 00:20:43.180
maybe soon


00:20:43.180 --> 00:20:45.480
when I thought about pre-trained model is


00:20:45.480 --> 00:20:51.140
Usually they they are trained for more diverse usage. So I


00:20:51.140 --> 00:20:55.720
Would think that they tend to be larger than model train


00:20:56.640 --> 00:20:59.460
especially for a single usage inside a single company


00:20:59.460 --> 00:21:01.480
with a single type of data.


00:21:01.480 --> 00:21:03.880
So I would say they are likely bigger,


00:21:03.880 --> 00:21:07.920
so they use more energy to train and to use,


00:21:07.920 --> 00:21:10.280
but by how much, I couldn't say.


00:21:10.280 --> 00:21:13.760
- Yeah, well, I think the paradox


00:21:13.760 --> 00:21:15.320
that you all are speaking about,


00:21:15.320 --> 00:21:17.160
one of the ways we could see that is


00:21:17.160 --> 00:21:20.560
just the ability to use machine learning


00:21:20.560 --> 00:21:22.620
to solve problems is so much easier now


00:21:22.620 --> 00:21:26.580
that what used to be a simple if else runs in a microsecond,


00:21:26.580 --> 00:21:31.580
is now a much more complicated part of your program.


00:21:31.580 --> 00:21:33.260
And so, yeah, there's gotta be


00:21:33.260 --> 00:21:35.140
just a raising of the cost there.


00:21:35.140 --> 00:21:39.620
Now, before we make it all sound like machine learning bad


00:21:39.620 --> 00:21:42.120
for the environment 100%, there are good things.


00:21:42.120 --> 00:21:45.940
Like I said, Google I/O was yesterday


00:21:45.940 --> 00:21:49.420
and they were talking about doing the navigation


00:21:49.420 --> 00:21:53.220
so that taking into account things like topography,


00:21:53.220 --> 00:22:00.100
speed and whatnot to actually try to optimize, minimize gas consumption with the directions


00:22:00.100 --> 00:22:06.100
they give you. And if they could do that with a little bit of computer code to save a ton of


00:22:06.100 --> 00:22:14.260
CO2 out of cars, that's a really big win for ML. Definitely. And I think the reason why we're,


00:22:14.260 --> 00:22:21.620
like, we have started with the online carbon emissions on our side at Mila in Montreal,


00:22:21.620 --> 00:22:26.620
and Jonathan and colleagues at Harvard with energy usage.


00:22:26.620 --> 00:22:28.700
And then we came together for food government.


00:22:28.700 --> 00:22:32.960
It's not to say that machine learning is bad,


00:22:32.960 --> 00:22:36.140
like just as most technologies,


00:22:36.140 --> 00:22:38.660
it's technology and it depends on how you use it.


00:22:38.660 --> 00:22:42.180
But where we're going as societies


00:22:42.180 --> 00:22:44.080
under the constraint of climate change


00:22:44.080 --> 00:22:48.420
can't leave any field out of questioning themselves


00:22:48.420 --> 00:22:50.180
of how they use their resources.


00:22:51.060 --> 00:22:55.120
So it's something you can't leave out of the picture,


00:22:55.120 --> 00:22:57.720
which doesn't mean that you can't use it.


00:22:57.720 --> 00:22:59.240
It's like, you have to think about it.


00:22:59.240 --> 00:23:02.880
And we can't have a single rule for everyone.


00:23:02.880 --> 00:23:04.720
It's just, you have to take that into account,


00:23:04.720 --> 00:23:08.200
and you can very well make the decision that it is worth it.


00:23:08.200 --> 00:23:09.760
And in many cases, it will be.


00:23:09.760 --> 00:23:12.480
Sometimes, maybe not.


00:23:12.480 --> 00:23:14.440
- Be conscious of it, yeah, for sure.


00:23:14.440 --> 00:23:18.240
All right, so I think that brings us to your project,


00:23:18.240 --> 00:23:19.640
CodeCarbon.


00:23:19.640 --> 00:23:21.280
You mentioned it a couple of times.


00:23:21.280 --> 00:23:24.760
So looking in from the outside,


00:23:24.760 --> 00:23:26.920
it seems to me like the primary thing


00:23:26.920 --> 00:23:28.320
that what you guys have done


00:23:28.320 --> 00:23:31.000
is you've built some Python libraries,


00:23:31.000 --> 00:23:34.520
a Python package that lets you answer these questions


00:23:34.520 --> 00:23:35.820
and track these things, right?


00:23:35.820 --> 00:23:39.300
And then a dashboard and data that will help you improve it.


00:23:39.300 --> 00:23:41.400
Is that a good elevator pitch?


00:23:41.400 --> 00:23:43.120
- Very good.


00:23:43.120 --> 00:23:45.080
- Fantastic.


00:23:45.080 --> 00:23:46.960
All right, so tell us about Carbon.


00:23:46.960 --> 00:23:47.800
- Yeah, sure.


00:23:48.640 --> 00:23:51.000
- We don't have any money though.


00:23:51.000 --> 00:23:52.320
- Oh, good.


00:23:52.320 --> 00:23:54.560
Yeah, but I think it's a great cause.


00:23:54.560 --> 00:23:57.500
And so tell us, tell everyone about it.


00:23:57.500 --> 00:24:00.400
- Thank you for the opportunity.


00:24:00.400 --> 00:24:05.000
I think one of the reasons we came together was like,


00:24:05.000 --> 00:24:07.740
we all know that in the machine learning life cycle,


00:24:07.740 --> 00:24:10.720
a lot of the computations you just forget about


00:24:10.720 --> 00:24:12.960
because there are so many experiments that you run.


00:24:12.960 --> 00:24:14.320
Like say you have a project


00:24:15.640 --> 00:24:20.040
and you're gonna work on it for like three, six, 12 months,


00:24:20.040 --> 00:24:21.180
how many experiments are you gonna run?


00:24:21.180 --> 00:24:23.720
How many hyperparameter searches are you gonna run?


00:24:23.720 --> 00:24:27.760
It's a very important problem.


00:24:27.760 --> 00:24:29.840
I think this is also something that is central


00:24:29.840 --> 00:24:34.600
to Comet.ml, which is the company where Boris works


00:24:34.600 --> 00:24:37.440
and they manage experiments.


00:24:37.440 --> 00:24:40.840
And I use that in my daily work.


00:24:40.840 --> 00:24:42.720
And I thought, well, we need something similar


00:24:42.720 --> 00:24:43.920
to track the carbon impact.


00:24:43.920 --> 00:24:46.320
It can't just be about the metrics.


00:24:46.320 --> 00:24:49.000
It can't just be about the images you generate


00:24:49.000 --> 00:24:51.200
because you're training a GAN, for instance.


00:24:51.200 --> 00:24:55.840
So how do we go about this?


00:24:55.840 --> 00:25:00.000
And well, because Python was,


00:25:00.000 --> 00:25:05.880
is I think the go-to language for AI research


00:25:05.880 --> 00:25:07.360
and development also,


00:25:07.360 --> 00:25:09.560
although in very optimized settings,


00:25:09.560 --> 00:25:10.640
you might want to go away from that.


00:25:10.640 --> 00:25:14.480
But we thought, well, we need to do something


00:25:14.480 --> 00:25:16.480
that is gonna be plug and play.


00:25:16.480 --> 00:25:17.800
So it has to be Python.


00:25:17.800 --> 00:25:21.080
It has to run in the background.


00:25:21.080 --> 00:25:22.800
It has to be light.


00:25:22.800 --> 00:25:27.800
And it has to be also something that is versatile


00:25:27.800 --> 00:25:32.800
in that it is not only about your just getting


00:25:32.800 --> 00:25:35.160
yet another metric, but it's also about understanding


00:25:35.160 --> 00:25:35.980
what it means.


00:25:35.980 --> 00:25:38.400
It's about also education.


00:25:38.400 --> 00:25:39.660
It's about education for yourself,


00:25:39.660 --> 00:25:43.340
but also maybe for other members of your organization.


00:25:43.340 --> 00:25:47.660
The people who might say, like, say you work in a company


00:25:47.660 --> 00:25:51.300
and you're thinking, well, I have hundreds of data scientists.


00:25:51.300 --> 00:25:54.740
Like, this is not marginal.


00:25:54.740 --> 00:25:56.300
I want to have an estimation.


00:25:56.300 --> 00:25:58.260
And if estimations are not good enough for you,


00:25:58.260 --> 00:25:59.420
well, contact your provider.


00:25:59.420 --> 00:26:02.620
And maybe you have a wattmeter plugged in somewhere


00:26:02.620 --> 00:26:04.140
where it matters.


00:26:04.140 --> 00:26:06.100
It's not my expertise.


00:26:06.100 --> 00:26:07.500
That's basically the idea.


00:26:07.500 --> 00:26:10.720
- Yeah, yeah, plug it in a wattmeter somewhere.


00:26:10.720 --> 00:26:13.900
That used to be a thing that you could do,


00:26:13.900 --> 00:26:18.900
but now it's Amazon or Azure or Linode or whoever,


00:26:18.900 --> 00:26:23.460
they're not gonna let you go plug it into their data center.


00:26:23.460 --> 00:26:24.660
And if you did, there's probably a bunch


00:26:24.660 --> 00:26:26.500
of other things happening there, right?


00:26:26.500 --> 00:26:28.840
Direct access to the compute resources


00:26:28.840 --> 00:26:30.960
is just hard to come by.


00:26:30.960 --> 00:26:32.820
- Yep.


00:26:32.820 --> 00:26:34.500
- Exactly.


00:26:34.500 --> 00:26:36.500
This is a very big constraint for us, right?


00:26:36.500 --> 00:26:38.060
This is-- and we're going to--


00:26:38.060 --> 00:26:40.300
I think I expect we'll get into a little more details


00:26:40.300 --> 00:26:40.800
about that.


00:26:40.800 --> 00:26:44.480
But this is why you need to understand


00:26:44.480 --> 00:26:48.460
cut carbon as a tool to estimate things and have approximations.


00:26:48.460 --> 00:26:49.660
And we use heuristics.


00:26:49.660 --> 00:26:55.620
And basically, if a consultant is


00:26:55.620 --> 00:26:57.220
having you pay for carbon offsets


00:26:57.220 --> 00:27:00.200
based on those kinds of numbers, you shouldn't pay.


00:27:00.200 --> 00:27:01.940
Because that's not the point.


00:27:01.940 --> 00:27:03.420
Yeah.


00:27:03.420 --> 00:27:06.120
- Yeah, it's really about giving you the information.


00:27:06.120 --> 00:27:08.500
One of the things I like about what you're doing


00:27:08.500 --> 00:27:11.320
is you can recommend other areas,


00:27:11.320 --> 00:27:12.540
like we talked about,


00:27:12.540 --> 00:27:14.180
like you could switch to this data center


00:27:14.180 --> 00:27:16.280
and then it would have this impact, right?


00:27:16.280 --> 00:27:19.700
- Yeah, I think it's part of the educational mission.


00:27:19.700 --> 00:27:24.700
It's like, we all know, or at least I wish we all knew,


00:27:24.700 --> 00:27:27.460
or we want everyone to know, I don't know how to put that,


00:27:27.460 --> 00:27:31.500
but that it's, climate change is a very serious threat


00:27:31.500 --> 00:27:36.500
And being conscious about your energy usage


00:27:36.500 --> 00:27:41.100
and your consumption of resources in general


00:27:41.100 --> 00:27:42.760
is one thing, it's very important,


00:27:42.760 --> 00:27:46.100
but then I think you consciously leave people


00:27:46.100 --> 00:27:48.100
out there with that feeling of guilt


00:27:48.100 --> 00:27:50.220
and there has to be actionable items.


00:27:50.220 --> 00:27:54.700
So changing your region is probably


00:27:54.700 --> 00:27:55.860
the easiest thing you can do,


00:27:55.860 --> 00:27:58.340
especially in the age of the cloud


00:27:58.340 --> 00:28:02.820
and at a time when basically moving your data


00:28:02.820 --> 00:28:07.380
across continents is about ticking a few checkboxes


00:28:07.380 --> 00:28:09.140
on a web interface, right?


00:28:09.140 --> 00:28:09.980
So--


00:28:09.980 --> 00:28:10.800
- Yeah.


00:28:10.800 --> 00:28:14.220
- What do you think, just to pick up a little bit


00:28:14.220 --> 00:28:19.220
on what Victor said here, is that this is a,


00:28:19.220 --> 00:28:21.580
the educational part of this is a very important part


00:28:21.580 --> 00:28:24.500
of the CodeCarbon project because we know


00:28:24.500 --> 00:28:27.300
as we have been involved in this that answering


00:28:27.300 --> 00:28:32.260
this question, what's the CO2 footprint of my computational work, is actually a very,


00:28:32.260 --> 00:28:36.980
very difficult question to answer. And it's opaque for a variety of reasons. It's opaque


00:28:36.980 --> 00:28:44.100
because the way that the energy industry deals with CO2 emissions is pretty opaque, unless


00:28:44.100 --> 00:28:49.740
you know the language of how they express this. And it's also difficult to understand


00:28:49.740 --> 00:28:56.580
when you are able to make the calculation, what does that mean? What's one gram of CO2


00:28:56.580 --> 00:29:00.220
relative to, you know, say, everyday activities.


00:29:00.220 --> 00:29:01.980
So one of the things that we've tried to do


00:29:01.980 --> 00:29:03.540
as part of this dashboard


00:29:03.540 --> 00:29:06.100
is simplify those two steps for people.


00:29:06.100 --> 00:29:07.820
'Cause we've been approached by people,


00:29:07.820 --> 00:29:10.500
you know, via email, via Slack,


00:29:10.500 --> 00:29:13.340
and we know we're not the only people concerned about this.


00:29:13.340 --> 00:29:18.340
And so this is just a way to help make these approximations


00:29:18.340 --> 00:29:21.420
both visible, but also, you know, kind of comprehensible


00:29:21.420 --> 00:29:25.420
and put it in the context of human activities.


00:29:25.420 --> 00:29:28.300
- Right, there's a lot of layers and, you know,


00:29:28.300 --> 00:29:29.980
companies that run the clouds,


00:29:29.980 --> 00:29:33.380
they are trying to be more responsible with their energy,


00:29:33.380 --> 00:29:34.620
but you don't know.


00:29:34.620 --> 00:29:38.020
A lot of times you don't know if this data center,


00:29:38.020 --> 00:29:41.680
you know, US, East One and AWS,


00:29:41.680 --> 00:29:44.100
how much energy from different sources


00:29:44.100 --> 00:29:45.100
is that actually using,


00:29:45.100 --> 00:29:47.660
how much have they actually, you know,


00:29:47.660 --> 00:29:49.340
built their own solar and wind?


00:29:49.340 --> 00:29:50.500
We don't know, right?


00:29:50.500 --> 00:29:53.460
But get a better sense using your tool.


00:29:53.460 --> 00:29:55.380
who got better data than the random person


00:29:55.380 --> 00:29:57.100
who just kind of estimates,


00:29:57.100 --> 00:30:00.780
well, they're doing some stuff, so it must be fine.


00:30:00.780 --> 00:30:03.180
- And another important thing I think is,


00:30:03.180 --> 00:30:07.300
and Jonathan is much more an expert in that than I am,


00:30:07.300 --> 00:30:10.420
but like not emitting is very different


00:30:10.420 --> 00:30:15.420
from offsetting in whatever way, Rex or whatever.


00:30:15.420 --> 00:30:16.300
- Yeah, that's a good point.


00:30:16.300 --> 00:30:18.900
- Your emissions and our atmosphere,


00:30:18.900 --> 00:30:21.180
our climate has inertia


00:30:21.180 --> 00:30:28.540
and the expected compensation in 5, 10, 20 years of your current emissions,


00:30:28.540 --> 00:30:32.180
those are two very different things, right?


00:30:32.180 --> 00:30:38.580
And it's much easier to put carbon in the atmosphere than taking it away from it.


00:30:38.580 --> 00:30:45.180
And so I think it's not just because you read that Google and others,


00:30:45.180 --> 00:30:50.540
Microsoft are carbon neutral, which comes from compensations of many forms.


00:30:50.980 --> 00:30:53.460
doesn't mean no carbon was emitted.


00:30:53.460 --> 00:30:58.980
Yeah, just to build on Victor's point again,


00:30:58.980 --> 00:31:03.660
there's decades of research in what you'd call environmental psychology,


00:31:03.660 --> 00:31:08.860
showing that explaining to people the consequences of inaction


00:31:08.860 --> 00:31:12.980
or of diffuse environmental costs to a particular action


00:31:12.980 --> 00:31:15.460
causes long-term behavior change.


00:31:15.460 --> 00:31:18.460
And I think one of the things that's been really exciting about


00:31:18.460 --> 00:31:25.340
seeing the machine learning and AI communities grapple with this question in a very public way


00:31:25.340 --> 00:31:31.660
is we've started to see articles of pressure being put on organizations to, "Why don't we


00:31:31.660 --> 00:31:37.980
have more green energy infrastructure undergirding our work?" And so the speed at which this has


00:31:37.980 --> 00:31:43.660
become a public conversation is really heartening as somebody who's been working in the environment


00:31:43.660 --> 00:31:49.420
for quite a bit of time. Yeah, I would say it does seem to be getting a lot of attention,


00:31:49.420 --> 00:31:55.180
which is good. It's a big problem, but attention instead of just head in the sand is a really big


00:31:55.180 --> 00:31:58.940
deal. Like we've been driving cars for a long time. We've been flying planes for a long time.


00:31:58.940 --> 00:32:05.980
There's a lot of like raised trucks with super big wheels with dual, you know,


00:32:06.940 --> 00:32:13.580
cold stack pipes on them, right? Like that's, that's, I can't speak for everyone that gets a


00:32:13.580 --> 00:32:16.860
truck like that, but I feel there's a lot of times when we have these conversations,


00:32:16.860 --> 00:32:22.540
people are just like, well, this is so horrible and so vague that I'm just going to live my life


00:32:22.540 --> 00:32:27.020
and enjoy it because I seem to not be able to do anything anyway. So I might as well have fun


00:32:27.020 --> 00:32:31.500
instead of not have fun while things are going wrong. Right. Like that's, that's kind of that


00:32:31.500 --> 00:32:35.180
psychology, right? And so I don't know, how do you all deal with that?


00:32:35.180 --> 00:32:42.620
And it's also something that's like when it's not before your eyes, it's much more difficult to


00:32:42.620 --> 00:32:51.180
understand and to respond to. And I think this is part of what we're seeing today with


00:32:51.180 --> 00:33:00.940
decades of activism is like, facts, hard facts are not enough to convince humans and


00:33:00.940 --> 00:33:03.580
and to some extent, it's also a good thing.


00:33:03.580 --> 00:33:08.580
And it has, I think, it has value in our recognition.


00:33:08.580 --> 00:33:14.260
But it also has this downside that it's just


00:33:14.260 --> 00:33:17.560
because you say a number to someone,


00:33:17.560 --> 00:33:18.620
if they don't understand it,


00:33:18.620 --> 00:33:21.140
if they don't see it for themselves in their everyday life,


00:33:21.140 --> 00:33:23.380
it's gonna be very hard to understand.


00:33:23.380 --> 00:33:27.060
So until you have used something like CodeCarbon,


00:33:27.060 --> 00:33:30.280
like I code every day, I train models every day,


00:33:30.280 --> 00:33:34.200
and I train a model for five days on a GPU in Quebec.


00:33:34.200 --> 00:33:37.440
That's my daily life basically.


00:33:37.440 --> 00:33:41.360
And some might find it dull.


00:33:41.360 --> 00:33:42.200
I like it.


00:33:42.200 --> 00:33:44.320
Anyway, that's not the point.


00:33:44.320 --> 00:33:46.120
I mean, until you have that and you're like,


00:33:46.120 --> 00:33:47.460
oh, this is what I do.


00:33:47.460 --> 00:33:51.560
Those numbers start to make sense.


00:33:51.560 --> 00:33:52.640
- Yeah.


00:33:52.640 --> 00:33:55.520
- And Evan, if you have numbers for your day to day


00:33:55.520 --> 00:33:57.160
that doesn't seem that much,


00:33:57.160 --> 00:34:00.560
like thousands of grams or kilograms.


00:34:00.560 --> 00:34:04.040
But once you sum all the emission


00:34:04.040 --> 00:34:07.720
for all the model train, for all the machine learning teams,


00:34:07.720 --> 00:34:09.420
for all the machine learning data scientists


00:34:09.420 --> 00:34:13.200
for a company for a year, or even for academia,


00:34:13.200 --> 00:34:16.560
that start to get, depending on your size of the company,


00:34:16.560 --> 00:34:18.680
of course, that start to get sizable,


00:34:18.680 --> 00:34:23.560
and you might want to take a serious look at it.


00:34:23.560 --> 00:34:25.840
- Yeah.


00:34:25.840 --> 00:34:30.720
All right, I want to dive into the code and talk about this.


00:34:30.720 --> 00:34:35.960
But I guess maybe speak really quickly to,


00:34:35.960 --> 00:34:38.000
I work at a company.


00:34:38.000 --> 00:34:40.320
We make shoes.


00:34:40.320 --> 00:34:41.840
They want me to use ML to figure out


00:34:41.840 --> 00:34:46.280
how to get better behaviors out of the materials for track


00:34:46.280 --> 00:34:47.120
runners or whatever.


00:34:47.120 --> 00:34:47.880
So I do that.


00:34:47.880 --> 00:34:54.120
How do I get that company to say, yes, we


00:34:54.120 --> 00:34:58.260
should measure our scientific data science work


00:34:58.260 --> 00:35:00.740
and we should offset it.


00:35:00.740 --> 00:35:04.200
There's a lot of layers between the people who care about shoes


00:35:04.200 --> 00:35:07.760
and sales and people who care about machine learning carbon


00:35:07.760 --> 00:35:10.640
offsets.


00:35:10.640 --> 00:35:12.840
My personal understanding of this situation


00:35:12.840 --> 00:35:19.280
is that empowering individuals with tools and numbers


00:35:19.280 --> 00:35:23.920
to convince organizations is part of our mission.


00:35:23.920 --> 00:35:31.420
So if the person in charge, whatever their role in the organization, thinks that in order


00:35:31.420 --> 00:35:38.240
to have an estimation of their carbon impact, they have to find a consulting firm, pay people


00:35:38.240 --> 00:35:45.400
for five weeks, and if they think this is the process, they're going to be reluctant.


00:35:45.400 --> 00:35:47.480
And I can understand why.


00:35:47.480 --> 00:35:55.160
you have a plug and play tool that even you as the evangelizer, if that's a word,


00:35:55.160 --> 00:36:02.200
but you get the idea, even if it doesn't cost you much to try. But I mean, the way


00:36:02.200 --> 00:36:06.380
we want to build this thing is just like one import and a couple of lines.


00:36:06.380 --> 00:36:11.640
Yeah, so let's talk about the code. I think maybe the answer, maybe an


00:36:11.640 --> 00:36:15.040
approach that you could have there is we'll run something like this on all of


00:36:15.040 --> 00:36:18.360
of the training that we do, and then we're going to report up


00:36:18.360 --> 00:36:21.280
our division and this company generates this much carbon.


00:36:21.280 --> 00:36:22.600
So if you care about carbon,


00:36:22.600 --> 00:36:24.320
you need to take that into account.


00:36:24.320 --> 00:36:26.800
- I think that's a good starting point.


00:36:26.800 --> 00:36:29.200
I think as we can see today together,


00:36:29.200 --> 00:36:31.960
I mean, those conversations are hard and long


00:36:31.960 --> 00:36:36.960
and it's not easy to understand all that matters


00:36:36.960 --> 00:36:40.240
and you may need that consulting firm in the end


00:36:40.240 --> 00:36:41.680
to help you understand what's at stake


00:36:41.680 --> 00:36:44.660
in your whole value chain.


00:36:44.660 --> 00:36:47.380
you gotta start somewhere, right?


00:36:47.380 --> 00:36:48.980
And if you're an individual


00:36:48.980 --> 00:36:50.380
and you wanna change your organization,


00:36:50.380 --> 00:36:54.060
well, I think if you wanna have an impact,


00:36:54.060 --> 00:36:58.140
those kinds of tools should be easy to start with.


00:36:58.140 --> 00:37:00.380
And then, as we've said, it's not enough


00:37:00.380 --> 00:37:01.420
and it's not precise enough,


00:37:01.420 --> 00:37:03.940
and then there are other steps you can take,


00:37:03.940 --> 00:37:08.420
but you need to get the conversations going and start it.


00:37:08.420 --> 00:37:11.500
- And to start that, you gotta start measuring.


00:37:11.500 --> 00:37:14.480
So in order to do that, let's talk about the code.


00:37:14.480 --> 00:37:16.300
It's literally four lines of code.


00:37:16.300 --> 00:37:17.140
It's all you gotta do.


00:37:17.140 --> 00:37:18.960
You pip install code carbon,


00:37:18.960 --> 00:37:22.700
and then from code carbon, import emissions tracker.


00:37:22.700 --> 00:37:25.540
Create one, tracker.start, do your training,


00:37:25.540 --> 00:37:28.280
tracker.stop, and that's it, right?


00:37:28.280 --> 00:37:30.620
- Right, and with the decorator solution,


00:37:30.620 --> 00:37:32.180
it's even two lines of code.


00:37:32.180 --> 00:37:34.760
- Yeah, with the decorator,


00:37:34.760 --> 00:37:36.820
you can just put a decorator on a function,


00:37:36.820 --> 00:37:39.620
and then basically any training that happens during that


00:37:40.620 --> 00:37:44.840
will be measured and then saved to a CSV file, right?


00:37:44.840 --> 00:37:46.220
- That's it. - That's correct.


00:37:46.220 --> 00:37:49.240
- And if you think a context manager should be implemented,


00:37:49.240 --> 00:37:50.920
well, you're welcome to create a PR.


00:37:50.920 --> 00:37:51.920
It's gonna be super easy.


00:37:51.920 --> 00:37:53.720
Everything is already there.


00:37:53.720 --> 00:37:54.980
- Yeah, exactly.


00:37:54.980 --> 00:37:58.880
I can already see it in my mind with the missions tracker,


00:37:58.880 --> 00:38:00.800
as tracker.


00:38:00.800 --> 00:38:01.640
Cool.


00:38:01.640 --> 00:38:05.440
So it creates one of these CSV files and then what?


00:38:05.440 --> 00:38:09.220
- So there are a bunch of things that happen.


00:38:10.520 --> 00:38:15.520
If you wanna, like the two big steps are one,


00:38:15.520 --> 00:38:18.720
you look for the hardware you understand,


00:38:18.720 --> 00:38:20.760
you like code carbon understands,


00:38:20.760 --> 00:38:25.440
then you track those, you measure the energy consumed.


00:38:25.440 --> 00:38:28.360
And so you have that, basically you measure the energy.


00:38:28.360 --> 00:38:33.080
And then next step is, well, how much carbon


00:38:33.080 --> 00:38:38.080
does this energy has emitted, has this energy emitted?


00:38:38.480 --> 00:38:42.020
And so you need to map the code to your location.


00:38:42.020 --> 00:38:46.520
- Right, and do you do that by just like a get location


00:38:46.520 --> 00:38:47.840
from IP address type of thing?


00:38:47.840 --> 00:38:48.680
- Exactly.


00:38:48.680 --> 00:38:49.500
- I'm like--


00:38:49.500 --> 00:38:53.840
- So you can either do that or provide the country ISO code


00:38:53.840 --> 00:38:58.360
for a couple of countries, Canada and the US,


00:38:58.360 --> 00:39:01.000
we have regions below the national level.


00:39:01.000 --> 00:39:05.600
Another thing that you can actually do is,


00:39:05.600 --> 00:39:07.040
or it's not gonna help you with the location,


00:39:07.040 --> 00:39:09.000
but it's gonna help you with the,


00:39:09.000 --> 00:39:14.000
the carbon impact is we can ping CO2 signal,


00:39:14.000 --> 00:39:18.600
which is an API that is being developed


00:39:18.600 --> 00:39:22.680
by the electricity map initiative group organization


00:39:22.680 --> 00:39:25.780
company, whatever their status.


00:39:25.780 --> 00:39:30.780
And so that's gonna help you have an exact estimation


00:39:30.780 --> 00:39:32.160
at that moment in time,


00:39:32.160 --> 00:39:36.680
depending on what data you have of those computations.


00:39:36.680 --> 00:39:38.600
Otherwise, we need to have your country code


00:39:38.600 --> 00:39:40.800
and we're gonna map that to historical data.


00:39:40.800 --> 00:39:45.480
- This CO2 signal, this is new to me.


00:39:45.480 --> 00:39:46.320
What is this?


00:39:46.320 --> 00:39:51.840
- I think you'd better look at then the, exactly.


00:39:51.840 --> 00:39:53.480
- Look at the map?


00:39:53.480 --> 00:39:54.920
- Exactly.


00:39:54.920 --> 00:39:59.920
So they have products, they have predictions


00:39:59.920 --> 00:40:02.120
of carbon emissions and so on,


00:40:02.120 --> 00:40:06.000
but that's basically, it's an initiative.


00:40:06.000 --> 00:40:09.280
The organization is called Tomorrow.


00:40:09.280 --> 00:40:12.720
And the goal here, at least with the electricity map,


00:40:12.720 --> 00:40:18.080
is to gather data about carbon intensity and the energy


00:40:18.080 --> 00:40:26.520
mix of countries through the forest of APIs and standards


00:40:26.520 --> 00:40:29.480
countries have for countries and companies


00:40:29.480 --> 00:40:31.320
and have for that kind of thing.


00:40:31.320 --> 00:40:34.600
So you can see that, at a level in Canada, not all--


00:40:34.600 --> 00:40:37.900
or in the US, not all regions are gonna work similarly


00:40:37.900 --> 00:40:40.760
and some regions might not even provide


00:40:40.760 --> 00:40:42.960
that kind of data in the open.


00:40:42.960 --> 00:40:44.820
- Yeah, that's too bad.


00:40:44.820 --> 00:40:47.520
Yeah, but it's really different


00:40:47.520 --> 00:40:51.800
depending on where you are in just even the US, right?


00:40:51.800 --> 00:40:53.200
Like in the Pacific Northwest,


00:40:53.200 --> 00:40:55.920
I think it's like very high levels of hydro.


00:40:55.920 --> 00:41:00.160
Southeast, there's a lot of coal still.


00:41:00.160 --> 00:41:01.440
It's not just what country,


00:41:01.440 --> 00:41:04.280
it's even like maybe a little more granular than that, right?


00:41:04.280 --> 00:41:06.600
at least for large places.


00:41:06.600 --> 00:41:08.440
- Yes, and also, as you can see,


00:41:08.440 --> 00:41:10.480
I think this is also a very interesting map


00:41:10.480 --> 00:41:13.080
because you can see that energy grids


00:41:13.080 --> 00:41:18.080
are very different from the grid that you know,


00:41:18.080 --> 00:41:23.520
like nation, state, whatever is after that, right?


00:41:23.520 --> 00:41:24.880
- Yeah, county, city, yeah, all that.


00:41:24.880 --> 00:41:26.040
- County, city, all of that.


00:41:26.040 --> 00:41:27.280
Like you can see, for example,


00:41:27.280 --> 00:41:31.440
the one that spans something like Iowa to...


00:41:31.440 --> 00:41:35.920
I was thinking state-related or like this thing that goes from Montana to Texas or something.


00:41:35.920 --> 00:41:40.640
Yeah, that doesn't look like any state I learned in school.


00:41:40.640 --> 00:41:45.120
No, but it's probably a unified grid for some reason because


00:41:45.120 --> 00:41:48.480
providers got together for under some constraints.


00:41:48.480 --> 00:41:52.560
Yep, yeah, exactly. So when I'm looking at this code here,


00:41:52.560 --> 00:42:00.400
I run that and then I get this map and it can give you recommendations on the cloud


00:42:00.400 --> 00:42:02.320
cloud regions, right, and where you might go.


00:42:02.320 --> 00:42:04.880
So for example, see--


00:42:04.880 --> 00:42:06.040
- So you're on the left.


00:42:06.040 --> 00:42:08.520
This is something that we might wanna change, right?


00:42:08.520 --> 00:42:10.360
The UI of this thing might not be obvious,


00:42:10.360 --> 00:42:11.520
but you're on the left.


00:42:11.520 --> 00:42:16.520
But this, I just wanted to make this clarification


00:42:16.520 --> 00:42:19.760
'cause even I sometimes forget,


00:42:19.760 --> 00:42:23.000
I'm like, where was this thing run?


00:42:23.000 --> 00:42:24.640
Oh, that's actually, yeah, you run on the left


00:42:24.640 --> 00:42:28.800
and we show you how it could have been different


00:42:28.800 --> 00:42:29.760
somewhere else.


00:42:29.760 --> 00:42:33.200
- Yeah, so if I pick say US West one for AWS


00:42:33.200 --> 00:42:35.600
versus EU West three,


00:42:35.600 --> 00:42:39.020
you can see the relative carbon offset or production,


00:42:39.020 --> 00:42:42.760
how bad that was or how good it was.


00:42:42.760 --> 00:42:44.280
And these are all comes from those reports


00:42:44.280 --> 00:42:47.640
generated out of that CSV file.


00:42:47.640 --> 00:42:49.720
- Exactly. - That's great.


00:42:49.720 --> 00:42:53.640
- So I just wanna be clear about how the data was gathered


00:42:53.640 --> 00:42:57.200
'cause that's a very important topic.


00:42:57.200 --> 00:43:03.840
So we still need to update the data for GCP, Google Cloud


00:43:03.840 --> 00:43:07.520
Platform, because they recently released those numbers.


00:43:07.520 --> 00:43:11.760
But for most of those locations, we had to make an assumption.


00:43:11.760 --> 00:43:14.400
The assumption was that the data center


00:43:14.400 --> 00:43:17.280
was plugged to the local grid.


00:43:17.280 --> 00:43:20.000
So if a data center is in Boston,


00:43:20.000 --> 00:43:24.520
we assume the data center uses the same energy


00:43:24.520 --> 00:43:27.740
as Boston's grid, which might not be the case, right?


00:43:27.740 --> 00:43:32.740
Many providers now have their own solar panels and whatnot.


00:43:32.740 --> 00:43:34.660
So that might not be the case.


00:43:34.660 --> 00:43:38.180
And so, but unless they release those numbers


00:43:38.180 --> 00:43:43.040
and there's, I can find the link, I'll share it with you.


00:43:43.040 --> 00:43:46.180
Unless we have those numbers publicized by the providers,


00:43:46.180 --> 00:43:48.580
I mean, there's only so much we can do, right?


00:43:48.580 --> 00:43:49.420
So.


00:43:49.420 --> 00:43:50.620
- Yeah, well, here's a call to action


00:43:50.620 --> 00:43:52.740
for those who haven't released it.


00:43:52.740 --> 00:43:53.580
Get on it, right?


00:43:53.580 --> 00:43:57.220
I think it was part of Jonathan's message earlier,


00:43:57.220 --> 00:43:59.640
which is like, there are so many layers


00:43:59.640 --> 00:44:01.280
and so many of them are okay.


00:44:01.280 --> 00:44:08.060
That's part of the, I think, our responsibility as users.


00:44:08.060 --> 00:44:09.120
- Yeah.


00:44:09.120 --> 00:44:10.260
- I don't like to put too much weight


00:44:10.260 --> 00:44:11.880
on individuals' shoulders,


00:44:11.880 --> 00:44:16.480
and I think structural changes have a much wider,


00:44:16.480 --> 00:44:17.980
well, much more potential,


00:44:17.980 --> 00:44:20.420
but I think it's still interconnected,


00:44:20.420 --> 00:44:23.180
and if you can do something about it, well, you should.


00:44:23.180 --> 00:44:27.420
- Yeah, let's talk a little bit about running it.


00:44:27.420 --> 00:44:32.940
So when I go over here and I say start and then stop,


00:44:32.940 --> 00:44:36.000
like how do you know how much energy I've used?


00:44:36.000 --> 00:44:39.300
I mean, I know once it leaves the computer,


00:44:39.300 --> 00:44:41.540
like there's a lot of assumptions and various things


00:44:41.540 --> 00:44:42.700
like we talked about,


00:44:42.700 --> 00:44:47.020
but how do you estimate how much that that code has taken?


00:44:47.020 --> 00:44:48.300
- That's a very good question.


00:44:48.300 --> 00:44:51.260
And Victor, can I answer this one?


00:44:51.260 --> 00:44:52.940
- Oh yes, sure.


00:44:52.940 --> 00:44:56.100
- Okay, so when you are training


00:44:56.100 --> 00:44:59.220
and you're running a machine learning program,


00:44:59.220 --> 00:45:01.060
you are mostly using GPU,


00:45:01.060 --> 00:45:03.860
and you are mostly using NVIDIA GPU.


00:45:03.860 --> 00:45:06.700
And thankfully, NVIDIA has a nice SDK


00:45:06.700 --> 00:45:10.000
to get, at a given time, the current,


00:45:10.000 --> 00:45:16.000
estimated that plus or minus 5% energy usage of the GPU.


00:45:16.000 --> 00:45:18.780
- Oh, really?


00:45:18.780 --> 00:45:20.220
Okay, so it's not like you're saying,


00:45:20.220 --> 00:45:22.580
"Oh, it's a 3070 Super,


00:45:22.580 --> 00:45:28.500
and it must be pinned CPU-wise or GPU-wise. So let's just assume this much time times this kind


00:45:28.500 --> 00:45:34.180
of computer, it gives you more narrow exact measurements. Okay, fantastic.


00:45:34.180 --> 00:45:40.340
But we still get the energy consumption from all GPU. So if you are trying multiple models,


00:45:40.340 --> 00:45:49.380
we might get higher or lower energy estimation. I'm not sure there. So that's for GPU.


00:45:49.380 --> 00:45:56.340
For CPU, we are supporting Intel, and we have several ways of doing that.


00:45:56.340 --> 00:46:00.740
Either we get a measurement at the beginning of the training and at the end,


00:46:00.740 --> 00:46:06.340
and we get the total energy usage between the two, so we can get the difference.


00:46:06.340 --> 00:46:12.420
Or we can also regularly get the immediate usage, I think.


00:46:13.620 --> 00:46:22.020
we are working to add memory usage because even if GPU and CPU are the top most


00:46:22.020 --> 00:46:31.220
resources that you use for multi-gigabytes server, it tends to be not negligible.


00:46:31.220 --> 00:46:41.220
Probably disk as well. Yeah, disk, everything takes energy. The goal is to focus on what takes


00:46:41.220 --> 00:46:50.260
most of the energy and how easy it is to get that consumption.


00:46:50.260 --> 00:46:56.340
So you get all of that either during the training frequently or at the beginning and the end.


00:46:56.340 --> 00:47:03.540
In addition, we get the duration and we detect if you're running in a data center or not.


00:47:03.540 --> 00:47:13.260
So in case we don't have access to anything, like you're running on AMD GPU, on an AMD


00:47:13.260 --> 00:47:21.580
CPU on Windows, we can still give you an estimation based on the duration and on your estimated


00:47:21.580 --> 00:47:27.420
location or if you are running inside a data center or a specific location, we can also


00:47:27.420 --> 00:47:31.060
get a more precise estimation for you.


00:47:31.060 --> 00:47:34.940
and we are measuring what energy usage,


00:47:34.940 --> 00:47:39.940
and then we can use our data to estimate again,


00:47:39.940 --> 00:47:41.460
estimation of estimation,


00:47:41.460 --> 00:47:45.060
of the CO2 emitted for that usage.


00:47:45.060 --> 00:47:50.700
- I don't know how deep you want to go into how it works,


00:47:50.700 --> 00:47:52.220
but I do want to point out--


00:47:52.220 --> 00:47:54.020
- Give us a little look inside, yeah.


00:47:54.020 --> 00:47:57.020
- Yeah, given that it's one of the most difficult area,


00:47:57.020 --> 00:48:00.460
I think I also want to use your platform


00:48:00.460 --> 00:48:03.980
to call for help, which is it's actually the low level


00:48:03.980 --> 00:48:10.420
inner workings of CPUs are, I mean, hard to understand,


00:48:10.420 --> 00:48:12.900
at least for me, I have a background


00:48:12.900 --> 00:48:13.860
and I'm a researcher, right?


00:48:13.860 --> 00:48:16.620
So it's an area where we--


00:48:16.620 --> 00:48:18.460
- Not necessarily a hardware specialist, right?


00:48:18.460 --> 00:48:20.220
You're writing on hardware, yeah.


00:48:20.220 --> 00:48:21.620
- Exactly, and so for example,


00:48:21.620 --> 00:48:26.620
like the way we read the energy consumption of Intel CPUs,


00:48:28.460 --> 00:48:34.160
I mean, the GPUs, as Boris said, have, at least NVIDIA's GPUs,


00:48:34.160 --> 00:48:36.820
have this driver that we can ping,


00:48:36.820 --> 00:48:38.900
and NVIDIA SMI is--


00:48:38.900 --> 00:48:43.340
all the PY and VML package is very useful,


00:48:43.340 --> 00:48:45.140
because we can just ping this and not


00:48:45.140 --> 00:48:46.940
care about how it's done, and trust NVIDIA


00:48:46.940 --> 00:48:50.420
and use that number.


00:48:50.420 --> 00:48:53.740
But for the CPUs, it's much more complicated.


00:48:53.740 --> 00:48:56.660
The reason is that what happens under the hood


00:48:56.660 --> 00:49:01.660
is modern Intel CPUs under the right settings,


00:49:01.660 --> 00:49:06.200
write actually their energy usage,


00:49:06.200 --> 00:49:08.660
millijoules to a text file.


00:49:08.660 --> 00:49:11.300
It's the RAPL interface and they write to a text file


00:49:11.300 --> 00:49:14.840
the number of millijoules they have consumed since,


00:49:14.840 --> 00:49:18.060
I don't know when, since they were turned on


00:49:18.060 --> 00:49:23.060
or the 1st of January 1970 or whatever the run date.


00:49:23.060 --> 00:49:26.600
What matters is that, and we look at the difference


00:49:26.600 --> 00:49:32.720
But those numbers are written by the CPU socket.


00:49:32.720 --> 00:49:35.920
So let me give you an example.


00:49:35.920 --> 00:49:39.680
In the academic setting where I work, we have shared clusters.


00:49:39.680 --> 00:49:49.600
I can request part of a node, and I'm going to request one GPU and 20 CPUs to do my computations.


00:49:49.600 --> 00:49:58.960
But what I saw looking at the rebel files is that there are two sockets of 40 CPUs.


00:49:58.960 --> 00:50:02.280
We have 80 CPUs per node and two sockets of 40.


00:50:02.280 --> 00:50:04.760
So there's no way to read from the rebel file.


00:50:04.760 --> 00:50:06.800
So your granularity is 40.


00:50:06.800 --> 00:50:11.200
And the CPUs that are allocated to me might change over time, maybe not.


00:50:11.200 --> 00:50:14.360
It depends on the resource manager.


00:50:14.360 --> 00:50:16.320
We use Sturm.


00:50:16.320 --> 00:50:20.560
And those CPUs will be split across those two sockets.


00:50:20.560 --> 00:50:25.680
And so we have that level of problems too, right?


00:50:25.680 --> 00:50:30.960
So the high level, you're working in a dedicated environment and it's only your program, then


00:50:30.960 --> 00:50:34.720
RAPL is perfect and we couldn't have dreamt for something better.


00:50:34.720 --> 00:50:44.040
But it does not allow us to go to the core, let alone the process granularity of power


00:50:44.040 --> 00:50:45.480
consumption.


00:50:45.480 --> 00:50:50.360
So I just want to put a big warning here.


00:50:50.360 --> 00:50:53.520
And one of the things that we need to look into--


00:50:53.520 --> 00:50:56.920
and it's very hard, and I don't know the numbers.


00:50:56.920 --> 00:50:59.840
Maybe even what I'm going to say won't make sense.


00:50:59.840 --> 00:51:03.360
But the only solution we have left


00:51:03.360 --> 00:51:06.120
is, is there some kind of heuristic


00:51:06.120 --> 00:51:12.280
to map the CPU utilization to the energy consumption,


00:51:12.280 --> 00:51:12.780
basically?


00:51:12.780 --> 00:51:16.860
Because otherwise, we're never going to be able to attribute


00:51:16.860 --> 00:51:23.140
your processes and sub-processes' CPU usage to watts, basically.


00:51:23.140 --> 00:51:25.500
>>Yeah. >>Because of this RAPL setup


00:51:25.500 --> 00:51:28.100
that is written by a socket.


00:51:28.100 --> 00:51:34.220
And I've talked a little to people who understand this way better than I do,


00:51:34.220 --> 00:51:37.700
and they thought this endeavor was very risky.


00:51:37.700 --> 00:51:40.780
They were pessimistic.


00:51:40.780 --> 00:51:43.300
And you're like, what else do we have to work with, right?


00:51:43.300 --> 00:51:47.660
- Yeah, and so I think the next thing is like,


00:51:47.660 --> 00:51:50.460
we're gonna need to get our hands on hardware,


00:51:50.460 --> 00:51:52.380
have it run and see how bad it is.


00:51:52.380 --> 00:51:58.380
And it's gonna be one setup with one mode


00:51:58.380 --> 00:52:01.380
for the compilation of the math libraries


00:52:01.380 --> 00:52:02.980
I'm gonna use to benchmark and whatnot.


00:52:02.980 --> 00:52:05.340
Like, there's only so much we can do


00:52:05.340 --> 00:52:09.000
if the hardware providers don't tell us more.


00:52:09.000 --> 00:52:17.800
It would be nice to see operating systems and then the hardware providers as well allow


00:52:17.800 --> 00:52:19.720
you to access that information, right?


00:52:19.720 --> 00:52:27.840
Like how much voltage am I currently consuming with just this process, right?


00:52:27.840 --> 00:52:32.000
You don't want to profile it because if you profile it, you'll be like 50% of the problem,


00:52:32.000 --> 00:52:33.000
right?


00:52:33.000 --> 00:52:37.040
And you'll slow it down and people won't want to touch it.


00:52:37.040 --> 00:52:38.040
So yeah.


00:52:38.040 --> 00:52:49.920
I've seen and talked to people at Power API and PiJewel initiatives. And even they, from


00:52:49.920 --> 00:52:59.640
what I remember, explained that even if you had total control on the software or the hardware,


00:52:59.640 --> 00:53:05.240
both of those things are going to be so dependent on the way you compile the libraries you use


00:53:05.240 --> 00:53:13.280
And a number of other facts that it's even the very definition of those things that we're looking for is not obvious.


00:53:13.280 --> 00:53:18.160
Or whether it's Linux versus macOS versus Windows, it's got to make a difference.


00:53:18.160 --> 00:53:31.960
It all matters. And the reason why I think it's still worth looking for an approximation through security utilization, even if it's a bad proxy is it's all about proxies.


00:53:32.160 --> 00:53:39.320
So it doesn't matter if you're precise to the millijoule


00:53:39.320 --> 00:53:43.200
on your CPU if your uncertainty around carbon emissions


00:53:43.200 --> 00:53:45.640
is huge.


00:53:45.640 --> 00:53:47.980
>>Victor: Yeah, otherwise you end up with something as much


00:53:47.980 --> 00:53:49.800
carbon as five cars, right?


00:53:49.800 --> 00:53:50.880
>>Romain: Yeah.


00:53:50.880 --> 00:53:51.720
>>Victor: And so--


00:53:51.720 --> 00:53:54.240
>>Kyle: We can get it down to 2.1 or 2.2 cars.


00:53:54.240 --> 00:53:56.080
Come on, let's go with that.


00:53:56.080 --> 00:53:56.920
>>Romain: Yeah.


00:53:56.920 --> 00:54:00.560
So it's really a very complex endeavor.


00:54:00.560 --> 00:54:02.840
Yeah, yeah, absolutely.


00:54:02.840 --> 00:54:06.720
So it sounds like it runs on multiple platforms.


00:54:06.720 --> 00:54:08.120
It sounds like it supports Intel.


00:54:08.120 --> 00:54:08.960
>>We'll try to, at least.


00:54:08.960 --> 00:54:09.480
>>Yeah, yeah.


00:54:09.480 --> 00:54:14.360
So Windows, Linux, macOS.


00:54:14.360 --> 00:54:19.760
I'm sitting here recording on my Mac mini M1 Apple Silicon.


00:54:19.760 --> 00:54:21.840
Can I run it here?


00:54:21.840 --> 00:54:23.000
>>Yeah.


00:54:23.000 --> 00:54:27.240
You would need to install the Intel Power Gadget,


00:54:27.240 --> 00:54:31.640
restart your computer, allow specific security permissions.


00:54:31.640 --> 00:54:33.640
It's not an Intel CPU.


00:54:33.640 --> 00:54:38.600
So I'm guessing it will be back to the simple heuristic based on the situation.


00:54:38.600 --> 00:54:43.320
We realized actually the Intel Power Gadget also tracks some AMD CPUs.


00:54:43.320 --> 00:54:49.000
Like we had a user say, "Oh, you don't seem to support AMD."


00:54:49.000 --> 00:54:51.160
And then they still installed the Intel Power Gadget.


00:54:51.160 --> 00:54:53.400
I don't know why, but they did. And then it worked.


00:54:53.400 --> 00:54:55.880
So I'm like, I'm not sure how this thing works.


00:54:56.360 --> 00:54:59.000
So Intel AMD, but maybe not Apple Silicon.


00:54:59.000 --> 00:54:59.840
- Yeah.


00:54:59.840 --> 00:55:00.680
- Yeah.


00:55:00.680 --> 00:55:01.500
- I'm not sure.


00:55:01.500 --> 00:55:02.960
- I don't think so.


00:55:02.960 --> 00:55:04.400
- Okay, well, probably most people


00:55:04.400 --> 00:55:07.720
won't be doing training on that.


00:55:07.720 --> 00:55:10.880
- I think the Silicon app,


00:55:10.880 --> 00:55:13.720
sorry, the Apple Silicon platform


00:55:13.720 --> 00:55:15.880
has a dedicated course for machine learning.


00:55:15.880 --> 00:55:17.960
- It does have, I think, 16 ML cores.


00:55:17.960 --> 00:55:20.280
Yeah, so yeah, maybe, maybe they are.


00:55:20.280 --> 00:55:22.680
They're coming out with the Mac Pro,


00:55:22.680 --> 00:55:24.320
which is supposed to have many, many cores.


00:55:24.320 --> 00:55:27.720
So maybe that'll be where people do it more, but.


00:55:27.720 --> 00:55:30.260
- So if Apple is hearing us,


00:55:30.260 --> 00:55:35.260
send us a Mac mini and we'll work on improving the tracking.


00:55:35.260 --> 00:55:37.040
- And one Mac mini is for all three of you,


00:55:37.040 --> 00:55:39.680
the whole team, come on, let's send it along.


00:55:39.680 --> 00:55:40.680
Make it happen.


00:55:40.680 --> 00:55:43.800
- You have my Twitter handle, send me a message.


00:55:43.800 --> 00:55:45.560
- Fantastic, all right.


00:55:45.560 --> 00:55:46.600
Let's see, before we move on,


00:55:46.600 --> 00:55:48.600
quick question from Brian in the live stream.


00:55:48.600 --> 00:55:50.640
Other than moving to different data centers,


00:55:50.640 --> 00:55:52.200
what are some of the highest impact changes


00:55:52.200 --> 00:55:55.480
people can make, different training methods, and so on.


00:55:55.480 --> 00:55:58.520
And by the way, that also leads exactly into where I was going.


00:55:58.520 --> 00:56:00.800
Thank you for that very timely question.


00:56:00.800 --> 00:56:03.160
Like patterns and things you can do.


00:56:03.160 --> 00:56:05.800
Let's talk about that.


00:56:05.800 --> 00:56:09.160
One of the things that we wrote in the "Contemplating


00:56:09.160 --> 00:56:11.920
the Carbon Emissions of Machine Learning" paper--


00:56:11.920 --> 00:56:13.680
it's on the website--


00:56:13.680 --> 00:56:17.480
is, while there's hyperparameter searches,


00:56:17.480 --> 00:56:19.160
one of the worst things you can do,


00:56:19.160 --> 00:56:22.480
both in terms of pure ML performance


00:56:22.480 --> 00:56:25.400
and carbon emissions is grid search, for instance.


00:56:25.400 --> 00:56:26.800
So maybe just don't do that.


00:56:26.800 --> 00:56:31.960
If you're lazy, just do a random hyperparameter search,


00:56:31.960 --> 00:56:33.960
or if you don't have a good metric,


00:56:33.960 --> 00:56:36.360
or use Bayesian optimizers and so on


00:56:36.360 --> 00:56:38.240
to look for those hyperparameters.


00:56:38.240 --> 00:56:41.560
Another thing that is not mentioned in that paper,


00:56:41.560 --> 00:56:43.360
but I think is still very important,


00:56:43.360 --> 00:56:46.480
and that cycles back to one of your first questions


00:56:46.480 --> 00:56:47.680
about inference versus training,


00:56:47.680 --> 00:56:49.760
is there are many methods out there,


00:56:49.760 --> 00:56:54.120
pruning, distillation, quantization,


00:56:54.120 --> 00:56:59.120
all that zoo of tools and techniques and algorithms


00:56:59.120 --> 00:57:03.640
to optimize your model.


00:57:03.640 --> 00:57:06.640
And if you're happy with your current model,


00:57:06.640 --> 00:57:09.160
chances are there are many techniques out there


00:57:09.160 --> 00:57:14.120
that can reduce its size and computational complexity


00:57:14.120 --> 00:57:15.480
by multiple factors.


00:57:16.800 --> 00:57:21.120
So if you're going to put a product out there with hundreds,


00:57:21.120 --> 00:57:25.560
thousands, millions of inferences,


00:57:25.560 --> 00:57:27.080
maybe just think about that.


00:57:27.080 --> 00:57:32.840
I expect people who deploy such tools do think about that.


00:57:32.840 --> 00:57:36.000
If you're deploying a tool for millions,


00:57:36.000 --> 00:57:37.920
it's in your interest to think about it.


00:57:37.920 --> 00:57:39.500
Because it's also going to be cheaper.


00:57:39.500 --> 00:57:43.280
You're probably thinking more about it in terms of just time.


00:57:43.280 --> 00:57:45.920
Time to train, time to get an answer.


00:57:45.920 --> 00:57:49.160
But that also is exactly lining up with energy consumed.


00:57:49.160 --> 00:57:53.240
So, you know, CO2 reduction comes along for the ride.


00:57:53.240 --> 00:57:55.480
- Yeah, it's often the case that if you invest


00:57:55.480 --> 00:57:58.520
in ecological solutions,


00:57:58.520 --> 00:58:00.880
they are gonna end up being economical to you.


00:58:00.880 --> 00:58:02.760
- Yeah.


00:58:02.760 --> 00:58:05.680
- Jonathan, it's more of your area.


00:58:05.680 --> 00:58:06.520
- Oh, definitely.


00:58:06.520 --> 00:58:08.360
- Maybe that's another way to go to you.


00:58:08.360 --> 00:58:09.960
- Oh, I couldn't underscore that more.


00:58:09.960 --> 00:58:11.120
I think, you know, something that I think


00:58:11.120 --> 00:58:14.120
that has come out of our results that we've seen


00:58:14.120 --> 00:58:16.720
is that there's not a strictly linear trade-off


00:58:16.720 --> 00:58:19.880
between energy usage and accuracy, for example.


00:58:19.880 --> 00:58:22.360
There's often, there's a shoulder usually there


00:58:22.360 --> 00:58:25.200
and finding that shoulder using code carbon


00:58:25.200 --> 00:58:28.760
to figure out, you know, if I throw, you know,


00:58:28.760 --> 00:58:33.080
this fraction of a kilogram of CO2 at this problem,


00:58:33.080 --> 00:58:34.680
I'm actually gonna get a lower accuracy


00:58:34.680 --> 00:58:36.820
than if I had stopped beforehand.


00:58:36.820 --> 00:58:39.960
So using a tool to figure out, you know, where that is,


00:58:39.960 --> 00:58:41.360
I think is very helpful.


00:58:41.360 --> 00:58:43.640
And so just being aware of the impact of it


00:58:43.640 --> 00:58:47.520
trying to maximize for accuracy and not just energy usage.


00:58:47.520 --> 00:58:49.520
- Right, yeah, one of the things you called out


00:58:49.520 --> 00:58:52.140
is more energy, which means more emissions,


00:58:52.140 --> 00:58:53.960
is not necessarily more accuracy.


00:58:53.960 --> 00:58:55.800
- Yes. - Adding on


00:58:55.800 --> 00:58:57.800
more particular solution, for example,


00:58:57.800 --> 00:59:00.360
when you're doing a hyper parameter search,


00:59:00.360 --> 00:59:03.040
which is basically, are you doing the combination


00:59:03.040 --> 00:59:06.480
of numbers of variables and try to find the best combination


00:59:06.480 --> 00:59:11.480
to get the best results, the best, more precise model


00:59:11.600 --> 00:59:14.280
or whatever metrics you are optimizing for,


00:59:14.280 --> 00:59:17.400
you will likely, most of the machine learning libraries


00:59:17.400 --> 00:59:19.000
have an option to do early stop.


00:59:19.000 --> 00:59:23.600
Like instead of doing training new model for four days


00:59:23.600 --> 00:59:26.960
for all hundreds and thousands of combination,


00:59:26.960 --> 00:59:31.560
you train 10 of them for one day


00:59:31.560 --> 00:59:33.200
and then you see how it evolve.


00:59:33.200 --> 00:59:38.200
And if you take only two best of them and try again,


00:59:39.120 --> 00:59:44.120
you can reduce your training time and emission


00:59:44.120 --> 00:59:46.400
by a lot of percentage.


00:59:46.400 --> 00:59:51.400
And on other protocol, you can also move all known,


00:59:51.400 --> 00:59:54.140
all the code that doesn't need GPU


00:59:54.140 --> 00:59:56.520
to run something somewhere else, like for CPU,


00:59:56.520 --> 00:59:57.560
then you store it on disk,


00:59:57.560 --> 01:00:00.400
it's still emitting less emission


01:00:00.400 --> 01:00:04.200
than not using the GPU on your server,


01:00:04.200 --> 01:00:07.280
and try to use your GPU better,


01:00:07.280 --> 01:00:10.840
even by training more model on the same GPU


01:00:10.840 --> 01:00:14.420
or changing your model to be more efficient


01:00:14.420 --> 01:00:17.940
to train in less time.


01:00:17.940 --> 01:00:20.860
- Interesting. - And one of the things


01:00:20.860 --> 01:00:22.260
that we've also advocated for,


01:00:22.260 --> 01:00:23.760
and it can sound a little naive,


01:00:23.760 --> 01:00:26.980
but as Jonathan said earlier,


01:00:26.980 --> 01:00:28.220
this field has been moving fast,


01:00:28.220 --> 01:00:31.840
is to publish and be transparent about those things.


01:00:31.840 --> 01:00:36.140
And I think if the community shows interest


01:00:36.140 --> 01:00:41.140
and shows that it is one of the broader impact features


01:00:41.140 --> 01:00:46.060
that they look for when they think about the systems


01:00:46.060 --> 01:00:47.860
they create and deploy.


01:00:47.860 --> 01:00:53.740
I think it's also something that can spread in other areas


01:00:53.740 --> 01:00:56.740
than just your very specific niche of research.


01:00:56.740 --> 01:00:59.180
And since I'm thinking about the research community here,


01:00:59.180 --> 01:01:03.660
but 'cause that's my environment,


01:01:03.660 --> 01:01:09.220
But I think it's also the case in the industry.


01:01:09.220 --> 01:01:10.820
>> Yeah.


01:01:10.820 --> 01:01:12.380
Another thing that you all talked about


01:01:12.380 --> 01:01:17.220
is if you're computing locally, so maybe at your university


01:01:17.220 --> 01:01:20.780
or in your house these days is probably where you are,


01:01:20.780 --> 01:01:25.300
the local energy infrastructure matters, right?


01:01:25.300 --> 01:01:26.180
>> It does.


01:01:26.180 --> 01:01:26.700
It does.


01:01:26.700 --> 01:01:30.700
For example, Quebec has an average of, I think,


01:01:30.700 --> 01:01:34.820
20 grams of CO2 per kilowatt hour or something,


01:01:34.820 --> 01:01:39.820
which is probably 40 times lower than some other regions.


01:01:39.820 --> 01:01:42.540
You can check the, well, no,


01:01:42.540 --> 01:01:44.780
'cause Quebec doesn't share their data with electricity,


01:01:44.780 --> 01:01:47.500
it's a shame, but you can see other,


01:01:47.500 --> 01:01:52.020
if you just compare the results in Europe, for instance,


01:01:52.020 --> 01:01:54.020
and you look for France, which is--


01:01:54.020 --> 01:01:56.940
- Like France versus Germany, yeah.


01:01:56.940 --> 01:01:59.700
- Yeah, it has a nuclear electricity grid,


01:01:59.700 --> 01:02:00.700
mostly France, right?


01:02:00.700 --> 01:02:03.620
So if you compare France to Germany,


01:02:03.620 --> 01:02:04.460
it's gonna be very different.


01:02:04.460 --> 01:02:08.540
- 95% low carbon, that's well done France.


01:02:08.540 --> 01:02:09.440
Good job Boris.


01:02:09.440 --> 01:02:13.820
- And, but even if you, I think if you click on Germany,


01:02:13.820 --> 01:02:19.220
what you'll see is you might have a time series somewhere


01:02:19.220 --> 01:02:20.500
for the last 24 hours.


01:02:20.500 --> 01:02:22.540
- At least have this nice breakdown over here.


01:02:22.540 --> 01:02:23.380
- You have that and, right.


01:02:23.380 --> 01:02:24.540
- Yeah, you can move it over.


01:02:24.540 --> 01:02:26.740
Yeah, there's your time series.


01:02:26.740 --> 01:02:30.260
- Right, so you can even see that during the day,


01:02:30.260 --> 01:02:31.100
it's not the same.


01:02:31.100 --> 01:02:33.540
And just like your electricity provider


01:02:33.540 --> 01:02:38.060
will charge you differently for different times of usage,


01:02:38.060 --> 01:02:42.760
like high demand or lower demand times of the day,


01:02:42.760 --> 01:02:45.420
and like carbon emissions are also gonna have


01:02:45.420 --> 01:02:47.780
that kind of variation that you could care for.


01:02:47.780 --> 01:02:53.660
- Yeah, one thing I wanted to give a quick shout out to,


01:02:53.660 --> 01:02:56.500
I don't know about different locations.


01:02:56.500 --> 01:02:59.300
Here in Portland, one of the options we have


01:02:59.300 --> 01:03:02.540
is to choose a slightly different energy choice.


01:03:02.540 --> 01:03:07.540
If we pay $6 more per month, or $11 as a small business,


01:03:07.540 --> 01:03:10.320
it will basically be wind and solar.


01:03:10.320 --> 01:03:15.040
And if your local grid offers something


01:03:15.040 --> 01:03:16.780
where you literally pay $6


01:03:16.780 --> 01:03:18.180
and it can dramatically change it,


01:03:18.180 --> 01:03:21.640
like, do the world a favor, opt in.


01:03:21.640 --> 01:03:25.540
- Yeah, and we have the equivalent in France also.


01:03:25.540 --> 01:03:31.260
Same in the United States, there's a patchwork of different state laws that mandate that


01:03:31.260 --> 01:03:34.500
these options are made available to people.


01:03:34.500 --> 01:03:36.660
So yeah, definitely take advantage of it.


01:03:36.660 --> 01:03:37.660
Yeah.


01:03:37.660 --> 01:03:40.140
Yeah, it's, I mean, it literally is a checkbox.


01:03:40.140 --> 01:03:42.860
Do you want to have this yes or no and a small fee?


01:03:42.860 --> 01:03:46.260
And they probably, you know, honestly, probably what's happening when you check that box,


01:03:46.260 --> 01:03:49.580
like some of that energy would have just gone to the general grid and now it's promised


01:03:49.580 --> 01:03:50.580
to you.


01:03:50.580 --> 01:03:54.060
But soon as enough people check that box to go beyond the capacity, then that's going


01:03:54.060 --> 01:03:57.300
to be an economic driver to make more of it happen.


01:03:57.300 --> 01:04:01.260
So hopefully, we can get there.


01:04:01.260 --> 01:04:02.720
Although I suspect data centers are


01:04:02.720 --> 01:04:05.620
where the majority of the computation happens.


01:04:05.620 --> 01:04:14.980
I mean, I'm not backing this by any knowledge here.


01:04:14.980 --> 01:04:16.300
It's just my personal perception.


01:04:16.300 --> 01:04:19.060
But I feel like it's too little.


01:04:19.060 --> 01:04:21.020
This is too cheap.


01:04:21.020 --> 01:04:25.340
How come it's so cheap?


01:04:25.340 --> 01:04:27.900
So many things in our data lab should actually


01:04:27.900 --> 01:04:32.140
be more expensive if we knew how much energy and resources


01:04:32.140 --> 01:04:34.260
and how much they cost the environment.


01:04:34.260 --> 01:04:37.500
So it feels like it's a no-brainer when it's so easy


01:04:37.500 --> 01:04:39.060
and it's so cheap in this case.


01:04:39.060 --> 01:04:43.660
But how many other areas of our data lab and consumptions


01:04:43.660 --> 01:04:45.380
have those classes?


01:04:45.380 --> 01:04:47.780
Would you pay three times as much to fly?


01:04:47.780 --> 01:04:50.500
Would you pay $3,000 a go from France to Portland


01:04:50.500 --> 01:04:57.380
than $1,000 or whatever, that's a harder thing than checking a $6 box. Yeah, and probably a


01:04:57.380 --> 01:05:03.860
harder problem. But luckily, we're talking about computers and ML and not air transportation. So


01:05:03.860 --> 01:05:08.580
you don't have to solve it here. We'll do that next time. Speaking of solving it here,


01:05:08.580 --> 01:05:10.820
what's next? Where are things going for you all in the future?


01:05:13.300 --> 01:05:20.100
So I'm a PhD student at Miller in Montral, so it's Quebec's AI institute.


01:05:20.100 --> 01:05:27.300
So I feel like I'm going to stay there for at least two or three more years until I finish this PhD and then we'll see.


01:05:27.300 --> 01:05:32.300
Yeah. But the other two, where are you going with this project?


01:05:32.300 --> 01:05:35.300
Oh, that was about the project. I'm sorry, I missed the point.


01:05:35.300 --> 01:05:36.300
Also, yeah.


01:05:36.300 --> 01:05:40.300
Yeah, I think that we've got some things on the horizon.


01:05:40.300 --> 01:05:45.300
One is that the other part sort of under the hood


01:05:45.300 --> 01:05:51.220
that's kind of complicated is deriving the energy mix


01:05:51.220 --> 01:05:54.620
and getting the CO2 intensity of the energy grid


01:05:54.620 --> 01:05:55.740
from the energy mix.


01:05:55.740 --> 01:05:58.860
So figuring out, okay, if you know you have X percent


01:05:58.860 --> 01:06:02.780
natural gas, X percent coal and X percent oil,


01:06:02.780 --> 01:06:04.980
how does that translate into CO2 emissions?


01:06:04.980 --> 01:06:08.060
And that's actually an extremely complicated problem


01:06:08.060 --> 01:06:11.380
to answer because we have different chemical compositions


01:06:11.380 --> 01:06:13.860
of coal around the world, for example.


01:06:13.860 --> 01:06:18.060
Coal that comes out of Kentucky has a different CO2 impact


01:06:18.060 --> 01:06:21.620
per joule from combustion than coal that comes out


01:06:21.620 --> 01:06:22.780
of Wyoming, for example.


01:06:22.780 --> 01:06:25.180
So we've got all these different layers to figure out.


01:06:25.180 --> 01:06:29.180
Well, you've got like oil sands of Canada versus Saudi Arabia


01:06:29.180 --> 01:06:29.980
or whatever, right?


01:06:29.980 --> 01:06:30.660
Exactly.


01:06:30.660 --> 01:06:31.180
Yeah.


01:06:31.180 --> 01:06:34.420
And all of these sort of chemical differences matter,


01:06:34.420 --> 01:06:36.220
and they reflect different efficiencies.


01:06:36.220 --> 01:06:39.540
and that's not even getting into the difference in hardware


01:06:39.540 --> 01:06:40.620
in different power plants.


01:06:40.620 --> 01:06:44.420
So what we want to do is we want to actually dive in a bit deeper


01:06:44.420 --> 01:06:48.220
and get at some of these regional differences in carbon intensity


01:06:48.220 --> 01:06:50.860
and plug them into the dataset here


01:06:50.860 --> 01:06:54.540
so that we can refine our estimates as much as possible.


01:06:54.540 --> 01:06:59.780
Yeah, and shout out to the cloud providers,


01:06:59.780 --> 01:07:01.140
provide more data.


01:07:01.140 --> 01:07:04.300
To the CPU providers, provide more hooks,


01:07:04.300 --> 01:07:05.380
things like that, right?


01:07:05.380 --> 01:07:08.720
My hope for the project is that in a few years,


01:07:08.720 --> 01:07:10.840
we don't need this project anymore.


01:07:10.840 --> 01:07:13.880
Because we are doing estimation of estimation of estimation,


01:07:13.880 --> 01:07:17.680
and there are better people in the industry,


01:07:17.680 --> 01:07:21.480
cloud providers and hardware vendors


01:07:21.480 --> 01:07:26.320
that are better suited to get more precise data.


01:07:26.320 --> 01:07:31.540
But until then, I hope that the project can help companies


01:07:31.540 --> 01:07:34.640
be aware of their mission, take action on that,


01:07:34.640 --> 01:07:38.920
and allow the project to be more precise


01:07:38.920 --> 01:07:43.120
and give some estimation range for everything we are measuring.


01:07:43.120 --> 01:07:46.560
I feel like there are five to ten companies in the world


01:07:46.560 --> 01:07:49.360
that can control all of the information you have.


01:07:49.360 --> 01:07:53.720
So we've got Intel, AMD, Apple for the chips,


01:07:53.720 --> 01:07:57.760
we've got AMD and NVIDIA for the cards,


01:07:57.760 --> 01:08:01.680
and Azure, AWS, GCP.


01:08:01.680 --> 01:08:05.480
Like, if they all provided more information,


01:08:05.480 --> 01:08:09.360
then this would be not much of an estimate, more of a measure.


01:08:09.360 --> 01:08:13.520
So a couple of comments from the live stream.


01:08:13.520 --> 01:08:15.960
Corey Adkin says, thank you all.


01:08:15.960 --> 01:08:18.720
I've recommended this package to my ML team, which is awesome.


01:08:18.720 --> 01:08:19.240
And then--


01:08:19.240 --> 01:08:20.200
Thank you, Corey.


01:08:20.200 --> 01:08:22.560
Yeah, and then Ryan Clark says, the efficiency


01:08:22.560 --> 01:08:25.400
varies widely between countries and whatnot.


01:08:25.400 --> 01:08:27.800
But you sort of addressed that already


01:08:27.800 --> 01:08:32.120
with your comment about trying to work


01:08:32.120 --> 01:08:34.400
to understand the different sources and how they,


01:08:34.400 --> 01:08:36.120
even though they both look like coal, for example,


01:08:36.120 --> 01:08:37.600
they're actually not the same.


01:08:37.600 --> 01:08:41.000
- Yeah, it's a really great question.


01:08:41.000 --> 01:08:43.120
And it really is something that,


01:08:43.120 --> 01:08:44.860
we've relied on data from the US


01:08:44.860 --> 01:08:47.180
because we have the highest resolution of this


01:08:47.180 --> 01:08:51.980
and of the CO2 impact per energy consumed.


01:08:51.980 --> 01:08:54.360
And we have the most transparency about the numbers.


01:08:54.360 --> 01:08:55.640
It's not just a number,


01:08:57.560 --> 01:09:00.280
in the end of a report or a footnote of a report,


01:09:00.280 --> 01:09:04.120
we can actually trace it and do some due diligence on that.


01:09:04.120 --> 01:09:05.640
So we've used those numbers,


01:09:05.640 --> 01:09:09.640
but if anybody listening to this or hearing this


01:09:09.640 --> 01:09:12.020
has a connection with any of those companies,


01:09:12.020 --> 01:09:13.160
the hardware companies,


01:09:13.160 --> 01:09:14.880
or knows how to get more energy data,


01:09:14.880 --> 01:09:17.760
we are always looking for collaborators and contributors.


01:09:17.760 --> 01:09:19.720
So please reach out to us.


01:09:19.720 --> 01:09:21.200
- Yeah, fantastic.


01:09:21.200 --> 01:09:23.800
All right, I know we're pretty much


01:09:23.800 --> 01:09:25.060
at the end of our time together.


01:09:25.060 --> 01:09:27.520
So let me just ask you one really quick question.


01:09:27.520 --> 01:09:32.000
So I have a thing I wanna, a model I wanna train.


01:09:32.000 --> 01:09:33.640
So I'm gonna fire up a Docker image,


01:09:33.640 --> 01:09:35.600
maybe a set of them on Kubernetes,


01:09:35.600 --> 01:09:37.960
and I kick them off, let them go do their thing.


01:09:37.960 --> 01:09:40.340
Then I'm gonna come back next week, have another idea.


01:09:40.340 --> 01:09:41.440
Then I'm gonna train up some more things.


01:09:41.440 --> 01:09:43.440
Maybe my colleague is doing the same.


01:09:43.440 --> 01:09:46.440
This is gonna generate a bunch of a mission.csv files.


01:09:46.440 --> 01:09:49.560
How do I correlate?


01:09:49.560 --> 01:09:51.840
How do I put these all together so that I can see like,


01:09:51.840 --> 01:09:54.440
as a team, this month is here we are.


01:09:54.440 --> 01:09:56.720
Is that something that happens?


01:09:56.720 --> 01:10:00.420
So I'm really glad you asked this question


01:10:00.420 --> 01:10:02.740
because this is something we're working on.


01:10:02.740 --> 01:10:07.740
So currently I think you can just sum up those CSV files.


01:10:07.740 --> 01:10:09.700
- I think it's up to you to track and like say,


01:10:09.700 --> 01:10:11.820
okay, here's when we're sending in from this route.


01:10:11.820 --> 01:10:12.660
- Yeah.


01:10:12.660 --> 01:10:13.480
- Okay.


01:10:13.480 --> 01:10:16.540
- CSV files have a lot of downsides.


01:10:16.540 --> 01:10:19.700
It's less object oriented and you could have a JSON file


01:10:19.700 --> 01:10:21.340
that would be more structured and so on,


01:10:21.340 --> 01:10:23.540
but at least it's very easily.


01:10:23.540 --> 01:10:24.380
- It's super easy.


01:10:24.380 --> 01:10:25.820
- And you can just alternate them, right?


01:10:25.820 --> 01:10:27.460
- I think it's totally good actually.


01:10:27.460 --> 01:10:28.820
It's more about the,


01:10:28.820 --> 01:10:31.060
it's going to be transient files in lots of places.


01:10:31.060 --> 01:10:33.940
How do I put them into one place so I see it as a whole?


01:10:33.940 --> 01:10:34.860
Yeah.


01:10:34.860 --> 01:10:37.440
- So what we've been working on lately


01:10:37.440 --> 01:10:39.300
with a team of volunteers in France


01:10:39.300 --> 01:10:42.740
with the data for good that FR initiative


01:10:42.740 --> 01:10:47.100
is to create and deploy an API in a database.


01:10:47.100 --> 01:10:51.380
So we want to create this online storage of the time series


01:10:51.380 --> 01:10:54.100
and not just the final sum


01:10:54.100 --> 01:10:59.100
and have that in a hierarchy of ownership


01:10:59.100 --> 01:11:03.900
from the organization to the single run


01:11:03.900 --> 01:11:05.920
through teams and projects.


01:11:05.920 --> 01:11:10.100
That requires a lot of work.


01:11:10.100 --> 01:11:12.420
That requires deployment,


01:11:12.420 --> 01:11:16.480
that requires fans and sponsors to host that thing.


01:11:16.480 --> 01:11:19.940
That requires a lot of engineering.


01:11:19.940 --> 01:11:22.380
And I'm glad you asked that question


01:11:22.380 --> 01:11:29.420
Because I also wanted to have one word about open source and who's doing this.


01:11:29.420 --> 01:11:31.900
And it's all about volunteers.


01:11:31.900 --> 01:11:35.700
And no one is paid for that.


01:11:35.700 --> 01:11:42.340
And companies like Comet, or the Boston Consulting Group, who have been a partner for more than


01:11:42.340 --> 01:11:48.180
a year, do dedicate some software engineering time.


01:11:48.180 --> 01:11:49.820
And we need more collaborations.


01:11:49.820 --> 01:11:54.940
And if you think this tool is great and you want to use it, I think we would really appreciate


01:11:54.940 --> 01:11:59.820
if some of you had time to help because it's a small team of volunteers.


01:11:59.820 --> 01:12:05.660
And it's the same for most open source projects out there, and they need collaborators and


01:12:05.660 --> 01:12:08.300
contributors.


01:12:08.300 --> 01:12:12.860
And I think it's one of the things you can do also is help out.


01:12:12.860 --> 01:12:16.240
And most of it is pure Python, right?


01:12:16.240 --> 01:12:19.520
So chances are you're gonna be able to help.


01:12:19.520 --> 01:12:23.360
And, or if you don't know Python,


01:12:23.360 --> 01:12:25.280
there's some data collection issues


01:12:25.280 --> 01:12:27.520
and it's just about writing to a CSV file.


01:12:27.520 --> 01:12:30.640
You just gotta find the time to go fetch those numbers.


01:12:30.640 --> 01:12:33.360
There are data visualization issues


01:12:33.360 --> 01:12:34.800
to help improve the dashboard.


01:12:34.800 --> 01:12:38.520
And so it's never ending, so everyone's gonna help.


01:12:38.520 --> 01:12:40.360
- Yeah, it sounds like a really great project


01:12:40.360 --> 01:12:41.720
to get involved in if people are looking


01:12:41.720 --> 01:12:44.120
to find an open source thing to work on.


01:12:44.120 --> 01:12:46.440
- Yeah, and we're willing to onboard you,


01:12:46.440 --> 01:12:48.640
which also is sometimes--


01:12:48.640 --> 01:12:49.480
- Yeah, that's great.


01:12:49.480 --> 01:12:51.880
- Bumpy in open source projects.


01:12:51.880 --> 01:12:56.540
And I think, I mean, it's hard and there are hundreds


01:12:56.540 --> 01:12:57.760
of guides on how to contribute


01:12:57.760 --> 01:12:59.460
to open source projects out there.


01:12:59.460 --> 01:13:03.480
I think we want people, so like,


01:13:03.480 --> 01:13:07.360
we're gonna help you help us.


01:13:07.360 --> 01:13:09.040
- Yeah, very cool.


01:13:09.040 --> 01:13:09.960
I encourage people to do so.


01:13:09.960 --> 01:13:12.040
All right, final quick question before we get out of here.


01:13:12.040 --> 01:13:15.400
Brian Hermsen says, "I know this would be a big ask,


01:13:15.400 --> 01:13:18.940
"but I would love to see this as a built-in profiler


01:13:18.940 --> 01:13:21.360
"for CPU-intensive ML libraries."


01:13:21.360 --> 01:13:23.960
Yeah, that would be nice.


01:13:23.960 --> 01:13:25.880
- We just told you CPU's super hard.


01:13:25.880 --> 01:13:28.520
(laughing)


01:13:28.520 --> 01:13:32.380
Yeah, I mean, it's, yeah, I think this is gonna go beyond


01:13:32.380 --> 01:13:36.400
what we know and can do, but I agree with you.


01:13:36.400 --> 01:13:39.720
It should be part of more decisions


01:13:39.720 --> 01:13:42.620
in computer science in general and software engineering.


01:13:42.620 --> 01:13:45.120
- Yep. - And hardware engineering


01:13:45.120 --> 01:13:47.040
and everything.


01:13:47.040 --> 01:13:50.480
- All right, let me ask you all the final two questions


01:13:50.480 --> 01:13:52.560
really quickly since there's three of you.


01:13:52.560 --> 01:13:53.760
If you're gonna write some Python code,


01:13:53.760 --> 01:13:55.200
what editor do you use?


01:13:55.200 --> 01:13:58.560
- VS Code. - Me too.


01:13:58.560 --> 01:14:01.200
- Sublime, sorry guys.


01:14:01.200 --> 01:14:02.040
(laughing)


01:14:02.040 --> 01:14:03.600
- Right on, it's obvious. - I used to be a Sublime fan,


01:14:03.600 --> 01:14:06.160
but VS Code is good now.


01:14:06.160 --> 01:14:07.640
- I feel like a lot of the Sublime people


01:14:07.640 --> 01:14:11.720
have moved on to VS Code, but Sublime's so popular as well.


01:14:11.720 --> 01:14:15.000
Notable PyPI package, maybe some cool library


01:14:15.000 --> 01:14:18.520
that works with some of the things you're all interested in.


01:14:18.520 --> 01:14:21.000
Just quick, that maybe people haven't heard of.


01:14:21.000 --> 01:14:30.560
- I like Rich, which is a super flexible,


01:14:30.560 --> 01:14:34.320
colorful, versatile tool to print stuff


01:14:34.320 --> 01:14:42.320
instead of writing again and again the same quacky print functions.


01:14:42.320 --> 01:14:47.320
- They call it a TUI. A TUI. Is that it? Do they have it in there? A TUI.


01:14:47.320 --> 01:14:50.320
A Terminal Universal Interface. That's right. That's so good.


01:14:50.320 --> 01:14:52.320
- That's cool. - It's incredible.


01:14:52.320 --> 01:14:59.320
- Yeah. And I just want to also give a shout-out to the computational


01:14:59.320 --> 01:15:05.960
open source libraries like NumPy, scikit-learn, and Matplotlib, Pandas, and so on. Because


01:15:05.960 --> 01:15:11.720
those things run the data science world, and it's all open source, non-profits,


01:15:11.720 --> 01:15:19.960
and it's a few maintainers. And they deserve a lot of the credit for their recent advances.


01:15:19.960 --> 01:15:24.440
They definitely do. Boris or John, you either want to give a quick shout out to anything?


01:15:25.240 --> 01:15:29.800
if I will do some chainless marketing, I would say the Comet ML, Python SDK, but more


01:15:29.800 --> 01:15:39.720
I would say as a FastAPI or some basis library that everyone use, request, and even just the


01:15:39.720 --> 01:15:44.920
Python standard library, I know some CPython core developer that are doing a tremendous job.


01:15:44.920 --> 01:15:53.000
It's a St. Clair's job, so thank you to them. >> Yeah, for sure. Yeah, everything Boris and


01:15:53.000 --> 01:15:56.800
and Victor have recommended are great stuff.


01:15:56.800 --> 01:15:58.560
>>Victor: Yeah, fantastic.


01:15:58.560 --> 01:16:00.600
All right, well, final call to action.


01:16:00.600 --> 01:16:03.560
People out there are listening.


01:16:03.560 --> 01:16:05.160
They're doing machine learning.


01:16:05.160 --> 01:16:07.680
They want to be able to use this to measure their work


01:16:07.680 --> 01:16:08.840
and maybe make some change.


01:16:08.840 --> 01:16:09.480
What do you say?


01:16:09.480 --> 01:16:16.440
>>Juan: Use it, contribute, analyze, share.


01:16:16.440 --> 01:16:19.400
I think most of the thing you can do about climate change


01:16:19.400 --> 01:16:24.960
is spreading awareness, discussing those things,


01:16:24.960 --> 01:16:28.400
and challenging the status quo.


01:16:28.400 --> 01:16:32.040
Yeah, fantastic.


01:16:32.040 --> 01:16:34.800
All right, Boris, Victor, John, thank you all for being here.


01:16:34.800 --> 01:16:36.680
It's been really great to have you.


01:16:36.680 --> 01:16:38.000
Thanks so much for your time.


01:16:38.000 --> 01:16:39.600
Yeah, thanks for having us.


01:16:39.600 --> 01:16:41.280
Have a great day, everyone.


01:16:41.280 --> 01:16:43.400
Or evening, if you're in France.


01:16:43.400 --> 01:16:45.200
Exactly, bye all.


01:16:45.200 --> 01:16:46.760
Bye.

