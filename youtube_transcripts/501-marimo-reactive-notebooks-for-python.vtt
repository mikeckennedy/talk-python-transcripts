WEBVTT

00:00:00.800 --> 00:00:03.620
Akshay, welcome to Talk Python To Me. Awesome to have you here.

00:00:03.620 --> 00:00:05.800
Thanks, Michael. Really happy to be here.

00:00:05.800 --> 00:00:09.440
Yeah. It's data science hour, isn't it?

00:00:09.440 --> 00:00:11.760
Yeah, I guess it is.

00:00:11.760 --> 00:00:22.040
In a sense, but also in a sense kind of bringing data science a little closer to traditional formal computer science or more, I don't know.

00:00:22.040 --> 00:00:24.380
I don't know what to think about computer science. Software engineering.

00:00:24.720 --> 00:00:31.660
Software engineering. Yeah, that's our goal. Blending data science with sort of the rigor of reproducibility of software engineering.

00:00:31.660 --> 00:00:38.140
Yeah. And I think people are going to find it pretty interesting. It's definitely gained a lot of traction lately.

00:00:38.140 --> 00:00:46.000
So it's going to be really fun to dive into Marimo. Before we do, though, who are you? What are you doing here? Tell people about yourself.

00:00:46.000 --> 00:00:52.420
Sure. So I'm Akshay. I'm one of the co-founders and developers of Marimo.

00:00:53.020 --> 00:01:03.380
I started working on Marimo a few years ago, I guess, a little over two years ago, right after I finished a PhD at Stanford where I was working on machine learning research.

00:01:03.380 --> 00:01:07.420
And before that, I was at Google Brain where I worked on TensorFlow.

00:01:08.480 --> 00:01:21.580
And I guess for the past several years, I've been wearing different hats, either a computer systems hat where I build open source software and domain specific languages for people who do machine learning or I just do machine learning.

00:01:21.700 --> 00:01:35.960
And for the past few years, it's been the first hat. So working on the Marimo notebook, which is our attempt to blend the best parts of interactive computing with the reusability and reproducibility of regular Python software.

00:01:35.960 --> 00:01:42.840
Well, that's very cool. You've been right at the cutting edge of this whole machine learning thing, I guess, right?

00:01:42.840 --> 00:01:48.560
If you go back a handful of years, it's different today than it was five years ago.

00:01:48.560 --> 00:01:53.700
Oh, yeah, it's very different. I was at Google Brain 2017 to 2018.

00:01:54.400 --> 00:02:00.120
So I think we had Transformers, but we didn't really appreciate all that they could do.

00:02:00.120 --> 00:02:00.780
Yeah.

00:02:00.780 --> 00:02:11.660
But it was a really exciting time to be at Google Brain where it was pure research, just like one that you could just work on anything that you wanted to work on.

00:02:11.660 --> 00:02:21.620
And I was an engineer there on a small sub team inside of TensorFlow where we were working on TensorFlow 2, which is sort of making TensorFlow more like PyTorch crudely.

00:02:21.720 --> 00:02:29.320
And that was a lot of fun, but yeah, got to go to like a bunch of talks by researchers and it was a special time for sure.

00:02:29.320 --> 00:02:30.720
Yeah, I bet it was.

00:02:30.720 --> 00:02:34.500
Well, you know, that's such an interesting background.

00:02:34.500 --> 00:02:42.640
I think maybe give people a sense of what is Google Brain and all that and maybe just Transformers, right?

00:02:42.640 --> 00:02:50.440
It's the foundation of so much surprising and unexpected tech these days.

00:02:51.380 --> 00:02:52.900
Yeah, yeah, I'm happy to.

00:02:52.900 --> 00:02:55.280
So Google Brain, what is Google Brain?

00:02:55.280 --> 00:02:59.240
So I guess technically Google Brain no longer exists as it did back then.

00:02:59.240 --> 00:03:01.800
Now it's just DeepMind with DeepMind and Google Brain merged.

00:03:01.800 --> 00:03:09.180
But back then, Google Brain was, so there was, I guess, two research orders under the alphabet umbrella, Google Brain and DeepMind.

00:03:11.420 --> 00:03:14.600
And Google Brain was a place where it was really special.

00:03:14.600 --> 00:03:23.480
There were folks working on all kinds of research projects from you, like using Transformers for code generation, but also like systems research projects.

00:03:23.580 --> 00:03:32.700
Like I was there when the Jack's machine learning library, which is an alternative to TensorFlow and PyTorch, was still being in the early days of development.

00:03:32.700 --> 00:03:37.320
And I was able to meet with like Roy Frostig, Matt Johnson.

00:03:37.320 --> 00:03:43.840
And that was really cool sort of coming up to speed on machine learning systems in that era.

00:03:45.320 --> 00:03:59.220
I was only there for a year because I decided I wanted to go back and do a PhD myself in machine learning research where I used actually TensorFlow and PyTorch to work on new sort of like machine learning modules.

00:03:59.980 --> 00:04:01.580
Did you feel bad when you used PyTorch?

00:04:01.580 --> 00:04:02.660
You're like, oh, I'm cheating.

00:04:02.660 --> 00:04:04.100
No, no.

00:04:04.100 --> 00:04:06.060
I mean, a little, I guess.

00:04:06.060 --> 00:04:09.820
But, you know, it's the thing like everyone else used PyTorch.

00:04:09.820 --> 00:04:15.060
And we had just started working on TensorFlow 2 when I joined, whereas PyTorch had already been mature.

00:04:15.060 --> 00:04:19.140
So it was the responsible thing to do, I think.

00:04:19.140 --> 00:04:23.480
And Transformers, what are these Transformer things?

00:04:23.480 --> 00:04:25.220
They came out of Google, right?

00:04:25.220 --> 00:04:26.760
Yeah, yeah, they did.

00:04:26.760 --> 00:04:28.120
Attention is all you need.

00:04:29.640 --> 00:04:35.380
These Transformer things, I guess, are the backbone of all these large language models that we're seeing today.

00:04:35.380 --> 00:04:46.100
And they proved to have like an incredible capacity for modeling, I guess, in a generative way, all kinds of text.

00:04:46.100 --> 00:04:50.000
And in a way that, honestly, if I had to admit, like surprised me.

00:04:50.000 --> 00:04:55.760
Like at the time in 27 to 18, like we were doing good work in like machine translation and stuff.

00:04:56.440 --> 00:05:07.320
But even back then, you know, there was researchers who were working on at Google Brain, like, you know, code generation, like writing a bunch of unit tests, stuff that people do regularly today, actually, with large language models.

00:05:08.860 --> 00:05:13.540
I put on my systems engineer hat back then, and I was a little skeptical, to be honest.

00:05:13.540 --> 00:05:15.220
And I've just totally proved wrong.

00:05:15.220 --> 00:05:16.680
And I'm happy to have been proved wrong.

00:05:17.400 --> 00:05:23.360
So it's been phenomenal seeing sort of that, the success of that particular model.

00:05:25.240 --> 00:05:28.000
And yeah, having played a small part in it.

00:05:28.000 --> 00:05:35.320
Yeah, I've been a long time skeptic of machine learning in the sense that for so long, it was kind of like fusion.

00:05:35.320 --> 00:05:40.000
It's going to be amazing, but it's 10, 20, 30 years out.

00:05:40.000 --> 00:05:48.600
And maybe, you know, and it was all almost like knowledge, knowledge-based type things.

00:05:48.800 --> 00:05:56.080
And just, I mean, it was interesting, it looked kind of relevant and possibly useful in some of the cases, but not like it is today.

00:05:56.080 --> 00:06:03.520
Like today, people don't even care about technology, are blown away by this stuff, and they use it all day long.

00:06:03.520 --> 00:06:08.800
And it's gone so much farther and so much faster than I expected it to.

00:06:08.800 --> 00:06:12.260
I'm all about it these days.

00:06:12.260 --> 00:06:24.180
I use, I still write most of my code, but anytime there's something tricky, instead of going to Google and hunting through Stack Overflow, let's see what chat says about it or something like that.

00:06:24.180 --> 00:06:27.800
And then maybe we'll go to Google if we don't get a good answer, you know?

00:06:27.800 --> 00:06:29.400
Yeah, no, no, I'm the same way.

00:06:29.400 --> 00:06:45.920
I spent more time than I care to admit last night migrating from Vim to NeoVim, and I know I'm late to the party, but perplexity and other tools just made it a lot easier to start from scratch installation without bringing over my VimRC.

00:06:45.920 --> 00:06:50.520
And you can ask it detailed questions, right?

00:06:50.640 --> 00:06:56.820
For example, I needed some way to reset the initial offset in DaVinci Resolve timelines.

00:06:56.820 --> 00:07:00.740
It was, okay, well, here's your four options, and these are the way you can do it, and these are the tradeoffs.

00:07:00.740 --> 00:07:06.360
It's not just you might get an, you know, here is the switch, but you get an analysis.

00:07:06.360 --> 00:07:08.820
And I'm pretty impressive.

00:07:08.820 --> 00:07:14.060
So the reason I'm going into this is I want to ask you, having been on the inside at the early days,

00:07:14.440 --> 00:07:22.840
what is your perspective of seeing this trajectory, or trajectory is the way I should put it, you know, upwards, not logarithmic?

00:07:22.840 --> 00:07:23.080
Yeah.

00:07:23.080 --> 00:07:31.180
I guess what I will say is I think one thing that's, like, really changed, like, so back when I was at Brain,

00:07:31.180 --> 00:07:36.700
even though models were advanced, like, I felt like in order to use machine learning well,

00:07:36.700 --> 00:07:40.840
you really did need to be somewhat trained in machine learning.

00:07:40.840 --> 00:07:45.580
You know, like, it was important to understand what a loss function, like, basic things, like, what a loss function was,

00:07:45.580 --> 00:07:47.660
what's training, what's validation.

00:07:47.660 --> 00:07:52.140
These days, like, you don't need to, like, at all, actually.

00:07:52.140 --> 00:07:54.400
I think I especially didn't use LLMs, right?

00:07:54.400 --> 00:07:57.580
Like, you just need to know inputs and outputs.

00:07:57.580 --> 00:08:00.060
It's like a function call that sort of has fuzzy outputs.

00:08:00.060 --> 00:08:02.820
You know, it's a mathematical function, in quotes.

00:08:02.820 --> 00:08:03.900
Yeah.

00:08:03.900 --> 00:08:14.960
So I think, like, that's, like, one thing that's, like, totally, I guess it kind of shows that artificial intelligence is transitioning more from, I guess, like, a science to a technology,

00:08:14.960 --> 00:08:21.520
and that tool that people can just, like, readily use without really needing to understand how it works.

00:08:22.860 --> 00:08:27.540
As for the trajectory, I've been bad at making predictions in the past.

00:08:27.540 --> 00:08:30.620
I think I would be bad at predicting anything right now.

00:08:30.620 --> 00:08:45.660
Surely, these models are, you know, very good for coding, for massaging, marketing, copy, and, like, you know, I do, like, random tasks where, like, I have a bio I wrote in first person,

00:08:45.660 --> 00:08:50.260
and someone asks for it in third person, and I'm too lazy to change, and I just give it to a chat model.

00:08:50.260 --> 00:08:51.540
Yeah.

00:08:51.540 --> 00:08:59.100
But if you ask for a trajectory of AGI or ASI, which I don't even remember what the S stands for these days,

00:08:59.100 --> 00:09:03.080
but I'm not sure I can predict anything on those timelines.

00:09:03.080 --> 00:09:04.720
Yeah.

00:09:04.720 --> 00:09:05.440
I hear you.

00:09:05.440 --> 00:09:07.940
I'm with you on the prediction.

00:09:08.600 --> 00:09:16.040
But I would say that the adoption and effectiveness of it has far outpaced what I would have guessed five years ago.

00:09:16.040 --> 00:09:16.580
Yeah.

00:09:16.580 --> 00:09:20.720
I mean, even local models, like, it's kind of exciting, like, what you can just run on your MacBook.

00:09:20.720 --> 00:09:23.520
I also didn't really anticipate that.

00:09:23.520 --> 00:09:25.700
Yeah.

00:09:25.700 --> 00:09:26.660
All right.

00:09:26.660 --> 00:09:30.380
I don't want to make this the AI show because it's not about AI, but your background is so interesting.

00:09:30.380 --> 00:09:38.600
So when you were working initially on Transformers, did you, as a group, not you individually,

00:09:38.600 --> 00:09:43.400
you guys perceive the need for the scale of the computation?

00:09:43.400 --> 00:09:51.140
Like, you know, to train GPT-01, I don't know how much compute was involved,

00:09:51.140 --> 00:09:55.200
but probably more than cities use in terms of energy sometimes.

00:09:55.200 --> 00:09:55.840
You know what I mean?

00:09:55.840 --> 00:09:57.040
It was a lot.

00:09:58.540 --> 00:10:04.700
So how much compute were you all using back then versus now, I guess is what I'm getting at.

00:10:04.700 --> 00:10:09.760
So I guess, yeah, and I think you kind of said it, but just to clarify or to make it clear,

00:10:09.760 --> 00:10:12.540
that I personally didn't work on Transformers.

00:10:12.540 --> 00:10:13.680
I was working on TensorFlow.

00:10:13.680 --> 00:10:21.040
So, yeah, the, I guess, embedded DSL for training machine learning models that was used within Google.

00:10:21.040 --> 00:10:21.840
I'm still used today.

00:10:23.820 --> 00:10:36.900
I can't give you specific numbers, to be honest, because I was pretty deep in the systems part of working on TensorFlow and not paying too much attention for, like, standing up distributed clusters.

00:10:36.900 --> 00:10:43.780
Like, I did things like, you know, adding support to TensorFlow for, like, creating, like, a function library.

00:10:44.460 --> 00:10:48.680
TensorFlow is like a Dataflow graph engine, and it didn't have functions in it.

00:10:48.680 --> 00:10:52.200
So I added support for functions, partitioning functions over devices.

00:10:52.200 --> 00:10:56.060
But other teams used that work to go and train the big models.

00:10:56.060 --> 00:11:03.740
I know it was a lot of compute, but I, a lot versus a lot, you know, all caps versus, you know, just capital case.

00:11:04.740 --> 00:11:06.040
Yeah, I'm sure there's a delta.

00:11:06.040 --> 00:11:07.620
I just, I don't know how much.

00:11:07.620 --> 00:11:08.040
Yeah.

00:11:08.040 --> 00:11:14.160
Well, today they're all talking about restarting nuclear reactors and plugging them straight to the data center.

00:11:14.160 --> 00:11:15.500
So it's a weird time.

00:11:15.500 --> 00:11:20.220
Let's go back, maybe a little bit before then.

00:11:20.220 --> 00:11:25.300
2012 or so, I believe, is maybe the right time frame.

00:11:25.300 --> 00:11:27.360
And let's talk about notebooks.

00:11:28.160 --> 00:11:32.580
And, you know, around then, Jupyter notebooks burst on the scene.

00:11:32.580 --> 00:11:44.720
And I think they fundamentally changed the ecosystem of Python and basically scientific work in general, right?

00:11:44.720 --> 00:11:54.200
There's, I mean, by changing Python, I mean, there are so many people in Python who are here because they got pulled into a notebook.

00:11:54.200 --> 00:11:55.840
They wrote a little bit of code.

00:11:55.840 --> 00:11:57.400
They got incredible results.

00:11:57.400 --> 00:12:03.240
They were never, ever a programmer, but now they're the maintainer of an open source project or something like that.

00:12:03.240 --> 00:12:04.100
You know what I mean?

00:12:04.100 --> 00:12:07.100
They're just like, oh, this is kind of neat.

00:12:07.100 --> 00:12:09.840
Oh, I'll create a biology library or whatever.

00:12:09.840 --> 00:12:14.920
And then all of a sudden, you know, they're deep in it.

00:12:14.920 --> 00:12:19.200
And so Jupyter, I think, was really the start of that.

00:12:19.200 --> 00:12:21.840
Maybe there was some precursors that I'm not familiar with.

00:12:21.840 --> 00:12:26.580
Yeah, Jupyter was essentially the start of it, especially for Python.

00:12:26.580 --> 00:12:29.860
Like, I think the idea of computation on, yeah, notebooks has been around.

00:12:29.860 --> 00:12:36.280
But, yeah, the IPython REPL, I guess the IPython project with the IPython REPL, I think, was early 2000s.

00:12:36.280 --> 00:12:50.060
And Jupyter, I think you're right, like 2012-ish, as he's burst onto the scene with putting the IPython REPL into a web browser with multiple REPL cells.

00:12:50.280 --> 00:12:53.220
And all of a sudden, you could do more than what you could do in the console.

00:12:53.220 --> 00:12:54.720
And also made it a lot more accessible.

00:12:54.720 --> 00:12:55.940
Yeah.

00:12:55.940 --> 00:13:06.300
Going back to that sixth cell you entered on your REPL and editing it, that is not a way to draw beginners in.

00:13:07.240 --> 00:13:08.580
No, definitely not.

00:13:08.580 --> 00:13:10.460
Up arrow key six times, no.

00:13:10.460 --> 00:13:16.920
Yeah, 2012, coincidentally, is when I started college as an undergrad.

00:13:16.920 --> 00:13:24.860
So I had been using, I kind of grew up, as long as I used Python, I think I probably was using Jupyter Notebooks.

00:13:25.100 --> 00:13:31.460
And I even started using Google CoLab before it was made public, because when I was interning at Google.

00:13:31.460 --> 00:13:37.500
And I think the year I started working at Google full-time is when they made it public to the world.

00:13:37.500 --> 00:13:43.760
So, yeah, notebooks have sort of shaped the way that I think and interact with code quite a bit.

00:13:43.760 --> 00:13:46.100
Yeah, absolutely.

00:13:46.100 --> 00:13:51.960
So maybe you could give us some perspective.

00:13:51.960 --> 00:13:54.440
It sounds like you were there, like, right at the right time.

00:13:54.440 --> 00:14:02.280
You know, what was the goal and sort of the job of Jupyter Notebooks and those kinds of things then?

00:14:02.280 --> 00:14:05.460
And how has that changed now?

00:14:05.460 --> 00:14:09.060
And maybe how does it still solve that problem or not solve it so much?

00:14:09.060 --> 00:14:14.700
Yeah, I think, I think, so, so stepping back.

00:14:14.700 --> 00:14:24.600
So you mentioned, like, how many people who might not have traditionally, you know, worked with code sort of came into it because of Jupyter Notebooks.

00:14:24.600 --> 00:14:28.080
And I think that's, like, really, I think you're onto something there.

00:14:28.080 --> 00:14:28.840
I think that's correct.

00:14:28.920 --> 00:14:40.200
And I think the special thing about Notebooks is that they, like, mix code and visuals and, like, narrative text in, like, this interactive programming environment.

00:14:41.080 --> 00:14:46.420
And that interactivity in particular, I think, is really important for anyone who works with data.

00:14:46.420 --> 00:14:52.680
It's where you've got to, like, first, like, you know, run some queries against your data to see the general shape of it.

00:14:52.680 --> 00:14:59.300
You know, run some transformations to see, like, you know, basically, like, explore your data.

00:14:59.300 --> 00:15:00.980
Like, hold it in your hands, right?

00:15:00.980 --> 00:15:09.900
And, like, you know, repls before and then Jupyter Notebooks in particular lets you do that in a way that you just can't easily do in a script because it holds the variables in memory.

00:15:09.900 --> 00:15:20.920
And so I think the role that it played was that it enabled data scientists or computational scientists, biologists, astrophysicists, all these different types of people who work with data.

00:15:22.400 --> 00:15:34.100
It let them rapidly experiment with code and models and, importantly, get some kind of, like, artifact out of it.

00:15:34.100 --> 00:15:42.100
And in particular, this was, like, a static HTML-type artifact, right, where you have some text documenting what experiments you're running.

00:15:42.100 --> 00:15:47.960
You have Python code and then you have, like, matplotlib plots and other artifacts.

00:15:50.180 --> 00:15:58.000
And I think for, you know, for the sciences in particular early on, that was super important and transformative.

00:15:58.000 --> 00:16:01.620
And we were talking about other computational notebook environments.

00:16:01.620 --> 00:16:09.060
And it's interesting to mention this because, like, things like this existed sort of before, like, Mathematica's, like, workbooks, I think they called them.

00:16:09.060 --> 00:16:10.160
I might have done that wrong.

00:16:10.160 --> 00:16:17.520
But I think just, like, the open-source nature of Python and the accessibility of it just, like, made it way easier to get started.

00:16:17.860 --> 00:16:30.380
And also the fact that it was, like, browser-based, right, so that, like, you can easily share, like, these, the HTML artifacts that come out, I think was really transformative.

00:16:30.380 --> 00:16:34.680
And insofar as, like, what they're used for today, they're used for a lot.

00:16:34.680 --> 00:16:38.800
It's kind of remarkable how much they're used.

00:16:38.800 --> 00:16:47.780
Like, I remember seeing a statistic for Google Colab alone, which is just one particular hosted version of a Jupyter notebook.

00:16:47.780 --> 00:16:49.400
And it was two years ago.

00:16:49.400 --> 00:16:52.600
And they said something about, like, having 10 million monthly active users.

00:16:52.600 --> 00:16:58.360
And so the number of people who use Jupyter on a monthly basis is surely larger than that.

00:16:58.360 --> 00:16:59.360
Oh, yeah.

00:17:00.240 --> 00:17:11.640
And they're used for the sciences, but they're also used for, like, things where you want, like, the traditional rigor and reproducibility of software engineering.

00:17:11.640 --> 00:17:16.900
So they're increasingly used for, like, data pipelines and, like, ETL jobs.

00:17:17.020 --> 00:17:25.920
And, like, so anyone who's in Databricks, for example, runs, like, they call them workflows, Databricks workflows, through essentially Jupyter notebooks.

00:17:25.920 --> 00:17:29.720
They're used for training machine learning models.

00:17:29.720 --> 00:17:32.660
Like, I've trained many models in a Jupyter notebook.

00:17:32.660 --> 00:17:35.040
I've developed algorithms in Jupyter notebooks.

00:17:35.040 --> 00:17:39.680
I've produced scientific figures that go straight into my paper from a Jupyter notebook.

00:17:41.620 --> 00:17:50.740
And the reason people do this is because, again, the interactivity and, like, the visuals that come out is very liberating compared to using a script.

00:17:50.740 --> 00:17:52.460
But they also have...

00:17:52.460 --> 00:17:56.760
I think there's also a developing understanding that happens from them.

00:17:56.760 --> 00:18:02.120
Because when you're writing just a straight program, you're like, okay, this step, this step, this step, this step, and then we get the answer.

00:18:02.120 --> 00:18:05.700
Whereas notebooks, it's like step one, step two.

00:18:05.700 --> 00:18:06.740
Let me look at it.

00:18:06.740 --> 00:18:07.980
Oh, maybe that's different.

00:18:07.980 --> 00:18:09.300
Let me go back and change...

00:18:09.300 --> 00:18:13.180
It's more iterative from an exploratory perspective.

00:18:13.180 --> 00:18:14.240
Yeah.

00:18:14.240 --> 00:18:15.540
I think that's exactly right.

00:18:15.540 --> 00:18:15.880
Yeah.

00:18:15.880 --> 00:18:17.380
Yeah.

00:18:17.380 --> 00:18:23.200
Because you have that, like, that, you know, when you're writing, like, a software system, you kind of know the state of the system.

00:18:23.200 --> 00:18:25.220
You know what you want to change it to.

00:18:25.220 --> 00:18:29.120
But when you're working with data, there's that unknown, what will my algorithm do to my data?

00:18:29.120 --> 00:18:30.680
You just have to run it to find out.

00:18:30.680 --> 00:18:31.820
Yeah, absolutely.

00:18:31.820 --> 00:18:36.980
And graphs and tables and iterative stuff like that is really nice.

00:18:37.260 --> 00:18:42.620
So why create something instead of Jupyter?

00:18:42.620 --> 00:18:43.540
Right?

00:18:43.540 --> 00:18:45.420
Why is Jupyter not enough for the world?

00:18:45.420 --> 00:18:46.520
Yeah.

00:18:46.520 --> 00:18:48.860
I think there's a...

00:18:48.860 --> 00:18:54.960
So just, you know, you're the creator of Marimo, along with the rest of the team and so on.

00:18:54.960 --> 00:19:00.520
But yeah, it's like, why create this thing when Jupyter exists?

00:19:01.780 --> 00:19:02.140
Yeah.

00:19:02.140 --> 00:19:05.940
So I think there's quite a few reasons.

00:19:05.940 --> 00:19:16.180
So Jupyter notebooks are, like, I guess, more like Jupyter notebooks powered by the IPython kernel, just to put a finger on it.

00:19:16.180 --> 00:19:17.220
Right.

00:19:17.320 --> 00:19:18.080
Because it could be different.

00:19:18.080 --> 00:19:21.760
It could be like a C++ kernel or .NET kernel or whatever.

00:19:21.760 --> 00:19:22.260
Yeah.

00:19:22.260 --> 00:19:23.100
Yeah, exactly.

00:19:23.300 --> 00:19:32.100
But this particular form of notebooks where, like, where you get a page and then in the front end shows you a bunch of cells that you execute one at a time imperatively.

00:19:32.820 --> 00:19:37.500
Even though, like, you have a sequence of cells, it still is essentially a REPL.

00:19:37.500 --> 00:19:38.680
And, like, it's...

00:19:38.680 --> 00:19:49.280
The onus falls on the developer, the scientist, whoever's using it, to, like, run each cell on their own and, like, maintain the state of their kernel.

00:19:49.460 --> 00:19:54.460
So, like, you run a cell, say you have three cells, you know, you decide to go rerun the second cell.

00:19:54.460 --> 00:19:58.520
You have to remember to rerun whatever cell.

00:19:58.520 --> 00:19:59.240
Depends on it.

00:19:59.240 --> 00:20:00.120
Maybe it's the third cell.

00:20:00.120 --> 00:20:02.220
Maybe it's the first cell because you wrote things out of order.

00:20:02.220 --> 00:20:11.560
And so you can easily get into a state with Jupyter notebooks where your code on the page doesn't match the outputs that were created.

00:20:11.920 --> 00:20:12.320
Yeah.

00:20:12.320 --> 00:20:17.460
So if you were to, like, basically go to the menu option and say rerun all cells, you would get different answers.

00:20:17.460 --> 00:20:18.840
Exactly.

00:20:18.840 --> 00:20:21.320
And this is, like, it's actually been studied.

00:20:21.320 --> 00:20:26.220
And, like, it happens a kind of a shockingly large amount of times that, like...

00:20:26.220 --> 00:20:30.180
So there's one study in 2019 by Pimentel.

00:20:30.180 --> 00:20:32.040
I'm going to probably pronounce his name wrong.

00:20:32.040 --> 00:20:34.360
But by, I think, four professors.

00:20:34.360 --> 00:20:36.640
And they studied a bunch of notebooks on GitHub.

00:20:37.020 --> 00:20:44.400
And they found that only, like, a quarter of the notebooks that were on GitHub, they were able to run it all.

00:20:44.400 --> 00:20:48.280
And then, like, either 4% of those or 4% of all of them.

00:20:48.280 --> 00:20:55.760
Only 4% of them, like, when they ran, recreated the same results that were serialized in the notebook.

00:20:55.760 --> 00:21:02.580
Meaning, like, maybe people ran cells out of order when they originally created the notebook and then committed it.

00:21:02.980 --> 00:21:10.540
Or maybe they didn't, like, create a requirements.txt that faithfully captured the package environment they used.

00:21:10.540 --> 00:21:15.620
So there's, like, this recognition that Jupyter Notebooks suffer from a reproducibility crisis.

00:21:15.620 --> 00:21:23.540
Which is rather unfortunate for a tool that is used for science and data science and data engineering.

00:21:23.540 --> 00:21:25.600
Like, things where reproducibility is paramount.

00:21:26.700 --> 00:21:26.820
Yeah.

00:21:26.820 --> 00:21:28.620
And so that was one issue.

00:21:28.620 --> 00:21:33.900
Reproducibility was, like, one main thing that, sort of, we wanted to solve for with Marima Notebooks.

00:21:33.900 --> 00:21:38.020
And the other thing, I think, that we alluded to earlier is that...

00:21:38.020 --> 00:21:42.620
So Jupyter Notebooks are stored as, like, a JSON file.

00:21:42.620 --> 00:21:46.040
Where, like, the outputs, like, the plots, etc.

00:21:46.040 --> 00:21:48.200
Are serialized as these binary strings.

00:21:49.040 --> 00:21:55.000
And, like, the, you know, one downside of that is that you can't really use these things.

00:21:55.000 --> 00:21:56.720
Like, you can use, like, traditional software.

00:21:56.720 --> 00:21:58.720
At least not without jumping through extra hoops.

00:21:58.720 --> 00:22:02.180
So, like, you make a small change to your Jupyter Notebook.

00:22:02.180 --> 00:22:03.940
You get a gigantic git diff.

00:22:03.940 --> 00:22:08.180
Because, you know, the binary representation of some object changed by a large amount.

00:22:09.180 --> 00:22:13.700
Or you want to reuse the Python code in that Jupyter Notebook.

00:22:13.700 --> 00:22:18.500
When you have to run it through, like, a Jupytext or some other thing to strip it out.

00:22:18.500 --> 00:22:19.740
And then so you...

00:22:19.740 --> 00:22:26.220
Oftentimes you get this, like, situation where people just, like, end up copy-pasting a bunch of things across a bunch of notebooks.

00:22:26.220 --> 00:22:27.760
And it quickly gets really messy.

00:22:27.760 --> 00:22:31.220
And that was another thing we wanted to solve for.

00:22:31.220 --> 00:22:39.120
Making notebooks, like, git-friendly and interoperable with other Python tooling, like git, pytest, etc.

00:22:39.120 --> 00:22:44.500
Yeah, there's some things that will run them, kind of, function module-like.

00:22:44.500 --> 00:22:49.320
But, yeah, it's not really the intended use case, is it?

00:22:49.320 --> 00:22:50.840
Yeah, it's not.

00:22:50.840 --> 00:22:51.900
But people want to.

00:22:51.900 --> 00:22:53.900
Which is, I think, like, the...

00:22:53.900 --> 00:23:00.900
It's funny, because, like, the intended use case, I think, of, like, traditional notebooks like Jupyter was, like...

00:23:00.900 --> 00:23:06.460
Interactive REPL Explorer data produced, like, simple narrative text.

00:23:06.460 --> 00:23:15.020
But then, like, they just got used for so much more than that in situations, yeah, where reproducibility, reusability is, like, really important.

00:23:15.020 --> 00:23:18.140
And I think that's what we're trying to solve for.

00:23:18.140 --> 00:23:20.180
Yeah, it sounds great.

00:23:20.180 --> 00:23:21.860
It looks like you've done quite well.

00:23:21.860 --> 00:23:23.080
We'll dive into the features and stuff.

00:23:23.080 --> 00:23:26.600
But just wondering out loud, you know, that study.

00:23:26.600 --> 00:23:29.460
I know it was not your study, so I'm not asking you for answers.

00:23:29.460 --> 00:23:31.700
Just, what do you think?

00:23:31.700 --> 00:23:46.120
If it's that low of a percentage of reproducibility, because people fell down on their, like, rigorous software engineering, for example, like, no requirements file, or hard-coded pass instead of relative pass, or whatever.

00:23:47.500 --> 00:24:00.020
If it's that number for notebooks, I wonder about just plain Python files that are also meant to act to solve, like, science problems and stuff that just didn't happen to be in notebooks.

00:24:00.020 --> 00:24:01.280
You know, I wonder if they're any better.

00:24:01.280 --> 00:24:02.280
Yeah.

00:24:02.680 --> 00:24:03.800
It's a good question.

00:24:03.800 --> 00:24:06.340
I think they will be better.

00:24:06.340 --> 00:24:10.020
I can just give an anecdote to, like, why I think they would be better.

00:24:10.020 --> 00:24:22.200
And so, like, so one example, and this happened to me many times, but, like, one particular example is, like, when I was working on my PhD thesis, which was about vector embeddings, it was me and a couple of co-authors.

00:24:22.380 --> 00:24:33.180
And, you know, both of us did our, like, created the examples for this embedding algorithm in, like, Jupyter notebooks.

00:24:33.180 --> 00:24:35.480
And these notebooks produced a bunch of plots, et cetera.

00:24:35.980 --> 00:24:40.680
And so at the end of the, once the thesis was written, I was putting up all our code on GitHub.

00:24:40.680 --> 00:24:45.500
And so I asked one of my co-authors, like, hey, like, can you share your notebooks with me?

00:24:45.500 --> 00:24:46.940
And this co-author is amazing.

00:24:46.940 --> 00:24:50.360
He's really smart, but not necessarily trained as a software engineer.

00:24:50.360 --> 00:24:52.980
And he shares his Jupyter notebook with me.

00:24:52.980 --> 00:24:54.100
And I run it.

00:24:54.100 --> 00:24:55.760
And it doesn't work at all.

00:24:55.760 --> 00:24:58.880
And the reason it doesn't work at all is that there's, like, multiple cells.

00:24:58.940 --> 00:25:06.580
And there's, like, this branching path where, like, it's clear that, like, he ran, like, you know, you see the execution order serialized in the notebook.

00:25:06.580 --> 00:25:08.660
And it's not, like, one, two, three, four.

00:25:08.660 --> 00:25:10.780
It's, like, one, two, seven, four, three.

00:25:10.780 --> 00:25:13.720
It's, like, these cells were ran in this path-dependent way.

00:25:13.720 --> 00:25:17.820
And then also it's, like, there's, like, three cells in the middle.

00:25:17.820 --> 00:25:19.180
He ran just one of them.

00:25:19.180 --> 00:25:20.800
I'm not exactly sure which one.

00:25:20.800 --> 00:25:26.000
And, like, whereas if you had a Python script, there's only one way to, I mean, sure, you can have data.

00:25:26.000 --> 00:25:26.600
That's a good point.

00:25:26.600 --> 00:25:28.380
You do not really get a choice.

00:25:28.900 --> 00:25:29.940
It runs top to bottom.

00:25:29.940 --> 00:25:30.800
Exactly.

00:25:30.800 --> 00:25:31.760
Depending on the data.

00:25:31.760 --> 00:25:32.040
Okay.

00:25:32.040 --> 00:25:44.300
So, yeah, that is something that's really, it's just very counter to the concept of reproducibility is that you can run them in any order.

00:25:44.300 --> 00:25:58.880
And there's not, you know, I feel like, I feel like Jupyter Notebooks should almost have, like, a red bar at the cross, like, an out-of-order bar warning across the top if it's not top to bottom.

00:25:58.880 --> 00:25:59.880
It doesn't have to be one, two, three.

00:25:59.880 --> 00:26:00.740
It doesn't have to be one, two, three.

00:26:00.740 --> 00:26:03.060
It could be one, five, six, nine.

00:26:03.260 --> 00:26:09.740
But it should be a monotonic increasing function as you read the numbers top to bottom.

00:26:09.740 --> 00:26:10.620
Yeah.

00:26:10.940 --> 00:26:15.900
Otherwise, it should be, like, a big warning or, like, a weird, like, some kind of indicator, like, hey, you're in the danger zone.

00:26:15.900 --> 00:26:16.440
You know what I mean?

00:26:17.080 --> 00:26:28.620
Yeah, and there's actually another thing that actually happens, has happened to me way more often than I care, I should care to admit while working with Jupyter Notebooks is that, like, it's not just the order you run the cells.

00:26:28.620 --> 00:26:31.740
It's also, like, what happens if you delete a cell?

00:26:31.740 --> 00:26:38.860
Because when you delete a cell, you no longer, so say a cell declares a variable X, and you deleted that cell, you're like, yeah, I don't want X anymore.

00:26:39.400 --> 00:26:47.860
But you may forget that just by deleting the cell, you're not removing the variables from memory, and so, like, X still exists.

00:26:47.860 --> 00:26:51.600
And so then you're running other cells that depend on X, everything is fine.

00:26:51.600 --> 00:26:56.120
But then you come back, and you run your notebook, and everything's broken.

00:26:56.120 --> 00:26:58.000
And, like, you don't, you have no idea.

00:26:58.000 --> 00:27:00.420
The first time this happened to me, it took me forever to debug.

00:27:00.420 --> 00:27:01.700
And later on, you realize that.

00:27:01.700 --> 00:27:03.300
I can imagine that is so rough.

00:27:03.300 --> 00:27:04.060
Yeah.

00:27:04.060 --> 00:27:07.600
Later on, you realize, okay, this is a pattern that happens.

00:27:07.600 --> 00:27:13.380
But it's like a, yeah, so that's another thing that we also wanted to solve for in Marimo notebooks.

00:27:13.380 --> 00:27:14.700
Awesome.

00:27:14.700 --> 00:27:15.280
All right.

00:27:15.280 --> 00:27:16.100
Well, tell us about Marimo.

00:27:16.100 --> 00:27:18.620
Okay.

00:27:18.620 --> 00:27:19.640
So let's see.

00:27:19.640 --> 00:27:23.300
So Marimo is, it's an open source notebook for Python.

00:27:23.300 --> 00:27:30.060
The main thing that's different between Marimo and Jupyter is that Marimo's reactive.

00:27:30.400 --> 00:27:38.320
And what that means is that, unlike a Jupyter notebook where you can run cells in any arbitrary order you like,

00:27:38.320 --> 00:27:49.580
in Marimo, when you run one cell, it knows what other cells need to be run in order to make sure that your code and outputs are synchronized.

00:27:49.780 --> 00:27:51.340
So it's kind of like Excel, right?

00:27:51.340 --> 00:27:52.680
So you have two cells.

00:27:52.680 --> 00:27:53.680
One declares X.

00:27:53.680 --> 00:27:55.080
Another one references X.

00:27:55.080 --> 00:27:57.820
You run the cell that declares X or defines X.

00:27:57.820 --> 00:28:04.000
All other cells that reference X will automatically run or they'll be marked as stale.

00:28:04.000 --> 00:28:07.320
You can, like, configure it if you're scared of automatic execution.

00:28:07.560 --> 00:28:18.400
But the point is that it, like, manages your variables for you so that you don't have to worry about outputs becoming, like, decohered from your code.

00:28:18.400 --> 00:28:23.980
And similarly, if you delete a cell, the variable will be scrubbed from memory.

00:28:23.980 --> 00:28:29.940
And then cells that are dependent on it will either be marked as stale with a big warning or automatically run and invalidated.

00:28:29.940 --> 00:28:34.320
So that reactivity provides, like, some amount of reproducibility.

00:28:35.900 --> 00:28:42.180
And then it also, some other key features, and then we can, like, dive into each of them, is an additional reactivity.

00:28:42.180 --> 00:28:47.540
Marimo notebooks are stored as pure Python files, which makes them easy to version with Git.

00:28:47.540 --> 00:28:56.020
And then we've also made it easy to run Marimo notebooks as Python scripts and then share them as interactive web apps with, like, little UI elements.

00:28:56.020 --> 00:28:58.520
Yeah, I'm excited to talk about that.

00:28:58.520 --> 00:28:59.540
That's some cool stuff there.

00:29:01.580 --> 00:29:10.940
Okay, so when you create a variable, if you say, like, x equals 1, it's not just a pi long pointer in memory, right?

00:29:10.940 --> 00:29:20.320
It's something that kind of looks at the read and write that get in the set of it and creates, like, a relationship where it says,

00:29:20.320 --> 00:29:24.680
if you were to push the change into it, it says, okay, I have been changed.

00:29:24.820 --> 00:29:26.680
Who else is interested in reading from me?

00:29:26.680 --> 00:29:28.420
And it can sort of work that out, right?

00:29:28.420 --> 00:29:29.060
How does that work?

00:29:29.060 --> 00:29:32.960
Actually, it's not really implemented in that way.

00:29:32.960 --> 00:29:33.900
Okay.

00:29:33.900 --> 00:29:35.240
So, okay.

00:29:35.240 --> 00:29:36.040
So, let's see.

00:29:36.040 --> 00:29:41.400
Yeah, this is interesting to dive into because there's, like, two ways that you can, like, get at reactivity.

00:29:41.640 --> 00:29:45.420
So, in Marimo, what we actually do is we do static analysis.

00:29:45.420 --> 00:29:51.200
So, we look for definitions and references on, like, of global variables.

00:29:51.200 --> 00:29:53.380
And then so, we just make a graph out of that.

00:29:53.380 --> 00:30:02.720
So, for every cell, we look at the, I guess, the loads in the ASTs and then, like, the assignments.

00:30:03.540 --> 00:30:09.620
And so, we can see statically who declares what and who reads what, like, who is a cell.

00:30:09.620 --> 00:30:16.340
And so, that makes it, like, performant and also predictable of, like, how your notebook is going to run.

00:30:16.340 --> 00:30:21.660
An alternative, I think, what you were getting at was, like, runtime tracing.

00:30:21.660 --> 00:30:27.940
More like a JavaScript front-end sort of deal, like a view binding, model binding type thing or something like that.

00:30:28.720 --> 00:30:35.440
Yeah, so, yeah, everything we do is static, is done with static analysis.

00:30:35.440 --> 00:30:40.000
There was another project called IPyFlow, which was, like, a reactive kernel for Jupyter.

00:30:40.000 --> 00:30:40.960
It's still around.

00:30:40.960 --> 00:30:48.120
They took, like, the runtime tracing approach of, like, checking on every assignment.

00:30:48.120 --> 00:30:50.320
Like, okay, there's a read.

00:30:50.320 --> 00:30:54.540
Now, where is that object in memory and then running cells that depend on it?

00:30:55.700 --> 00:31:00.340
I think in practice, you know, I was talking to Stephen Mackey, the author of that extension.

00:31:00.340 --> 00:31:08.440
And then also, like, based on some work that I saw at Google TensorFlow, like, that's, like, really hard to get 100% right.

00:31:08.440 --> 00:31:10.560
It's basically impossible to get 100% right.

00:31:10.560 --> 00:31:15.520
So, like, you will miss some, like, low references and definitions.

00:31:16.060 --> 00:31:22.340
And so, like, there's this weird usability cliff as a user where, like, when you run a cell, you're not sure what else will run.

00:31:22.340 --> 00:31:28.220
Whereas if you do it based on static analysis, you can give guarantees on what will run and what won't.

00:31:28.220 --> 00:31:35.320
Yeah, I guess the static analysis is a good choice because there's only so many cells.

00:31:35.460 --> 00:31:43.620
You don't have to track it down to, like, well, within the DOM and all the JavaScript objects, we're linking all these together and they can do whatever they want from all these different angles.

00:31:43.620 --> 00:31:47.920
It's just, like, when this cell runs, what other cells do we need to think about?

00:31:47.920 --> 00:31:50.360
So it's kind of, like, what does this create?

00:31:50.360 --> 00:31:51.820
What does it change?

00:31:51.820 --> 00:31:54.060
And then push that along, right?

00:31:54.060 --> 00:31:55.320
So it's a little more constrained.

00:31:56.000 --> 00:31:56.680
Exactly, yeah.

00:31:56.680 --> 00:31:58.960
So basically, yeah, that's exactly right.

00:31:58.960 --> 00:32:03.420
And so it's a data flow graph where the data flowing on the edges is the variables across cells.

00:32:03.420 --> 00:32:05.320
Yeah.

00:32:05.320 --> 00:32:06.320
And I don't know.

00:32:06.320 --> 00:32:12.040
I think I've been thinking about data flow graphs for a long time, ever since TensorFlow, during my PhD too, when I worked on CVXPY.

00:32:12.040 --> 00:32:16.760
So it's just a thing that I enjoy thinking about and working on.

00:32:16.760 --> 00:32:17.380
Yeah.

00:32:17.440 --> 00:32:26.920
So what about your experience working on TensorFlow and at Google and at Stanford and stuff that sort of influenced this project?

00:32:26.920 --> 00:32:30.200
Yeah, a couple of things.

00:32:30.200 --> 00:32:45.660
So definitely a big thing that influenced this project was, like, working as a scientist at Stanford where, like, I and my colleagues use Jupyter Notebooks, like, on almost a daily basis because they let us see our data while we worked on it.

00:32:46.420 --> 00:32:50.800
And so really valued the iterative programming environment.

00:32:50.800 --> 00:32:59.880
Really didn't like all the bugs that we kept on running into, which are, like, kind of our fault, right, because of, like, oh, we forget to run a cell, et cetera.

00:32:59.880 --> 00:33:07.960
Didn't like that it was not easy to reuse the code in a notebook in just other Python modules.

00:33:07.960 --> 00:33:14.580
Didn't like that I couldn't share my artifacts in a meaningful way with my PhD advisor who can't run Python notebooks.

00:33:14.840 --> 00:33:18.420
Like, I couldn't, like, make a little app to showcase my research project.

00:33:18.420 --> 00:33:36.680
It's so interesting how PhD advisors and just professors in general, how they're either embracing or their inability to embrace or their prejudices for or against the technology so influence science, the people in the research teams, everything.

00:33:36.800 --> 00:33:43.120
It's like, well, we'd like to use this, but the principal author really doesn't like it, doesn't want to run it, so we're not using that.

00:33:43.120 --> 00:33:45.460
Or, you know, just these little edge cases.

00:33:45.460 --> 00:33:47.760
Like, I was made to learn Fortran in college.

00:33:47.760 --> 00:33:49.000
I'm still sour about it.

00:33:51.020 --> 00:33:51.600
That's funny.

00:33:51.600 --> 00:33:52.440
Yeah, no, it's true.

00:33:52.440 --> 00:33:54.240
Yeah, it does have a big effect.

00:33:54.240 --> 00:33:59.540
And then at Google, I guess the things that influenced, so we used Notebooks 2 there.

00:33:59.540 --> 00:34:12.260
Since I was doing the systems engineering work at Google, I personally didn't use them too much, although I did use, like, Google Colab for, like, training, like, creating training courses and stuff for, like, other engineers and for demos.

00:34:12.480 --> 00:34:28.980
But I guess the part of Google that influenced it was just, like, thinking about data flow graphs for a year and, you know, we were – there was, like, a couple of parable projects, like, one that was using runtime tracing for, like, figuring out, like, how to make a DAG.

00:34:29.640 --> 00:34:37.900
And it was just, I don't know, kind of traumatic just because, like, you miss things and the user experience just, like, it kind of falls over.

00:34:37.900 --> 00:34:44.020
And so I guess the part from there was it just made me not want to use runtime tracing.

00:34:44.020 --> 00:34:46.160
It made me embrace static analysis for this.

00:34:46.160 --> 00:34:48.620
Yeah.

00:34:48.620 --> 00:34:50.160
Yeah, it makes a lot of sense.

00:34:50.160 --> 00:34:51.900
All right.

00:34:51.900 --> 00:34:54.960
Well, let's talk some features here.

00:34:55.580 --> 00:35:07.360
What are the – I guess probably the premier feature is the reactivity, in which case it doesn't matter which cell you run, they're never going to get out of date, right?

00:35:07.360 --> 00:35:09.740
Yeah, that's correct.

00:35:09.740 --> 00:35:15.400
So the reactivity, in other words, the data flow graph behind it, is the premier feature.

00:35:15.400 --> 00:35:18.860
And it lets you reason about your code locally, right, which is really nice.

00:35:18.860 --> 00:35:20.580
Like, you can just look at your one cell.

00:35:20.580 --> 00:35:25.340
You don't really have to worry about – you know what variables it reads and what it defines.

00:35:25.340 --> 00:35:29.060
And you don't have to worry about, oh, but what cells do I need to run before this?

00:35:29.060 --> 00:35:40.060
So not only does it, like, make sure your code and outputs are in sync, it also, like, makes it really, like, fun and useful.

00:35:40.060 --> 00:35:44.460
Like, it makes it possible to, like, really rapidly experiment with, like, ideas.

00:35:44.660 --> 00:35:53.480
As long as, like, your cells aren't too expensive, if you enable automatic execution, then you can change a parameter, run a particular cell.

00:35:53.480 --> 00:35:59.320
And it'll run only, you know, what's required to, like, update, like, subsequent outputs.

00:36:00.740 --> 00:36:13.660
And then another, like, consequence of reactivity that I think is really neat and our users really like is it makes it far easier to use interactive, like, UI widgets than it is in, like, a Jupyter notebook.

00:36:14.660 --> 00:36:21.480
And the way that this works is that – so Marimo is, like, both a notebook and also a library.

00:36:21.480 --> 00:36:24.620
So you can import Marimo as Mo into your notebook.

00:36:24.620 --> 00:36:30.580
And when you do this, you get access to a bunch of things, including these – a bunch of different UI widgets,

00:36:30.580 --> 00:36:46.500
ranging from the simple ones, like sliders, drop-down menus, to, like, cooler ones, like interactive selectable charts and, like, data frame transformers that, like, automatically generate the Python code needed for your transformation.

00:36:46.500 --> 00:36:56.880
And the way that reactivity comes into here is that, like, because we know which – when you create a UI element, as long as you bind it to a global variable,

00:36:56.880 --> 00:37:05.120
just say, you know, my slider equals mo.ui.slider, then when you interact with the slider anywhere on the screen,

00:37:05.120 --> 00:37:08.360
well, we can just say, okay, that slider's bound to X.

00:37:08.360 --> 00:37:10.740
We just need to run all other cells that depend on X.

00:37:10.740 --> 00:37:19.080
And all of a sudden, you have really nice interactivity, interactive elements controlling your code execution without ever having to write a callback.

00:37:19.080 --> 00:37:22.520
And so I think people find that really liberating, too.

00:37:22.520 --> 00:37:29.920
So you don't really have to hit backspace, change it, you know, a character value for your variable, shift, enter, shift, enter, shift, enter.

00:37:29.920 --> 00:37:34.000
You know, just change a number and everything automatically recalculates.

00:37:34.000 --> 00:37:34.740
Yeah.

00:37:34.740 --> 00:37:40.980
And this dependency flow, is it possible to have a cyclical graph?

00:37:41.180 --> 00:37:49.780
Like, if I did this in Jupyter, I could go – I could go down to the third cell and define X and then go back up and then use X.

00:37:49.780 --> 00:37:52.640
If I run it in the right order, it won't know that there's a problem.

00:37:52.640 --> 00:37:57.140
Imagine it's only possible to go one way, right?

00:37:57.140 --> 00:37:58.680
You can't get into a weird cycle?

00:38:00.580 --> 00:38:00.940
Yeah.

00:38:00.940 --> 00:38:03.700
So we do give people escape hatches.

00:38:03.700 --> 00:38:08.720
We ask them, please don't use it unless you really know what you're doing and you really want to do this.

00:38:08.720 --> 00:38:21.380
Because in most cases, we find, especially for, like, if your goal is to just, like, work with data as a data scientist, data engineer scientist, we feel you don't need that cycles.

00:38:22.120 --> 00:38:22.980
You don't need cycles.

00:38:22.980 --> 00:38:36.220
But if you're making an app, and I guess I should mention, Marimo lets you run any notebook as – well, a notebook, but also from the command line, you can serve your notebook as a web app, like, similar to Streamlit, if you've seen that.

00:38:36.220 --> 00:38:41.280
In those cases, sometimes you do want state, basically, right, like cyclic references.

00:38:41.280 --> 00:38:44.380
So by default, Marimo actually checks for cycles.

00:38:44.380 --> 00:38:50.900
If you have a cycle across cells, it, you know, politely tells you, like, hey, like, that's not really cool in Marimo.

00:38:50.900 --> 00:38:52.440
Please break your cycle.

00:38:52.440 --> 00:38:54.220
Here's some suggestions how to do that.

00:38:54.220 --> 00:39:04.820
But if you're really insistent, then you can go to our docs and learn about the state object that we have that does let you get into some, like, runtime-based cell execution.

00:39:04.820 --> 00:39:10.840
And you can update a state object and kind of in a React from 10D way, it'll run dependence of that state.

00:39:10.840 --> 00:39:11.480
Okay.

00:39:11.480 --> 00:39:12.200
Interesting.

00:39:13.400 --> 00:39:14.840
Yeah, I guess that makes sense for apps.

00:39:14.840 --> 00:39:17.680
You definitely need some sort of global state there.

00:39:17.680 --> 00:39:31.660
Yeah, we – I think, like, we've seen that, like, sometimes our users will reach for state in call bits just because that's what they're used to, and, like, you know, that's what they maybe were required to use in, like, Jupyter, et cetera.

00:39:31.660 --> 00:39:35.780
So we're trying to tell them, like, hey, in most cases, you actually don't need this.

00:39:35.780 --> 00:39:37.000
Yeah, very cool.

00:39:39.280 --> 00:39:45.880
So when you create a Jupyter notebook, you don't really create Python files.

00:39:45.880 --> 00:39:46.880
You create the notebook files.

00:39:46.880 --> 00:39:57.140
You create the notebook files, and those notebook files are JSON with both embedded cell execution bits, the code, but also the answers that go below.

00:39:57.140 --> 00:40:08.380
That's why if you go to GitHub and you look at a notebook, you can instantly see what could be super expensive computation, but pictures and stuff there because it's, like, residual in the artifact, right?

00:40:09.100 --> 00:40:09.360
Yeah.

00:40:09.360 --> 00:40:13.380
You guys do Python files.

00:40:13.380 --> 00:40:23.120
Do you have a way to, like, save that state in a sort of presentation style or something like that?

00:40:23.120 --> 00:40:23.940
You know what I mean?

00:40:23.940 --> 00:40:26.360
Is there, like, an associated state file?

00:40:26.360 --> 00:40:27.960
Yeah.

00:40:27.960 --> 00:40:33.240
So that's a really good question, and the answer is yes, but that is the biggest tradeoff, I think, of our file format.

00:40:33.240 --> 00:40:46.440
So, like, a surprising number of people actually have come to us and told us, like, I didn't expect this, but they tell us the reason we decided to try Marima notebooks is because you say it is versionable with Git.

00:40:46.440 --> 00:40:52.860
Like, that's, like, they're, like, that's the one reason I, especially, like, people in software and industry, and then they stay for all the other things.

00:40:53.520 --> 00:40:59.100
So that's what the pure Python file format allows, in addition to, like, modularity, running it as a script.

00:40:59.100 --> 00:41:05.060
For seeing outputs, yeah, they're not saved in the Python file.

00:41:05.060 --> 00:41:08.660
So we have a couple of ways to get around that.

00:41:08.660 --> 00:41:14.140
So one, like, you can export any Marima notebook to an IPython notebook file, actually.

00:41:14.140 --> 00:41:17.640
So, like, you can set up this, like, we have a feature, like, automatic snapshotting.

00:41:17.640 --> 00:41:27.060
You can automatically snapshot your notebook to, like, a parallel IPyMB file that's stored in a subdirectory of your notebook folder.

00:41:27.060 --> 00:41:31.380
And so you can push that up or share that if you like.

00:41:31.380 --> 00:41:39.140
When working locally, though, we actually have this cool feature that my co-finder, Miles, recently built.

00:41:39.980 --> 00:41:46.920
Is that we actually, so when you're working, you're working with your notebook, the outputs are actually saved.

00:41:46.920 --> 00:41:52.420
The representation of the outputs are saved in this, like, subdirectory, underscore, underscore, Marimo.

00:41:52.420 --> 00:42:01.820
So that the next time you open the notebook, it just picks up those outputs and then, like, loads them into the browser so that you can see where you left off.

00:42:01.820 --> 00:42:03.560
So.

00:42:03.560 --> 00:42:04.180
I see.

00:42:04.180 --> 00:42:06.160
So kind of like PyCache.

00:42:06.160 --> 00:42:07.300
Yeah.

00:42:07.600 --> 00:42:11.820
I would actually assume, given the name, but I haven't actually looked into PyCache too much.

00:42:11.820 --> 00:42:17.580
Well, I mean, just in the sense that it's saved, like, right there in your project using that directory.

00:42:17.580 --> 00:42:18.360
Oh, yes, yes, yes.

00:42:18.360 --> 00:42:19.260
Yeah, the PyCache folder.

00:42:19.260 --> 00:42:19.840
Exactly.

00:42:19.840 --> 00:42:20.520
Yeah, yeah, yeah.

00:42:20.520 --> 00:42:20.860
Exactly.

00:42:20.860 --> 00:42:29.200
And we have one other feature that another contributor, his name is Dylan, has been developing, which I think is, like, really cool,

00:42:29.300 --> 00:42:37.700
which is along those same lines, but based on, like, Nick style caching.

00:42:37.700 --> 00:42:44.980
So, like, it'll actually save, like, the Python objects themselves using a variety of different protocols.

00:42:45.520 --> 00:42:53.240
And because we have the DAG, he can actually, like, you know, guarantee, like, the only guarantee, like, consistency of the cache.

00:42:53.240 --> 00:42:58.580
But that means, like, not only are your outputs automatically loaded, like, also the variables are loaded.

00:42:58.580 --> 00:43:00.820
So you can literally pick up where you left off.

00:43:03.000 --> 00:43:09.880
Yeah, it sounds like some sweet SQLite could be in action there instead of just, you know, flat files or whatever.

00:43:09.880 --> 00:43:10.720
Yeah.

00:43:10.720 --> 00:43:12.240
Yeah, very cool.

00:43:12.240 --> 00:43:23.280
So you talked about when the reactivity fires, it can sometimes be expensive to recompute the cells.

00:43:23.280 --> 00:43:24.780
You know, sometimes they're super simple.

00:43:24.780 --> 00:43:29.700
Sometimes they're, you know, train the machine learning model for two days.

00:43:29.700 --> 00:43:31.240
Yeah.

00:43:32.000 --> 00:43:34.400
Are there caching mechanisms?

00:43:34.400 --> 00:43:38.200
You know, in a Python script, we've got functools.lrucache.

00:43:38.200 --> 00:43:49.000
And then there's other things that are kind of cool, in-process caches, like PyMocha is kind of like the functool stuff, but way more flexible and so on.

00:43:49.000 --> 00:43:55.200
And you could put those onto functions that then would have really interesting caching characteristics.

00:43:55.200 --> 00:44:00.500
Like, if you're going to rerun it, but I've run it before with this other value, here's the same answer back, right?

00:44:01.320 --> 00:44:08.400
Is there a way to set up that kind of caching or performance memoization type stuff?

00:44:08.400 --> 00:44:09.320
Yeah, definitely.

00:44:09.320 --> 00:44:09.800
Yeah, definitely.

00:44:09.800 --> 00:44:12.000
And that same contributor, Dylan.

00:44:12.000 --> 00:44:16.180
So he's implemented these and is continuing to build it out.

00:44:16.180 --> 00:44:20.880
But we have, I guess, two options.

00:44:20.880 --> 00:44:29.760
One is in-memory cache, which is basically the API is the same as functools.cache, but is designed to work in an iterative programming environment.

00:44:29.880 --> 00:44:37.360
Like, if you use functools.cache naively, like, if a function, if a cell defining a function reruns, like, your cache gets busted, right?

00:44:37.960 --> 00:44:41.140
So Mo.cache is a little smarter.

00:44:41.140 --> 00:44:45.360
And, like, using the DAG can know whether or not it needs to bust the cache.

00:44:45.360 --> 00:44:47.900
But to the user, it feels the same.

00:44:47.900 --> 00:44:58.800
And then we also have a persistent cache, which is the one that I was kind of alluding to when I mentioned you can automatically pick up where you left off by loading objects from disk.

00:44:59.040 --> 00:45:04.920
And so you can, like, put an entire cell in a context manager, like, with Mo.persistent cache.

00:45:04.920 --> 00:45:07.140
It'll sort of do the right thing.

00:45:07.140 --> 00:45:20.140
We've been talking about experimenting with, like, opting into, letting users opt into, like, global cell-wide caching, just, like, you know, automatically memorize cells or just have a UI element to do something like that.

00:45:20.140 --> 00:45:21.820
But we haven't quite done that yet.

00:45:22.460 --> 00:45:24.660
Yeah, I mean, it sounds real tricky for Jupyter.

00:45:24.660 --> 00:45:35.220
But because you all know the inputs and the outputs, it's almost as if you could sort of drive a hidden LRU cache equivalent at the cell level.

00:45:35.220 --> 00:45:35.820
You know what I mean?

00:45:35.820 --> 00:45:37.640
That's exactly right.

00:45:37.640 --> 00:45:37.980
Yeah.

00:45:37.980 --> 00:45:44.480
I think, yeah, because we know the inputs and outputs, that's kind of how everything flows from a project.

00:45:44.480 --> 00:45:49.160
You can think about projects like, if you turn a notebook into a data flow graph, what can you do?

00:45:49.160 --> 00:45:52.600
And, yeah, caching is, smart caching is definitely one of them.

00:45:52.600 --> 00:45:53.140
Yeah.

00:45:53.140 --> 00:45:57.280
I mean, it's not a, I make a sound like, well, you know, the input's output, so it's fine.

00:45:57.280 --> 00:46:02.520
But, you know, you could have the same data frame, but you could have added a column to the data frame.

00:46:02.520 --> 00:46:05.300
And the LRU cache goes, is it the same pointer?

00:46:05.300 --> 00:46:05.920
It is.

00:46:05.920 --> 00:46:06.580
We're good to go.

00:46:06.580 --> 00:46:07.580
It's like, well, yes.

00:46:07.580 --> 00:46:08.100
However.

00:46:08.100 --> 00:46:09.060
Yeah.

00:46:09.060 --> 00:46:10.280
It's not the same.

00:46:10.280 --> 00:46:12.940
You know, you almost got to, like, hash it or do something funky.

00:46:12.940 --> 00:46:13.980
And, yeah.

00:46:13.980 --> 00:46:14.240
Yeah.

00:46:14.240 --> 00:46:15.260
It's not perfect.

00:46:15.260 --> 00:46:15.640
Automatic sounds hard.

00:46:15.640 --> 00:46:16.080
No.

00:46:16.080 --> 00:46:16.480
Yeah.

00:46:16.480 --> 00:46:16.600
Yeah.

00:46:16.600 --> 00:46:17.340
Yeah, exactly.

00:46:17.340 --> 00:46:19.400
That's why we haven't quite enabled it.

00:46:19.400 --> 00:46:21.660
Yeah.

00:46:21.660 --> 00:46:22.440
It is hard.

00:46:22.440 --> 00:46:23.620
Yeah.

00:46:23.620 --> 00:46:24.960
Side effects, too.

00:46:24.960 --> 00:46:26.380
Network requests, all these things.

00:46:26.380 --> 00:46:28.060
All right.

00:46:28.060 --> 00:46:32.600
I have three more topics I want to cover before we run out of time here.

00:46:32.600 --> 00:46:35.500
We may cover more, but three sort of required.

00:46:36.540 --> 00:46:38.960
First one, because this is the one I'm going to forget most likely.

00:46:38.960 --> 00:46:51.620
You are at Google, and then by way of going through a PhD, you now are not at Google creating this project, which is open source on GitHub.

00:46:51.620 --> 00:46:56.140
And I don't see a pricing page at the top, but I do see it for enterprises.

00:46:56.980 --> 00:46:59.840
Like, how is this sustaining itself?

00:46:59.840 --> 00:47:00.980
Like, what's the business model?

00:47:02.260 --> 00:47:17.940
So when we first started, right after my PhD, so that was early 2022, we were actually lucky enough to get funding from a national lab associated with Stanford, so the Stanford Linear Accelerator.

00:47:18.500 --> 00:47:24.780
So I was talking with some scientists there, and we were talking about, I knew I wanted to make this thing.

00:47:24.780 --> 00:47:26.000
And they were like, what are you up to?

00:47:26.000 --> 00:47:31.500
And I was like, oh, well, I want to make this, like, notebook thing that, like, you know, fixes all notebooks, inspired by FudoJL.

00:47:31.500 --> 00:47:33.520
And they were like, that's awesome.

00:47:33.520 --> 00:47:34.080
We're scientists.

00:47:34.080 --> 00:47:37.940
We use notebooks every day, and we're getting a little tired of reproducibility issues.

00:47:37.940 --> 00:47:38.880
We want to make apps.

00:47:38.880 --> 00:47:40.720
So they're like, we'll fund you to do this.

00:47:40.720 --> 00:47:41.500
And so we...

00:47:41.500 --> 00:47:42.620
Awesome.

00:47:42.620 --> 00:47:45.800
So they kind of wrote you into one of their larger grants, something like that?

00:47:46.000 --> 00:47:49.860
We got, like, a subcontract that, like, was covered by one of their grants, yeah.

00:47:49.860 --> 00:47:56.660
So that wasn't enough for me and my co-founder, Miles, to work on it for two years, full-time alone.

00:47:56.660 --> 00:48:02.180
And, like, I think it really let us polish the product and develop it.

00:48:02.180 --> 00:48:13.840
And then mid-last year in July, one of our users is, like, one of our probably biggest power users, actually, is Anthony Goldblum,

00:48:13.960 --> 00:48:17.100
who is the founder and former CEO of Kaggle.

00:48:17.100 --> 00:48:18.660
Oh, nice.

00:48:18.660 --> 00:48:19.040
Yeah.

00:48:19.040 --> 00:48:20.180
Really into data science.

00:48:20.180 --> 00:48:22.280
So he's been one of our biggest power users.

00:48:22.280 --> 00:48:30.280
And at a certain point, he, last year, became, I guess, passionate enough about our project that he reached out to us and asked us,

00:48:30.280 --> 00:48:36.500
hey, like, can this venture fund I'm part of, can we invest?

00:48:37.100 --> 00:48:39.340
And so that was July of last year.

00:48:39.340 --> 00:48:45.920
And so we raised money from them as well as from a bunch of, like, prominent angel investors, like Jeff Dean from Google,

00:48:45.920 --> 00:48:48.820
Clem from Hugging Face, Lucas B.

00:48:48.820 --> 00:48:50.200
Walter from Weights & Bias and others.

00:48:50.200 --> 00:48:56.680
But so now our team is funded primarily through the venture funding.

00:48:57.980 --> 00:49:03.240
Right now, our business model is build open source software based on our venture funding.

00:49:03.240 --> 00:49:08.160
We do have plans for commercialization, but we're just not at a point where it makes sense to work on that right now.

00:49:08.160 --> 00:49:13.160
But what I can promise is that Marimo will always be open source Apache 2.0 license.

00:49:13.160 --> 00:49:18.780
We never plan to sell the notebook itself, but instead plan to work on complementary infrastructure.

00:49:18.780 --> 00:49:22.340
Yeah, I can already think of two good ones.

00:49:22.340 --> 00:49:24.620
Cool.

00:49:24.620 --> 00:49:25.620
Yeah.

00:49:25.620 --> 00:49:26.520
Awesome.

00:49:26.520 --> 00:49:27.100
Okay.

00:49:27.100 --> 00:49:39.380
The reason I ask is, you know, people always just want to know either how, what is kind of the success story of open source but sustainable, you know, as a full-time thing?

00:49:40.640 --> 00:49:48.480
If they're buying into it, how likely is that going to stay open source or, like, what's the catch?

00:49:48.480 --> 00:49:49.360
You know, that kind of stuff.

00:49:49.360 --> 00:49:50.560
Yeah.

00:49:50.560 --> 00:49:51.640
No, it's a good question.

00:49:51.640 --> 00:50:00.700
I mean, we, honestly, I was, I think when we raised money, it actually, like, assuaged some of our users.

00:50:00.700 --> 00:50:04.580
Like, because they were like, oh, like, Miles and Akshay are really cool.

00:50:04.580 --> 00:50:08.040
They're building this really cool stuff, but, like, how are they paying rent?

00:50:08.040 --> 00:50:14.600
And, like, so when we told them, like, yeah, we raised, you know, a few million dollars from Akshay Ventures, they were like, okay, that's great.

00:50:14.600 --> 00:50:15.360
You deserve it.

00:50:15.360 --> 00:50:16.440
Please continue building.

00:50:16.440 --> 00:50:18.140
Nice.

00:50:18.140 --> 00:50:19.140
Yeah.

00:50:19.140 --> 00:50:20.780
Yeah, that's awesome.

00:50:22.020 --> 00:50:22.620
All right.

00:50:22.620 --> 00:50:23.780
Let's see.

00:50:23.780 --> 00:50:25.400
Which one are we going to talk about next?

00:50:25.400 --> 00:50:26.700
Not this one yet.

00:50:26.700 --> 00:50:30.740
We'll talk about this because there's a nice comment from Amir out in the audience.

00:50:30.740 --> 00:50:32.680
I love the new AI feature in Mario.

00:50:33.600 --> 00:50:36.380
So you have an AI capability.

00:50:36.380 --> 00:50:45.920
And then the other thing I want to talk about is, so we save some time for it, is publishing or running your reactive notebook as an app.

00:50:45.920 --> 00:50:49.540
But let's talk AI first because we started the show that way.

00:50:49.540 --> 00:50:52.500
I don't want to start to round it out that way, you know?

00:50:53.340 --> 00:50:57.780
So we have, like, a few different ways that AI is, I guess, integrated into the project.

00:50:57.780 --> 00:51:05.540
So one thing that we're trying really hard to do is, like, build, like, a modern editor, like, designed specifically for working with data.

00:51:05.900 --> 00:51:10.560
And I think these days, modern means one of the requirements is you have AI stuff built in.

00:51:10.560 --> 00:51:14.120
So you can, like, generate code with AI.

00:51:14.120 --> 00:51:25.760
You can, like, even tell the – you can, like, tag, like, data frames and, like, tables that you have in memory and, like, give them as context, give their schemas as context to your assistant in, like, a cursor-like way.

00:51:27.900 --> 00:51:42.560
We're also, like, experimenting with a new service right now, like, marimo.app.ai, where you can go type a little prompt, like, generate me a notebook that plots a 3D quadratic surface with Matplotlib.

00:51:42.560 --> 00:51:44.100
Because I always forget how to do that.

00:51:44.100 --> 00:51:48.760
And then it'll, you know, do its best to, in one shot, create that notebook for you.

00:51:48.760 --> 00:51:50.940
And then you can play around with it.

00:51:50.940 --> 00:51:55.800
And then you can either download it locally or share it out.

00:51:55.800 --> 00:51:59.500
Yeah, very cool.

00:51:59.500 --> 00:52:05.020
I'll put a link to the online AI feature that people can play with.

00:52:05.020 --> 00:52:06.080
It looks really, really nice.

00:52:06.080 --> 00:52:09.140
And it worked super quick when I asked it to go.

00:52:09.140 --> 00:52:21.120
Now, one thing I want to talk about really quick now that I'm looking at this is you've got the code, but it's below the presentation of the result of the code.

00:52:21.120 --> 00:52:22.100
Yeah.

00:52:23.360 --> 00:52:27.400
So that is a stylistic choice, which is configurable.

00:52:27.400 --> 00:52:30.040
Because people told us, many of them told us, we don't like this.

00:52:30.040 --> 00:52:31.560
Please just put the output below.

00:52:31.560 --> 00:52:33.000
But other people like it.

00:52:33.000 --> 00:52:33.440
Okay.

00:52:33.440 --> 00:52:34.020
You love it.

00:52:34.020 --> 00:52:34.740
Okay.

00:52:34.740 --> 00:52:35.160
Yeah.

00:52:35.160 --> 00:52:36.000
And so this is...

00:52:36.000 --> 00:52:36.100
Okay.

00:52:36.100 --> 00:52:36.860
Well, what is the point?

00:52:36.860 --> 00:52:39.160
Is the point for me to see the code or the answer?

00:52:39.560 --> 00:52:45.840
The point is to see the graph and the tables and then if I care, I'll look at the code.

00:52:46.380 --> 00:52:48.240
So the way that I...

00:52:48.240 --> 00:52:51.180
So I think I mentioned Pluto JL really briefly.

00:52:51.180 --> 00:52:53.280
So Pluto JL is one of our biggest inspirations.

00:52:53.280 --> 00:52:55.280
It's a Julia project, a reactive notebook.

00:52:55.280 --> 00:53:01.960
Now, a lot of the great ideas that I think are great about Marimo came, honestly, very straight from Pluto.

00:53:02.300 --> 00:53:07.340
And one thing that Fonz, like the creator of Pluto, you know, he likes to say is he said, code is...

00:53:07.340 --> 00:53:10.120
The code of a cell is a caption for its output.

00:53:10.120 --> 00:53:11.640
And that's the way you think about it.

00:53:11.640 --> 00:53:13.220
And when you think about it that way, it makes a lot of sense.

00:53:14.380 --> 00:53:18.420
But I think like Pluto and then Observable also both have outputs on top.

00:53:18.420 --> 00:53:19.120
I don't know.

00:53:19.120 --> 00:53:19.780
It's like...

00:53:19.780 --> 00:53:20.700
I feel like if you...

00:53:20.700 --> 00:53:22.140
It's like one of those heuristics you use.

00:53:22.140 --> 00:53:25.380
You look at a notebook, output on top, it's a reactive notebook.

00:53:25.380 --> 00:53:26.780
Otherwise, it's imperative.

00:53:26.780 --> 00:53:28.000
I got you.

00:53:28.000 --> 00:53:28.480
Gotcha.

00:53:28.480 --> 00:53:28.940
Yeah.

00:53:28.940 --> 00:53:33.600
I can see why you might not like it, but I like it.

00:53:33.600 --> 00:53:35.660
So I think it's pretty cool.

00:53:35.660 --> 00:53:36.240
Yeah.

00:53:36.240 --> 00:53:42.420
And then this marmo.app.ai, once you create one of these, you have a shareable link that you

00:53:42.420 --> 00:53:44.520
can hand it off to other people, right?

00:53:44.520 --> 00:53:45.660
Yeah.

00:53:45.660 --> 00:53:49.480
So you can open a new tab, which I think will...

00:53:49.480 --> 00:53:53.300
So actually, all of this actually, interestingly enough, is running in our WebAssembly playground.

00:53:53.300 --> 00:53:54.680
Yeah.

00:53:54.680 --> 00:53:57.100
So there's that URL right there, which you can just share.

00:53:57.100 --> 00:53:59.140
You can also do like the little...

00:53:59.140 --> 00:54:02.880
There's a hamburger menu, which you can click on to get a permalink that's shorter.

00:54:02.880 --> 00:54:06.360
But...

00:54:06.360 --> 00:54:06.500
Right.

00:54:06.500 --> 00:54:07.900
Yeah.

00:54:09.900 --> 00:54:14.500
Honestly, we just built this Generate with AI feature like a little over a week ago.

00:54:14.500 --> 00:54:17.620
And just curious to see what people use it for.

00:54:17.620 --> 00:54:19.220
There's a lot more we could invest here.

00:54:19.220 --> 00:54:21.880
I mean, you know, everyone talks about agents.

00:54:21.880 --> 00:54:24.100
You can think about, oh, data science agent.

00:54:24.100 --> 00:54:28.960
Like, but for now, we're just trying to one-shot thing and see how it lands with folks.

00:54:28.960 --> 00:54:29.980
Yeah, sure.

00:54:29.980 --> 00:54:30.940
Let's start with that.

00:54:30.940 --> 00:54:32.140
Well, it looks really great.

00:54:32.140 --> 00:54:34.520
And the UI is super nice.

00:54:34.520 --> 00:54:35.480
So well done.

00:54:35.480 --> 00:54:36.720
Appreciate it.

00:54:36.720 --> 00:54:37.720
I'll pass that on to Miles.

00:54:37.720 --> 00:54:40.900
He built this as a weeknight project.

00:54:40.900 --> 00:54:43.340
You know, sometimes you just get inspired.

00:54:43.340 --> 00:54:44.240
Just like, you know what?

00:54:44.240 --> 00:54:45.740
I'm doing it.

00:54:45.740 --> 00:54:49.760
I'm just taking two days off the regular work and I'm just doing this.

00:54:49.760 --> 00:54:50.180
You know what I mean?

00:54:50.180 --> 00:54:50.480
Yeah.

00:54:50.480 --> 00:54:51.420
Yeah, definitely.

00:54:51.420 --> 00:54:52.400
Yeah.

00:54:52.400 --> 00:54:53.200
All right.

00:54:53.300 --> 00:55:02.200
So the final thing I want to talk about, which you kind of hinted at a little bit there with the WebAssembly stuff, is I want to run my app.

00:55:02.200 --> 00:55:08.000
So tell us about, as I'm fumbling around to find a place to show you.

00:55:08.000 --> 00:55:11.000
Anyway, tell us about running the app.

00:55:11.940 --> 00:55:13.320
Yeah, so there's a few different ways.

00:55:13.320 --> 00:55:22.320
Like the sort of traditional way, if you have like a, you know, client server architecture.

00:55:22.320 --> 00:55:24.000
So you have your notebook file.

00:55:24.000 --> 00:55:26.320
It's called, I don't know, notebook.py.

00:55:26.320 --> 00:55:28.420
It has some UI elements, et cetera.

00:55:28.420 --> 00:55:29.760
It has some code.

00:55:29.760 --> 00:55:32.640
You get an app, but just by default, you hide all the code.

00:55:32.640 --> 00:55:34.460
Now you have text outputs UI elements.

00:55:34.460 --> 00:55:35.840
You can think of that as an app.

00:55:36.060 --> 00:55:52.240
So if you type marimorunnotebook.py at the command line, it'll start a web server that's serving your notebook in a read-only session that you can connect to, et cetera.

00:55:52.240 --> 00:55:53.540
Can you do the widgets?

00:55:53.540 --> 00:56:01.720
Like if it's read-only, can I like slide the widgets to like see it do stuff?

00:56:01.720 --> 00:56:02.440
You know what I mean?

00:56:02.440 --> 00:56:03.200
Yeah, yeah, yeah.

00:56:03.200 --> 00:56:04.740
So you can slide the widgets, see it do stuff.

00:56:04.740 --> 00:56:07.900
If you just can't change the underlying Python code, like you can't like.

00:56:07.900 --> 00:56:08.700
Got it.

00:56:08.700 --> 00:56:10.660
But yes, that's true.

00:56:10.660 --> 00:56:12.660
Shell exec, rm-rf.

00:56:12.660 --> 00:56:13.500
Okay, let's go.

00:56:13.500 --> 00:56:14.840
Yeah, yeah.

00:56:14.840 --> 00:56:16.080
So that is not allowed.

00:56:16.080 --> 00:56:18.600
And so that's the traditional way, client server.

00:56:18.600 --> 00:56:31.420
But last year, we actually, I think it was last year, we added support for WebAssembly through the PyDive project, which is a port of CPython to WASM slash Unscriptum.

00:56:31.420 --> 00:56:35.200
And so now you can actually take any Marima notebook.

00:56:35.200 --> 00:56:45.660
And as long as you satisfy some constraints, which are documented on our website, you can export it as like static HTML and some assets and just throw it up on GitHub pages or server wherever you like.

00:56:46.920 --> 00:56:49.380
And that's also what our online playground is powered by.

00:56:49.380 --> 00:56:59.000
And we found this to be just like a really easy way to share notebooks, easy for folks in industry, easy for educators, and also just incredibly satisfying.

00:56:59.000 --> 00:57:09.280
In our docs, like we have tons of little Marima notebooks iframed into like various like API pages, etc.

00:57:09.400 --> 00:57:13.720
That just like lets you actually interact with the code as opposed to just reading it statically.

00:57:13.720 --> 00:57:14.980
Yeah, that's nice.

00:57:14.980 --> 00:57:16.240
That's super cool.

00:57:16.240 --> 00:57:19.600
So it's pretty low effort, it sounds like.

00:57:19.600 --> 00:57:29.160
And it's just, it's a lot of work to run a server and maintain it, especially if you're going to put it up there so other people can interact with it.

00:57:29.720 --> 00:57:33.720
Then you've got to worry about abuse and all that kind of stuff.

00:57:33.720 --> 00:57:38.900
If you can ship it as a static website, people are just abusing themselves if they mess with it anyway.

00:57:38.900 --> 00:57:40.000
Exactly.

00:57:40.000 --> 00:57:44.900
Like he, I had to give like huge props to like the Piedive maintainers.

00:57:44.900 --> 00:57:51.700
They are amazing, really responsive and just building this labor of love.

00:57:51.700 --> 00:58:00.820
And like, I don't know, they are really pushing the, yeah, pushing the needle on sort of the accessibility of Python.

00:58:00.820 --> 00:58:02.300
Yeah, that's awesome.

00:58:02.300 --> 00:58:04.320
Have you done anything with PyScript?

00:58:04.320 --> 00:58:07.360
I haven't done anything with it.

00:58:07.360 --> 00:58:08.140
I know of them.

00:58:08.140 --> 00:58:10.160
So they also use Pyodide underneath the hood.

00:58:10.160 --> 00:58:16.640
Yeah, they let you pick between Pyodide for more data science-y stuff and MicroPython for more faster stuff.

00:58:18.740 --> 00:58:22.740
I am like pretty not educated about MicroPython.

00:58:22.740 --> 00:58:28.180
I read about it, but I'd be curious on your take also, like on choosing one person.

00:58:28.180 --> 00:58:32.940
Yeah, well, I think it's brilliant if you want like a front-end framework equivalent.

00:58:32.940 --> 00:58:39.960
If you want PyView or PyReact or whatever, you don't need all the extras.

00:58:39.960 --> 00:58:44.800
You kind of need the Python language and a little bit of extras and the ability to call APIs, right?

00:58:45.200 --> 00:58:56.200
And so MicroPython is a super cut-down version that's built to run on like little tiny chips and self-contained systems on a chip type things.

00:58:56.200 --> 00:58:57.920
So it's just way lighter.

00:58:57.920 --> 00:59:01.500
It's 100K versus 10 megs or something like that, you know?

00:59:01.560 --> 00:59:04.760
If it solves the problem, right?

00:59:04.760 --> 00:59:10.700
If it gives you enough Python, I guess is the way to think of it, then it's a really cool option for front-end things.

00:59:10.700 --> 00:59:12.420
I don't know that it works for you guys, right?

00:59:12.420 --> 00:59:19.120
Because you want as much compatibility with like Matplotlib and Seaborn and all these things.

00:59:19.220 --> 00:59:28.360
But if your goal is like, I want to replace the JavaScript language with the Python language, and I know I'm in a browser, so I'm willing to make concessions, I think it's a pretty good option.

00:59:28.360 --> 00:59:29.720
Yeah, that makes sense.

00:59:29.720 --> 00:59:30.240
Yeah, you're right.

00:59:30.240 --> 00:59:31.460
We want max compatibility.

00:59:31.460 --> 00:59:41.640
Like we have one demo where like you can load SKLearn, take PCA of these like images of numerical digits, put it in all Terraplot, select them, get it back as a data frame.

00:59:41.700 --> 00:59:44.780
That's all running in the browser and like it's magical.

00:59:44.780 --> 00:59:46.280
It's on your home screen.

00:59:46.280 --> 00:59:49.520
People can watch the little embeddings explorer.

00:59:49.520 --> 00:59:50.180
It's super cool.

00:59:50.180 --> 00:59:51.160
It is very cool.

00:59:51.160 --> 00:59:55.780
And it's honestly magical what PyDat has been able to enable.

00:59:55.780 --> 00:59:57.080
Yeah.

00:59:57.080 --> 00:59:59.560
I imagine it's just getting started.

00:59:59.560 --> 01:00:00.860
I think so.

01:00:00.860 --> 01:00:01.580
Yeah.

01:00:01.580 --> 01:00:03.280
Yeah.

01:00:03.280 --> 01:00:04.880
They're constantly shipping.

01:00:04.880 --> 01:00:06.800
They just added support for Wasm GC.

01:00:06.800 --> 01:00:10.100
So performance is increasing.

01:00:10.480 --> 01:00:13.460
Exposed the bug in WebKit along the way.

01:00:13.460 --> 01:00:14.320
Wow.

01:00:14.320 --> 01:00:14.620
Okay.

01:00:14.620 --> 01:00:15.420
That's good.

01:00:15.420 --> 01:00:16.520
Yeah.

01:00:16.520 --> 01:00:18.280
Cool.

01:00:18.280 --> 01:00:19.940
All right.

01:00:19.940 --> 01:00:22.860
Well, we're getting to the end of our time here.

01:00:22.860 --> 01:00:25.040
So, you know, people are interested in this.

01:00:25.040 --> 01:00:26.680
They might want to try it for themselves.

01:00:26.680 --> 01:00:31.980
Maybe they're part of a science team or a data science team at a company.

01:00:31.980 --> 01:00:35.780
What do you tell them if they're interested in Marimo and they want to check it out?

01:00:36.880 --> 01:00:41.220
The easiest way, I think, is to just start running it locally.

01:00:41.220 --> 01:00:44.840
And so our sort of source of truth is our GitHub repo.

01:00:44.840 --> 01:00:47.460
So github.com, marimoteam slash marimo.

01:00:47.460 --> 01:00:52.440
Or if it's easy to remember, our homepage is marimo.io, which links to our GitHub.

01:00:53.100 --> 01:00:59.000
But then you can install from pip or uv or whatever your favorite package manager is and just sort of go to town.

01:00:59.000 --> 01:01:08.900
If you really just, you know, don't have the ability to do that for whatever reason, you can go to marimo.new, which will create a blank Marimo notebook powered by WebAssembly in your browser.

01:01:09.580 --> 01:01:12.260
It has links to various marimo tutorials, an example.

01:01:12.260 --> 01:01:14.280
Notebooks.

01:01:14.280 --> 01:01:19.740
Oh, we didn't even get to talk about the uv integration, which may be another time.

01:01:19.740 --> 01:01:23.800
But that's another way that marimo makes notebooks reproducible down to the packages.

01:01:23.800 --> 01:01:25.180
Oh, yeah.

01:01:25.180 --> 01:01:25.400
UV is awesome.

01:01:25.400 --> 01:01:27.160
UV is fantastic.

01:01:27.160 --> 01:01:30.100
I'm a huge fan of uv and Charlie Marsh and team.

01:01:30.780 --> 01:01:30.980
Yeah.

01:01:30.980 --> 01:01:36.520
But github marimo.io and docs.marimo.io is what I would look at.

01:01:36.520 --> 01:01:37.620
Awesome.

01:01:37.620 --> 01:01:40.080
Well, thank you so much for being on the show.

01:01:40.080 --> 01:01:41.980
Congratulations on the project.

01:01:41.980 --> 01:01:44.820
It's really come a long way, it sounds like.

01:01:44.820 --> 01:01:45.920
So it looks great.

01:01:45.920 --> 01:01:47.380
Thanks, Michael.

01:01:47.380 --> 01:01:48.080
I appreciate it.

01:01:48.080 --> 01:01:49.040
It was a lot of fun to chat.

01:01:49.040 --> 01:01:49.980
Yeah, you bet.

01:01:49.980 --> 01:01:50.440
Bye.

01:01:50.440 --> 01:01:51.260
Bye.

01:01:51.260 --> 01:01:53.320
you

01:01:53.320 --> 01:01:55.300
Thank you.

