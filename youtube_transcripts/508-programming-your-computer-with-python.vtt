WEBVTT

00:00:00.100 --> 00:00:02.340
Glyph, welcome back to Talk Python To Me.

00:00:02.480 --> 00:00:03.020
Great to have you here.

00:00:03.340 --> 00:00:04.160
It's great to be back.

00:00:05.400 --> 00:00:05.960
Yes, indeed.

00:00:06.600 --> 00:00:11.720
We are going to bring it home for everyone, personal computing right on their computer.

00:00:13.219 --> 00:00:15.080
We're going to program like it's 1997.

00:00:18.459 --> 00:00:22.860
Yeah, it's weird how you say that, and I totally know what you mean.

00:00:23.580 --> 00:00:29.160
But also, believe it or not, computers are way better than they were in 1997.

00:00:29.700 --> 00:00:30.340
Better than

00:00:30.340 --> 00:00:31.500
my Pentium? Are you serious?

00:00:32.940 --> 00:00:37.400
Not only are they better, there's just a lot more of them in front of you in a much smaller space.

00:00:38.200 --> 00:00:40.240
Yeah, I have a ridiculous number of computers in my office.

00:00:41.500 --> 00:00:42.620
It's almost out of control.

00:00:43.580 --> 00:00:46.120
But what do you do with the old ones? You turn them into servers. Come on.

00:00:47.040 --> 00:00:47.400
Home servers.

00:00:48.100 --> 00:00:49.600
That's a topic for a different day.

00:00:50.920 --> 00:00:51.560
Yeah, it sure is.

00:00:53.020 --> 00:00:56.000
All right, well, I'm super excited to talk about programming a computer.

00:00:56.380 --> 00:01:02.320
We're going to talk a little bit of Mac, a little bit of Linux, a little bit of Windows, and more broadly other things.

00:01:03.440 --> 00:01:06.940
Most of it with Python, not 100% necessarily, but almost all of it.

00:01:07.580 --> 00:01:08.600
It's going to be a great time.

00:01:09.020 --> 00:01:18.080
Now, before we dive into it, though, I'm sure there's some folks out there like, Glyph, that's the guy that just is so unique he gets to go by a single name.

00:01:18.260 --> 00:01:18.820
How awesome is that?

00:01:18.870 --> 00:01:19.580
But who is he anyway?

00:01:20.420 --> 00:01:20.680
Who are you?

00:01:21.000 --> 00:01:22.000
Who am I?

00:01:22.700 --> 00:01:23.420
That's a good question.

00:01:23.940 --> 00:01:26.880
I've had a varied and eclectic career, I guess.

00:01:28.260 --> 00:01:31.560
Right now, I am an independent software developer.

00:01:32.000 --> 00:01:33.680
I do some consulting here and there.

00:01:34.340 --> 00:01:36.240
I do a bunch of open source development.

00:01:36.980 --> 00:01:41.320
I've got a Patreon for my own independent stuff.

00:01:41.860 --> 00:01:45.880
I'm sure we'll get into some of it because some of it is directly relevant to today's topic.

00:01:47.060 --> 00:01:49.700
I'm doing some Mac desktop app development.

00:01:50.200 --> 00:01:55.300
I've got some secret projects, which I hope that I will eventually actually finish and release.

00:01:55.540 --> 00:01:57.140
That's awesome. You're here to announce those today.

00:01:58.760 --> 00:01:59.120
Unfortunately,

00:01:59.340 --> 00:02:01.680
I don't think we're going to be making any news just now.

00:02:03.880 --> 00:02:08.700
But yeah, so I do, and I do a bunch of open source project development.

00:02:08.780 --> 00:02:14.740
So my own Patreon and my own GitHub sponsors is mostly about different stuff that I'm doing.

00:02:15.240 --> 00:02:30.280
And this talk that we're going to be discussing today that I did give a couple years back, and I'm giving a refreshed version of at the upcoming PyCon, I did release a couple of packages when I first gave it.

00:02:31.420 --> 00:02:38.700
And that's the kind of stuff that I do with my personal backing that folks sign up for.

00:02:38.700 --> 00:02:51.620
But I'm also doing, I suppose I should say for any new listeners, I am the founder of the Twisted project, kind of precursor to AsyncIO in the standard library.

00:02:52.500 --> 00:03:03.260
And nowadays, now that AsyncIO is kind of standard in the standard library, it's a collection of protocol implementations and testing tools and whatnot for event-driven programming.

00:03:03.720 --> 00:03:08.340
And that is a member project of the PSF, which has its own GitHub sponsors.

00:03:08.920 --> 00:03:18.160
And I also am going to be doing some contract development to do maintenance on that so we can actually make use of some of the funding that we've collected over the years, do some more fundraising.

00:03:19.440 --> 00:03:24.920
Just a couple hours ago, I was doing our first-party WebSockets integration.

00:03:25.300 --> 00:03:26.880
So I do a lot of different things is what I'm saying.

00:03:27.060 --> 00:03:28.340
It's just got a lot going on.

00:03:29.180 --> 00:03:29.740
That's awesome.

00:03:30.700 --> 00:03:31.080
I love it.

00:03:31.180 --> 00:03:35.560
How does one get their project to become a member project of the PSF?

00:03:37.020 --> 00:03:38.160
Well, so technically speaking,

00:03:38.380 --> 00:03:43.360
Twisted is a, the PSF is the Twisted Project's fiscal sponsor.

00:03:45.060 --> 00:03:53.500
We got there via the circuitous route of really not wanting to make a nonprofit 501c3 25 years ago.

00:03:55.140 --> 00:04:02.720
And in the course of trying to avoid that, we signed up with the Software Freedom Conservancy.

00:04:04.020 --> 00:04:12.340
the SFC and twisted weren't quite aligned because twisted was like a really liberally licensed project that was mostly focused on infrastructure.

00:04:12.930 --> 00:04:22.720
and, we were not particularly interested in like the free software movement D aspects of things.

00:04:23.020 --> 00:04:31.900
And the SFC was largely about like GPL license enforcement, creating like a, a consistent legal environment under which the free software movement can operate.

00:04:32.180 --> 00:04:44.020
And so make sure people copy left, everything. Yeah. Well, let's, let's try to get everybody to copyleft everything, although they do do a little bit of that. And I'm sure they would certainly prefer it, but more about like enforcing it once you have, right.

00:04:44.110 --> 00:04:45.600
They have member

00:04:45.600 --> 00:05:07.720
projects like Inkscape and I believe they, well, they do work with a bunch of different projects to kind of litigate and try to, you know, get people to obey the GPL. And so since we had a little bit of a, differing goals. And the PSF is more interested in promoting Python as infrastructure. We moved over our fiscal sponsorship to the PSF.

00:05:08.970 --> 00:05:17.100
So mostly I think the way that you do it is you just ask, but the PSF is taking on a lot right now.

00:05:17.290 --> 00:05:20.980
So you may be in a long queue if you were to try to sign up now.

00:05:21.900 --> 00:05:28.040
Yeah, I'm sure. I'm sure it's a hard process and they filter a lot of stuff out that doesn't really fit.

00:05:28.660 --> 00:05:32.120
Obey the GPL. I feel like that's a good conference shirt or maybe a hat.

00:05:33.180 --> 00:05:33.780
You know what I mean?

00:05:34.460 --> 00:05:40.240
Yeah, yeah. Well, once again, a topic for a different day. I have enough feelings on that to fill a couple hours.

00:05:42.100 --> 00:05:59.400
Well, moving right along then. I first became aware of your talk sitting in the sunshine in San Francisco at Pi Bay two years ago, I suppose, coming up a year and a half, something like that, when you gave a variation of this talk, Programming Your Computer with Python.

00:05:59.750 --> 00:06:00.440
That was a great talk.

00:06:00.490 --> 00:06:01.680
That was one of my favorites from the conference.

00:06:02.220 --> 00:06:02.760
Thank you very much.

00:06:03.240 --> 00:06:07.820
Then I saw you're giving it again at PyCon, and so I thought, you know, you're still into this stuff.

00:06:07.880 --> 00:06:08.940
Let's talk some more about it.

00:06:11.200 --> 00:06:11.820
Yeah, yeah.

00:06:12.160 --> 00:06:31.920
So, I mean, what really inspired this talk in the first place, and it's pretty much as relevant now, I think, as it was back when I first thought to give it, was just like, Python is really popular in a bunch of different contexts, but particularly at PyBay, right?

00:06:31.990 --> 00:06:43.140
Like there's different audiences, and PyBay and PyCon, I think, have a kind of similar audience in that you get a lot of people doing the typical stuff with Python, which is to say backend development and web development.

00:06:43.620 --> 00:06:46.300
A lot of APIs, a lot of AIs, a lot of Jupyter.

00:06:46.600 --> 00:06:46.920
Right.

00:06:48.000 --> 00:06:52.420
And Jupyter is starting to edge a little bit closer to what I'm talking about here.

00:06:53.220 --> 00:06:57.420
but it is still fundamentally kind of back-endy.

00:06:59.020 --> 00:07:06.960
You kind of expect the code to run on a big cluster or something, and there's just not a ton of local compute.

00:07:08.870 --> 00:07:12.360
Your typical data scientist is doing batch stuff.

00:07:13.360 --> 00:07:15.000
Jupyter has little...

00:07:15.060 --> 00:07:21.360
And Jupyter is, in a way, like a microcosm of Python itself in that there are interactive widgets in Jupyter.

00:07:21.640 --> 00:07:25.300
you could be programming stuff kind of quasi-locally, right?

00:07:25.360 --> 00:07:27.760
Like you could be interacting with your own file system.

00:07:28.140 --> 00:07:33.360
You could be building stuff that you can directly manipulate the data, but like you probably aren't.

00:07:33.520 --> 00:07:41.800
You're probably just loading up some data frames and some NumPy arrays or whatever and then doing a bunch of batch computations on them.

00:07:41.860 --> 00:07:48.560
And so we build all these skills about just generalized software development.

00:07:48.800 --> 00:07:53.400
Like most of the skills that you build while working on Python do generalize.

00:07:54.320 --> 00:08:09.020
And then we kind of staple those general skills to this very specific, like a couple of very specific use cases when Python's like a super general tool and there exist all these libraries and all these tools to help you put Python in all kinds of places to solve all kinds of problems.

00:08:10.140 --> 00:08:16.040
And then when we need to do like, we solve some other problem, we end up just picking some other tool.

00:08:17.620 --> 00:08:19.440
And this is in a way, right?

00:08:19.540 --> 00:08:28.120
We're talking about this one talk that I've put together and that I've delivered a few times and will be delivering again.

00:08:28.620 --> 00:08:35.280
But there's kind of a through line through a lot of my public speaking and a lot of the topics that I've covered that are different aspects of this.

00:08:35.800 --> 00:08:39.500
We've got, there's this one, which is like programming your own local computer.

00:08:39.590 --> 00:08:43.520
But there's also desktop development and there's also mobile development.

00:08:43.789 --> 00:08:44.820
And I've talked about fronted.

00:08:44.880 --> 00:08:55.320
I gave a presentation, I don't even know when, maybe PyCon 2009 or something about like using, but before there was PyScript, there was Pyjamas, right?

00:08:55.840 --> 00:09:06.400
PyJS, these like front end frameworks where you could build whole front ends with Python in the browser and like, you know, because there's, Python's the second best language for everything, right?

00:09:06.500 --> 00:09:08.560
And that's really, really powerful.

00:09:08.720 --> 00:09:16.100
It's kind of better than being the best language for something because the best, like the best language for making a Mac app is Swift, right?

00:09:16.260 --> 00:09:19.860
Like you just get the first party thing from Apple It's a really easy onboarding experience.

00:09:22.020 --> 00:09:25.400
But the problem with that is that it's the best language for Mac app development.

00:09:25.940 --> 00:09:29.780
So everything else is like a second-class citizen in the Swift world.

00:09:30.440 --> 00:09:33.060
Or a complete foreigner where it doesn't work at all.

00:09:33.060 --> 00:09:34.080
Right, exactly.

00:09:35.010 --> 00:09:40.580
And I do say a second-class citizen because there is a Swift backend ecosystem and you can kind of use it for that stuff.

00:09:40.950 --> 00:09:45.400
And there is a bunch of open source work, but it's very clearly deprioritized.

00:09:45.520 --> 00:09:51.500
Even as Apple itself invests resources into it, It's just clearly never going to be the thing because they have a strategic vision.

00:09:51.700 --> 00:09:56.040
They're all about moving miles and miles of capacitive touchscreen glass.

00:09:56.320 --> 00:09:58.940
And if you're not in the critical path of doing that, then

00:09:58.940 --> 00:10:00.560
fundamentally the

00:10:00.560 --> 00:10:02.320
market is just not going to prioritize that.

00:10:03.820 --> 00:10:10.240
Even within the Apple ecosystem, the Mac desktop is deprioritized compared to iOS.

00:10:10.700 --> 00:10:10.880
Right.

00:10:11.080 --> 00:10:13.980
And the Mac is doing very, very well right now.

00:10:14.220 --> 00:10:17.200
It's not a dire situation, but you can still tell.

00:10:17.600 --> 00:10:23.860
There's still hints there about how that kind of financial destiny shapes things.

00:10:24.860 --> 00:10:28.220
And in the Python world, people just kind of do stuff.

00:10:28.450 --> 00:10:31.600
And we don't have like a roadmap or a set of priorities, right?

00:10:31.760 --> 00:10:34.240
There are certainly economic pressures, right?

00:10:34.340 --> 00:10:40.580
Like AI is certainly distorting the landscape a little bit right now in terms of what gets interest and hype.

00:10:40.710 --> 00:10:43.200
But like if you're doing something cool with Python, right?

00:10:43.320 --> 00:10:47.320
Like Blender has Python in it, and you can just use that.

00:10:47.600 --> 00:10:48.720
And it's been there for years and years.

00:10:48.920 --> 00:10:49.860
It's not going anywhere, right?

00:10:49.960 --> 00:10:51.440
Like it's not getting deprioritized.

00:10:51.440 --> 00:10:58.060
The people who put Python into Blender and do stuff with that have their reasons for doing it, and they're going to keep doing it.

00:10:58.840 --> 00:11:08.340
There's no email they're going to get from an executive that says, ah, never mind, you know, Python really needs to focus on AI now.

00:11:08.520 --> 00:11:10.160
So Blender's an LLM today, right?

00:11:10.340 --> 00:11:10.420
Like,

00:11:10.660 --> 00:11:11.280
no, they have

00:11:11.280 --> 00:11:12.420
their own stuff that they're working on.

00:11:13.260 --> 00:11:17.660
You probably get it to render the words LLM, but that's not what they mean.

00:11:18.220 --> 00:11:18.360
Sure.

00:11:21.460 --> 00:11:36.960
So anyway, so all that said, what that means, Python being the second best language for everything means that if you're going to do a desktop thing with Python, you still have access to all of those libraries and all those tools that you could bring with you.

00:11:36.970 --> 00:11:57.780
If you're going to do desktop automations in Python instead of like AppleScript, You've got all the libraries that come from the world of Python that allow you to have access to all of this power and all that expertise that you've built up over the course of your career doing back-end stuff or data analysis that you can then just do on your own computer.

00:11:58.590 --> 00:12:06.200
And so there's a few aspects to this, which are there's the personal automation stuff, there's the user interface stuff.

00:12:08.000 --> 00:12:11.420
So how would you like to approach this?

00:12:11.420 --> 00:12:12.480
What would you like to talk about first?

00:12:12.940 --> 00:12:22.060
Let's start with riffing a bit on why local computing matters or maybe why it shouldn't be as overlooked as it is.

00:12:24.640 --> 00:12:26.119
I mean, I think that there's...

00:12:26.630 --> 00:12:34.660
Well, so, okay, we've talked a lot about the library ecosystem and all these different tools and functionality, whatever, but bring it back down to fundamentals.

00:12:35.580 --> 00:12:38.820
Your computer is probably really, really fast.

00:12:39.170 --> 00:13:02.200
Even if you don't have the best top-of-the-line machine, and a lot of us as developers do have a lot of privilege to have access to extremely powerful hardware, a laptop that you can get right now for kind of a middle-of-the-road, affordable laptop price is hundreds of times more powerful than the most powerful server from a couple of decades ago.

00:13:03.100 --> 00:13:04.960
You have so much power at your fingertips.

00:13:07.040 --> 00:13:58.740
and not only that but there's a latency issue too even if your computer weren't that powerful even a few years ago when computers didn't have as much CPU and as much RAM and there's kind of a slope that goes upwards over time where there's always more of those things so like anytime you go backwards a few years you'll have less of it but there's persistently throughout the history of computing you pretty much always get better latency if you're doing something locally. And so if you are trying to get something done, if you have a workflow that you're executing many, many times a day, and you want to get it done quickly, your local computer is probably faster than any remote server you have access to just to get the task kicked off, get all the data resident.

00:13:59.560 --> 00:14:02.540
I have an eight core server for all the infrastructure at Talk Python.

00:14:03.840 --> 00:14:06.140
I think 8 core, 16 gigs RAM, something like that.

00:14:06.220 --> 00:14:06.620
It's plenty.

00:14:07.280 --> 00:14:13.680
I'm pretty sure my M4 Mac mini on a single core operation is faster than it.

00:14:14.700 --> 00:14:14.780
Yeah.

00:14:15.070 --> 00:14:18.760
And not only that, but like, and it's interesting how you phrase that, right?

00:14:18.840 --> 00:14:20.940
Like you don't even know, right?

00:14:20.960 --> 00:14:25.300
You're not even sure how much compute you have locally because you're not, you're not stressing it, right?

00:14:25.340 --> 00:14:26.160
Like you're not using it up.

00:14:26.280 --> 00:14:32.520
Not to mention the fact that those that talk Python infrastructure, you know, running the most popular podcast in the Python space.

00:14:32.710 --> 00:14:34.360
I'm sure that it's all very heavily loaded.

00:14:34.580 --> 00:14:36.820
There's stuff happening to it all the time.

00:14:37.210 --> 00:14:44.640
Every time you post anything on the Fediverse, it's got to be fetched 100 million times or whatever the hug of death is these days.

00:14:45.340 --> 00:14:45.780
It's

00:14:45.780 --> 00:14:48.300
like a DDoS that you use yourself every time you post something.

00:14:49.520 --> 00:14:49.660
Right.

00:14:49.770 --> 00:15:24.520
And so you have all of your local compute is also, in addition to being probably way more powerful than you initially would give it credit for because you think of it as a desktop or a mobile device as opposed to a really powerful computer. In addition to it being super low latency, it's also probably just idle all the time. It's not doing anything. And if you're plugged in and you're at a desk, if you're not literally mobile on battery all the time, that's free real estate. You can just use it for whatever you need. You got lots of RAM, you got lots of disk, You got lots of CPU overhead.

00:15:26.260 --> 00:15:29.280
To some extent, this is also kind of my secret motivation for doing this.

00:15:30.560 --> 00:15:37.560
Over the years in the industry, and you can kind of see this with that push towards iOS and iPads and mobile devices and web front ends, right?

00:15:37.660 --> 00:15:44.240
There's always this push for the industry as overall to say, maybe you don't need so much power locally.

00:15:44.360 --> 00:15:45.920
Maybe we should take that away and put it in the cloud.

00:15:46.100 --> 00:15:47.620
Wouldn't it be more convenient if it was all

00:15:47.620 --> 00:15:48.060
in the cloud,

00:15:48.140 --> 00:15:48.220
right?

00:15:48.320 --> 00:15:54.060
And there's no nefarious individual or group that's doing this, but it's just a constant economic pressure.

00:15:54.620 --> 00:15:57.100
And my personal feeling is like, no, no, give it to me.

00:15:57.260 --> 00:15:58.660
Put all the compute locally.

00:15:58.800 --> 00:15:59.600
I want to have it.

00:15:59.620 --> 00:16:01.080
I don't know what you're doing with it.

00:16:01.100 --> 00:16:06.640
I don't want it multi-tenanted in the cloud where I have fewer security guarantees and fewer privacy guarantees.

00:16:06.830 --> 00:16:10.840
And if I want things to be fast, I have to move them away to be less secure.

00:16:11.440 --> 00:16:12.300
I want it to be

00:16:12.300 --> 00:16:12.560
local.

00:16:12.630 --> 00:16:13.060
So I want

00:16:13.060 --> 00:16:15.580
people to do things that require it to be local.

00:16:16.200 --> 00:16:17.240
I am with you.

00:16:17.580 --> 00:16:17.680
Yeah.

00:16:17.860 --> 00:16:18.240
And I'm with you.

00:16:18.240 --> 00:16:26.020
And there's a lot of interesting technologies these days that make that possible, from local LLMs to Docker to a bunch of things.

00:16:27.440 --> 00:16:28.820
I don't know how you feel about it.

00:16:28.900 --> 00:16:30.700
It sounds like we might be on the same page.

00:16:31.480 --> 00:16:33.240
To me, it's also a bit of agency.

00:16:34.620 --> 00:16:40.300
I don't want the only place that my code can run is on a bespoke cloud from one of the hyperscalers.

00:16:40.660 --> 00:16:46.180
I want to be able to, at maximum complexity, say Docker Compose up and then run my code.

00:16:46.660 --> 00:16:48.380
More likely, just run my code.

00:16:48.920 --> 00:16:51.580
Yeah, well, and there's a scaling issue there, too.

00:16:51.700 --> 00:17:19.140
If you try to make sure that you can run, and we'll get to UIs and interactivity in a bit, but even if you're just running your back-end batch code, if you can run your full deployed cloud-based web application on your local computer, And you can have an equivalent environment that you can bring up with Docker Compose or whatever.

00:17:21.480 --> 00:17:25.640
I forget what the tiny Kubernetes is, the K some number.

00:17:25.800 --> 00:17:26.260
Kube Control.

00:17:26.860 --> 00:17:27.339
Kube

00:17:27.339 --> 00:17:27.620
Control.

00:17:28.220 --> 00:17:32.180
There's also K7S, I think.

00:17:32.680 --> 00:17:33.320
There's some tool that

00:17:33.320 --> 00:17:34.540
scales

00:17:34.540 --> 00:17:35.380
everything down for you.

00:17:36.920 --> 00:17:42.460
If you can run it on your laptop, then you can run it on an alternate host.

00:17:43.100 --> 00:17:57.060
Speaking now, kind of stepping out of my weird hippie activist, individual activism frame of reference and into my I'm actually a consultant that does business for corporations kind of role.

00:17:57.620 --> 00:18:17.360
They're actually pretty aligned value-wise because if the only place that you can run your cloud application is in a hyperscaler's cloud, then you have no price pressure driving the competitive landscape in a way that benefits you as the application developer.

00:18:19.120 --> 00:18:37.240
I won't say a brand name, but your cloud provider will ratchet up your costs and then you'll just have to pay more costs. There's no way that you have any leverage against them to say, well, because you can't credibly say, I'll move somewhere else because moving somewhere else becomes this huge migration cost.

00:18:37.400 --> 00:18:37.480
Now,

00:18:37.640 --> 00:18:39.120
there's

00:18:39.120 --> 00:18:54.880
limits to that. There are applications that you really can't run just fully on a laptop, But there's a way larger proportion of our listeners today who can totally just do that than think they can.

00:18:56.299 --> 00:18:58.700
Most applications can actually just run on a laptop.

00:18:59.020 --> 00:19:00.500
I don't know what number you'd put on it.

00:19:02.100 --> 00:19:04.560
I would say it's got to at least be 95%.

00:19:05.799 --> 00:19:26.480
Yeah, it's tough to put a number on it like that, but it is also the kind of thing where if it's not 95%, there's also a lot of the ones that really can't because they're architected around cloud-native or branded technologies that have these very specific APIs, it's not clear to me that that's bringing a lot of benefits in a lot of cases.

00:19:27.940 --> 00:19:45.260
Especially because whenever you're running something locally, especially if you can make sure that it's easy to be portable and you can run it locally on your Mac, locally in WSL, right?

00:19:45.480 --> 00:19:49.680
Not just in Docker, but kind of in the same environment that your dev tools live.

00:19:50.060 --> 00:20:09.240
If you can maintain that level of portability, the increase in operational costs that you have when you have to go and do complicated stuff to get the reliability and the elasticity that your cloud provider might give you, you actually get a huge amount in just like, you can run a debugger on it.

00:20:09.480 --> 00:20:10.900
You can single step through the code,

00:20:11.110 --> 00:20:11.240
right?

00:20:11.440 --> 00:20:12.060
The ability

00:20:12.060 --> 00:20:13.740
to do that is really overlooked.

00:20:15.140 --> 00:20:24.180
That's not to denigrate debugging and production, using tools like Honeycomb that can give you traces and help you really understand what's happening at scale.

00:20:25.000 --> 00:20:28.720
There's a lot of logical abstractions which you don't need to scale up to understand what's going on with them.

00:20:29.080 --> 00:20:36.140
Single-stepping and debugging and being able to run in a in-vitro environment is really, really a useful feature.

00:20:37.040 --> 00:20:40.780
It doesn't seem like you're giving up anything, But you are when you don't

00:20:40.780 --> 00:20:41.440
have that ability

00:20:41.440 --> 00:20:42.120
to run it locally.

00:20:42.480 --> 00:20:43.040
Yeah, absolutely.

00:20:44.039 --> 00:20:50.240
And if you can run it locally or in Docker, the chance is that you can just say, you know what, I don't want to be in this cloud anymore.

00:20:50.600 --> 00:20:52.360
Some new opportunities opened up.

00:20:53.080 --> 00:20:53.260
Hetzner

00:20:53.260 --> 00:20:53.820
has a new

00:20:53.820 --> 00:20:54.640
local data center.

00:20:54.940 --> 00:20:56.340
DigitalOcean has something amazing.

00:20:56.560 --> 00:21:00.040
And it's a fifth the price and just as fast or faster.

00:21:00.760 --> 00:21:01.280
Let's just move.

00:21:01.600 --> 00:21:01.880
You know what I mean?

00:21:02.040 --> 00:21:08.620
And if it's, well, we move our Docker containers and our little system just goes over, that's one thing.

00:21:08.760 --> 00:21:15.120
if you've got to rework serverless and queuing and all of a sudden it's like, yeah, but no.

00:21:15.759 --> 00:21:16.320
Right.

00:21:16.460 --> 00:21:16.640
And

00:21:16.640 --> 00:21:20.240
you can still make use of technologies like serverless.

00:21:20.380 --> 00:21:43.480
If you develop all your code as if it's a library and most of your logic is in kind of a neutral form factor where you can use it from a desktop app or a Docker container or a serverless container, it may not be worth investing that much in making that possible if that's not really your core competency and you don't need it.

00:21:44.240 --> 00:22:14.100
But it's not worth nothing, and it's worth investing a little bit. And often one of the points that I try to make in the talk is it's not actually that hard. It seems really, really challenging, but a lot of the times it's just because the desktop tools and the local development tools are not quite as well documented. It's not as easy to Google for something and get an immediate result for an error message just because not as many people are using them.

00:22:14.340 --> 00:22:15.660
So there's a collective action thing here.

00:22:16.340 --> 00:22:23.900
It's a call to action to get more folks involved in doing things locally because it makes the whole process easier for everybody else.

00:22:24.440 --> 00:22:26.120
Yeah, I 100% agree.

00:22:26.830 --> 00:22:31.300
Before we jump too far from this whole server aspect you were talking about, are you familiar with Coolify?

00:22:32.080 --> 00:22:33.760
I'm not. That's the first I'm hearing of it.

00:22:33.920 --> 00:22:45.440
This is a pretty interesting open source project that is basically, I'll use their H2, an open source and self-hostable Heroku Netlify Vercel alternative.

00:22:46.280 --> 00:22:56.580
So basically it's like some kind of Docker Compose Up sort of thing, but then it gives you the platform to get push into and host all your things, kind of like those places I named.

00:22:56.980 --> 00:22:58.220
Oh, I'd have to check that out.

00:22:58.880 --> 00:23:00.000
Yeah, it looks pretty interesting.

00:23:01.200 --> 00:23:07.560
And, you know, if you're thinking, well, we have more requirements, We need continuous deployment and all these things.

00:23:08.240 --> 00:23:08.440
Look around.

00:23:08.510 --> 00:23:10.540
I think there's a lot of interesting options.

00:23:10.780 --> 00:23:15.140
And then this could go on EC2 or it could go on Hetzner or it could go on DigitalOcean or Linode or whatever.

00:23:15.340 --> 00:23:16.880
There's a lot of interesting options here.

00:23:17.880 --> 00:23:32.060
And just one more thing on the whole local compute power part of this, which is that because all of these alternatives that they're talking about have famously had drama with their free tiers and with the amount of compute that you get.

00:23:32.680 --> 00:23:36.700
One of the other things, like one of the examples I bring up in the talk is Twisted's test suite.

00:23:37.890 --> 00:23:42.560
And just like how much faster it can be if you run it locally.

00:23:44.000 --> 00:23:48.000
And this is particularly of interest to the open source part of the Python community.

00:23:48.680 --> 00:23:55.880
And the reason I'm raising it here is because free tiers are one of the places that you see this.

00:23:56.200 --> 00:24:15.800
If you actually go all in in a kind of server-first workflow and you have a for-profit company and you're developing software that you have customers for, the local compute power argument does start to fall apart a little bit because you really can get very, very powerful servers that can run your CI really, really fast.

00:24:16.920 --> 00:24:22.720
But also, you're not getting those for free in the GitHub Actions tier that open source projects have access to.

00:24:22.790 --> 00:24:28.260
And particularly if you need to test on macOS and Windows, you're going to be paying for that.

00:24:29.400 --> 00:24:39.000
If you are trying to subsist on free resources, you'll often find they're very slow and heavily contended with a lot of other projects.

00:24:39.680 --> 00:25:33.720
And so having the ability to run your tests locally to decrease the pressure on your free tier trial test host or your free tier GitHub Actions or CircleCI or whatever, you will uh the difference in speed there is huge because you're like way way over provisioned in your local compute and these providers who would really like you to pay a pretty penny for like the really fast stuff a lot of us just like open source projects for logistical reasons often have to even if the project does have some resources we still need to stay in the like free tier of these things because like if your library has a big budget for CI but all of your downstreams that are actually using it have to use the GitHub Actions free tier, you really want to be living there anyway even if you could afford to live elsewhere.

00:25:34.060 --> 00:25:37.780
Right. Right. Otherwise it gets out of sync and it doesn't work so well.

00:25:37.880 --> 00:25:38.000
Yeah.

00:25:39.560 --> 00:25:43.220
Yeah. Cool. All right. Well let's talk desktop apps a bit.

00:25:44.530 --> 00:25:51.420
So give us some of the benefits of desktop first development. I mean hotkeys, notifications, what else?

00:25:52.050 --> 00:25:54.500
Well, so those are the big ones.

00:25:55.680 --> 00:25:59.620
And there are other things.

00:26:00.020 --> 00:26:01.720
Hotkeys, notifications, sounds.

00:26:04.020 --> 00:26:04.540
Geolocation.

00:26:05.180 --> 00:26:09.860
Geolocation, HUD overlays, the ability to put a window onto the screen.

00:26:12.080 --> 00:26:24.020
The fact that you can do all of those things, The presence of any one of those features, the ability to pop up a window or whatever, many of these things can kind of be emulated in web apps.

00:26:24.340 --> 00:26:27.340
The browser is a really powerful deployment platform these days.

00:26:29.240 --> 00:26:40.200
But the way that you develop something, if it is running locally, like case in point.

00:26:40.220 --> 00:26:48.320
So there's this app that I'm developing called Pomodoro Boros, which I'm running right now.

00:26:48.560 --> 00:26:55.200
It is a Pomodoro timer, and it puts a big old HUD overlay over your whole screen so that you do not get distracted.

00:26:55.400 --> 00:26:59.400
Because I have ADHD, and I need, if it's not in my visual field, it might as well not exist.

00:27:00.180 --> 00:27:14.400
And so an app like that, not only can it remain running in the background, which, like, if you quit your browser, you close browser tab, it can go away.

00:27:14.610 --> 00:27:18.580
And there's like no, you can summon it back if you intentionally want to.

00:27:19.340 --> 00:27:24.280
If you as the user remember to relaunch that tab and repin it and put it in the

00:27:24.280 --> 00:27:24.700
right place

00:27:24.810 --> 00:27:26.520
and everything, like you can do it.

00:27:27.020 --> 00:27:32.540
But first of all, speaking as a person of ADHD, I don't want to be doing that all the time.

00:27:32.590 --> 00:27:33.860
And I physically can't sometimes.

00:27:34.390 --> 00:27:41.000
But also just like even for neurotypical people with plenty of executive function, that's the computer's job.

00:27:41.220 --> 00:27:43.440
Like the computer's job is to remember to run stuff, right?

00:27:43.660 --> 00:27:47.100
Like, and you can have the app relaunch itself.

00:27:47.280 --> 00:27:49.060
It can launch it login, right?

00:27:49.400 --> 00:27:51.860
Like having a browser launch it login is a whole rigmarole.

00:27:52.000 --> 00:27:57.920
It's like not impossible, but it requires lots of weird little hacks and it tends to be kind of fragile.

00:28:00.340 --> 00:28:06.820
Whereas, you know, you can make an app that doesn't have a command queue or like Alt F4 quit, right?

00:28:06.920 --> 00:28:09.660
Like you can have it go into the background and run by itself.

00:28:09.810 --> 00:28:11.200
It can schedule cron jobs.

00:28:11.310 --> 00:28:24.060
It can just generally keep itself running and automating away in such a way that if it needs to grab your attention again via a notification, via a geolocation hook, right?

00:28:24.160 --> 00:28:33.040
Like you can not just do geolocation to geofence yourself, but also to like schedule your app to launch when crossing a geolocation fence.

00:28:33.160 --> 00:28:35.580
That's a little trickier, but like it is definitely a thing you can do.

00:28:37.820 --> 00:28:47.380
All of those things make it so that you can have code that runs when it needs to run and that you can interact with immediately.

00:28:47.780 --> 00:28:55.920
You can have a cloud service send you a push notification or a text message or whatever and try to remind you that you should do something.

00:28:56.620 --> 00:29:10.660
But with a desktop app, with something that's running locally, even if it's running locally in your terminal, One of the other things that I have, I have a different app called PinPal, which is all about helping you memorize new passwords.

00:29:11.940 --> 00:29:24.500
PinPal can actually run, I'm working on the desktop app version, but the other thing it can do is you just set it up in your PS1 so that if it's time to rehearse your passwords, it puts a little badge in your command prompt.

00:29:25.060 --> 00:29:43.000
And so even if you're not going for the full high-touch desktop API integration, Just the fact that it's running in my local shell on every time it displays the prompt, that allows it to be much more present and something that I'm not going to forget.

00:29:43.260 --> 00:29:52.020
And certainly for things that involve my development workflow, I'm not going to forget something that can be sensitive to what my working directory is.

00:29:52.260 --> 00:29:59.760
It can activate things and deactivate things and make it so that anything that I need to do, the local computation has already happened.

00:30:00.200 --> 00:30:03.960
Like it's already done by the time I, as the user, I'm thinking that I need it.

00:30:04.360 --> 00:30:05.640
Yeah, that's awesome.

00:30:05.840 --> 00:30:09.200
And you could probably do like automation, accessibility things.

00:30:09.950 --> 00:30:16.180
Like you could have it run on a schedule or something when you're in your email or something like that.

00:30:16.260 --> 00:30:17.060
Like, hey, you're in your email.

00:30:17.140 --> 00:30:23.220
Remember that these two things need to be done now, but not, you know, not hassle you at 7 or 8 a.m.

00:30:23.300 --> 00:30:26.420
or whenever you said to hassle you, but like when you're already doing the thing, right?

00:30:26.720 --> 00:30:30.260
Yeah, and there are, That's another thing you can do.

00:30:30.540 --> 00:30:39.140
I'm not even sure if I mentioned this one in the talk, but there are two things that the word notifications means in the macOS world, at least.

00:30:40.600 --> 00:30:45.260
There's a UN user notification center, which is where you send notifications to the user.

00:30:46.040 --> 00:30:54.340
But there's also notifications, which are, or NS notification center, which is like just stuff is happening on the computer.

00:30:54.800 --> 00:30:57.900
Is your battery empty past a certain threshold?

00:30:59.120 --> 00:31:00.840
Like you said, you're in your email.

00:31:01.320 --> 00:31:07.500
You can ask the operating system not just what's the frontmost window, but tell me when the frontmost window changes.

00:31:08.860 --> 00:31:09.740
Send me an event.

00:31:10.700 --> 00:31:12.060
They're different on different operating systems.

00:31:13.880 --> 00:31:21.920
Unfortunately, a lot of this kind of breaks down on Windows because Windows is, and I say this as unbiasedly as I can, kind of a misery.

00:31:22.400 --> 00:31:24.780
There's so many just terrible APIs on Windows.

00:31:25.000 --> 00:31:26.840
Everything's possible, but nothing is easy.

00:31:28.200 --> 00:31:39.160
And so unfortunately, some of the talk that can very quickly show these rapid examples on Mac and Linux is like, and then on Windows, here's this 900-page book that was published 20 years ago.

00:31:39.360 --> 00:31:40.640
That's probably the way you have to go.

00:31:42.600 --> 00:31:43.300
Calm in particular.

00:31:43.900 --> 00:31:44.440
Let me introduce

00:31:44.440 --> 00:31:48.420
you to the Win32 API and D column, and you're going to have a good time.

00:31:48.720 --> 00:31:49.020
Right.

00:31:49.560 --> 00:31:58.760
And yeah, you keep thinking like, oh, there's going to be, well, didn't they get rid of all that when they upgraded to the WinRT API?

00:31:58.930 --> 00:32:02.220
And it's like, nope, Windows is a sedimentary operating system.

00:32:02.460 --> 00:32:02.760
It's just

00:32:02.760 --> 00:32:05.940
layers, one on top of another.

00:32:06.420 --> 00:32:07.480
Layers are formed.

00:32:07.670 --> 00:32:08.520
They are not removed.

00:32:08.920 --> 00:32:09.120
Exactly.

00:32:10.160 --> 00:32:10.420
So anyway,

00:32:10.440 --> 00:32:11.020
I

00:32:11.020 --> 00:32:14.980
don't want this to be like a trash talking Windows thing because there's definitely ways to do a lot of this on Windows too.

00:32:15.060 --> 00:32:22.680
There's message pumps that you can get from like, you open an HWIN in a foreign executable and you can kind of tell what it's doing.

00:32:25.040 --> 00:32:25.620
And I'm looking

00:32:25.620 --> 00:32:30.240
at some interesting things there to like track other applications and so on.

00:32:30.920 --> 00:32:40.500
You know, just to, I don't know if this is all P's folks or not, to put a good word out there for Windows, you know, you won't program your own stuff.

00:32:40.670 --> 00:32:48.120
Like VB6 and some of these rapid GUI tools were ridiculous back in the day, even though they're not, I'm sure you could still build with them.

00:32:48.240 --> 00:32:53.160
They're just like, I need a button here, a text box there, and when I click this, I need that to become a web browser.

00:32:53.460 --> 00:32:53.680
Click.

00:32:54.060 --> 00:32:56.460
You know, and that's like two, three minutes and you're good to go.

00:32:56.800 --> 00:33:06.300
Honestly, a lot of the stuff that is good about the Windows API, you end up kind of going through that portal back in time where you're like, how would I have done this in VV6?

00:33:06.820 --> 00:33:23.780
And then you like, and unfortunately, as I'm not a heavy Windows user, one of the problems is that like, The really good automation targets for Windows are frequently the things like Excel and Word.

00:33:24.100 --> 00:33:25.820
And I don't have Excel or Word.

00:33:25.920 --> 00:33:31.900
I got Steam and Windows Mail and a couple of open source applications in my Windows install.

00:33:32.600 --> 00:33:42.100
But if you have, there's also things like Excel Wings and people who are heavy Windows users who have more concrete automation use cases for doing things locally.

00:33:42.820 --> 00:33:58.580
There are a ton of ways that you can get really deep into a really rich API in a lot of the Microsoft first-party applications, which, again, this is one of those places where they're pushing people to the web-based Office 365 stuff.

00:33:58.820 --> 00:34:06.000
They still have a big investment local desktop platform, but a lot of people are not using it as much.

00:34:06.260 --> 00:34:11.440
If you get in there and you build a lot of workflows around that desktop stuff, Microsoft will notice.

00:34:11.740 --> 00:34:13.419
They will want to support you in doing that.

00:34:15.300 --> 00:34:24.020
And so, yeah, like the, there are lots of tools there for getting what you need to do done.

00:34:24.240 --> 00:34:26.520
The problem with Windows is really it's not as generalized.

00:34:26.919 --> 00:34:28.659
Like everything has its own API on Windows.

00:34:28.800 --> 00:34:33.460
And so you have to, on the Mac, I can tell you like, oh, well, there's just general way that you can learn about an application.

00:34:35.399 --> 00:34:37.879
And many applications have kind of a half-hearted implementation of it.

00:34:38.000 --> 00:34:48.600
On Windows, if you, like, It's much harder for a talk like mine to go and give a cursory level of like, hey, look at this wonderland. You can kind of get into lots of different things. And here's some brief examples.

00:34:48.820 --> 00:35:01.060
It's more like, no, no, on Windows, you have to kind of know what you want to do. Like once you know, and you're willing to dig in really hard on a specific automation target, there's lots there, but it may be somewhat different from system to system.

00:35:02.000 --> 00:35:16.560
Yeah. I haven't tried it, but a lot of the stuff that you would reach out and interact with for that stuff is in the COM, a bunch of COM objects, component object model, which are tremendously hard to build and get right. But once they're there, I think you can use them pretty easily.

00:35:17.080 --> 00:35:23.180
You can probably use that from Python pretty easily and then just look at the documentation for that thing.

00:35:23.380 --> 00:35:24.560
This is the tricky thing.

00:35:25.020 --> 00:35:57.340
So this is one of the things I'm enhancing for the next iteration of the talk is that I dug in a little deeper on those tools. There's a tool called Olay View, which is an ancient tool. If you bring that up and you start digging around in your local system, you can find a lot of these APIs. Win32 com is the, like, from PyWin32 gives you direct access to all that legacy stuff. And this is actually kind of a great way of illustrating the Python's the second best language for everything.

00:36:00.340 --> 00:36:09.300
You know, like, if you're doing stuff with C# these days, like the modern Microsoft tool chain, they push you really hard towards WinRT and the new way of doing things.

00:36:09.540 --> 00:36:14.800
And it's really difficult to get into the older com stuff because they're like, ah, that's deprecated.

00:36:14.920 --> 00:36:18.680
It's not something you're using with.NET.

00:36:19.360 --> 00:36:20.040
Forget about that.

00:36:20.260 --> 00:36:28.560
Whereas in Python, you can pip install WinRT, pip install PyWin32 right next to each other and be calling both different kinds of APIs.

00:36:28.800 --> 00:36:30.620
And it's perfectly easy.

00:36:30.760 --> 00:36:31.040
Like,

00:36:31.300 --> 00:36:33.980
again,

00:36:34.240 --> 00:36:36.500
because nobody's setting out a roadmap for the Python community.

00:36:36.610 --> 00:36:41.260
You know, and this is kind of why I like giving talks about stuff like this.

00:36:42.260 --> 00:36:47.300
If you're going to a conference and taking a tutorial, you could learn a whole new thing, right?

00:36:47.340 --> 00:36:54.040
Like, you can do a ton of learning in a three-hour tutorial.

00:36:54.120 --> 00:37:02.540
If you're going to a conference talk, you're getting the – also, okay, can folks see this screen on the live stream, by the way?

00:37:03.200 --> 00:37:05.200
On the live stream, I can't, not on the – Okay, so

00:37:05.200 --> 00:37:14.780
I do have to mention that Michael just brought up the Pi Win 32 page, and there are three maintainers, and the top one is me.

00:37:16.380 --> 00:37:32.380
Because as much as I'm not a Windows guy, I'm on that list actually because when at the advent of binary wheels, I was the one who kind of went in and said, like, PyWin32 has got to have like downloadable wheels for every version of Python.

00:37:32.430 --> 00:37:38.040
I built my own like fork of it because I couldn't get access for a while called PyPIWin32.

00:37:38.270 --> 00:37:48.040
It was just like no code changes, just it's built and it has a bunch of hacks to get the paths right so that you could just import it without like changing your Windows path or manually

00:37:48.040 --> 00:37:48.640
doing

00:37:48.640 --> 00:37:49.040
DLLs.

00:37:49.680 --> 00:37:49.820
So yeah,

00:37:49.960 --> 00:37:50.460
so I've

00:37:50.460 --> 00:37:51.360
been doing this for a long time.

00:37:53.980 --> 00:37:57.400
Yeah, so that definitely does this calm stuff as well.

00:37:57.490 --> 00:37:58.260
So that's super cool.

00:37:58.860 --> 00:38:15.200
Yeah, but the reason that I like giving talks about stuff like this is that you can give these pointers out to things where people have been toiling away, building all of this stuff for you in Python for years and years.

00:38:15.480 --> 00:38:16.260
There's PyWid32.

00:38:17.400 --> 00:38:20.700
There's Py, I think it's called, is it?

00:38:21.200 --> 00:38:23.260
Now I'm forgetting which one's the current one.

00:38:23.260 --> 00:38:26.920
But there's WinRT, the WinRT module on PyPI.

00:38:32.080 --> 00:38:34.860
There's the Python D-Bus.

00:38:35.200 --> 00:38:40.320
There's like all of these different tools that people have built integrations for your desktop and your operating system.

00:38:41.350 --> 00:38:51.120
And they're almost all like pretty recently maintained PyG object if you want to build GUI applications with

00:38:51.120 --> 00:38:51.860
the native toolkit

00:38:51.860 --> 00:38:52.960
for GNOME

00:38:54.060 --> 00:38:55.140
PyOBJC maybe

00:38:55.600 --> 00:39:26.060
yep PyObjective C and yeah and the PyObjective C is also a great example of like there are if you search PyPI for PyObjC dash framework you will find a zillion frameworks that are like all the things that have been wrapped so that

00:39:28.160 --> 00:39:29.440
Did I search the right thing?

00:39:30.280 --> 00:39:30.840
PyOBJC?

00:39:31.740 --> 00:39:32.560
PyOBJC, yeah.

00:39:33.020 --> 00:39:33.160
You

00:39:33.160 --> 00:39:34.240
dropped the C.

00:39:36.880 --> 00:39:37.440
Atomic is

00:39:37.440 --> 00:39:37.780
driving?

00:39:39.319 --> 00:39:40.000
If you

00:39:40.000 --> 00:39:43.980
add a C to the end of the search, yeah.

00:39:44.420 --> 00:39:45.900
And if you scroll down, there's like a ton of

00:39:45.900 --> 00:39:46.500
Yeah, Object,

00:39:46.780 --> 00:39:56.340
Core, Mass, Shortcut, CF Network. These are the accounts. These are the important subsystems of macOS, for example, right?

00:39:56.600 --> 00:39:56.780
Right.

00:39:56.920 --> 00:39:59.140
And there are dozens and dozens of them.

00:39:59.800 --> 00:40:00.120
Oh, yeah.

00:40:00.400 --> 00:40:04.480
Right, yeah. Like, just scroll and scroll and scroll. We're only to the Bs now.

00:40:06.420 --> 00:40:07.780
Go to the 14 pages. Let's go.

00:40:08.020 --> 00:40:08.300
Yeah.

00:40:08.380 --> 00:40:10.280
So there's tons and tons of stuff.

00:40:10.380 --> 00:40:13.500
like this whole universe that's available to you in Python.

00:40:14.860 --> 00:40:22.960
And this is why this is like a kind of a, as much as we were talking about very generalized, like, oh, you know, local compute is really powerful and everything.

00:40:23.020 --> 00:40:51.280
Like there's a general aspect to this, but there's a really Python specific aspect to this, which is there's all these libraries and tools that are not just, that were not just developed as a proof of concept, but are like consistently maintained and used pretty heavily in some like niche areas where people really are using them in production, but they're not really talking about them all that much because they don't think they're of interest to the community. They're not getting out there as much.

00:40:54.100 --> 00:41:00.780
Nobody's excited about Browser Engine Kit, which is just that thing built into macOS, and then oh, I'm talking to it from Python. Oh, okay.

00:41:01.140 --> 00:41:04.940
Good for you. It's not like I invented a new async web framework or anything, right?

00:41:05.000 --> 00:41:05.100
Right.

00:41:05.320 --> 00:41:24.940
Or here's my new system for integrating AI, you know, LLMs with, with cloud image generation and, you know, the, to defraud parking attendants or whatever the most recent, you know, hot startup is.

00:41:25.490 --> 00:41:38.240
The, like the, they're all, or, you know, or, or super high scale, you know, numerical computing or GP, it's not even called GP, GPU anymore.

00:41:38.460 --> 00:41:41.660
It's just like, you know, parallel compute.

00:41:44.140 --> 00:41:53.840
Not all these things make great individualized demos, but the infrastructure, there is a rich soil for you to plant

00:41:53.840 --> 00:41:54.420
all kinds

00:41:54.420 --> 00:41:56.080
of different applications in.

00:41:57.320 --> 00:42:15.280
And a lot of people, and actually this is something that I have not brought up in the talk, but that is something that I would love to kind of get out there as a, as an idea, which is I said like, you know, some of these tools, you use them, you get these weird error messages and you kind of get stuck.

00:42:15.420 --> 00:42:24.800
And a lot of people get stuck and bounce off attempting to use desktop stuff or local compute stuff because it's not as popular.

00:42:25.340 --> 00:42:26.560
So there's not as many resources.

00:42:26.800 --> 00:42:50.520
So people don't can't easily figure out how to use them, but quite often it's worth doing that little extra bit of work to dig in and figure out what the problem is because as frustrating and confusing as it can be to kind of trace through a traceback and somebody else's library that was like supposed to work and just isn't for some reason doing that debugging and maybe contributing a little bit upstream to some open source thing.

00:42:50.640 --> 00:42:58.280
That's a wrapper for the thing that you want to use is often not nearly as hard as like, Oh, well, there's a really good rust library for this.

00:42:58.420 --> 00:43:00.480
Let me just switch the whole project over to Rust.

00:43:00.480 --> 00:43:07.140
Or like, oh, this is really a Unity thing that I'm trying to do, so I'll just report all of my code to C#.

00:43:08.140 --> 00:43:15.400
It's straightforward because there's tutorials for how to do that, and you don't have to kind of go off by yourself to do this investigation.

00:43:16.520 --> 00:43:40.940
But it ends up being a lot harder in many cases to just go into a completely new ecosystem, redo all of the work that you've had to do understanding the problem domain, debugging, getting some high quality code to do whatever your primary thing is, just to access some new binding to some library that is available somewhere else.

00:43:41.580 --> 00:43:41.980
Yeah.

00:43:43.240 --> 00:43:46.540
Yeah, those are definitely fraught with the danger.

00:43:47.640 --> 00:43:52.220
I don't know if you've heard the big rewrite by Dylan Beatty, but I'll put it in the show notes.

00:43:55.480 --> 00:44:00.820
To the American Pie parody, which is like a six-minute song, and he goes through all the generations of

00:44:00.820 --> 00:44:01.380
rehiring the

00:44:01.380 --> 00:44:01.500
country.

00:44:01.580 --> 00:44:02.280
It's incredible.

00:44:03.120 --> 00:44:04.660
So I'll put that as a warning to folks.

00:44:05.040 --> 00:44:07.000
I haven't heard it, but I've experienced it.

00:44:08.530 --> 00:44:08.960
So, yeah.

00:44:09.520 --> 00:44:09.600
Yeah.

00:44:10.100 --> 00:44:11.440
This song will connect with you.

00:44:12.760 --> 00:44:30.260
You know, one of the things when I'm looking at this Pie PI listing here, it seems to me that as you're venturing out into these new areas that you're not super experienced with, Like, I know to do Python, but Objective-C, like, didn't even macOS stop doing that?

00:44:30.490 --> 00:44:35.420
I thought they did Swift, which still routes down to the same stuff, I'm pretty sure.

00:44:37.400 --> 00:44:49.420
But you could go to your favorite chat coding assistant and say, how would I accomplish this thing I want to accomplish in straight Swift?

00:44:50.180 --> 00:44:52.040
It could give you the answers using some of these APIs.

00:44:53.100 --> 00:44:57.220
And then you could say, now imagine there's a compatibility layer, rewrite it in Python.

00:44:57.380 --> 00:44:59.300
I bet you would be pretty darn close, right?

00:44:59.540 --> 00:45:05.800
As opposed to if you ask how to do it in Python, it might just go haywire and make up some crazy wrapper, right?

00:45:06.060 --> 00:45:06.340
Yeah.

00:45:08.600 --> 00:45:10.260
This is a place – so I personally

00:45:10.260 --> 00:45:15.880
have had just a series – like I am, I guess, an AI skeptic.

00:45:16.520 --> 00:45:16.640
Okay.

00:45:16.720 --> 00:45:17.160
And

00:45:17.160 --> 00:45:24.200
so I tend to, one of the most popular articles on my blog is the Grand Unified Theory of the AI hype cycle.

00:45:25.839 --> 00:45:35.960
And I have concerns about the energy use and the training data provenance and the copyright issues and all kinds of social stuff like that.

00:45:35.960 --> 00:45:39.900
But fundamentally, I am trying to educate myself about these technologies.

00:45:39.930 --> 00:45:42.720
I am trying to use them and learn what they're good at.

00:45:43.280 --> 00:45:46.420
I see some folks like Simon Willison having great success.

00:45:46.860 --> 00:45:48.120
Yeah, he's leading the way for sure.

00:45:49.220 --> 00:45:56.160
And I try to do some of this stuff, and they just faceplant for me really hard all the time.

00:45:56.260 --> 00:46:04.800
I have never had an LLM successfully do something that I want to do, possibly because the stuff that the LLMs are good at, I can do in my sleep.

00:46:05.040 --> 00:46:06.400
And so I've already

00:46:06.400 --> 00:46:06.640
typed

00:46:06.640 --> 00:46:09.440
all the code the LLM would type for me faster than it could get it out.

00:46:09.700 --> 00:46:18.860
And then I hit a problem like, oh, how do I do a business chat integration on macOS with, you know, PyOpC framework business chat?

00:46:19.360 --> 00:46:22.280
And it has no idea because there's no example code.

00:46:22.290 --> 00:46:22.980
It really is,

00:46:23.160 --> 00:46:23.840
you

00:46:23.840 --> 00:46:43.400
know, an example of a place where if an LLM is really good at doing a particular kind of thing with code, If you're getting a lot of really solid, quick, accurate, correct implementations, that probably means that there's just a ton of open source code that already does what you need.

00:46:43.540 --> 00:46:45.080
And libraries and examples, yeah.

00:46:45.320 --> 00:46:45.480
Right.

00:46:45.680 --> 00:46:48.100
You'd probably be better off just using a library that did that.

00:46:48.160 --> 00:47:00.860
And not to say that there's no cases where it can integrate two things, but it can integrate two things that are already kind of speaking the same language, that are largely in the same area of the token vector space in the model, right?

00:47:01.040 --> 00:47:04.140
Like that there's overlap between the way that these things are expressed.

00:47:04.840 --> 00:47:22.280
And being off the beaten path with some of these libraries that are less frequently used and that do require you to like know the Objective-C API, know the C# API, know the translation rule, and then express the thing in terms of the translation rule.

00:47:23.260 --> 00:47:24.680
Yeah, it can be really...

00:47:24.780 --> 00:47:41.260
You're definitely much better off in terms of both if you're using LLMs, using LLMs, but also even if you're just looking for reference material, learn the translation rules because they're often quite simple, and then look for the example in the other language, even if you don't know the other language.

00:47:41.520 --> 00:47:42.220
I don't really

00:47:42.220 --> 00:47:42.980
know Objective-C.

00:47:43.210 --> 00:47:44.219
I don't really...

00:47:44.240 --> 00:47:47.340
I mean, I know C and I like can kind of read it.

00:47:47.980 --> 00:47:49.660
There's not actually all that much to Objective-C.

00:47:50.820 --> 00:47:52.160
I definitely don't know C#.

00:47:52.820 --> 00:47:56.320
And I've gone from, and C# definitely has some syntax.

00:47:56.640 --> 00:47:58.580
Like there's at signs and square brackets all over

00:47:58.580 --> 00:47:59.000
the place.

00:47:59.080 --> 00:48:00.660
And I'm like, I

00:48:00.660 --> 00:48:16.200
don't really know what this means, but it is nevertheless pretty straightforward to look up an example because like most of the examples for like demos of doing the thing you need to do with an API are going to be a flat sequence of method calls.

00:48:16.640 --> 00:48:18.500
It's just like do this, then do this, then do this, then do this.

00:48:18.830 --> 00:48:24.300
And you're like, okay, well, I know it's dash greater, greater question mark for some reason.

00:48:24.390 --> 00:48:26.880
I don't know why they're doing that, but that's the symbol in this language.

00:48:27.010 --> 00:48:34.700
And so like, but I know that when I see that, that means I have to use two pairs of parentheses in Python or whatever.

00:48:35.579 --> 00:48:40.360
That is a made up example from a fake language, but there are lots of like very straightforward translation rules.

00:48:40.600 --> 00:49:29.320
And like, just as an example there's pi objective c uses the objective c runtime which like Swift also Swift has its own stuff that isn't necessarily always exposed to this but like the core of the frameworks is all exposed via the objective c runtime to Swift in the same way that it's exposed to Python if you look at a method name you can there's a rule you like replace all the colons with underscores and then that's kind of the method name that you would use Rubicon which is a different Objective-C bridge that works on iOS has a similar set of rules. They're not exactly the same, but once you know what they are, you can just apply them over and over again. And if you can find an example of the C version, you can find the Python or you can work out the Python version for yourself pretty straightforwardly.

00:49:29.740 --> 00:49:41.640
Yeah. And I agree with you about the farther a field you go, the harder it gets, which is why I imagined And you try to get it to do it in the one language, and you try to get it to help you convert that quick.

00:49:41.690 --> 00:49:42.100
You know what I mean?

00:49:42.280 --> 00:49:44.300
It's going to have a better chance than some

00:49:44.300 --> 00:49:44.860
super niche

00:49:44.860 --> 00:49:45.580
thing, I imagine.

00:49:46.200 --> 00:49:57.620
Although, ironically, in the PyJC docs, you get the same kind of click on this tab for Python, this tab for Objective-C, as you get in Apple's official docs, where it's click on this tab for Objective

00:49:57.620 --> 00:49:57.960
-C, this

00:49:57.960 --> 00:49:58.660
tab for Swift.

00:49:58.900 --> 00:49:59.700
It's a similar type

00:49:59.700 --> 00:50:00.180
of...

00:50:00.220 --> 00:50:00.920
That's pretty handy, yeah.

00:50:03.000 --> 00:50:04.800
But when you have a,

00:50:05.120 --> 00:50:12.140
one of the things, so like at first it seems like, oh, this must be such a pain in Python.

00:50:12.360 --> 00:50:15.520
You're constantly having to jump back and forth and do all this mental translation.

00:50:15.720 --> 00:50:24.000
And while that is true, there's also the fact that if you're like writing a Swift app, like I've done relatively little of this type of development.

00:50:24.060 --> 00:50:27.020
But like I have run through the kind of like Swift tutorials and whatnot.

00:50:27.080 --> 00:50:28.320
So I understand I use Xcode.

00:50:28.820 --> 00:50:32.660
I've done a bunch of stuff with code signing and like reverse engineering how to do that.

00:50:33.100 --> 00:50:36.720
Sometimes it involves watching what Xcode would do and then trying to figure out what happened.

00:50:37.380 --> 00:50:40.060
So I have done the kind of happy path version.

00:50:40.700 --> 00:50:45.740
And the thing is, you don't get a REPL with Objective-C or with Swift or C#, right?

00:50:45.900 --> 00:51:06.620
And the fact that you can, even though you do have to do this tedious translation sometimes for these types of APIs, it's almost the same thing as like if you're just doing regular web development and you're reading a JSON API and the SDK is in JavaScript, you don't typically think of that as being a laborious, difficult translation step.

00:51:06.790 --> 00:51:14.700
You just look at the JavaScript and if the JavaScript is not telling you what you need, you go and you just look at the HTTP underlying it.

00:51:15.050 --> 00:51:18.900
And you know how to parse JSON and you know how to deal with HTTP resources.

00:51:19.010 --> 00:51:20.880
And it's the same kind of mental translation.

00:51:21.720 --> 00:51:25.180
This is a pretty straightforward thing that programmers do all the time without even thinking about it.

00:51:26.440 --> 00:51:39.420
And one of the things that makes Python a lovely language to do that, if you're working in a web context, is you Python-M async.io or you run Python as a REPL and you just start fiddling around with some example data.

00:51:39.500 --> 00:51:41.220
You load it up and you start calling the APIs.

00:51:41.620 --> 00:52:15.880
And for a lot of these APIs, the difficulty of the extra translation step, the absence of a specific tutorial, is easily eclipsed and then some from the fact that you can do all of this development kind of iteratively and interactively in not just not necessarily even just a um a repl but also like a jupyter notebook like a lot of these things open up a jupyter notebook start calling the apis that you need to call you know record the output have a look at what the os is telling you there there are exceptions

00:52:15.880 --> 00:52:16.420
to that

00:52:17.170 --> 00:53:07.180
in particular in like if you're doing like full-on desktop app development sometimes you get into these weird places where like you really need like a, an app bundle on the Mac or you need like some registry keys set on windows that pointed a particular executable. And so you do, you do sometimes get into these places where like, okay, you kind of need to participate as if you're living in the native developer ecosystem. But even then you can write yourself a little, you know, like write a Jupyter kernel that like you can connect to that just has that little stub executable on the side or has the app bundle that you can connect to. Because there's lots of ways to programmatically create a REPL in Python. Or even just, if you don't even want to get that fancy, just a text field that'll eval some Python to interactively discover whatever it is that you need to learn about the API.

00:53:07.430 --> 00:53:18.340
So you've got a lot of powerful tools. But again, once you've determined, okay, I'm just going to use Python for this. I have this problem that I want to solve locally on my computer.

00:53:19.500 --> 00:53:27.320
You have to kind of bridge these gaps to do some things that would be a little bit easier if you were using the native tools.

00:53:28.800 --> 00:53:36.120
But what you get for paying that cost is you get to bring all of your Python tools along with you and do all of this cool stuff that you already know how to do.

00:53:37.480 --> 00:53:38.300
Yeah, that's awesome.

00:53:40.260 --> 00:53:45.720
And on top of talking about the different ways to check it out, we've got really nice IDEs, right?

00:53:46.860 --> 00:53:48.640
Especially PyCharm and VS Code.

00:53:49.620 --> 00:53:50.800
the 100 variants of that thing.

00:53:52.820 --> 00:53:56.640
You have really nice debuggers to go through and understand stuff on top of it.

00:53:56.710 --> 00:53:56.820
And

00:53:56.820 --> 00:53:57.300
sometimes

00:53:57.300 --> 00:54:00.140
you do in other places, but sometimes you don't.

00:54:00.280 --> 00:54:03.000
And maybe they cost money, you don't have that thing, and so on.

00:54:03.580 --> 00:54:14.880
And that process of having to learn a whole new debugger and a whole new way of getting your code to run, not to mention learning a new programming language, that's a big cost.

00:54:15.490 --> 00:54:17.920
And it may not feel like it, because again, it's straightforward.

00:54:18.120 --> 00:54:21.640
It doesn't involve a lot of hard thinking to do all those tutorials.

00:54:22.760 --> 00:54:26.220
But it does mean that you don't get to bring your superpowers with you.

00:54:26.660 --> 00:54:26.960
Yeah.

00:54:27.760 --> 00:54:30.220
Well, there's also a Node.js type of argument to make.

00:54:31.680 --> 00:54:42.040
And that is, if you can write your desktop app in Python, and it happens to be talking to services you own, you can keep it in the same language.

00:54:42.560 --> 00:54:45.900
Maybe not the same frameworks, because you're talking NS object sort of deals.

00:54:46.240 --> 00:54:51.240
But still, it's closer to one unified programming language end to end.

00:54:52.060 --> 00:54:52.140
Yeah.

00:54:52.420 --> 00:54:54.820
And you can do it as much as makes sense, right?

00:54:54.900 --> 00:55:05.120
Like you can have your – maybe it makes sense to use Positron, right, which is the Beware browser-based tool.

00:55:05.160 --> 00:55:13.540
It's like Electron, but it uses Python instead of like the Chromium electron shell.

00:55:14.240 --> 00:55:24.420
And so what that means is that you can say, well, I'm going to write like a Django app and I'm going to do everything kind of a plain vanilla back-end way, but I want this one thing from a local desktop app.

00:55:25.240 --> 00:55:34.160
And so I'll write it mostly that way, and then I'll use Positron, and now I've got all the power of Python in addition to all the power of the web stuff that I was using.

00:55:35.520 --> 00:55:43.360
And you can move that seamlessly from the back-end to the local compute as you need it.

00:55:43.560 --> 00:55:48.820
Like it's really that agility, that portability of like, you're not going to tell me where I can run my code, right?

00:55:48.920 --> 00:55:54.440
Like that's the spirit that I would like to inculcate in anybody

00:55:54.440 --> 00:55:54.920
who's doing

00:55:54.920 --> 00:55:55.340
this talk.

00:55:55.460 --> 00:56:01.100
It's like, if you can run Python anywhere, nobody can tell you no.

00:56:04.040 --> 00:56:07.500
I'm trying to think of the conference hat or t-shirt slogan for that one.

00:56:08.280 --> 00:56:10.160
We're going to put down our Obey the GPO.

00:56:10.660 --> 00:56:11.380
We're going to put that one on.

00:56:11.480 --> 00:56:17.620
Let's take just a couple of moments and talk about maybe three quick libraries that we could use.

00:56:17.760 --> 00:56:20.600
And then I want to talk about LLMs actually just a little bit.

00:56:20.600 --> 00:56:26.660
But let's talk about Notify.py and then your two projects, QuickMac Hotkey and QuickMac App.

00:56:28.840 --> 00:56:29.020
Yeah.

00:56:31.860 --> 00:56:35.300
So I'm not as familiar with Notify.py.

00:56:35.460 --> 00:56:36.920
I've played with it a tiny bit.

00:56:38.920 --> 00:56:50.240
I actually recently added, because macOS has some weird restrictions on the way notifications work, I actually just added a bunch of stuff to QuickMac App relatively recently to do

00:56:50.240 --> 00:56:50.740
notifications

00:56:50.740 --> 00:56:51.040
there.

00:56:52.200 --> 00:56:57.180
But yeah, NotifyPi, if what you need is a background notification, NotifyPi is a much better place to start.

00:56:57.960 --> 00:56:58.180
I see.

00:56:59.070 --> 00:57:00.640
Yeah, so it looks like a pretty simple API.

00:57:00.740 --> 00:57:02.160
I haven't really done much with it either.

00:57:02.310 --> 00:57:05.760
The one that I've used, which I had on the screen for a minute, but we never got to it, is Rumps.

00:57:07.040 --> 00:57:11.280
Ridiculously uncomplicated macOS Python status bar apps that just live.

00:57:11.440 --> 00:57:15.120
I've got one running right up in the status bar of my app right now, and I love it.

00:57:16.480 --> 00:57:16.720
Cool.

00:57:16.720 --> 00:57:17.240
What does it do?

00:57:18.340 --> 00:57:28.240
So this one, I find myself very often having to take things like, you know, over on Talk Python or for course recordings or whatever.

00:57:28.410 --> 00:57:40.860
I have to take this title, Developer Trends in 2025 or whatever it is, and then turn it into kind of the slug that you might have up here, like lowercase, no symbol.

00:57:41.120 --> 00:57:43.600
Something could be a file or a URL or something like that.

00:57:44.000 --> 00:57:45.540
So it does a bunch of operations around that.

00:57:45.620 --> 00:57:55.400
Like whatever's in the clipboard, it'll trim it, lowercase it, uppercase it, turn it to this slug type thing, or even make it pastable into Excel if it comes out of HTML, stuff like that.

00:57:56.660 --> 00:58:02.520
See, and that was exactly the kind of thing, like you just rattled off like nine different things that you need to do.

00:58:02.540 --> 00:58:04.380
And it's such a simple thing.

00:58:04.500 --> 00:58:06.940
I'm sure you did it probably a thousand times.

00:58:07.960 --> 00:58:08.480
Oh, yeah.

00:58:09.640 --> 00:58:10.140
So brutal

00:58:10.140 --> 00:58:12.340
to type it out, and I'm like, oh, are you serious again?

00:58:13.900 --> 00:58:21.820
And yeah, but you put that little status bar app in there, and it just takes a whole element of pain out of your day.

00:58:22.720 --> 00:58:25.920
It uses rumps, and it uses PiperClip, and that's it.

00:58:26.440 --> 00:58:29.100
But it's not that advanced what it does.

00:58:29.340 --> 00:58:33.500
I mean, some of them are literally one line, return, string low, or string up, or string trim.

00:58:33.700 --> 00:58:35.540
it's so good.

00:58:36.040 --> 00:58:39.340
And you get to express it in a language you already

00:58:39.340 --> 00:58:39.760
know, right?

00:58:39.850 --> 00:58:42.860
Like string lower, string upper, string trim, title case, whatever.

00:58:43.240 --> 00:58:48.080
There's so many things you can do in Python that are just one method that you just already know how to do, so it seems trivial.

00:58:48.740 --> 00:58:56.960
But the number of keystrokes and motions on your keyboard and mouse movements to replicate that incredibly simple thing is a lot, especially if you're doing it all the time.

00:58:58.020 --> 00:59:01.660
So yeah, I guess Rumps would be a competitor to QuickMac app,

00:59:02.000 --> 00:59:02.140
probably.

00:59:03.080 --> 00:59:04.340
It's really, really limited.

00:59:04.430 --> 00:59:06.080
I think yours is more capable.

00:59:07.099 --> 00:59:10.340
It's good if that's what you want, but you cannot ask much of it.

00:59:11.340 --> 00:59:25.520
Yeah, one of the things that I'm doing, this is kind of veering off into a different talk and other stuff that I'm doing, but I have also been trying really hard to do more of this stuff for real in a way to ship to other users.

00:59:26.580 --> 00:59:37.480
This talk is more, like what I'm going to be talking about at PyCon, is more about doing exactly the kind of thing just said, solving problems for yourself, using your local compute resources for you.

00:59:38.010 --> 00:59:44.360
But I'm simultaneously trying to productionize this stuff to provide examples of like, and you can take it further.

00:59:44.730 --> 00:59:48.280
And because there are examples out there, like Dropbox was a Python app for 15

00:59:48.280 --> 00:59:48.620
years.

00:59:49.090 --> 00:59:49.940
And so clearly,

00:59:50.080 --> 00:59:54.540
if you want to, you can make pretty successful Python desktop apps.

00:59:55.280 --> 01:00:07.020
But there are so few examples, and they're so far between, and they're so specialized that our community, like nobody's talking about the Python-ness of Dropbox.

01:00:07.180 --> 01:00:07.420
That's not

01:00:07.420 --> 01:00:08.280
like a talking point.

01:00:08.280 --> 01:00:11.660
You may have the only desktop talk at PyCon, for example.

01:00:12.520 --> 01:00:13.120
Not true.

01:00:13.960 --> 01:00:19.420
But the one other that I'm sure is there is Russell, who's in the slot right against me.

01:00:20.660 --> 01:00:23.940
So that one time, I guess, is the desktop time.

01:00:24.120 --> 01:00:26.660
But there is so much code out there.

01:00:27.640 --> 01:00:29.880
I maintain hardly any of these libraries.

01:00:30.790 --> 01:00:34.760
I have my two things, which are wrappers around other things that already exist.

01:00:35.080 --> 01:00:36.500
All my stuff is higher level.

01:00:38.100 --> 01:00:41.600
And I think you've probably used the phrase dark matter developers in the

01:00:41.600 --> 01:00:41.820
past.

01:00:42.040 --> 01:00:42.540
Yes, yes.

01:00:42.670 --> 01:00:45.460
I haven't thought about that for a while, but yes, I love that phrase so much.

01:00:45.720 --> 01:00:55.480
But one kind of dark matter developer are just the folks doing kind of work-a-day stuff in banks and insurance companies and car

01:00:55.540 --> 01:00:57.420
And up-logging or tweeting or etc.

01:00:57.500 --> 01:00:58.480
or whatever about it, right?

01:00:58.640 --> 01:00:58.920
They're just

01:00:58.920 --> 01:01:03.600
doing a job with some code and we never hear from them and they're like most Python programmers.

01:01:05.040 --> 01:01:05.720
Case in point, right?

01:01:05.860 --> 01:01:06.680
Like most of them use Windows.

01:01:07.720 --> 01:01:23.220
But there's another version of that, which is like, there's a huge part of the open source community that's maintaining all kinds of packages to do all kinds of esoteric things with Python that we also don't, that aren't like plugged into the core development ecosystem that we don't necessarily see at conferences.

01:01:24.820 --> 01:01:30.560
And those folks who are doing more specialized open source infrastructure deserve more celebration.

01:01:31.440 --> 01:01:38.120
And like desktop apps or, you know, desktop integrations are one part of that, but there's lots of other, you know, like signal processing things

01:01:38.320 --> 01:01:38.700
and like other

01:01:38.700 --> 01:01:41.620
esoteric areas that not everybody needs.

01:01:41.800 --> 01:01:44.220
And so they just have less of an audience.

01:01:45.660 --> 01:01:52.440
But again, the fact that Python is the second best language for everything means that anytime you need to do two things at once, it's the best language.

01:01:53.180 --> 01:01:57.340
And it's all those second tier folks that are out there doing the specialized libraries.

01:01:58.580 --> 01:02:15.100
The generalized libraries, the Django's and Flasks and SQL alchemies of the world, that stuff is super important and the language would absolutely not be what it is without that, but we're all kind of aware of that stuff and it's

01:02:15.100 --> 01:02:15.540
that second

01:02:15.760 --> 01:02:19.840
tier that really makes Python turbocharged powerful.

01:02:21.350 --> 01:02:25.760
Right. You come to it and your little weird space of the world, they already have libraries for that.

01:02:26.120 --> 01:02:28.160
Right. And we've all got something like

01:02:28.160 --> 01:02:49.260
that, right? Like no matter what industry you work in, you're using some set of libraries for doing that stuff. Even if you're working in like mass market social media or whatever, you're still probably using some cluster management tools or something that like not everybody is using that is, that are, you know, that type of more specialized open source that's like still super important.

01:02:49.640 --> 01:02:53.420
Yeah. Let me riff on one more thing here.

01:02:53.540 --> 01:02:57.280
quick, see what you think about this. So I'll tell you about an app that I wrote last week.

01:02:57.350 --> 01:03:00.620
I think it was last week. It must have been the beginning of last week. It's been a little while.

01:03:01.439 --> 01:03:17.100
Is I want a program that when I'm working in a project in a Git repository, I can ask an LLM what, do a better job than Michael's four words to summarize the commit I'm about to make to Git.

01:03:18.079 --> 01:03:24.180
I want to say updated dependencies or more error checking, right?

01:03:24.280 --> 01:03:26.340
But not what I did, why I did it, right?

01:03:26.480 --> 01:03:29.800
I should do better, but I find in real life I don't.

01:03:30.280 --> 01:03:31.820
And so I said, well, okay, what can I do?

01:03:32.000 --> 01:03:46.580
Well, I'm going to use this thing called LM Studio, which is cool because it lets you download stuff from Hugging Face, like most of the models that you know about, the llamas and the mistrals and so on, right?

01:03:46.800 --> 01:03:55.860
But it also, the second tab that looks like a terminal, It runs an OpenAI compatible server on your local machine.

01:03:56.220 --> 01:03:58.840
I have my Mac Mini that has the most RAM.

01:03:58.940 --> 01:03:59.880
I just leave it running there.

01:04:00.380 --> 01:04:04.900
And then anywhere in my local network, I can just use it to run code against.

01:04:05.020 --> 01:04:21.860
And so I wrote maybe 100 lines of code that will go through a git diff, take all those pieces, put a good prompt in front of it, and send it over there and then get it back in a structured way that has like a title but then a description below it if you go into detail, like GitHub supports and so on.

01:04:23.100 --> 01:04:24.580
And it costs nothing.

01:04:25.580 --> 01:04:37.540
It doesn't really hurt the environment very much because it's just running for like four seconds on my local machine and my iStats menu says it uses seven watts for four seconds, which is like an LED light bulb for four seconds.

01:04:38.320 --> 01:04:41.900
It's not nothing, but it's not melting the earth level of GPU usage.

01:04:42.020 --> 01:04:42.580
You know what I mean?

01:04:42.900 --> 01:04:43.020
Right.

01:04:43.520 --> 01:04:45.660
And it's also local, so it's not sharing your data.

01:04:46.300 --> 01:04:52.800
So I think that this, for people who are like, I want to build something local, but it kind of needs an LLM, I think this is a pretty neat thing.

01:04:53.020 --> 01:04:56.800
Whatever models you have installed, if you ask for them, it'll load them up and just answer your question with it.

01:04:57.160 --> 01:04:57.800
It's pretty neat.

01:04:58.380 --> 01:05:16.420
Yeah, and I do feel like there's still a pretty big, one of the things that has stopped me from doing more stuff like that is really the, and this is really frustrating, attempting to search around on Hugging Face, Because I feel like there are no what Simon termed vegan models that I can find.

01:05:16.950 --> 01:05:19.440
The ones that are like all the data was collected consensually.

01:05:21.580 --> 01:05:22.100
But

01:05:22.100 --> 01:05:26.820
if we could square that circle, and I think some people are working on that.

01:05:28.840 --> 01:05:31.520
Again, like you said, seven watts for a few seconds.

01:05:34.600 --> 01:05:48.640
That level of power utilization, not only is it less, But also, you can know if you're, for example, I've got solar, and so I know when it's basically free in terms of environmental impact.

01:05:51.240 --> 01:05:53.340
And I can run it at those times.

01:05:54.140 --> 01:06:02.700
There's also the fact that if we could square the training data problem, you get the privacy concerns because it's not actually.

01:06:02.860 --> 01:06:05.880
A lot of the privacy concerns with LLMs are just, it's a server.

01:06:06.340 --> 01:06:06.640
Nothing to do

01:06:06.640 --> 01:06:07.340
with LLMs, right?

01:06:07.520 --> 01:06:10.520
Yeah, you're giving this data to another place.

01:06:11.020 --> 01:06:13.560
You are giving it to Sam Altman, personally.

01:06:13.880 --> 01:06:14.980
You can do what he wants with it.

01:06:15.340 --> 01:06:15.960
I think the

01:06:15.960 --> 01:06:22.420
other part that's bad about LLMs is they could turn around and be turned into training data, which then gets turned as a result.

01:06:22.680 --> 01:06:27.520
Not just they have it, but it might become the way that the thing speaks to others, which is worse.

01:06:28.380 --> 01:06:34.020
And so, yeah, by doing local compute, you still have to worry about the training data.

01:06:34.160 --> 01:06:38.480
You still have to worry a little bit about the environmental usage, but you can keep your own eye on it.

01:06:38.580 --> 01:06:41.560
You can measure it and decide whether it's useful.

01:06:41.800 --> 01:06:46.900
You're already doing, you're probably doing transparency effects on your desktop.

01:06:48.180 --> 01:06:48.940
Yeah, just give

01:06:48.940 --> 01:06:49.560
people a sense.

01:06:49.700 --> 01:06:55.860
Right now I'm doing a live stream, so I'm doing screen sharing and you and I are talking and it's running at 17 watts

01:06:55.860 --> 01:06:57.040
on my Mac Mini.

01:07:00.020 --> 01:07:01.880
And that's 30% CPU, right?

01:07:02.040 --> 01:07:02.160
So

01:07:02.160 --> 01:07:04.480
it's

01:07:04.480 --> 01:07:05.400
pretty mellow.

01:07:05.740 --> 01:07:08.460
I think this solves two of the three problems, Glyph.

01:07:08.460 --> 01:07:16.620
I think it solves or avoids pretty much the environmental effect, at least from running the questions, not training the models in the first place.

01:07:17.020 --> 01:07:17.900
And it solves the privacy.

01:07:18.440 --> 01:07:23.700
It certainly doesn't address what I generally consider to be more or less copyright theft.

01:07:24.540 --> 01:07:25.560
That these things constitute.

01:07:25.920 --> 01:07:26.920
But they already exist.

01:07:27.080 --> 01:07:29.680
And you're saying, like, I dislike that.

01:07:29.760 --> 01:07:31.020
It's not going to make it go away.

01:07:31.020 --> 01:07:33.060
It just means you're somewhat disadvantaged.

01:07:33.860 --> 01:07:34.860
Which is a tough place

01:07:34.860 --> 01:07:35.700
to be, I think, honestly.

01:07:36.120 --> 01:07:36.920
Yeah, it is.

01:07:37.060 --> 01:07:51.340
Although one thing about the, another thing that I find LLMs often teach us this interesting lesson, and this local models can actually make it clearer because they're worse, like because they're quantized down to be less

01:07:51.340 --> 01:07:51.760
powerful.

01:07:52.220 --> 01:07:52.580
You can

01:07:52.580 --> 01:07:56.400
see this a little bit more, which is like that generating the commit message thing.

01:07:56.680 --> 01:08:00.540
Like if that is being useful to you, then no shade or anything.

01:08:00.620 --> 01:08:06.780
I think that that's definitely better than just typing, you know, TK, TK, TK or whatever, which is probably

01:08:06.780 --> 01:08:07.180
what I do.

01:08:08.100 --> 01:08:08.500
Ah,

01:08:08.760 --> 01:08:09.760
I'm going to say the letter A.

01:08:10.460 --> 01:08:10.580
Right.

01:08:11.380 --> 01:08:18.299
But it does also kind of highlight like, well, the thing you really want to do in a commit message is you really want to say why, not what.

01:08:18.859 --> 01:08:19.520
Because the what,

01:08:19.620 --> 01:08:20.420
the thing

01:08:20.420 --> 01:08:25.220
that the LLM can extract from the summary is always the less interesting thing.

01:08:25.819 --> 01:08:31.680
And so quite often when you're asking an LLM to do something, that's a good hint that like the interesting part is somewhere else.

01:08:32.839 --> 01:08:33.440
And so

01:08:33.440 --> 01:08:40.359
it's useful to take a step back on the commit message thing to say, why am I doing this?

01:08:40.600 --> 01:08:41.440
Yes, absolutely.

01:08:42.100 --> 01:08:50.080
So if I don't use the result when I ask the question, it might at least remind me what I did with great detail so I can write a better message.

01:08:50.660 --> 01:08:51.060
Sometimes

01:08:51.060 --> 01:08:58.120
it goes, because we were no longer checking for the user possibly not being logged in, which would have caused a crash.

01:08:58.240 --> 01:09:00.040
I'm like, dang, it figured that out.

01:09:00.240 --> 01:09:00.640
Brilliant.

01:09:00.900 --> 01:09:01.480
That's the commit message.

01:09:01.660 --> 01:09:02.040
You know what I mean?

01:09:02.359 --> 01:09:02.420
Yep.

01:09:02.640 --> 01:09:04.560
But it's still an interesting tool in the toolbox.

01:09:05.620 --> 01:09:08.640
And being local, I think it counts as part of this story.

01:09:08.650 --> 01:09:11.440
So I just thought I'd throw that out there because I've had a lot of success with that lately.

01:09:11.839 --> 01:09:20.400
Yeah, and if we do figure out the training data thing, which again, there are people working on that, we will still need the local compute part of the story to have a fully...

01:09:20.840 --> 01:09:38.859
If we solve the training data thing and somebody does a good, fully consensual, everybody's on board with the training data model, and then it's just running remotely and it's still a cloud service and you're still sending all your training data to it, So having the power to run these things locally and leverage the power of local compute.

01:09:39.170 --> 01:09:44.240
And as you said, hook it in with an automation that you wrote.

01:09:44.710 --> 01:09:54.740
Again, in Python, having that agency and that power at your fingertips is super useful and a super important part of the puzzle.

01:09:54.940 --> 01:10:14.020
Not just for like, and a lot of the complaints about LLMs are really just complaints about automation and some of the problems with the computing industry and the internet more broadly and bringing your compute local and taking full control over and responsibility for it can really address a lot of those problems.

01:10:14.240 --> 01:10:16.820
And I think it's something that we need to be thinking about all the time, right?

01:10:16.980 --> 01:10:22.580
In the same way that when you're talking about, you know, a lot of the stuff we started off talking about with cloud compute, right?

01:10:22.720 --> 01:10:27.060
Like, do you need to have, you know, all these esoteric services?

01:10:27.380 --> 01:10:32.260
Do you need to have so many resources deployed if you're not even getting particularly good latency

01:10:32.260 --> 01:10:32.720
compute?

01:10:33.060 --> 01:10:37.860
Could it just be in Funktools, LRU cache, instead of a whole other service, right?

01:10:38.180 --> 01:10:38.420
Exactly.

01:10:39.030 --> 01:10:40.700
And could you just do it locally?

01:10:40.900 --> 01:10:42.660
Could you do it radically more simply?

01:10:42.820 --> 01:10:45.080
What if it was just a Python module?

01:10:45.360 --> 01:10:46.180
Could you just make it a

01:10:46.180 --> 01:10:46.920
Python module?

01:10:47.740 --> 01:10:53.000
And there's so many places, not everywhere, but there are so many places where the answer to that is, yes, it could.

01:10:53.480 --> 01:10:56.820
And in those cases where you can answer yes, you should totally do it.

01:10:57.840 --> 01:11:12.600
Awesome. Well, very inspiring talk. I will give a two-part call to action at the end of this, maybe three. One, if you catch this on the YouTube live stream, go see Glyph's talk at PyCon.

01:11:13.180 --> 01:11:24.820
That'd be great. If you listen to this in the recorded version, edited and shipped to the podcast players, PyCon will be in the rearview mirror. So look for the recording of his talk coming out of PyCon.

01:11:25.560 --> 01:11:27.440
Or worst case scenario, check out the PyBay one.

01:11:30.560 --> 01:11:31.160
What do you want to add?

01:11:31.280 --> 01:11:32.320
People want to program their own computers.

01:11:32.680 --> 01:11:34.020
You've been very inspirational.

01:11:35.720 --> 01:11:46.520
Well, of course, they should follow me, glyph at mastodon.social, where I'm constantly talking about programming my own computer and all of the misery that comes along with it.

01:11:48.160 --> 01:11:49.440
And I also do some

01:11:49.440 --> 01:11:49.780
streaming.

01:11:49.820 --> 01:11:50.340
You mean character

01:11:50.340 --> 01:11:50.580
building?

01:11:51.480 --> 01:11:52.700
Yes, yes, character building.

01:11:52.760 --> 01:11:55.220
We're learning. We're all learning and growing. That's what we're doing.

01:11:57.020 --> 01:12:07.180
And yeah, I've got a couple libraries. You mentioned QuickMac Hotkey, QuickMac App. I've got a tool called Encrust, which is for code signing Mac applications.

01:12:08.740 --> 01:12:15.660
That is not to be underestimated. That is a huge roadblock to going from programming my computer to programming other people's computer.

01:12:16.100 --> 01:12:19.760
Yeah, and I am using it in real life.

01:12:20.560 --> 01:12:30.960
Speaking of, we were talking earlier about people who, like other folks in niche areas who are doing things with Python that you may not hear about as much.

01:12:31.250 --> 01:12:40.600
One of my favorite things about Incrust is that Just Van Rossum uses it to ship some kind of app that has something to do, I'm pretty sure, with fonts.

01:12:41.220 --> 01:12:42.360
That's about as much as I know

01:12:42.360 --> 01:12:42.800
about it.

01:12:43.640 --> 01:12:49.720
But he is actually shipping an app to users, and I'm using Incrust to ship a couple different apps.

01:12:50.140 --> 01:13:00.920
They're still kind of alpha quality, but they're the sort of alpha quality that does like, Encrust also nowadays not only does the Mac App Store, or no, sorry, not Mac App Store, still have yet to do the App Store stuff.

01:13:01.320 --> 01:13:08.000
It does Mac notarization and it does code signing, but it also does Sparkle, which if you're not

01:13:08.000 --> 01:13:08.160
familiar.

01:13:08.500 --> 01:13:08.560
Yeah.

01:13:09.320 --> 01:13:10.220
This app has an update.

01:13:10.380 --> 01:13:11.300
Would you like to install it?

01:13:11.440 --> 01:13:11.940
Click enter to

01:13:11.940 --> 01:13:12.900
restart and install.

01:13:13.260 --> 01:13:15.740
And it will generate and publish those.

01:13:16.220 --> 01:13:25.600
Like it integrates the tooling to set that up for you I did all the testing to make sure that you can ship an actual Python app and it installs properly and all that stuff.

01:13:28.460 --> 01:13:29.260
I've got a couple of users.

01:13:31.100 --> 01:13:39.540
I've been very Mac-focused lately just because that's the platform that I use, but there's stuff in the works for Linux for some of those apps as well.

01:13:42.320 --> 01:13:48.320
I will hopefully have more to say and make it easier for folks to publish on their platform of choice.

01:13:49.800 --> 01:13:57.760
But, and as much as I would love to point people at the one great project, once again, it kind of depends what you want to do.

01:13:58.740 --> 01:14:11.340
You've got to find that weird niche in the Python world, weird niche in the world that you care about the most, and then find the folks making it happen in Python because there's probably at least a few of them.

01:14:11.820 --> 01:14:12.100
Yeah.

01:14:12.970 --> 01:14:15.700
Get together, upgrade some of these tools, get them totally working.

01:14:16.440 --> 01:14:16.560
Yep.

01:14:17.060 --> 01:14:18.500
Then encrust your apps and ship them out.

01:14:19.360 --> 01:14:19.900
Please do.

01:14:20.280 --> 01:14:22.400
And let me know if there are bugs, because there almost certainly are.

01:14:23.680 --> 01:14:24.840
Glyph, thanks for being here as always.

01:14:25.140 --> 01:14:25.820
Awesome to have you back.

01:14:26.760 --> 01:14:26.820
Thanks.

01:14:27.460 --> 01:14:28.580
Thank you so much for having me.

01:14:29.300 --> 01:14:29.440
Bye.

01:14:30.200 --> 01:14:30.380
Bye.

01:14:59.520 --> 01:14:59.540
Продолжение следует...

