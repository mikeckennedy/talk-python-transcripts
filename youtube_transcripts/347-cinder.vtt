WEBVTT

00:00:00.000 --> 00:00:03.400
- Dino, welcome to Talk Python To Me.


00:00:03.400 --> 00:00:05.820
- Hi Michael, thanks for having me.


00:00:05.820 --> 00:00:07.740
- I'm really excited to talk to you.


00:00:07.740 --> 00:00:09.740
You've been involved in a lot of projects


00:00:09.740 --> 00:00:12.340
that I've wanted to talk to you about over the years


00:00:12.340 --> 00:00:16.300
and haven't yet, so we're gonna touch on a couple of those.


00:00:16.300 --> 00:00:20.100
But we've got some really big news around Cinder


00:00:20.100 --> 00:00:22.720
and some performance stuff that you all over at Instagram


00:00:22.720 --> 00:00:24.500
are doing to try to make Python faster.


00:00:24.500 --> 00:00:26.300
You did a really cool PyCon keynote,


00:00:26.300 --> 00:00:28.620
or not keynote, a talk on that.


00:00:28.620 --> 00:00:33.100
So we're gonna dive deep into this alternate reality


00:00:33.100 --> 00:00:35.900
runtime of CPython called Cinder that you all have created.


00:00:35.900 --> 00:00:37.800
That's gonna be a lot of fun.


00:00:37.800 --> 00:00:38.960
- Yeah.


00:00:38.960 --> 00:00:41.020
And it's only slightly alternate reality.


00:00:41.020 --> 00:00:42.540
- It's not that much of an alternate reality,


00:00:42.540 --> 00:00:43.380
just a little bit.


00:00:43.380 --> 00:00:44.220
- Yeah.


00:00:44.220 --> 00:00:48.820
- Before we do though, let's just hear your story.


00:00:48.820 --> 00:00:50.860
How'd you get into programming in Python?


00:00:50.860 --> 00:00:54.980
- So programming, I started programming


00:00:54.980 --> 00:00:57.660
when I was a teenager.


00:00:57.660 --> 00:01:02.200
I got into computers initially, really through BBSs.


00:01:02.200 --> 00:01:03.040
- Oh, yes.


00:01:03.040 --> 00:01:05.000
- Which maybe probably a lot of people--


00:01:05.000 --> 00:01:05.840
- Was this pre-internet?


00:01:05.840 --> 00:01:07.800
This was pre, this is like dial up,


00:01:07.800 --> 00:01:10.420
oh, you would dial into the BBS?


00:01:10.420 --> 00:01:11.260
Oh my God.


00:01:11.260 --> 00:01:13.420
- Yep, yeah, like, you know, I had a modem,


00:01:13.420 --> 00:01:16.100
someone else had a modem sitting in their home,


00:01:16.100 --> 00:01:18.020
waiting for people to call in.


00:01:18.020 --> 00:01:21.700
You'd log in, send emails, post messages,


00:01:21.700 --> 00:01:24.500
take your turns on games, log out,


00:01:24.500 --> 00:01:28.020
and someone else could log in and respond to your emails.


00:01:28.020 --> 00:01:28.860
- It was so amazing.


00:01:28.860 --> 00:01:31.700
It's been email mint, wait for another BBS


00:01:31.700 --> 00:01:33.260
to dial in to connect to that one


00:01:33.260 --> 00:01:36.140
to like sync its local batch of emails.


00:01:36.140 --> 00:01:38.460
It was like a peer to peer email, it was so weird.


00:01:38.460 --> 00:01:39.500
- Yeah, yeah.


00:01:39.500 --> 00:01:42.460
I mean, or like there's a lot of local emails, right?


00:01:42.460 --> 00:01:45.700
Where it's just on, you're waiting for the other person


00:01:45.700 --> 00:01:46.980
to have a chance to log in.


00:01:46.980 --> 00:01:49.460
But yeah, there's also that network,


00:01:49.460 --> 00:01:51.740
like a couple of different big networks.


00:01:52.620 --> 00:01:54.620
It was such a different time.


00:01:54.620 --> 00:01:56.320
- It was such a different time.


00:01:56.320 --> 00:01:58.980
I was not super into this as much.


00:01:58.980 --> 00:02:00.420
My brother was really into it.


00:02:00.420 --> 00:02:04.180
We had two phone lines so that we could do more of this.


00:02:04.180 --> 00:02:06.400
Did you ever play Trade Wars or any of the games


00:02:06.400 --> 00:02:07.240
that were out there?


00:02:07.240 --> 00:02:08.700
- Yes, Trade Wars was awesome.


00:02:08.700 --> 00:02:09.580
- Real good.


00:02:09.580 --> 00:02:11.380
I think I would still enjoy Trade Wars.


00:02:11.380 --> 00:02:12.220
It was so good.


00:02:12.220 --> 00:02:13.060
- Yeah.


00:02:13.060 --> 00:02:16.680
I was still playing Trade Wars in college.


00:02:16.680 --> 00:02:21.680
We formed teams and were trying to take over


00:02:21.940 --> 00:02:25.420
some trade wars that was available over the internet,


00:02:25.420 --> 00:02:28.820
actually, that you could like, telnet into and play.


00:02:28.820 --> 00:02:29.660
(laughs)


00:02:29.660 --> 00:02:31.860
- A lot of this BBS stuff had sort of found a home


00:02:31.860 --> 00:02:34.340
over telnet for a while, hadn't it?


00:02:34.340 --> 00:02:35.180
- Yeah.


00:02:35.180 --> 00:02:36.000
- Yeah.


00:02:36.000 --> 00:02:41.000
- And I think, I think the main BBS software that I used,


00:02:41.000 --> 00:02:44.700
that was used in St. Louis where I grew up,


00:02:44.700 --> 00:02:47.660
which was World War IV, with,


00:02:47.660 --> 00:02:51.380
I think it's still around and like available


00:02:51.380 --> 00:02:53.940
for you to like, if you really want to host it


00:02:53.940 --> 00:02:58.940
on some internet server, but who's going to do that?


00:02:58.940 --> 00:03:01.540
- Incredible.


00:03:01.540 --> 00:03:04.220
Okay, so how's the BBS story fed into


00:03:04.220 --> 00:03:06.060
the programming side of things?


00:03:06.060 --> 00:03:11.060
- So the BBS software that kind of was really popular,


00:03:11.060 --> 00:03:14.500
you could get a license to it for 50 bucks


00:03:14.500 --> 00:03:17.980
and you got the source code for it along with it.


00:03:17.980 --> 00:03:21.380
and there's a big active modding community.


00:03:21.380 --> 00:03:24.340
And so, you know, I started off like taking people's mods


00:03:24.340 --> 00:03:27.820
and applying them and then trying to make my own mods


00:03:27.820 --> 00:03:31.720
and like just ended up teaching myself C.


00:03:31.720 --> 00:03:37.100
And initially very poorly taught myself C,


00:03:37.100 --> 00:03:40.840
but then, you know, finally got good at it at some point.


00:03:40.840 --> 00:03:43.480
- How fun.


00:03:43.480 --> 00:03:44.320
- Yeah.


00:03:45.740 --> 00:03:50.300
Did other people use your mods or were you running your own BBS or anything like that?


00:03:50.300 --> 00:03:57.340
I did a really bad job at running my own BBS.


00:03:57.340 --> 00:04:01.940
I petitioned my parents for a second phone line,


00:04:01.940 --> 00:04:04.580
but I also wanted to use it for phone calls.


00:04:04.580 --> 00:04:07.180
So to call my BBS, you had to dial in,


00:04:07.180 --> 00:04:11.020
and then I had this device where you could punch four extra codes


00:04:11.020 --> 00:04:12.700
and it would connect you to the modem.


00:04:14.020 --> 00:04:17.900
So that was kind of annoying and didn't make it the world's most popular BBS.


00:04:17.900 --> 00:04:20.660
And it was rather short lived.


00:04:20.660 --> 00:04:22.860
- Hurt some of the automation, yeah.


00:04:22.860 --> 00:04:24.340
- Yeah.


00:04:24.340 --> 00:04:26.460
But I published my mods.


00:04:26.460 --> 00:04:28.620
My friends ran BBSes.


00:04:28.620 --> 00:04:30.580
They'd pick up some of the mods.


00:04:30.580 --> 00:04:33.980
I don't know that I was the most popular modder out there.


00:04:33.980 --> 00:04:35.780
I should go and see if I can find them.


00:04:35.780 --> 00:04:37.100
That might be terrifying, though.


00:04:37.100 --> 00:04:38.260
- Yeah, that might be terrifying.


00:04:38.260 --> 00:04:39.860
But it could also be amazing.


00:04:39.860 --> 00:04:43.140
All right, let's wrap up the BBS side of things.


00:04:43.140 --> 00:04:44.940
putting some bookends on the timeframe here.


00:04:44.940 --> 00:04:47.100
What was the beginning baud rate


00:04:47.100 --> 00:04:50.260
and end baud rate of your BBS time?


00:04:50.260 --> 00:04:54.740
- 2400 to 57.6K.


00:04:54.740 --> 00:04:57.740
- Yeah, so you took it all the way to the end there.


00:04:57.740 --> 00:05:00.060
2400 probably meant it didn't require


00:05:00.060 --> 00:05:01.900
putting the phone on.


00:05:01.900 --> 00:05:02.740
- No, no coupler.


00:05:02.740 --> 00:05:04.420
- Like the war games.


00:05:04.420 --> 00:05:07.660
- Yeah, never that bad.


00:05:07.660 --> 00:05:09.940
- Fantastic.


00:05:09.940 --> 00:05:11.340
All right, how about Python?


00:05:12.860 --> 00:05:16.420
So I got into Python in a very weird way


00:05:16.420 --> 00:05:18.680
'cause I started working on a Python implementation


00:05:18.680 --> 00:05:23.680
having really never touched or used Python before.


00:05:23.680 --> 00:05:25.000
Obviously I'd heard about it


00:05:25.000 --> 00:05:26.720
and I was kind of like, "Significant white space,


00:05:26.720 --> 00:05:27.920
"that sounds weird."


00:05:27.920 --> 00:05:35.480
But ended up really loving working on it on IronPython,


00:05:35.480 --> 00:05:40.060
really loving the language and the way it was designed.


00:05:40.060 --> 00:05:45.060
It's a very, it gave me a very weird outlook on Python,


00:05:45.060 --> 00:05:50.540
I think, just because I knew all sorts of weird corner cases


00:05:50.540 --> 00:05:54.640
about Python and the language and all the details there,


00:05:54.640 --> 00:05:57.960
but then didn't really know much about libraries


00:05:57.960 --> 00:05:59.040
and things like that.


00:05:59.040 --> 00:06:02.860
And to some extent that continues today,


00:06:02.860 --> 00:06:06.120
but I get to write a lot more Python code today too.


00:06:07.040 --> 00:06:10.320
but like always having been on the implementation side


00:06:10.320 --> 00:06:12.340
is a little strange.


00:06:12.340 --> 00:06:15.260
- It is strange.


00:06:15.260 --> 00:06:17.640
And it is, I guess it would be a weird way


00:06:17.640 --> 00:06:18.800
to get to know the language.


00:06:18.800 --> 00:06:22.240
So I feel like one of the real big powers of Python


00:06:22.240 --> 00:06:23.980
is that you can be really effective with it


00:06:23.980 --> 00:06:26.400
with a super partial understanding.


00:06:26.400 --> 00:06:28.800
Like you could have literally no idea


00:06:28.800 --> 00:06:29.840
how to create a function


00:06:29.840 --> 00:06:32.280
and you could still do useful things with Python.


00:06:32.280 --> 00:06:36.840
Whereas if you're gonna jump in


00:06:36.840 --> 00:06:41.480
and create Iron Python, which we'll talk about in a second,


00:06:41.480 --> 00:06:43.600
you have to start out, what are these meta classes


00:06:43.600 --> 00:06:47.280
and how do I best implement dynamic objects


00:06:47.280 --> 00:06:48.120
and all this stuff?


00:06:48.120 --> 00:06:49.780
That's like the opposite of starting


00:06:49.780 --> 00:06:51.960
with a partial understanding.


00:06:51.960 --> 00:06:54.380
- Well, and how do imports work?


00:06:54.380 --> 00:06:57.600
That was a big thing.


00:06:57.600 --> 00:06:59.120
- I remember when I learned about them,


00:06:59.120 --> 00:07:01.160
I'm like, wait, this is like running code.


00:07:01.160 --> 00:07:06.160
It's not like an include file or a statically linked file


00:07:06.480 --> 00:07:10.360
or adding a reference in .NET or something like that.


00:07:10.360 --> 00:07:13.120
It's, nope, it just runs whatever's in the script


00:07:13.120 --> 00:07:15.640
and it happens to be most of the time it defines behaviors


00:07:15.640 --> 00:07:17.240
but it doesn't have to.


00:07:17.240 --> 00:07:20.120
- Yeah, and like how do you pick


00:07:20.120 --> 00:07:21.760
what's going to get imported?


00:07:21.760 --> 00:07:26.760
And yeah, the semantics there are so complicated.


00:07:26.760 --> 00:07:33.600
- Yep, there are some oddities of Python


00:07:33.600 --> 00:07:36.900
but in general, it seems to be working well for people.


00:07:36.900 --> 00:07:38.740
But I can see as I'm implementing it,


00:07:38.740 --> 00:07:41.920
it could, you could definitely be pulling some hair out.


00:07:41.920 --> 00:07:44.620
- And I mean, so many things implementing it


00:07:44.620 --> 00:07:47.800
are just, they're super sane.


00:07:47.800 --> 00:07:50.440
Like they make a lot of sense.


00:07:50.440 --> 00:07:53.940
There's just some weird corner cases that you run into


00:07:53.940 --> 00:07:57.020
that are, it's like, what's going on here?


00:07:57.020 --> 00:07:59.740
And when I worked on higher end Python,


00:07:59.740 --> 00:08:02.140
we couldn't look at the source code of CPython.


00:08:02.140 --> 00:08:04.900
which made things really interesting.


00:08:04.900 --> 00:08:08.740
- Okay, because this predates .NET being open source


00:08:08.740 --> 00:08:09.940
and all that kind of stuff, right?


00:08:09.940 --> 00:08:11.260
- Yep, yep.


00:08:11.260 --> 00:08:15.400
- You don't want to be poisoned by the ideas.


00:08:15.400 --> 00:08:18.780
- Yeah, and Iron Python was open source,


00:08:18.780 --> 00:08:23.340
but this was when Microsoft was still very much figuring out


00:08:23.340 --> 00:08:29.020
what, how they wanted to approach open source,


00:08:29.020 --> 00:08:31.460
and were still very cagey about it.


00:08:31.460 --> 00:08:33.460
It was very interesting.


00:08:33.460 --> 00:08:34.980
- Yeah, they've come a long way.


00:08:34.980 --> 00:08:36.740
Many companies have, I would say.


00:08:36.740 --> 00:08:38.100
It's still, there's some,


00:08:38.100 --> 00:08:39.140
- Yeah.


00:08:39.140 --> 00:08:40.580
- video synchronicities, I guess, there,


00:08:40.580 --> 00:08:44.580
but certainly it's a different time now than it was then.


00:08:44.580 --> 00:08:49.340
This was like, what, 2008, 2009 timeframe-ish?


00:08:49.340 --> 00:08:51.140
Or 2005, maybe?


00:08:51.140 --> 00:08:56.140
- It's, yeah, 2005, 2006,


00:08:56.140 --> 00:08:58.820
I think it was around Iron Python 1.0.


00:09:01.260 --> 00:09:02.860
2006 sounds about right.


00:09:02.860 --> 00:09:03.720
Yeah.


00:09:03.720 --> 00:09:06.500
Yeah. So that's a while ago.


00:09:06.500 --> 00:09:07.760
Yes.


00:09:07.760 --> 00:09:10.580
Doesn't sound that long ago to me, but honestly, it's a while ago.


00:09:10.580 --> 00:09:12.140
It's yeah.


00:09:12.140 --> 00:09:14.540
It's kind of, yeah.


00:09:14.540 --> 00:09:17.420
It's like remembering that the nineties is not 10 years ago.


00:09:17.420 --> 00:09:19.520
It's true.


00:09:19.520 --> 00:09:22.080
All right.


00:09:22.080 --> 00:09:24.140
how about day to day?


00:09:24.140 --> 00:09:24.700
What are you doing now?


00:09:24.700 --> 00:09:25.860
Your Instagram, right?


00:09:25.860 --> 00:09:27.200
Yeah.


00:09:27.260 --> 00:09:32.220
So basically I work on our fork of CPython,


00:09:32.220 --> 00:09:36.780
which we call Sender, and my job is to help make,


00:09:36.780 --> 00:09:38.800
and my entire team's job is to make


00:09:38.800 --> 00:09:40.420
Instagram run more efficiently.


00:09:40.420 --> 00:09:44.700
I mean obviously Instagram's a very large website


00:09:44.700 --> 00:09:46.220
that has a lot of traffic,


00:09:46.220 --> 00:09:51.040
and it's a very large Django app.


00:09:51.040 --> 00:09:56.040
So we just spend our time trying to improve CPython


00:09:57.240 --> 00:10:01.620
and very specifically trying to improve CPython


00:10:01.620 --> 00:10:03.520
for Instagram's workload.


00:10:03.520 --> 00:10:08.520
We're very driven by kind of that is our sole direction.


00:10:08.520 --> 00:10:13.400
And so it lets us make some interesting decisions


00:10:13.400 --> 00:10:16.420
and drive some interesting decisions,


00:10:16.420 --> 00:10:19.120
but it's just really spending the day


00:10:19.120 --> 00:10:23.280
looking at what we can do to improve performance


00:10:23.280 --> 00:10:25.160
and going off and implementing that.


00:10:25.160 --> 00:10:29.220
and making Instagram a little bit faster.


00:10:29.220 --> 00:10:34.220
- So when we talk about Python and Django running Instagram,


00:10:34.220 --> 00:10:37.700
I put up a little post here of something I did yesterday,


00:10:37.700 --> 00:10:39.680
just to have some Instagram stuff to show.


00:10:39.680 --> 00:10:41.340
Is that talking about the website?


00:10:41.340 --> 00:10:43.500
Is that the APIs behind the scenes?


00:10:43.500 --> 00:10:47.180
Like when you say Django runs Instagram,


00:10:47.180 --> 00:10:49.100
what are we talking about here?


00:10:49.100 --> 00:10:51.860
- So it's the website, it's the APIs.


00:10:51.860 --> 00:10:55.620
There's obviously some parts that aren't Django,


00:10:55.620 --> 00:11:00.940
but kind of everything that people's devices


00:11:00.940 --> 00:11:04.540
are interacting with is going through the Django front end.


00:11:04.540 --> 00:11:06.500
And there's also a bunch of like,


00:11:06.500 --> 00:11:08.740
if we have asynchronous processes


00:11:08.740 --> 00:11:11.380
that need to take off and run in the background,


00:11:11.380 --> 00:11:14.760
that's kind of all handled by a Django tier as well.


00:11:14.760 --> 00:11:20.180
So it's a good chunk of what's going on.


00:11:20.180 --> 00:11:21.100
- Yeah, nice.


00:11:21.100 --> 00:11:25.180
This is probably one of the, if not the largest,


00:11:25.180 --> 00:11:26.580
Django deployment there is, right?


00:11:26.580 --> 00:11:29.540
This is a lot of servers we're talking about, right?


00:11:29.540 --> 00:11:30.740
- I would assume so.


00:11:30.740 --> 00:11:31.860
I don't know.


00:11:31.860 --> 00:11:33.100
I don't know.


00:11:33.100 --> 00:11:35.340
There might be something else pretty big out there.


00:11:35.340 --> 00:11:39.660
- Yeah, I feel like the talk at the 2017 PyCon,


00:11:39.660 --> 00:11:41.540
remember that one we used to go to places


00:11:41.540 --> 00:11:42.380
where there are other people


00:11:42.380 --> 00:11:44.380
and we'd just go and be in the same room and stuff?


00:11:44.380 --> 00:11:45.660
Read the same mail? - That was so nice.


00:11:45.660 --> 00:11:46.500
- I know, it sure was.


00:11:46.500 --> 00:11:48.740
And there was a cool Instagram talk about,


00:11:48.740 --> 00:11:53.740
I believe that one was about disabling the GC


00:11:53.740 --> 00:11:56.140
or something like that.


00:11:56.140 --> 00:11:57.780
I feel like they said in that talk,


00:11:57.780 --> 00:11:58.620
at least at that time,


00:11:58.620 --> 00:11:59.580
that was one of the largest,


00:11:59.580 --> 00:12:01.260
not the largest Django deployment.


00:12:01.260 --> 00:12:05.220
- Yeah, and we no longer disable the GC.


00:12:05.220 --> 00:12:07.580
We fixed the memory leak, so that's good.


00:12:07.580 --> 00:12:08.420
- Okay.


00:12:08.420 --> 00:12:09.900
(laughing)


00:12:09.900 --> 00:12:11.220
We're gonna talk a lot about memory


00:12:11.220 --> 00:12:12.980
and honestly, this whole conversation


00:12:12.980 --> 00:12:17.120
is gonna be a bit of a test,


00:12:17.120 --> 00:12:21.160
an assessment of my CPython internals,


00:12:21.160 --> 00:12:23.100
but I think that's okay


00:12:23.100 --> 00:12:25.960
because a lot of people out there don't know


00:12:25.960 --> 00:12:29.060
super in-depth details about CPython


00:12:29.060 --> 00:12:32.660
and I can play the person who asked the questions for them.


00:12:32.660 --> 00:12:33.900
- Awesome.


00:12:33.900 --> 00:12:34.740
- Awesome.


00:12:34.740 --> 00:12:36.160
- I can try to answer questions.


00:12:36.160 --> 00:12:37.560
(laughing)


00:12:37.560 --> 00:12:38.720
- Well, we'll keep it focused on the part


00:12:38.720 --> 00:12:40.160
that you've been doing.


00:12:40.160 --> 00:12:43.800
But during your talk, you mentioned a couple of things.


00:12:43.800 --> 00:12:46.900
First, you said, okay, well,


00:12:46.900 --> 00:12:51.140
when we're running over on Django,


00:12:51.140 --> 00:12:54.060
we're running on, you say UWSGI,


00:12:54.060 --> 00:12:56.180
I feel like it's a micro,


00:12:56.180 --> 00:12:57.460
like it used to be a like a--


00:12:57.460 --> 00:12:58.620
- Micro whiskey.


00:12:58.620 --> 00:12:59.980
- Yeah, micro whiskey, so I don't know,


00:12:59.980 --> 00:13:02.380
UWSGI, micro whiskey, whatever it is.


00:13:02.380 --> 00:13:03.220
- Yeah.


00:13:03.220 --> 00:13:04.220
- I feel like all these projects


00:13:04.220 --> 00:13:06.580
that have interesting names should have a,


00:13:06.580 --> 00:13:08.940
press here to hear how it should be pronounced.


00:13:08.940 --> 00:13:10.420
Should it be WSGI or whiskey?


00:13:10.420 --> 00:13:16.500
Anyway, this micro whiskey you guys are running on


00:13:16.500 --> 00:13:20.040
and understanding how it creates child processes


00:13:20.040 --> 00:13:21.240
and forks out the work.


00:13:21.240 --> 00:13:23.300
It's really important for understanding


00:13:23.300 --> 00:13:26.800
some of the improvements that you've made


00:13:26.800 --> 00:13:28.880
and some of the areas you've focused on.


00:13:28.880 --> 00:13:30.440
So maybe we could start a little bit


00:13:30.440 --> 00:13:33.960
by talking about just the infrastructure


00:13:33.960 --> 00:13:38.500
and how actually the execution of Python code


00:13:38.500 --> 00:13:39.920
happens over at Instagram.


00:13:39.920 --> 00:13:40.920
- Yeah.


00:13:40.920 --> 00:13:45.840
So in addition to uWSGI, it's running on Linux.


00:13:45.840 --> 00:13:49.340
and which is probably not surprising to anyone.


00:13:49.340 --> 00:13:51.460
And one of the common things--


00:13:51.460 --> 00:13:53.560
- Literally zero people are surprised now.


00:13:53.560 --> 00:13:54.400
- Yeah.


00:13:54.400 --> 00:13:55.960
- Hot-toast Windows server, come on.


00:13:55.960 --> 00:13:58.260
(laughing)


00:13:58.260 --> 00:13:59.420
- Or Solaris.


00:13:59.420 --> 00:14:03.280
- Or a Raspberry Pi cluster, come on.


00:14:03.280 --> 00:14:05.260
- Yeah, that'd be awesome.


00:14:05.260 --> 00:14:09.200
So like one of the common things


00:14:09.200 --> 00:14:13.500
that people take advantage on Linux is fork and exec,


00:14:13.500 --> 00:14:16.620
where you start up a master process


00:14:16.620 --> 00:14:20.100
and then you fork off some trial processes


00:14:20.100 --> 00:14:24.200
and they can share all of the memory of that master process.


00:14:24.200 --> 00:14:27.060
So it's a relatively cheap operation


00:14:27.060 --> 00:14:30.500
to go off and spawn those trial processes


00:14:30.500 --> 00:14:34.960
and you get a lot of sharing between those two processes,


00:14:34.960 --> 00:14:38.180
which reduces kind of the memory that you need to use


00:14:38.180 --> 00:14:39.260
and all of that good stuff.


00:14:39.260 --> 00:14:49.720
And so the way uWSGI is working is that we are spawning our master process, going off


00:14:49.720 --> 00:14:56.240
importing kind of all of the website, like we try to make sure that everything gets loaded


00:14:56.240 --> 00:15:02.120
initially and then spawn off a whole bunch of worker processes which are going to actually


00:15:02.120 --> 00:15:05.480
be serving the traffic.


00:15:05.480 --> 00:15:08.960
And if something happens to one of those worker processes,


00:15:08.960 --> 00:15:11.520
then the master will come in


00:15:11.520 --> 00:15:14.040
and spawn a new worker to replace it.


00:15:14.040 --> 00:15:17.680
And that kind of goes on and on and on.


00:15:17.680 --> 00:15:21.920
- It's also not just about durability.


00:15:21.920 --> 00:15:24.600
It's also about scalability, right?


00:15:24.600 --> 00:15:28.440
If one of the worker processes is busy working on a request,


00:15:28.440 --> 00:15:30.680
well, there might be nine others


00:15:30.680 --> 00:15:34.560
and the supervisor process can look and say,


00:15:34.560 --> 00:15:36.640
okay, well I got some requests gotta be processed.


00:15:36.640 --> 00:15:39.180
Here, this one's not busy and sort of scale it out.


00:15:39.180 --> 00:15:43.940
And that also helps a lot with Python's GIL and stuff.


00:15:43.940 --> 00:15:46.360
You can just throw more of these worker processes at it


00:15:46.360 --> 00:15:47.580
to get more scalability.


00:15:47.580 --> 00:15:51.200
And at some point that kind of hits the database limits


00:15:51.200 --> 00:15:54.040
anyway, so it doesn't really matter that much, right?


00:15:54.040 --> 00:15:56.560
- Yeah, and I think like you can auto tune.


00:15:56.560 --> 00:15:59.800
I don't know exactly all the details of our settings.


00:15:59.800 --> 00:16:02.080
- But it can also be like settings in there, yeah.


00:16:02.080 --> 00:16:07.080
Yeah, like it can tune for memory for stalled workers.


00:16:07.080 --> 00:16:13.260
It's pretty smart.


00:16:13.260 --> 00:16:15.480
- Yeah.


00:16:15.480 --> 00:16:17.520
- But yeah.


00:16:17.520 --> 00:16:19.280
- There's actually a really interesting,


00:16:19.280 --> 00:16:20.880
I don't know, have you, maybe you've seen this.


00:16:20.880 --> 00:16:23.160
There's a really interesting post called


00:16:23.160 --> 00:16:27.120
configuring USG for production deployment


00:16:27.120 --> 00:16:29.080
over on Bloomberg Tech,


00:16:29.080 --> 00:16:31.880
talking about all these knobs that they turn


00:16:31.880 --> 00:16:34.120
to make it work better and do these different things.


00:16:34.120 --> 00:16:38.360
And it's super interesting if these tuning knobs


00:16:38.360 --> 00:16:39.960
are unfamiliar to Python people.


00:16:39.960 --> 00:16:44.280
Yeah, but the important takeaway here is


00:16:44.280 --> 00:16:48.040
when we're talking about running your code on a single server


00:16:48.040 --> 00:16:50.800
we're talking about five, 10, 20 copies


00:16:50.800 --> 00:16:52.960
of the same process running the same code.


00:16:52.960 --> 00:16:53.800
- 40, 60.


00:16:53.800 --> 00:16:55.040
(laughing)


00:16:55.040 --> 00:16:56.560
- Exactly.


00:16:56.560 --> 00:16:58.200
You guys pay for bigger cloud instances.


00:16:58.200 --> 00:17:00.160
I mean, you have your own data centers, right?


00:17:00.160 --> 00:17:02.280
So you probably get a lot of VMs.


00:17:02.280 --> 00:17:08.520
- Yeah, and so that impacts a lot of the decisions


00:17:08.520 --> 00:17:09.440
that we make.


00:17:09.440 --> 00:17:14.380
And we can talk about those more later.


00:17:14.380 --> 00:17:20.040
I think another interesting thing about our UWSD


00:17:20.040 --> 00:17:22.040
and our deployments in general


00:17:22.040 --> 00:17:25.680
is that we're also redeploying every 10 minutes.


00:17:25.680 --> 00:17:28.920
- I saw that, that blows my mind.


00:17:28.920 --> 00:17:32.600
So tell me about this rapid redeployment.


00:17:32.600 --> 00:17:34.980
- It blows my mind too.


00:17:34.980 --> 00:17:38.820
And when I started at Facebook, I guess now Meta,


00:17:38.820 --> 00:17:40.360
but it was Facebook back then,


00:17:40.360 --> 00:17:45.360
you go through a process called bootcamp


00:17:45.360 --> 00:17:47.520
where you spend your first several weeks


00:17:47.520 --> 00:17:48.940
just learning about Facebook.


00:17:48.940 --> 00:17:50.800
And one of the first things you learn is like,


00:17:50.800 --> 00:17:53.720
Facebook.com redeploys every three to four hours.


00:17:53.720 --> 00:17:55.760
I'm like, that's insanely fast.


00:17:55.760 --> 00:17:58.080
and then land an Instagram.


00:17:58.080 --> 00:18:00.200
We redeploy every 10 minutes.


00:18:00.200 --> 00:18:01.460
It's like, what?


00:18:01.460 --> 00:18:03.540
(laughs)


00:18:03.540 --> 00:18:06.040
So-- - Yeah, that's incredible.


00:18:06.040 --> 00:18:07.520
- It like-- - Can you talk about


00:18:07.520 --> 00:18:08.800
why that is?


00:18:08.800 --> 00:18:10.920
Is there just that many improvements


00:18:10.920 --> 00:18:12.640
in code changes going on


00:18:12.640 --> 00:18:17.640
or is there some other balancing reason that this happens?


00:18:17.640 --> 00:18:21.920
- I don't know what all the original reasoning is.


00:18:21.920 --> 00:18:25.280
It has a very nice.


00:18:25.280 --> 00:18:27.520
So one of the nice things about deploying a lot


00:18:27.520 --> 00:18:29.660
is when something goes wrong,


00:18:29.660 --> 00:18:33.440
it's not hard to figure out what caused things to go wrong.


00:18:33.440 --> 00:18:35.860
- Right, a bunch of small changes


00:18:35.860 --> 00:18:37.060
and each one gets deployed.


00:18:37.060 --> 00:18:38.920
So you're not going back to the last six months


00:18:38.920 --> 00:18:39.760
or whatever, right?


00:18:39.760 --> 00:18:41.640
- Yeah, exactly.


00:18:41.640 --> 00:18:45.360
Or I mean, even, I mean, each of those deployments


00:18:45.360 --> 00:18:48.320
has a good number of changes in it.


00:18:48.320 --> 00:18:53.320
And, you know, if even if it was like four hours,


00:18:54.160 --> 00:18:58.240
there would be a huge number of changes that you'd have to track things down through.


00:18:58.240 --> 00:19:04.080
And it's also like, it's really satisfying from a developer standpoint,


00:19:04.080 --> 00:19:09.280
in that, you know, you land your change and it's rolling out in half an hour.


00:19:09.280 --> 00:19:14.960
And so I don't think anyone, again, I don't know all the original reasoning,


00:19:14.960 --> 00:19:17.280
but I don't think anyone would really want to change it


00:19:17.280 --> 00:19:21.840
just because it actually has some significant benefits.


00:19:22.560 --> 00:19:28.080
It makes things interesting and challenging in some ways too, but otherwise I think it's really nice.


00:19:28.080 --> 00:19:39.120
Yeah, it just never ceases to frustrate me or blow my mind how there's these companies just have extended downtime.


00:19:39.120 --> 00:19:45.240
Like, I'm not talking, we pushed out a new version and in order to switch things in and out of the load balancer,


00:19:45.240 --> 00:19:50.400
there's five seconds of downtime or database migration and it creates a new index


00:19:50.400 --> 00:19:53.000
and that's going to take one or two minutes.


00:19:53.000 --> 00:19:57.800
I'm talking, we're going to be down for six hours on Sunday,


00:19:57.800 --> 00:19:59.600
so please schedule your work around.


00:19:59.600 --> 00:20:01.800
I'm just like, what is wrong with these companies?


00:20:01.800 --> 00:20:08.640
Like, how is it possible that it takes so long to deploy these things?


00:20:08.640 --> 00:20:11.400
And if they had put in some mechanism


00:20:11.400 --> 00:20:17.560
to ship small amounts of code with automation,


00:20:17.560 --> 00:20:20.740
then they would just not be in this situation, right?


00:20:20.740 --> 00:20:23.320
Like they would get pushed somewhere


00:20:23.320 --> 00:20:25.680
and then something would happen


00:20:25.680 --> 00:20:28.580
and then they would have a new version of the site, right?


00:20:28.580 --> 00:20:32.960
- It always baffles me when I end up at a website


00:20:32.960 --> 00:20:36.640
like, and it's like, we're currently down for service.


00:20:36.640 --> 00:20:37.520
It's like, what?


00:20:37.520 --> 00:20:41.380
Like, this is a website, you're not supposed to do that.


00:20:41.380 --> 00:20:44.800
- The most insane thing, I'll cut off this thing,


00:20:44.800 --> 00:20:46.320
but it drives me crazy.


00:20:46.320 --> 00:20:50.000
The most insane thing is I've seen websites that were closed on Sunday.


00:20:50.000 --> 00:20:51.840
I'm like, "What do you mean it's closed on Sunday?"


00:20:51.840 --> 00:20:52.840
Yeah.


00:20:52.840 --> 00:20:56.160
Just go and turn it off when you go home?


00:20:56.160 --> 00:20:58.360
It's open Monday to Friday sort of thing.


00:20:58.360 --> 00:21:03.360
It was like a government website and I don't know why it had to be closed, but apparently


00:21:03.360 --> 00:21:05.360
it had to be closed.


00:21:05.360 --> 00:21:10.320
We have engineers standing by Monday through Friday to process your requests by hand.


00:21:10.320 --> 00:21:11.320
Exactly.


00:21:11.320 --> 00:21:12.320
We got to push the button.


00:21:12.320 --> 00:21:13.320
No one's there to push the button.


00:21:13.320 --> 00:21:18.320
- Okay, so I guess one more setting the stage stories here


00:21:18.320 --> 00:21:24.200
or things to know is that you run these servers


00:21:24.200 --> 00:21:28.480
quite close to their limits in terms of like CPU usage


00:21:28.480 --> 00:21:29.760
and stuff like that.


00:21:29.760 --> 00:21:34.080
And then also you said one of the areas that you focus on


00:21:34.080 --> 00:21:37.400
is request per second as your important metric.


00:21:37.400 --> 00:21:39.760
Do you wanna talk about those for a moment?


00:21:39.760 --> 00:21:43.720
- Sure, so I don't know what the overall numbers


00:21:43.720 --> 00:21:47.200
under normal load are.


00:21:47.200 --> 00:21:52.200
I don't think the CPU load is necessarily super high,


00:21:52.200 --> 00:21:56.360
but what we wanna know at the end of the day


00:21:56.360 --> 00:22:01.120
is like how many requests can we serve under peak load?


00:22:01.120 --> 00:22:05.440
And so what we can actually do is take traffic


00:22:05.440 --> 00:22:08.720
and route it to a set of servers


00:22:08.720 --> 00:22:12.860
and drive that traffic up to where the server


00:22:12.860 --> 00:22:16.280
is under peak load, and we see how many requests


00:22:16.280 --> 00:22:20.560
per second a server is able to serve at that point,


00:22:20.560 --> 00:22:22.720
which gives us a pretty good idea


00:22:22.720 --> 00:22:27.720
of kind of what the overall level of efficiency is.


00:22:27.720 --> 00:22:32.520
So when we make a change, we can basically run an A/B test


00:22:32.520 --> 00:22:34.680
where we take one set of servers


00:22:34.680 --> 00:22:38.940
that don't have the change, drive them up to peak load,


00:22:38.940 --> 00:22:41.640
and compare it against another set of servers


00:22:41.640 --> 00:22:44.440
that have the change,


00:22:44.440 --> 00:22:47.580
and drive those set of servers up to peak load,


00:22:47.580 --> 00:22:50.060
and then compare between the two


00:22:50.060 --> 00:22:54.100
and see how many requests per second we end up getting


00:22:54.100 --> 00:22:56.340
and what the change is.


00:22:56.340 --> 00:23:01.340
And we can do that to a decent amount of accuracy.


00:23:01.340 --> 00:23:03.820
I think kind of like when we kick off a manual test,


00:23:03.820 --> 00:23:08.260
we try to strive for within 0.25%.


00:23:08.260 --> 00:23:10.100
When we're doing releases of Sender,


00:23:10.100 --> 00:23:12.460
I think we try to push it a little bit further


00:23:12.460 --> 00:23:14.460
by doing more runs.


00:23:14.460 --> 00:23:18.120
So we get down to like 0.1% or something like that.


00:23:18.120 --> 00:23:22.300
So we have a pretty good idea of what the performance impact


00:23:22.300 --> 00:23:24.940
of what those changes are gonna end up looking like.


00:23:24.940 --> 00:23:26.380
- I think that makes a ton of sense.


00:23:26.380 --> 00:23:29.540
You could do profiling and obviously-


00:23:29.540 --> 00:23:30.500
- We do that too.


00:23:30.500 --> 00:23:31.820
- Yeah.


00:23:31.820 --> 00:23:34.300
But in the end of the day, there's


00:23:34.300 --> 00:23:36.060
a bunch of different things, right?


00:23:36.060 --> 00:23:40.140
If I profile against some process and say,


00:23:40.140 --> 00:23:43.420
well, this went this much faster in terms of CPU,


00:23:43.420 --> 00:23:45.020
maybe it took more memory.


00:23:45.020 --> 00:23:48.660
And at production scale, it turns into swap,


00:23:48.660 --> 00:23:51.380
which means it's dramatically--


00:23:51.380 --> 00:23:54.300
there's a bunch of pushes and pulls in there.


00:23:54.300 --> 00:23:56.400
And this pragmatic, just like, let's just


00:23:56.400 --> 00:23:59.140
see what it can take now, is interesting.


00:23:59.140 --> 00:24:08.140
You all are in this advantaged situation where you have more traffic than any given server can handle, I would imagine.


00:24:08.140 --> 00:24:10.140
Yes.


00:24:10.140 --> 00:24:12.140
So you can tune...


00:24:12.140 --> 00:24:14.140
We actually work on one server.


00:24:14.140 --> 00:24:16.140
Exactly.


00:24:16.140 --> 00:24:18.140
It hasn't been rebooted in seven years.


00:24:18.140 --> 00:24:20.140
Yeah.


00:24:20.140 --> 00:24:22.740
you have the ability to say,


00:24:22.740 --> 00:24:25.780
well, let's just tune some of our traffic


00:24:25.780 --> 00:24:27.740
over to this one particular server


00:24:27.740 --> 00:24:29.720
to sort of see this limit.


00:24:29.720 --> 00:24:34.100
Whereas a lot of companies and products don't, right?


00:24:34.100 --> 00:24:39.100
Like I use this thing called locust.io,


00:24:39.100 --> 00:24:42.060
which is just a fantastic Python framework


00:24:42.060 --> 00:24:44.340
for doing load testing,


00:24:44.340 --> 00:24:46.060
to actually know the upper bound


00:24:46.060 --> 00:24:48.180
of what my servers can handle,


00:24:48.180 --> 00:24:49.600
because we get a lot of traffic,


00:24:49.600 --> 00:24:53.240
but we don't get 30,000 requests a second lots of traffic.


00:24:53.240 --> 00:24:54.280
(laughing)


00:24:54.280 --> 00:24:57.800
And so I think this is really neat that you can actually


00:24:57.800 --> 00:25:00.520
test in production sort of beyond integration tests,


00:25:00.520 --> 00:25:04.780
not test that it works right, but send real traffic


00:25:04.780 --> 00:25:06.280
and actually see how it responds.


00:25:06.280 --> 00:25:08.240
'Cause really that's the most important thing, right?


00:25:08.240 --> 00:25:11.120
Does it do more or does it do less than before?


00:25:11.120 --> 00:25:13.320
- And you brought up profiling


00:25:13.320 --> 00:25:16.320
and we still have to use profiling sometimes to like,


00:25:17.720 --> 00:25:21.420
0.25%, 0.1%, that's still a lot of noise.


00:25:21.420 --> 00:25:25.400
And so if there's some little micro-optimization,


00:25:25.400 --> 00:25:27.240
we can still be like, okay, well,


00:25:27.240 --> 00:25:31.580
what's this function using after the change,


00:25:31.580 --> 00:25:35.540
kind of across some percentage of the entire fleet,


00:25:35.540 --> 00:25:38.280
which is kind of amazing, 'cause the profiling's


00:25:38.280 --> 00:25:42.320
just running on production traffic sampled.


00:25:42.320 --> 00:25:44.160
So for smaller things,


00:25:44.160 --> 00:25:46.840
that ends up becoming super important.


00:25:46.840 --> 00:25:49.120
- Right, and you're making a ton of changes


00:25:49.120 --> 00:25:50.280
as we're about to dive into,


00:25:50.280 --> 00:25:53.000
but there are additive or multiplicative


00:25:53.000 --> 00:25:54.040
or something like that, right?


00:25:54.040 --> 00:25:55.840
So if you make this thing 1% faster,


00:25:55.840 --> 00:25:58.000
that 5% faster, this 3% faster,


00:25:58.000 --> 00:25:59.600
all of a sudden you could end up


00:25:59.600 --> 00:26:02.640
at 20 to 30% faster in production, right?


00:26:02.640 --> 00:26:03.480
- Yep.


00:26:03.480 --> 00:26:05.200
- All right.


00:26:05.200 --> 00:26:07.360
- And how you do that math, we just add up the percents.


00:26:07.360 --> 00:26:08.200
(laughing)


00:26:08.200 --> 00:26:09.040
- Exactly.


00:26:09.040 --> 00:26:10.480
Oh, where's Cinder?


00:26:10.480 --> 00:26:11.320
Here we go.


00:26:11.320 --> 00:26:14.160
All right, so when I saw this come out,


00:26:14.160 --> 00:26:16.320
when did you all make this public?


00:26:16.320 --> 00:26:18.240
- Shortly before PyCon?


00:26:18.240 --> 00:26:22.400
- Yeah, that's right.


00:26:22.400 --> 00:26:23.240
- Yeah.


00:26:23.240 --> 00:26:26.200
- Put it like February, March, something like that.


00:26:26.200 --> 00:26:27.040
- Yeah, something like that.


00:26:27.040 --> 00:26:29.800
- That sounds exactly right with this eight months ago.


00:26:29.800 --> 00:26:35.360
So this is under the Facebook incubator.


00:26:35.360 --> 00:26:36.560
You guys got to rename this.


00:26:36.560 --> 00:26:37.400
Should be meta.


00:26:37.400 --> 00:26:39.440
- Yeah, I wonder who's job it is.


00:26:39.440 --> 00:26:41.480
- I mean, come on, come on.


00:26:41.480 --> 00:26:44.240
So it doesn't matter all that much.


00:26:44.240 --> 00:26:46.080
It's Instagram, I guess.


00:26:46.080 --> 00:26:50.080
but let me just read the first opening bit here.


00:26:50.080 --> 00:26:51.320
I think there's a lot to take away


00:26:51.320 --> 00:26:53.360
just from the first sentence.


00:26:53.360 --> 00:26:56.760
Cinder is Instagram's internal performance oriented


00:26:56.760 --> 00:26:59.600
production version of CPython 3.8.


00:26:59.600 --> 00:27:01.800
So performance oriented,


00:27:01.800 --> 00:27:02.920
we've been talking about performance.


00:27:02.920 --> 00:27:05.540
We're gonna get into a lot of the cool things you've done.


00:27:05.540 --> 00:27:07.040
Production version.


00:27:07.040 --> 00:27:09.160
So you guys are running on this on Cinder?


00:27:09.160 --> 00:27:12.280
Fantastic.


00:27:12.280 --> 00:27:16.120
and we redeploy like once a week.


00:27:16.120 --> 00:27:20.760
- You redeploy the Cinder or CPython runtime, right?


00:27:20.760 --> 00:27:21.600
- Yep.


00:27:21.600 --> 00:27:22.420
- Yeah, yeah, yeah.


00:27:22.420 --> 00:27:26.680
- So like the source that's up here is,


00:27:26.680 --> 00:27:30.240
yeah, if you go back and look at maybe a week ago


00:27:30.240 --> 00:27:31.840
is what we're probably running in production


00:27:31.840 --> 00:27:32.880
at any given time.


00:27:32.880 --> 00:27:34.760
- Right, okay, fantastic.


00:27:34.760 --> 00:27:37.120
And then CPython 3.8,


00:27:37.120 --> 00:27:39.840
because you've made a lot of changes to this


00:27:39.840 --> 00:27:42.720
that can't really move forward.


00:27:42.720 --> 00:27:45.400
So you picked the one, I'm guessing that was


00:27:45.400 --> 00:27:47.120
the most current when you first started,


00:27:47.120 --> 00:27:48.040
most current and stable,


00:27:48.040 --> 00:27:50.160
and just started working on that, right?


00:27:50.160 --> 00:27:52.240
- So we do upgrade.


00:27:52.240 --> 00:27:56.000
It was previously built on CPython 3.7.


00:27:56.000 --> 00:27:57.280
- Oh, cool, okay.


00:27:57.280 --> 00:28:02.280
- There's hundreds or, I don't know if we're yet up


00:28:02.280 --> 00:28:05.220
into thousands of changes yet,


00:28:06.360 --> 00:28:10.760
But there's a lot of diffs that we've applied.


00:28:10.760 --> 00:28:14.440
It's been, I mean, we've been working on it for,


00:28:14.440 --> 00:28:18.620
I've been working on it for three years now


00:28:18.620 --> 00:28:20.420
and it predates me.


00:28:20.420 --> 00:28:23.800
So we've upgraded to 3.7,


00:28:23.800 --> 00:28:27.000
we're gonna upgrade to 3.10 next,


00:28:27.000 --> 00:28:32.000
which we're actually planning on starting early next year.


00:28:32.000 --> 00:28:35.460
So it's just a big involved process.


00:28:35.460 --> 00:28:40.460
- And you've also contributed some stuff from Cinder


00:28:40.460 --> 00:28:43.700
to 3.10, that'll be interesting as well.


00:28:43.700 --> 00:28:45.660
That probably actually makes it harder to merge


00:28:45.660 --> 00:28:46.660
rather than easier.


00:28:46.660 --> 00:28:49.460
- We hope that makes it easier.


00:28:49.460 --> 00:28:51.220
That is one of the things that--


00:28:51.220 --> 00:28:53.240
- Yeah, I guess you could drop that whole section, right?


00:28:53.240 --> 00:28:54.080
You could just say, you know what,


00:28:54.080 --> 00:28:55.980
we don't even need this whole enhancement


00:28:55.980 --> 00:28:58.140
because that's part of Python now, right?


00:28:58.140 --> 00:28:58.980
Okay.


00:28:58.980 --> 00:29:00.460
- Yeah, that is the incentive for us,


00:29:00.460 --> 00:29:02.660
one of the incentives for us to contribute.


00:29:04.500 --> 00:29:05.660
- Yeah, yeah.


00:29:05.660 --> 00:29:09.140
Itamar out in the live stream and the audience says-


00:29:09.140 --> 00:29:10.240
- 2,000.


00:29:10.240 --> 00:29:11.240
- I did commit.


00:29:11.240 --> 00:29:12.080
Oh my gosh.


00:29:12.080 --> 00:29:13.080
Yeah, that's awesome.


00:29:13.080 --> 00:29:13.920
So-


00:29:13.920 --> 00:29:17.080
- Itamar is going to be help.


00:29:17.080 --> 00:29:21.580
He is now our kind of full-time dedicated resource


00:29:21.580 --> 00:29:23.440
to help us upstream things.


00:29:23.440 --> 00:29:26.320
- Oh, that's spoke to upstream.


00:29:26.320 --> 00:29:28.320
Itamar's job is to take the work you're doing here


00:29:28.320 --> 00:29:31.560
and then work on getting that into C5 Lump properly.


00:29:31.560 --> 00:29:32.600
- Yeah.


00:29:32.600 --> 00:29:33.440
Yeah.


00:29:33.440 --> 00:29:38.440
We could have been doing such a better job, I think.


00:29:38.440 --> 00:29:41.560
We've upstreamed some little things,


00:29:41.560 --> 00:29:43.920
some slightly more significant things,


00:29:43.920 --> 00:29:45.480
but it's something that we really need


00:29:45.480 --> 00:29:46.840
to be working on more.


00:29:46.840 --> 00:29:51.040
And so now we've got someone who's dedicated to it


00:29:51.040 --> 00:29:54.400
and obviously he's not just doing it in a vacuum,


00:29:54.400 --> 00:29:56.460
we're gonna help him.


00:29:56.460 --> 00:29:58.400
But having someone drive that


00:29:58.400 --> 00:30:01.640
and make sure it actually happens is super important.


00:30:01.640 --> 00:30:02.560
- Yeah, that's really cool.


00:30:02.560 --> 00:30:05.740
I suspect that he and Lucas Lenga will become friends.


00:30:05.740 --> 00:30:08.560
(all laughing)


00:30:08.560 --> 00:30:10.440
Lucas will be on the receiving end of that a lot.


00:30:10.440 --> 00:30:11.280
I bet.


00:30:11.280 --> 00:30:15.000
The developer in residence over at CPython.


00:30:15.000 --> 00:30:15.880
Cool.


00:30:15.880 --> 00:30:20.880
All right, so I guess let's talk about this.


00:30:20.880 --> 00:30:22.400
Is it supported?


00:30:22.400 --> 00:30:25.800
So right now the story is you guys have put this out here


00:30:25.800 --> 00:30:27.600
as sort of a proof of concept


00:30:27.600 --> 00:30:29.120
and by the way, we're using it,


00:30:29.120 --> 00:30:34.120
but not we expect other teams and companies to take this


00:30:34.120 --> 00:30:36.640
and then like just run on it as well, right?


00:30:36.640 --> 00:30:40.100
This is probably more to like work on the upstreaming side.


00:30:40.100 --> 00:30:41.680
Is that the story?


00:30:41.680 --> 00:30:44.700
- Yeah, and like let people know what we're doing.


00:30:44.700 --> 00:30:49.640
If someone wants to pick it up and try it, that's great.


00:30:49.640 --> 00:30:54.080
It's just mainly, you know, we're focused on our workload


00:30:54.080 --> 00:30:59.080
and making it faster and can't commit to helping people


00:30:59.080 --> 00:31:02.160
people out and making it work for them.


00:31:02.160 --> 00:31:03.400
- Right, but as you just said,


00:31:03.400 --> 00:31:07.760
you are working on bringing these changes up to CPython


00:31:07.760 --> 00:31:08.880
and you already have to some degree.


00:31:08.880 --> 00:31:12.000
So that's pretty good.


00:31:12.000 --> 00:31:14.800
I guess it also lets you all take a more


00:31:14.800 --> 00:31:18.200
specialized focused view and say, you know what?


00:31:18.200 --> 00:31:22.880
We wanna make micro-WSGI when it's forks off child processes


00:31:22.880 --> 00:31:26.760
we wanna make it that happen better and use less memory.


00:31:26.760 --> 00:31:28.120
And we're gonna focus on that.


00:31:28.120 --> 00:31:31.400
And if it makes sense to move that to main Python, good.


00:31:31.400 --> 00:31:34.600
If not, then we're just gonna keep those changes there.


00:31:34.600 --> 00:31:39.280
- Yeah, and that's happened, I think,


00:31:39.280 --> 00:31:42.680
with like we've done some work around immortalization


00:31:42.680 --> 00:31:46.880
of the GCE, which is kind of a big improvement


00:31:46.880 --> 00:31:49.640
over not collecting that we were talking about earlier.


00:31:49.640 --> 00:31:54.000
And that didn't make sense for upstream CPython.


00:31:54.000 --> 00:31:55.000
And so it was just, okay,


00:31:55.000 --> 00:31:57.080
that's something that we just have to maintain.


00:31:57.080 --> 00:31:59.000
I was so excited when I saw this come out.


00:31:59.000 --> 00:32:02.080
I'm like, wow, this is the biggest performance story


00:32:02.080 --> 00:32:04.480
I've seen around CPython for quite a while.


00:32:04.480 --> 00:32:06.280
And now there have been some other things as well.


00:32:06.280 --> 00:32:09.440
We'll touch on at the end on how they come together.


00:32:09.440 --> 00:32:13.280
But maybe walk us through what is Sender?


00:32:13.280 --> 00:32:15.400
What is this work?


00:32:15.400 --> 00:32:18.040
And we can dive into some of the areas maybe.


00:32:18.040 --> 00:32:19.000
- Sure.


00:32:19.000 --> 00:32:20.840
You have immortal instances highlighted.


00:32:20.840 --> 00:32:22.760
So we could start talking about that.


00:32:22.760 --> 00:32:23.800
- Let's start with JIT first.


00:32:23.800 --> 00:32:24.640
I think, yeah, yeah.


00:32:24.640 --> 00:32:25.480
- Okay, sure.


00:32:25.480 --> 00:32:28.080
- JIT. - Yeah, that's not fair.


00:32:28.080 --> 00:32:31.240
- So the JIT isn't what I work on day to day.


00:32:31.240 --> 00:32:33.760
We have several other team members


00:32:33.760 --> 00:32:35.480
who are working on that full time,


00:32:35.480 --> 00:32:40.940
but it's obviously a huge part of the performance story.


00:32:40.940 --> 00:32:45.940
So the JIT right now is, it's a method at a time JIT,


00:32:45.940 --> 00:32:48.680
so it compiles each individual method.


00:32:48.680 --> 00:32:52.920
It's, again, very tuned for our workload.


00:32:52.920 --> 00:32:56.680
kind of you can see here, like some of the descriptions


00:32:56.680 --> 00:32:57.840
of how to use this thing,


00:32:57.840 --> 00:33:01.080
and it's mentioning this JIT list file.


00:33:01.080 --> 00:33:02.720
So when we're using this in production,


00:33:02.720 --> 00:33:07.760
what happens is we compile all of the functions


00:33:07.760 --> 00:33:10.440
ahead of time inside of the master process


00:33:10.440 --> 00:33:14.500
before we fork off all those worker processes,


00:33:14.500 --> 00:33:17.600
because we want all that memory to be served,


00:33:17.600 --> 00:33:20.920
shared between the different processes.


00:33:20.920 --> 00:33:25.920
So that's kind of a unusual mode for a chip to work in.


00:33:25.920 --> 00:33:28.160
- Right, you don't normally think about


00:33:28.160 --> 00:33:29.920
filtering processes and forking,


00:33:29.920 --> 00:33:32.600
they just do their own thing, right?


00:33:32.600 --> 00:33:34.600
- Yeah, it's just like, okay, I have this method,


00:33:34.600 --> 00:33:36.540
it's gone hot, it's time to chip it.


00:33:36.540 --> 00:33:43.560
So, yeah, so it's used in this weird way.


00:33:43.560 --> 00:33:46.940
At some point we need to, I think,


00:33:46.940 --> 00:33:49.740
add support for kind of normal,


00:33:49.740 --> 00:33:53.540
normal JITting methods when they get hot.


00:33:53.540 --> 00:33:56.940
Like we were at the point where we're talking


00:33:56.940 --> 00:34:01.380
about using Cinder a little bit beyond Instagram


00:34:01.380 --> 00:34:02.800
within meta.


00:34:02.800 --> 00:34:08.220
And so at that point, people are gonna need something


00:34:08.220 --> 00:34:10.480
that isn't so heavily tuned to uWSGI.


00:34:12.540 --> 00:34:17.240
The JIT does, it's entirely,


00:34:17.240 --> 00:34:21.520
we kind of own the full stack.


00:34:21.520 --> 00:34:26.520
So it uses, I think, is it AsmJIT?


00:34:26.520 --> 00:34:32.140
It uses a library to do the x64 code generation.


00:34:32.140 --> 00:34:37.140
But other than that, we go from a high level representation


00:34:37.140 --> 00:34:40.040
where--


00:34:40.040 --> 00:34:41.280
- How close is the high level representation


00:34:41.280 --> 00:34:46.280
to just Python's bytecode, the PYC's bytecode?


00:34:46.280 --> 00:34:51.240
- A pretty good set of overlap.


00:34:51.240 --> 00:34:55.480
There are also a lot of opcodes


00:34:55.480 --> 00:34:58.540
which kind of turn into multiple smaller things.


00:34:58.540 --> 00:35:01.580
So like off the top of my head,


00:35:01.580 --> 00:35:05.120
I think like making a function involves


00:35:05.120 --> 00:35:08.560
setting several different attributes on it at the end.


00:35:08.560 --> 00:35:11.820
So there's something that says, make me this function,


00:35:11.820 --> 00:35:15.580
which is just a single op code in CPython.


00:35:15.580 --> 00:35:17.260
And there's several different op codes


00:35:17.260 --> 00:35:19.500
which are setting those fields on it.


00:35:19.500 --> 00:35:24.260
So it's pretty close, but maybe slightly lower level.


00:35:24.260 --> 00:35:27.780
There's also a lot of op codes in there


00:35:27.780 --> 00:35:31.700
for just kind of super low level operations.


00:35:31.700 --> 00:35:33.280
So one of the things,


00:35:33.280 --> 00:35:35.480
the thing that I spend most of my time working on


00:35:35.480 --> 00:35:37.020
is static Python.


00:35:37.020 --> 00:35:38.760
And so we've added a bunch of things


00:35:38.760 --> 00:35:42.760
that support primitive math and simple loads


00:35:42.760 --> 00:35:46.480
and stores of fields and lower level things like that.


00:35:46.480 --> 00:35:48.200
So it's a mix.


00:35:48.200 --> 00:35:50.920
- Yeah, the static Python that we're gonna talk about


00:35:50.920 --> 00:35:51.760
is super cool.


00:35:51.760 --> 00:35:54.680
And is that possible because the JIT,


00:35:54.680 --> 00:35:55.820
like you can do whatever you want


00:35:55.820 --> 00:35:58.280
and then the JIT will see that and then adapt.


00:35:58.280 --> 00:36:01.860
- The JIT's really important to it


00:36:01.860 --> 00:36:04.960
because like it takes things that are usually


00:36:04.960 --> 00:36:09.200
tons of instructions and turns them into a single instruction


00:36:09.200 --> 00:36:11.520
or a couple of instructions.


00:36:11.520 --> 00:36:14.000
It's not 100% required,


00:36:14.000 --> 00:36:16.400
like we support it in the interpreter loop


00:36:16.400 --> 00:36:20.160
and kind of our goal is to do no harm


00:36:20.160 --> 00:36:23.360
and generally like at least get the normal performance,


00:36:23.360 --> 00:36:26.820
but legit being able to resolve things statically


00:36:26.820 --> 00:36:29.420
and turn them into simple loads is super important.


00:36:31.440 --> 00:36:36.440
So from HIR, we turn that into an SSA form


00:36:36.440 --> 00:36:40.380
and run a bunch of optimizations over it.


00:36:40.380 --> 00:36:43.300
I think one really interesting optimization


00:36:43.300 --> 00:36:46.220
is ref count removal.


00:36:46.220 --> 00:36:51.220
So we can see that these objects are either borrowed


00:36:51.220 --> 00:36:57.700
or just that we'd have extra ref counts happening on them


00:36:57.700 --> 00:36:59.920
that we don't need to actually insert


00:36:59.920 --> 00:37:02.400
and we can just collide all of those, which is--


00:37:02.400 --> 00:37:04.080
- There's a lot of interesting stuff happening


00:37:04.080 --> 00:37:05.920
around memory that you all are doing.


00:37:05.920 --> 00:37:07.660
- Yes.


00:37:07.660 --> 00:37:10.380
- One of them is this ref count,


00:37:10.380 --> 00:37:13.120
and you make assumptions that are reasonable.


00:37:13.120 --> 00:37:16.720
Like when I'm in a method call of a class,


00:37:16.720 --> 00:37:21.500
I don't need to increment and then decrement the self object


00:37:21.500 --> 00:37:22.640
because guess what?


00:37:22.640 --> 00:37:24.720
The thing must be alive because it's doing stuff, right?


00:37:24.720 --> 00:37:26.640
And then it sounds like also maybe with constants,


00:37:26.640 --> 00:37:29.280
like the number one doesn't need its ref count to change


00:37:29.280 --> 00:37:31.380
and stuff like that, you notice that and go,


00:37:31.380 --> 00:37:33.520
you know what, we're just gonna skip that.


00:37:33.520 --> 00:37:38.120
- Yeah, yeah, and one of the things we've done


00:37:38.120 --> 00:37:40.360
is the immortalization of objects.


00:37:40.360 --> 00:37:44.160
And so we can also, like the number one


00:37:44.160 --> 00:37:47.040
is gonna be an immortal instance.


00:37:47.040 --> 00:37:50.460
And so in that case, we can be like, okay, yeah,


00:37:50.460 --> 00:37:53.400
we don't need to deal with ref counts on this.


00:37:53.400 --> 00:37:55.600
Unless of course, like that number one


00:37:55.600 --> 00:38:00.600
ends up going off to somewhere that maybe doesn't understand


00:38:00.600 --> 00:38:03.220
the ref counting semantics of the JIT,


00:38:03.220 --> 00:38:06.260
in which case maybe we do have to end up inserting them.


00:38:06.260 --> 00:38:08.900
Or like it's going through like an if else or something


00:38:08.900 --> 00:38:13.780
where one of the branches we have to end up ref counting.


00:38:13.780 --> 00:38:16.420
So it's smart.


00:38:16.420 --> 00:38:22.340
And it's important because within mortal instances,


00:38:22.340 --> 00:38:24.580
our ref counts are a little bit more expensive


00:38:24.580 --> 00:38:26.980
than normal ref counts,


00:38:26.980 --> 00:38:30.220
'cause we have to check to see if the object is immortal too.


00:38:30.220 --> 00:38:33.860
- Right, instead of just doing an increment on a number.


00:38:33.860 --> 00:38:34.700
- Yeah. (laughs)


00:38:34.700 --> 00:38:37.340
- Okay, so this immortal instances,


00:38:37.340 --> 00:38:39.060
this comes back to that memory thing


00:38:39.060 --> 00:38:41.020
that comes back to the turning off the GC,


00:38:41.020 --> 00:38:42.460
which you stopped turning it off.


00:38:42.460 --> 00:38:44.060
It sounds like immortal instances


00:38:44.060 --> 00:38:47.300
are a more nuanced way to solve that same problem.


00:38:47.300 --> 00:38:51.980
- So this is really about that fork and exec model.


00:38:51.980 --> 00:38:56.480
So when we fork off those worker processes,


00:38:56.480 --> 00:38:58.920
they're initially sharing all of the memory


00:38:58.920 --> 00:39:00.800
with the master process,


00:39:00.800 --> 00:39:03.760
unless they happen to go off and write to it.


00:39:03.760 --> 00:39:08.640
And ref counts are a really big source


00:39:08.640 --> 00:39:11.900
of writing to that shared memory.


00:39:11.900 --> 00:39:14.800
And so what this does is it takes all of the objects


00:39:14.800 --> 00:39:18.600
that are present inside of the master process


00:39:18.600 --> 00:39:21.520
and runs through, marks them all as immortal.


00:39:21.520 --> 00:39:25.880
And then from then on out, the trial process will be like,


00:39:25.880 --> 00:39:27.240
oh, this thing's immortal.


00:39:27.240 --> 00:39:29.320
I'm not gonna change the ref count.


00:39:29.320 --> 00:39:30.160
And so that makes it--


00:39:30.160 --> 00:39:31.480
- Okay, so this happens,


00:39:31.480 --> 00:39:34.200
you basically just scan the whole heap


00:39:34.200 --> 00:39:35.960
right before you do the fork,


00:39:35.960 --> 00:39:38.440
and you're like, everything, we're just gonna clone this,


00:39:38.440 --> 00:39:39.820
and it becomes unchangeable.


00:39:39.820 --> 00:39:43.200
And then we'll just, at least with regard to its ref count,


00:39:43.200 --> 00:39:44.040
and we'll go from there.


00:39:44.040 --> 00:39:45.120
- Yep, yeah.


00:39:45.120 --> 00:39:48.420
And then as long as, ideally, we also don't,


00:39:48.420 --> 00:39:52.700
we shouldn't have a lot of global mutable state.


00:39:52.700 --> 00:39:54.100
People shouldn't be,


00:39:54.100 --> 00:39:55.300
like, you know, if you think about


00:39:55.300 --> 00:39:57.500
what's in the master process,


00:39:57.500 --> 00:39:59.920
it's like classes and functions,


00:39:59.920 --> 00:40:02.340
and people shouldn't be really going off


00:40:02.340 --> 00:40:05.700
and mutating those things inside of the worker processes.


00:40:05.700 --> 00:40:08.740
It seems like something strange is happening


00:40:08.740 --> 00:40:09.760
if that's going on.


00:40:09.760 --> 00:40:13.620
- I guess maybe let me ask you really quick


00:40:13.620 --> 00:40:16.300
or let you talk about really quickly this.


00:40:16.300 --> 00:40:20.860
The real benefit here is if on Linux,


00:40:20.860 --> 00:40:23.020
when you fork off these processes,


00:40:23.020 --> 00:40:26.180
if the memory itself hasn't been changed,


00:40:26.180 --> 00:40:30.380
that can be shared across the 40 or 60 processes.


00:40:30.380 --> 00:40:31.660
But as soon as that memory change,


00:40:31.660 --> 00:40:34.600
it has like a local copy has to be dedicated


00:40:34.600 --> 00:40:36.940
to that one worker process.


00:40:36.940 --> 00:40:39.100
So if it's silly stuff, simple stuff,


00:40:39.100 --> 00:40:42.540
like I want to pass this string around


00:40:42.540 --> 00:40:44.400
that happens to be global,


00:40:44.400 --> 00:40:47.080
And then it says, well, it's passed.


00:40:47.080 --> 00:40:47.920
Excuse me.


00:40:47.920 --> 00:40:52.500
So you've got to add ref to it,


00:40:52.500 --> 00:40:56.460
which means you get 60 copies of it all of a sudden, right?


00:40:56.460 --> 00:40:57.680
Those really simple things,


00:40:57.680 --> 00:41:00.240
you were able to get lots better memory sharing,


00:41:00.240 --> 00:41:02.640
which then leads to cache hits versus cache mists


00:41:02.640 --> 00:41:03.680
and misses.


00:41:03.680 --> 00:41:06.000
And there's like all these knock-on effects, right?


00:41:06.000 --> 00:41:06.840
- Yeah.


00:41:06.840 --> 00:41:09.280
And it's not just the string itself, right?


00:41:09.280 --> 00:41:11.840
It's the entire page that the string lives on.


00:41:11.840 --> 00:41:16.840
So, you might have a 15 byte string


00:41:16.840 --> 00:41:21.360
with a 16 byte object header


00:41:21.360 --> 00:41:25.040
and you end up copying 4K of memory.


00:41:25.040 --> 00:41:29.160
- Because you changed a six reference number


00:41:29.160 --> 00:41:31.600
to a seven or to a five.


00:41:31.600 --> 00:41:32.440
- Yeah.


00:41:32.440 --> 00:41:34.120
- Fascinating.


00:41:34.120 --> 00:41:35.520
Okay.


00:41:35.520 --> 00:41:38.680
Do you think that Python, CPython itself could adopt this?


00:41:38.680 --> 00:41:41.320
- So we tried.


00:41:41.320 --> 00:41:44.740
We tried to upstream it and there is resistance to it.


00:41:44.740 --> 00:41:48.180
I mean, it is touching something that's very core.


00:41:48.180 --> 00:41:50.680
It's gonna be a bit of a maintenance burden.


00:41:50.680 --> 00:41:54.740
There are other reasons, I think,


00:41:54.740 --> 00:41:56.860
that people are now talking about wanting


00:41:56.860 --> 00:41:58.860
to have immortal instances.


00:41:58.860 --> 00:42:02.340
So Eric Snow has been working on subinterpreters


00:42:02.340 --> 00:42:06.260
for a long time and I think he has been interested


00:42:06.260 --> 00:42:11.260
in them recently for sharing objects between interpreters.


00:42:11.260 --> 00:42:19.580
And I think Sam Gross's work on NoGil might have some form of immortal instances as well.


00:42:19.580 --> 00:42:30.460
So maybe the core immortal instances support could land upstream at some point,


00:42:30.460 --> 00:42:36.540
but maybe the code that actually is walking the heap and is freezing everything,


00:42:36.540 --> 00:42:41.540
maybe that's very Instagram specific and doesn't have much value in upstreaming.


00:42:41.540 --> 00:42:48.820
It seems to me that there's probably a set of things that would be good immortal


00:42:48.820 --> 00:42:53.920
instances for almost any Python process that starts up, right?


00:42:53.920 --> 00:42:58.460
Like before your code runs everything there probably would be a good candidate


00:42:58.460 --> 00:42:59.300
for that.


00:42:59.300 --> 00:43:04.140
And you know, there's potential,


00:43:05.020 --> 00:43:08.620
Like it's kind of scary because ref counts are so frequent


00:43:08.620 --> 00:43:14.780
and so adding extra code in the ref count process seems risky.


00:43:14.780 --> 00:43:19.520
But if you can freeze enough stuff that was kind of there


00:43:19.520 --> 00:43:23.340
before the program started up, that's super core and happening a lot,


00:43:23.340 --> 00:43:33.080
then maybe it does actually end up making sense for other workloads too.


00:43:33.080 --> 00:43:37.160
Yeah, perhaps. Okay, so these immortal instances are one of the things you all have done.


00:43:37.160 --> 00:43:39.160
That's pretty fascinating.


00:43:39.160 --> 00:43:44.160
And also a huge win, something like 5%.


00:43:44.160 --> 00:43:46.160
Yeah, yeah, that's right. It says right here.


00:43:46.160 --> 00:43:48.160
Big win in production, 5%.


00:43:48.160 --> 00:43:52.160
Does that mean 5% request per second?


00:43:52.160 --> 00:43:55.160
Is that when you say 5%? Is that the metric you're talking about here?


00:43:55.160 --> 00:43:56.160
Yep.


00:43:56.160 --> 00:43:58.160
Yeah.


00:43:58.160 --> 00:44:01.160
Have you thought about or tested, I'm sure you've thought about,


00:44:01.160 --> 00:44:06.160
like if this lets you run more worker processes off of,


00:44:06.160 --> 00:44:10.380
you know, increment that, that spawn worker process number.


00:44:10.380 --> 00:44:15.180
- I think the developer who worked on this was doing,


00:44:15.180 --> 00:44:20.180
did look at that number and was looking at tweaking


00:44:20.180 --> 00:44:22.320
the number of worker processes.


00:44:22.320 --> 00:44:26.540
If I recall, he got a little bit of pushback


00:44:26.540 --> 00:44:29.220
from people who were nervous about increasing it.


00:44:29.220 --> 00:44:30.280
- Don't mess with this number.


00:44:30.280 --> 00:44:31.560
We never mess with this number.


00:44:31.560 --> 00:44:32.400
What are you doing?


00:44:32.400 --> 00:44:33.220
(laughing)


00:44:33.220 --> 00:44:34.060
- Yeah.


00:44:34.060 --> 00:44:37.400
Yeah.


00:44:37.400 --> 00:44:38.220
(laughing)


00:44:38.220 --> 00:44:39.060
So I don't--


00:44:39.060 --> 00:44:40.040
- I hear you.


00:44:40.040 --> 00:44:40.880
I'm just thinking,


00:44:40.880 --> 00:44:43.380
if it really does create more shared memory,


00:44:43.380 --> 00:44:46.760
maybe it creates more space on the same hardware


00:44:46.760 --> 00:44:48.040
for you to actually create more.


00:44:48.040 --> 00:44:51.040
And then that would just possibly allow


00:44:51.040 --> 00:44:53.320
even a bigger gain in requests per second


00:44:53.320 --> 00:44:55.560
because there's more parallelism.


00:44:55.560 --> 00:44:57.960
- And given that it was such a big win,


00:44:57.960 --> 00:45:00.040
it could have just been that we were already


00:45:00.040 --> 00:45:02.140
under significant memory pressure


00:45:02.140 --> 00:45:05.160
and it got us out of significant memory pressure.


00:45:05.160 --> 00:45:06.700
Maybe we had the right number.


00:45:06.700 --> 00:45:08.540
Maybe we had too many hosts, I don't know.


00:45:08.540 --> 00:45:10.340
- Yeah, yeah, perhaps, perhaps.


00:45:10.340 --> 00:45:13.780
But still 5% is, as one of the changes,


00:45:13.780 --> 00:45:16.100
is still a pretty big deal.


00:45:16.100 --> 00:45:20.700
All right, the next one on deck is strict modules.


00:45:20.700 --> 00:45:22.780
Let's talk about strict modules.


00:45:22.780 --> 00:45:25.900
- So, I mean, we've talked about a little bit of things


00:45:25.900 --> 00:45:28.300
that are kind of related to this.


00:45:28.300 --> 00:45:30.220
You know, I was saying, like, if you have things


00:45:30.220 --> 00:45:32.700
that are going off and mutating your things


00:45:32.700 --> 00:45:34.700
in the master process, it's like, what?


00:45:34.700 --> 00:45:35.840
That's kind of crazy.


00:45:35.840 --> 00:45:42.100
So strict modules weren't about performance, actually.


00:45:42.100 --> 00:45:44.640
There's a little bit of performance thought behind it,


00:45:44.640 --> 00:45:48.100
but now they're really, we're not considering them


00:45:48.100 --> 00:45:50.420
as a performance feature at all.


00:45:50.420 --> 00:45:53.180
They're more about a reliability feature.


00:45:53.180 --> 00:45:57.060
And so you brought up early on how, like, Python modules,


00:45:57.060 --> 00:45:59.480
just going off, executing some code,


00:45:59.480 --> 00:46:02.380
who knows what that code's gonna do.


00:46:02.380 --> 00:46:08.420
So strict modules is a attempt to tame that process.


00:46:08.420 --> 00:46:15.040
And what we do is we run static analysis over the code.


00:46:15.040 --> 00:46:18.440
I mean, we are basically interpreting the code


00:46:18.440 --> 00:46:19.800
in a safe interpreter.


00:46:19.800 --> 00:46:24.660
And if the module has any external side effects


00:46:24.660 --> 00:46:27.420
or depends upon any external side effects,


00:46:27.420 --> 00:46:29.080
we don't allow it to be imported.


00:46:29.080 --> 00:46:34.660
And so we know that all the modules are side effect free


00:46:34.660 --> 00:46:35.900
that are strict.


00:46:35.900 --> 00:46:40.300
And we've-


00:46:40.300 --> 00:46:41.900
- When you say they're side effect free,


00:46:41.900 --> 00:46:43.860
does that mean that the importing of them


00:46:43.860 --> 00:46:46.940
is side effect free or all of their functions


00:46:46.940 --> 00:46:48.820
are also side effect free?


00:46:48.820 --> 00:46:49.860
- The importing of them.


00:46:49.860 --> 00:46:52.460
Their functions can do whatever they want.


00:46:52.460 --> 00:46:54.860
they can call functions from other modules,


00:46:54.860 --> 00:46:58.020
they can call functions from themselves.


00:46:58.020 --> 00:47:00.820
If they call those modules at the top level


00:47:00.820 --> 00:47:02.340
while doing the import,


00:47:02.340 --> 00:47:04.800
then those functions need to be side effect free.


00:47:04.800 --> 00:47:10.540
- Where does this lead you?


00:47:10.540 --> 00:47:12.780
What do you get out of this?


00:47:12.780 --> 00:47:14.940
- We get additional reliability.


00:47:14.940 --> 00:47:19.940
So like Instagram, as I think maybe we mentioned this,


00:47:21.300 --> 00:47:25.140
being a big monolithic application.


00:47:25.140 --> 00:47:26.300
Maybe we didn't get to that.


00:47:26.300 --> 00:47:27.140
- Yeah, I don't think we talked about that,


00:47:27.140 --> 00:47:31.560
but this is not a 100 microservices type of thing, is it?


00:47:31.560 --> 00:47:34.660
- No, it's one giant application.


00:47:34.660 --> 00:47:36.860
The thing that gets redeployed every 10 minutes


00:47:36.860 --> 00:47:38.660
is that giant application.


00:47:38.660 --> 00:47:41.380
- That makes the redeployment even more impressive,


00:47:41.380 --> 00:47:43.860
by the way, right?


00:47:43.860 --> 00:47:46.280
- Yeah, I mean, maybe.


00:47:49.520 --> 00:47:51.640
- It's nice in that it's one giant application


00:47:51.640 --> 00:47:53.800
'cause you just have to redeploy one thing.


00:47:53.800 --> 00:47:55.880
(laughs)


00:47:55.880 --> 00:48:00.320
- Things you gotta keep in sync all at the same time, right?


00:48:00.320 --> 00:48:02.680
- Yeah, our PEs make that happen


00:48:02.680 --> 00:48:04.320
and it just happens behind the scenes


00:48:04.320 --> 00:48:05.560
as far as I'm concerned.


00:48:05.560 --> 00:48:07.640
(laughs)


00:48:07.640 --> 00:48:13.120
So, if you have, like, if you import one module


00:48:13.120 --> 00:48:16.360
and it depends on side effects from another module


00:48:16.360 --> 00:48:20.020
and then something changes the import order,


00:48:20.020 --> 00:48:22.900
whether that's like state that things are depending upon,


00:48:22.900 --> 00:48:25.480
suddenly things blow up in production


00:48:25.480 --> 00:48:29.780
and your site doesn't work and everyone's really sad.


00:48:29.780 --> 00:48:34.100
So this is like, we wanna get to a world


00:48:34.100 --> 00:48:36.620
where our modules are completely safe.


00:48:36.620 --> 00:48:38.940
We've used this, we've experimented


00:48:38.940 --> 00:48:40.920
doing other things with this.


00:48:40.920 --> 00:48:43.560
So like adding a hop reload capability,


00:48:43.560 --> 00:48:47.100
We know the modules are completely side effect free.


00:48:47.100 --> 00:48:49.640
Why not just patch the module in place


00:48:49.640 --> 00:48:53.080
and like let developers move on


00:48:53.080 --> 00:48:54.860
without restarting the website?


00:48:54.860 --> 00:48:59.060
It has the potential to kind of really change


00:48:59.060 --> 00:49:00.780
the way we store modules,


00:49:00.780 --> 00:49:03.800
although we haven't gone down this route yet,


00:49:03.800 --> 00:49:05.700
where instead of storing modules


00:49:05.700 --> 00:49:09.660
is a bunch of Python code that needs to run off and execute.


00:49:09.660 --> 00:49:13.340
Could we store modules as like, here's a class definition,


00:49:13.340 --> 00:49:18.340
here's a function and can we lazily load portions


00:49:18.340 --> 00:49:20.960
of the modules out of there?


00:49:20.960 --> 00:49:24.220
But we also have a really other different take


00:49:24.220 --> 00:49:26.380
on lazy loading that's in Cinder now too.


00:49:26.380 --> 00:49:30.340
- Yeah, that's interesting.


00:49:30.340 --> 00:49:33.740
'Cause normally you can't re-import something


00:49:33.740 --> 00:49:39.780
because maybe you've set up some kind of static value


00:49:41.640 --> 00:49:45.560
on a class, you've set some module level variable,


00:49:45.560 --> 00:49:47.260
and that'll get wiped away, right?


00:49:47.260 --> 00:49:51.600
- I mean, you can call reload on a module,


00:49:51.600 --> 00:49:56.600
but whether or not that's a safe thing to do, who knows?


00:49:56.600 --> 00:49:58.620
- Exactly, exactly.


00:49:58.620 --> 00:49:59.460
All right, cool.


00:49:59.460 --> 00:50:02.120
So I think one of the more interesting areas,


00:50:02.120 --> 00:50:04.840
probably the two that really stood out to me


00:50:04.840 --> 00:50:06.600
are the JIT and StaticPython,


00:50:06.600 --> 00:50:09.180
with the mortal objects being right behind it.


00:50:09.180 --> 00:50:11.440
But StaticPython, this is your area, right?


00:50:11.440 --> 00:50:12.380
What is this?


00:50:12.380 --> 00:50:13.400
- Yep.


00:50:13.400 --> 00:50:18.400
So this is a attempt to leverage the types


00:50:18.400 --> 00:50:22.960
that we already have throughout our entire code base.


00:50:22.960 --> 00:50:27.480
So Instagram is a hundred percent typed,


00:50:27.480 --> 00:50:30.320
although there are still some any types flowing around,


00:50:30.320 --> 00:50:34.360
but you can't add code that isn't typed.


00:50:34.360 --> 00:50:39.200
So we know the types of things.


00:50:39.200 --> 00:50:40.720
- Right, you're talking traditional,


00:50:40.720 --> 00:50:43.800
just colon int, colon str, optional str,


00:50:43.800 --> 00:50:47.200
that type of typing, yeah?


00:50:47.200 --> 00:50:52.200
- Yeah, so why not add a compilation step


00:50:52.200 --> 00:50:56.200
when we're compiling things to PYCs,


00:50:56.200 --> 00:51:00.940
instead of just ignoring the types?


00:51:00.940 --> 00:51:02.940
Why don't we pay attention to the types?


00:51:02.940 --> 00:51:08.200
So we have a compiler that's written in Python.


00:51:08.200 --> 00:51:12.240
There's actually this old compiler package


00:51:12.240 --> 00:51:14.380
that started in Python 2.


00:51:14.380 --> 00:51:19.120
There's this external, there's this developer on GitHub,


00:51:19.120 --> 00:51:24.120
PF Falcon, who upgraded it to Python 3 at some point,


00:51:24.120 --> 00:51:29.440
and we upgraded it to Python 3.8,


00:51:29.440 --> 00:51:34.440
and made it match CPython identical


00:51:34.440 --> 00:51:36.920
for bytecode generation.


00:51:36.920 --> 00:51:41.000
So we have this great Python code base to work in,


00:51:41.000 --> 00:51:42.620
to write a compiler in,


00:51:42.620 --> 00:51:45.680
and we analyze the type annotations,


00:51:45.680 --> 00:51:48.220
and then we have runtime support


00:51:48.220 --> 00:51:51.100
and a set of new opcodes


00:51:51.100 --> 00:51:56.100
that can much more efficiently dispatch the things.


00:51:56.100 --> 00:52:01.240
There's a great, my coworker, Karl Meyer,


00:52:01.240 --> 00:52:04.320
had this awesome slide of calling a function


00:52:05.460 --> 00:52:10.460
during a PyCon talk and it was just like pages,


00:52:10.460 --> 00:52:13.760
well, it was one page and a very, very tiny font


00:52:13.760 --> 00:52:16.140
of the assembly of what it takes for CPython


00:52:16.140 --> 00:52:17.780
to invoke a function.


00:52:17.780 --> 00:52:21.660
And then we're able to just directly call the function


00:52:21.660 --> 00:52:24.180
using the x64 calling convention.


00:52:24.180 --> 00:52:26.340
So shuffle a few registers around


00:52:26.340 --> 00:52:28.380
and emit a call instruction.


00:52:28.380 --> 00:52:29.220
- That's awesome.


00:52:29.220 --> 00:52:31.800
It surprised me when I first got into Python,


00:52:32.780 --> 00:52:35.580
how expensive calling a function was,


00:52:35.580 --> 00:52:39.180
not regardless of what it does, just the act of calling it.


00:52:39.180 --> 00:52:41.940
You know, coming from C# and C++


00:52:41.940 --> 00:52:44.580
where you think you'll get inline by either the compiler


00:52:44.580 --> 00:52:46.740
or the JIT compiler and all sorts of interesting things.


00:52:46.740 --> 00:52:48.180
You're like, wait, this is expensive.


00:52:48.180 --> 00:52:51.620
I should consider whether or not I'm calling a function


00:52:51.620 --> 00:52:52.500
in a tight loop.


00:52:52.500 --> 00:52:55.780
- There's so many things it has to deal with.


00:52:55.780 --> 00:52:59.220
Like it has to deal with adding the default values in


00:52:59.220 --> 00:53:01.740
and you don't know whether you're gonna have to do that


00:53:01.740 --> 00:53:03.580
until you get to the function.


00:53:03.580 --> 00:53:06.460
It's gotta deal with taking keyword arguments


00:53:06.460 --> 00:53:09.880
and mapping those onto the correct keywords.


00:53:09.880 --> 00:53:13.500
And like, that's one thing in static Python,


00:53:13.500 --> 00:53:14.860
we do that at compile time.


00:53:14.860 --> 00:53:17.540
Like we, if you're calling with keyword arguments,


00:53:17.540 --> 00:53:19.340
they turn into positional arguments


00:53:19.340 --> 00:53:21.340
because we know what we're going to,


00:53:21.340 --> 00:53:24.280
and we can just shuffle those around at compile time


00:53:24.280 --> 00:53:26.900
and just save a whole bunch of overhead.


00:53:26.900 --> 00:53:27.740
- Yeah, that's fantastic.


00:53:27.740 --> 00:53:28.940
And the way people should think of this


00:53:28.940 --> 00:53:33.940
is maybe like mypyc or Cython where it looks like


00:53:33.940 --> 00:53:37.500
regular Python, but then out the other side


00:53:37.500 --> 00:53:40.020
comes better stuff, except for the difference here


00:53:40.020 --> 00:53:42.680
is you guys do it at JIT, not as some sort of


00:53:42.680 --> 00:53:45.260
ahead of time pre-deployment type of thing.


00:53:45.260 --> 00:53:48.380
- Yeah, and so the first thing we did with it


00:53:48.380 --> 00:53:52.020
was actually we had, I don't know, 40 Cython modules


00:53:52.020 --> 00:53:55.020
that were inside of the Instagram code base.


00:53:55.020 --> 00:53:57.460
And that was a big developer pain point


00:53:57.460 --> 00:54:00.280
and that those things had to be rebuilt.


00:54:00.280 --> 00:54:04.200
The tooling for editing them wasn't as good


00:54:04.200 --> 00:54:06.980
because you don't get syntax color highlighting.


00:54:06.980 --> 00:54:09.860
And so we were able to just get rid of all of those.


00:54:09.860 --> 00:54:12.420
And those were heavily tuned,


00:54:12.420 --> 00:54:15.560
like using a bunch of Cython features.


00:54:15.560 --> 00:54:17.600
And so that really kind of proved things out


00:54:17.600 --> 00:54:21.540
that like, okay, if we need to use low-level features,


00:54:21.540 --> 00:54:23.300
'cause we support things like permanent events


00:54:23.300 --> 00:54:24.720
if you wanna use them,


00:54:24.720 --> 00:54:28.600
instead of like having boxed variable size.


00:54:28.600 --> 00:54:33.600
And so that was a good proving that it worked.


00:54:33.600 --> 00:54:38.960
And now I think it's more close to my PySE at runtime


00:54:38.960 --> 00:54:41.800
as we've been going through and converting other modules


00:54:41.800 --> 00:54:47.100
to a static Python within the Instagram code base.


00:54:47.100 --> 00:54:48.860
- Yeah, fantastic.


00:54:48.860 --> 00:54:51.880
You guys say that static Python plus sender JIT


00:54:51.880 --> 00:54:56.340
achieve seven times performance improvements over CPython


00:54:56.340 --> 00:54:58.120
on the type version of Richard's benchmark.


00:54:58.120 --> 00:55:00.080
I mean, obviously you gotta be specific, right?


00:55:00.080 --> 00:55:00.920
But still that's a huge--


00:55:00.920 --> 00:55:02.840
- Yeah, yep.


00:55:02.840 --> 00:55:06.600
And some of that's like the ability


00:55:06.600 --> 00:55:08.840
to use primitive integers.


00:55:08.840 --> 00:55:12.320
Some of that's the ability to use V tables


00:55:12.320 --> 00:55:16.320
for invoking functions instead of having


00:55:16.320 --> 00:55:18.200
to do the dynamic lookup, which is something


00:55:18.200 --> 00:55:20.600
that both mypyc and Cython support.


00:55:21.720 --> 00:55:24.340
So lots of little things end up adding up a lot


00:55:24.340 --> 00:55:26.040
and some of that's just legit.


00:55:26.040 --> 00:55:27.200
- Yeah, it's fantastic.


00:55:27.200 --> 00:55:32.340
You've talked about using primitive integers


00:55:32.340 --> 00:55:35.380
and I've always thought that Python


00:55:35.380 --> 00:55:37.380
should support this idea somehow.


00:55:37.380 --> 00:55:41.280
Like if you're doing some operation


00:55:41.280 --> 00:55:42.980
like computing the square root or something,


00:55:42.980 --> 00:55:46.740
you take two numbers, two integers and do some math,


00:55:46.740 --> 00:55:50.180
maybe multiply, square them and then subtract them


00:55:50.180 --> 00:55:51.660
or something like that.


00:55:51.660 --> 00:55:56.540
And all of that stuff goes through a really high overhead


00:55:56.540 --> 00:55:58.860
version of what a number is, right?


00:55:58.860 --> 00:56:03.860
Like instead of being a four or eight byte thing


00:56:03.860 --> 00:56:09.140
on a register, it's 50 bytes or something like that


00:56:09.140 --> 00:56:13.540
as a high object long thing that gets ref counted.


00:56:13.540 --> 00:56:16.860
And then like somewhere in there is the number bit.


00:56:16.860 --> 00:56:19.180
And that's awesome because it supports having huge numbers.


00:56:19.180 --> 00:56:22.460
Like you don't ever see negative 2.1 billion


00:56:22.460 --> 00:56:25.140
when you add an increment of a number by one in Python,


00:56:25.140 --> 00:56:25.980
which is great.


00:56:25.980 --> 00:56:30.000
But it also means that at certain times you're doing math


00:56:30.000 --> 00:56:33.060
is just so much slower 'cause you can't use registers.


00:56:33.060 --> 00:56:36.720
You've gotta use like complex math, right?


00:56:36.720 --> 00:56:39.340
It sounds like you're doing this,


00:56:39.340 --> 00:56:42.980
this like let's treat this number as a small number


00:56:42.980 --> 00:56:46.260
rather than a high object pointer drive thing.


00:56:46.260 --> 00:56:50.100
And JITs can handle this to some degree, right?


00:56:50.100 --> 00:56:53.660
And they can recognize that things are small numbers


00:56:53.660 --> 00:56:58.140
and generate more efficient code.


00:56:58.140 --> 00:56:59.660
I think when you had Anthony on,


00:56:59.660 --> 00:57:01.620
he was talking about Pigeon doing this.


00:57:01.620 --> 00:57:07.340
There's still some overhead there


00:57:07.340 --> 00:57:10.340
for dealing with the cases where you have to bail out


00:57:10.340 --> 00:57:12.860
and it's not that case.


00:57:12.860 --> 00:57:16.220
It's nice just having the straight line code that's there.


00:57:16.220 --> 00:57:20.720
You can also do tag pointers, which again, kind of handle that.


00:57:20.720 --> 00:57:26.300
Tag pointers are kind of difficult on CPython because things expect PyObject stars,


00:57:26.300 --> 00:57:31.440
and if that PyObject star ever escapes to something that's not your CPython code,


00:57:31.440 --> 00:57:33.440
it's going to be very unhappy.


00:57:33.440 --> 00:57:34.680
- Yeah.


00:57:34.680 --> 00:57:39.500
- So this is, I mean, the nice thing is it's a relatively straightforward way to allow it.


00:57:39.500 --> 00:57:44.140
It was actually a little bit controversial in that like,


00:57:44.140 --> 00:57:48.740
is this really what Python developers are going to expect


00:57:48.740 --> 00:57:51.940
and are we going to have the right semantics there?


00:57:51.940 --> 00:57:54.620
And I think we have a to-do item to actually make things


00:57:54.620 --> 00:57:57.420
raise overflow errors if they do overflow


00:57:57.420 --> 00:58:01.980
instead of flowing over to negative 2 billion.


00:58:01.980 --> 00:58:03.620
- That would be fantastic.


00:58:03.620 --> 00:58:05.460
(laughing)


00:58:05.460 --> 00:58:07.380
I would personally rather see an overflow error


00:58:07.380 --> 00:58:10.100
but then have it wrap around to the negative side


00:58:10.100 --> 00:58:11.960
or go back to zero if it's unsigned


00:58:11.960 --> 00:58:14.700
or whatever terrible outcome you're gonna get.


00:58:14.700 --> 00:58:17.600
- Yeah, yeah, it's a much more reasonable behavior.


00:58:17.600 --> 00:58:19.840
We've just, I guess we haven't been very motivated


00:58:19.840 --> 00:58:21.300
to actually go and fix that.


00:58:21.300 --> 00:58:25.360
- Well, you're probably not doing the type of processing


00:58:25.360 --> 00:58:26.500
that would lead to that, right?


00:58:26.500 --> 00:58:29.300
You're probably not doing like scientific stuff


00:58:29.300 --> 00:58:32.340
where all of a sudden, you took a factorial too big


00:58:32.340 --> 00:58:34.060
or you did some insane thing like that.


00:58:34.060 --> 00:58:35.660
There's probably not a single factorial


00:58:35.660 --> 00:58:37.600
in the entire code base, I would guess.


00:58:37.600 --> 00:58:39.560
- Yeah, there's not a lot of math.


00:58:39.560 --> 00:58:42.580
There was like some, like the only place


00:58:42.580 --> 00:58:44.600
where you've used primitive integers really


00:58:44.600 --> 00:58:46.280
was in the existing conversion,


00:58:46.280 --> 00:58:49.080
in the conversion of the existing Cython code.


00:58:49.080 --> 00:58:49.920
Where people had--


00:58:49.920 --> 00:58:53.040
- Because it probably started as an int32 or an int64, right?


00:58:53.040 --> 00:58:54.280
- Yeah, yeah.


00:58:54.280 --> 00:58:56.280
Like they had that option available to them.


00:58:56.280 --> 00:58:58.100
They used it.


00:58:58.100 --> 00:58:59.740
It's not like something that we're going through


00:58:59.740 --> 00:59:02.560
and sprinkling in a random Python code.


00:59:02.560 --> 00:59:04.260
'Cause like, yeah, we don't do much math.


00:59:04.260 --> 00:59:07.740
It's very object oriented, lots of function calls,


00:59:07.740 --> 00:59:10.620
lots of classes.


00:59:10.620 --> 00:59:11.980
- Yeah, absolutely.


00:59:11.980 --> 00:59:15.540
All right, there's a lot of other good things


00:59:15.540 --> 00:59:16.380
that you talked about,


00:59:16.380 --> 00:59:18.340
but they're not necessarily listed right here.


00:59:18.340 --> 00:59:23.100
Like, it's sort of kind of stuff with async and await.


00:59:23.100 --> 00:59:25.060
It sounds like you guys use async and await a lot.


00:59:25.060 --> 00:59:26.340
Is that right?


00:59:26.340 --> 00:59:27.380
- Yes.


00:59:27.380 --> 00:59:31.200
So the, yeah, the entire code base is basically async.


00:59:32.380 --> 00:59:34.720
there was a big conversion,


00:59:34.720 --> 00:59:38.500
a big push to convert it right as I was starting.


00:59:38.500 --> 00:59:42.640
And now everything basically is async,


00:59:42.640 --> 00:59:43.480
unless obviously it's not--


00:59:43.480 --> 00:59:45.200
- Yeah, I heard that async await is slow,


00:59:45.200 --> 00:59:46.600
why would you ever use that?


00:59:46.600 --> 00:59:51.280
- Because it allows additional parallelization,


00:59:51.280 --> 00:59:54.400
because multiple requests can be served by the same worker.


00:59:54.400 --> 00:59:56.880
- Sure, well, you know, whenever I hear those,


00:59:56.880 --> 00:59:58.280
I see examples of like,


00:59:59.520 --> 01:00:02.560
we're just calling something as fast as you can.


01:00:02.560 --> 01:00:05.880
And it doesn't really provide,


01:00:05.880 --> 01:00:07.740
there's not an actual waiting, right?


01:00:07.740 --> 01:00:09.140
Like the async and await is really good


01:00:09.140 --> 01:00:12.120
to scale the time when you're waiting, do something else.


01:00:12.120 --> 01:00:14.000
And a lot of the examples, this is slower,


01:00:14.000 --> 01:00:15.280
there's like no waiting period,


01:00:15.280 --> 01:00:17.560
but you know what is a really good slow thing?


01:00:17.560 --> 01:00:19.140
An external API and a database.


01:00:19.140 --> 01:00:22.200
And it sounds like you guys probably talk to those things.


01:00:22.200 --> 01:00:26.060
- And yes, and I mean, the no waiting case


01:00:26.060 --> 01:00:30.020
is actually what this eager coroutine evaluation


01:00:30.020 --> 01:00:30.860
is all about.


01:00:30.860 --> 01:00:33.260
Like, yeah, sometimes we're talking to a database,


01:00:33.260 --> 01:00:36.300
but sometimes you have a function that's like,


01:00:36.300 --> 01:00:38.540
have I fetched this from the database?


01:00:38.540 --> 01:00:40.020
Okay, here it is.


01:00:40.020 --> 01:00:41.640
I don't have to wait for it.


01:00:41.640 --> 01:00:44.140
Otherwise I'll go off and fetch it from the database.


01:00:44.140 --> 01:00:47.500
- Right, if there's an early return before the first await.


01:00:47.500 --> 01:00:48.340
- Exactly.


01:00:48.340 --> 01:00:51.020
- There's not a huge value to calling this, right?


01:00:51.020 --> 01:00:51.860
- Yeah.


01:00:51.860 --> 01:00:54.140
- So tell us about this eager coroutine evaluation,


01:00:54.140 --> 01:00:55.980
which deals with that, right?


01:00:55.980 --> 01:00:58.620
- Yeah, so this lets us run the function


01:00:58.620 --> 01:01:03.620
up to the first await and only go off and kind of,


01:01:03.620 --> 01:01:07.500
so A, like normally what happens is


01:01:07.500 --> 01:01:10.780
you produce your coroutine object,


01:01:10.780 --> 01:01:14.040
schedule that on your event loop,


01:01:14.040 --> 01:01:15.740
and then eventually it'll get called.


01:01:15.740 --> 01:01:17.380
And now when you call the function,


01:01:17.380 --> 01:01:19.720
it's gonna run, it's gonna immediately run up


01:01:19.720 --> 01:01:21.160
to the first await.


01:01:21.160 --> 01:01:23.180
And if it doesn't hit that first await,


01:01:23.180 --> 01:01:25.260
it's just gonna have the value that's produced


01:01:25.260 --> 01:01:29.060
and you're not gonna have to go through this big churn


01:01:29.060 --> 01:01:30.300
of going through the event loop


01:01:30.300 --> 01:01:33.380
with this whole coroutine object.


01:01:33.380 --> 01:01:36.220
So, yeah. - That's fantastic.


01:01:36.220 --> 01:01:40.500
- It is slightly different semantics


01:01:40.500 --> 01:01:46.020
because now you could have some CPU heavy thing,


01:01:46.020 --> 01:01:51.020
which is just like not sharing the CPU with other workers,


01:01:51.020 --> 01:01:53.340
which isn't great.


01:01:54.620 --> 01:01:57.920
And I think it can end up kind of,


01:01:57.920 --> 01:02:00.200
I think there can be some slight differences


01:02:00.200 --> 01:02:02.540
on what the scheduling happens,


01:02:02.540 --> 01:02:04.780
like where you could have observable differences,


01:02:04.780 --> 01:02:07.620
but we haven't had any issues with that.


01:02:07.620 --> 01:02:10.660
So I think it's might be a little bit controversial,


01:02:10.660 --> 01:02:12.740
but it is such a big win


01:02:12.740 --> 01:02:14.900
that it makes a lot of sense for us.


01:02:14.900 --> 01:02:18.300
- It certainly could change the order.


01:02:18.300 --> 01:02:21.700
If you were doing, here's a whole bunch of coroutines


01:02:21.700 --> 01:02:24.260
and a bunch of awaits and stuff,


01:02:24.260 --> 01:02:25.580
and then you ran them in one mode,


01:02:25.580 --> 01:02:27.340
the sort of standard mode versus this,


01:02:27.340 --> 01:02:29.460
you would get a different order.


01:02:29.460 --> 01:02:33.140
But, you know, I mean, it sounds like you're gonna


01:02:33.140 --> 01:02:35.780
ultimately put the same amount of CPU load on,


01:02:35.780 --> 01:02:39.020
I mean, async and await runs on one thread anyway,


01:02:39.020 --> 01:02:40.780
generally.


01:02:40.780 --> 01:02:41.600
- Yeah.


01:02:41.600 --> 01:02:43.420
- Unless you do something funky to like wrap


01:02:43.420 --> 01:02:44.580
some kind of thread or something,


01:02:44.580 --> 01:02:47.120
but in general, it still runs there.


01:02:47.120 --> 01:02:51.380
- I would hope that most people aren't super dependent


01:02:51.380 --> 01:02:52.580
upon the order.


01:02:52.580 --> 01:02:53.540
(laughs)


01:02:53.540 --> 01:02:55.200
- If you're dependent upon the order


01:02:55.200 --> 01:02:57.280
and you're doing threading or something like that,


01:02:57.280 --> 01:02:59.060
you're doing it wrong.


01:02:59.060 --> 01:03:00.480
- Yeah.


01:03:00.480 --> 01:03:03.900
The fairness issue might be a bigger issue.


01:03:03.900 --> 01:03:10.060
But yeah, for us it makes a lot of sense.


01:03:10.060 --> 01:03:11.400
- Yeah, that's really cool.


01:03:11.400 --> 01:03:17.260
All right, another one was shadow code or shadow byte code.


01:03:17.260 --> 01:03:20.980
- Yeah, so this is our inline caching implementation.


01:03:21.940 --> 01:03:26.940
We've had this for a few years.


01:03:26.940 --> 01:03:31.980
Python 3.11 is getting something very similar.


01:03:31.980 --> 01:03:36.140
So we kind of expect that our version will be going away.


01:03:36.140 --> 01:03:39.700
We'll have to see if there's any cases that aren't covered


01:03:39.700 --> 01:03:43.060
or if there's any performance differences.


01:03:43.060 --> 01:03:47.500
But basically it's nearly identical.


01:03:47.500 --> 01:03:50.160
We have a extra copy of the byte code,


01:03:50.160 --> 01:03:53.580
which is why it's called shadow byte code,


01:03:53.580 --> 01:03:56.320
which we can mutate in the background


01:03:56.320 --> 01:04:00.760
and replace the normal opcodes with specialized ones.


01:04:00.760 --> 01:04:04.180
So if we're doing a load adder,


01:04:04.180 --> 01:04:08.480
and that load adder is against an instance


01:04:08.480 --> 01:04:11.680
of a specific type, we can just say,


01:04:11.680 --> 01:04:14.640
okay, well, we know that this load adder


01:04:14.640 --> 01:04:18.280
doesn't have a type descriptor associated with it,


01:04:18.280 --> 01:04:22.840
a descriptor associated with it,


01:04:22.840 --> 01:04:25.420
like a get set data descriptor.


01:04:25.420 --> 01:04:31.480
We know that the instance has a split dictionary,


01:04:31.480 --> 01:04:36.160
which is the way CPython shares dictionaries,


01:04:36.160 --> 01:04:39.080
dictionary layout between instances of classes.


01:04:39.080 --> 01:04:42.520
We know this attribute is at offset two


01:04:42.520 --> 01:04:44.460
within the split dictionary.


01:04:44.460 --> 01:04:46.880
So we just do a simple type check


01:04:46.880 --> 01:04:49.120
and make sure that the type's still compatible


01:04:49.120 --> 01:04:52.680
and go off and look in the instance dictionary


01:04:52.680 --> 01:04:53.840
and pull the value out.


01:04:53.840 --> 01:04:57.180
Instead of going through and looking up


01:04:57.180 --> 01:04:59.660
all of those other things that I've just described,


01:04:59.660 --> 01:05:01.360
which is kind of what you have to do


01:05:01.360 --> 01:05:03.720
every single time on a normal load adder.


01:05:03.720 --> 01:05:06.480
- Yeah, that's really cool.


01:05:06.480 --> 01:05:10.320
Is this something that could come back to CPython?


01:05:10.320 --> 01:05:12.080
- Yeah, I think the fact that they've gone off


01:05:12.080 --> 01:05:14.160
and built their own version in 3.11


01:05:14.160 --> 01:05:16.360
means that's not gonna happen. (laughs)


01:05:16.360 --> 01:05:18.360
- The idea lives there.


01:05:18.360 --> 01:05:20.360
- Yes.


01:05:20.360 --> 01:05:22.360
- Awesome.


01:05:22.360 --> 01:05:24.360
What else?


01:05:24.360 --> 01:05:28.360
We're getting short on time here.


01:05:28.360 --> 01:05:31.360
I think maybe you could just highlight really quickly,


01:05:31.360 --> 01:05:37.360
stepping back one feature point on the async I/O stuff.


01:05:37.360 --> 01:05:42.360
Is the send receive without stop iteration stuff that you all did,


01:05:42.360 --> 01:05:45.360
and that getting upstreamed as well already?


01:05:45.360 --> 01:05:57.040
>> Yeah. So that was adding -- so I didn't work on this. Developer Vladimir Mative worked


01:05:57.040 --> 01:06:09.280
on this. And that was adding in a -- I think he added in a new set of slots for actually


01:06:09.280 --> 01:06:14.080
achieving this at the end of the day. And in Sender, we have a type flag that says this


01:06:14.080 --> 01:06:16.600
this type has these additional slots.


01:06:16.600 --> 01:06:19.960
And so we can call the send function


01:06:19.960 --> 01:06:22.720
and the receive function and get back an enum


01:06:22.720 --> 01:06:25.800
that's kind of, did this thing return a result?


01:06:25.800 --> 01:06:28.080
Did this thing throw an exception?


01:06:28.080 --> 01:06:31.760
And here's the result.


01:06:31.760 --> 01:06:35.680
So that instead of producing the stop iteration


01:06:35.680 --> 01:06:39.880
on every single result, we just return the result.


01:06:41.040 --> 01:06:45.240
And that is obviously big with coroutines


01:06:45.240 --> 01:06:47.680
'cause coroutines are generators at the end of the day.


01:06:47.680 --> 01:06:48.920
- Yeah, that's fantastic.


01:06:48.920 --> 01:06:52.580
Yeah, everything can get more efficient


01:06:52.580 --> 01:06:55.400
by not allocating on sort of hidden


01:06:55.400 --> 01:06:58.140
behind the scene exceptions, right?


01:06:58.140 --> 01:06:59.360
- Yeah.


01:06:59.360 --> 01:07:01.800
- All right, well, there's a bunch of cool stuff here


01:07:01.800 --> 01:07:04.300
and I'm really happy to hear that you and your team


01:07:04.300 --> 01:07:06.240
and Hidem are out there are working


01:07:06.240 --> 01:07:07.480
on bringing this stuff over


01:07:07.480 --> 01:07:09.000
because I was so excited when I saw it


01:07:09.000 --> 01:07:10.040
and then I saw, is it supported?


01:07:10.040 --> 01:07:12.340
"Ah, not really, you really shouldn't use this."


01:07:12.340 --> 01:07:13.880
I'm like, "Oh, but it's so good,


01:07:13.880 --> 01:07:16.960
"like I want so much of this stuff to be moved over."


01:07:16.960 --> 01:07:18.760
So that's cool.


01:07:18.760 --> 01:07:21.900
- And I think some of it will be difficult to move over.


01:07:21.900 --> 01:07:23.900
Like moving the entire JIT over,


01:07:23.900 --> 01:07:25.860
the JIT's written in C++.


01:07:25.860 --> 01:07:28.960
Obviously the CPython core developers


01:07:28.960 --> 01:07:32.880
were open to C++ for a JIT at one point in time


01:07:32.880 --> 01:07:34.680
with unladen swallow.


01:07:34.680 --> 01:07:38.580
Whether or not that feeling has changed, who knows?


01:07:38.580 --> 01:07:40.940
but it's a big piece of code to drop in.


01:07:40.940 --> 01:07:44.740
So one thing that we really want to do going forward


01:07:44.740 --> 01:07:47.980
is actually get to the point where the big pieces of Sender


01:07:47.980 --> 01:07:49.980
are actually just pip installable.


01:07:49.980 --> 01:07:54.980
So we'll work on getting the hooks that we need upstreamed.


01:07:54.980 --> 01:07:56.900
One thing that the JIT relies on a lot


01:07:56.900 --> 01:07:59.100
is dictionary watchers so that we can do


01:07:59.100 --> 01:08:01.580
really super fast global loads.


01:08:01.580 --> 01:08:05.620
And we have a bunch of hooks into like type modification


01:08:05.620 --> 01:08:10.160
and function modification that aren't super onerous


01:08:10.160 --> 01:08:11.280
by any means.


01:08:11.280 --> 01:08:13.880
So if we can get those upstream,


01:08:13.880 --> 01:08:17.240
then we can make the JIT just be here, pip install this.


01:08:17.240 --> 01:08:23.320
And so hopefully we can get those upstream in 3.11


01:08:23.320 --> 01:08:29.360
and have pip install sender start working.


01:08:29.360 --> 01:08:30.900
- Yeah, that'd be awesome.


01:08:30.900 --> 01:08:33.480
So yeah, really good work on these.


01:08:33.480 --> 01:08:35.800
I guess let's wrap up our conversation here


01:08:35.800 --> 01:08:37.180
'cause we're definitely short on time.


01:08:37.180 --> 01:08:41.000
But you know, there's the other projects,


01:08:41.000 --> 01:08:43.360
which I'm gonna start calling the Shannon plan


01:08:43.360 --> 01:08:45.880
that Mark and Guido are working on.


01:08:45.880 --> 01:08:47.640
They've been working on for a year.


01:08:47.640 --> 01:08:51.940
And then there's Pigeon, which by the way,


01:08:51.940 --> 01:08:55.560
Anthony Shaw's taken over, but you created Pigeon, right?


01:08:55.560 --> 01:08:56.400
- Yep.


01:08:56.400 --> 01:08:58.440
(laughing)


01:08:58.440 --> 01:08:59.280
- Well done on that.


01:08:59.280 --> 01:09:00.440
- On a week at a PyCon.


01:09:00.440 --> 01:09:03.400
- Exactly.


01:09:03.400 --> 01:09:06.740
And Sam Gross's work on the Nogel stuff,


01:09:06.740 --> 01:09:10.320
all of this seems to be independent,


01:09:10.320 --> 01:09:12.500
but in the same area as those things.


01:09:12.500 --> 01:09:13.720
Where do you see the synergies?


01:09:13.720 --> 01:09:17.040
Do you see any chance for those to come together?


01:09:17.040 --> 01:09:18.240
Is that through some kind of pip,


01:09:18.240 --> 01:09:19.320
putting the right hooks in there


01:09:19.320 --> 01:09:21.100
and other people plugging in what they want?


01:09:21.100 --> 01:09:23.280
Or what do you see there?


01:09:23.280 --> 01:09:26.080
Be great if this can come together a little bit.


01:09:26.080 --> 01:09:28.720
- Yeah, in a lot of places,


01:09:28.720 --> 01:09:31.440
we're working on independent things.


01:09:32.320 --> 01:09:35.360
Obviously, Pidgin is a JIT and we're a JIT.


01:09:35.360 --> 01:09:37.980
So what the future of JITs--


01:09:37.980 --> 01:09:39.920
- Different goals to some degree, right?


01:09:39.920 --> 01:09:44.500
- Yeah, but I mean, also very similar and overlapping goals.


01:09:44.500 --> 01:09:47.740
I think there'll probably have to be discussion


01:09:47.740 --> 01:09:52.340
of what the future of JITs look like in CPython.


01:09:52.340 --> 01:09:54.780
Like, is that something that's part of the core?


01:09:54.780 --> 01:09:58.500
Or is that something that should live on as being external?


01:09:58.500 --> 01:10:01.060
Or is there gonna be a grand competition


01:10:01.060 --> 01:10:03.580
and at one point one of the JITs will win.


01:10:03.580 --> 01:10:06.480
Who knows?


01:10:06.480 --> 01:10:10.700
It's a good discussion that should probably take place.


01:10:10.700 --> 01:10:12.740
The hooks for JITs are there.


01:10:12.740 --> 01:10:17.740
And between what Brett and I added for Pigeon


01:10:17.740 --> 01:10:22.540
and Mark Shannon's vector call work


01:10:22.540 --> 01:10:25.580
that happened several releases ago,


01:10:25.580 --> 01:10:28.300
I think JITs have a pretty good foundation


01:10:28.300 --> 01:10:30.800
for hooking and replacing code execution.


01:10:30.800 --> 01:10:37.500
They probably need other hooks to get into other things


01:10:37.500 --> 01:10:39.960
like the dictionary watchers that I mentioned.


01:10:39.960 --> 01:10:43.820
But we can keep working on hooks.


01:10:43.820 --> 01:10:46.560
Other things have less overlap,


01:10:46.560 --> 01:10:51.560
so hopefully we can all kind of work in our own streams


01:10:51.560 --> 01:10:54.700
and work to improve things and make those available


01:10:54.700 --> 01:10:58.700
to Python developers in the best way that's available


01:10:58.700 --> 01:11:01.940
and not be stomping on each other's shoes


01:11:01.940 --> 01:11:04.140
or duplicating work too much.


01:11:04.140 --> 01:11:05.160
- Yeah, absolutely.


01:11:05.160 --> 01:11:07.500
Well, it's an exciting time.


01:11:07.500 --> 01:11:09.680
I feel like a lot of stuff is sort of coming back


01:11:09.680 --> 01:11:12.340
to the forefront and feels like--


01:11:12.340 --> 01:11:13.900
- So much performance work.


01:11:13.900 --> 01:11:14.740
- Yeah, for sure.


01:11:14.740 --> 01:11:18.660
Feels like the core developers are open to hearing about it


01:11:18.660 --> 01:11:21.900
and taking on some of the disruption and complexity


01:11:21.900 --> 01:11:25.880
that might come from it, but still could be valuable, right?


01:11:25.880 --> 01:11:28.180
I guess there's probably enough--


01:11:28.180 --> 01:11:29.740
- It's absolutely gonna be valuable.


01:11:29.740 --> 01:11:31.340
- Yeah, I feel like there's enough pressure


01:11:31.340 --> 01:11:34.060
from other languages like Go and Rust and stuff.


01:11:34.060 --> 01:11:36.280
Oh, you should come over to our world


01:11:36.280 --> 01:11:37.860
and forget that Python stuff.


01:11:37.860 --> 01:11:38.940
And like, hold on, hold on, hold on.


01:11:38.940 --> 01:11:41.540
We can do that too, but we've got to do it.


01:11:41.540 --> 01:11:42.740
- We can get faster.


01:11:42.740 --> 01:11:44.020
- Yeah.


01:11:44.020 --> 01:11:45.060
Well, this is awesome work.


01:11:45.060 --> 01:11:46.980
Thanks for coming on and sharing.


01:11:46.980 --> 01:11:48.060
- Thank you for having me.


01:11:48.060 --> 01:11:49.180
- Yeah, you and your team are doing.


01:11:49.180 --> 01:11:50.380
Now, before you get out of here,


01:11:50.380 --> 01:11:51.880
Got the final two questions.


01:11:51.880 --> 01:11:55.620
Let's do notable PyPI package first.


01:11:55.620 --> 01:11:58.980
So is there some library or notable package out there


01:11:58.980 --> 01:12:00.700
that you come across like, oh, this thing's awesome.


01:12:00.700 --> 01:12:03.020
People should know about whatever.


01:12:03.020 --> 01:12:05.820
- So does it have to be PyPI?


01:12:05.820 --> 01:12:08.580
- No, any project.


01:12:08.580 --> 01:12:12.000
- Okay, so as I said, I have a very weird relationship


01:12:12.000 --> 01:12:15.420
with Python, right, as using mainly


01:12:15.420 --> 01:12:19.820
from the implementation side.


01:12:19.820 --> 01:12:23.280
So I think my favorite package is the standard library.


01:12:23.280 --> 01:12:27.500
And if I had to pick something out of the standard library,


01:12:27.500 --> 01:12:30.020
I think one of the coolest parts is mock.


01:12:30.020 --> 01:12:36.660
It's been an interesting integration with static Python,


01:12:36.660 --> 01:12:41.860
but like seeing the way people use it


01:12:41.860 --> 01:12:45.980
and drive their tests, it's kind of really kind of amazing.


01:12:45.980 --> 01:12:46.800
- Yeah, I agree.


01:12:46.800 --> 01:12:48.140
It's definitely a very cool


01:12:48.140 --> 01:12:50.260
that people should certainly be using.


01:12:50.260 --> 01:12:52.140
And now if you're gonna write some Python code,


01:12:52.140 --> 01:12:53.780
you might also have special requirements


01:12:53.780 --> 01:12:55.060
that shift you in one way or the other,


01:12:55.060 --> 01:12:56.620
but what editor are you using?


01:12:56.620 --> 01:12:59.740
- Oh, I use VS Code pretty much.


01:12:59.740 --> 01:13:01.780
Well, I use VS Code and I use Nano


01:13:01.780 --> 01:13:04.980
when I need to make a quick edit from the command prompt.


01:13:04.980 --> 01:13:06.660
- Yeah, I'm a fan of Nano as well.


01:13:06.660 --> 01:13:07.780
Like, let's just keep it simple.


01:13:07.780 --> 01:13:09.700
It's just give me a Nano and I'll edit this thing


01:13:09.700 --> 01:13:10.540
over the shell.


01:13:10.540 --> 01:13:11.380
- Yeah.


01:13:11.380 --> 01:13:13.460
It has syntax color highlighting now.


01:13:13.460 --> 01:13:14.780
(laughing)


01:13:14.780 --> 01:13:17.060
- Oh, advanced, that's awesome.


01:13:17.060 --> 01:13:18.460
- Cool, no, I use it as well.


01:13:18.460 --> 01:13:21.020
All right, well, Dino, thank you so much for being here.


01:13:21.020 --> 01:13:21.860
Final call to action,


01:13:21.860 --> 01:13:23.500
people are excited about these ideas,


01:13:23.500 --> 01:13:25.380
maybe they wanna contribute back or try them out.


01:13:25.380 --> 01:13:26.220
What do you say?


01:13:26.220 --> 01:13:30.440
- I mean, try out Sender, yeah, it's unsupported,


01:13:30.440 --> 01:13:34.900
but if you have thoughts on it, that's cool.


01:13:34.900 --> 01:13:37.140
I think we'll be in a better place.


01:13:37.140 --> 01:13:39.020
- You have instructions on how to build it right here,


01:13:39.020 --> 01:13:40.100
so you could check it out.


01:13:40.100 --> 01:13:41.660
- There's a Docker container.


01:13:41.660 --> 01:13:42.620
- Yeah, okay.


01:13:42.620 --> 01:13:46.260
- Yeah, so it's pretty easy to give it a shot.


01:13:46.260 --> 01:13:55.540
You know, like, it might be harder to get it up and running in a perf sensitive environment.


01:13:55.540 --> 01:14:00.620
If you want to try out static Python, that'd be cool or strict modules and give us any


01:14:00.620 --> 01:14:03.140
feedback you have on those.


01:14:03.140 --> 01:14:04.140
Fantastic.


01:14:04.140 --> 01:14:05.140
All right.


01:14:05.140 --> 01:14:07.140
Well, thanks for being on the show.


01:14:07.140 --> 01:14:08.140
Great to chat with you.


01:14:08.140 --> 01:14:09.140
Thank you, Michael.


01:14:09.140 --> 01:14:10.140
Yeah, you bet.


01:14:10.140 --> 01:14:11.140
Bye.


01:14:11.140 --> 01:14:12.140
See you.


01:14:12.140 --> 01:14:13.140
Yeah.


01:14:13.140 --> 01:14:13.140
Bye.


01:14:13.140 --> 01:14:23.140
[BLANK_AUDIO]

