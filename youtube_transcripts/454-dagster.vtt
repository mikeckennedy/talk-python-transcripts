WEBVTT

00:00:00.000 --> 00:00:04.260
>> Pedram, welcome to Talk Python To Me.

00:00:04.260 --> 00:00:05.740
It's amazing to have you here.

00:00:05.740 --> 00:00:08.000
>> Michael, great to be here.

00:00:08.000 --> 00:00:10.420
>> Yeah. We're going to talk about data,

00:00:10.420 --> 00:00:12.680
data pipelines, automation.

00:00:12.680 --> 00:00:14.440
Boy, let me tell you,

00:00:14.440 --> 00:00:17.960
have I been in the DevOps side of things this week.

00:00:17.960 --> 00:00:22.180
I'm going to have a special appreciation of it,

00:00:22.180 --> 00:00:24.360
I can tell already.

00:00:24.360 --> 00:00:26.240
>> I could almost.

00:00:26.240 --> 00:00:30.960
>> Indeed. Before we get to that though,

00:00:30.960 --> 00:00:32.760
before we talk about Dagster and

00:00:32.760 --> 00:00:35.320
data pipelines and orchestration more broadly,

00:00:35.320 --> 00:00:37.400
let's just get a little bit of background on you.

00:00:37.400 --> 00:00:38.960
Introduce yourself for people.

00:00:38.960 --> 00:00:40.880
How did you get into Python and

00:00:40.880 --> 00:00:43.200
data orchestration and all those things?

00:00:43.200 --> 00:00:45.880
>> Of course. My name is Pedram Naveed.

00:00:45.880 --> 00:00:50.200
I'm the head of Data Engineering and DevRel at Dagster,

00:00:50.200 --> 00:00:51.440
that's a mouthful.

00:00:51.440 --> 00:00:56.320
I've been a long-time Python user since 2.7.

00:00:56.320 --> 00:00:59.200
I got started with Python like I do with many things,

00:00:59.200 --> 00:01:00.880
just out of sheer laziness.

00:01:00.880 --> 00:01:05.440
I was working at a bank and there was this rote task,

00:01:05.440 --> 00:01:07.880
something involving going into servers,

00:01:07.880 --> 00:01:09.840
opening up a text file and seeing if

00:01:09.840 --> 00:01:11.800
a patch was applied to a server.

00:01:11.800 --> 00:01:13.640
A nightmare scenario when there's

00:01:13.640 --> 00:01:17.520
a 100 servers to check and 15 different patches to confirm.

00:01:17.520 --> 00:01:19.320
>> Yeah. This predates like

00:01:19.320 --> 00:01:22.240
the Cloud and all that automation stuff, right?

00:01:22.240 --> 00:01:24.840
>> This is definitely before Cloud.

00:01:24.840 --> 00:01:27.880
This was right between Python 2 and

00:01:27.880 --> 00:01:29.240
Python 3 and we were trying to figure

00:01:29.240 --> 00:01:31.480
out how to use print statements correctly.

00:01:31.480 --> 00:01:33.040
That's when I learned Python. I was like,

00:01:33.040 --> 00:01:35.000
there's got to be a better way and honestly,

00:01:35.000 --> 00:01:37.200
I've not looked back. I think if you look at

00:01:37.200 --> 00:01:38.840
my entire career trajectory,

00:01:38.840 --> 00:01:41.320
you'll see it's just punctuated by

00:01:41.320 --> 00:01:45.520
finding ways to be more lazy in many ways.

00:01:45.520 --> 00:01:48.200
>> Yeah. Who was it?

00:01:48.200 --> 00:01:50.960
I think it was Matthew Rocklin that had the phrase

00:01:50.960 --> 00:01:55.120
something like productive laziness or something like that.

00:01:55.120 --> 00:01:58.560
I'm going to find a way to leverage my laziness,

00:01:58.560 --> 00:02:00.440
to force me to build automation so

00:02:00.440 --> 00:02:02.560
I never ever have to do this thing again.

00:02:02.560 --> 00:02:04.440
I got that sort of print.

00:02:04.440 --> 00:02:06.080
>> It's very motivating to not have to do

00:02:06.080 --> 00:02:08.640
something and I'll do anything to not do something.

00:02:08.640 --> 00:02:11.960
>> Yeah. It's incredible.

00:02:11.960 --> 00:02:13.760
Like that DevOps stuff I was talking about,

00:02:13.760 --> 00:02:18.040
just one command and there's

00:02:18.040 --> 00:02:20.880
maybe eight or nine new apps with all their tiers,

00:02:20.880 --> 00:02:22.920
redeployed, updated, resynced.

00:02:22.920 --> 00:02:25.560
It took me a lot of work to get there.

00:02:25.560 --> 00:02:28.880
But now, I never have to think about it again,

00:02:28.880 --> 00:02:31.720
at least not for a few years and it's amazing.

00:02:31.720 --> 00:02:35.600
I can just be productive. It's right in line with that.

00:02:35.600 --> 00:02:39.360
What are some of the Python projects you've worked on,

00:02:39.360 --> 00:02:42.440
talked about different ways to apply this over the years?

00:02:42.440 --> 00:02:45.600
>> Yeah. It started with internal,

00:02:45.600 --> 00:02:46.760
just like Python projects,

00:02:46.760 --> 00:02:48.320
trying to automate, like I said,

00:02:48.320 --> 00:02:52.960
some rote tasks that I had and that accidentally becomes

00:02:52.960 --> 00:02:55.760
a bigger project people see it and they're like, "Oh,

00:02:55.760 --> 00:02:58.360
I want that too." Well, now I have to build

00:02:58.360 --> 00:03:02.200
a GUI interface because most people don't speak Python.

00:03:02.200 --> 00:03:05.800
That got me into PyGUI,

00:03:05.800 --> 00:03:08.280
I think it was called way back when.

00:03:08.280 --> 00:03:10.240
That was a fun journey.

00:03:10.240 --> 00:03:12.400
Then from there, it's really taken off.

00:03:12.400 --> 00:03:15.480
A lot of it has been mostly personal projects,

00:03:15.480 --> 00:03:18.080
trying to understand open source was

00:03:18.080 --> 00:03:21.400
a really big learning path for me as well.

00:03:21.400 --> 00:03:23.880
Really being absorbed by things like

00:03:23.880 --> 00:03:27.040
SQLAlchemy and requests back when they were coming out.

00:03:27.040 --> 00:03:33.040
Eventually, it led to more of a data engineering type of role,

00:03:33.040 --> 00:03:35.840
where I got involved with tools like Airflow and try to

00:03:35.840 --> 00:03:40.400
automate data pipelines instead of patches on a server.

00:03:40.400 --> 00:03:43.440
That one day led to,

00:03:43.440 --> 00:03:45.520
I guess, making a long story short,

00:03:45.520 --> 00:03:49.160
a role at Dagster where now I contribute a little bit to Dagster.

00:03:49.160 --> 00:03:50.960
I work on Dagster, the core project itself,

00:03:50.960 --> 00:03:55.320
but I also use Dagster internally to build our own data pipelines.

00:03:55.320 --> 00:03:59.040
>> I'm sure it's interesting to see how you

00:03:59.040 --> 00:04:02.920
all both build Dagster and then consume Dagster.

00:04:02.920 --> 00:04:06.280
>> Yeah, it's been wonderful.

00:04:06.280 --> 00:04:08.360
I think there's a lot of great things about it.

00:04:08.360 --> 00:04:13.360
One is getting access to Dagster before it's fully released.

00:04:13.360 --> 00:04:15.720
Internally, we dog food,

00:04:15.720 --> 00:04:17.360
new features, new concepts,

00:04:17.360 --> 00:04:18.880
and we work with the product team,

00:04:18.880 --> 00:04:21.320
the engineering team to say, "Hey, this makes sense.

00:04:21.320 --> 00:04:23.600
This doesn't, this works really well, that doesn't."

00:04:23.600 --> 00:04:28.880
That feedback loop is so fast and so iterative that for me personally,

00:04:28.880 --> 00:04:31.040
being able to see that come to fruition,

00:04:31.040 --> 00:04:32.680
it's really, really compelling.

00:04:32.680 --> 00:04:37.120
But at the same time, I get to work at a place that's building a tool for me.

00:04:37.120 --> 00:04:39.160
You don't often get that luxury.

00:04:39.160 --> 00:04:40.760
I've worked in ads,

00:04:40.760 --> 00:04:42.600
I've worked in insurance,

00:04:42.600 --> 00:04:45.080
it's like banking, it's like these are nice things,

00:04:45.080 --> 00:04:47.440
but it's not built for me.

00:04:47.440 --> 00:04:50.440
For me, that's probably been the biggest benefit, I would say.

00:04:50.440 --> 00:04:52.800
>> If you work in some marketing thing,

00:04:52.800 --> 00:04:55.760
you're like, "I retargeted myself so well today.

00:04:55.760 --> 00:04:58.880
You wouldn't believe it. I really enjoyed it."

00:04:58.880 --> 00:05:01.440
>> I've seen ads that I've created before.

00:05:01.440 --> 00:05:04.400
It's a little fun, but it's not the same.

00:05:04.400 --> 00:05:07.360
>> Yeah. I've heard of people who are really,

00:05:07.360 --> 00:05:11.720
really good at ad targeting and finding groups where

00:05:11.720 --> 00:05:15.440
they prank their wife or something or just had

00:05:15.440 --> 00:05:18.080
an ad that would only show up for their wife by running.

00:05:18.080 --> 00:05:21.560
It was so specific and freaked them out a little bit.

00:05:21.560 --> 00:05:24.000
>> Yeah, that's pretty clever.

00:05:24.000 --> 00:05:27.880
>> Yeah, maybe it wasn't appreciated, but it is clever.

00:05:27.880 --> 00:05:31.200
>> Who knows? All right.

00:05:31.200 --> 00:05:34.200
Well, before we jump in,

00:05:34.200 --> 00:05:39.240
you said that of course you built GUIs with PyGUI and those things

00:05:39.240 --> 00:05:43.120
because people don't speak Python back then,

00:05:43.120 --> 00:05:46.280
two, seven days and whatever. Is that different now?

00:05:46.280 --> 00:05:47.960
Not that people speak Python,

00:05:47.960 --> 00:05:49.640
but is it different in the sense that like, "Hey,

00:05:49.640 --> 00:05:53.080
I could give them a Jupyter Notebook or I could give

00:05:53.080 --> 00:05:56.920
them Streamlit or one of these things."

00:05:56.920 --> 00:06:00.520
A little more or less you build in and just plug it in?

00:06:00.520 --> 00:06:03.400
>> I think so. Like you said,

00:06:03.400 --> 00:06:05.360
it's not different in that most people

00:06:05.360 --> 00:06:07.600
probably still to this day don't speak Python.

00:06:07.600 --> 00:06:08.560
>> Yeah.

00:06:08.560 --> 00:06:11.360
>> I know we had this movement a little bit back where

00:06:11.360 --> 00:06:13.080
everyone was going to learn SQL

00:06:13.080 --> 00:06:14.960
and everyone was going to learn to code.

00:06:14.960 --> 00:06:19.840
I was never that bullish on that trend because if I'm a marketing person,

00:06:19.840 --> 00:06:21.840
I've got 10,000 things to do and

00:06:21.840 --> 00:06:25.040
learning to code isn't going to be the priority ever.

00:06:25.040 --> 00:06:28.080
I think building interfaces for people that are easy to

00:06:28.080 --> 00:06:31.800
use and speaks well to them is always useful.

00:06:31.800 --> 00:06:33.560
That never has gone away.

00:06:33.560 --> 00:06:36.080
But I think the tooling around it has been better.

00:06:36.080 --> 00:06:38.160
I don't think I'll ever want to use PyGUI again,

00:06:38.160 --> 00:06:39.240
nothing wrong with the platform,

00:06:39.240 --> 00:06:41.320
it's just not fun to write.

00:06:41.320 --> 00:06:44.240
Streamlit makes it so easy to do that.

00:06:44.240 --> 00:06:48.080
It's something like retool and there's like a thousand other ways now that you

00:06:48.080 --> 00:06:50.440
can bring these tools in front of your stakeholders and

00:06:50.440 --> 00:06:53.120
your users that just wasn't possible before.

00:06:53.120 --> 00:06:54.840
>> I think it's a pretty exciting time.

00:06:54.840 --> 00:06:57.840
There are a lot of pretty polished tools.

00:06:57.840 --> 00:06:59.960
>> Yeah, it's gotten so good.

00:06:59.960 --> 00:07:03.680
>> Yeah. There's some interesting ones like OpenBB,

00:07:03.680 --> 00:07:07.000
do you know that? The financial dashboard thing.

00:07:07.000 --> 00:07:08.840
>> I've heard of this, I haven't seen it.

00:07:08.840 --> 00:07:11.400
>> Yeah, it's basically for traders,

00:07:11.400 --> 00:07:16.200
but it's like a terminal type thing that has a bunch of

00:07:16.200 --> 00:07:21.480
Matplotlib and other interactive stuff that pops up compared to say,

00:07:21.480 --> 00:07:24.200
Bloomberg dashboard type things.

00:07:24.200 --> 00:07:30.240
But yeah, that's one sense where maybe traders go and learn Python because it's like,

00:07:30.240 --> 00:07:31.920
all right, there's enough value here.

00:07:31.920 --> 00:07:34.160
But in general, I don't think people are

00:07:34.160 --> 00:07:36.800
going to stop what they're doing and learning the code.

00:07:36.800 --> 00:07:39.680
So these new UI things are not.

00:07:39.680 --> 00:07:42.680
All right, let's dive in and talk about

00:07:42.680 --> 00:07:49.360
this general category first of data pipelines,

00:07:49.360 --> 00:07:51.960
data orchestration, all those things.

00:07:51.960 --> 00:07:55.520
We'll talk about Dagster and some of the trends and that.

00:07:55.520 --> 00:08:02.760
So I just grabbed some random Internet search for what does a data pipeline maybe look like?

00:08:02.760 --> 00:08:07.000
But people out there listening who don't necessarily live in that space,

00:08:07.000 --> 00:08:09.920
which I think is honestly many of us,

00:08:09.920 --> 00:08:11.960
maybe we should, but maybe in our minds,

00:08:11.960 --> 00:08:14.360
we don't think we live in data pipeline land.

00:08:14.360 --> 00:08:15.880
Tell them about it.

00:08:15.880 --> 00:08:21.440
>> Yeah, for sure. It is hard to think about if you haven't done or built one before.

00:08:21.440 --> 00:08:23.920
But in many ways,

00:08:23.920 --> 00:08:28.760
a data pipeline is just a series of steps that you apply to some dataset that you

00:08:28.760 --> 00:08:34.960
have in order to transform it to something a little bit more valuable at the very end.

00:08:34.960 --> 00:08:37.280
That's a simplified version.

00:08:37.280 --> 00:08:39.000
The devil's in the details,

00:08:39.000 --> 00:08:41.600
but really at the end of the day,

00:08:41.600 --> 00:08:42.680
you're in a business,

00:08:42.680 --> 00:08:46.600
the production of data happens by the very nature of operating that business.

00:08:46.600 --> 00:08:51.400
It tends to be the core thing that all businesses have in common.

00:08:51.400 --> 00:08:54.480
Then the other output is you have people within

00:08:54.480 --> 00:08:57.880
a business who are trying to understand how the business is operating.

00:08:57.880 --> 00:09:03.000
This used to be easy when all we had was a single spreadsheet that we could look at once a month.

00:09:03.000 --> 00:09:07.200
I think businesses have gone a little bit more complex than these days.

00:09:07.200 --> 00:09:08.200
>> Computers.

00:09:08.200 --> 00:09:11.920
>> The expectations, they expect to be able to see almost real-time,

00:09:11.920 --> 00:09:13.920
not I'll see it at the end of the month.

00:09:13.920 --> 00:09:14.600
>> That's right.

00:09:14.600 --> 00:09:15.120
>> That's right.

00:09:15.120 --> 00:09:15.840
>> Yeah.

00:09:15.840 --> 00:09:18.160
>> I think people have gotten used to getting data too,

00:09:18.160 --> 00:09:20.600
which is both good and bad.

00:09:20.600 --> 00:09:23.080
Good in the sense that now people are making better decisions,

00:09:23.080 --> 00:09:26.160
bad and then there's more work for us to do and we can't just sit on our feet

00:09:26.160 --> 00:09:28.640
for half a day, half a month,

00:09:28.640 --> 00:09:30.440
waiting for the next request to come in.

00:09:30.440 --> 00:09:34.320
There's just an endless stream that seems to never end.

00:09:34.320 --> 00:09:36.360
That's what really a pipeline is all about.

00:09:36.360 --> 00:09:41.360
It's like taking these data and making it consumable in a way that users,

00:09:41.360 --> 00:09:45.180
tools will understand that helps people make decisions at the very end of the day.

00:09:45.180 --> 00:09:47.480
That's the nuts and bolts of it.

00:09:47.480 --> 00:09:52.960
>> In your mind, does data acquisition live in this land?

00:09:52.960 --> 00:09:57.960
For example, maybe we have a scheduled job that goes and does web scraping,

00:09:57.960 --> 00:10:00.280
calls an API once an hour,

00:10:00.280 --> 00:10:04.000
and that might kick off a whole pipeline of processing,

00:10:04.000 --> 00:10:14.520
or we watch a folder for people to upload over FTP,

00:10:14.520 --> 00:10:16.920
like a CSV file or something horrible like that.

00:10:16.920 --> 00:10:18.600
You don't even want to speak, it's unspeakable.

00:10:18.600 --> 00:10:20.120
But something like that where you say,

00:10:20.120 --> 00:10:23.320
"Oh, a new CSV has arrived for me to get."

00:10:23.320 --> 00:10:29.080
>> Yeah, I think that's the beginning of all data pipeline journeys in my mind.

00:10:29.080 --> 00:10:33.680
Very much. An FTP, as much as we hate it, it's not terrible.

00:10:33.680 --> 00:10:37.880
I mean, there are worse ways to transfer files.

00:10:37.880 --> 00:10:43.240
But it's I think still very much in use today.

00:10:43.240 --> 00:10:46.320
Every data pipeline journey at some point has to

00:10:46.320 --> 00:10:49.720
begin with that consumption of data from somewhere.

00:10:49.720 --> 00:10:52.520
>> Yeah. Hopefully, it's SFTP,

00:10:52.520 --> 00:10:55.200
not just straight FTP, like the encrypted.

00:10:55.200 --> 00:10:58.680
Don't just send your password in the plain text.

00:10:58.680 --> 00:11:01.960
Well, I've seen that go wrong.

00:11:01.960 --> 00:11:05.120
That's a story for another day, honestly.

00:11:05.120 --> 00:11:09.120
Well, let's talk about the project that you work on.

00:11:09.120 --> 00:11:11.600
We've been talking about it in general,

00:11:11.600 --> 00:11:14.280
but let's talk about Dijkstra.

00:11:14.280 --> 00:11:17.240
Where does it fit in this world?

00:11:17.240 --> 00:11:22.920
>> Yes. Dijkstra to me is a way to build a data platform.

00:11:22.920 --> 00:11:25.120
It's also a different way of

00:11:25.120 --> 00:11:27.920
thinking about how you build data pipelines.

00:11:27.920 --> 00:11:31.600
Maybe it's good to compare it with what the world was like,

00:11:31.600 --> 00:11:35.840
I think before Dijkstra and how it came about to be.

00:11:35.840 --> 00:11:37.840
If you think of Airflow,

00:11:37.840 --> 00:11:41.360
I think it's probably the most canonical orchestrator out there.

00:11:41.360 --> 00:11:43.840
But there are other ways which people

00:11:43.840 --> 00:11:46.160
used to orchestrate these data pipelines.

00:11:46.160 --> 00:11:48.280
They were often task-based.

00:11:48.280 --> 00:11:50.640
I would download file,

00:11:50.640 --> 00:11:52.040
I would unzip file,

00:11:52.040 --> 00:11:53.360
I would upload file.

00:11:53.360 --> 00:11:56.280
These are the words we use to describe

00:11:56.280 --> 00:11:59.560
the various steps within a pipeline.

00:11:59.560 --> 00:12:01.200
>> Some of those little steps might be

00:12:01.200 --> 00:12:03.000
Python functions that you write,

00:12:03.000 --> 00:12:05.280
maybe there's some pre-built other ones.

00:12:05.280 --> 00:12:07.400
>> Yeah. They might be Python,

00:12:07.400 --> 00:12:08.840
could be a batch script,

00:12:08.840 --> 00:12:11.680
could be logging into a server and downloading a file,

00:12:11.680 --> 00:12:13.400
could be hitting request to

00:12:13.400 --> 00:12:15.720
download something from the Internet, unzipping it.

00:12:15.720 --> 00:12:18.800
Just a various hodgepodge of commands that would run.

00:12:18.800 --> 00:12:21.480
That's typically how we thought about it.

00:12:21.480 --> 00:12:24.240
For more complex scenarios where your data is bigger,

00:12:24.240 --> 00:12:27.600
maybe it's running against a Hadoop cluster or a Spark cluster.

00:12:27.600 --> 00:12:29.800
The compute's been offloaded somewhere else.

00:12:29.800 --> 00:12:31.800
But the conceptual way you

00:12:31.800 --> 00:12:34.720
tended to think about these things is in terms of tasks.

00:12:34.720 --> 00:12:38.360
Process this thing, do this massive data dump,

00:12:38.360 --> 00:12:39.840
run a bunch of things,

00:12:39.840 --> 00:12:43.080
and then your job is complete.

00:12:43.080 --> 00:12:49.000
With Dagster, we flip it around a little bit on our heads and we say,

00:12:49.000 --> 00:12:50.960
instead of thinking about tasks,

00:12:50.960 --> 00:12:53.360
what if we flipped that around and thought about

00:12:53.360 --> 00:12:56.200
the actual underlying assets that you're creating?

00:12:56.200 --> 00:12:59.920
What if you told us not the steps that you're going to take,

00:12:59.920 --> 00:13:01.720
but the thing that you produce?

00:13:01.720 --> 00:13:05.440
Because it turns out as people and as data people and stakeholders,

00:13:05.440 --> 00:13:08.240
really, we don't care about the task.

00:13:08.240 --> 00:13:10.120
We just assume that you're going to do it.

00:13:10.120 --> 00:13:12.400
What we care about is that table,

00:13:12.400 --> 00:13:14.080
that model, that file,

00:13:14.080 --> 00:13:16.120
that Jupyter Notebook.

00:13:16.120 --> 00:13:19.640
If we model our pipeline through that,

00:13:19.640 --> 00:13:21.440
then we get a whole bunch of other benefits.

00:13:21.440 --> 00:13:24.720
That's the Dagster's pitch.

00:13:24.720 --> 00:13:27.240
If you want to understand

00:13:27.240 --> 00:13:29.560
the things that are being produced by these tasks,

00:13:29.560 --> 00:13:31.840
tell us about the underlying assets.

00:13:31.840 --> 00:13:34.440
Then when a stakeholder says and comes to you and says,

00:13:34.440 --> 00:13:36.360
how old is this table?

00:13:36.360 --> 00:13:37.800
Has it been refreshed lately?

00:13:37.800 --> 00:13:39.800
Well, you don't have to go look at a specific task.

00:13:39.800 --> 00:13:43.360
Remember that task ABC had model XYZ.

00:13:43.360 --> 00:13:47.040
You just go and look up model XYZ directly there and it's there for you.

00:13:47.040 --> 00:13:49.040
Because you've defined things in this way,

00:13:49.040 --> 00:13:51.480
you get other nice things like a lineage graph.

00:13:51.480 --> 00:13:55.560
You get to understand how fresh your data is.

00:13:55.560 --> 00:13:57.680
You can do event-based orchestration and all kinds of

00:13:57.680 --> 00:14:01.000
nice things that are a lot harder to do in a task world.

00:14:01.000 --> 00:14:05.880
>> More declarative, less imperative, I suppose.

00:14:05.880 --> 00:14:07.600
>> Yeah. It's been the trend.

00:14:07.600 --> 00:14:09.640
I think in lots of tooling,

00:14:09.640 --> 00:14:13.840
React, I think was famous for this as well in many ways.

00:14:13.840 --> 00:14:15.960
It was a hard framework, I think,

00:14:15.960 --> 00:14:18.960
for people to get their heads around initially,

00:14:18.960 --> 00:14:24.400
because we were so used to the jQuery style of doing things.

00:14:24.400 --> 00:14:27.280
>> Yeah. How do I hook the event that makes the thing happen?

00:14:27.280 --> 00:14:30.000
>> React said, let's think about it a little bit differently.

00:14:30.000 --> 00:14:32.680
Let's do this event-based orchestration.

00:14:32.680 --> 00:14:36.000
I think the proofs in the pudding reacts

00:14:36.000 --> 00:14:38.600
everywhere now and jQuery maybe not so much.

00:14:38.600 --> 00:14:41.760
>> Yeah. There's still a lot of jQuery out there,

00:14:41.760 --> 00:14:44.960
but there's not a lot of active jQuery.

00:14:44.960 --> 00:14:46.840
But I imagine there's some.

00:14:46.840 --> 00:14:48.000
>> There is.

00:14:48.000 --> 00:14:49.800
>> Yeah. Just because people like,

00:14:49.800 --> 00:14:51.680
you know what, don't touch that, that works.

00:14:51.680 --> 00:14:53.880
>> Which is probably the smartest thing people can do,

00:14:53.880 --> 00:14:54.800
I think, a lot of times.

00:14:54.800 --> 00:14:57.960
>> Yeah. Honestly. Even though new frameworks are shiny.

00:14:57.960 --> 00:15:02.600
If there's any ecosystem that loves to chase the shiny new idea,

00:15:02.600 --> 00:15:04.680
it's the JavaScript web world.

00:15:04.680 --> 00:15:07.960
>> Yeah. There's no shortage of new frameworks coming out every time.

00:15:07.960 --> 00:15:09.440
>> I mean, we do too,

00:15:09.440 --> 00:15:12.600
but not as much as like, that's six months old.

00:15:12.600 --> 00:15:14.720
That's so old, we can't possibly do that anymore.

00:15:14.720 --> 00:15:17.440
We're rewriting it. We're going to do the big rewrite again.

00:15:17.440 --> 00:15:17.880
>> Yeah.

00:15:17.880 --> 00:15:23.360
>> Fine. So Dagster is the company,

00:15:23.360 --> 00:15:25.000
but also is open source.

00:15:25.000 --> 00:15:27.520
What's the story around,

00:15:27.520 --> 00:15:30.160
can I use it for free? Is it open source? Do I pay for it?

00:15:30.160 --> 00:15:30.840
>> I understand.

00:15:30.840 --> 00:15:31.360
>> Okay.

00:15:31.360 --> 00:15:33.200
>> So Dagster Labs is the company,

00:15:33.200 --> 00:15:36.000
Dagster open source is the product.

00:15:36.000 --> 00:15:37.440
It's 100 percent free.

00:15:37.440 --> 00:15:40.520
We're very committed to the open source model.

00:15:40.520 --> 00:15:44.200
I would say 95 percent of the things you can get out of

00:15:44.200 --> 00:15:46.600
Dagster are available through open source,

00:15:46.600 --> 00:15:49.760
and we tend to try to release everything through that model.

00:15:49.760 --> 00:15:53.280
You can run very complex pipelines,

00:15:53.280 --> 00:15:56.000
and you can deploy it all on your own if you wish.

00:15:56.000 --> 00:15:57.520
There is a Dagster Cloud product,

00:15:57.520 --> 00:16:00.200
which is really the hosted version of Dagster.

00:16:00.200 --> 00:16:02.640
If you want a hosted plane,

00:16:02.640 --> 00:16:04.400
we can do that for you through Dagster Cloud.

00:16:04.400 --> 00:16:06.400
But it all runs on the same code base,

00:16:06.400 --> 00:16:09.800
and the modeling and the files all essentially look the same.

00:16:09.800 --> 00:16:13.600
>> Okay. So obviously, you could get,

00:16:13.600 --> 00:16:14.920
like I talked about at the beginning,

00:16:14.920 --> 00:16:16.800
you could go down the DevOps side,

00:16:16.800 --> 00:16:19.880
get your own open source Dagster setup,

00:16:19.880 --> 00:16:22.960
schedule it, run it on servers, all those things.

00:16:22.960 --> 00:16:25.760
But if we just wanted something real simple,

00:16:25.760 --> 00:16:28.480
we could just go to you guys and say,

00:16:28.480 --> 00:16:30.240
"Hey, I built this with Dagster.

00:16:30.240 --> 00:16:31.800
Will you run it for me?"

00:16:31.800 --> 00:16:34.400
>> Pretty much, yeah. So there's two options there.

00:16:34.400 --> 00:16:36.440
You can do the serverless model,

00:16:36.440 --> 00:16:38.560
which says, "Dagster, just run it.

00:16:38.560 --> 00:16:39.880
We take care of the compute,

00:16:39.880 --> 00:16:41.280
we take care of the execution for you,

00:16:41.280 --> 00:16:44.520
and you just write the code and upload it to GitHub

00:16:44.520 --> 00:16:47.920
or any repository of your choice,

00:16:47.920 --> 00:16:49.840
and we'll sync to that and then run it."

00:16:49.840 --> 00:16:52.080
The other option is to do a hybrid model.

00:16:52.080 --> 00:16:55.720
>> Sorry. So you basically do the CI/CD aspect.

00:16:55.720 --> 00:16:59.080
You just say, you push to name your branch.

00:16:59.080 --> 00:17:01.080
If you push that branch, that means we're just going to

00:17:01.080 --> 00:17:04.280
deploy a new version and whatever happens after that,

00:17:04.280 --> 00:17:06.080
it'll be in production, right?

00:17:06.080 --> 00:17:09.480
>> Exactly, yeah. We offer some templates that you can use in

00:17:09.480 --> 00:17:12.880
GitHub for workflows in order to accommodate that.

00:17:12.880 --> 00:17:15.000
>> Excellent. Then I cut you off,

00:17:15.000 --> 00:17:16.520
you're saying something about hybrid.

00:17:16.520 --> 00:17:18.200
>> Hybrid is the other option.

00:17:18.200 --> 00:17:20.200
For those of you who want to run your own compute,

00:17:20.200 --> 00:17:22.280
you don't want the data leaving your ecosystem,

00:17:22.280 --> 00:17:25.160
you can say, "We've got this Kubernetes cluster,

00:17:25.160 --> 00:17:27.400
this ECS cluster, but we still want to use

00:17:27.400 --> 00:17:30.560
the Dagster Cloud product to manage the control plane.

00:17:30.560 --> 00:17:32.960
Dagster Cloud will do that, and then you can go off and

00:17:32.960 --> 00:17:34.880
execute things on your own environment

00:17:34.880 --> 00:17:36.240
if that's something you wish to do.

00:17:36.240 --> 00:17:38.680
>> Oh, yeah. That's pretty clever because

00:17:38.680 --> 00:17:40.880
running stuff in containers isn't too bad,

00:17:40.880 --> 00:17:43.080
but running container clusters,

00:17:43.080 --> 00:17:46.760
all of a sudden, you're back doing a lot of work, right?

00:17:46.760 --> 00:17:47.840
>> Exactly, yeah.

00:17:47.840 --> 00:17:50.560
>> Yeah. Well, let's maybe talk

00:17:50.560 --> 00:17:53.440
about Dagster for a bit,

00:17:53.440 --> 00:17:55.880
then I want to talk about some of the trends as well.

00:17:55.880 --> 00:18:00.760
But let's just talk through maybe setting up a pipeline.

00:18:00.760 --> 00:18:02.280
What does it look like?

00:18:02.280 --> 00:18:03.760
You talked about in general,

00:18:03.760 --> 00:18:05.400
less imperative, more declarative,

00:18:05.400 --> 00:18:07.600
but what does it look like?

00:18:07.600 --> 00:18:09.960
Be careful about talking about code on audio,

00:18:09.960 --> 00:18:12.440
but give us a sense of what

00:18:12.440 --> 00:18:14.920
the programming model feels like for us.

00:18:14.920 --> 00:18:16.640
>> As much as possible,

00:18:16.640 --> 00:18:18.760
it really feels like just writing Python.

00:18:18.760 --> 00:18:21.040
It's pretty easy.

00:18:21.040 --> 00:18:22.680
You add a decorator on top

00:18:22.680 --> 00:18:25.960
of your existing Python function that does something.

00:18:25.960 --> 00:18:28.720
That's a simple decorator called asset,

00:18:28.720 --> 00:18:30.680
and then your pipeline,

00:18:30.680 --> 00:18:32.520
that function becomes a data asset.

00:18:32.520 --> 00:18:35.200
That's how it's represented in the Dagster UI.

00:18:35.200 --> 00:18:38.600
You could imagine you've got a pipeline

00:18:38.600 --> 00:18:42.560
that gets maybe Slack analytics

00:18:42.560 --> 00:18:45.240
and uploads that to some dashboard.

00:18:45.240 --> 00:18:47.480
Your first pipeline, your function

00:18:47.480 --> 00:18:49.480
will be called something like Slack data,

00:18:49.480 --> 00:18:51.200
and that would be your asset.

00:18:51.200 --> 00:18:54.360
In that function is where you do all the transform,

00:18:54.360 --> 00:18:55.640
the downloading of the data,

00:18:55.640 --> 00:18:57.040
until you've really created

00:18:57.040 --> 00:18:59.440
that fundamental data asset that you care about.

00:18:59.440 --> 00:19:03.040
That could be stored either in a data warehouse,

00:19:03.040 --> 00:19:05.280
two or three, however you want to persist it,

00:19:05.280 --> 00:19:06.640
that's really up to you.

00:19:06.640 --> 00:19:09.280
Then the resources is where

00:19:09.280 --> 00:19:11.920
the power I think of a lot of Dagster comes in.

00:19:11.920 --> 00:19:15.480
The asset is declaration of the thing I'm going to create.

00:19:15.480 --> 00:19:19.480
The resource is how I'm going to operate on that.

00:19:19.480 --> 00:19:23.200
Because sometimes you might want to have a,

00:19:23.200 --> 00:19:25.560
let's say a DuckDB instance locally

00:19:25.560 --> 00:19:27.760
because it's easier and faster to operate.

00:19:27.760 --> 00:19:29.000
But when you're moving to the Cloud,

00:19:29.000 --> 00:19:32.720
you want to have a Databricks or a Snowflake.

00:19:32.720 --> 00:19:35.560
You can swap out resources based on environments,

00:19:35.560 --> 00:19:38.480
and your asset can reference that resource.

00:19:38.480 --> 00:19:40.960
And as long as it has that same API,

00:19:40.960 --> 00:19:43.720
you can really flexibly change

00:19:43.720 --> 00:19:46.680
between where that data is going to be persistent.

00:19:46.680 --> 00:19:49.960
- Does Dagster know how to talk to those different platforms?

00:19:49.960 --> 00:19:53.520
Does it natively understand DuckDB and Snowflake?

00:19:53.520 --> 00:19:56.280
- Yeah, so it's interesting.

00:19:56.280 --> 00:19:57.880
People often look to Dagster and like,

00:19:57.880 --> 00:19:59.480
"Oh, does it do X?"

00:19:59.480 --> 00:20:00.920
And the question is like,

00:20:00.920 --> 00:20:04.480
Dagster does anything you can do Python with.

00:20:04.480 --> 00:20:05.480
- Most things, yeah.

00:20:05.480 --> 00:20:06.320
- Which is most things.

00:20:06.320 --> 00:20:08.640
So I think if you come from the Airflow world,

00:20:08.640 --> 00:20:10.920
you're very much used to like these Airflow providers.

00:20:10.920 --> 00:20:11.760
And if you want to use-

00:20:11.760 --> 00:20:12.960
- That's kind of what I was thinking, yeah.

00:20:12.960 --> 00:20:14.480
- Yeah, you want to use a Postgres,

00:20:14.480 --> 00:20:15.880
you need to find the Postgres provider.

00:20:15.880 --> 00:20:18.800
You want to use S3, you need to find S3 provider.

00:20:18.800 --> 00:20:20.480
With Dagster, you kind of say,

00:20:20.480 --> 00:20:22.360
you don't have to do any of that.

00:20:22.360 --> 00:20:24.480
If you want to use Snowflake, for example,

00:20:24.480 --> 00:20:28.240
you install the Snowflake connector package from Snowflake,

00:20:28.240 --> 00:20:30.360
and you use that as a resource directly.

00:20:30.360 --> 00:20:33.880
And then you just run your SQL that way.

00:20:33.880 --> 00:20:36.400
There are some places where we do have integrations

00:20:36.400 --> 00:20:38.640
that help if you want to get into the weeds

00:20:38.640 --> 00:20:39.480
with I/O manager,

00:20:39.480 --> 00:20:42.440
it's where we persist the data on your behalf.

00:20:42.440 --> 00:20:45.720
And so for S3, for Snowflake, for example,

00:20:45.720 --> 00:20:49.360
there's other ways where we can persist that data for you.

00:20:49.360 --> 00:20:51.240
But if you're just trying to run a query,

00:20:51.240 --> 00:20:52.760
just trying to execute something,

00:20:52.760 --> 00:20:54.480
just trying to save something somewhere,

00:20:54.480 --> 00:20:56.280
you don't have to use that system at all.

00:20:56.280 --> 00:20:59.680
You can just use whatever Python package

00:20:59.680 --> 00:21:01.360
you would use anyway to do that.

00:21:01.360 --> 00:21:05.320
- So maybe some data is expensive

00:21:05.320 --> 00:21:08.120
for us to get as a company,

00:21:08.120 --> 00:21:10.400
like maybe we're charged on a usage basis

00:21:10.400 --> 00:21:12.640
or super slow or something.

00:21:12.640 --> 00:21:14.960
I could write just Python code that goes and say,

00:21:14.960 --> 00:21:17.440
well, look in my local database.

00:21:17.440 --> 00:21:19.480
If it's already there, use that and it's not too stale.

00:21:19.480 --> 00:21:21.600
Otherwise, then do actually go get it,

00:21:21.600 --> 00:21:25.400
put it there and then get it back.

00:21:25.400 --> 00:21:29.880
And like that kind of stuff would be up to me to put together.

00:21:29.880 --> 00:21:31.160
- Yeah, and that's the nice thing

00:21:31.160 --> 00:21:35.200
is you're not really limited by like anyone's data model

00:21:35.200 --> 00:21:38.400
or world view on how data should be retrieved

00:21:38.400 --> 00:21:40.440
or saved or augmented.

00:21:40.440 --> 00:21:41.400
You could do it a couple of ways.

00:21:41.400 --> 00:21:43.600
You could say, whenever I'm working locally,

00:21:44.640 --> 00:21:47.680
use this persistent data store

00:21:47.680 --> 00:21:50.880
that we're just gonna use for development purposes.

00:21:50.880 --> 00:21:53.480
- A fancy database called SQLite, something like that.

00:21:53.480 --> 00:21:55.960
- Exactly, yes, a wonderful database.

00:21:55.960 --> 00:21:57.280
- Actually, it's yeah.

00:21:57.280 --> 00:21:58.640
- It'll work really, really well.

00:21:58.640 --> 00:22:01.440
And then you just say, when I'm in a different environment,

00:22:01.440 --> 00:22:04.120
when I'm in production, swap out my SQLite resource

00:22:04.120 --> 00:22:08.560
for a, name your favorite cloud warehouse resource

00:22:08.560 --> 00:22:10.760
and go fetch that data from there.

00:22:10.760 --> 00:22:12.960
Or I wanna use a mini IO locally.

00:22:12.960 --> 00:22:15.640
I wanna use S3 on prod.

00:22:15.640 --> 00:22:18.040
It's very simple to swap these things out.

00:22:18.040 --> 00:22:23.040
- Okay, yeah, so it looks like you build up these assets

00:22:23.040 --> 00:22:26.800
as y'all call them, these pieces of data,

00:22:26.800 --> 00:22:28.560
Python code that accesses them.

00:22:28.560 --> 00:22:31.920
And then you have a nice UI that lets you go

00:22:31.920 --> 00:22:34.960
and build those out kind of workflow style, right?

00:22:34.960 --> 00:22:36.840
- Yeah, exactly.

00:22:36.840 --> 00:22:39.480
This is where we get into the wonderful world of DAGs,

00:22:40.440 --> 00:22:45.320
which stands for directed acyclic graph, I think.

00:22:45.320 --> 00:22:47.120
It stands for a bunch of things

00:22:47.120 --> 00:22:48.480
that are not connected in a circle,

00:22:48.480 --> 00:22:49.760
but are connected in some way.

00:22:49.760 --> 00:22:51.440
So there can't be any loops, right?

00:22:51.440 --> 00:22:53.800
'Cause then you never know where to start or where to end.

00:22:53.800 --> 00:22:56.760
- Could be a diamond, but not a circle, right?

00:22:56.760 --> 00:22:57.600
- Not a circle.

00:22:57.600 --> 00:23:01.600
As long as there's like a path through this dataset

00:23:01.600 --> 00:23:03.280
where the beginning and an end,

00:23:03.280 --> 00:23:05.560
then we can kind of start to model

00:23:05.560 --> 00:23:09.400
this connected graph of things.

00:23:09.400 --> 00:23:10.640
And then we know how to execute them, right?

00:23:10.640 --> 00:23:13.160
We can say, well, this is the first thing we have to run

00:23:13.160 --> 00:23:15.040
'cause that's where all dependencies start.

00:23:15.040 --> 00:23:16.880
And then we can either branch off in parallel

00:23:16.880 --> 00:23:20.160
or we can continue linearly until everything is complete.

00:23:20.160 --> 00:23:21.600
And if something breaks in the middle,

00:23:21.600 --> 00:23:23.480
we can resume from that broken spot.

00:23:23.480 --> 00:23:26.840
- Okay, excellent.

00:23:26.840 --> 00:23:29.320
And is that the recommended way?

00:23:29.320 --> 00:23:31.360
Like if I write all this Python code

00:23:31.360 --> 00:23:32.360
that works on the pieces,

00:23:32.360 --> 00:23:36.080
then the next recommendation would be to fire up the UI

00:23:36.080 --> 00:23:36.920
and start building it?

00:23:36.920 --> 00:23:39.360
Or do you say, ah, you should really write it in code

00:23:39.360 --> 00:23:41.840
and then you can just visualize it or monitor it?

00:23:41.840 --> 00:23:45.040
- Everything in Dagster is written as code.

00:23:45.040 --> 00:23:49.120
The UI reads that code and it interprets it as a DAG

00:23:49.120 --> 00:23:51.240
and then it displays that for you.

00:23:51.240 --> 00:23:52.560
There are some things you do with the UI,

00:23:52.560 --> 00:23:55.640
like you can materialize assets, you can make them run,

00:23:55.640 --> 00:23:58.760
you can do backfills, you can view metadata,

00:23:58.760 --> 00:24:01.760
you can sort of enable and disable schedules.

00:24:01.760 --> 00:24:03.680
But the core, we really believe this is Dagster,

00:24:03.680 --> 00:24:06.640
like the core declaration of how things are done,

00:24:06.640 --> 00:24:08.680
it's always done through code.

00:24:08.680 --> 00:24:10.320
- Okay, excellent.

00:24:10.320 --> 00:24:13.760
So when you say materialize, maybe I have an asset,

00:24:13.760 --> 00:24:15.640
which is really a Python function I wrote

00:24:15.640 --> 00:24:18.600
that goes and pulls down a CSV file.

00:24:18.600 --> 00:24:20.080
The materialize would be,

00:24:20.080 --> 00:24:24.440
I wanna see kind of representative data in this, in the UI.

00:24:24.440 --> 00:24:26.720
And so I could go, all right, I think this is right,

00:24:26.720 --> 00:24:28.440
let's keep passing it down.

00:24:28.440 --> 00:24:30.080
Is that what that means?

00:24:30.080 --> 00:24:32.520
- Materialize really means just run this particular asset,

00:24:32.520 --> 00:24:35.760
make this asset new again, fresh again, right?

00:24:37.040 --> 00:24:38.680
As part of that materialization,

00:24:38.680 --> 00:24:40.400
we sometimes output metadata

00:24:40.400 --> 00:24:41.640
and you can kind of see this on the right,

00:24:41.640 --> 00:24:43.440
if you're looking at the screen here,

00:24:43.440 --> 00:24:47.960
where we talk about what the timestamp was, the URL,

00:24:47.960 --> 00:24:51.640
there's a nice little graph of like number of rows over time.

00:24:51.640 --> 00:24:54.200
All that metadata is something you can emit

00:24:54.200 --> 00:24:58.000
and we emit some ourselves by default with the framework.

00:24:58.000 --> 00:24:59.560
And then as you materialize these assets,

00:24:59.560 --> 00:25:01.960
as you run that asset over and over again, over time,

00:25:01.960 --> 00:25:04.360
we capture all that and then you can really get

00:25:04.360 --> 00:25:07.880
a nice overview of this assets lifetime, essentially.

00:25:07.880 --> 00:25:10.640
- Nice.

00:25:10.640 --> 00:25:14.560
I think the metadata is really pretty excellent, right?

00:25:14.560 --> 00:25:18.160
Over time, you can see how the data's grown and changed.

00:25:18.160 --> 00:25:21.840
- Yeah, the metadata is really powerful

00:25:21.840 --> 00:25:23.920
and it's one of the nice benefits

00:25:23.920 --> 00:25:25.640
of being in this asset world, right?

00:25:25.640 --> 00:25:27.720
Because you don't really wanna metadata

00:25:27.720 --> 00:25:29.200
on like this task that run,

00:25:29.200 --> 00:25:32.400
you wanna know like this table that I created,

00:25:32.400 --> 00:25:35.560
how many rows has it had every single time it's run?

00:25:35.560 --> 00:25:38.040
And then that number drops by like 50%,

00:25:38.040 --> 00:25:39.400
that's a big problem.

00:25:39.400 --> 00:25:41.920
Conversely, if the runtime is slowly increasing

00:25:41.920 --> 00:25:43.920
every single day, you might not notice it,

00:25:43.920 --> 00:25:45.160
but over a month or two,

00:25:45.160 --> 00:25:49.040
it went from a 30 second pipeline to 30 minutes,

00:25:49.040 --> 00:25:51.400
maybe there's like a great place to start optimizing

00:25:51.400 --> 00:25:53.240
that one specific asset.

00:25:53.240 --> 00:25:56.000
- Right, and what's cool, if it's just Python code,

00:25:56.000 --> 00:25:59.880
well, you know how to optimize that probably, right?

00:25:59.880 --> 00:26:00.760
- Hopefully, yeah.

00:26:01.800 --> 00:26:03.560
- Well, as much as you're gonna, yeah,

00:26:03.560 --> 00:26:06.040
you have all the power of Python

00:26:06.040 --> 00:26:08.160
and you should be able to,

00:26:08.160 --> 00:26:10.480
as opposed to it's deep down inside some framework

00:26:10.480 --> 00:26:11.800
that you don't really-- - Exactly.

00:26:11.800 --> 00:26:12.840
- Yeah. - You use Python,

00:26:12.840 --> 00:26:13.920
you can benchmark it,

00:26:13.920 --> 00:26:15.880
there's probably, you probably knew,

00:26:15.880 --> 00:26:18.120
you didn't write it that well when you first started

00:26:18.120 --> 00:26:20.880
and you can always find ways to improve it.

00:26:20.880 --> 00:26:25.160
- So this UI is something that you can just run locally,

00:26:25.160 --> 00:26:26.640
kind of like Jupyter.

00:26:26.640 --> 00:26:28.760
- 100%, just type docs or dev

00:26:28.760 --> 00:26:32.560
and then you get the full UI experience,

00:26:32.560 --> 00:26:34.600
you get to see the runs, all your assets.

00:26:34.600 --> 00:26:37.080
- Is it a web app?

00:26:37.080 --> 00:26:38.640
- It is, yeah.

00:26:38.640 --> 00:26:41.960
It's a web app, there's a Postgres backend

00:26:41.960 --> 00:26:44.000
and then there's a couple of services that run,

00:26:44.000 --> 00:26:47.800
the web server, the GraphQL and then the workers.

00:26:47.800 --> 00:26:51.320
- Nice, yeah, so pretty serious web app, it sounds like.

00:26:51.320 --> 00:26:53.480
But you probably run it all. - Yeah, something like--

00:26:53.480 --> 00:26:56.680
- Yeah, just something you run all,

00:26:56.680 --> 00:26:58.360
probably containers or something,

00:26:58.360 --> 00:27:00.760
then you just fire up when you download it, right?

00:27:00.760 --> 00:27:03.400
- Locally, it doesn't even use containers,

00:27:03.400 --> 00:27:07.560
it's just all pure Python for that.

00:27:07.560 --> 00:27:09.760
But once you deploy, yeah,

00:27:09.760 --> 00:27:12.000
I think you might wanna go down the container route.

00:27:12.000 --> 00:27:13.720
But it's nice not having to have Docker

00:27:13.720 --> 00:27:16.360
just to run a simple test deployment.

00:27:16.360 --> 00:27:19.400
- Yeah, I guess not everyone's machine has that, for sure.

00:27:19.400 --> 00:27:25.800
So question from the audience here, Jazzy asks,

00:27:25.800 --> 00:27:28.480
does it hook into AWS in particular?

00:27:28.480 --> 00:27:31.040
Is it compatible with existing pipelines

00:27:31.040 --> 00:27:34.000
like ingestion Lambdas or transform Lambdas?

00:27:34.000 --> 00:27:37.040
- Yeah, you can hook into AWS.

00:27:37.040 --> 00:27:40.040
So we have some AWS integrations built in.

00:27:40.040 --> 00:27:41.200
Like I mentioned before,

00:27:41.200 --> 00:27:43.520
there's nothing stopping you from importing Boto3

00:27:43.520 --> 00:27:44.960
and doing anything really you want.

00:27:44.960 --> 00:27:47.240
So a very simple use case,

00:27:47.240 --> 00:27:49.680
like let's say you already have an existing transformation

00:27:49.680 --> 00:27:52.880
that's being triggered in AWS through some Lambda,

00:27:52.880 --> 00:27:55.120
you could just model that within Dexter

00:27:55.120 --> 00:27:58.880
and say, trigger that Lambda through Boto3.

00:27:58.880 --> 00:28:01.360
And then the asset itself

00:28:01.360 --> 00:28:04.400
is really that representation of that pipeline,

00:28:04.400 --> 00:28:05.600
but you're not actually running that code

00:28:05.600 --> 00:28:06.720
within Dexter itself,

00:28:06.720 --> 00:28:09.040
that's still occurring on the AWS framework.

00:28:09.040 --> 00:28:11.280
And that's a really simple way to start

00:28:11.280 --> 00:28:12.720
adding a little bit of observability

00:28:12.720 --> 00:28:15.480
and orchestration to existing pipelines.

00:28:15.480 --> 00:28:16.640
- Okay, that's pretty cool

00:28:16.640 --> 00:28:19.280
because now you have this nice UI

00:28:19.280 --> 00:28:21.600
and these metadata and this history,

00:28:21.600 --> 00:28:24.000
but it's someone else's cloud.

00:28:24.000 --> 00:28:24.960
- Exactly, yeah.

00:28:24.960 --> 00:28:27.320
- And you can start to pull more information in there

00:28:27.320 --> 00:28:29.720
and over time you might decide,

00:28:29.720 --> 00:28:32.880
this Lambda that I had, it's starting to get out of hand.

00:28:32.880 --> 00:28:35.640
I wanna kind of break it apart into multiple assets

00:28:35.640 --> 00:28:37.320
where I want to sort of optimize it

00:28:37.320 --> 00:28:39.640
a little way and Dexter can help you along that.

00:28:39.640 --> 00:28:42.960
- Well, yeah, excellent.

00:28:42.960 --> 00:28:46.880
How do you set up like triggers

00:28:46.880 --> 00:28:50.240
or observability inside Dexter?

00:28:50.240 --> 00:28:52.480
Like Jazzy asked about S3,

00:28:52.480 --> 00:28:53.800
but like in general, right?

00:28:53.800 --> 00:28:56.080
If a row is entered into a database,

00:28:56.080 --> 00:28:58.080
something is dropped in a blob storage

00:28:58.080 --> 00:29:01.080
or the date changes, I don't know.

00:29:01.080 --> 00:29:03.080
- Yeah, those are great questions.

00:29:03.080 --> 00:29:04.840
So you have a lot of options.

00:29:04.840 --> 00:29:07.440
In Dexter, we do model every asset

00:29:07.440 --> 00:29:10.360
with a couple little flags, I think,

00:29:10.360 --> 00:29:12.560
that are really useful to think about.

00:29:12.560 --> 00:29:13.840
One is whether the code

00:29:13.840 --> 00:29:16.640
of that particular asset has changed, right?

00:29:16.640 --> 00:29:19.080
And then the other one is whether

00:29:19.080 --> 00:29:21.640
anything upstream of that asset has changed.

00:29:21.640 --> 00:29:24.080
And those two things really power a lot

00:29:24.080 --> 00:29:27.880
of automation functionality that we can get downstream.

00:29:27.880 --> 00:29:30.800
So let's start with, I think the S3 example

00:29:30.800 --> 00:29:31.880
is the easiest to understand.

00:29:31.880 --> 00:29:35.400
You have a bucket and there is a file

00:29:35.400 --> 00:29:37.120
that gets uploaded every day.

00:29:37.120 --> 00:29:39.320
You don't know what time that file gets uploaded.

00:29:39.320 --> 00:29:40.640
You don't know when it'll be uploaded,

00:29:40.640 --> 00:29:43.040
but you know, at some point it will be.

00:29:43.040 --> 00:29:45.240
In Dexter, we have a thing called the sensor,

00:29:45.240 --> 00:29:48.600
which you can just connect to an S3 location.

00:29:48.600 --> 00:29:51.120
You can define how it looks into that file

00:29:51.120 --> 00:29:52.120
or into that folder.

00:29:52.120 --> 00:29:55.240
And then you would just pull every 30 seconds

00:29:55.240 --> 00:29:57.200
until something happens.

00:29:57.200 --> 00:29:58.920
When that something happens,

00:29:58.920 --> 00:30:00.760
that triggers sort of an event.

00:30:00.760 --> 00:30:02.760
And that event can trickle at your will,

00:30:02.760 --> 00:30:05.080
downstream to everything that depends on it

00:30:05.080 --> 00:30:07.440
as you sort of connect to these things.

00:30:07.440 --> 00:30:09.280
So it gets you awake from this like,

00:30:09.280 --> 00:30:11.840
oh, I'm gonna schedule something to run every hour.

00:30:11.840 --> 00:30:14.240
Maybe the data will be there, but maybe it won't.

00:30:14.240 --> 00:30:16.720
And you can have a much more event-based workflow.

00:30:16.720 --> 00:30:19.560
When this file runs, I want everything downstream

00:30:19.560 --> 00:30:21.680
to know that this data has changed.

00:30:21.680 --> 00:30:23.720
And as sort of data flows through these systems,

00:30:23.720 --> 00:30:26.480
everything will sort of work its way down.

00:30:26.480 --> 00:30:27.720
- Yeah, I like it.

00:30:27.720 --> 00:30:29.520
The sensor concept is really cool

00:30:29.520 --> 00:30:34.520
because I'm sure that there's a ton of cloud machines

00:30:34.520 --> 00:30:37.200
that people provisioned

00:30:37.200 --> 00:30:39.680
just because this thing runs every 15 minutes,

00:30:39.680 --> 00:30:40.920
that runs every 30 minutes,

00:30:40.920 --> 00:30:43.040
and you add them up and in aggregate,

00:30:43.040 --> 00:30:47.240
we need eight machines just to handle the automation

00:30:47.240 --> 00:30:49.360
rather than, you know,

00:30:49.360 --> 00:30:50.720
'cause they're hoping to catch something

00:30:50.720 --> 00:30:51.600
without too much latency,

00:30:51.600 --> 00:30:55.040
but maybe like that actually only changes once a week.

00:30:55.040 --> 00:30:56.080
- Exactly.

00:30:56.080 --> 00:30:59.160
And I think that's where we have to like sometimes

00:30:59.160 --> 00:31:01.520
step away from the way we're so used to thinking

00:31:01.520 --> 00:31:04.200
about things, and I'm guilty of this.

00:31:04.200 --> 00:31:05.440
When I create a data pipeline,

00:31:05.440 --> 00:31:07.560
my natural inclination is to create a schedule

00:31:07.560 --> 00:31:09.720
where I can say, is this a daily one?

00:31:09.720 --> 00:31:10.560
Is this weekly?

00:31:10.560 --> 00:31:11.960
Is this monthly?

00:31:11.960 --> 00:31:13.000
But what I'm finding more and more

00:31:13.000 --> 00:31:14.720
is when I'm creating my pipelines,

00:31:14.720 --> 00:31:16.400
I'm not adding a schedule.

00:31:16.400 --> 00:31:19.240
I'm using Dagster's auto-materialized policies,

00:31:19.240 --> 00:31:21.280
and I'm just telling it, you figure it out.

00:31:21.280 --> 00:31:23.360
I don't have to think about schedules.

00:31:23.360 --> 00:31:25.480
Just figure out when the things should be updated.

00:31:25.480 --> 00:31:28.160
When it's, you know, parents have been updated, you run.

00:31:28.160 --> 00:31:30.360
When the data has changed, you run.

00:31:30.360 --> 00:31:33.240
And then just like figure it out and leave me alone.

00:31:33.240 --> 00:31:34.080
- Yeah.

00:31:34.080 --> 00:31:36.640
- And it's worked pretty well for me so far.

00:31:36.640 --> 00:31:38.080
- I think it's great.

00:31:38.080 --> 00:31:41.000
I have a search, refresh the search index

00:31:41.000 --> 00:31:44.040
on the various podcast pages that runs,

00:31:44.040 --> 00:31:45.800
and it runs every hour,

00:31:45.800 --> 00:31:48.480
but the podcast ships weekly, right?

00:31:48.480 --> 00:31:49.600
- Right.

00:31:49.600 --> 00:31:50.760
- I don't know which hour it is,

00:31:50.760 --> 00:31:53.120
and so it seems like that's enough latency,

00:31:53.120 --> 00:31:54.720
but it would be way better

00:31:54.720 --> 00:31:56.360
to put just a little bit of smarts,

00:31:56.360 --> 00:32:00.680
like what was the last date that anything changed?

00:32:00.680 --> 00:32:02.000
Was that since the last time you saw it?

00:32:02.000 --> 00:32:04.360
Maybe we'll just leave that alone, you know?

00:32:04.360 --> 00:32:05.880
But yeah, you're starting to inspire me

00:32:05.880 --> 00:32:10.280
to go write more code, but pretty cool.

00:32:10.280 --> 00:32:13.840
All right, so on the homepage at dagster.io,

00:32:13.840 --> 00:32:17.480
you've got a nice graphic that shows you both

00:32:17.480 --> 00:32:19.520
how to write the code, like some examples of the code,

00:32:19.520 --> 00:32:22.960
as well as how that looks in the UI.

00:32:22.960 --> 00:32:26.720
And one of them says to launch backfills.

00:32:26.720 --> 00:32:28.520
What is this backfill thing?

00:32:28.520 --> 00:32:30.000
- Oh, this is my favorite thing.

00:32:30.000 --> 00:32:31.240
Okay. - Okay.

00:32:31.240 --> 00:32:35.800
- So when you first start your data journey

00:32:35.800 --> 00:32:38.160
as a data engineer, you sort of have a pipeline,

00:32:38.160 --> 00:32:41.400
and you build it, and it just runs on a schedule,

00:32:41.400 --> 00:32:42.960
and that's fine.

00:32:42.960 --> 00:32:45.840
What you soon find is, you know,

00:32:45.840 --> 00:32:48.480
you might have to go back in time, right?

00:32:48.480 --> 00:32:53.480
You might say, "I've got this dataset that updates monthly."

00:32:53.480 --> 00:32:55.960
Here's a great example, AWS Cost Reporting, right?

00:32:55.960 --> 00:32:59.640
AWS will send you some data around, you know,

00:32:59.640 --> 00:33:03.120
all your instances and your S3 bucket, all that,

00:33:03.120 --> 00:33:06.320
and it'll update that data every day or every month

00:33:06.320 --> 00:33:08.240
or whatever have you.

00:33:08.240 --> 00:33:10.240
Due to some reason, you've got to go back in time

00:33:10.240 --> 00:33:12.320
and refresh data that AWS updated

00:33:12.320 --> 00:33:13.920
due to some, like, discrepancy.

00:33:15.240 --> 00:33:17.400
Backfill is sort of how you do that,

00:33:17.400 --> 00:33:20.320
and it works hand-in-hand with this idea of a partition.

00:33:20.320 --> 00:33:24.720
A partition is sort of how your data is naturally organized,

00:33:24.720 --> 00:33:26.440
and it's like a nice way to represent

00:33:26.440 --> 00:33:28.720
that natural organization.

00:33:28.720 --> 00:33:30.880
It has nothing to do with, like, the fundamental way,

00:33:30.880 --> 00:33:32.160
how often you want to run it.

00:33:32.160 --> 00:33:35.120
It's more around, like, I've got a dataset

00:33:35.120 --> 00:33:38.440
that comes in once a month, it's represented monthly.

00:33:38.440 --> 00:33:40.640
It might be updated daily, but it's the representation

00:33:40.640 --> 00:33:43.800
of the data is monthly, so I will partition it by month.

00:33:43.800 --> 00:33:45.240
It doesn't have to be dates.

00:33:45.240 --> 00:33:46.280
It could be strings.

00:33:46.280 --> 00:33:47.920
It could be a list.

00:33:47.920 --> 00:33:50.720
You could have a partition for every, you know,

00:33:50.720 --> 00:33:54.760
company or every client or, you know,

00:33:54.760 --> 00:33:55.840
every domain you have,

00:33:55.840 --> 00:33:58.040
whatever you sort of think is a natural way

00:33:58.040 --> 00:34:00.720
to think about breaking apart that pipeline.

00:34:00.720 --> 00:34:04.000
And once you do that partition,

00:34:04.000 --> 00:34:05.720
you can do these nice things called backfills,

00:34:05.720 --> 00:34:08.600
which says, instead of running this entire pipeline

00:34:08.600 --> 00:34:11.680
and all my data, I want you to pick that one month

00:34:11.680 --> 00:34:13.040
where your data went wrong

00:34:13.040 --> 00:34:15.200
or that one month where data was missing

00:34:15.200 --> 00:34:17.760
and just run the partition on that range.

00:34:17.760 --> 00:34:21.120
And so you limit the compute, you save resources,

00:34:21.120 --> 00:34:22.680
it's gonna be a little bit more efficient,

00:34:22.680 --> 00:34:24.200
and it's just easier to, like,

00:34:24.200 --> 00:34:25.520
think about your pipeline and stuff

00:34:25.520 --> 00:34:27.040
because you've got this natural built-in

00:34:27.040 --> 00:34:28.080
partitioning system.

00:34:28.080 --> 00:34:33.720
- Excellent, so maybe you missed some important event.

00:34:33.720 --> 00:34:37.680
Maybe your automation went down for a little bit,

00:34:37.680 --> 00:34:40.560
came back up, you're like, oh no, we've missed it, right?

00:34:40.560 --> 00:34:42.680
But you want to start over.

00:34:43.520 --> 00:34:44.360
You don't want to start over.

00:34:44.360 --> 00:34:45.200
- For like three years, so you're like,

00:34:45.200 --> 00:34:48.080
maybe we could just go and run the last day.

00:34:48.080 --> 00:34:48.920
It's worth it.

00:34:48.920 --> 00:34:49.760
- Exactly.

00:34:49.760 --> 00:34:51.600
Or another one would be your vendor says,

00:34:51.600 --> 00:34:53.600
hey, by the way, we actually screwed up.

00:34:53.600 --> 00:34:56.000
We uploaded this file from two months ago,

00:34:56.000 --> 00:34:57.560
but the numbers were all wrong.

00:34:57.560 --> 00:35:01.800
We've uploaded a new version to that destination.

00:35:01.800 --> 00:35:04.240
Can you update your data set?

00:35:04.240 --> 00:35:07.840
One way is to recompute the entire universe from scratch.

00:35:07.840 --> 00:35:09.000
But if you've partitioned things,

00:35:09.000 --> 00:35:12.120
then you can say, no, limit that to just this one partition

00:35:12.120 --> 00:35:13.480
for that one.

00:35:13.480 --> 00:35:15.400
And that one partition can trickle down all the way

00:35:15.400 --> 00:35:18.400
to all your other assets that depend on that one.

00:35:18.400 --> 00:35:21.560
- Do you have to pre decide,

00:35:21.560 --> 00:35:23.960
you have to think about this partitioning beforehand

00:35:23.960 --> 00:35:25.840
or can you do it retroactively?

00:35:25.840 --> 00:35:27.000
- You can do it retroactively.

00:35:27.000 --> 00:35:29.160
And I have done that before as well.

00:35:29.160 --> 00:35:32.160
It really depends on where you're at.

00:35:32.160 --> 00:35:35.080
I think if it's your first asset ever,

00:35:35.080 --> 00:35:37.240
probably don't bother with partitions,

00:35:37.240 --> 00:35:40.960
but it really isn't a lot of work to get them started.

00:35:41.960 --> 00:35:43.200
- Okay.

00:35:43.200 --> 00:35:44.160
Yeah, really neat.

00:35:44.160 --> 00:35:46.120
I like a lot of the ideas here.

00:35:46.120 --> 00:35:48.800
I like that it's got this visual component

00:35:48.800 --> 00:35:53.800
that you can see what's going on, inspect it.

00:35:53.800 --> 00:35:57.320
You also see you can debug runs.

00:35:57.320 --> 00:35:58.320
What happens there?

00:35:58.320 --> 00:36:01.040
Like obviously when you're pulling data

00:36:01.040 --> 00:36:02.240
from many different sources,

00:36:02.240 --> 00:36:04.960
maybe it's not your data you're taking in.

00:36:04.960 --> 00:36:06.680
You know, fields could vanish.

00:36:06.680 --> 00:36:08.120
It can be the wrong type.

00:36:08.120 --> 00:36:09.280
Systems can go down.

00:36:09.280 --> 00:36:12.040
I'm sure the debugging is interesting.

00:36:12.040 --> 00:36:17.040
So it looks a little bit kind of like a web browser debug

00:36:17.040 --> 00:36:18.120
dev tools thing.

00:36:18.120 --> 00:36:22.000
- So for the record, my code never fails.

00:36:22.000 --> 00:36:23.600
I've never had a bug in my life,

00:36:23.600 --> 00:36:25.120
but for those of you who have.

00:36:25.120 --> 00:36:26.440
- Yeah, well, mine doesn't either.

00:36:26.440 --> 00:36:29.400
I only do it to make an example and for reminding me

00:36:29.400 --> 00:36:31.080
how other, yes.

00:36:31.080 --> 00:36:33.120
If I do it's intentional, of course.

00:36:33.120 --> 00:36:35.280
- You get to humble myself a little bit.

00:36:35.280 --> 00:36:36.120
- Exactly.

00:36:37.560 --> 00:36:39.600
This view is one of my favorite.

00:36:39.600 --> 00:36:40.760
I mean, so many favorite views,

00:36:40.760 --> 00:36:43.720
but this is, it's actually really fun to watch.

00:36:43.720 --> 00:36:46.520
Watch this actually run when you execute this pipeline.

00:36:46.520 --> 00:36:50.560
But really like, let's go back to, you know,

00:36:50.560 --> 00:36:52.120
the world before orchestrators.

00:36:52.120 --> 00:36:54.120
We use cron, right?

00:36:54.120 --> 00:36:56.080
We'd have a bash script that would do something

00:36:56.080 --> 00:36:57.680
and we'd have a cron drop that said,

00:36:57.680 --> 00:36:59.680
make sure this thing runs.

00:36:59.680 --> 00:37:02.040
And then hopefully it was successful,

00:37:02.040 --> 00:37:03.920
but sometimes it wasn't.

00:37:03.920 --> 00:37:05.400
And it's a sometimes it wasn't,

00:37:05.400 --> 00:37:06.760
that's always been the problem, right?

00:37:06.760 --> 00:37:08.720
It's like, well, what do I do now?

00:37:08.720 --> 00:37:10.680
How do I know why it failed?

00:37:10.680 --> 00:37:12.920
What was, when did it fail?

00:37:12.920 --> 00:37:15.720
You know, at what point or what steps did it fail?

00:37:15.720 --> 00:37:16.920
That's really hard to do.

00:37:16.920 --> 00:37:19.320
What this debugger really is,

00:37:19.320 --> 00:37:22.800
is a structured log of every step that's been going on

00:37:22.800 --> 00:37:24.880
through your pipeline, right?

00:37:24.880 --> 00:37:26.800
So in this view, there's three assets

00:37:26.800 --> 00:37:27.920
that we can kind of see here.

00:37:27.920 --> 00:37:30.720
One is called users, one is called orders

00:37:30.720 --> 00:37:32.880
and one is to run dbt.

00:37:32.880 --> 00:37:34.880
But presumably there's these two, you know,

00:37:34.880 --> 00:37:36.520
tables that are being updated

00:37:36.520 --> 00:37:38.160
and then a dbt job, it looks like

00:37:38.160 --> 00:37:40.520
that's being updated at the very end.

00:37:40.520 --> 00:37:42.160
Once you execute this pipeline,

00:37:42.160 --> 00:37:45.400
all the logs are captured from each of those assets.

00:37:45.400 --> 00:37:49.000
So you can manually write your own logs.

00:37:49.000 --> 00:37:50.920
You have access to a Python logger

00:37:50.920 --> 00:37:53.800
and you can use your info, your error, whatever have you

00:37:53.800 --> 00:37:55.000
and log output that way.

00:37:55.000 --> 00:37:57.320
And it'll be captured in a structured way,

00:37:57.320 --> 00:38:00.560
but it also capture logs from your integrations.

00:38:00.560 --> 00:38:03.480
So if you're using dbt, we capture those logs as well.

00:38:03.480 --> 00:38:06.200
You can see it processing every single asset.

00:38:06.200 --> 00:38:07.600
So if anything does go wrong,

00:38:07.600 --> 00:38:11.000
you can filter down and understand at what step,

00:38:11.000 --> 00:38:13.240
at what point did something go wrong.

00:38:13.240 --> 00:38:16.840
- That's awesome.

00:38:16.840 --> 00:38:19.040
Just the historical aspect,

00:38:19.040 --> 00:38:20.320
'cause just going through logs,

00:38:20.320 --> 00:38:24.320
especially multiple systems can be really, really tricky

00:38:24.320 --> 00:38:29.320
to figure out what actually caused this to go wrong.

00:38:29.320 --> 00:38:33.200
But come back and say, oh, it crashed,

00:38:33.200 --> 00:38:35.560
pull up the UI and see,

00:38:35.560 --> 00:38:38.200
all right, well, show me what this run did,

00:38:38.200 --> 00:38:39.440
show me what this job did.

00:38:39.440 --> 00:38:42.320
Seems like it's a lot easier to debug

00:38:42.320 --> 00:38:46.400
than your standard web API or something like that.

00:38:46.400 --> 00:38:47.240
- Exactly.

00:38:47.240 --> 00:38:48.560
You can click on any of these assets

00:38:48.560 --> 00:38:51.600
that get that metadata that we had earlier as well.

00:38:51.600 --> 00:38:54.600
If one step failed and it's kind of flaky,

00:38:54.600 --> 00:38:56.160
you can just click on that one step and say,

00:38:56.160 --> 00:38:58.520
just rerun this, everything else is fine.

00:38:58.520 --> 00:39:00.960
We don't need to restart from scratch.

00:39:00.960 --> 00:39:05.040
- Okay, and it'll keep the data from before

00:39:05.040 --> 00:39:06.640
so you don't have to rerun that.

00:39:06.640 --> 00:39:11.000
- Yeah, I mean, it depends on how you built the pipeline.

00:39:11.000 --> 00:39:12.880
We like to build item potent pipelines

00:39:12.880 --> 00:39:14.320
is how we sort of talk about it,

00:39:14.320 --> 00:39:16.080
the data engineering landscape, right?

00:39:16.080 --> 00:39:18.800
So you should be able to run something multiple times

00:39:18.800 --> 00:39:20.720
and not break anything in a perfect world,

00:39:20.720 --> 00:39:24.280
that's not always possible, but ideally, yes.

00:39:24.280 --> 00:39:28.080
And so we can presume that if user is completed successfully,

00:39:28.080 --> 00:39:29.320
then we don't have to run that again

00:39:29.320 --> 00:39:31.280
because that data was persisted,

00:39:31.280 --> 00:39:33.640
database S3 somewhere.

00:39:33.640 --> 00:39:35.360
And if orders was the one that was broken,

00:39:35.360 --> 00:39:38.280
we can just only run orders and not have to worry

00:39:38.280 --> 00:39:40.440
about rewriting the whole thing from scratch.

00:39:40.440 --> 00:39:44.520
- Excellent, so item potent for people who maybe don't know,

00:39:44.520 --> 00:39:46.960
if you run it once or you perform the operation once

00:39:46.960 --> 00:39:49.440
or you perform it 20 times,

00:39:49.440 --> 00:39:52.520
same outcome should have side effects, right?

00:39:52.520 --> 00:39:53.600
- That's the idea, yeah.

00:39:53.600 --> 00:39:54.600
- That's the idea.

00:39:54.600 --> 00:39:56.640
We can strive for it. - Easier said than done sometimes.

00:39:56.640 --> 00:39:57.680
- It sure is.

00:39:57.680 --> 00:39:59.680
- Sometimes it's easy, sometimes it's very hard,

00:39:59.680 --> 00:40:02.760
but the more you can build pipelines that way,

00:40:02.760 --> 00:40:04.880
the easier your life becomes.

00:40:04.880 --> 00:40:07.960
- Generally, not always,

00:40:07.960 --> 00:40:10.360
but generally true for programming as well, right?

00:40:10.360 --> 00:40:12.080
If you talk to functional programming people,

00:40:12.080 --> 00:40:14.400
they'll say like, it's an absolute, but.

00:40:14.400 --> 00:40:19.200
- Yes, yes, functional programmers love this kind of stuff

00:40:19.200 --> 00:40:21.600
and it actually does lend itself really well

00:40:21.600 --> 00:40:22.840
to data pipelines.

00:40:22.840 --> 00:40:25.640
Data pipelines, unlike maybe some of the software

00:40:25.640 --> 00:40:27.600
engineering stuff, it's a little bit different

00:40:27.600 --> 00:40:31.520
in that the data changing is what causes often

00:40:31.520 --> 00:40:34.400
most of the headaches, right?

00:40:34.400 --> 00:40:38.400
It's less so the actual code you write,

00:40:38.400 --> 00:40:41.360
but more the expectations tend to change so frequently

00:40:41.360 --> 00:40:44.720
and so often in new and novel and interesting ways

00:40:44.720 --> 00:40:46.840
that you would often never expect.

00:40:46.840 --> 00:40:51.520
And so the more you can sort of make that function so pure

00:40:51.520 --> 00:40:54.600
that you can provide any sort of dataset

00:40:54.600 --> 00:40:57.640
and really test really easily these expectations

00:40:57.640 --> 00:40:58.880
when they get broken,

00:40:58.880 --> 00:41:00.760
the easier it is to sort of debug these things

00:41:00.760 --> 00:41:02.640
and build on them in the future.

00:41:02.640 --> 00:41:04.960
- Yeah, and cache them as well.

00:41:04.960 --> 00:41:06.600
- Yes, it's always nice.

00:41:06.600 --> 00:41:09.280
- Yeah, so speaking of that kind of stuff,

00:41:09.280 --> 00:41:12.720
like what's the scalability story?

00:41:12.720 --> 00:41:16.880
If I've got some big, huge, complicated data pipeline,

00:41:16.880 --> 00:41:21.880
can I parallelize them and have them run multiple pieces

00:41:21.880 --> 00:41:26.400
like if there's different branches or something like that?

00:41:26.400 --> 00:41:29.080
- Yeah, exactly, that's one of the key benefits, I think,

00:41:29.080 --> 00:41:34.040
in writing your assets in this DAG way, right?

00:41:34.040 --> 00:41:39.240
Anything that is parallelizable will be parallelized.

00:41:39.240 --> 00:41:40.920
Now, sometimes you might wanna put limits on that.

00:41:40.920 --> 00:41:43.040
Sometimes too much parallelization is bad.

00:41:43.040 --> 00:41:45.200
Your poor little database can't handle it.

00:41:45.200 --> 00:41:46.120
And you can say, you know,

00:41:46.120 --> 00:41:49.280
maybe a concurrency limit on this one just for today

00:41:49.280 --> 00:41:51.280
is worth putting on,

00:41:51.280 --> 00:41:53.600
or if you're hitting an API for an external vendor,

00:41:53.600 --> 00:41:56.320
they might not appreciate 10,000 requests a second

00:41:56.320 --> 00:41:59.040
on that one, so maybe you would slow it down.

00:41:59.040 --> 00:42:00.520
But in this-- - Or rate limiting, right?

00:42:00.520 --> 00:42:02.000
You can run into too many requests

00:42:02.000 --> 00:42:04.320
and then your stuff crashes, then you gotta start.

00:42:04.320 --> 00:42:06.080
It can be a whole thing.

00:42:06.080 --> 00:42:06.920
- It can be a whole thing.

00:42:06.920 --> 00:42:09.320
There's memory concerns, but let's pretend the world

00:42:09.320 --> 00:42:10.680
is simple.

00:42:10.680 --> 00:42:14.360
Anything that can be parallelized will be through Dagster.

00:42:14.360 --> 00:42:16.360
And that's really the benefit of writing these DAGs

00:42:16.360 --> 00:42:19.200
is that there's a nice algorithm for determining

00:42:19.200 --> 00:42:20.640
what that actually looks like.

00:42:20.640 --> 00:42:23.000
- Yeah, I guess if you have a diamond shape

00:42:23.000 --> 00:42:24.880
or any sort of split, right?

00:42:24.880 --> 00:42:28.360
Those two things now become, 'cause it's acyclical,

00:42:28.360 --> 00:42:30.560
they can't turn around and then eventually depend

00:42:30.560 --> 00:42:32.160
on each other again. - Exactly.

00:42:32.160 --> 00:42:35.840
- That's a perfect chance to just go fork it out.

00:42:35.840 --> 00:42:38.440
- Exactly, and that's kind of where partitions

00:42:38.440 --> 00:42:39.680
are also kind of interesting.

00:42:39.680 --> 00:42:42.200
If you have a partitioned asset,

00:42:42.200 --> 00:42:45.840
you could take your dataset partitioned into five buckets

00:42:45.840 --> 00:42:47.440
and run all five partitions at once,

00:42:47.440 --> 00:42:49.560
knowing full well that 'cause you've written this

00:42:49.560 --> 00:42:53.840
in a idempotent and partitioned way

00:42:53.840 --> 00:42:57.160
that the first pipeline will only operate on Apple

00:42:57.160 --> 00:42:59.360
and the second one only operates on bananas

00:42:59.360 --> 00:43:01.600
and there is no commingling of apples and bananas

00:43:01.600 --> 00:43:03.600
anywhere in the pipeline.

00:43:03.600 --> 00:43:04.440
- Oh, that's interesting.

00:43:04.440 --> 00:43:06.280
I hadn't really thought about using the partitions

00:43:06.280 --> 00:43:07.840
for parallelism, but of course.

00:43:07.840 --> 00:43:12.520
- Yeah, it's a fun little way to break things apart.

00:43:12.520 --> 00:43:18.760
- So if we run this on the Dagster cloud or even on our own,

00:43:18.760 --> 00:43:21.480
this is pretty much automatic.

00:43:21.480 --> 00:43:23.680
We don't have to do anything.

00:43:23.680 --> 00:43:25.280
Like Dagster just looks at it and says,

00:43:25.280 --> 00:43:27.720
this looks parallelizable and it'll go or?

00:43:27.720 --> 00:43:30.560
- That's right, yeah.

00:43:30.560 --> 00:43:32.520
As long as you've got the full deployment,

00:43:32.520 --> 00:43:34.360
whether it's OSS or cloud,

00:43:34.360 --> 00:43:36.560
Dagster will basically parallelize it for you

00:43:36.560 --> 00:43:39.160
as much as possible.

00:43:39.160 --> 00:43:40.000
- Excellent.

00:43:40.000 --> 00:43:41.120
- You can set global currency limits.

00:43:41.120 --> 00:43:46.120
So you might say, 64 is more than enough parallelization

00:43:46.120 --> 00:43:48.240
that I need, or maybe I want less

00:43:48.240 --> 00:43:50.480
because I'm worried about overloading systems,

00:43:50.480 --> 00:43:51.920
but it's really up to you.

00:43:51.920 --> 00:43:54.400
- I'm putting this on a $10 server, please don't.

00:43:55.000 --> 00:43:55.840
Please don't kill it.

00:43:55.840 --> 00:43:59.800
Just respect that it's somewhat wimpy, but that's okay.

00:43:59.800 --> 00:44:01.280
- Yeah, it'll get the job done.

00:44:01.280 --> 00:44:03.200
- It'll get the job done.

00:44:03.200 --> 00:44:05.080
All right, I wanna talk about some of the tools

00:44:05.080 --> 00:44:09.760
and some of the tools that are maybe at play here

00:44:09.760 --> 00:44:11.680
when working with Dagster and some of the trends and stuff.

00:44:11.680 --> 00:44:16.680
But before that, maybe speak to where

00:44:16.680 --> 00:44:21.400
you could see people adopt a tool like Dagster,

00:44:21.400 --> 00:44:22.840
but they generally don't.

00:44:22.840 --> 00:44:25.120
They don't realize like, oh, actually,

00:44:25.120 --> 00:44:26.800
there's a whole framework for this, right?

00:44:26.800 --> 00:44:31.800
Like I could, sure, I could go and build just on HTTP server

00:44:31.800 --> 00:44:37.120
and hook into the request and start writing to it.

00:44:37.120 --> 00:44:39.920
But like, maybe I should use Flask or FastAPI.

00:44:39.920 --> 00:44:43.920
Like there's these frameworks that we really naturally adopt

00:44:43.920 --> 00:44:47.960
for certain situations like APIs and others,

00:44:47.960 --> 00:44:50.960
background jobs, data pipelines,

00:44:50.960 --> 00:44:53.200
where I think there's probably a good chunk of people

00:44:53.200 --> 00:44:55.120
who could benefit from stuff like this,

00:44:55.120 --> 00:44:57.800
but they just don't think they need a framework for it.

00:44:57.800 --> 00:44:59.360
Like, cron is enough.

00:44:59.360 --> 00:45:04.720
- Yeah, it's funny because sometimes cron is enough.

00:45:04.720 --> 00:45:07.760
And I don't wanna encourage people not to use cron,

00:45:07.760 --> 00:45:12.600
but think twice, at least is what I would say.

00:45:12.600 --> 00:45:17.280
So probably the first like trigger for me of thinking of,

00:45:17.280 --> 00:45:18.360
is Dagster a good choice?

00:45:18.360 --> 00:45:20.920
Is like, am I trying to ingest data from somewhere?

00:45:20.920 --> 00:45:23.480
'Cause that's something that fails.

00:45:23.480 --> 00:45:25.800
Like, I think we just can accept that,

00:45:25.800 --> 00:45:27.720
if you're moving data around,

00:45:27.720 --> 00:45:31.280
the data source will break, the expectations will change,

00:45:31.280 --> 00:45:34.200
you will need to debug it, you'll need to rerun it.

00:45:34.200 --> 00:45:35.880
And doing that in cron is a nightmare.

00:45:35.880 --> 00:45:38.200
So I would say definitely start to think about

00:45:38.200 --> 00:45:41.600
an orchestration system if you're ingesting data.

00:45:41.600 --> 00:45:43.720
If you have a simple cron job that sends one email,

00:45:43.720 --> 00:45:45.320
like you're probably fine.

00:45:45.320 --> 00:45:48.640
I don't think you need to implement all of Dagster

00:45:48.640 --> 00:45:49.840
just to do that.

00:45:49.840 --> 00:45:53.840
But the more closer you get to data pipelining,

00:45:53.840 --> 00:45:57.240
I think the better your life will be,

00:45:57.240 --> 00:46:01.440
if you're not trying to debug a obtuse process

00:46:01.440 --> 00:46:04.000
that no one really understands six months from now.

00:46:04.000 --> 00:46:06.480
- Excellent.

00:46:06.480 --> 00:46:10.120
All right, maybe we could touch on some of the tools

00:46:10.120 --> 00:46:12.080
that are interesting to see people using.

00:46:12.080 --> 00:46:15.840
You talked about DUPDB and DBT,

00:46:15.840 --> 00:46:17.280
a lot of Ds starting here,

00:46:17.280 --> 00:46:22.280
but give us a sense of like some of the supporting tools

00:46:22.280 --> 00:46:24.680
you see a lot of folks using that are interesting.

00:46:24.680 --> 00:46:25.520
- Yeah, for sure.

00:46:25.520 --> 00:46:29.200
I think in the data space,

00:46:29.200 --> 00:46:33.960
probably DBT is one of the most popular choices.

00:46:33.960 --> 00:46:37.040
And DBT, in many ways,

00:46:37.040 --> 00:46:40.080
it's nothing more than a command line tool

00:46:40.080 --> 00:46:44.640
that runs a bunch of SQL in a DAG as well.

00:46:44.640 --> 00:46:48.200
So it was actually a nice fit with Dagster and DBT together.

00:46:48.200 --> 00:46:52.200
DBT is really used by people who are trying to model

00:46:52.200 --> 00:46:55.320
that business process using SQL

00:46:55.320 --> 00:46:57.000
against typically a data warehouse.

00:46:57.000 --> 00:47:00.680
So if you have your data in, for example,

00:47:00.680 --> 00:47:05.680
a Postgres, a Snowflake, Databricks, Microsoft SQL,

00:47:05.680 --> 00:47:08.360
these types of data warehouses,

00:47:08.360 --> 00:47:10.520
generally you're trying to model

00:47:10.520 --> 00:47:12.400
some type of business process.

00:47:12.400 --> 00:47:15.920
And typically people use SQL to do that.

00:47:15.920 --> 00:47:18.120
Now you can do this without DBT,

00:47:18.120 --> 00:47:22.240
but DBT has provided a nice clean interface to doing so.

00:47:22.240 --> 00:47:24.360
It makes it very easy to connect these models together,

00:47:24.360 --> 00:47:27.120
to run them, to have a development workflow

00:47:27.120 --> 00:47:28.200
that works really well.

00:47:28.200 --> 00:47:29.480
And then you can push it to prod

00:47:29.480 --> 00:47:31.240
and have things run again in production.

00:47:31.240 --> 00:47:33.080
So that's DBT.

00:47:33.080 --> 00:47:35.520
We find it works really well.

00:47:35.520 --> 00:47:38.400
And a lot of our customers are actually using DBT as well.

00:47:40.000 --> 00:47:43.280
There's DuckDB, which is a great,

00:47:43.280 --> 00:47:46.880
it's like the SQL light for columnar databases, right?

00:47:46.880 --> 00:47:50.400
It's in process, it's fast, it's written by the Dutch.

00:47:50.400 --> 00:47:52.120
There's nothing you can't like about it.

00:47:52.120 --> 00:47:53.240
It's free. We love that.

00:47:53.240 --> 00:47:56.440
- It feels very comfortable in Python itself.

00:47:56.440 --> 00:47:58.400
- It does. It's so easy.

00:47:58.400 --> 00:47:59.280
Yeah, exactly.

00:47:59.280 --> 00:48:00.720
The Dutch have given us so much

00:48:00.720 --> 00:48:02.360
and they've asked nothing of us.

00:48:02.360 --> 00:48:04.540
So I'm always very thankful for them.

00:48:04.540 --> 00:48:07.520
It's fast. It's so fast.

00:48:08.640 --> 00:48:12.320
It's like, if you've ever used pandas

00:48:12.320 --> 00:48:15.200
for processing large volumes of data,

00:48:15.200 --> 00:48:16.960
you've occasionally hit memory limits

00:48:16.960 --> 00:48:20.920
or inefficiencies in doing these large aggregates.

00:48:20.920 --> 00:48:23.920
I won't go into all the reasons of why that is,

00:48:23.920 --> 00:48:26.600
but DuckDB sort of changes that

00:48:26.600 --> 00:48:28.760
because it's a fast serverless

00:48:28.760 --> 00:48:32.560
sort of C++ written tooling

00:48:32.560 --> 00:48:36.440
to do really fast vectorized work.

00:48:36.440 --> 00:48:38.720
And by that, I mean, like it works on columns.

00:48:38.720 --> 00:48:41.880
So typically in like SQL light, you're doing transactions.

00:48:41.880 --> 00:48:45.360
You're doing single row updates, writes, inserts,

00:48:45.360 --> 00:48:47.400
and SQL light is great at that.

00:48:47.400 --> 00:48:49.680
Where typical transactional databases fail

00:48:49.680 --> 00:48:53.480
or aren't as powerful is when you're doing aggregates,

00:48:53.480 --> 00:48:55.400
when you're looking at an entire column, right?

00:48:55.400 --> 00:48:57.080
Just the way they're architected.

00:48:57.080 --> 00:48:59.760
If you want to know the average, the median,

00:48:59.760 --> 00:49:02.760
the sum of some large number of columns,

00:49:02.760 --> 00:49:05.120
and you want to group that by a whole bunch of things,

00:49:05.120 --> 00:49:07.560
you want to know the first date someone did something

00:49:07.560 --> 00:49:08.840
and the last one,

00:49:08.840 --> 00:49:11.160
those types of vectorized operations,

00:49:11.160 --> 00:49:13.920
DuckDB is really, really fast at doing.

00:49:13.920 --> 00:49:17.800
And it's a great alternative to, for example, pandas,

00:49:17.800 --> 00:49:20.520
which can often hit memory limits

00:49:20.520 --> 00:49:22.520
and be a little bit slow in that regard.

00:49:22.520 --> 00:49:26.240
- Yeah, it looks like it has some pretty cool aspects,

00:49:26.240 --> 00:49:27.960
transactions, of course,

00:49:27.960 --> 00:49:32.960
but it also says direct parquet, CSV, and JSON querying.

00:49:33.280 --> 00:49:37.240
So if you've got a CSV file hanging around

00:49:37.240 --> 00:49:38.480
and you want to ask questions about it,

00:49:38.480 --> 00:49:41.880
or JSON or some of the data science stuff through parquet,

00:49:41.880 --> 00:49:47.160
turn a indexed proper query engine against it.

00:49:47.160 --> 00:49:49.920
Don't just use a dictionary or something, right?

00:49:49.920 --> 00:49:54.720
- Yeah, it's great for reading a CSV, zip files,

00:49:54.720 --> 00:49:59.360
tar files, parquets, partition parquet files,

00:49:59.360 --> 00:50:01.800
all that stuff that usually was really annoying

00:50:01.800 --> 00:50:03.400
to do and operate on,

00:50:03.400 --> 00:50:05.960
you can now install DuckDB.

00:50:05.960 --> 00:50:07.200
It's kind of great CLI too.

00:50:07.200 --> 00:50:11.160
So before you go out and like program your entire pipeline,

00:50:11.160 --> 00:50:13.760
you just run DuckDB and you can start writing SQL

00:50:13.760 --> 00:50:16.160
against CSV files and all this stuff

00:50:16.160 --> 00:50:17.800
to really understand your data

00:50:17.800 --> 00:50:19.800
and just really see how quick it is.

00:50:19.800 --> 00:50:24.040
I used it on a bird dataset that I had

00:50:24.040 --> 00:50:25.280
as an example project.

00:50:25.280 --> 00:50:27.680
And there was millions of rows

00:50:27.680 --> 00:50:29.000
and I was joining them together

00:50:29.000 --> 00:50:30.800
and doing massive group buys.

00:50:30.800 --> 00:50:32.920
And it was done in like seconds.

00:50:32.920 --> 00:50:34.320
And it was just hard for me to believe

00:50:34.320 --> 00:50:35.960
that it was even correct,

00:50:35.960 --> 00:50:36.800
'cause it was so quick.

00:50:36.800 --> 00:50:38.440
So it's wonderful.

00:50:38.440 --> 00:50:40.360
- I must have done that wrong somehow.

00:50:40.360 --> 00:50:43.360
'Cause it's done, it shouldn't be done.

00:50:43.360 --> 00:50:46.160
Yeah, and the fact it's in process

00:50:46.160 --> 00:50:50.440
means there's not a server for you to babysit,

00:50:50.440 --> 00:50:53.200
patch, make sure it's still running.

00:50:53.200 --> 00:50:56.520
It's accessible, but not too accessible, all that, right?

00:50:56.520 --> 00:50:57.600
- It's a pip install away,

00:50:57.600 --> 00:50:59.640
which is always, we love that, right?

00:51:00.640 --> 00:51:01.680
- Yeah, absolutely.

00:51:01.680 --> 00:51:06.480
You mentioned, or I guess I mentioned Parquet,

00:51:06.480 --> 00:51:09.360
but also Apache Arrow seems like it's making its way

00:51:09.360 --> 00:51:12.080
into a lot of different tools

00:51:12.080 --> 00:51:13.760
and sort of foundational,

00:51:13.760 --> 00:51:17.760
sort of high memory,

00:51:17.760 --> 00:51:20.200
high performance in memory processing.

00:51:20.200 --> 00:51:21.800
Have you used this, Eddie?

00:51:21.800 --> 00:51:23.800
- I've used it, especially through,

00:51:23.800 --> 00:51:26.920
like working through different languages.

00:51:26.920 --> 00:51:29.280
So moving data between Python and R

00:51:29.280 --> 00:51:30.720
is where I last used this.

00:51:30.720 --> 00:51:32.320
And Arrow's great at that.

00:51:32.320 --> 00:51:34.840
I believe Arrow is like the,

00:51:34.840 --> 00:51:39.840
underneath some of the Rust to Python as well.

00:51:39.840 --> 00:51:42.520
It's working there.

00:51:42.520 --> 00:51:45.440
So typically I don't use Arrow like directly myself,

00:51:45.440 --> 00:51:48.520
but it's in many of the tooling I use.

00:51:48.520 --> 00:51:50.120
It's a great product.

00:51:50.120 --> 00:51:54.360
And like so much of the ecosystem is now built on Arrow.

00:51:54.360 --> 00:51:55.200
- Yeah, I think a lot of it is,

00:51:55.200 --> 00:51:56.880
I feel like the first time I heard about it

00:51:56.880 --> 00:51:58.640
was through Polars.

00:51:58.640 --> 00:51:59.680
- That's right.

00:51:59.680 --> 00:52:00.800
- Yeah, I'm pretty sure,

00:52:00.800 --> 00:52:05.800
which is another Rust story for kind of like Pandas,

00:52:05.800 --> 00:52:09.680
but a little bit more fluent, lazy API.

00:52:09.680 --> 00:52:11.000
- Yes.

00:52:11.000 --> 00:52:12.720
We live in such great times, to be honest.

00:52:12.720 --> 00:52:15.720
So Polars is a,

00:52:15.720 --> 00:52:18.280
Python bindings for Rust, I believe,

00:52:18.280 --> 00:52:20.840
is kind of how I think about it.

00:52:20.840 --> 00:52:22.240
It does all the transformation in Rust,

00:52:22.240 --> 00:52:25.160
but you've had this Python interface to it.

00:52:25.160 --> 00:52:29.360
And it makes things again, incredibly fast.

00:52:29.360 --> 00:52:31.360
I would say similar in speed to DuckDP.

00:52:31.360 --> 00:52:33.520
They both are quite comparable sometimes.

00:52:33.520 --> 00:52:36.400
- Yeah, it also claims to have vectorized

00:52:36.400 --> 00:52:39.120
and column runner processing and all that kind of stuff.

00:52:39.120 --> 00:52:41.280
- Yeah, it's pretty incredible.

00:52:41.280 --> 00:52:44.120
So not a drop-in replacement for Pandas,

00:52:44.120 --> 00:52:47.040
but if you have the opportunity to use it

00:52:47.040 --> 00:52:49.320
and you don't need to use the full breadth

00:52:49.320 --> 00:52:50.200
of what Pandas offers,

00:52:50.200 --> 00:52:52.240
'cause Pandas is quite a huge package.

00:52:52.240 --> 00:52:53.680
There's a lot it does.

00:52:53.680 --> 00:52:55.400
But if you're just doing simple transforms,

00:52:55.400 --> 00:52:57.600
I think Polars is a great option to explore.

00:52:57.600 --> 00:53:01.080
- Yeah, I talked to Richie Vink,

00:53:01.080 --> 00:53:02.640
Vink who was part of that.

00:53:02.640 --> 00:53:06.200
And I think they explicitly chose

00:53:06.200 --> 00:53:09.080
to not try to make it a drop-in replacement for Pandas,

00:53:09.080 --> 00:53:10.360
but tried to choose an API

00:53:10.360 --> 00:53:12.960
that would allow the engine to be smarter.

00:53:12.960 --> 00:53:14.600
And go like, I see you're asking for this,

00:53:14.600 --> 00:53:17.560
but the step before you wanted this other thing,

00:53:17.560 --> 00:53:19.960
so let me do that transformation all in one shot.

00:53:19.960 --> 00:53:23.440
And a little bit like a query optimization engine.

00:53:23.440 --> 00:53:24.280
- Yep.

00:53:24.280 --> 00:53:28.600
- Yeah, what else is out there?

00:53:28.600 --> 00:53:30.240
We got time for just a couple more.

00:53:30.240 --> 00:53:31.400
If there's anything that you're like,

00:53:31.400 --> 00:53:32.640
oh yeah, people use this all the time.

00:53:32.640 --> 00:53:34.880
Obviously the databases you've said,

00:53:34.880 --> 00:53:38.920
Postgres, Snowflake, et cetera.

00:53:38.920 --> 00:53:42.760
- Yeah, there's so much.

00:53:42.760 --> 00:53:46.600
So another little one I like, it's called DLT, DLT Hub.

00:53:46.600 --> 00:53:50.600
It's getting a lot of attraction as well.

00:53:50.600 --> 00:53:53.800
And what I like about it is how lightweight it is.

00:53:53.800 --> 00:53:55.960
I'm such a big fan of lightweight tooling.

00:53:55.960 --> 00:53:57.800
That's not massive frameworks.

00:53:57.800 --> 00:54:03.120
Loading data is I think still kind of yucky in many ways.

00:54:03.120 --> 00:54:04.400
It's not fun.

00:54:04.400 --> 00:54:08.080
And DLT makes it a little bit simpler and easier to do so.

00:54:08.080 --> 00:54:10.880
So that's one I would recommend people just to look into

00:54:10.880 --> 00:54:15.440
if you got to either ingest data from some API,

00:54:15.440 --> 00:54:18.080
some website, some CSV file.

00:54:18.080 --> 00:54:20.560
It's a great way to do that.

00:54:20.560 --> 00:54:22.640
- It claims it's the Python library

00:54:22.640 --> 00:54:26.040
for data teams loading data into unexpected places.

00:54:26.040 --> 00:54:27.040
Very interesting.

00:54:27.040 --> 00:54:28.040
- Yes, that's great.

00:54:28.040 --> 00:54:31.320
- Yeah, this looks cool.

00:54:31.320 --> 00:54:38.120
All right, well, I guess maybe let's talk about,

00:54:38.120 --> 00:54:40.480
let's talk business and then we can talk about what's next

00:54:40.480 --> 00:54:42.200
and then we'll probably be out of time.

00:54:42.200 --> 00:54:45.880
I'm always fascinated.

00:54:45.880 --> 00:54:48.440
I think there's starting to be a bit of a blueprint for this,

00:54:48.440 --> 00:54:53.280
but companies that take a thing, they make it

00:54:53.280 --> 00:54:56.040
and they give it away and then they have a company around it.

00:54:56.040 --> 00:55:00.320
And congratulations to you all for doing that, right?

00:55:00.320 --> 00:55:02.440
And a lot of it seems to kind of center

00:55:02.440 --> 00:55:04.880
around the open core model,

00:55:04.880 --> 00:55:08.000
which I don't know if that's exactly

00:55:08.000 --> 00:55:10.360
how you would characterize yourself,

00:55:10.360 --> 00:55:12.240
but maybe just talk about the business side.

00:55:12.240 --> 00:55:16.040
'Cause I know there's many successful open source projects

00:55:16.040 --> 00:55:18.840
that don't necessarily result in full-time jobs

00:55:18.840 --> 00:55:21.680
or companies if people were to want that.

00:55:21.680 --> 00:55:24.360
- Yeah, it's a really interesting place.

00:55:24.360 --> 00:55:27.720
And I don't think it's one that anyone

00:55:27.720 --> 00:55:30.160
has truly figured out well,

00:55:30.160 --> 00:55:33.320
I can say this is the way forward for everyone,

00:55:33.320 --> 00:55:34.280
but it is something we're trying.

00:55:34.280 --> 00:55:37.000
And I think for Dexter, I think it's working pretty well.

00:55:37.000 --> 00:55:42.000
And what I think is really powerful about Dexter

00:55:42.000 --> 00:55:45.440
is like the open source product is really, really good.

00:55:45.440 --> 00:55:48.760
And it hasn't really been limited in many ways

00:55:48.760 --> 00:55:52.960
in order to drive like cloud product consumption.

00:55:52.960 --> 00:55:54.680
We really believe that there's actual value

00:55:54.680 --> 00:55:56.640
in that separation of these things.

00:55:56.640 --> 00:55:57.960
There are some things that we just can't do

00:55:57.960 --> 00:55:59.400
in the open source platform.

00:55:59.400 --> 00:56:03.040
For example, there's pipelines on cloud that involve

00:56:03.040 --> 00:56:04.640
ingesting data through our own systems

00:56:04.640 --> 00:56:06.160
in order to do reporting,

00:56:06.160 --> 00:56:07.840
which just doesn't make sense to do

00:56:07.840 --> 00:56:09.200
on the open source system.

00:56:09.200 --> 00:56:11.600
It makes the product way too complex.

00:56:11.600 --> 00:56:13.920
But for the most part, I think Dexter open source,

00:56:13.920 --> 00:56:15.160
we really believe that like just getting it

00:56:15.160 --> 00:56:16.840
in the hands of developers is the best way

00:56:16.840 --> 00:56:18.480
to prove the value of it.

00:56:18.480 --> 00:56:20.560
And if we can build a business on top of that,

00:56:20.560 --> 00:56:22.920
I think we're all super happy to do so.

00:56:22.920 --> 00:56:27.160
It's nice that we get to sort of drive both sides of it.

00:56:27.160 --> 00:56:29.960
To me, that's like one of the more exciting parts, right?

00:56:29.960 --> 00:56:34.360
A lot of the development that we do in Dexter open source

00:56:34.360 --> 00:56:37.280
is driven by people who are paid through,

00:56:37.280 --> 00:56:39.400
what happens on Dexter cloud.

00:56:39.400 --> 00:56:41.960
And I think from what I can tell,

00:56:41.960 --> 00:56:44.640
there's no better way to build open source product

00:56:44.640 --> 00:56:46.760
than to have people who are adequately paid

00:56:46.760 --> 00:56:48.320
to develop that product.

00:56:48.320 --> 00:56:50.120
Otherwise it can be a labor of love,

00:56:50.120 --> 00:56:52.600
but one that doesn't last for very long.

00:56:52.600 --> 00:56:54.200
- Yeah, whenever I think about building software,

00:56:54.200 --> 00:56:57.760
there's like 80% of it that's super exciting and fun,

00:56:57.760 --> 00:57:00.320
10% and then there's that little sliver

00:57:00.320 --> 00:57:02.760
of like really fine polish,

00:57:02.760 --> 00:57:06.320
that if it's not just your job to make that thing polished,

00:57:06.320 --> 00:57:08.360
you're just for the most part,

00:57:08.360 --> 00:57:10.280
just not gonna polish that bit, right?

00:57:11.120 --> 00:57:15.360
- It's tough, UI, design, support.

00:57:15.360 --> 00:57:17.840
There's all these things that go into making a software

00:57:17.840 --> 00:57:19.920
like really extraordinary.

00:57:19.920 --> 00:57:21.400
That's really, really tough to do.

00:57:21.400 --> 00:57:25.800
And I think I really like the open source business model.

00:57:25.800 --> 00:57:28.480
I think for me being able to just try something,

00:57:28.480 --> 00:57:29.640
not having talked to sales

00:57:29.640 --> 00:57:32.600
and being able to just deploy locally and test it out

00:57:32.600 --> 00:57:33.560
and see if this works.

00:57:33.560 --> 00:57:37.840
And if I choose to do so, deploy it in production,

00:57:37.840 --> 00:57:39.440
or if I bought the cloud product

00:57:39.440 --> 00:57:41.840
and I don't like the direction that I was going,

00:57:41.840 --> 00:57:44.360
I can even go open source as well.

00:57:44.360 --> 00:57:45.760
That's pretty compelling to me.

00:57:45.760 --> 00:57:47.600
- Yeah, for sure it is.

00:57:47.600 --> 00:57:52.400
And I think the more moving pieces of infrastructure,

00:57:52.400 --> 00:57:55.400
more uptime you want and all those types of things,

00:57:55.400 --> 00:57:57.880
the more somebody who's maybe a programmer,

00:57:57.880 --> 00:58:01.080
but not a DevOps infrastructure person,

00:58:01.080 --> 00:58:02.680
but needs to have it there, right?

00:58:02.680 --> 00:58:04.640
Like that's an opportunity as well, right?

00:58:04.640 --> 00:58:07.160
For you to say, look, you can write the code.

00:58:07.160 --> 00:58:08.960
We made it cool for you to write the code,

00:58:08.960 --> 00:58:12.760
but you don't have to get notified

00:58:12.760 --> 00:58:14.360
when the server's down or whatever.

00:58:14.360 --> 00:58:15.560
Like, we'll just take care of that for you.

00:58:15.560 --> 00:58:17.120
That's pretty awesome.

00:58:17.120 --> 00:58:19.480
- Yeah, and it's efficiencies of scale as well, right?

00:58:19.480 --> 00:58:21.880
Like we've learned the same mistakes over and over again,

00:58:21.880 --> 00:58:24.800
so you don't have to, which is nice.

00:58:24.800 --> 00:58:27.360
I don't know how many people who want to maintain servers,

00:58:27.360 --> 00:58:30.960
but people do, and they're more than welcome to

00:58:30.960 --> 00:58:33.560
if that's how they choose to do so.

00:58:33.560 --> 00:58:34.400
- Yeah, for sure.

00:58:34.400 --> 00:58:37.240
All right, we're just about out of time.

00:58:37.240 --> 00:58:39.080
Let's close up our conversation

00:58:39.080 --> 00:58:42.200
with where are things going for Dagster?

00:58:42.200 --> 00:58:44.120
Like what's on the roadmap?

00:58:44.120 --> 00:58:46.360
What are you excited about?

00:58:46.360 --> 00:58:47.560
- Oh, that's a good one.

00:58:47.560 --> 00:58:52.320
I think we've actually published our roadmap online

00:58:52.320 --> 00:58:53.880
somewhere if you search Dagster roadmap,

00:58:53.880 --> 00:58:55.320
it's probably out there.

00:58:55.320 --> 00:58:56.760
I think for the most part,

00:58:56.760 --> 00:58:59.200
that hasn't changed much going into 2024,

00:58:59.200 --> 00:59:00.800
though we may update it.

00:59:00.800 --> 00:59:02.400
Ah, there it is.

00:59:02.400 --> 00:59:05.640
We're really just doubling down on what we've built already.

00:59:05.640 --> 00:59:07.560
I think there's a lot of work we can do

00:59:07.560 --> 00:59:10.040
on the product itself to make it easier to use,

00:59:10.040 --> 00:59:11.520
easier to understand.

00:59:11.520 --> 00:59:13.240
My team specifically is really focused

00:59:13.240 --> 00:59:15.080
around the education piece.

00:59:15.080 --> 00:59:18.720
And so we launched Dagster University's first module,

00:59:18.720 --> 00:59:20.640
which helps you really understand the core,

00:59:20.640 --> 00:59:22.640
like concepts around Dagster.

00:59:22.640 --> 00:59:24.720
Our next module is coming up in a couple months,

00:59:24.720 --> 00:59:26.960
and that'll be around using Dagster with dbt,

00:59:26.960 --> 00:59:28.880
which is our most popular integration.

00:59:28.880 --> 00:59:31.640
We're building up more integrations as well.

00:59:31.640 --> 00:59:35.880
So I built a little integration called embedded ELT

00:59:35.880 --> 00:59:37.840
that makes it easy to ingest data.

00:59:37.840 --> 00:59:39.360
But I wanna actually build an integration

00:59:39.360 --> 00:59:42.080
with DLT as well, DLT hub.

00:59:42.080 --> 00:59:43.480
So we'll be doing that.

00:59:43.480 --> 00:59:45.640
And there's more coming down the pipe,

00:59:45.640 --> 00:59:47.600
but I don't know how much I can say.

00:59:47.600 --> 00:59:50.360
Look forward to an event in April

00:59:50.360 --> 00:59:53.800
where we'll have a launch event on all that's coming.

00:59:53.800 --> 00:59:54.640
- Nice.

00:59:54.640 --> 00:59:56.680
Is that an online thing people can attend

00:59:56.680 --> 00:59:57.560
or something like that? - Exactly.

00:59:57.560 --> 00:59:59.240
Yeah, there'll be some announcement there

00:59:59.240 --> 01:00:01.880
on the Dagster website on that.

01:00:01.880 --> 01:00:04.680
Maybe I will call it one thing that's actually really fun.

01:00:04.680 --> 01:00:07.320
It's called Dagster Open Platform.

01:00:07.320 --> 01:00:11.640
It's a GitHub repo that we launched a couple months ago,

01:00:11.640 --> 01:00:13.160
I wanna say.

01:00:13.160 --> 01:00:16.280
And we took our internal,

01:00:16.280 --> 01:00:20.920
I should go back one more, sorry.

01:00:20.920 --> 01:00:23.760
It's like GitHub, Dagster Open Platform and GitHub.

01:00:23.760 --> 01:00:28.200
- I have it somewhere.

01:00:28.200 --> 01:00:30.080
- Yeah, if you go.

01:00:30.080 --> 01:00:33.880
- It's here under the organization.

01:00:33.880 --> 01:00:38.880
- Yes, it should be somewhere in here.

01:00:38.880 --> 01:00:42.360
There it is, Dagster Open Platform on GitHub.

01:00:42.360 --> 01:00:45.240
And it's really a clone of our production pipelines

01:00:45.240 --> 01:00:46.080
for the most part.

01:00:46.080 --> 01:00:47.920
There's some things we've chosen to ignore

01:00:47.920 --> 01:00:49.240
because they're sensitive,

01:00:49.240 --> 01:00:50.280
but as much as possible,

01:00:50.280 --> 01:00:53.400
we've defaulted to making it public and open.

01:00:53.400 --> 01:00:56.200
And the whole reason behind this was because,

01:00:56.200 --> 01:00:57.920
as data engineers, it's often hard to see

01:00:57.920 --> 01:00:59.720
how other data engineers write code.

01:00:59.720 --> 01:01:02.880
We get to see how software engineers write code quite often,

01:01:02.880 --> 01:01:07.200
but most people don't wanna share their data platforms

01:01:07.200 --> 01:01:09.000
for various good reasons.

01:01:09.000 --> 01:01:13.280
- Well, also, there's smaller teams or maybe just one person.

01:01:13.280 --> 01:01:16.360
And then those pipelines are so integrated

01:01:16.360 --> 01:01:20.200
into your specific infrastructure, right?

01:01:20.200 --> 01:01:23.480
So it's not like, well, here's a web framework to share.

01:01:23.480 --> 01:01:26.000
Here's how we integrate into that one weird API

01:01:26.000 --> 01:01:28.000
that we have that no one else has.

01:01:28.000 --> 01:01:31.160
So it's no point in publishing it to you, right?

01:01:31.160 --> 01:01:32.400
- That's typically how it goes,

01:01:32.400 --> 01:01:34.360
or they're so large that they're afraid

01:01:34.360 --> 01:01:36.720
that there's some important information

01:01:36.720 --> 01:01:39.080
that they just don't wanna take the risk on.

01:01:39.080 --> 01:01:40.640
So we built something that's in the middle

01:01:40.640 --> 01:01:44.400
where we've taken as much as we can and we've publicized it.

01:01:44.400 --> 01:01:46.080
And you can't run this on your own.

01:01:46.080 --> 01:01:46.920
That's not the point.

01:01:46.920 --> 01:01:48.880
The point is to look at the code and see,

01:01:48.880 --> 01:01:50.120
how does Dagster use Dagster

01:01:50.120 --> 01:01:51.600
and what does that look like?

01:01:51.600 --> 01:01:52.440
- Nice, okay.

01:01:52.440 --> 01:01:55.720
All right, well, I'll put a link to that in the show notes

01:01:55.720 --> 01:01:57.200
and people can check it out.

01:01:57.200 --> 01:01:59.160
- Appreciate it.

01:01:59.160 --> 01:02:01.640
- Yeah, I guess let's wrap it up with the final call

01:02:01.640 --> 01:02:03.800
to action people are interested in Dagster.

01:02:03.800 --> 01:02:04.640
How do they get started?

01:02:04.640 --> 01:02:05.840
What do you tell them?

01:02:05.840 --> 01:02:09.840
- Oh yeah, dagster.io is probably the greatest place to start.

01:02:09.840 --> 01:02:12.080
You can try the cloud product.

01:02:12.080 --> 01:02:13.640
We have free self-serve

01:02:13.640 --> 01:02:17.120
or you can try the local install as well.

01:02:17.120 --> 01:02:20.200
If you get stuck, a great place to join is our Slack channel

01:02:20.200 --> 01:02:22.000
which is up on our website.

01:02:22.000 --> 01:02:24.240
There's even a Ask AI channel

01:02:24.240 --> 01:02:26.160
where you can just talk to a Slack bot

01:02:26.160 --> 01:02:28.880
that's been trained on all our GitHub issues and discussions

01:02:28.880 --> 01:02:32.240
and it's surprisingly good at walking you through,

01:02:32.240 --> 01:02:34.840
any debugging, any issues or even advice.

01:02:34.840 --> 01:02:36.080
- That's pretty excellent actually.

01:02:36.080 --> 01:02:37.280
- Yeah, it's real fun.

01:02:37.280 --> 01:02:38.120
It's really fun.

01:02:38.120 --> 01:02:39.960
And if that doesn't work, we're also there in the community

01:02:39.960 --> 01:02:42.160
where you can just chat to us as well.

01:02:42.160 --> 01:02:43.760
- Cool, all right.

01:02:43.760 --> 01:02:46.080
Well, Pedram, thank you for being on the show.

01:02:46.080 --> 01:02:48.560
Thanks for all the work on Dagster and sharing it with us.

01:02:48.560 --> 01:02:49.640
- Thank you, Michael.

01:02:49.640 --> 01:02:50.880
- You bet, see you later.

01:02:50.880 --> 01:02:53.880
[getthequad.com/gradschools/podcast]

