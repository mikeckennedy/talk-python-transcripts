WEBVTT

00:00:00.000 --> 00:00:01.000
Hey, Max.


00:00:01.000 --> 00:00:02.000
Hey, hey.


00:00:02.000 --> 00:00:03.000
Hello.


00:00:03.000 --> 00:00:04.000
Hey, hey.


00:00:04.000 --> 00:00:05.000
Hello.


00:00:05.000 --> 00:00:10.040
Well, welcome to the YouTube channel and in just a moment to the podcast.


00:00:10.040 --> 00:00:14.320
And everyone out there, if you're watching, please put your thoughts and comments into


00:00:14.320 --> 00:00:17.880
the live chat and we'll try to make it part of the show if you're watching afterwards.


00:00:17.880 --> 00:00:20.360
Well, no live chat, but thanks for watching.


00:00:20.360 --> 00:00:23.320
And with that, Max, welcome to Talk 5th Enemy.


00:00:23.320 --> 00:00:26.000
Well, it's good to be back on the show.


00:00:26.000 --> 00:00:28.600
- No, I know it's live too, so no mistakes.


00:00:28.600 --> 00:00:31.360
I'm gonna try to not say anything outrageous.


00:00:31.360 --> 00:00:33.880
- People get the unfiltered versions, though.


00:00:33.880 --> 00:00:35.320
Absolutely, absolutely.


00:00:35.320 --> 00:00:37.880
Other people come check out the live show.


00:00:37.880 --> 00:00:39.520
Yeah, so welcome back.


00:00:39.520 --> 00:00:42.360
It's been a little while since you were on the show,


00:00:42.360 --> 00:00:44.320
about since September.


00:00:44.320 --> 00:00:46.440
We talked about supersets.


00:00:46.440 --> 00:00:48.480
We also talked a little bit about Airflow,


00:00:48.480 --> 00:00:50.720
some of the stuff that you've been working on.


00:00:50.720 --> 00:00:54.020
And now we're kind of circling back


00:00:54.020 --> 00:00:56.140
through this data side of things,


00:00:56.140 --> 00:00:59.800
but trying to bring AI into the whole story.


00:00:59.800 --> 00:01:01.740
So pretty cool project


00:01:01.740 --> 00:01:04.100
I'm looking forward to talking to you about.


00:01:04.100 --> 00:01:05.840
- Awesome, excited to talk about it too.


00:01:05.840 --> 00:01:09.080
And these things are related in many ways.


00:01:09.080 --> 00:01:12.500
Like one common foundation is Python.


00:01:12.500 --> 00:01:14.740
Like a lot of these projects are in Python.


00:01:14.740 --> 00:01:15.820
They're data related.


00:01:15.820 --> 00:01:18.460
And here, prompt demise and prompt engineering


00:01:18.460 --> 00:01:22.420
and integrating AI is related in a way


00:01:22.420 --> 00:01:26.760
that we're building some AI features into super set right now


00:01:26.760 --> 00:01:30.940
and into preset so it ties things together in some ways.


00:01:30.940 --> 00:01:35.560
- Yeah, I can certainly see a lot of synergy here.


00:01:35.560 --> 00:01:37.320
So I guess before we dive into it,


00:01:37.320 --> 00:01:39.400
it hasn't been that long since you were on the show,


00:01:39.400 --> 00:01:41.660
but give us a quick update,


00:01:41.660 --> 00:01:42.840
just a bit about your background


00:01:42.840 --> 00:01:44.520
for people who don't know you before


00:01:44.520 --> 00:01:47.400
and what you've been up to.


00:01:47.400 --> 00:01:52.400
- Yeah, so my career is a career of like maybe 20 or so


00:01:52.400 --> 00:02:02.040
years in data building, doing data engineering, trying to make data useful for organizations.


00:02:02.040 --> 00:02:05.440
Over the past decade or so, I've been very involved in open source.


00:02:05.440 --> 00:02:08.800
I started Apache Airflow in 2014.


00:02:08.800 --> 00:02:13.440
So for those not familiar with Airflow, though it's pretty well known now, it's used at,


00:02:13.440 --> 00:02:19.480
I heard, I think it's like tens of thousands, I think above 100,000 companies are using


00:02:19.480 --> 00:02:22.360
Apache Airflow, which is kind of insane to think about.


00:02:22.360 --> 00:02:27.280
like you started a little project. So for me, I started this project at Airbnb and it


00:02:27.280 --> 00:02:32.520
really took off. And I think it's just like great called a project community fit. Like


00:02:32.520 --> 00:02:37.520
people really needed that. It was the right abstraction for people at the time and still


00:02:37.520 --> 00:02:44.000
today. And it just really took off. So I was working on orchestration and then I was like,


00:02:44.000 --> 00:02:50.680
I just love things that are visual and interactive. So there was no great open source BI tool


00:02:50.680 --> 00:02:54.840
all their business intelligence. So the sole data, data, dashboarding, exploration,


00:02:54.840 --> 00:03:01.400
SQL IDE. So it's a playground for people trying to understand and visualize and explore data.


00:03:01.400 --> 00:03:07.720
So I started working on Apache SuperSend in 2000, I think it was like 15 or 16 at Airbnb too. And we


00:03:07.720 --> 00:03:13.320
also brought that to the Apache Software Foundation. So again, like a very, very popular


00:03:13.320 --> 00:03:18.520
open source project that's used in like tens of thousands, a hundred thousand organizations or so.


00:03:19.560 --> 00:03:26.280
And today, it has become a super great open source alternative to Tableau, Looker,


00:03:26.280 --> 00:03:30.360
like all those business intelligence tool is very viable for organizations.


00:03:30.360 --> 00:03:35.400
And then quick, quick plug that preset I started a company, I started some,


00:03:35.400 --> 00:03:39.560
also an entrepreneur, I started a company a little bit more than four years ago around


00:03:39.560 --> 00:03:46.840
Apache Superset. And the idea is to bring Superset to the masses. So it's really like hosted,


00:03:47.400 --> 00:03:50.760
manage state-of-the-art Apache Super Set for everyone


00:03:50.760 --> 00:03:51.960
with some bells and whistles.


00:03:51.960 --> 00:03:54.680
So the best Super Set you can run,


00:03:54.680 --> 00:03:56.200
there's a free version too.


00:03:56.200 --> 00:03:58.920
So you can go and play and try it,


00:03:58.920 --> 00:04:00.280
today gets started in five minutes.


00:04:00.280 --> 00:04:03.800
So it's a little bit of a commercial pointer,


00:04:03.800 --> 00:04:06.440
but also very relevant to what I've been doing,


00:04:06.440 --> 00:04:07.920
personally over the past three or four years.


00:04:07.920 --> 00:04:10.000
- Sure, it's some of the inspiration


00:04:10.000 --> 00:04:11.760
for some of the things we're gonna talk about as well,


00:04:11.760 --> 00:04:14.920
and trying to bring some of the AI craziness


00:04:14.920 --> 00:04:16.520
back to products, right?


00:04:16.520 --> 00:04:18.880
from an engineering perspective, not just a,


00:04:18.880 --> 00:04:22.960
"Hey, look, I asked what basketball team was gonna,


00:04:22.960 --> 00:04:24.320
"you know, win this year."


00:04:24.320 --> 00:04:26.520
And it gave me this answer, right?


00:04:26.520 --> 00:04:28.120
- It's like, and I, caveats,


00:04:28.120 --> 00:04:31.080
I don't know anything that happened since 2021.


00:04:31.080 --> 00:04:33.520
So AI, or, I mean, OEM AI specifically,


00:04:33.520 --> 00:04:34.880
Bart is a little bit better at that,


00:04:34.880 --> 00:04:36.680
but it's like, you know,


00:04:36.680 --> 00:04:38.600
the last thing I read off of the internet


00:04:38.600 --> 00:04:40.320
was in fall 2021.


00:04:40.320 --> 00:04:43.560
Gosh, it makes some things a little bit challenging.


00:04:43.560 --> 00:04:45.480
But yeah, so we're looking, we're building, you know,


00:04:45.480 --> 00:04:47.720
AI features into preset, you know,


00:04:47.720 --> 00:04:49.040
as a commercial open source company,


00:04:49.040 --> 00:04:51.800
we need to build some differentiators too from supersets.


00:04:51.800 --> 00:04:54.960
We contribute a huge amount, like maybe 50, 80%


00:04:54.960 --> 00:04:57.820
of the work we do at preset is contributed back to superset,


00:04:57.820 --> 00:05:00.220
but we're looking to build differentiators.


00:05:00.220 --> 00:05:04.080
And we feel like AI is a great kind of commercial


00:05:04.080 --> 00:05:06.760
differentiator too on top of superset


00:05:06.760 --> 00:05:09.040
that makes people even more interested to come


00:05:09.040 --> 00:05:12.320
and run preset too, so.


00:05:12.320 --> 00:05:13.160
- Yeah, excellent.


00:05:13.160 --> 00:05:17.560
And people, you say they were popular projects,


00:05:17.560 --> 00:05:21.320
like Airflow has 30,000 stars,


00:05:21.320 --> 00:05:24.040
Apache SuperSet has 50,000 stars,


00:05:24.040 --> 00:05:26.760
which puts it on par with Django and Flask


00:05:26.760 --> 00:05:28.800
for people sort of mental models out there,


00:05:28.800 --> 00:05:30.600
which is, I would say it's pretty well known.


00:05:30.600 --> 00:05:31.720
So awesome.


00:05:31.720 --> 00:05:36.200
- Yeah, stars is kind of vanity metric in some ways, right?


00:05:36.200 --> 00:05:39.560
Not necessarily usefulness or value delivery,


00:05:39.560 --> 00:05:42.880
but it's a proxy for popularity and hype, you know?


00:05:42.880 --> 00:05:48.720
So it gives a good sense and I think I get 50,000 stars if you look at,


00:05:48.720 --> 00:05:51.720
it's probably in the top 100 of GitHub projects.


00:05:51.720 --> 00:05:57.240
If you remove the top 100, there's a lot of documentations and


00:05:57.240 --> 00:06:00.600
guides and things that are not really open source projects.


00:06:00.600 --> 00:06:06.520
It's probably like top 100 open source project-ish in both cases.


00:06:06.520 --> 00:06:07.080
>> Right.


00:06:07.080 --> 00:06:07.800
>> It's really cool.


00:06:07.800 --> 00:06:11.800
It's like you start a project and you don't know whether it's gonna take off and


00:06:11.800 --> 00:06:15.440
and it's like, wow, it's just nice to see that.


00:06:15.440 --> 00:06:16.400
- Yeah, absolutely.


00:06:16.400 --> 00:06:18.220
I mean, on one hand it's nice,


00:06:18.220 --> 00:06:20.460
but it doesn't necessarily make it better.


00:06:20.460 --> 00:06:22.160
But it does mean there's a lot of people using it.


00:06:22.160 --> 00:06:23.280
There's a lot of polish.


00:06:23.280 --> 00:06:27.720
There's a lot of PRs and stuff that have been submitted


00:06:27.720 --> 00:06:28.800
to make it work.


00:06:28.800 --> 00:06:30.360
A lot of things that can plug into, right?


00:06:30.360 --> 00:06:31.760
So there's certainly a value


00:06:31.760 --> 00:06:34.560
for having a project popular versus unpopular.


00:06:34.560 --> 00:06:35.400
- Oh my God, yes.


00:06:35.400 --> 00:06:36.760
And I would say one thing is,


00:06:36.760 --> 00:06:41.760
all the secondary assets outside of the core projects


00:06:41.760 --> 00:06:46.640
documentation, and there will be a lot of like use cases and testimonials and


00:06:46.640 --> 00:06:52.400
reviews and people bending the framework in various ways and forks and plugins.


00:06:52.400 --> 00:06:57.560
Another thing too that people I think don't really understand the value of in


00:06:57.560 --> 00:07:02.760
software and open sources or I'm sure people understand the value but it's not


00:07:02.760 --> 00:07:06.580
talked about it's just a whole battle-tested thing like when something


00:07:06.580 --> 00:07:12.100
has run at thousands of organizations in production for a long time.


00:07:12.100 --> 00:07:18.100
There's a lot of things that happen in a software that are very, very valuable for the incremental


00:07:18.100 --> 00:07:20.140
organization adopting it.


00:07:20.140 --> 00:07:22.180
Yeah, absolutely.


00:07:22.180 --> 00:07:27.100
Well, let's talk large language models for a second.


00:07:27.100 --> 00:07:31.180
So AI means different things to different people, right?


00:07:31.180 --> 00:07:38.980
And they kind of get carved off as they find some kind of productive productized use.


00:07:38.980 --> 00:07:43.580
AI is this general term and like, oh, machine learning is now a thing that we've done or


00:07:43.580 --> 00:07:45.460
computer vision is a thing we've done.


00:07:45.460 --> 00:07:51.660
And the large language model, they're sort of starting to find their own special space.


00:07:51.660 --> 00:07:58.260
So maybe we could talk a bit about a couple of examples just so people get a sense.


00:07:58.260 --> 00:08:02.020
To me, ChatGPT seems like the most well-known.


00:08:02.020 --> 00:08:03.440
What do you think?


00:08:03.440 --> 00:08:06.100
- Yeah, I mean, well, I'll say if you think about


00:08:06.100 --> 00:08:08.660
what is a large language model,


00:08:08.660 --> 00:08:10.420
what are some of the leaps there?


00:08:10.420 --> 00:08:11.820
And I'm not an expert,


00:08:11.820 --> 00:08:14.860
so I'm gonna try to not put my foot in my mouth,


00:08:14.860 --> 00:08:17.260
but some things that I think are interesting.


00:08:17.260 --> 00:08:20.980
A large language model is a big neural network


00:08:20.980 --> 00:08:24.420
that is trained on a big corpus of text.


00:08:24.420 --> 00:08:26.300
I think one of the big leaps we've seen


00:08:26.300 --> 00:08:28.500
as unsupervised learning.


00:08:28.500 --> 00:08:32.500
So like really often like in machine learning in the past


00:08:32.500 --> 00:08:37.400
or pre-LLMs, we would have very specific


00:08:37.400 --> 00:08:40.860
like training set and outcomes we were looking for.


00:08:40.860 --> 00:08:42.620
And then the training data would have to be


00:08:42.620 --> 00:08:44.020
really structured.


00:08:44.020 --> 00:08:45.900
Here, what we're doing with large language models


00:08:45.900 --> 00:08:49.940
is feeding a lot of, huge corpus of text


00:08:49.940 --> 00:08:52.220
and what the large language model is trying to do


00:08:52.220 --> 00:08:54.420
or resolve is to chain words, right?


00:08:54.420 --> 00:08:56.980
is trying to predict the next word,


00:08:56.980 --> 00:09:01.620
which seems like you would be able to put words together


00:09:01.620 --> 00:09:04.020
that kind of makes sense,


00:09:04.020 --> 00:09:06.500
but like you wouldn't think that consciousness,


00:09:06.500 --> 00:09:07.380
not just like consciousness,


00:09:07.380 --> 00:09:08.860
but intelligence would come out of that,


00:09:08.860 --> 00:09:10.140
but somehow it does, right?


00:09:10.140 --> 00:09:12.740
Like if you chain, it's like, if you say,


00:09:12.740 --> 00:09:15.260
you know, "Hupty Dutty sits on A,"


00:09:15.260 --> 00:09:17.540
it's really clear it's gonna be wall,


00:09:17.540 --> 00:09:19.300
you know, the next word.


00:09:19.300 --> 00:09:22.340
But if you push this idea much further


00:09:22.340 --> 00:09:24.980
with a very large corpus of like human knowledge,


00:09:24.980 --> 00:09:27.220
somehow there's some really amazing stuff


00:09:27.220 --> 00:09:30.260
that does happen on these artistic language models.


00:09:30.260 --> 00:09:33.500
And I think that realization happened around,


00:09:33.500 --> 00:09:38.500
you know, Chad, at GPT-3, 3.5 getting pretty good


00:09:38.500 --> 00:09:40.220
and then at four, we're like, oh my God,


00:09:40.220 --> 00:09:44.040
this stuff can really kind of seems like it can think


00:09:44.040 --> 00:09:46.380
or be smart or be very helpful.


00:09:46.380 --> 00:09:49.060
- Yeah, the thing that I think impresses me the most


00:09:49.060 --> 00:09:51.300
about these is they seem,


00:09:51.300 --> 00:09:53.540
and people can tell me it's statistics


00:09:53.540 --> 00:09:55.340
and I'll believe them,


00:09:55.340 --> 00:09:57.340
but it seems like they have an understanding


00:09:57.340 --> 00:10:00.080
of the context of what they're talking about


00:10:00.080 --> 00:10:03.220
more than just predicting like Humpty Dumpty sat on the what?


00:10:03.220 --> 00:10:04.380
It sat on the wall, right?


00:10:04.380 --> 00:10:07.660
Obviously that's what was likely to come next


00:10:07.660 --> 00:10:09.260
when you see that set of words.


00:10:09.260 --> 00:10:12.740
But there's an example that I like to play with,


00:10:12.740 --> 00:10:13.580
which I copied here.


00:10:13.580 --> 00:10:14.660
I'll give it a little thing.


00:10:14.660 --> 00:10:19.060
I'll say, "Hey, here's a program, Python program.


00:10:19.060 --> 00:10:20.380
I'm gonna ask you questions about it.


00:10:20.380 --> 00:10:21.200
Let's call it Arrow."


00:10:21.200 --> 00:10:24.320
And it's like this highly nested program


00:10:24.320 --> 00:10:27.300
that function that tests whether something's a platypus.


00:10:27.300 --> 00:10:28.740
I saw this example somewhere and I thought,


00:10:28.740 --> 00:10:31.100
"Okay, this is pretty cool."


00:10:31.100 --> 00:10:34.620
But it has this, if it's a mammal,


00:10:34.620 --> 00:10:37.260
then if it has fur, then if it has a beak,


00:10:37.260 --> 00:10:38.980
then if it has a tail,


00:10:38.980 --> 00:10:41.340
and you can just do stuff that's really interesting.


00:10:41.340 --> 00:10:43.460
Like I'll ask it to a...


00:10:43.460 --> 00:10:45.780
- Is bird or something like that or.


00:10:45.780 --> 00:10:47.700
- Yeah, yeah, yeah, rewrite it,


00:10:47.700 --> 00:10:52.700
write it using guarding clauses to be not nested, right?


00:10:52.700 --> 00:10:56.380
- Oh yeah.


00:10:56.380 --> 00:10:59.420
- Right, and it'll say, sure, here we go.


00:10:59.420 --> 00:11:01.500
And instead of being, if this, then nest,


00:11:01.500 --> 00:11:03.380
if this, then if this, it'll do, if not,


00:11:03.380 --> 00:11:04.460
if not return false, right?


00:11:04.460 --> 00:11:06.060
Which is really cool.


00:11:06.060 --> 00:11:08.100
And that's kind of a pretty interesting one,


00:11:08.100 --> 00:11:11.300
but like, this is the one,


00:11:11.300 --> 00:11:13.280
this is the example that I think is crazy.


00:11:13.280 --> 00:11:18.280
is rewrite arrow to test for crocodiles.


00:11:18.280 --> 00:11:23.040
- They're using what people would call a one shot,


00:11:23.040 --> 00:11:24.560
a few shot example of like,


00:11:24.560 --> 00:11:28.560
hey, here's an example of the kind of stuff I might want.


00:11:28.560 --> 00:11:31.040
There's some different ways to do that,


00:11:31.040 --> 00:11:32.600
but it's a pattern in prompt engineering


00:11:32.600 --> 00:11:34.440
where you'll say you have a zero shot,


00:11:34.440 --> 00:11:37.280
one shot, a few shot examples we could get into.


00:11:37.280 --> 00:11:40.320
But it does feel like it understands the code, right?


00:11:40.320 --> 00:11:42.440
Like what you're trying to do.


00:11:42.440 --> 00:11:44.440
- Right, just for people listening, it said,


00:11:44.440 --> 00:11:46.220
okay, here's a function isCrocodile.


00:11:46.220 --> 00:11:49.660
If not self.isReptile, if not self.hasScales,


00:11:49.660 --> 00:11:51.820
these are false examples, right?


00:11:51.820 --> 00:11:54.260
If it has four legs and a long snout, it can swim, right?


00:11:54.260 --> 00:11:57.500
Like it rewrote the little tests and stuff, right?


00:11:57.500 --> 00:12:00.220
In a way, that seems really unlikely


00:12:00.220 --> 00:12:03.700
that it's just predicting just likelihood


00:12:03.700 --> 00:12:05.540
'cause it's never seen anything like this really,


00:12:05.540 --> 00:12:08.340
which is really, it's pretty mind-blowing, I think.


00:12:08.340 --> 00:12:11.140
- Or it had, like it read the entire internet


00:12:11.140 --> 00:12:12.780
and all of GitHub and that kind of stuff.


00:12:12.780 --> 00:12:15.300
So it has seen similar things.


00:12:15.300 --> 00:12:17.460
The thing that's mind boggling is just like,


00:12:17.460 --> 00:12:19.580
when you think about what it did there


00:12:19.580 --> 00:12:23.820
is it read the entire conversation so far,


00:12:23.820 --> 00:12:25.700
your input prompt,


00:12:25.700 --> 00:12:27.700
and it has like a system prompt ahead of time


00:12:27.700 --> 00:12:29.580
that says, you know, your ChatGPT,


00:12:29.580 --> 00:12:31.660
try to be helpful to people.


00:12:31.660 --> 00:12:33.740
And here's a bunch of things that you should


00:12:33.740 --> 00:12:35.460
or should not stay, you're non-biased,


00:12:35.460 --> 00:12:39.380
you try to be concise and good and virtuous.


00:12:39.380 --> 00:12:41.840
And people have found all sorts of jailbreaks out of that.


00:12:41.840 --> 00:12:44.220
But all it does from that point on


00:12:44.220 --> 00:12:47.100
is try to predict the next word,


00:12:47.100 --> 00:12:49.520
which is kind of insane that it gets to,


00:12:49.520 --> 00:12:52.940
the amount of structure that we see here.


00:12:52.940 --> 00:12:53.780
- Right, right.


00:12:53.780 --> 00:12:55.460
That's a lot of structure there, right?


00:12:55.460 --> 00:12:57.460
So pretty impressive.


00:12:57.460 --> 00:13:01.020
And ChatGPT is starting to grow.


00:13:01.020 --> 00:13:02.220
You know, you've got version four


00:13:02.220 --> 00:13:03.560
and you can start using some of the plugins.


00:13:03.560 --> 00:13:04.900
It's gonna keep going crazy there.


00:13:04.900 --> 00:13:08.300
Other examples are simply just released Lemur,


00:13:08.300 --> 00:13:10.140
which is a large language model,


00:13:10.140 --> 00:13:13.000
but really focused on transcribing speech,


00:13:13.000 --> 00:13:14.780
which I think is kind of cool.


00:13:14.780 --> 00:13:19.780
Microsoft released Microsoft Security Co-Pilot,


00:13:19.780 --> 00:13:23.300
which is a large language model to talk about things


00:13:23.300 --> 00:13:26.660
like Nginx misconfiguration and stuff like that.


00:13:26.660 --> 00:13:29.760
There's just a lot of stuff out there


00:13:29.760 --> 00:13:31.900
that's coming along here, right?


00:13:31.900 --> 00:13:34.620
A lot of thousands of words coming in type of thing.


00:13:34.620 --> 00:13:36.940
- On the open source front too,


00:13:36.940 --> 00:13:39.540
- There's all ethical thing like should everyone


00:13:39.540 --> 00:13:43.700
and anyone have access to open source models doing that


00:13:43.700 --> 00:13:45.660
while we don't really understand.


00:13:45.660 --> 00:13:47.900
We probably shouldn't get into the ethics


00:13:47.900 --> 00:13:50.660
part of the debate here


00:13:50.660 --> 00:13:53.300
'cause that's a whole series of episodes


00:13:53.300 --> 00:13:54.540
we probably won't wanna get into.


00:13:54.540 --> 00:13:56.340
But what's interesting is,


00:13:56.340 --> 00:13:58.260
Databricks came up with a model for what's called


00:13:58.260 --> 00:14:00.620
Figures, came up with one called Lama


00:14:00.620 --> 00:14:03.180
and they open source and or the weight.


00:14:03.180 --> 00:14:07.620
So you have the model topology with the pre-trained weights.


00:14:07.620 --> 00:14:09.860
In some cases, there's open source corpus of training


00:14:09.860 --> 00:14:14.540
that are also coming out and are also open source.


00:14:14.540 --> 00:14:18.060
So that means like, and these open source models


00:14:18.060 --> 00:14:21.220
are somewhat competitive or increasingly competitive


00:14:21.220 --> 00:14:27.120
with GPT-4, yeah, which is kind of crazy.


00:14:27.120 --> 00:14:32.460
And some of them I don't, or where GPT-4 has limitations,


00:14:32.460 --> 00:14:33.940
they break through these limitations.


00:14:33.940 --> 00:14:36.440
So one thing that's really important


00:14:36.440 --> 00:14:40.440
as a current limitation of the GPT models and LLMs


00:14:40.440 --> 00:14:45.280
is the prompt window, the token prompt window.


00:14:45.280 --> 00:14:47.140
So basically when you ask a question,


00:14:47.140 --> 00:14:53.400
it's been trained and has machine learn with data up to,


00:14:53.400 --> 00:14:56.640
I think in the case of GPT 3.5 or 4,


00:14:56.640 --> 00:15:01.640
it's the corpus of training goes all the way to fall 2021.


00:15:01.680 --> 00:15:03.160
So if you ask like, who is the current president


00:15:03.160 --> 00:15:05.560
of the United States, it just doesn't know,


00:15:05.560 --> 00:15:09.020
or it will tell you as of 2021, it is this person.


00:15:09.020 --> 00:15:13.040
But so if you're trying to do tasks,


00:15:13.040 --> 00:15:14.160
like what I've been working on,


00:15:14.160 --> 00:15:16.240
we'll probably get into later in the conversation


00:15:16.240 --> 00:15:19.000
is trying to generate SQL.


00:15:19.000 --> 00:15:20.000
It doesn't know your table.


00:15:20.000 --> 00:15:20.840
So you have to say like,


00:15:20.840 --> 00:15:22.520
hey, here's all the tables in my database.


00:15:22.520 --> 00:15:25.860
Now, can you generate SQL that does X on top of it?


00:15:25.860 --> 00:15:30.860
And that context window is limited and increasing.


00:15:30.860 --> 00:15:33.140
and increasing, but some of these open source models


00:15:33.140 --> 00:15:34.520
have different types of limitations.


00:15:34.520 --> 00:15:37.100
They might have like 2x, 4x, 5x, 10x,


00:15:37.100 --> 00:15:42.000
you know, 10x the limitation that GPT-4 might have.


00:15:42.000 --> 00:15:45.540
- Right, it's interesting to ask the questions, right?


00:15:45.540 --> 00:15:48.620
But it's more interesting


00:15:48.620 --> 00:15:51.420
from a software developer's perspective of,


00:15:51.420 --> 00:15:53.900
can I teach it a little bit more


00:15:53.900 --> 00:15:56.100
about what my app needs to know


00:15:56.100 --> 00:15:58.540
or what my app structure is, right?


00:15:58.540 --> 00:16:02.340
in your case, I want to use SuperSet


00:16:02.340 --> 00:16:04.820
to ask the database questions.


00:16:04.820 --> 00:16:07.480
But if I'm gonna bring in AI,


00:16:07.480 --> 00:16:10.720
it needs to understand the database structure


00:16:10.720 --> 00:16:14.140
so that when I say, "Help me do a query to do this thing,"


00:16:14.140 --> 00:16:16.820
it needs to know what the heck to do, right?


00:16:16.820 --> 00:16:18.260
- The table, it needs to know,


00:16:18.260 --> 00:16:22.300
so there's this stuff it knows and this stuff it can't know.


00:16:22.300 --> 00:16:25.020
And some of it goes, is related to the fact


00:16:25.020 --> 00:16:27.900
that whether this information is gonna public on the internet


00:16:27.900 --> 00:16:31.080
whether it has happened to be trained against it.


00:16:31.080 --> 00:16:32.260
And then if it's in private,


00:16:32.260 --> 00:16:35.140
there's just no hope that it would know about,


00:16:35.140 --> 00:16:37.020
you know, your own internal documents


00:16:37.020 --> 00:16:37.980
or your database structure.


00:16:37.980 --> 00:16:42.500
So in our case, it speaks SQLs very, very well.


00:16:42.500 --> 00:16:43.820
So as we get into this example,


00:16:43.820 --> 00:16:48.740
like how to get GPT to generate good SQL


00:16:48.740 --> 00:16:51.740
in the context of a tool like SuperSET or SQL lab,


00:16:51.740 --> 00:16:53.260
which is our SQL IDE.


00:16:53.260 --> 00:16:56.540
So it knows how to speak SQL super well.


00:16:56.540 --> 00:16:59.580
It knows the different dialects of SQL very, very well.


00:16:59.580 --> 00:17:02.180
It knows its functions, its dates functions,


00:17:02.180 --> 00:17:04.380
which a lot of the SQL,


00:17:04.380 --> 00:17:05.940
and like the engineers only call it like,


00:17:05.940 --> 00:17:07.420
yeah, I can never remember


00:17:07.420 --> 00:17:10.260
like what Postgres date diff function is,


00:17:10.260 --> 00:17:12.420
but at GPT or GPT models,


00:17:12.420 --> 00:17:14.700
just it knows SQL, it knows the dialects,


00:17:14.700 --> 00:17:16.420
it knows the mechanics of SQL,


00:17:16.420 --> 00:17:18.620
it understands data modeling, foreign keys,


00:17:18.620 --> 00:17:21.540
joins, primary, all this stuff it understands.


00:17:21.540 --> 00:17:24.640
It knows nothing about your specific database,


00:17:26.140 --> 00:17:28.380
the schema names and the table names


00:17:28.380 --> 00:17:30.180
and the column names that they might be able to use.


00:17:30.180 --> 00:17:33.340
So that's where we need to start providing some context


00:17:33.340 --> 00:17:34.860
and this context window is limited.


00:17:34.860 --> 00:17:39.700
So it's like, how do you use that context well


00:17:39.700 --> 00:17:41.940
or as well as possible?


00:17:41.940 --> 00:17:44.700
And that's the field and some of the ideas behind it


00:17:44.700 --> 00:17:46.740
is prompt crafting and prompt engineering,


00:17:46.740 --> 00:17:50.340
which we can get into once we get there,


00:17:50.340 --> 00:17:51.740
maybe we're there already.


00:17:51.740 --> 00:17:55.380
- Yeah, yeah, well, yeah, I think where I see


00:17:55.380 --> 00:17:59.380
this stuff going is from this general purpose knowledge


00:17:59.380 --> 00:18:04.340
starting to bring in more private or personal


00:18:04.340 --> 00:18:06.400
or internal type of information, right?


00:18:06.400 --> 00:18:09.860
Like our data about our customers is like structured


00:18:09.860 --> 00:18:11.760
like this in a table and here's what we know about them.


00:18:11.760 --> 00:18:14.300
Now let us ask questions about our company


00:18:14.300 --> 00:18:15.900
and our thing, right?


00:18:15.900 --> 00:18:19.160
And it's like starting to make inroads


00:18:19.160 --> 00:18:20.500
in that direction, I think.


00:18:20.500 --> 00:18:23.780
- Yeah, one thing to know about is,


00:18:23.780 --> 00:18:28.220
there's different approaches to teach


00:18:28.220 --> 00:18:29.420
or provide that context.


00:18:29.420 --> 00:18:33.660
So one would be to build your own model from scratch, right?


00:18:33.660 --> 00:18:35.580
And that's pretty prohibitive.


00:18:35.580 --> 00:18:38.180
So you'd have to find the right corpus.


00:18:38.180 --> 00:18:40.820
And instead of starting with a model that knows SQL


00:18:40.820 --> 00:18:42.900
and needs to know your table and context,


00:18:42.900 --> 00:18:46.380
you have to start from zero and very prohibitive.


00:18:46.380 --> 00:18:48.380
Another one is you start from a base model


00:18:48.380 --> 00:18:50.460
at some point of some kind.


00:18:50.460 --> 00:18:53.820
There's a topology, so there's different layers


00:18:53.820 --> 00:18:55.900
and number of neurons and it knows some things


00:18:55.900 --> 00:18:57.940
and then you load up some weights that are open source


00:18:57.940 --> 00:19:00.820
and then you say, I'm gonna tune this model


00:19:00.820 --> 00:19:04.740
to teach it my database schemas


00:19:04.740 --> 00:19:06.500
and basically my own corpus of data.


00:19:06.500 --> 00:19:08.500
So it could be your data dictionaries,


00:19:08.500 --> 00:19:10.180
could be your internal documents,


00:19:10.180 --> 00:19:13.800
it could be your GitHub code, your dbt projects.


00:19:13.800 --> 00:19:15.260
If you have one of your Airflow DAGs,


00:19:15.260 --> 00:19:17.700
be like, I'm gonna dump all this stuff in the model


00:19:17.700 --> 00:19:22.340
that will get baked into their neural network itself.


00:19:22.340 --> 00:19:26.260
That's doable, pretty prohibitive in this era.


00:19:26.260 --> 00:19:29.220
If you have the challenge that we have at Preset,


00:19:29.220 --> 00:19:31.820
which is we have multiple customers with different schemas,


00:19:31.820 --> 00:19:33.300
we can't have spillover.


00:19:33.300 --> 00:19:36.460
So you have to train a model for each one of our customers


00:19:36.460 --> 00:19:38.620
and serve a model for each one of our customers.


00:19:38.620 --> 00:19:40.780
So still pretty prohibitive.


00:19:40.780 --> 00:19:43.440
And a lot of people fall back on this third or fourth method


00:19:43.440 --> 00:19:46.860
that I would call prompt engineering,


00:19:46.860 --> 00:19:49.160
which is I'm gonna use the base model,


00:19:49.160 --> 00:19:53.940
the open AI API or just an API on LLM.


00:19:53.940 --> 00:19:55.980
And then I will, if no SQL already,


00:19:55.980 --> 00:19:58.340
I'll just say, hey, here's a bunch of tables


00:19:58.340 --> 00:19:59.180
that you might wanna use.


00:19:59.180 --> 00:20:00.940
Can you generate SQL on top of it?


00:20:00.940 --> 00:20:05.420
So then that's just a big request with a lot of context.


00:20:05.420 --> 00:20:07.900
Then we have to start thinking about


00:20:07.900 --> 00:20:10.460
maximizing the use of that context window


00:20:10.460 --> 00:20:13.420
to pass the information that's most relevant


00:20:13.420 --> 00:20:16.620
within the limits allowed by the specific model.


00:20:16.620 --> 00:20:20.180
And that starts to get into reproducibility,


00:20:20.180 --> 00:20:24.540
accuracy, and just those limitations,


00:20:24.540 --> 00:20:27.460
which is kind of an engineering type of thing.


00:20:27.460 --> 00:20:29.980
- Yeah, and then maybe a topic too,


00:20:29.980 --> 00:20:33.140
and this conversation is based on a recent blog post


00:20:33.140 --> 00:20:36.100
and the flow, just going back to the flow of that blog post,


00:20:36.100 --> 00:20:38.940
we started by establishing the premise


00:20:38.940 --> 00:20:42.260
that everyone is trying to bring AI


00:20:42.260 --> 00:20:43.740
into their product today.


00:20:43.740 --> 00:20:46.140
Thousands of product builders are currently exploring ways


00:20:46.140 --> 00:20:48.880
to harness the power of AI in the products


00:20:48.880 --> 00:20:51.380
and experiences they create.


00:20:51.380 --> 00:20:53.720
That's the premise for us with text to SQL


00:20:53.720 --> 00:20:56.560
and SQL lab as part of superset and preset.


00:20:56.560 --> 00:21:00.440
But I don't know, like if you think of any product,


00:21:00.440 --> 00:21:02.760
any startup, any SaaS product you use,


00:21:02.760 --> 00:21:03.960
if you work at HubSpot today,


00:21:03.960 --> 00:21:06.660
you're trying to figure out how to leverage AI


00:21:06.660 --> 00:21:11.660
to build, you know, sales chatbots or SDR chatbots.


00:21:11.660 --> 00:21:14.560
So everyone everywhere is trying to figure that out.


00:21:14.560 --> 00:21:18.840
And the challenge is, I guess, very probabilistic


00:21:18.840 --> 00:21:21.600
in a different interface to anything we know.


00:21:21.600 --> 00:21:23.000
You know, engineers would be like,


00:21:23.000 --> 00:21:26.220
oh, let's look at an API and leverage it.


00:21:26.220 --> 00:21:30.560
And APIs are very, very deterministic in general.


00:21:30.560 --> 00:21:33.440
AI is kind of wild beast to tame.


00:21:33.440 --> 00:21:34.400
(laughs)


00:21:34.400 --> 00:21:38.840
You ask, first the interface is language, not code.


00:21:38.840 --> 00:21:40.480
And then what comes back


00:21:40.480 --> 00:21:43.800
is like semi-probabilistic in nature.


00:21:43.800 --> 00:21:45.400
- And it could change underneath you.


00:21:45.400 --> 00:21:48.120
It's a little bit like web scraping in that regard.


00:21:48.120 --> 00:21:50.040
That like, it does the same, it does the same.


00:21:50.040 --> 00:21:52.280
And then, you know, something out there changed,


00:21:52.280 --> 00:21:56.160
not your code, and then a potentially different behavior


00:21:56.160 --> 00:21:57.280
comes back, right?


00:21:57.280 --> 00:21:59.320
Because they may have trained another couple of years,


00:21:59.320 --> 00:22:00.760
refined the model, switched the model,


00:22:00.760 --> 00:22:04.000
changed the default temperature, all these things.


00:22:04.000 --> 00:22:06.200
- Yeah, there's a lot that can happen there.


00:22:06.200 --> 00:22:08.080
One thing I noticed, like starting to work


00:22:08.080 --> 00:22:10.260
with what I would call prompt crafting,


00:22:10.260 --> 00:22:12.800
which is, you know, you work with ChatGPT


00:22:12.800 --> 00:22:17.640
and you craft different prompt with putting emphasis


00:22:17.640 --> 00:22:20.840
in a place or another or changing the order of things


00:22:20.840 --> 00:22:22.200
or just changing a word, right?


00:22:22.200 --> 00:22:25.520
Just say like important exclamation point,


00:22:25.520 --> 00:22:29.920
capitalize the words, you know, the reserve words in SQL.


00:22:29.920 --> 00:22:31.400
And then just the fact that you put


00:22:31.400 --> 00:22:33.240
important exclamation point, you know,


00:22:33.240 --> 00:22:36.320
will make it do it or not do it.


00:22:36.320 --> 00:22:37.960
Changing from a model to another.


00:22:37.960 --> 00:22:39.800
So one thing that's great is the model,


00:22:39.800 --> 00:22:41.920
like they said, OpenAI are,


00:22:41.920 --> 00:22:46.360
they are immutable as far as I know.


00:22:46.360 --> 00:22:50.040
But like if you use GPT-3.5 Turbo, for instance,


00:22:50.040 --> 00:22:52.160
that's just one train model.


00:22:52.160 --> 00:22:55.620
I believe that that is immutable.


00:22:55.620 --> 00:22:59.240
The chatbot on top of it might get fine-tuned


00:22:59.240 --> 00:23:03.360
and change over time, but the model is supposed to be static.


00:23:03.360 --> 00:23:04.560
You mentioned temperature,


00:23:04.560 --> 00:23:06.440
be kind of interesting to just mention


00:23:06.440 --> 00:23:08.120
for those who are not familiar with that.


00:23:08.120 --> 00:23:09.680
So when you interact with AI,


00:23:09.680 --> 00:23:12.640
one of the core parameters is temperature.


00:23:12.640 --> 00:23:16.760
And it's, I think it's a value from zero to one,


00:23:16.760 --> 00:23:21.520
or I'm not sure if, you know, how exactly you pass it,


00:23:21.520 --> 00:23:25.960
but it basically defines how creative you want,


00:23:25.960 --> 00:23:29.000
you wanna let the AI be.


00:23:29.000 --> 00:23:31.480
Like how, if you put it to zero,


00:23:31.480 --> 00:23:33.160
you're gonna have something more deterministic.


00:23:33.160 --> 00:23:36.080
So asking the same question should lead to a similar


00:23:36.080 --> 00:23:39.640
or the same answer, though not in my experience.


00:23:39.640 --> 00:23:41.440
It feels like it should, but it doesn't.


00:23:41.440 --> 00:23:44.240
But then if you put a higher, it will get more creative.


00:23:44.240 --> 00:23:48.800
Talk more about like how that actually


00:23:48.800 --> 00:23:50.640
seemed to work behind the scene.


00:23:50.640 --> 00:23:54.200
- Yeah, well, that variability seems to show up more


00:23:54.200 --> 00:23:56.480
in the image-based ones.


00:23:56.480 --> 00:23:59.480
So for example, this article, this blog post that you wrote,


00:23:59.480 --> 00:24:01.000
you have this image here and you said,


00:24:01.000 --> 00:24:04.680
oh, and I made this image from mid-journey.


00:24:04.680 --> 00:24:08.360
I've also got some examples of a couple that I did.


00:24:08.360 --> 00:24:09.560
Where did I stick them?


00:24:09.560 --> 00:24:11.120
Somewhere, here we go.


00:24:11.120 --> 00:24:13.640
Where I asked, just for YouTube thumbnails,


00:24:13.640 --> 00:24:16.760
I asked Midjourney for a radio astronomy example


00:24:16.760 --> 00:24:19.800
that I can use, 'cause here's one that's not encumbered


00:24:19.800 --> 00:24:22.800
by some sort of licensing, but still looks kinda cool


00:24:22.800 --> 00:24:25.120
and is representative, right?


00:24:25.120 --> 00:24:28.800
And there, it's like massive difference.


00:24:28.800 --> 00:24:31.840
I'm not sure how much difference I've seen.


00:24:31.840 --> 00:24:32.720
I know it will make some,


00:24:32.720 --> 00:24:35.280
but I haven't seen as dramatic of a difference


00:24:35.280 --> 00:24:38.320
on like ChatGPT versus imagery.


00:24:38.320 --> 00:24:39.160
Yeah.


00:24:39.160 --> 00:24:41.440
- Yeah, I'm not sure exactly how they introduced


00:24:41.440 --> 00:24:46.440
the variability on the generative images AI.


00:24:46.440 --> 00:24:48.720
I know it's like this multi-dimensional space


00:24:48.720 --> 00:24:51.880
with a lot of words and a lot of images in there.


00:24:51.880 --> 00:24:55.240
And then it's probably like where the location point


00:24:55.240 --> 00:24:59.400
of that, they randomize that point


00:24:59.400 --> 00:25:01.520
in that multi-dimensional space.


00:25:01.520 --> 00:25:03.640
For Chagipiti, it's pretty easy to reason about,


00:25:03.640 --> 00:25:05.660
and I might be wrong on this, again, I'm not an expert,


00:25:05.660 --> 00:25:09.020
but you know how the way it works is it writes,


00:25:09.020 --> 00:25:10.140
it takes the prompt,


00:25:10.140 --> 00:25:14.580
and then it comes up with the next word sequentially.


00:25:14.580 --> 00:25:17.260
So for each word, for the next word,


00:25:17.260 --> 00:25:19.940
so Humpty Dumpty sat on A,


00:25:19.940 --> 00:25:22.700
it might be wall at 99%,


00:25:22.700 --> 00:25:27.700
but like there might be 1% of fence or something like that.


00:25:27.700 --> 00:25:31.500
And if you up the temperature,


00:25:31.500 --> 00:25:36.340
there's, it's more likely to pick the non first word


00:25:36.340 --> 00:25:38.060
and that probably less,


00:25:38.060 --> 00:25:39.660
it probably do in a weighted way,


00:25:39.660 --> 00:25:41.740
like it's possible that I take a second


00:25:41.740 --> 00:25:43.780
or the third word randomly.


00:25:43.780 --> 00:25:46.460
And then of course it's gonna get a tree or decision tree.


00:25:46.460 --> 00:25:49.460
Once it picks the words, the next word is also changes.


00:25:49.460 --> 00:25:53.740
So as you up that, it goes down path


00:25:53.740 --> 00:25:56.820
that sends it into more creative or the right.


00:25:56.820 --> 00:25:57.660
- Right.


00:25:59.100 --> 00:26:01.140
- Yeah, a little butterfly effect.


00:26:01.140 --> 00:26:02.300
Makes a different choice here,


00:26:02.300 --> 00:26:05.420
and then it sends it down through the graph.


00:26:05.420 --> 00:26:06.720
Interesting.


00:26:06.720 --> 00:26:09.080
So one thing that you really pointed out here,


00:26:09.080 --> 00:26:11.520
and I think is maybe worth touching on a bit,


00:26:11.520 --> 00:26:13.740
is this idea of prompt engineering.


00:26:13.740 --> 00:26:16.460
There's even places like learnprompting.org


00:26:16.460 --> 00:26:19.700
that try to teach you how to talk to these things.


00:26:19.700 --> 00:26:23.220
And you make a strong distinction between prompt crafting


00:26:23.220 --> 00:26:24.820
or just talking to the AI


00:26:24.820 --> 00:26:28.900
versus really trying to put an engineering focus on it.


00:26:28.900 --> 00:26:31.340
Do you wanna talk about the differentiation?


00:26:31.340 --> 00:26:33.900
- Yeah, I think it's a super important differentiation,


00:26:33.900 --> 00:26:36.080
but one that I'm proposing, right?


00:26:36.080 --> 00:26:38.500
So I don't think that people have settled


00:26:38.500 --> 00:26:40.980
as to what is one or what is the other.


00:26:40.980 --> 00:26:44.180
I think I saw a Reddit post recently that was like,


00:26:44.180 --> 00:26:46.840
prompt engineering is just a load of crap.


00:26:46.840 --> 00:26:48.820
Like, you know, anyone can go,


00:26:48.820 --> 00:26:51.300
'cause they thought their understanding


00:26:51.300 --> 00:26:53.140
of prompt engineering was like,


00:26:53.140 --> 00:26:56.460
oh, you know, you fine tune or you craft your prompt


00:26:56.460 --> 00:26:58.860
and you say like, you are an expert AI


00:26:58.860 --> 00:27:03.540
working on creating molecules, now can you do this?


00:27:03.540 --> 00:27:07.180
And then by doing that, you might get a better outcome.


00:27:07.180 --> 00:27:09.380
Or one really interesting thing that people


00:27:09.380 --> 00:27:12.540
have been doing in prompt crafting that


00:27:12.540 --> 00:27:14.460
seemed to have a huge impact on-- there's


00:27:14.460 --> 00:27:20.980
been paper written on this specific just hint or craft


00:27:20.980 --> 00:27:25.260
tweak is let's proceed step by step.


00:27:25.260 --> 00:27:28.340
So basically, whatever the question is that you are asking


00:27:28.340 --> 00:27:30.460
is specifically around like more mathematicals


00:27:30.460 --> 00:27:33.740
or like things that require more systematic


00:27:33.740 --> 00:27:35.540
step-by-step thinking.


00:27:35.540 --> 00:27:39.020
The whole like, just like, let's think, let's expose this


00:27:39.020 --> 00:27:42.680
or let's go about it step-by-step makes it much better.


00:27:42.680 --> 00:27:46.940
So here you might be able to, well, so, you know,


00:27:46.940 --> 00:27:50.940
if you had an example where ChatGPT-3 failed


00:27:50.940 --> 00:27:54.500
or ChatGPT-4 failed, you could just say,


00:27:54.500 --> 00:27:56.340
Colin, let's go step-by-step


00:27:56.340 --> 00:27:59.500
and it might succeed that time around.


00:27:59.500 --> 00:28:02.600
- Right, maybe you can get it to help you understand


00:28:02.600 --> 00:28:04.620
instead of just get the answer, right?


00:28:04.620 --> 00:28:09.620
Like factor this polynomial into its primary,


00:28:09.620 --> 00:28:11.780
you know, solutions or roots or whatever.


00:28:11.780 --> 00:28:12.940
And you're like, okay, show me,


00:28:12.940 --> 00:28:15.400
don't just show me the answer, show me step by step


00:28:15.400 --> 00:28:17.460
so I could understand and try to learn


00:28:17.460 --> 00:28:18.860
from what you've done, right?


00:28:18.860 --> 00:28:20.700
- Yeah, I mean, if you think about how the way


00:28:20.700 --> 00:28:22.900
that it's trying to come up with a new word,


00:28:22.900 --> 00:28:25.880
if all it does is a language-based answer


00:28:25.880 --> 00:28:29.000
to a mathematical question, like how many days


00:28:29.000 --> 00:28:31.520
are there between this date and that date?


00:28:31.520 --> 00:28:36.400
There's no, that specific example might not exist


00:28:36.400 --> 00:28:38.360
or it's kind of complicated for it to go about it.


00:28:38.360 --> 00:28:40.280
But if you say let's think step by step,


00:28:40.280 --> 00:28:42.420
okay, there's this many months,


00:28:42.420 --> 00:28:44.880
this month's duration is this long,


00:28:44.880 --> 00:28:47.960
there's this many days since the beginning of that month,


00:28:47.960 --> 00:28:50.520
I might get it right that time around.


00:28:50.520 --> 00:28:53.360
- Right, or if it fails, you could pick up partway along


00:28:53.360 --> 00:28:55.280
where it has some more.


00:28:55.280 --> 00:28:56.640
- Yeah, you know, and then you can trace,


00:28:56.640 --> 00:28:58.600
I mean, just you too, like, I think, you know,


00:28:58.600 --> 00:29:00.640
one thing is like, you should be extremely careful


00:29:00.640 --> 00:29:03.260
as like taking for granted that it's right all the time,


00:29:03.260 --> 00:29:04.600
you know, so that means like,


00:29:04.600 --> 00:29:07.280
it also helps you review its process


00:29:07.280 --> 00:29:09.400
and where it might be wrong.


00:29:09.400 --> 00:29:11.580
But back to crafting versus engineering.


00:29:11.580 --> 00:29:14.200
So crafting would be the process that I think


00:29:14.200 --> 00:29:18.760
is more attached to a use ChatGPT every day,


00:29:18.760 --> 00:29:20.640
the same way that, you know, we've been trained


00:29:20.640 --> 00:29:23.840
at Googling, you know, over the past like two decades.


00:29:25.040 --> 00:29:28.200
You use quotes, you use plus and minus,


00:29:28.200 --> 00:29:32.360
and you know which keywords to use intuitively,


00:29:32.360 --> 00:29:33.800
where it's gonna get confused or not.


00:29:33.800 --> 00:29:37.320
So I think prompt crafting is a different version of that


00:29:37.320 --> 00:29:40.200
that's just more worthy.


00:29:40.200 --> 00:29:43.660
And if you're working with the AI to try to assist you,


00:29:43.660 --> 00:29:44.800
write your blog post,


00:29:44.800 --> 00:29:47.520
or to try to assist you in any task really,


00:29:47.520 --> 00:29:51.080
just to be smart about how you bring the context,


00:29:51.080 --> 00:29:54.580
how you tell it to proceed, goes a very, very long way.


00:29:54.580 --> 00:29:56.560
So that's what I call prompt crafting,


00:29:56.560 --> 00:29:58.620
call it like one-off cases.


00:29:58.620 --> 00:30:01.880
- Kind of what people do when they're interacting


00:30:01.880 --> 00:30:04.540
with the large language model.


00:30:04.540 --> 00:30:05.380
- I think so, right?


00:30:05.380 --> 00:30:07.520
Like it's not evident for a lot of people


00:30:07.520 --> 00:30:10.040
who are exploring the edge of where it fails


00:30:10.040 --> 00:30:12.200
and they love to see it fail.


00:30:12.200 --> 00:30:14.960
And then they don't think about like,


00:30:14.960 --> 00:30:18.000
oh, what could I have told it to get the answer


00:30:18.000 --> 00:30:18.920
I was actually looking for?


00:30:18.920 --> 00:30:20.260
Like, ah, I got you wrong.


00:30:20.260 --> 00:30:23.360
You know, it's as if I bad, bad actor in a conversation.


00:30:23.360 --> 00:30:26.160
of like, ah, you're wrong and I told you so.


00:30:26.160 --> 00:30:28.560
You know, so I think there's a lot of that online,


00:30:28.560 --> 00:30:30.880
but I think for all these examples that I've seen,


00:30:30.880 --> 00:30:33.240
I'm really tempted to take the prompt that they had


00:30:33.240 --> 00:30:35.880
and then give it an instruction or two or more


00:30:35.880 --> 00:30:38.060
and then figure out how to get it


00:30:38.060 --> 00:30:38.920
to come up with the right thing.


00:30:38.920 --> 00:30:41.920
So prompt crafting, super important skill.


00:30:41.920 --> 00:30:44.840
You know, you could probably get a boost of,


00:30:44.840 --> 00:30:46.840
for most knowledge information workers,


00:30:46.840 --> 00:30:49.760
you'll get a boost of 50% to 10X


00:30:49.760 --> 00:30:51.280
for a lot of the tasks you do every day


00:30:51.280 --> 00:30:52.560
if you use AI well.


00:30:52.560 --> 00:30:55.360
So it's a great personal skill to have.


00:30:55.360 --> 00:30:56.960
Go and develop that skill if you don't.


00:30:56.960 --> 00:30:58.840
Prop engineering, in my case, I'm like,


00:30:58.840 --> 00:31:00.440
you're building something,


00:31:00.440 --> 00:31:04.900
you're using an AI as an API behind the scene.


00:31:04.900 --> 00:31:08.680
You want to pass it a bunch of relevant contexts,


00:31:08.680 --> 00:31:11.520
really specify what you want to get out of it.


00:31:11.520 --> 00:31:14.040
Maybe you even want to get a structured output, right?


00:31:14.040 --> 00:31:16.420
You might want to get a JSON blob out of it.


00:31:16.420 --> 00:31:20.580
You say, return a JSON blob with the following format.


00:31:20.580 --> 00:31:22.520
So it's more structured.


00:31:22.520 --> 00:31:24.760
So then to give all these instructions,


00:31:24.760 --> 00:31:27.000
there's this idea of providing few shots too.


00:31:27.000 --> 00:31:29.660
You might be storing context in a vector database.


00:31:29.660 --> 00:31:31.460
I don't know if we're getting ahead to that today,


00:31:31.460 --> 00:31:35.640
but there are ways to kind of structure


00:31:35.640 --> 00:31:37.600
and organize your potential embeddings


00:31:37.600 --> 00:31:39.160
or the things you want to pass as context.


00:31:39.160 --> 00:31:40.800
So there's a lot here.


00:31:40.800 --> 00:31:43.220
I think somewhere too, I talk about prompt engineering.


00:31:43.220 --> 00:31:44.520
If we'd scroll in the blog posts,


00:31:44.520 --> 00:31:47.320
like what is in prompt engineering,


00:31:47.320 --> 00:31:51.200
it will list the kind of things.


00:31:51.200 --> 00:31:53.560
it might be higher in the post.


00:31:53.560 --> 00:31:55.360
Sorry, we're scrolling for people.


00:31:55.360 --> 00:31:56.200
(laughing)


00:31:56.200 --> 00:31:59.360
I just wanna introduce what is prompt engineering?


00:31:59.360 --> 00:32:00.700
- Yeah, yeah, yeah.


00:32:00.700 --> 00:32:04.680
- Well, no, it's above this section,


00:32:04.680 --> 00:32:07.320
above, so Mickey, you scroll at the beginning,


00:32:07.320 --> 00:32:08.920
like what is prompt engineering?


00:32:08.920 --> 00:32:11.280
- Yeah, here you go.


00:32:11.280 --> 00:32:12.880
- Oh yeah, right here, the definition of,


00:32:12.880 --> 00:32:15.100
this is ChadsGPT's version of it.


00:32:15.100 --> 00:32:18.240
So when you do prompt engineering, you can add context,


00:32:18.240 --> 00:32:20.440
which that means that you're gonna have to retrieve context


00:32:20.440 --> 00:32:24.040
maybe from a database, from a user session,


00:32:24.040 --> 00:32:26.520
from your Redux store if you're in the front end, right?


00:32:26.520 --> 00:32:29.720
So you're gonna go and fetch the context that's relevant


00:32:29.720 --> 00:32:31.320
in context of the application,


00:32:31.320 --> 00:32:33.120
at least while building products.


00:32:33.120 --> 00:32:34.280
Specify an answer format.


00:32:34.280 --> 00:32:36.280
You could just say, yes, I just want a yes or no,


00:32:36.280 --> 00:32:40.240
a Boolean, I want a JSON blob with not only the answer,


00:32:40.240 --> 00:32:43.920
but your confidence on that answer or something like that.


00:32:43.920 --> 00:32:47.520
Limiting scope, asking for pros and cons,


00:32:47.520 --> 00:32:50.480
incorporating verification or sourcing.


00:32:50.480 --> 00:32:53.880
So that's more, if you iterate on a prompt,


00:32:53.880 --> 00:32:55.040
you're gonna be rigorous about,


00:32:55.040 --> 00:32:59.120
is this prompt better than the previous prompt I had?


00:32:59.120 --> 00:33:02.200
If I pass five rows of sample data


00:33:02.200 --> 00:33:06.800
while doing text to SQL, does it do better than if I,


00:33:06.800 --> 00:33:09.640
or does it do more poorly than if I pass 10 rows


00:33:09.640 --> 00:33:11.880
of sample data or provide a certain amount


00:33:11.880 --> 00:33:13.720
of column level statistics?


00:33:13.720 --> 00:33:16.080
So prompt engineering is not just from crafting.


00:33:16.080 --> 00:33:20.080
It is like bringing maybe the scientific method to it,


00:33:20.080 --> 00:33:23.480
bring some engineering of like fetching the right context


00:33:23.480 --> 00:33:26.520
and organizing it well, and then measuring the outcome.


00:33:26.520 --> 00:33:27.340
- Right, exactly.


00:33:27.340 --> 00:33:28.920
Something that comes out, you can measure and say,


00:33:28.920 --> 00:33:33.920
this is 10% better by my metric than it was before


00:33:33.920 --> 00:33:35.480
with this additional data, right?


00:33:35.480 --> 00:33:37.440
That's a big difference.


00:33:37.440 --> 00:33:40.200
- Right, and then there's so many things moving, right?


00:33:40.200 --> 00:33:43.440
Like, and everything is changing so fast in the space.


00:33:43.440 --> 00:33:46.420
So you're like, oh, well, ChatGPT-5 is out,


00:33:46.420 --> 00:33:49.860
or GPT-4 Turbo is half the price and then just came out.


00:33:49.860 --> 00:33:51.140
Now I'm just gonna move to that.


00:33:51.140 --> 00:33:54.060
They're like, wait, is that performing better?


00:33:54.060 --> 00:33:56.860
Or what are the trade-off?


00:33:56.860 --> 00:34:00.340
Or even I'm gonna add, I'm gonna move this section,


00:34:00.340 --> 00:34:03.880
asking for a certain JSON format above this other section.


00:34:03.880 --> 00:34:08.380
I'm gonna write important exclamation point, do X.


00:34:08.380 --> 00:34:10.940
Does that improve my result?


00:34:10.940 --> 00:34:15.940
as I mess it up and which one of my test case perhaps


00:34:15.940 --> 00:34:17.980
that succeeded before fails now


00:34:17.980 --> 00:34:19.620
and which one failed before succeeds now.


00:34:19.620 --> 00:34:21.700
So it can be like, is that a better


00:34:21.700 --> 00:34:26.220
or worse iteration towards my goal?


00:34:26.220 --> 00:34:27.060
- Right, right.


00:34:27.060 --> 00:34:32.060
Kind of bringing this unit testing TDD mindset.


00:34:32.060 --> 00:34:34.340
- Yes, yes.


00:34:34.340 --> 00:34:37.020
So that's what we're getting deeper into the blog post.


00:34:37.020 --> 00:34:39.860
Right, so the blog post is talking about


00:34:39.860 --> 00:34:44.860
bring this TDD, the test-driven development mindset


00:34:44.860 --> 00:34:47.300
to prompt engineering, right?


00:34:47.300 --> 00:34:50.100
And there's a lot of things that are in common.


00:34:50.100 --> 00:34:54.340
You can take and apply and kind of transfer just over,


00:34:54.340 --> 00:34:56.100
but there are some things to that breakdown


00:34:56.100 --> 00:34:57.420
that are fundamentally different


00:34:57.420 --> 00:34:59.860
between testing a prompt or working with AI


00:34:59.860 --> 00:35:04.860
and working with just a bit more deterministic


00:35:04.860 --> 00:35:07.660
code testing type framework.


00:35:07.660 --> 00:35:09.660
- Yeah, yeah, for sure.


00:35:09.660 --> 00:35:13.580
So you called out a couple of reasons


00:35:13.580 --> 00:35:15.940
of why TDD is important for prompt engineering.


00:35:15.940 --> 00:35:18.180
Maybe we could run through those.


00:35:18.180 --> 00:35:23.180
- Yeah, so the first thing is the AI model


00:35:23.180 --> 00:35:25.660
is not a deterministic things,


00:35:25.660 --> 00:35:30.660
or you use a modern API or a GraphQL REST API.


00:35:30.660 --> 00:35:34.820
The format of what you ask is extremely clear


00:35:34.820 --> 00:35:36.540
and then the format of what you get back


00:35:36.540 --> 00:35:38.700
is usually defined by a schema.


00:35:38.700 --> 00:35:41.380
It's like very deterministic, pretty guaranteed


00:35:41.380 --> 00:35:42.740
that you do the same request,


00:35:42.740 --> 00:35:46.940
so you get the same output ish, or at least format.


00:35:46.940 --> 00:35:48.700
With AI, that's not the case, right?


00:35:48.700 --> 00:35:53.000
So it's much more unpredictable and probabilistic by nature.


00:35:53.000 --> 00:35:56.420
Second one is handling complexity.


00:35:56.420 --> 00:35:59.700
So AI systems are complex, black boxy,


00:35:59.700 --> 00:36:01.340
kind of unpredictable too.


00:36:01.340 --> 00:36:05.340
So embrace that and assume that you might get something


00:36:05.340 --> 00:36:08.360
really creative coming out of there for better or for worse.


00:36:08.360 --> 00:36:13.360
And then reducing risk, like you're shipping product,


00:36:13.360 --> 00:36:16.460
if you're shipping product, writing product,


00:36:16.460 --> 00:36:21.180
you don't want this only any sort of like bias


00:36:21.180 --> 00:36:24.660
or weird thing like the AI could go crazy.


00:36:24.660 --> 00:36:28.100
- Yeah, there are examples of AIs going crazy before


00:36:28.100 --> 00:36:31.700
like Tay, do you remember Microsoft Tay?


00:36:31.700 --> 00:36:34.340
- I don't know that one, but I know of other examples.


00:36:34.340 --> 00:36:36.900
- Yeah, I mean, it came out and it was like this sort of


00:36:36.900 --> 00:36:41.660
just, you know, I'm here to learn from you internet and people just turned it


00:36:41.660 --> 00:36:44.060
into a racist and made it do all sorts of horrible things.


00:36:44.060 --> 00:36:47.620
And they had to shut it down a couple of days later because it just, it's like,


00:36:47.620 --> 00:36:52.500
Whoa, it met the internet and the internet is mean. So, that's not great.


00:36:52.500 --> 00:36:55.980
Yeah. Train it on a four Chan or let it, you know,


00:36:55.980 --> 00:36:58.060
go crawl for Shannon and read it.


00:36:58.060 --> 00:37:00.180
And that's not always going to be nice.


00:37:00.180 --> 00:37:01.980
Right. I mean, you, you,


00:37:01.980 --> 00:37:05.300
you don't entirely control what's going to come out of those things. And so.


00:37:05.780 --> 00:37:08.740
Yeah, I would say a little more predictable, right? And it's not


00:37:08.740 --> 00:37:13.020
even like you don't entirely control. Yeah, like basically,


00:37:13.020 --> 00:37:16.860
you know, control might be a complete illusion, like even the


00:37:16.860 --> 00:37:21.700
people working at open AI don't fully understand what's


00:37:21.700 --> 00:37:26.780
happening in there. Yeah, like, well, it read a bunch of stuff,


00:37:26.780 --> 00:37:30.820
and it's predicting the next word, and it gets most things


00:37:30.820 --> 00:37:34.180
right. By the way, like they do a lot around this idea of like,


00:37:34.180 --> 00:37:36.540
not necessarily TDD, but there's a whole eval framework


00:37:36.540 --> 00:37:40.340
so you can submit your evaluation functions to OpenAI.


00:37:40.340 --> 00:37:42.980
And as they train the next version of things,


00:37:42.980 --> 00:37:47.640
they include that in what their evaluation system


00:37:47.640 --> 00:37:48.480
for the new thing.


00:37:48.480 --> 00:37:50.360
So say, if I wanted to go and contribute back


00:37:50.360 --> 00:37:53.500
a bunch of like text to SQL type use cases


00:37:53.500 --> 00:37:55.660
as they call evals,


00:37:55.660 --> 00:37:58.260
then they would take that into consideration


00:37:58.260 --> 00:38:01.340
when they train the next models.


00:38:01.340 --> 00:38:03.600
All right, so going down the list, reducing risk, right?


00:38:03.600 --> 00:38:05.660
So you're integrating some of that beast


00:38:05.660 --> 00:38:08.200
that's not fully tamed into your product.


00:38:08.200 --> 00:38:10.200
You probably wanna make sure it's tamed enough


00:38:10.200 --> 00:38:12.980
to live inside your product.


00:38:12.980 --> 00:38:14.620
Continuous improvements,


00:38:14.620 --> 00:38:17.100
that should have been maybe the first one in the list


00:38:17.100 --> 00:38:19.140
is you're iterating on your prompts,


00:38:19.140 --> 00:38:21.420
you're trying to figure out a past context,


00:38:21.420 --> 00:38:25.460
you're trying different model versions,


00:38:25.460 --> 00:38:28.180
maybe you're trying some open source models


00:38:28.180 --> 00:38:32.220
or the latest GPT cheaper and greater thing.


00:38:32.220 --> 00:38:35.840
So you wanna make sure that as you iterate,


00:38:35.840 --> 00:38:37.640
you're getting to the actual outcomes


00:38:37.640 --> 00:38:39.340
that you want systematically.


00:38:39.340 --> 00:38:40.840
Then performance measurement too,


00:38:40.840 --> 00:38:42.000
of like how long does it take?


00:38:42.000 --> 00:38:43.640
How much does it cost?


00:38:43.640 --> 00:38:48.640
You kind of need to have a handle on that.


00:38:48.640 --> 00:38:53.240
The new model might be 3% better on your corpus of tests,


00:38:53.240 --> 00:38:54.780
but it might be six times the price.


00:38:54.780 --> 00:38:57.680
Like do you want, are you okay with that?


00:38:57.680 --> 00:38:58.520
- Right, right.


00:38:58.520 --> 00:39:01.180
Or just from a user perspective, yeah.


00:39:01.180 --> 00:39:03.540
Time to interaction, that's one thing with AI


00:39:03.540 --> 00:39:07.020
we're realizing now is a lot of the prompts on four


00:39:07.020 --> 00:39:11.700
will be like one to seven seconds,


00:39:11.700 --> 00:39:13.420
which in the Google era,


00:39:13.420 --> 00:39:16.540
there's been some really great papers out of Google


00:39:16.540 --> 00:39:20.860
early on that prove that it's like 100 milliseconds


00:39:20.860 --> 00:39:24.700
as an impact on user behaviors and how long they stay.


00:39:24.700 --> 00:39:25.540
- Right.


00:39:25.540 --> 00:39:29.940
Yeah, people give up on checkout flows or whatever


00:39:29.940 --> 00:39:32.380
going to the next part of your site,


00:39:32.380 --> 00:39:34.700
measurably on 100 millisecond blocks, right?


00:39:34.700 --> 00:39:38.260
When you're talking, well, here's 70 of those,


00:39:38.260 --> 00:39:40.220
that's gonna have an effect, potentially.


00:39:40.220 --> 00:39:43.580
- Oh, it has, it has been proven and very intricate


00:39:43.580 --> 00:39:47.460
in usage patterns, session duration, session outcomes,


00:39:47.460 --> 00:39:50.740
right, and a second is a mountain.


00:39:50.740 --> 00:39:53.340
If today, like we were to A/B test Google


00:39:53.340 --> 00:39:56.740
between whatever millisecond it's at now,


00:39:56.740 --> 00:39:59.380
to just one second or half a second,


00:39:59.380 --> 00:40:01.740
that the results coming out of that A/B test


00:40:01.740 --> 00:40:04.060
would show very, very different behaviors.


00:40:04.060 --> 00:40:04.900
- Wow.


00:40:04.900 --> 00:40:06.100
- I think there's some, no quote me on it,


00:40:06.100 --> 00:40:07.500
there's some really great papers, you know,


00:40:07.500 --> 00:40:10.700
written on TTI and just time to interaction


00:40:10.700 --> 00:40:12.980
and the way it influence user behavior.


00:40:12.980 --> 00:40:15.180
So we're still, you know, in the AI world,


00:40:15.180 --> 00:40:17.760
it has to, if you're gonna wait two to seven seconds


00:40:17.760 --> 00:40:19.560
for your prompt to come back,


00:40:19.560 --> 00:40:21.160
it's gotta add some real,


00:40:21.160 --> 00:40:23.300
some real important value to what's happening.


00:40:23.300 --> 00:40:24.740
- Yeah, it does.


00:40:24.740 --> 00:40:28.300
I think it's interesting that it's presented as a chat.


00:40:28.300 --> 00:40:30.500
I think that gives people a little bit of a pause.


00:40:30.500 --> 00:40:31.620
Like, oh, it's talking to me.


00:40:31.620 --> 00:40:33.620
So let's let it think for a second


00:40:33.620 --> 00:40:34.740
rather than it's a website


00:40:34.740 --> 00:40:36.380
that's supposed to give me an answer.


00:40:36.380 --> 00:40:39.220
- Yeah, compared to then I guess your basis for comparison


00:40:39.220 --> 00:40:44.220
is a human, not a website or not comparing against Google.


00:40:44.220 --> 00:40:46.560
- Yeah, I ask it a really hard question.


00:40:46.560 --> 00:40:47.660
Give it some time, right?


00:40:47.660 --> 00:40:49.420
Like that's not normally how we think about these things.


00:40:49.420 --> 00:40:51.460
Okay, so you have a kind of a workflow


00:40:51.460 --> 00:40:53.700
from this engineering, building a product,


00:40:53.700 --> 00:40:57.340
testing like an AI inside of your product.


00:40:57.340 --> 00:40:58.900
if you wanna walk us through your workflow here.


00:40:58.900 --> 00:41:02.700
- Yeah, and if you, I think I looked at TDD,


00:41:02.700 --> 00:41:05.540
you know, and originally what is the normal


00:41:05.540 --> 00:41:07.540
like TDD type workflow?


00:41:07.540 --> 00:41:10.940
And I just adapted this little diagram


00:41:10.940 --> 00:41:14.060
to prompt engineering, right?


00:41:14.060 --> 00:41:15.380
'Cause the whole idea of the blog post


00:41:15.380 --> 00:41:18.420
is to bring prompt engine, like TDD mindset


00:41:18.420 --> 00:41:19.240
to prompt engineering.


00:41:19.240 --> 00:41:23.020
So this is where I went, but yeah, the workflow is like,


00:41:23.020 --> 00:41:26.340
okay, define the use case and desired AI behavior.


00:41:26.340 --> 00:41:27.940
what are you trying to solve with AI?


00:41:27.940 --> 00:41:31.140
In my case, the example that I'll use


00:41:31.140 --> 00:41:33.580
and try to reuse throughout this presentation


00:41:33.580 --> 00:41:38.580
is throughout this conversation is, you know, text to SQL.


00:41:38.580 --> 00:41:41.800
So like we're trying to, what a user prompt,


00:41:41.800 --> 00:41:44.940
what a database schema, get the AI to generate


00:41:44.940 --> 00:41:48.260
good useful SQL, find the right tables and columns to use,


00:41:48.260 --> 00:41:51.220
that kind of stuff, create test cases.


00:41:51.220 --> 00:41:53.900
So it's like, okay, if I have this database


00:41:53.900 --> 00:41:57.420
and I have this prompt, give me my top five salary


00:41:57.420 --> 00:42:00.420
per department on this HR dataset,


00:42:00.420 --> 00:42:04.420
there's a fairly deterministic output to that.


00:42:04.420 --> 00:42:06.940
You could say the SQL is not necessarily deterministic,


00:42:06.940 --> 00:42:08.780
there's different ways to write that SQL,


00:42:08.780 --> 00:42:10.940
but there's a deterministic data frame


00:42:10.940 --> 00:42:12.540
or results set that might come up.


00:42:12.540 --> 00:42:15.500
- There is a right answer of the top five salaries.


00:42:15.500 --> 00:42:16.340
- That's right.


00:42:16.340 --> 00:42:18.420
- So you can see like, am I getting, ultimately get that.


00:42:18.420 --> 00:42:21.500
- And it's great if it is deterministic


00:42:21.500 --> 00:42:22.780
'cause you can test it.


00:42:22.780 --> 00:42:27.420
If you try to use AI to say write an essay about


00:42:27.420 --> 00:42:31.020
Napoleon Bonaparte's second conquest,


00:42:31.020 --> 00:42:36.060
in less than 500 words, it's not as deterministic


00:42:36.060 --> 00:42:39.580
and it's hard to test whether the AI is doing good or not.


00:42:39.580 --> 00:42:41.540
So you might need human evaluators.


00:42:41.540 --> 00:42:45.500
But I would say in most AI product,


00:42:45.500 --> 00:42:48.540
or people are trying to bring AI to their product,


00:42:48.540 --> 00:42:51.340
in many cases, more deterministic.


00:42:51.340 --> 00:42:53.460
So another example of like more deterministic would say like,


00:42:53.460 --> 00:42:58.460
oh, getting, if you say getting AI to write Python functions,


00:42:58.460 --> 00:43:01.900
it's like, oh, write a function that, you know,


00:43:01.900 --> 00:43:06.900
returns if a number is prime, yes or no,


00:43:06.900 --> 00:43:11.780
like that you can get the function and test it


00:43:11.780 --> 00:43:13.900
in a deterministic kind of way.


00:43:13.900 --> 00:43:16.460
So anyways, just pointing out, it's better,


00:43:16.460 --> 00:43:18.700
you're only gonna be able to have a TDD mindset


00:43:18.700 --> 00:43:21.920
if you have like somewhat deterministic outcome


00:43:21.920 --> 00:43:24.540
to the, you wanna use the AI for.


00:43:24.540 --> 00:43:25.860
Then create a Promp generator.


00:43:25.860 --> 00:43:27.100
So that would be your first version


00:43:27.100 --> 00:43:29.340
or in the text to SQL example,


00:43:29.340 --> 00:43:33.180
it's given the 20 tables in this database


00:43:33.180 --> 00:43:36.420
and this columns and table names and data types


00:43:36.420 --> 00:43:39.260
and sample data, generate SQL that answers


00:43:39.260 --> 00:43:40.580
the following user prompt.


00:43:40.580 --> 00:43:42.140
And then the user prompt would say something


00:43:42.140 --> 00:43:46.020
like department by top five salary per department.


00:43:47.100 --> 00:43:49.100
And then we're getting for people


00:43:49.100 --> 00:43:51.700
that are not on the visual stream,


00:43:51.700 --> 00:43:53.580
not YouTube, but on just audio,


00:43:53.580 --> 00:43:54.820
we're getting into the loop here


00:43:54.820 --> 00:43:55.980
where it's like run the test,


00:43:55.980 --> 00:43:56.940
evaluate the results,


00:43:56.940 --> 00:43:58.780
refine the test, refine the prompts,


00:43:58.780 --> 00:44:00.220
and then start over.


00:44:00.220 --> 00:44:03.720
Right, and probably compile the results,


00:44:03.720 --> 00:44:04.940
keep track of the results


00:44:04.940 --> 00:44:06.540
so that you can compare,


00:44:06.540 --> 00:44:10.140
not just like, are you 3% better on your test cases,


00:44:10.140 --> 00:44:12.680
but also did you,


00:44:12.680 --> 00:44:15.300
which tests that used to fail succeed now,


00:44:15.300 --> 00:44:17.020
which tests that used to fail?


00:44:17.020 --> 00:44:18.900
and succeed, fail now.


00:44:18.900 --> 00:44:21.900
And then once you're happy with the level of success


00:44:21.900 --> 00:44:25.880
you have, you can integrate the prompt into the product


00:44:25.880 --> 00:44:27.300
or maybe upgrade.


00:44:27.300 --> 00:44:28.380
- Ship it.


00:44:28.380 --> 00:44:29.820
- Yeah, ship it.


00:44:29.820 --> 00:44:31.100
- Ship it.


00:44:31.100 --> 00:44:34.620
So I think it's probably a good time to jump over


00:44:34.620 --> 00:44:37.640
to your framework for this,


00:44:37.640 --> 00:44:40.220
because pytest and other testing frameworks in Python


00:44:40.220 --> 00:44:43.140
are great, but they're pretty low level


00:44:43.140 --> 00:44:44.540
compared to these types of questions


00:44:44.540 --> 00:44:45.740
you're trying to answer, right?


00:44:45.740 --> 00:44:50.380
like how has this improved over time for,


00:44:50.380 --> 00:44:52.940
I was doing 83% right, right?


00:44:52.940 --> 00:44:54.800
pytest asserts a true or a false.


00:44:54.800 --> 00:44:57.560
It doesn't assert that 83% is.


00:44:57.560 --> 00:45:00.340
- Yeah, and it's a part of CI,


00:45:00.340 --> 00:45:04.220
like if any of your pytest fail,


00:45:04.220 --> 00:45:08.180
you're probably gonna not CI, not allow CI,


00:45:08.180 --> 00:45:10.020
not even merge the PR, right?


00:45:10.020 --> 00:45:12.360
So one thing that's different between


00:45:12.360 --> 00:45:14.840
test-driven development and unit testing


00:45:14.840 --> 00:45:19.220
and prompt engineering is that the outcome is probabilistic.


00:45:19.220 --> 00:45:20.140
It's not true or false.


00:45:20.140 --> 00:45:22.520
It might just be like zero or one, right?


00:45:22.520 --> 00:45:26.080
Where, or a spectrum, you know, it fails.


00:45:26.080 --> 00:45:29.060
For a specific test, you're like,


00:45:29.060 --> 00:45:31.880
oh, if it gets this column, but not this other column,


00:45:31.880 --> 00:45:34.380
you succeed at, you know, 50%.


00:45:34.380 --> 00:45:36.520
So it's non-binary.


00:45:36.520 --> 00:45:38.940
It's also, you don't need perfection to ship.


00:45:38.940 --> 00:45:41.520
You just need better than the previous version


00:45:41.520 --> 00:45:43.560
or good enough to start with.


00:45:43.560 --> 00:45:47.180
So the mindset is, so there's a bunch of differences.


00:45:47.180 --> 00:45:50.620
And for those interested, we won't get into the blog post.


00:45:50.620 --> 00:45:53.620
I think I list out the things that are different


00:45:53.620 --> 00:45:54.460
between the two.


00:45:54.460 --> 00:45:56.660
I think it's a little bit above this,


00:45:56.660 --> 00:45:59.580
but the first thing I wanna say is like the level


00:45:59.580 --> 00:46:02.300
of ambition of this project versus say an Airflow


00:46:02.300 --> 00:46:03.860
is super set is like very low, right?


00:46:03.860 --> 00:46:08.860
So it's maybe more similar to a test, a unit test library


00:46:11.000 --> 00:46:13.400
and no discredit to the great awesome


00:46:13.400 --> 00:46:14.940
like unit test libraries out there,


00:46:14.940 --> 00:46:17.260
but you would think those are fairly simple


00:46:17.260 --> 00:46:18.960
and straightforward,


00:46:18.960 --> 00:46:22.240
which is the information architecture of a pytest


00:46:22.240 --> 00:46:24.600
is probably simpler than the information architecture


00:46:24.600 --> 00:46:26.360
of a Django for instance, right?


00:46:26.360 --> 00:46:28.120
It's just like a different thing.


00:46:28.120 --> 00:46:30.800
And here the level of ambition is much low,


00:46:30.800 --> 00:46:34.840
and much, you know, for this is fairly simple.


00:46:34.840 --> 00:46:37.660
So Promptomize is something that I created,


00:46:37.660 --> 00:46:42.660
which is a toolkit to help people write,


00:46:42.660 --> 00:46:48.700
to evaluate and score and understand


00:46:48.700 --> 00:46:51.420
while they iterate on their,


00:46:51.420 --> 00:46:53.100
while doing prompt engineering.


00:46:53.100 --> 00:46:56.820
But so in this case, I think I talk about the use case


00:46:56.820 --> 00:46:59.820
I preset, which is we have a big corpus


00:46:59.820 --> 00:47:02.100
that luckily was contributed by,


00:47:02.100 --> 00:47:03.180
I forgot which university,


00:47:03.180 --> 00:47:08.180
but a bunch of PhD people did a text to SQL contest.


00:47:08.180 --> 00:47:09.340
- I think it was Yale.


00:47:09.340 --> 00:47:10.180
- Yale, yeah.


00:47:10.180 --> 00:47:11.940
- I think it was Yale, yeah.


00:47:11.940 --> 00:47:13.220
- So great people at Yale were like,


00:47:13.220 --> 00:47:18.220
"Hey, we're gonna generate 3000 prompts on 200 databases


00:47:18.220 --> 00:47:22.940
with the SQL that should be the outcome of that."


00:47:22.940 --> 00:47:25.700
It's a big test set so that different researchers


00:47:25.700 --> 00:47:29.340
working on text to SQL can compare their results.


00:47:29.340 --> 00:47:31.980
So for us, we were able to take that test set


00:47:31.980 --> 00:47:38.340
some of our own test sets and run it at scale against, you know, OpenAI or against


00:47:38.340 --> 00:47:44.420
LLAMA or against different models. And by doing that, we're able to evaluate like,


00:47:44.420 --> 00:47:49.980
you know, this particular combo of like this prompt engineering methodology with


00:47:49.980 --> 00:47:55.940
this model generates, you know, 73% accuracy. And we have these reports we


00:47:55.940 --> 00:48:00.460
can compare, you know, fairly easily which prompts that, as I said before, were


00:48:00.460 --> 00:48:03.300
or failing before succeeding now and vice versa.


00:48:03.300 --> 00:48:06.700
So you think, am I actually making progress here


00:48:06.700 --> 00:48:08.180
or going backwards?


00:48:08.180 --> 00:48:09.500
And if you try to do that on your own,


00:48:09.500 --> 00:48:11.220
like if you're crafting your prompt,


00:48:11.220 --> 00:48:13.760
just anecdotally and try on five or six things,


00:48:13.760 --> 00:48:15.740
like you quickly realize like,


00:48:15.740 --> 00:48:18.220
oh shit, I'm gonna need to really test


00:48:18.220 --> 00:48:20.260
out of a much broader range of this


00:48:20.260 --> 00:48:23.020
and then some rigor methodology around that.


00:48:23.020 --> 00:48:25.380
- So right, how you remember and go back and go,


00:48:25.380 --> 00:48:27.080
this actually made it better, right?


00:48:27.080 --> 00:48:30.220
'Cause it's hard to keep all that in your mind, yeah.


00:48:30.220 --> 00:48:34.260
- Yeah, and something interesting that I'm realizing


00:48:34.260 --> 00:48:36.660
to work on this stuff is like,


00:48:36.660 --> 00:48:38.020
everything is changing so fast, right?


00:48:38.020 --> 00:48:39.340
The models are changing fast,


00:48:39.340 --> 00:48:41.340
the prompting windows are changing fast,


00:48:41.340 --> 00:48:43.340
the vector databases, which is a way


00:48:43.340 --> 00:48:47.280
that organize and structure a context for your prompts,


00:48:47.280 --> 00:48:49.020
evolving extremely fast.


00:48:49.020 --> 00:48:52.500
So it feels like you're working on unsettled ground


00:48:52.500 --> 00:48:55.700
in a lot of ways, like a lot of stuff you're doing


00:48:55.700 --> 00:48:57.580
might be challenged by, you know,


00:48:57.580 --> 00:48:59.300
the BART API came out last week,


00:48:59.300 --> 00:49:01.260
Maybe it's better at SQL generation


00:49:01.260 --> 00:49:04.860
and then it got to throw everything that I did on OpenAI.


00:49:04.860 --> 00:49:06.780
But here's something you don't throw away.


00:49:06.780 --> 00:49:09.460
Your test library and your use cases.


00:49:09.460 --> 00:49:10.300
- Right.


00:49:10.300 --> 00:49:13.140
- Maybe is the thing, is the real asset here.


00:49:13.140 --> 00:49:14.260
The rest of the stuff is like,


00:49:14.260 --> 00:49:17.660
oh yeah, it's moving so fast that all the mechanics


00:49:17.660 --> 00:49:21.780
of the prompt engineering itself


00:49:21.780 --> 00:49:25.140
and the interface with the whatever model


00:49:25.140 --> 00:49:26.820
is the best at the time,


00:49:26.820 --> 00:49:28.220
you're probably gonna have to throw away


00:49:28.220 --> 00:49:31.760
as this evolves quickly, but your test library


00:49:31.760 --> 00:49:35.040
is something really, really solid that you can perpetuate


00:49:35.040 --> 00:49:36.920
or like, you know, keep improving


00:49:36.920 --> 00:49:40.040
and bringing along with you along the way.


00:49:40.040 --> 00:49:43.120
So it's kind of an interesting thought around that.


00:49:43.120 --> 00:49:44.280
- Yeah, let's talk to this,


00:49:44.280 --> 00:49:46.520
let's talk through this example you have on Promptimize


00:49:46.520 --> 00:49:49.640
is GitHub, read me here to give it,


00:49:49.640 --> 00:49:51.220
make it a little concrete for people like,


00:49:51.220 --> 00:49:53.720
how do you actually write one of these tests?


00:49:53.720 --> 00:49:56.420
- Yeah, so there's different types of prompts,


00:49:56.420 --> 00:50:00.460
But yeah, what I wanted to get to was just like,


00:50:00.460 --> 00:50:04.020
what is the prompt and how do you evaluate it?


00:50:04.020 --> 00:50:07.740
And then behind the scene, we're gonna be discovering


00:50:07.740 --> 00:50:09.540
all your prompts and running them


00:50:09.540 --> 00:50:11.620
and compiling results and reports, right?


00:50:11.620 --> 00:50:13.360
And doing analytics and making it easy


00:50:13.360 --> 00:50:14.460
to do analytics on it.


00:50:14.460 --> 00:50:15.620
The examples that we have here,


00:50:15.620 --> 00:50:18.380
and I'll try to be conscious of both the people


00:50:18.380 --> 00:50:20.580
who can read the code and people who don't,


00:50:20.580 --> 00:50:22.500
maybe the people who are just on audio.


00:50:22.500 --> 00:50:25.060
But here from Proptimize, the prompt,


00:50:25.060 --> 00:50:27.460
we import a simple prompt.


00:50:27.460 --> 00:50:29.760
And then we bring some evals that are just like utility


00:50:29.760 --> 00:50:34.060
functions around evaluating the output


00:50:34.060 --> 00:50:36.500
of what comes back from the AI.


00:50:36.500 --> 00:50:39.260
And here the first prompt case in the model,


00:50:39.260 --> 00:50:44.260
here I just create an array or a list of prompt cases.


00:50:44.260 --> 00:50:46.740
So a prompt case is like a test case.


00:50:46.740 --> 00:50:50.140
And with this prompt case, this very simple one,


00:50:50.140 --> 00:50:52.220
I say, "Hello there!"


00:50:52.220 --> 00:50:58.980
And then I evaluate that as says, you know, either hi or hello in the output, right?


00:50:58.980 --> 00:51:04.820
So if any of the words exist and what comes back, I give it a one or a zero.


00:51:04.820 --> 00:51:13.980
Framework allows you to, you could say, oh, it has to have both these words or give the percentage of success based on the number of words from this list that it has.


00:51:14.980 --> 00:51:17.700
But that's the first case.


00:51:17.700 --> 00:51:20.100
The second one is a little bit more complicated,


00:51:20.100 --> 00:51:25.100
but name the top 50 guitar players of all time, I guess.


00:51:25.100 --> 00:51:27.100
And I make sure that Frank Zappa is in the list


00:51:27.100 --> 00:51:29.900
'cause I'm a Frank Zappa fan here.


00:51:29.900 --> 00:51:32.900
But you could have a different, you could say,


00:51:32.900 --> 00:51:36.460
hey, I wanna make sure that at least three out of five


00:51:36.460 --> 00:51:37.960
of these are in the list.


00:51:37.960 --> 00:51:40.020
So those are very more natural language,


00:51:40.020 --> 00:51:44.020
very simple tests too.


00:51:44.020 --> 00:51:47.540
You know, just so that's the hello world essentially.


00:51:47.540 --> 00:51:49.380
And then, you know, we're showing some examples


00:51:49.380 --> 00:51:50.900
of what's happening behind the scene.


00:51:50.900 --> 00:51:55.140
We'll actually like call, you know, the underlying API,


00:51:55.140 --> 00:51:58.820
get the results, run your eval function and compile a report.


00:51:58.820 --> 00:52:00.700
What was the prompt?


00:52:00.700 --> 00:52:04.380
What was, oh, a bird just flew into my room.


00:52:04.380 --> 00:52:05.500
- Inside.


00:52:05.500 --> 00:52:07.760
- That's gonna make the podcast interesting.


00:52:08.660 --> 00:52:10.820
Oh my goodness. Okay.


00:52:10.820 --> 00:52:13.180
That might be a first year.


00:52:13.180 --> 00:52:14.820
That is nuts.


00:52:14.820 --> 00:52:16.260
Oh, well, it's out of my room.


00:52:16.260 --> 00:52:18.740
Guess what? There's other people in that house.


00:52:18.740 --> 00:52:21.020
I'm just going to close the door to my room.


00:52:21.020 --> 00:52:23.580
Deal with it later.


00:52:23.580 --> 00:52:26.420
all right.


00:52:26.420 --> 00:52:28.300
Well, that's, that's a first.


00:52:28.300 --> 00:52:33.940
I've had a bat fly into my house once, but, never a bird.


00:52:33.940 --> 00:52:36.020
So both are crazy.


00:52:36.020 --> 00:52:37.540
How, how interesting.


00:52:37.780 --> 00:52:39.580
This is the first on the podcast out of eight years,


00:52:39.580 --> 00:52:43.740
we've never had a bird, wild animal enter the studio of the guest.


00:52:43.740 --> 00:52:44.940
Yes.


00:52:44.940 --> 00:52:50.660
Well, I live in Tahoe, so I guess that's something that's better than a bear.


00:52:50.660 --> 00:52:53.020
You know, it is better than there.


00:52:53.020 --> 00:52:54.500
All right.


00:52:54.500 --> 00:52:57.700
but yeah, so like just like keep it enumerated, kind of what


00:52:57.700 --> 00:52:59.940
we're, we see in visually here.


00:52:59.940 --> 00:53:05.420
you know, we'll keep a YAML file as the report output.


00:53:05.860 --> 00:53:09.260
So in Promptimize, you have your test case


00:53:09.260 --> 00:53:11.940
or your prompt cases, like test cases.


00:53:11.940 --> 00:53:14.100
You have an output report that says,


00:53:14.100 --> 00:53:17.620
for this prompt case, here's the key.


00:53:17.620 --> 00:53:19.100
Here's what the prompt that was actually


00:53:19.100 --> 00:53:21.140
the user input that came in.


00:53:21.140 --> 00:53:23.100
Here's what the prompt look like.


00:53:23.100 --> 00:53:28.220
What was the response, the raw response from the API?


00:53:28.220 --> 00:53:29.140
What are all the tasks?


00:53:29.140 --> 00:53:29.980
How long did it run?


00:53:29.980 --> 00:53:33.060
So a bunch of metadata and relevant information


00:53:33.060 --> 00:53:35.940
that we can use later to create these reports.


00:53:35.940 --> 00:53:38.940
So you're like, was the score zero or one?


00:53:38.940 --> 00:53:41.220
So you got the whole output report here.


00:53:41.220 --> 00:53:43.020
- Yeah, okay.


00:53:43.020 --> 00:53:46.260
And then you also have a way to get like a report.


00:53:46.260 --> 00:53:48.260
I'm not sure, maybe I scroll past, sorry.


00:53:48.260 --> 00:53:50.820
Where it shows you how it did, right?


00:53:50.820 --> 00:53:52.380
I think that was in your-


00:53:52.380 --> 00:53:53.420
- I think at the blog post,


00:53:53.420 --> 00:53:55.100
do you see a much more complex?


00:53:55.100 --> 00:53:56.340
- There you go, yeah.


00:53:56.340 --> 00:53:59.500
- So this one, we're running the spider dataset


00:53:59.500 --> 00:54:01.100
that I just, that I talked about.


00:54:01.100 --> 00:54:05.740
Remember, it's like the Yale generated text to SQL competition corpus.


00:54:05.740 --> 00:54:10.780
So here we looked at, you know, my percentage of success is 70%.


00:54:10.780 --> 00:54:13.220
So, you know, here you say weight and score.


00:54:13.220 --> 00:54:18.700
So there's a way to say, oh, this particular prompt case is 10 times more important than another one, right?


00:54:18.700 --> 00:54:23.660
So you can do a relative importance of weight of your different text cases.


00:54:23.660 --> 00:54:28.900
Now, one thing we didn't mention too, is like all these tests are generated programmatically too.


00:54:29.380 --> 00:54:33.140
So that it's the same philosophy behind Airflow of like,


00:54:33.140 --> 00:54:37.140
it's almost like a little DSL to write your test case.


00:54:37.140 --> 00:54:40.420
So you could read from a YAML file, for instance,


00:54:40.420 --> 00:54:43.020
in the case of what we do with Spyder SQL,


00:54:43.020 --> 00:54:44.680
there's a big JSON file of all the prompts


00:54:44.680 --> 00:54:46.100
and all the databases,


00:54:46.100 --> 00:54:51.100
and then we dynamically generate 1000 tests based on that.


00:54:51.100 --> 00:54:53.820
So you can do programmatic test definition,


00:54:53.820 --> 00:54:57.020
so more and more dynamic if you want it to be,


00:54:57.020 --> 00:54:58.780
or you could do more static if you prefer that.


00:54:58.780 --> 00:55:01.020
So in this case, we're doing,


00:55:01.020 --> 00:55:03.140
we introduced this idea of a category too.


00:55:03.140 --> 00:55:05.820
So I mentioned like there's some features in Promptomize


00:55:05.820 --> 00:55:10.820
like categorizing your tests or weights,


00:55:10.820 --> 00:55:11.700
and things like that.


00:55:11.700 --> 00:55:15.660
So here we'll do some reporting on per category,


00:55:15.660 --> 00:55:17.420
what is the score per category?


00:55:17.420 --> 00:55:20.580
You can see which database is performing well


00:55:20.580 --> 00:55:21.700
or poorly again.


00:55:21.700 --> 00:55:24.540
So I could have another category that is large database,


00:55:24.540 --> 00:55:28.460
small databases and see how that what the score is.


00:55:28.460 --> 00:55:30.780
and compare reports.


00:55:30.780 --> 00:55:34.540
- It's pretty cool that it saves the test run to a file


00:55:34.540 --> 00:55:36.500
that then you can ask questions about


00:55:36.500 --> 00:55:38.980
and write and generate this report on


00:55:38.980 --> 00:55:42.700
rather than just running it and passing or failing, right?


00:55:42.700 --> 00:55:44.140
- Yeah, or like giving the output


00:55:44.140 --> 00:55:45.700
and then having to run it again.


00:55:45.700 --> 00:55:48.740
Yeah, there's some other features around if,


00:55:48.740 --> 00:55:50.780
so you can memoize the test.


00:55:50.780 --> 00:55:52.060
So because it has a reports,


00:55:52.060 --> 00:55:56.660
if you like, you know, exit off of it or restart it later,


00:55:57.900 --> 00:56:02.900
it won't rerun the same tests if it's the same hash input.


00:56:02.900 --> 00:56:05.340
Even though with AI you might get a different answer


00:56:05.340 --> 00:56:07.260
with the same input, but at least in this case


00:56:07.260 --> 00:56:12.260
it will say like, hey, I'm rerunning the same prompt


00:56:12.260 --> 00:56:14.820
instead of like waiting five seconds for open AI


00:56:14.820 --> 00:56:17.220
and then paying the tokens and paying the piper,


00:56:17.220 --> 00:56:20.080
you know, I'm just gonna skip that.


00:56:20.080 --> 00:56:22.280
So there's some logic around


00:56:22.280 --> 00:56:24.500
skipping what's been done already.


00:56:24.500 --> 00:56:26.980
- Right, yeah, that's really cool.


00:56:26.980 --> 00:56:29.820
because it's not just a couple of milliseconds to run it.


00:56:29.820 --> 00:56:32.360
It could be a while to get the answers.


00:56:32.360 --> 00:56:34.500
- Yeah, also like your early libraries,


00:56:34.500 --> 00:56:37.260
I haven't written the sub, the threading for it


00:56:37.260 --> 00:56:39.900
where you can say like, oh, run it on eight threads.


00:56:39.900 --> 00:56:45.060
So that's like, you know, things to improve the,


00:56:45.060 --> 00:56:47.100
the real leap is what we're talking.


00:56:47.100 --> 00:57:00.740
Uh-oh, we might have lost Max, folks.


00:57:00.740 --> 00:57:03.740
Hang tight.


00:57:03.740 --> 00:57:25.940
Hey Max, are you back?


00:57:25.940 --> 00:57:26.940
I'm back.


00:57:26.940 --> 00:57:27.940
Apologies.


00:57:27.940 --> 00:57:33.540
So I think my laptop's got some ports that it won't charge into.


00:57:33.540 --> 00:57:34.660
>> Yeah.


00:57:34.660 --> 00:57:38.420
>> Hopefully, too much [INAUDIBLE] Apologies for people on like,


00:57:38.420 --> 00:57:41.220
we got the bird, now we got me running out of power.


00:57:41.220 --> 00:57:43.860
>> [LAUGH] >> But we still have one.


00:57:43.860 --> 00:57:48.420
>> Maybe the bird had eaten your power cable or something, right?


00:57:48.420 --> 00:57:52.340
>> There could be a relationship between a compounding effect there.


00:57:52.340 --> 00:57:56.500
But yeah, what I was gonna say is I would prompt them, I think, and


00:57:56.500 --> 00:57:59.420
you know, the blog post is probably more impactful


00:57:59.420 --> 00:58:02.220
than the Python project itself.


00:58:02.220 --> 00:58:03.620
If the Python project takes off


00:58:03.620 --> 00:58:05.620
and a bunch of people are using it to test prompts


00:58:05.620 --> 00:58:08.260
and contribute to it, it's great.


00:58:08.260 --> 00:58:09.260
But I think it's more like,


00:58:09.260 --> 00:58:11.800
okay, this is uncharted territory,


00:58:11.800 --> 00:58:16.780
working with an AI type interface.


00:58:16.780 --> 00:58:17.900
And then it's more like,


00:58:17.900 --> 00:58:22.700
how do we best do that as practitioners


00:58:22.700 --> 00:58:24.820
or as people building products?


00:58:24.820 --> 00:58:27.420
I think that's the big idea there.


00:58:27.420 --> 00:58:29.820
Then the test library, you could probably write your own.


00:58:29.820 --> 00:58:32.900
Like I think for me, that was like a one or two week project.


00:58:32.900 --> 00:58:35.820
The way that I would like to say as like normally,


00:58:35.820 --> 00:58:39.460
if it wasn't for getting all the help from ChatGPT on,


00:58:39.460 --> 00:58:42.100
it's like, I'm creating a project,


00:58:42.100 --> 00:58:44.460
I'm setting up my setup.py,


00:58:44.460 --> 00:58:46.860
setup tools is always a little bit of a pain in the ass.


00:58:46.860 --> 00:58:51.340
And then I'm like, can you help me create like my setup.py


00:58:51.340 --> 00:58:53.140
and then generate some code.


00:58:53.140 --> 00:58:59.220
And I'm like, oh, I want to make sure that the PyPI is going to get my read me from GitHub.


00:58:59.220 --> 00:59:02.380
I forgot how to read the markdown and pass the stuff.


00:59:02.380 --> 00:59:03.740
Can you do that for me?


00:59:03.740 --> 00:59:06.740
And then Chedjiviti generates this stuff very nicely.


00:59:06.740 --> 00:59:07.060
Right.


00:59:07.060 --> 00:59:15.840
I want to make sure I use my request that requirements of TXT inside my dynamically building my setup tools integration.


00:59:15.840 --> 00:59:16.780
Can you do that for me?


00:59:16.780 --> 00:59:20.180
And it's just like, bam, bam, bam, like all that repetitive stuff.


00:59:20.180 --> 00:59:21.460
I need to find Chedjiviti.


00:59:21.460 --> 00:59:21.980
It's incredible.


00:59:21.980 --> 00:59:23.980
- Me? - Go ahead.


00:59:23.980 --> 00:59:26.620
- Yeah, I kind of want to close out the conversation with that.


00:59:26.620 --> 00:59:32.620
I do agree that the blog post is super powerful in how it kind of teaches you to think


00:59:32.620 --> 00:59:38.620
about how might you go about testing, integrating with an AI and these types of products, right?


00:59:38.620 --> 00:59:45.180
Much like TDD brought a way to think about how do we actually apply the concept just,


00:59:45.180 --> 00:59:49.340
well, I have things and I can test them with this assert thing. How should I actually go


00:59:49.340 --> 00:59:54.700
about building software, right? So this is kind of that for AI integrated software. So it's


00:59:54.700 --> 00:59:59.340
certainly worth people watching. Let's just close it out with, you kind of touched on some of those


00:59:59.340 --> 01:00:08.140
things there. How do you recommend that people leverage things like ChatGPT to help them build


01:00:08.140 --> 01:00:18.220
their apps or how to use AI to kind of amp up your software development?


01:00:18.220 --> 01:00:23.460
>> 100%, I mean, it's been a lot of people report on Twitter,


01:00:23.460 --> 01:00:31.140
people used to Google all the problems that they had while writing code.


01:00:31.140 --> 01:00:35.420
And using a lot of Stack Overflow, I don't know what the stats on Stack Overflow


01:00:35.420 --> 01:00:40.620
traffic, but once you try working with ChatterGPT to do coding,


01:00:40.620 --> 01:00:45.060
you probably don't go back to those other flows of, I don't know,


01:00:45.060 --> 01:00:48.700
It's like putting your error message or stack trace into Google and


01:00:48.700 --> 01:00:53.980
then go into a bunch of Stack Overflow link and try to make sense of what comes out.


01:00:53.980 --> 01:00:58.820
To me, it's been so much better to go just with ChatGPT and


01:00:58.820 --> 01:01:00.220
there's a conversation there too.


01:01:00.220 --> 01:01:03.900
So say for instance, if I'm in proptomize, I needed a function to say,


01:01:03.900 --> 01:01:08.100
can you write, I wrote that function before, but it's a can you crawl a certain


01:01:08.100 --> 01:01:14.380
given folder and look for modules that contain objects of a certain class?


01:01:14.380 --> 01:01:18.880
and then bring that back and you have to use the import lib


01:01:18.880 --> 01:01:21.580
and just a little bit of pain in the ass to write this.


01:01:21.580 --> 01:01:24.380
It writes a function that works pretty well.


01:01:24.380 --> 01:01:26.020
Then I'm like, "Oh, I forgot to ask you


01:01:26.020 --> 01:01:27.940
"to look into lists and dictionaries.


01:01:27.940 --> 01:01:29.340
"Can you do that too?"


01:01:29.340 --> 01:01:30.820
Then it does that in a second.


01:01:30.820 --> 01:01:33.000
It's like, "Oh, you didn't have type hints


01:01:33.000 --> 01:01:35.020
"and duck string and duck test.


01:01:35.020 --> 01:01:37.980
"Can you write that too?"


01:01:37.980 --> 01:01:39.320
And it's a bang, bang, bang,


01:01:39.320 --> 01:01:42.820
and just like copy paste in your utils file and it works.


01:01:42.820 --> 01:01:45.540
and you save like two hours, you know?


01:01:45.540 --> 01:01:47.500
- I think it would be really good at those things


01:01:47.500 --> 01:01:49.620
that are kind of algorithmic.


01:01:49.620 --> 01:01:52.300
Now, you might, they might be the kind of thing


01:01:52.300 --> 01:01:55.780
that you would do on a whiteboard job interview test, right?


01:01:55.780 --> 01:01:59.260
It just, it's just gonna know that really, really solid.


01:01:59.260 --> 01:02:02.980
It actually, but it knows quite a bit


01:02:02.980 --> 01:02:05.900
about the other libraries and stuff that are out there.


01:02:05.900 --> 01:02:06.740
- It's insane, yeah.


01:02:06.740 --> 01:02:09.540
So one thing that I came across is I wanted,


01:02:09.540 --> 01:02:11.060
I leveraged something called Lankchain,


01:02:11.060 --> 01:02:13.660
which pointed to people getting interested


01:02:13.660 --> 01:02:15.260
in prompt engineering.


01:02:15.260 --> 01:02:17.220
There's a really good,


01:02:17.220 --> 01:02:19.900
well, the library link chain is really interesting.


01:02:19.900 --> 01:02:21.940
It's not perfect, it's new, it's moving fast,


01:02:21.940 --> 01:02:24.660
but encourage people to check it out.


01:02:24.660 --> 01:02:26.740
Also like 41,000 stars, so very-


01:02:26.740 --> 01:02:28.500
- I know that's nuts, right?


01:02:28.500 --> 01:02:29.940
And it's in Python.


01:02:29.940 --> 01:02:32.140
- Yes, you can do like, yeah, it's in Python too.


01:02:32.140 --> 01:02:37.140
You should talk to whoever is writing this or started this.


01:02:37.140 --> 01:02:39.380
But yeah, you can chain some prompt


01:02:39.380 --> 01:02:42.140
to say like the output of a prompt will generate the next one.


01:02:42.140 --> 01:02:43.940
There's this idea of agents.


01:02:43.940 --> 01:02:48.820
There's this idea of estimating tokens before doing the request.


01:02:48.820 --> 01:02:53.860
There's a bunch of really cool things that it does.


01:02:53.860 --> 01:02:55.540
To me, the docs are not that comprehensive.


01:02:55.540 --> 01:03:03.340
There's someone else that created, if you Google "Lang chain cookbook", you'll find


01:03:03.340 --> 01:03:06.100
someone else that wrote what I thought was more


01:03:06.100 --> 01:03:09.720
comprehensive way to start.


01:03:09.720 --> 01:03:14.420
This one has a YouTube video and an IP1B file


01:03:14.420 --> 01:03:17.460
introduces you to the concept in an interactive way.


01:03:17.460 --> 01:03:20.280
I thought that was really, really good.


01:03:20.280 --> 01:03:23.780
But yeah, so we were trying to, I was trying to use this.


01:03:23.780 --> 01:03:26.020
I was like, oh, can you generate a bunch of like


01:03:26.020 --> 01:03:26.860
land chain related stuff?


01:03:26.860 --> 01:03:29.220
I was like, I don't know of a project calling chain.


01:03:29.220 --> 01:03:31.860
It was created after 2021.


01:03:31.860 --> 01:03:33.660
So that was like, I wish I could just say like,


01:03:33.660 --> 01:03:36.180
just go read the GitHub, you know, just read it all,


01:03:36.180 --> 01:03:39.700
read the docs and then I'll ask you questions.


01:03:39.700 --> 01:03:44.500
And then Chajupiti is not that great at that currently,


01:03:44.500 --> 01:03:47.100
at learning things that doesn't know,


01:03:47.100 --> 01:03:49.060
for reasons we talked about.


01:03:49.060 --> 01:03:51.180
Bard is much more up to date.


01:03:51.180 --> 01:03:54.500
So you can always for those projects,


01:03:54.500 --> 01:03:56.300
you know, Chajupiti might be better at Django


01:03:56.300 --> 01:03:58.660
'cause it's old and settled


01:03:58.660 --> 01:04:00.340
and it's better at writing code overall,


01:04:00.340 --> 01:04:03.420
the Bard might be decent, pretty good.


01:04:03.420 --> 01:04:06.180
- Right, if you ask advice on how to do prompt demise stuff,


01:04:06.180 --> 01:04:07.460
it's like, I don't know what that is.


01:04:07.460 --> 01:04:08.660
- Yeah, it's like, I've never heard of,


01:04:08.660 --> 01:04:09.860
it might elucidate too.


01:04:09.860 --> 01:04:11.540
I think if you'd go and make sure that,


01:04:11.540 --> 01:04:12.900
like I've seen it,


01:04:12.900 --> 01:04:14.940
like prompt demise sounds like it would be this


01:04:14.940 --> 01:04:16.740
and it just makes up stuff.


01:04:16.740 --> 01:04:20.420
So, not that great.


01:04:20.420 --> 01:04:24.140
But yeah, absolutely, I encourage people to try,


01:04:24.140 --> 01:04:26.620
for any subtasks that you're trying to do


01:04:26.620 --> 01:04:28.700
to see if it can help you at it


01:04:28.700 --> 01:04:31.380
and maybe try a variation on the prompt.


01:04:31.380 --> 01:04:34.940
And then if it's not good at it, do it the old way.


01:04:34.940 --> 01:04:37.840
But yeah, it might be better too


01:04:37.840 --> 01:04:40.700
for those familiar with the idea of functional programming


01:04:40.700 --> 01:04:42.800
where each function is more deterministic


01:04:42.800 --> 01:04:47.660
and can be reasoned about and unit test in an isolation.


01:04:47.660 --> 01:04:49.620
ChaiGPT is gonna be better at that


01:04:49.620 --> 01:04:51.800
'cause it doesn't know about all your other packages


01:04:51.800 --> 01:04:52.640
and modules.


01:04:52.640 --> 01:04:54.860
So really great for the utils functions


01:04:54.860 --> 01:04:59.740
a very deterministic, functional, super great at that.


01:04:59.740 --> 01:05:03.860
Another thing is, and you tell me when we run out of time,


01:05:03.860 --> 01:05:06.940
but another thing that was really interesting too,


01:05:06.940 --> 01:05:09.940
of bringing some of the concept and promptimize


01:05:09.940 --> 01:05:12.500
and writing the blog post itself.


01:05:12.500 --> 01:05:13.320
- Right.


01:05:13.320 --> 01:05:15.300
- And things like, hey, I'm thinking about the difference


01:05:15.300 --> 01:05:17.940
of the properties of test-driven development


01:05:17.940 --> 01:05:20.120
as it applies for prompt engineering.


01:05:20.120 --> 01:05:23.020
Here's my blog post, but can you think


01:05:23.020 --> 01:05:28.020
of other differences between the two that are very core.


01:05:28.020 --> 01:05:31.420
Can you talk about the similarities and the differences?


01:05:31.420 --> 01:05:35.540
And it would come up with just really, really great ideas,


01:05:35.540 --> 01:05:40.020
brainstorming and just very smart at mixing concepts.


01:05:40.020 --> 01:05:42.340
- I do think one thing that's not a great idea


01:05:42.340 --> 01:05:44.020
is just say, "Write this for me."


01:05:44.020 --> 01:05:46.620
But if you've got something in mind


01:05:46.620 --> 01:05:48.500
and you're gonna say, "Give me some ideas,"


01:05:48.500 --> 01:05:50.960
or, "Where should I go deeper into this?"


01:05:50.960 --> 01:05:54.840
and then you use your own creativity to create that,


01:05:54.840 --> 01:05:56.160
that's a totally valid use.


01:05:56.160 --> 01:05:59.000
I wouldn't feel like, oh, I'm reading this AI crap, right?


01:05:59.000 --> 01:06:00.880
It just, it brought out some insights


01:06:00.880 --> 01:06:02.240
that you had forgot to think about


01:06:02.240 --> 01:06:04.520
and now you are, right?


01:06:04.520 --> 01:06:05.960
- Or when it fails, it's just saying like,


01:06:05.960 --> 01:06:08.600
I got it to fail, AI is wrong, I'm smarter than it.


01:06:08.600 --> 01:06:10.560
You're like, wait, is there something,


01:06:10.560 --> 01:06:14.240
can I try to, you know, here's what it didn't get right


01:06:14.240 --> 01:06:16.540
and why, like, what did I need to tell it?


01:06:16.540 --> 01:06:20.080
So you can go and edit your prompt or ask a follow-up


01:06:20.080 --> 01:06:23.760
and generally it will do better and well.


01:06:23.760 --> 01:06:25.680
- Yeah, I think also you can ask it to find bugs


01:06:25.680 --> 01:06:27.360
or security vulnerabilities.


01:06:27.360 --> 01:06:28.200
- Yeah.


01:06:28.200 --> 01:06:31.560
- Right, you're like, here's my 30 line function.


01:06:31.560 --> 01:06:32.840
Do you see any bugs?


01:06:32.840 --> 01:06:36.400
Do you see any security vulnerabilities?


01:06:36.400 --> 01:06:40.520
Like, yeah, you're passing this straight to,


01:06:40.520 --> 01:06:42.400
you're concatenating the string in the SQL


01:06:42.400 --> 01:06:43.240
or something like that.


01:06:43.240 --> 01:06:46.420
- Yeah, the rigor stuff too,


01:06:46.420 --> 01:06:50.000
or like, I would say writing a good doc string,


01:06:50.000 --> 01:06:52.780
writing doc tests, writing unit tests,


01:06:52.780 --> 01:06:56.240
reviewing the logic, that kind of stuff.


01:06:56.240 --> 01:06:58.160
It does, type hints, right?


01:06:58.160 --> 01:07:00.480
If you're like me, I don't really like


01:07:00.480 --> 01:07:02.440
to write type hints up front,


01:07:02.440 --> 01:07:05.760
but I'm like, can you just sprinkle some type hints


01:07:05.760 --> 01:07:06.600
on top of that?


01:07:06.600 --> 01:07:08.480
- Retrofit this thing for me.


01:07:08.480 --> 01:07:10.560
- Yeah, that's it, just make it production grade.


01:07:10.560 --> 01:07:11.840
You know, one thing that's interesting too,


01:07:11.840 --> 01:07:14.360
of like, you would think I'm a big TDD guy,


01:07:14.360 --> 01:07:16.480
like I don't do test driven.


01:07:16.480 --> 01:07:17.880
(laughing)


01:07:17.880 --> 01:07:18.720
It's just not my thing.


01:07:18.720 --> 01:07:23.400
I like to write code, I don't think of what I'm gonna use the function for


01:07:23.400 --> 01:07:25.760
and before I write it.


01:07:25.760 --> 01:07:32.520
But it's good at generating unit tests for a function too.


01:07:32.520 --> 01:07:36.440
And then I think what's interesting with Promptimize too is you might,


01:07:36.440 --> 01:07:41.440
I think you want deterministic, what I call prompt cases or test cases.


01:07:41.440 --> 01:07:46.120
But you can say, I've written five or


01:07:46.120 --> 01:07:49.820
six of these can you write variations on that theme too.


01:07:49.820 --> 01:07:54.280
So you can use it to generate test cases


01:07:54.280 --> 01:07:55.740
in the case of like TDD,


01:07:55.740 --> 01:07:58.360
but also the opposite, like for promptimize,


01:07:58.360 --> 01:08:00.800
you can get it to generate stuff dynamically too.


01:08:00.800 --> 01:08:06.040
- Yeah, it's pretty amazing.


01:08:06.040 --> 01:08:07.200
It is pretty neat.


01:08:07.200 --> 01:08:08.320
Let's maybe close this out,


01:08:08.320 --> 01:08:10.080
but I'll ask you one more question.


01:08:10.080 --> 01:08:11.360
- Okay, can I do one more?


01:08:11.360 --> 01:08:12.200
Can I show one more?


01:08:12.200 --> 01:08:13.880
This is the Python podcast.


01:08:13.880 --> 01:08:15.000
- Get in there, let's do it.


01:08:15.000 --> 01:08:19.040
If you go on that repo for Promptomize under examples,


01:08:19.040 --> 01:08:21.220
there's one called Python examples.


01:08:21.220 --> 01:08:24.920
- There we go, all right.


01:08:24.920 --> 01:08:26.320
Examples. - Examples.


01:08:26.320 --> 01:08:28.840
- Yeah, Python examples. - Python examples.


01:08:28.840 --> 01:08:32.160
So if you scroll down a little bit further


01:08:32.160 --> 01:08:34.520
where you'll see a list of tests,


01:08:34.520 --> 01:08:36.040
a little bit further still.


01:08:36.040 --> 01:08:38.480
- Here we go, something like this.


01:08:38.480 --> 01:08:41.040
- Yeah, something like this, so they stop right here.


01:08:41.040 --> 01:08:42.760
So say here it says,


01:08:42.760 --> 01:08:46.600
So here I wrote a prompt that asks the bot


01:08:46.600 --> 01:08:49.180
to generate Python function.


01:08:49.180 --> 01:08:51.680
Then I sandbox it and bring the function


01:08:51.680 --> 01:08:53.640
I wrote into the interpreter.


01:08:53.640 --> 01:08:54.500
And then I test it.


01:08:54.500 --> 01:08:56.600
So I say, write a function that tests


01:08:56.600 --> 01:09:00.660
if a number is a prime number and returns a Boolean.


01:09:00.660 --> 01:09:04.840
And then I test, I have six test cases for it.


01:09:04.840 --> 01:09:07.520
So write a function that finds the greatest common denominator


01:09:07.520 --> 01:09:09.680
of two numbers, right?


01:09:09.680 --> 01:09:11.780
And then behind the scene, if we won't get


01:09:11.780 --> 01:09:13.740
to the class above, the class above,


01:09:13.740 --> 01:09:17.180
like basically interacts with it, gets the input,


01:09:17.180 --> 01:09:20.020
then runs the test and compiles the results, right?


01:09:20.020 --> 01:09:25.020
So we could test, you know, how well 3.5 compares to four,


01:09:25.020 --> 01:09:28.100
but I thought it was relevant for the Python folks


01:09:28.100 --> 01:09:29.100
on the line.


01:09:29.100 --> 01:09:32.260
So we're testing out, it is that writing Python.


01:09:32.260 --> 01:09:35.180
- Write a function that generates the Fibonacci sequence.


01:09:35.180 --> 01:09:36.020
Yeah.


01:09:36.020 --> 01:09:37.860
- Up to a certain number of terms, right?


01:09:37.860 --> 01:09:39.220
It's easy to test.


01:09:39.220 --> 01:09:41.160
So it's cool stuff.


01:09:41.160 --> 01:09:42.960
What was your last question?


01:09:42.960 --> 01:09:45.240
- Oh, I was gonna say something like,


01:09:45.240 --> 01:09:47.360
see how far we can push it.


01:09:47.360 --> 01:09:51.400
Write a Python function to use requests


01:09:51.400 --> 01:09:56.400
and beautiful soup to scrape the titles


01:09:56.400 --> 01:10:01.120
of episodes of Talk Python To Me.


01:10:01.120 --> 01:10:05.460
- Oh yeah, and there, yeah, it is.


01:10:05.460 --> 01:10:06.760
And if you don't have a, you know,


01:10:06.760 --> 01:10:09.080
one thing that's a pain in the butt for podcast people


01:10:09.080 --> 01:10:11.620
is to write like what all we talk about.


01:10:11.620 --> 01:10:14.960
So you use another AI to get the transcripts.


01:10:14.960 --> 01:10:16.160
It's like, can you write something


01:10:16.160 --> 01:10:17.780
that's gonna leverage this library


01:10:17.780 --> 01:10:19.960
to transcript the library, summarize it


01:10:19.960 --> 01:10:24.960
and publish it back with SEO in mind.


01:10:24.960 --> 01:10:27.880
- Yeah, it's really quite amazing.


01:10:27.880 --> 01:10:29.340
It went through and said, okay, here's a function


01:10:29.340 --> 01:10:33.640
and it knows talkbython.evm/episodes/all.


01:10:33.640 --> 01:10:35.200
Hughes H, get the title.


01:10:35.200 --> 01:10:37.640
And let's just finish this out, Max.


01:10:37.640 --> 01:10:39.000
I'll throw this into a--


01:10:39.000 --> 01:10:41.320
- An interpreter, see if it runs.


01:10:41.320 --> 01:10:44.120
- Interpreter, and I'll see if I can get it to run.


01:10:44.120 --> 01:10:45.920
- Hey, you know what's really interesting too,


01:10:45.920 --> 01:10:47.840
is like you can give it a random function,


01:10:47.840 --> 01:10:50.880
like you can write a function and say like,


01:10:50.880 --> 01:10:53.360
if, you know, write a certain function


01:10:53.360 --> 01:10:55.000
that does certain things, and you say,


01:10:55.000 --> 01:10:58.400
"If I give this input to this function,


01:10:58.400 --> 01:11:00.160
"what is it gonna come out of?"


01:11:00.160 --> 01:11:02.080
And it doesn't have an interpreter,


01:11:02.080 --> 01:11:05.820
but it can interpret code like you and I do, right?


01:11:05.820 --> 01:11:08.260
Like an interview question of like,


01:11:08.260 --> 01:11:10.900
hey, here's a function if I input a three as a value,


01:11:10.900 --> 01:11:12.520
what's gonna come and what's gonna return.


01:11:12.520 --> 01:11:15.440
So it's able to do the follow the loops,


01:11:15.440 --> 01:11:19.120
follow the if statements and basically just do a logical.


01:11:19.120 --> 01:11:21.320
- Yeah, another thing I think would be really good


01:11:21.320 --> 01:11:25.100
is to say, here's a function, explain to me what it does.


01:11:25.100 --> 01:11:26.260
- Oh yeah, it's super great at that.


01:11:26.260 --> 01:11:27.720
It's great at that for SQL too.


01:11:27.720 --> 01:11:30.280
Here's a stupid long SQL query.


01:11:30.280 --> 01:11:31.520
Can you explain to me?


01:11:31.520 --> 01:11:33.680
- Yeah, it's like, the explanation is on,


01:11:33.680 --> 01:11:36.480
can you just summarize that in a hundred words?


01:11:36.480 --> 01:11:37.640
- Let's go step by step.


01:11:37.640 --> 01:11:39.080
Let's do step by step.


01:11:39.080 --> 01:11:40.600
What's this do?


01:11:40.600 --> 01:11:43.000
- But yeah, I mean, maybe a closing statement is like,


01:11:43.000 --> 01:11:45.240
this stuff is changing our world.


01:11:45.240 --> 01:11:47.200
Like for me, I'm interested in how it's changing,


01:11:47.200 --> 01:11:49.320
how we're building products, you know?


01:11:49.320 --> 01:11:54.160
But the core things as a data practitioner,


01:11:54.160 --> 01:11:56.980
as a Python expert, as a programmer,


01:11:56.980 --> 01:12:00.840
it's really changing the way people work day after day.


01:12:00.840 --> 01:12:05.240
faster than we all think.


01:12:05.240 --> 01:12:08.040
And you might understand pretty well,


01:12:08.040 --> 01:12:12.560
it's changing your daily workflow as a software engineer,


01:12:12.560 --> 01:12:16.120
but it's changing people's workflow through chemistry


01:12:16.120 --> 01:12:21.120
or like in every field, there's a lot we can leverage here


01:12:21.120 --> 01:12:22.580
if you use it well.


01:12:22.580 --> 01:12:26.060
- Right, take this idea and apply it to,


01:12:26.060 --> 01:12:29.160
whatever vertical you wanna think of,


01:12:29.160 --> 01:12:31.280
It's doing the same thing there, right?


01:12:31.280 --> 01:12:32.440
Medicine all over.


01:12:32.440 --> 01:12:34.560
Yeah, 100%, 100%.


01:12:34.560 --> 01:12:38.640
All right, well, let's call it a wrap.


01:12:38.640 --> 01:12:41.480
I think we're out of time here.


01:12:41.480 --> 01:12:50.120
So really quick before we quit, PyPI package I recommend.


01:12:50.120 --> 01:12:52.680
Maybe something AI-related that you found recently.


01:12:52.680 --> 01:12:53.480
Like, oh, this thing's cool.


01:12:53.480 --> 01:12:55.520
People should check it out.


01:12:55.520 --> 01:12:58.400
>>Proptimize, I think it would be something to check out.


01:12:58.400 --> 01:13:00.120
I think there's something called future tools


01:13:00.120 --> 01:13:01.700
that you could try to navigate there,


01:13:01.700 --> 01:13:05.780
but it shows like all of the AI powered tools


01:13:05.780 --> 01:13:08.720
that are coming out and it's hard to keep up.


01:13:08.720 --> 01:13:10.840
- Yeah, yeah, I think I have seen that, yeah.


01:13:10.840 --> 01:13:13.800
- And then if you wanna keep up on a daily


01:13:13.800 --> 01:13:17.840
with what's happening in AI, there's TLDR AI,


01:13:17.840 --> 01:13:22.160
they have like a DL with relevant lists for the day.


01:13:22.160 --> 01:13:25.440
I think that's a, it's hard to stay on.


01:13:25.440 --> 01:13:30.440
I prefer like their weekly digest of what's going on in AI.


01:13:30.440 --> 01:13:33.260
- Just a stream of information.


01:13:33.260 --> 01:13:36.520
- Yeah, it's kind of dizzying and it's like,


01:13:36.520 --> 01:13:38.000
oh, this new model does this.


01:13:38.000 --> 01:13:39.320
Like I've got to change everything to that.


01:13:39.320 --> 01:13:43.680
And then something else that if you update


01:13:43.680 --> 01:13:45.160
the correct course too often,


01:13:45.160 --> 01:13:47.080
and it's just like, you know, do nothing.


01:13:47.080 --> 01:13:50.480
'Cause you're like, the foundation's shifting


01:13:50.480 --> 01:13:52.520
too fast under you, so.


01:13:52.520 --> 01:13:54.280
- Yeah, absolutely.


01:13:54.280 --> 01:13:55.120
Well, very cool.


01:13:55.120 --> 01:13:59.120
And then final question, you're gonna write some pilot code.


01:13:59.120 --> 01:14:00.920
What editor are you using these days?


01:14:00.920 --> 01:14:03.080
- I'm a Vim user.


01:14:03.080 --> 01:14:05.120
Yeah, I know it's not the best.


01:14:05.120 --> 01:14:06.480
I'd like, I know all the limitation,


01:14:06.480 --> 01:14:08.600
but it's like muscle memory.


01:14:08.600 --> 01:14:12.640
And I'm a UX guy now working on supersets.


01:14:12.640 --> 01:14:17.640
I do appreciate the development of all the new IDEs


01:14:17.640 --> 01:14:19.560
and the functionality that they have.


01:14:19.560 --> 01:14:21.320
I think it's amazing.


01:14:21.320 --> 01:14:23.520
It's just like, for me, it's all,


01:14:23.520 --> 01:14:25.980
Like I know all my bash commands and big commands


01:14:25.980 --> 01:14:27.940
and my muscle memory.


01:14:27.940 --> 01:14:31.140
So I just do things that way still.


01:14:31.140 --> 01:14:31.980
- Absolutely.


01:14:31.980 --> 01:14:35.420
All right, well, Max, thanks for coming on the show,


01:14:35.420 --> 01:14:38.700
helping everyone explore this wild new frontier


01:14:38.700 --> 01:14:40.180
of AI and large language models.


01:14:40.180 --> 01:14:41.020
And for creating-


01:14:41.020 --> 01:14:44.180
- Yeah, well, exploring it while we're still relevant


01:14:44.180 --> 01:14:47.620
because I don't know how long we're gonna be relevant for.


01:14:47.620 --> 01:14:48.860
So yeah.


01:14:48.860 --> 01:14:49.980
- Yeah.


01:14:49.980 --> 01:14:50.980
Enjoy it while we can, right?


01:14:50.980 --> 01:14:51.820
Get out there.


01:14:51.820 --> 01:14:53.580
[LAUGHTER]


01:14:53.580 --> 01:14:56.780
Either control the robots or be controlled by them.


01:14:56.780 --> 01:14:58.980
So get on the right side of that.


01:14:58.980 --> 01:15:00.660
All right, thanks again.


01:15:00.660 --> 01:15:02.180
Yeah, see you later.


01:15:02.180 --> 01:15:04.140
Yeah, as always.


01:15:04.140 --> 01:15:04.640
Bye.


01:15:04.640 --> 01:15:14.640
[BLANK_AUDIO]

