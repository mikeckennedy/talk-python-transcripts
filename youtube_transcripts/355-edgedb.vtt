WEBVTT

00:00:00.000 --> 00:00:03.720
- Everyone on YouTube, thank you for joining us


00:00:03.720 --> 00:00:06.040
and watching the live stream or being part of the live stream.


00:00:06.040 --> 00:00:09.280
If you're here now, Yuri, happy to have you


00:00:09.280 --> 00:00:10.120
on the YouTube channel.


00:00:10.120 --> 00:00:12.600
You about ready to kick off this podcast thing?


00:00:12.600 --> 00:00:14.000
- Absolutely, let's do it.


00:00:14.000 --> 00:00:14.840
- Right on.


00:00:14.840 --> 00:00:15.660
- Right there.


00:00:15.660 --> 00:00:18.040
(laughing)


00:00:18.040 --> 00:00:20.600
- Yuri, welcome to Talk Python to Me.


00:00:20.600 --> 00:00:22.160
- Yeah, yeah.


00:00:22.160 --> 00:00:23.320
- It's great to have you here.


00:00:23.320 --> 00:00:27.340
You know, we just met recently at Pi Bay down there.


00:00:27.340 --> 00:00:30.200
So in honor of that, I wore my Pie Bay shirt today.


00:00:30.200 --> 00:00:33.540
- Oh my God, I forgot about that episode.


00:00:33.540 --> 00:00:35.780
- Yeah, where's your Pie Bay shirt?


00:00:35.780 --> 00:00:36.620
Oh, come on.


00:00:36.620 --> 00:00:37.820
- Yeah, yeah, yeah.


00:00:37.820 --> 00:00:39.540
- What a cool conference, huh?


00:00:39.540 --> 00:00:40.580
- Yeah, it is, it is.


00:00:40.580 --> 00:00:42.820
I love small conferences.


00:00:42.820 --> 00:00:46.940
- I like small conferences and in the time of COVID


00:00:46.940 --> 00:00:48.440
and all of this madness,


00:00:48.440 --> 00:00:53.260
having a winter conference outside in California


00:00:53.260 --> 00:00:55.700
at a beautiful food cart area where it's warm.


00:00:55.700 --> 00:00:58.040
Oh, there were just so many things to like about that.


00:00:58.040 --> 00:00:59.600
I gotta tell you, it was great.


00:00:59.600 --> 00:01:00.440
- It was amazing.


00:01:00.440 --> 00:01:03.560
It was the best day of the year for me, essentially.


00:01:03.560 --> 00:01:05.440
Just being able to talk to people finally.


00:01:05.440 --> 00:01:06.280
- I know, I know.


00:01:06.280 --> 00:01:08.120
- And meeting new friends was amazing.


00:01:08.120 --> 00:01:09.880
- And we both gave talks there.


00:01:09.880 --> 00:01:11.840
I talked about Flask and HTMX,


00:01:11.840 --> 00:01:15.240
and you spoke about building a database engine,


00:01:15.240 --> 00:01:19.840
a whole database with Python, and that was interesting.


00:01:19.840 --> 00:01:22.160
So then I watched a little more and I just thought,


00:01:22.160 --> 00:01:25.680
Wow, there are a lot of interesting pieces of technology


00:01:25.680 --> 00:01:28.880
in and around this thing you built called EdgeDB.


00:01:28.880 --> 00:01:30.600
So I'm super excited to dive into that with you.


00:01:30.600 --> 00:01:33.440
But before we do, let's just hear your story real quick.


00:01:33.440 --> 00:01:35.400
How'd you get into programming in Python?


00:01:35.400 --> 00:01:41.960
- So my co-founder, Elvis and I met many years ago,


00:01:41.960 --> 00:01:44.000
probably 14 years ago or something like that,


00:01:44.000 --> 00:01:47.000
working in a small Canadian company,


00:01:47.000 --> 00:01:51.280
building big enterprise software for companies like Walmart.


00:01:51.280 --> 00:01:54.320
And back then, we were actually--


00:01:54.320 --> 00:01:59.800
the system that we were working on was written in PHP.


00:01:59.800 --> 00:02:02.200
And we pushed PHP to the limits, but we always


00:02:02.200 --> 00:02:06.200
knew that, hey, when we start our own thing,


00:02:06.200 --> 00:02:10.080
we will be looking for something new and fresh for us


00:02:10.080 --> 00:02:11.320
to tinker with.


00:02:11.320 --> 00:02:15.920
And we looked around, and we just liked Python.


00:02:15.920 --> 00:02:17.240
Liked it a lot.


00:02:17.240 --> 00:02:17.760
Fantastic.


00:02:17.760 --> 00:02:18.720
Was that Django?


00:02:18.720 --> 00:02:20.800
I mean, that's right around the time of the Django growth,


00:02:20.800 --> 00:02:22.800
or was it something else that brought you in?


00:02:22.800 --> 00:02:24.720
- We started with Django.


00:02:24.720 --> 00:02:26.680
We played with it a little,


00:02:26.680 --> 00:02:30.600
but actually like we just started building our own thing


00:02:30.600 --> 00:02:33.880
pretty much immediately without looking like


00:02:33.880 --> 00:02:37.240
too deeply at existing frameworks or anything.


00:02:37.240 --> 00:02:39.160
- Yeah, I get the sense that you and your co-founder


00:02:39.160 --> 00:02:41.320
are framework builders.


00:02:41.320 --> 00:02:42.560
- Yes, yes, we are.


00:02:42.560 --> 00:02:44.680
Somebody asked me, maybe it was Guido,


00:02:44.680 --> 00:02:45.520
I don't remember anymore,


00:02:45.520 --> 00:02:48.760
what was your first thing that you wrote in Python?


00:02:48.760 --> 00:02:50.760
and I said, "Function decorator."


00:02:50.760 --> 00:02:51.600
(laughs)


00:02:51.600 --> 00:02:53.840
I could just jump right in.


00:02:53.840 --> 00:02:54.940
- Exactly, awesome.


00:02:54.940 --> 00:02:57.520
Cool.


00:02:57.520 --> 00:02:59.580
So how about now?


00:02:59.580 --> 00:03:01.200
What are you doing these days?


00:03:01.200 --> 00:03:03.240
Working on EdgeDB full-time?


00:03:03.240 --> 00:03:05.800
- EdgeDB full-time exclusively, yeah.


00:03:05.800 --> 00:03:07.360
We're building a great company here,


00:03:07.360 --> 00:03:11.700
so it requires 100% of my attention.


00:03:11.700 --> 00:03:13.160
- Yeah, I bet it does.


00:03:13.160 --> 00:03:17.000
You can build a business on the side,


00:03:17.000 --> 00:03:19.480
but it's a hard time.


00:03:19.480 --> 00:03:22.700
And you have this great article that talks about


00:03:22.700 --> 00:03:24.900
how you're gonna build your favorite new database


00:03:24.900 --> 00:03:27.220
in a month, but that it actually takes 10 years


00:03:27.220 --> 00:03:28.980
or something like that, right?


00:03:28.980 --> 00:03:29.820
- Yeah, pretty much.


00:03:29.820 --> 00:03:34.700
Yeah, it was a long, sometimes painful journey.


00:03:34.700 --> 00:03:38.460
And we didn't realize like right off the bat


00:03:38.460 --> 00:03:40.700
that we will be building a database, right?


00:03:40.700 --> 00:03:43.060
We were building a Python framework


00:03:43.060 --> 00:03:45.820
and the Python or essentially.


00:03:45.820 --> 00:03:47.920
- A better way to talk to databases in Python


00:03:47.920 --> 00:03:49.500
was your idea, right?


00:03:49.500 --> 00:03:51.120
- Yeah, yeah, exactly.


00:03:51.120 --> 00:03:54.060
- Yeah, but I guess you didn't have in mind


00:03:54.060 --> 00:03:55.940
that you would also build the database.


00:03:55.940 --> 00:03:56.920
(laughing)


00:03:56.920 --> 00:03:58.860
- No idea, yeah.


00:03:58.860 --> 00:03:59.700
- Very cool.


00:03:59.700 --> 00:04:01.480
Well, I think what you built is pretty interesting


00:04:01.480 --> 00:04:03.740
and people are going to enjoy checking it out.


00:04:03.740 --> 00:04:06.820
But more so, I think what is pretty interesting


00:04:06.820 --> 00:04:10.740
is there's a lot of things in the Python space


00:04:10.740 --> 00:04:12.920
that we enjoy and we appreciate,


00:04:12.920 --> 00:04:16.240
especially what I would consider to be


00:04:16.240 --> 00:04:19.380
the advantages of modern Python.


00:04:19.380 --> 00:04:20.220
I don't know how you feel about it.


00:04:20.220 --> 00:04:22.260
I know you've been deep in this world,


00:04:22.260 --> 00:04:25.880
but to me it seems like just two or three years ago,


00:04:25.880 --> 00:04:28.380
the people building frameworks,


00:04:28.380 --> 00:04:31.220
think FastAPI or Pydantic or stuff like that,


00:04:31.220 --> 00:04:36.220
have really embraced the true,


00:04:36.220 --> 00:04:38.940
they'd taken full advantage of Python 3, right?


00:04:38.940 --> 00:04:40.300
They said, oh, look, we have these typing,


00:04:40.300 --> 00:04:41.620
we have typing, we have async and await,


00:04:41.620 --> 00:04:43.180
We have all these things that we can bring together,


00:04:43.180 --> 00:04:44.700
and it really feels like that stuff


00:04:44.700 --> 00:04:48.620
is all starting to come together in a big way.


00:04:48.620 --> 00:04:51.580
Is that, over the last couple of years, what do you think?


00:04:51.580 --> 00:04:54.380
- Yeah, I also have this feeling


00:04:54.380 --> 00:04:57.700
that the ecosystem becomes more and more robust,


00:04:57.700 --> 00:05:00.780
that people build amazing systems with Python.


00:05:00.780 --> 00:05:05.780
I think that asynchronous I/O played a part in it, for sure.


00:05:05.780 --> 00:05:08.980
But I think that the other big thing


00:05:08.980 --> 00:05:10.500
that is happening to Python right now


00:05:10.500 --> 00:05:15.500
is strict typing, mypy and other similar tools.


00:05:15.500 --> 00:05:17.340
This is what actually allows you


00:05:17.340 --> 00:05:19.660
to manage your code base at scale.


00:05:19.660 --> 00:05:23.500
And this is just incredibly important.


00:05:23.500 --> 00:05:26.300
So yeah, those two things I would say.


00:05:26.300 --> 00:05:28.260
- Absolutely, and you talk, we're gonna get into it


00:05:28.260 --> 00:05:29.520
when we get into the architecture and stuff,


00:05:29.520 --> 00:05:31.100
but you talk about using Cython


00:05:31.100 --> 00:05:34.100
for making parts of your Python code faster.


00:05:34.100 --> 00:05:37.340
And of course that relies heavily on typing


00:05:37.340 --> 00:05:39.300
'cause you wanna say, here's an int64,


00:05:39.300 --> 00:05:43.980
don't turn it to a pi long object pointer.


00:05:43.980 --> 00:05:47.280
We just want an int64 that works on the stack really quickly,


00:05:47.280 --> 00:05:48.460
right?


00:05:48.460 --> 00:05:49.580
- Yeah, yeah, absolutely.


00:05:49.580 --> 00:05:51.660
I mean, it's an open question.


00:05:51.660 --> 00:05:53.780
Will Python ever enjoy strict typing


00:05:53.780 --> 00:06:00.540
that the Python interpreter actually


00:06:00.540 --> 00:06:03.900
takes care of to make things run faster or not?


00:06:03.900 --> 00:06:06.580
But for Cython, it's absolutely critical.


00:06:06.580 --> 00:06:08.500
And actually, I had this--


00:06:08.500 --> 00:06:12.340
Sometimes I have this feeling that writing code in Cython is easier than in Python


00:06:12.340 --> 00:06:13.540
because, hey, I have a compiler.


00:06:13.540 --> 00:06:17.780
If something mismatches, I know it at the compile time, not the runtime.


00:06:17.780 --> 00:06:20.900
Yeah, I suspect mypy is a little like that as well, right?


00:06:20.900 --> 00:06:21.860
Exactly, exactly.


00:06:21.860 --> 00:06:26.740
So when mypy started happening, because I was experimenting heavily with Cython before


00:06:26.740 --> 00:06:31.940
mypy became popular, when mypy finally became like this common thing to use,


00:06:31.940 --> 00:06:36.420
yeah, it was almost a revelation that we finally have this beautiful workflow with Python.


00:06:36.420 --> 00:06:41.060
- Yeah. Well, I want to talk about some of the technologies


00:06:41.060 --> 00:06:44.020
that are sort of surrounding this larger project


00:06:44.020 --> 00:06:45.540
that you've been working on.


00:06:45.540 --> 00:06:48.820
So over on GitHub, github.com/magicstack,


00:06:48.820 --> 00:06:52.100
this is your company,


00:06:52.100 --> 00:06:55.140
and one of the, you know, where sort of EdgeDB


00:06:55.140 --> 00:06:56.820
and all that is coming out of.


00:06:56.820 --> 00:07:00.580
But there's a lot of interesting things happening here


00:07:00.580 --> 00:07:04.580
that I think people who see modern Python doing its thing


00:07:05.220 --> 00:07:07.100
are going to appreciate.


00:07:07.100 --> 00:07:10.260
We talked about the async stuff and so on.


00:07:10.260 --> 00:07:12.980
So I wanted to dive into some of those first that


00:07:12.980 --> 00:07:17.080
are orbiting your projects that you all have created here.


00:07:17.080 --> 00:07:19.220
So let's start with MagicPython.


00:07:19.220 --> 00:07:21.500
Tell us what this MagicPython is about.


00:07:21.500 --> 00:07:24.280
>> So MagicPython is a syntax highlighter,


00:07:24.280 --> 00:07:27.580
and it's actually used in VS Code by default.


00:07:27.580 --> 00:07:30.380
So if you use VS Code and you edit Python in VS Code,


00:07:30.380 --> 00:07:34.100
this is the stuff that VS Code uses under the hood.


00:07:34.100 --> 00:07:39.060
It was used by GitHub for years to highlight all Python code.


00:07:39.060 --> 00:07:45.300
And recently, I think GitHub switched to this TreeSitter, other Python highlighter.


00:07:45.300 --> 00:07:50.980
But yeah, MagicPython was, and I guess is, incredibly popular.


00:07:50.980 --> 00:07:56.020
It was born out of frustration, actually, because we were big fans of metaprogramming.


00:07:56.020 --> 00:07:58.900
We abused Python a lot in interesting ways.


00:07:58.900 --> 00:08:06.580
and one of the ways to abuse it was to push some meta information to function annotations.


00:08:06.580 --> 00:08:13.300
It was before mypy and before typing, so yeah, we just were adding stuff to those annotations.


00:08:13.300 --> 00:08:18.660
And we quickly discovered that built-in syntax highlighters in TextMate back then,


00:08:18.660 --> 00:08:23.380
back then I was using TextMate heavily, they just couldn't highlight annotations.


00:08:23.380 --> 00:08:28.420
So my goal was to basically, hey, can we create our own syntax


00:08:28.420 --> 00:08:30.880
collateral for Python that would just take care of notations?


00:08:30.880 --> 00:08:35.620
And by the way, highlight all of the newer stuff that is available in Python 3.


00:08:35.620 --> 00:08:40.420
Because back then, Python 2 was still the king and Python 3 was kind of...


00:08:40.420 --> 00:08:43.920
- Interesting. So a lot of the highlighters and editors and stuff


00:08:43.920 --> 00:08:47.920
really would highlight kind of based on Python 2 type of syntax.


00:08:47.920 --> 00:08:48.620
- Exactly. - Okay.


00:08:48.620 --> 00:08:49.880
- Exactly. Exactly.


00:08:49.880 --> 00:08:54.360
I know, it's 20... whatever this was, 2015 or something.


00:08:54.360 --> 00:08:57.640
2015, yeah, it was clear to me that Python 3 is the future,


00:08:57.640 --> 00:09:01.960
but yeah, the industry was still kind of moving slowly towards it.


00:09:01.960 --> 00:09:09.960
But the key innovation of MagicPython, and I think this is why I think it's a high quality thing,


00:09:09.960 --> 00:09:12.360
is unit tests.


00:09:12.360 --> 00:09:19.240
So I'm a big fan of writing tests and having this test-driven development.


00:09:19.240 --> 00:09:25.680
And the first thing after highlighting Hello World in TextMate,


00:09:25.680 --> 00:09:30.720
the first thing for me was to figure out, can I actually build a unit test engine?


00:09:30.720 --> 00:09:35.760
Because if you think of those syntax highlighters, essentially, it's a huge reg exp.


00:09:35.760 --> 00:09:39.920
It's just mind-bogglingly huge, huge, huge reg exp.


00:09:39.920 --> 00:09:42.640
- And writing reg exp is hard. - I was thinking about that.


00:09:42.640 --> 00:09:44.000
Yeah.


00:09:44.000 --> 00:09:47.280
- But modifying... - I was thinking about that.


00:09:47.280 --> 00:09:53.200
Well, I was thinking down the road, you have a really interesting query syntax that's pretty


00:09:53.200 --> 00:09:56.400
rich and powerful for EdgeDB.


00:09:56.400 --> 00:10:01.560
Did your experience writing Magic Python give you the ability to go like, "Oh yeah, we can


00:10:01.560 --> 00:10:06.640
write this thing that parses this insane complex language"?


00:10:06.640 --> 00:10:12.240
How much did this play into your ability to go beyond SQL?


00:10:12.240 --> 00:10:13.240
I wouldn't say much.


00:10:13.240 --> 00:10:17.700
I mean, we have syntax highlighters for schema files and the HQL.


00:10:17.700 --> 00:10:19.200
They're pretty basic right now.


00:10:19.200 --> 00:10:23.020
We just highlight keywords and literals.


00:10:23.020 --> 00:10:27.160
We have some interesting plans about that, and we can talk about it later, I guess, when


00:10:27.160 --> 00:10:32.420
we'll be talking about HDB, like implementing language server protocol for HQL.


00:10:32.420 --> 00:10:35.300
But the highlighter itself is pretty simple.


00:10:35.300 --> 00:10:41.260
But I used this unit testing framework in those highlighters, and this is what gives


00:10:41.260 --> 00:10:42.260
me peace of mind.


00:10:42.260 --> 00:10:47.060
that the HQL highlighter is just working when I'm adding like a new operator or a new keyword.


00:10:47.060 --> 00:10:51.620
I don't have to just test it manually on some like big file.


00:10:51.620 --> 00:10:57.780
Yeah, absolutely. Sort of speaking to that thing that I talked about, a lot of interesting stuff


00:10:57.780 --> 00:11:02.580
coming out of your work. Adrian out there says, "Didn't know you also made HTTP tools as well."


00:11:02.580 --> 00:11:08.180
Indeed, yeah, there's a lot of cool stuff that you've done. So final thing on MagicPython,


00:11:09.940 --> 00:11:13.700
Can I use it for other purposes than just VS Code Sublime and Atom?


00:11:13.700 --> 00:11:19.060
Like, if I wanted to build my own thing that, you know, printed out, like, terminal stuff


00:11:19.060 --> 00:11:27.700
or like some other kind of UI app, could I build, could I use this more generally than the editors?


00:11:27.700 --> 00:11:33.300
I haven't tried it myself, but given that GitHub was using it to highlight the code,


00:11:33.300 --> 00:11:37.940
I believe that there must be some libraries and packages that just can consume this


00:11:37.940 --> 00:11:43.460
text made inspired syntax and just highlight, I don't know, stuff you printed to terminal.


00:11:43.460 --> 00:11:47.620
>> I see. So it comes out as text made and then it just happens to these three editors


00:11:47.620 --> 00:11:50.580
with their common heritage understand that. Yeah.


00:11:50.580 --> 00:11:55.060
>> Yeah. I think text made started the revolution originally, then sublime text just inherited the


00:11:55.060 --> 00:11:59.540
format and then VS Code just decided, hey, we should just use it. Yeah.


00:11:59.540 --> 00:12:03.780
>> Cool. Yeah. Very cool. All right. Next, let's talk ASync.


00:12:06.980 --> 00:12:13.780
So when you spoke about your journey towards creating this product in this business,


00:12:13.780 --> 00:12:21.620
you talked about how central having asynchronous I/O and server work is going to be. And of course


00:12:21.620 --> 00:12:28.340
that is true, right? Not all databases, but most databases are able to be a point of extreme


00:12:28.340 --> 00:12:33.380
concurrency to the point that they can like handle the processing, right? So if you've got a web app,


00:12:33.380 --> 00:12:38.260
you could scale your web app out and like if it's got two connections or 200 connections to the database,


00:12:38.260 --> 00:12:43.380
generally that's fine. The database is meant to sort of scale that vertically, I guess.


00:12:43.380 --> 00:12:48.100
So you really talked about, well, if you're going to do this in Python,


00:12:48.100 --> 00:12:51.220
that probably means leveraging asyncio pretty strongly, right?


00:12:51.220 --> 00:12:57.380
Yeah, yeah. It was pretty clear that we need asynchronous IO. As you said, databases have to


00:12:57.380 --> 00:13:01.860
handle lots of connections. And also it's important to understand that most databases, like Postgres,


00:13:01.860 --> 00:13:06.020
for example, the cost of establishing a new connection is pretty high.


00:13:06.020 --> 00:13:12.100
So we wanted Edge... I mean, there are tools to mitigate that, like PgBouncer, for example.


00:13:12.100 --> 00:13:15.900
It's like middleware you put in front of PostgreSQL to make connections cheaper.


00:13:15.900 --> 00:13:22.380
And we just didn't want to have any of such tools as a requirement for EdgeDB.


00:13:22.380 --> 00:13:26.580
We just wanted it to work natively out of the box without any configuration.


00:13:26.580 --> 00:13:32.500
So yeah, we had to have cheap connections in terms of how fast you can connect.


00:13:32.500 --> 00:13:35.620
And also, I mean, if your connection is just hanging out there,


00:13:35.620 --> 00:13:38.740
we wanted to allow that, essentially.


00:13:38.740 --> 00:13:43.300
So we had to have a way to handle thousands,


00:13:43.300 --> 00:13:45.540
maybe hundreds of thousands, just concurrent connections


00:13:45.540 --> 00:13:48.100
that maybe are not super active, but just, I mean, open.


00:13:48.100 --> 00:13:55.140
And asynchronous core is the only way how you would be able to do this.


00:13:55.140 --> 00:13:58.980
Like not even like even if Python didn't have GIL, for example,


00:13:58.980 --> 00:14:03.460
we would still use asynchronous I/O to tackle this problem.


00:14:03.460 --> 00:14:07.700
Yeah, I don't know exactly what the memory cost of a thread in Python is,


00:14:07.700 --> 00:14:12.740
but there's an overhead for threads and the context switching between the OS


00:14:12.740 --> 00:14:15.300
trying to figure out if that thread still needs to do stuff.


00:14:15.300 --> 00:14:18.740
Yeah, you can't have hundreds of thousands of threads and be in a good place.


00:14:18.740 --> 00:14:22.420
Yeah, but my concern wasn't even that.


00:14:22.980 --> 00:14:25.380
maybe we would be smart and implement some sort of


00:14:25.380 --> 00:14:28.900
m2n scheduling or something like that. I don't know.


00:14:28.900 --> 00:14:34.100
It's just I don't believe that humans are good at writing threaded code.


00:14:34.100 --> 00:14:40.580
Async/await gives you this luxury of essentially seeing where you can


00:14:40.580 --> 00:14:43.940
actually give up control of the current code when it can await


00:14:43.940 --> 00:14:47.380
things and potentially switch the context, right? So you can be smart


00:14:47.380 --> 00:14:51.060
about locking access to shared resources and things like that.


00:14:51.060 --> 00:14:55.100
With threads, it's way, way harder.


00:14:55.100 --> 00:14:59.340
Maybe with Rust, it's easier because there is some compile time magic


00:14:59.340 --> 00:15:01.500
that can help you.


00:15:01.500 --> 00:15:04.660
But with pretty much every other language,


00:15:04.660 --> 00:15:07.860
thread-based programming is very hard.


00:15:07.860 --> 00:15:08.860
It is hard.


00:15:08.860 --> 00:15:12.700
Well, I suspect many people, but not everyone out there listening,


00:15:12.700 --> 00:15:18.620
knows that when you use the async I/O tasks and so on,


00:15:18.620 --> 00:15:21.040
at least by default, they run on a single thread.


00:15:21.040 --> 00:15:23.040
There's not actual threading happening.


00:15:23.040 --> 00:15:24.040
Right?


00:15:24.040 --> 00:15:28.260
When you use threads or multi-processing, you can get that true concurrency,


00:15:28.260 --> 00:15:30.260
but this is different.


00:15:30.260 --> 00:15:31.260
It's not really threads.


00:15:31.260 --> 00:15:32.760
Yeah, it's different.


00:15:32.760 --> 00:15:40.560
Basically, the idea for Async/Await is to use it for I/O bound code.


00:15:40.560 --> 00:15:43.060
So if your code is doing lots of I/O,


00:15:43.060 --> 00:15:45.980
pushing data from multiple connections here and there,


00:15:45.980 --> 00:15:47.360
this is an ideal thing.


00:15:47.360 --> 00:15:51.600
But if you're computing something like, I don't know,


00:15:51.600 --> 00:15:57.080
doing something scientific computation or just use blocking I/O or disk I/O,


00:15:57.080 --> 00:16:01.080
it's best to offset that computation into a separate process.


00:16:01.080 --> 00:16:07.840
But yeah, if you just want to handle a lot of I/O in Python concurrently,


00:16:07.840 --> 00:16:10.640
Async I/O is the way.


00:16:10.640 --> 00:16:16.320
Yeah, the way that I like to think of Async I/O and Async and Await


00:16:16.320 --> 00:16:20.560
is what you're scaling is you're scaling the waiting. If you're


00:16:20.560 --> 00:16:23.400
waiting on anything, if I'm waiting on a database or waiting


00:16:23.400 --> 00:16:26.320
in the database version for the client to talk to me or not to


00:16:26.320 --> 00:16:30.360
talk to me, then you can basically take that period where


00:16:30.360 --> 00:16:33.360
you'd be waiting and turn that into predictive computational


00:16:33.360 --> 00:16:33.640
time.


00:16:33.640 --> 00:16:36.720
I love it. I think we should put this like straight into the


00:16:36.720 --> 00:16:39.640
ducks. I never thought about this way.


00:16:39.640 --> 00:16:45.720
I'll see these, these benchmarks and stuff said, Oh, well, I did


00:16:45.720 --> 00:16:49.920
this thing where I overwhelmed the database and then it didn't go very fast when I did


00:16:49.920 --> 00:16:54.080
async I/O. It's like, well, because there's no period in which you're waiting. You're


00:16:54.080 --> 00:16:58.400
like constraining the resource beyond what it can take. But if there was some sort of,


00:16:58.400 --> 00:17:02.040
oh, I'm waiting for this thing to get back to me. Well, then all of a sudden there's


00:17:02.040 --> 00:17:07.280
your performance. Okay. So when I saw this come out, I was super excited. I think this


00:17:07.280 --> 00:17:14.360
was three, four, if my history reminds me correctly when this came out. Do you remember?


00:17:14.360 --> 00:17:22.600
I think it was around 3.4 because the most important prerequisite for async.io to happen


00:17:22.600 --> 00:17:24.840
was actually the yield from syntax.


00:17:24.840 --> 00:17:27.400
Probably not a lot of people remember about it.


00:17:27.400 --> 00:17:33.140
But back then async.io required this add-courting decorator and you would use yield from instead


00:17:33.140 --> 00:17:34.820
of await in your code.


00:17:34.820 --> 00:17:41.000
So that PEP, so basically Python 3.3 I think was a moratorium on modifying Python language.


00:17:41.000 --> 00:17:44.420
So we had to wait for Python 3.4 to add yield from,


00:17:44.420 --> 00:17:45.580
and then async happened.


00:17:45.580 --> 00:17:47.340
- Right, that enabled it.


00:17:47.340 --> 00:17:48.540
But when I remember when it came out,


00:17:48.540 --> 00:17:50.540
I was like super excited about this.


00:17:50.540 --> 00:17:53.340
And I saw like, oh, this is a harsh programming model.


00:17:53.340 --> 00:17:56.700
This is really like direct in juggling


00:17:56.700 --> 00:17:58.720
the those sorts of things.


00:17:58.720 --> 00:18:01.220
And I had experience with C#,


00:18:01.220 --> 00:18:04.580
which had async and await keywords as well.


00:18:04.580 --> 00:18:06.900
I'm like, gosh, I wish this language had async and await.


00:18:06.900 --> 00:18:08.580
And then I didn't know you then,


00:18:08.580 --> 00:18:13.580
But I thank you because you offered authored PEP 492


00:18:13.580 --> 00:18:15.760
co-routines with async and await.


00:18:15.760 --> 00:18:18.180
Basically we have async and await in Python


00:18:18.180 --> 00:18:19.280
because of you, right?


00:18:19.280 --> 00:18:21.600
- Well, yes.


00:18:21.600 --> 00:18:23.700
- I don't wanna give you too much credit,


00:18:23.700 --> 00:18:25.720
you created the prep, the PEP that said,


00:18:25.720 --> 00:18:29.160
like, let's stop using yield from and continue


00:18:29.160 --> 00:18:31.100
and all these other things that you do with.


00:18:31.100 --> 00:18:32.980
- I can tell you the entire backstory.


00:18:32.980 --> 00:18:33.820
- Yeah, do tell us.


00:18:33.820 --> 00:18:34.660
- It's relatively short.


00:18:34.660 --> 00:18:37.340
Yeah, yeah, so basically we were trying to figure out


00:18:37.340 --> 00:18:42.340
like the future API for HDB, Python client back then,


00:18:42.340 --> 00:18:44.760
when HDB wasn't even a thing.


00:18:44.760 --> 00:18:47.600
And we knew that we want to support the asyncio


00:18:47.600 --> 00:18:49.940
in our future client.


00:18:49.940 --> 00:18:52.280
But how do you actually have like a migration block?


00:18:52.280 --> 00:18:53.480
Like you would have to say like,


00:18:53.480 --> 00:18:56.240
try finally, accept, rollback, commit.


00:18:56.240 --> 00:18:57.600
It's like a lot of code.


00:18:57.600 --> 00:18:59.360
And we have context managers in Python, right?


00:18:59.360 --> 00:19:01.020
So with the context manager,


00:19:01.020 --> 00:19:02.960
you will just say with transaction


00:19:02.960 --> 00:19:05.720
and just do all this magic behind the scenes.


00:19:05.720 --> 00:19:09.220
but we didn't have an asynchronous version of with.


00:19:09.220 --> 00:19:12.720
We had yield from, but how do you kind of mush together


00:19:12.720 --> 00:19:15.160
yield from and with wasn't clear.


00:19:15.160 --> 00:19:18.520
So I thought, hey, if we have like async keyword,


00:19:18.520 --> 00:19:20.240
we could have async with.


00:19:20.240 --> 00:19:21.680
And then it was natural case,


00:19:21.680 --> 00:19:25.880
we just should replace yield from with await,


00:19:25.880 --> 00:19:27.640
because I was also familiar with C#,


00:19:27.640 --> 00:19:32.640
and I also liked the short and neat syntax of async await.


00:19:32.640 --> 00:19:35.240
And then the next thought was that,


00:19:35.240 --> 00:19:38.040
"Hey, what if you have a cursor to the database


00:19:38.040 --> 00:19:39.440
and just want to iterate over the rows


00:19:39.440 --> 00:19:41.400
and make it like prefetch those rows?"


00:19:41.400 --> 00:19:43.540
And this is how Async 4 was born.


00:19:43.540 --> 00:19:45.580
And then in about a couple of weeks,


00:19:45.580 --> 00:19:47.180
Language Summit happened.


00:19:47.180 --> 00:19:48.920
I think it was in Montreal.


00:19:48.920 --> 00:19:52.540
That was PyCon US in Montreal.


00:19:52.540 --> 00:19:53.620
And I met with Guido.


00:19:53.620 --> 00:19:56.060
I showed him like rough sketch and he said,


00:19:56.060 --> 00:19:58.360
"Yeah, let's do it."


00:19:58.360 --> 00:20:02.840
I think I implemented the first prototype of this thing


00:20:02.840 --> 00:20:05.060
in the interpreter over a couple of nights,


00:20:05.060 --> 00:20:08.020
I just coded straight for 48 hours.


00:20:08.020 --> 00:20:10.020
I wanted to impress Guido.


00:20:10.020 --> 00:20:12.420
[LAUGHS]


00:20:12.420 --> 00:20:15.580
And yeah, I just had this rough implementation.


00:20:15.580 --> 00:20:18.340
And then just over the course of months and a half,


00:20:18.340 --> 00:20:24.460
I was refining it and writing this PEP.


00:20:24.460 --> 00:20:25.580
And this is how it happened.


00:20:25.580 --> 00:20:28.160
I think it all happened because of Guido, because first of all,


00:20:28.160 --> 00:20:31.260
he saw clearly this is an improvement to Yieldthrone,


00:20:31.260 --> 00:20:33.460
like a big improvement.


00:20:33.460 --> 00:20:34.740
- It's a huge improvement.


00:20:34.740 --> 00:20:36.900
It makes it incredibly approachable.


00:20:36.900 --> 00:20:38.220
It's like you do what you normally do,


00:20:38.220 --> 00:20:40.460
but sometimes you might have to put the word await there.


00:20:40.460 --> 00:20:41.420
- Exactly.


00:20:41.420 --> 00:20:45.020
- But your mental model isn't about callbacks


00:20:45.020 --> 00:20:46.420
and weird stuff like that.


00:20:46.420 --> 00:20:48.540
It's just like you write the regular code,


00:20:48.540 --> 00:20:50.120
but you sometimes need to await a thing.


00:20:50.120 --> 00:20:51.660
And it's beautiful.


00:20:51.660 --> 00:20:52.740
- Yeah, exactly, exactly.


00:20:52.740 --> 00:20:54.060
And yeah, I'm grateful to Guido


00:20:54.060 --> 00:20:56.920
because first of all, he recognized this thing


00:20:56.920 --> 00:20:57.820
and encouraged me.


00:20:57.820 --> 00:21:00.500
And second of all, he actually like inspired


00:21:00.500 --> 00:21:03.260
lots and lots of refinements in this proposal.


00:21:03.260 --> 00:21:06.400
And I was like working with him essentially all this time,


00:21:06.400 --> 00:21:09.680
like a discussion happened in Python dev,


00:21:09.680 --> 00:21:11.680
and sometimes he and I exchanged emails


00:21:11.680 --> 00:21:14.620
and he proposed some ideas and I would just tweak the path.


00:21:14.620 --> 00:21:17.080
So yeah, Guido was actually also behind this proposal


00:21:17.080 --> 00:21:18.280
to a big extent.


00:21:18.280 --> 00:21:21.280
- Yeah, there's some mind blowing stuff here,


00:21:21.280 --> 00:21:26.040
like the async with, for example, as you point out, right?


00:21:26.040 --> 00:21:29.720
These are wild ideas, right?


00:21:29.720 --> 00:21:31.000
Instead of just calling, just saying,


00:21:31.000 --> 00:21:34.060
There can be a function you have async for, async with,


00:21:34.060 --> 00:21:35.760
there's really neat things in here.


00:21:35.760 --> 00:21:38.260
- Actually, yeah.


00:21:38.260 --> 00:21:41.660
I think that still async with is pretty unique.


00:21:41.660 --> 00:21:43.800
Like JavaScript, for example, is lucky


00:21:43.800 --> 00:21:46.400
because they have this nice syntax


00:21:46.400 --> 00:21:48.600
for declaring anonymous functions, right?


00:21:48.600 --> 00:21:50.680
And so you can just say,


00:21:50.680 --> 00:21:53.400
await transaction and pass a function.


00:21:53.400 --> 00:21:55.000
And it's like a multi-line function


00:21:55.000 --> 00:21:56.000
and you can do whatever you need.


00:21:56.000 --> 00:21:59.000
You don't actually have to have something like async with


00:21:59.000 --> 00:22:00.880
in TypeScript.


00:22:00.880 --> 00:22:04.440
JavaScript, but in many other languages,


00:22:04.440 --> 00:22:06.040
you would need something like this.


00:22:06.040 --> 00:22:11.040
And pretty much, I think we pioneered this idea in Python.


00:22:11.040 --> 00:22:16.560
I think I saw a proposal to make using async in C#,


00:22:16.560 --> 00:22:18.600
but I'm not actually engaged with C# community,


00:22:18.600 --> 00:22:21.080
so I'm not, maybe it was implemented, maybe not.


00:22:21.080 --> 00:22:25.000
- That would be the parallel, but I've also not tracking it.


00:22:25.000 --> 00:22:26.720
Okay, this is really cool.


00:22:26.720 --> 00:22:29.360
So awesome, awesome work on this, Pep,


00:22:29.360 --> 00:22:31.280
when getting this in live.


00:22:31.280 --> 00:22:33.960
Yeah, so let's talk two more AsyncIO things real quick


00:22:33.960 --> 00:22:35.360
here before we get to Edge TV.


00:22:35.360 --> 00:22:37.480
Or actually, three.


00:22:37.480 --> 00:22:40.760
One jumped the list just yesterday.


00:22:40.760 --> 00:22:44.100
Okay, so when you're doing AsyncIO,


00:22:44.100 --> 00:22:46.080
there's this background event loop


00:22:46.080 --> 00:22:48.640
that looks at all the things that could be done


00:22:48.640 --> 00:22:50.840
and says, are any of them waiting?


00:22:50.840 --> 00:22:52.920
Can we take that while it's waiting


00:22:52.920 --> 00:22:54.760
and put it aside and go do something else, right?


00:22:54.760 --> 00:22:57.120
That way I scale the waiting story.


00:22:57.120 --> 00:22:59.960
And there's an implementation for that in CPython,


00:22:59.960 --> 00:23:04.280
but you all decided, you and Elvis, your co-founder,


00:23:04.280 --> 00:23:07.520
decided it would be nice if there was a faster,


00:23:07.520 --> 00:23:09.720
more optimized version of that part


00:23:09.720 --> 00:23:12.040
that does the checking and execution.


00:23:12.040 --> 00:23:13.640
So you created this thing called UVloop,


00:23:13.640 --> 00:23:15.800
an ultra-fast async I/O event loop.


00:23:15.800 --> 00:23:17.280
It's incredibly easy to use, right?


00:23:17.280 --> 00:23:19.720
Like to install it is-- - Two lines.


00:23:19.720 --> 00:23:20.880
- It's two lines, right?


00:23:20.880 --> 00:23:22.640
You import and then you run install


00:23:22.640 --> 00:23:26.320
and you're good to go, which is fantastic.


00:23:26.320 --> 00:23:31.600
tell people about uv loop and how broadly should this just be standard stuff we do in


00:23:31.600 --> 00:23:35.480
all of our code that uses async and await?


00:23:35.480 --> 00:23:37.600
>> That's an interesting question.


00:23:37.600 --> 00:23:38.600
Let's jump in.


00:23:38.600 --> 00:23:41.200
So uv loop wasn't the first thing that I created.


00:23:41.200 --> 00:23:43.620
The first thing was actually HTTP tools.


00:23:43.620 --> 00:23:46.640
Someone asked you about that a few minutes ago.


00:23:46.640 --> 00:23:49.440
So I just wanted to experiment with Cython.


00:23:49.440 --> 00:23:50.680
I discovered Cython.


00:23:50.680 --> 00:23:54.080
I thought, hey, this might actually be a useful tool


00:23:54.080 --> 00:23:58.920
and allow us to speed up Python a lot for some things


00:23:58.920 --> 00:24:00.320
like parsing HTTP, for example.


00:24:00.320 --> 00:24:00.820
>> Right.


00:24:00.820 --> 00:24:02.280
The type of-- yeah.


00:24:02.280 --> 00:24:03.160
>> Exactly, exactly.


00:24:03.160 --> 00:24:07.960
So I look at Node.js, and they used a C HTTP parser.


00:24:07.960 --> 00:24:12.680
I think that parser was actually extracted from Nginx.


00:24:12.680 --> 00:24:15.640
And yeah, I just dropped it in HTTP tools.


00:24:15.640 --> 00:24:18.280
It's literally 100 lines of code, maybe even less,


00:24:18.280 --> 00:24:19.880
maybe 50.


00:24:19.880 --> 00:24:23.080
just like a small dropper over the C library.


00:24:23.080 --> 00:24:25.480
It worked and it worked great.


00:24:25.480 --> 00:24:27.880
Then I thought, "Oh my God,


00:24:27.880 --> 00:24:29.600
I now have this superpower."


00:24:29.600 --> 00:24:32.000
>> What other things can I grab and wrap?


00:24:32.000 --> 00:24:35.400
>> Exactly. Because you could do the same,


00:24:35.400 --> 00:24:37.400
but just like using Python C API,


00:24:37.400 --> 00:24:39.180
but you will end up writing like 3x,


00:24:39.180 --> 00:24:41.240
maybe 5x amount of code.


00:24:41.240 --> 00:24:43.840
Using Cython just feels like magic.


00:24:43.840 --> 00:24:48.120
Yeah, it worked. Then I was like, "Interesting."


00:24:48.120 --> 00:24:56.460
So there is this libuv library that actually powers Node.js and it's cross-platform and it's super fast and Node.js is fast.


00:24:56.460 --> 00:25:03.540
Maybe, just maybe, I can do the same. I can just wrap it into Python and make a drop-in replacement for EventLoop.


00:25:03.540 --> 00:25:12.540
So I prototyped something relatively quickly, maybe in a few days, basically, I just implemented a loop object and call soon.


00:25:12.540 --> 00:25:17.240
Like, basically, the staple of anything. The most basic thing.


00:25:17.240 --> 00:25:22.360
And it worked. It worked just fine. I was able to implement call later and then I was able to run a coroutine like


00:25:22.360 --> 00:25:30.120
await sleep one print hello world and it worked and then I just over the course of next


00:25:30.120 --> 00:25:35.240
several months, I think three, maybe four, maybe five months, I was just gradually implementing


00:25:35.240 --> 00:25:40.440
async-io-api, swearing a lot because I discovered that this API surface is just huge.


00:25:40.440 --> 00:25:44.360
It's an enormous API actually.


00:25:45.000 --> 00:25:49.160
And yeah, then we posted benchmarks.


00:25:49.160 --> 00:25:54.800
And I think it went somewhat viral.


00:25:54.800 --> 00:25:59.000
It was on HN. I think it was like post number one.


00:25:59.000 --> 00:26:03.200
Yeah, I think Brian and I covered it over on the Python Bytes podcast when it came out.


00:26:03.200 --> 00:26:05.040
Because it was big news. Yeah.


00:26:05.040 --> 00:26:09.200
Yeah, people are excited. Specifically, because basically,


00:26:09.200 --> 00:26:14.880
we showed that you can write some Python code like a simple protocol parser


00:26:14.880 --> 00:26:16.880
and it will be almost as fast as Go.


00:26:16.880 --> 00:26:21.320
And sometimes it's faster than Node.js, which was surprising.


00:26:21.320 --> 00:26:25.160
So, yeah, I think a lot of people are excited about it.


00:26:25.160 --> 00:26:28.280
Yeah, that's fantastic. So the quick takeaway here is


00:26:28.280 --> 00:26:31.800
UVLoop makes async.io two to four times faster.


00:26:31.800 --> 00:26:34.080
You've got some benchmarks for different situations


00:26:34.080 --> 00:26:37.080
and amount of data and so on, at least with regard to sockets.


00:26:37.080 --> 00:26:40.560
So let's wrap this one up with...


00:26:40.560 --> 00:26:43.960
Is that a universal statement that you would recommend there?


00:26:44.320 --> 00:26:46.320
Yeah, uvloop.install?


00:26:46.320 --> 00:26:50.520
It depends. I think for production it makes a lot of sense to use uvloop.


00:26:50.520 --> 00:26:55.020
You should try it because I mean there are still some minor incompatibilities in uvloop


00:26:55.020 --> 00:26:57.280
that are really hard to track.


00:26:57.280 --> 00:27:00.720
Maybe there is some behavior difference or maybe there is a bug simply.


00:27:00.720 --> 00:27:04.320
You're using something that a lot of people are not using with uvloop.


00:27:04.320 --> 00:27:07.520
And it's still a possibility.


00:27:07.520 --> 00:27:11.420
So yeah, use it. Use it with care in production.


00:27:11.420 --> 00:27:13.420
In local development, I don't think you need it.


00:27:13.420 --> 00:27:16.260
Like vanilla async.io should be plenty.


00:27:16.260 --> 00:27:19.500
There is one more interesting thing about UVLoop.


00:27:19.500 --> 00:27:21.100
It's a package.


00:27:21.100 --> 00:27:22.540
It's a package on PyPI.


00:27:22.540 --> 00:27:26.620
So if we find the bug, we fix it and we publish a package.


00:27:26.620 --> 00:27:32.140
You don't have to wait until Python 3.11.7 to get your bugs


00:27:32.140 --> 00:27:33.020
fixed.


00:27:33.020 --> 00:27:33.980
So in a way--


00:27:33.980 --> 00:27:35.580
Or improvements made, yeah.


00:27:35.580 --> 00:27:37.180
Or improvements made, exactly.


00:27:37.180 --> 00:27:43.480
So this kind of suggests that it's a great idea to use Evoloop.


00:27:43.480 --> 00:27:48.220
But on the other hand, we really haven't had any emergency releases or anything in a long time.


00:27:48.220 --> 00:27:53.160
We basically release almost every year just to catch up with the latest Python version.


00:27:53.160 --> 00:27:57.060
I would say that Evoloop is pretty stable at this point.


00:27:57.060 --> 00:27:58.960
Yeah, very cool.


00:27:58.960 --> 00:27:59.960
Yeah, it definitely seems neat.


00:27:59.960 --> 00:28:05.100
I think also it's probably a context of when does it make sense, right?


00:28:05.100 --> 00:28:09.100
if you're running three tasks and that's your whole program,


00:28:09.100 --> 00:28:10.640
who cares how fast Event Loop is?


00:28:10.640 --> 00:28:11.840
All right, it's three tasks.


00:28:11.840 --> 00:28:13.840
But if you have many, many fine-grained,


00:28:13.840 --> 00:28:15.980
tons of little tasks and there's lots of core,


00:28:15.980 --> 00:28:18.540
like how complex and how many tasks,


00:28:18.540 --> 00:28:20.960
like basically how complex is the task coordination job


00:28:20.960 --> 00:28:22.620
of asyncio, right?


00:28:22.620 --> 00:28:23.860
The more complicated it is,


00:28:23.860 --> 00:28:26.240
probably the better benefit you'll get from uv loop.


00:28:26.240 --> 00:28:27.140
What do you think?


00:28:27.140 --> 00:28:32.440
- I think, I mean, if we go deep in the details,


00:28:32.440 --> 00:28:36.220
I would say it's not so much about juggling tasks around.


00:28:36.220 --> 00:28:39.780
It is more about performing I/O in the most optimal way.


00:28:39.780 --> 00:28:40.600
>> Okay.


00:28:40.600 --> 00:28:43.360
>> Libv is just because it's so low level.


00:28:43.360 --> 00:28:49.320
It just uses lots and lots of tricks under the hood to just do I/O faster.


00:28:49.320 --> 00:28:52.680
The entire loop of calling callbacks in the loop,


00:28:52.680 --> 00:28:55.820
it's a tight loop in C essentially.


00:28:55.820 --> 00:28:56.200
>> Right.


00:28:56.200 --> 00:28:59.660
>> It's much faster than a loop in Python.


00:28:59.660 --> 00:29:02.200
That actually, yeah, those two points.


00:29:02.200 --> 00:29:07.960
But yeah, the performance improvement is noticeable usually, very noticeable.


00:29:07.960 --> 00:29:08.960
Cool.


00:29:08.960 --> 00:29:15.880
Well, the benefit is if it's literally import uv loop, uv loop.install, run your benchmarks,


00:29:15.880 --> 00:29:17.880
comment that line out, run your benchmarks again.


00:29:17.880 --> 00:29:18.880
Exactly.


00:29:18.880 --> 00:29:19.880
It's so easy.


00:29:19.880 --> 00:29:21.080
You don't have to commit to it.


00:29:21.080 --> 00:29:23.680
It's not like, oh, we're going to swap ORMs and try it again.


00:29:23.680 --> 00:29:24.680
Exactly.


00:29:24.680 --> 00:29:25.680
Yeah.


00:29:25.680 --> 00:29:28.160
But I just love packages in Python that do this magic.


00:29:28.160 --> 00:29:31.660
I think if you remember, there was this package called Psyco


00:29:31.660 --> 00:29:35.120
created by Armin Rigo, creator of PyPy.


00:29:35.120 --> 00:29:38.460
You just import Psyco, Psyco install, or something like that.


00:29:38.460 --> 00:29:42.380
And boom, you have like an alternative CPython eval loop.


00:29:42.380 --> 00:29:46.300
Your program just magically becomes five, 10 times faster.


00:29:46.300 --> 00:29:47.220
It's just magic.


00:29:47.220 --> 00:29:50.520
So yeah, it's great when we can do something like this.


00:29:50.520 --> 00:29:52.060
- Yeah, that's fantastic.


00:29:52.060 --> 00:29:54.300
Adrian has an interesting question.


00:29:54.300 --> 00:29:58.020
I know this came up around requests a couple of years ago.


00:29:58.020 --> 00:30:01.580
could you give your thoughts on having things as part of the standard library,


00:30:01.580 --> 00:30:08.740
basically having uvloop in this case be the replacement for async ioloop


00:30:08.740 --> 00:30:11.460
rather than having an external package updated independently?


00:30:11.460 --> 00:30:17.700
Yeah, it's an interesting question and I'm not super involved in conversations like this.


00:30:17.700 --> 00:30:21.380
I know that Python core developers consider it actually separating some standard library


00:30:21.380 --> 00:30:25.620
and shipping of them aside so that it can have like its own release schedule.


00:30:25.620 --> 00:30:31.780
I think it's sort of mitigated with Lukasz Langa actually speeding up the release cycle for PyPI now.


00:30:31.780 --> 00:30:34.820
It's being released like every year, which is amazing.


00:30:34.820 --> 00:30:38.900
And I think the pressure is lower now to separate the standard library.


00:30:38.900 --> 00:30:44.340
As far as including uv loop as part of standard library, I'm not sure it's a good idea.


00:30:44.340 --> 00:30:47.940
First of all, it's entirely in Cython.


00:30:47.940 --> 00:30:50.580
It's like 50,000 lines of Cython or something like that.


00:30:50.580 --> 00:30:56.580
We will have to either adopt Cython as like an official standard library tool,


00:30:56.580 --> 00:30:58.580
or rewrite it in C.


00:30:58.580 --> 00:31:01.580
And if you rewrite it in C, it's going to be 100,000 lines in C.


00:31:01.580 --> 00:31:03.580
It will be huge.


00:31:03.580 --> 00:31:07.580
So probably not going to happen anytime soon.


00:31:07.580 --> 00:31:13.580
Maybe with things like mypyC, we can make it happen eventually.


00:31:13.580 --> 00:31:15.580
- That's interesting. - But mypyC is still pretty early.


00:31:15.580 --> 00:31:17.580
Right. Okay.


00:31:17.580 --> 00:31:22.580
Yeah, the conversation was had around that with regard to requests as well.


00:31:22.580 --> 00:31:25.580
Maybe you're even part of it since you're a core developer.


00:31:25.580 --> 00:31:32.580
But they decided not to make requests the new HTTP library of CPython


00:31:32.580 --> 00:31:35.580
because it would hobble requests.


00:31:35.580 --> 00:31:38.580
Like, it would mean requests could only be changed,


00:31:38.580 --> 00:31:41.580
you know, once every 12 months or something like that, right?


00:31:41.580 --> 00:31:44.580
Yeah, I think one of the concerns with requests specifically,


00:31:44.580 --> 00:31:49.580
and I wasn't actively involved in those conversations at all,


00:31:49.580 --> 00:31:54.580
but I think the concern that I heard was that HTTP is pretty wild


00:31:54.580 --> 00:31:59.580
and you often need to fix some security issues and bugs


00:31:59.580 --> 00:32:01.580
and you need to act quickly.


00:32:01.580 --> 00:32:05.580
And if something as huge as requests and so fundamental as requests


00:32:05.580 --> 00:32:11.580
was part of standard library, we would just have to be way more flexible


00:32:11.580 --> 00:32:14.780
about making bug releases for CPython.


00:32:14.780 --> 00:32:19.380
And Python is just, it's such a huge thing, right?


00:32:19.380 --> 00:32:22.380
Like operating systems bundle with like multiple different


00:32:22.380 --> 00:32:25.980
workflows are centered around it.


00:32:25.980 --> 00:32:28.580
- It runs on helicopters in Mars.


00:32:28.580 --> 00:32:31.280
I mean, come on, there's a lot of edge cases.


00:32:31.280 --> 00:32:32.580
People are not picking it out of here, right?


00:32:32.580 --> 00:32:33.420
- Exactly.


00:32:33.420 --> 00:32:36.080
It's just upgrading a separate library is so much easier


00:32:36.080 --> 00:32:38.480
than upgrading the entire Python thing.


00:32:38.480 --> 00:32:44.000
So yeah, I think this is why packages like requests for sure will stay out of standard library.


00:32:44.000 --> 00:32:45.000
Yeah.


00:32:45.000 --> 00:32:48.600
All right, final question before we move on from uv loop,


00:32:48.600 --> 00:32:51.100
because it's not even our main topic, but it is very interesting.


00:32:51.100 --> 00:32:55.900
Teddy asks, "Are there any trade-offs of using uv loop


00:32:55.900 --> 00:32:59.100
as opposed to the native built-in one?"


00:32:59.100 --> 00:33:03.440
I think this is time for me to make a shout out


00:33:03.440 --> 00:33:09.760
because we still haven't implemented a couple of APIs that are in AsyncIO,


00:33:09.760 --> 00:33:14.640
like API balls protocol, maybe there is something else.


00:33:14.640 --> 00:33:18.800
I just haven't got time to do it myself and we are busy with


00:33:18.800 --> 00:33:24.480
with SGB, so if anyone wants to join the project and help, that would


00:33:24.480 --> 00:33:27.120
be great. And that basically answers the question.


00:33:27.120 --> 00:33:30.320
The fundamental APIs are already all there.


00:33:30.320 --> 00:33:33.320
It's almost 100% compatible with uv loop,


00:33:33.320 --> 00:33:35.960
with vanilla async I/O.


00:33:35.960 --> 00:33:40.720
No trade-offs, except there are a couple of relatively new APIs,


00:33:40.720 --> 00:33:43.220
I think, path 3.9 and path 3.10,


00:33:43.220 --> 00:33:45.120
that are still missing from uv loop,


00:33:45.120 --> 00:33:47.120
and we still should implement them.


00:33:47.120 --> 00:33:49.360
Yeah, to be a true replacement, right?


00:33:49.360 --> 00:33:53.760
Yeah, I think it's sent file and API goals and maybe something else.


00:33:53.760 --> 00:33:57.720
Okay, uv loop is running inside EdgeDB?


00:33:58.860 --> 00:34:03.200
Yeah, it powers the I/O server.


00:34:03.200 --> 00:34:08.440
Basically, we use multi-processing architecture in HTTP.


00:34:08.440 --> 00:34:11.580
We have a pool of compiler processes


00:34:11.580 --> 00:34:16.520
because this is like computation CPU heavy thing to compile a query.


00:34:16.520 --> 00:34:19.980
And then there is a core I/O process that just runs uv loop


00:34:19.980 --> 00:34:23.320
and quickly, quickly, quickly goes through your connections


00:34:23.320 --> 00:34:26.420
and pushing the data between clients, etc.


00:34:26.420 --> 00:34:27.920
All right.


00:34:28.600 --> 00:34:31.400
Another thing that came out just today, I know this is...


00:34:31.400 --> 00:34:35.140
I don't want to spend too much time on it, but there's a big


00:34:35.140 --> 00:34:43.480
new feature for tasks and AsyncIO in Python 3.11 coming very soon.


00:34:43.480 --> 00:34:47.980
And you just gave a shout out on Twitter yesterday


00:34:47.980 --> 00:34:52.480
saying that Task Groups is coming to AsyncIO.


00:34:52.480 --> 00:34:55.480
This is a way, because right now if you start two tasks,


00:34:55.480 --> 00:34:57.780
there's no way to say, "Well, if this one fails,


00:34:57.780 --> 00:35:00.360
Don't even bother running that one. They're fully independent.


00:35:00.360 --> 00:35:04.520
This is a way to create a dependency and control them as a set.


00:35:04.520 --> 00:35:06.520
Tell us real quick about this.


00:35:06.520 --> 00:35:09.760
Yeah, we have an API for spawning tasks concurrently.


00:35:09.760 --> 00:35:16.160
It's called async_air_gatherer, but it's just a suboptimal API in many ways.


00:35:16.160 --> 00:35:20.480
And this API is way superior.


00:35:20.480 --> 00:35:27.480
We have to credit Nathaniel J. Smith for his work on Trio and Trio Nursery specifically.


00:35:27.480 --> 00:35:30.380
And Trio is--


00:35:30.380 --> 00:35:33.020
I mean, we can run an entirely different podcast episode


00:35:33.020 --> 00:35:33.660
just about Trio.


00:35:33.660 --> 00:35:34.660
>>Luis: I actually had nothing on.


00:35:34.660 --> 00:35:37.420
Yeah, we talked about Trio on the show quite a while ago


00:35:37.420 --> 00:35:38.820
when it was fairly new.


00:35:38.820 --> 00:35:40.120
>>Kostya: It's an amazing thing.


00:35:40.120 --> 00:35:42.720
And there are lots and lots of great ideas in Trio.


00:35:42.720 --> 00:35:45.620
One of them is having this thing.


00:35:45.620 --> 00:35:47.780
It's called Nursery in Trio.


00:35:47.780 --> 00:35:50.620
And the Async and the Task Groups,


00:35:50.620 --> 00:35:52.300
Async and Task Groups, essentially,


00:35:52.300 --> 00:35:54.660
they just replicate this nursery idea.


00:35:54.660 --> 00:35:57.180
they ported from Trio to AsyncIO.


00:35:57.180 --> 00:36:01.540
Like the bigger points about how this API works


00:36:01.540 --> 00:36:02.980
are all similar to Trio.


00:36:02.980 --> 00:36:06.500
There are some details about how cancellation works, et cetera.


00:36:06.500 --> 00:36:10.700
But most people probably won't really care about that one.


00:36:10.700 --> 00:36:12.340
Yeah, OK, very cool.


00:36:12.340 --> 00:36:16.620
It's great to see more innovation happening in AsyncIO.


00:36:16.620 --> 00:36:18.820
Yeah, but task groups--


00:36:18.820 --> 00:36:22.220
I'll just talk for a couple more minutes about task groups.


00:36:22.220 --> 00:36:24.920
So task groups was a long requested thing.


00:36:24.920 --> 00:36:28.200
A lot of people wanted task groups in Async.io.


00:36:28.200 --> 00:36:30.280
And I was DMed like,


00:36:30.280 --> 00:36:33.200
sometimes I was DMed like on a daily basis entirely.


00:36:33.200 --> 00:36:34.380
We promised us task groups.


00:36:34.380 --> 00:36:36.240
When can we have our task groups?


00:36:36.240 --> 00:36:40.000
So the big like elephant in the room with task groups


00:36:40.000 --> 00:36:41.960
is how do we handle exceptions?


00:36:41.960 --> 00:36:44.280
Because multiple things can fail at the same time.


00:36:44.280 --> 00:36:45.720
And they essentially will propagate


00:36:45.720 --> 00:36:47.680
out of this Async with task group.


00:36:47.680 --> 00:36:52.080
- You'll end up with a hierarchical tree


00:36:52.080 --> 00:36:54.280
of exceptions representing the state of failure,


00:36:54.280 --> 00:36:57.800
which is not how we typically think of exceptions.


00:36:57.800 --> 00:36:58.920
- Exactly, exactly.


00:36:58.920 --> 00:37:00.160
And we just had to figure it out.


00:37:00.160 --> 00:37:02.120
And we had to figure it out in the core,


00:37:02.120 --> 00:37:03.880
because if it was just some, I don't know,


00:37:03.880 --> 00:37:06.800
some exception class defined in async.io,


00:37:06.800 --> 00:37:07.720
then what would happen


00:37:07.720 --> 00:37:09.920
when your async.io program crashed, right?


00:37:09.920 --> 00:37:12.920
You wouldn't have like a correct traceback


00:37:12.920 --> 00:37:13.760
in your terminal.


00:37:13.760 --> 00:37:15.880
You wouldn't be able to understand what actually happened.


00:37:15.880 --> 00:37:18.560
So we had to integrate this into tracebacks,


00:37:18.560 --> 00:37:20.120
into like a debug.


00:37:20.120 --> 00:37:25.260
We needed to make sure that it's like a standard thing that tools like Sentry, for example,


00:37:25.260 --> 00:37:30.040
can take advantage of it and provide you like great visibility into what happens in your


00:37:30.040 --> 00:37:31.040
IcQ application.


00:37:31.040 --> 00:37:33.680
So we had to work in this exception group thing.


00:37:33.680 --> 00:37:44.360
And there is this amazing new core developer, Yurit Katryl, and she spearheaded this effort


00:37:44.360 --> 00:37:52.880
of just implementing this and drafting a proposal and just doing it to completion, essentially.


00:37:52.880 --> 00:37:56.860
And it's because of her work, actually, task groups are finally a thing.


00:37:56.860 --> 00:38:01.400
Because task groups themselves, it's like 100 lines of code with comments.


00:38:01.400 --> 00:38:03.160
There is not much to them.


00:38:03.160 --> 00:38:06.040
The huge thing is getting exception groups in.


00:38:06.040 --> 00:38:11.320
And I believe Python is the first language that has this feature, like, right in the


00:38:11.320 --> 00:38:15.160
its syntax, right, and its runtime model.


00:38:15.160 --> 00:38:18.480
And this is also huge because I actually believe


00:38:18.480 --> 00:38:21.180
that Python now can be like one of the best languages


00:38:21.180 --> 00:38:22.780
to do concurrent programming in.


00:38:22.780 --> 00:38:27.040
And I don't know, maybe when we have JIT


00:38:27.040 --> 00:38:30.120
or something like that, it might actually match


00:38:30.120 --> 00:38:31.800
goal in performance some way.


00:38:31.800 --> 00:38:33.200
Would be ideal thing.


00:38:33.200 --> 00:38:34.880
- So while I'm looking at this syntax here,


00:38:34.880 --> 00:38:38.000
which I'll try to quickly, simply communicate


00:38:38.000 --> 00:38:39.720
to people listening on audio,


00:38:39.720 --> 00:38:41.560
It's an async with block.


00:38:41.560 --> 00:38:44.960
So what you do is you say async with asyncio dot task group


00:38:44.960 --> 00:38:46.100
and you create this task group


00:38:46.100 --> 00:38:49.680
and then you can create tasks within there


00:38:49.680 --> 00:38:51.600
that are all grouped together.


00:38:51.600 --> 00:38:55.040
And then you also can do things like a wait stuff


00:38:55.040 --> 00:38:57.320
while you're in there.


00:38:57.320 --> 00:38:58.840
It looks to me like one of the things


00:38:58.840 --> 00:39:02.800
that often I don't see possible in Python's async.


00:39:02.800 --> 00:39:07.080
Previously, it's the ability to just fire off a task


00:39:07.080 --> 00:39:10.660
and have it sort of just run in the background


00:39:10.660 --> 00:39:12.160
to completion, right?


00:39:12.160 --> 00:39:15.940
So you don't have to do like async or like run all


00:39:15.940 --> 00:39:19.220
or gather or any of those types of things.


00:39:19.220 --> 00:39:21.940
Basically the with block,


00:39:21.940 --> 00:39:24.660
we won't exit the with block until all the tasks are finished


00:39:24.660 --> 00:39:27.580
or till it fails, one of those two, right?


00:39:27.580 --> 00:39:29.940
That's a cool feature of it alone to just kind of say,


00:39:29.940 --> 00:39:33.060
like, I don't need to kind of store up all the tasks


00:39:33.060 --> 00:39:34.880
and then make sure I'm waiting on them forever.


00:39:34.880 --> 00:39:35.860
Like I can just kick them off


00:39:35.860 --> 00:39:38.520
and then if they happen to start in this place,


00:39:38.520 --> 00:39:41.320
then they're going to finish when this with block finishes.


00:39:41.320 --> 00:39:43.620
I'm even more excited about this than I was before.


00:39:43.620 --> 00:39:44.460
- Right, right, right.


00:39:44.460 --> 00:39:48.100
It's a nice API to compose things in AsyncIO.


00:39:48.100 --> 00:39:48.940
- Yes, exactly.


00:39:48.940 --> 00:39:51.880
- I believe it's one of the bigger deals


00:39:51.880 --> 00:39:55.180
for AsyncIO in the recent years.


00:39:55.180 --> 00:39:57.260
So I'm super excited.


00:39:57.260 --> 00:39:58.900
- 3.11 is out soon.


00:39:58.900 --> 00:40:00.260
Not exactly sure of the release date.


00:40:00.260 --> 00:40:02.020
I know it's in alpha stuff right now.


00:40:02.020 --> 00:40:03.700
So it's getting real near.


00:40:03.700 --> 00:40:06.020
- Yeah, yeah, it should be close.


00:40:06.020 --> 00:40:07.780
- Yeah, for sure, awesome.


00:40:07.780 --> 00:40:11.880
All right, last thing before we get to EdgeDB proper.


00:40:11.880 --> 00:40:16.540
People, I would say that Postgres is the most popular


00:40:16.540 --> 00:40:19.520
database for Python people doing database things,


00:40:19.520 --> 00:40:21.340
possibly with the exception of SQLite,


00:40:21.340 --> 00:40:22.640
but that really accounts for just like,


00:40:22.640 --> 00:40:24.420
oh, I'm doing testing or oh, I use this


00:40:24.420 --> 00:40:28.180
for this incredibly small, but like production level stuff,


00:40:28.180 --> 00:40:29.700
it's gotta be Postgres, right?


00:40:31.580 --> 00:40:33.760
- Yeah, yeah, it's fair to say.


00:40:33.760 --> 00:40:36.680
- Yeah, maybe throw in some MySQL


00:40:36.680 --> 00:40:37.640
and then like a little bit down,


00:40:37.640 --> 00:40:39.040
maybe some MongoDB, something like that.


00:40:39.040 --> 00:40:41.200
But like clearly it seems like Postgres


00:40:41.200 --> 00:40:45.000
has a lot of interest for folks.


00:40:45.000 --> 00:40:48.520
If you wanna talk to it through async and await,


00:40:48.520 --> 00:40:52.360
which is exactly how you wanna scale your database stuff,


00:40:52.360 --> 00:40:55.560
a pretty popular library is this one called async-pg, right?


00:40:55.560 --> 00:40:57.400
- Yep, yep, yep.


00:40:57.400 --> 00:40:59.200
- Yeah, you and Elvis created that, huh?


00:40:59.200 --> 00:41:02.760
Yeah, so yeah, it was an interesting experience basically.


00:41:02.760 --> 00:41:06.480
We knew that EdgeDB will be based on Postgres.


00:41:06.480 --> 00:41:08.400
That was clear day one.


00:41:08.400 --> 00:41:11.440
And we also knew that we have to have like this


00:41:11.440 --> 00:41:15.000
very high performance bridge essentially


00:41:15.000 --> 00:41:17.640
between Python and Postgres.


00:41:17.640 --> 00:41:19.680
And it had to be asynchronous.


00:41:19.680 --> 00:41:23.600
So there was no good asynchronous client


00:41:23.600 --> 00:41:25.760
for Postgres back at the time.


00:41:25.760 --> 00:41:31.020
And we couldn't just use PsykOPG, the most popular Postgres driver,


00:41:31.020 --> 00:41:34.100
because it uses text encoding for data.


00:41:34.100 --> 00:41:38.980
Maybe not anymore, but it used to have text, used to use text encoding.


00:41:38.980 --> 00:41:42.160
And we actually had to use binary for some things.


00:41:42.160 --> 00:41:45.700
So we just knew that, okay, we have to just jump in and explore Postgres protocol.


00:41:45.700 --> 00:41:47.900
And we decided, okay, let's write the driver.


00:41:47.900 --> 00:41:51.660
And yeah, this is how AsyncPG was born.


00:41:51.740 --> 00:41:54.260
I think what makes async/pager different,


00:41:54.260 --> 00:41:57.540
just besides that it implements binary protocol


00:41:57.540 --> 00:42:01.860
and it's asynchronous, it's API,


00:42:01.860 --> 00:42:06.860
because we were not basing it on the common Python DB API.


00:42:06.860 --> 00:42:13.020
We basically designed an API to be as low level as possible,


00:42:13.020 --> 00:42:15.140
as close to PostgreSQL semantics as possible.


00:42:15.140 --> 00:42:17.900
So in DB API, there is this thing called cursor,


00:42:17.900 --> 00:42:20.700
which has nothing to do with the actual database cursor.


00:42:20.700 --> 00:42:23.060
So we didn't want to replicate that.


00:42:23.060 --> 00:42:25.900
So yeah, we just built what we thought


00:42:25.900 --> 00:42:29.500
were proper primitives for working with Postgres


00:42:29.500 --> 00:42:30.660
as efficiently as possible.


00:42:30.660 --> 00:42:35.740
We used binary protocol plus async.io.


00:42:35.740 --> 00:42:38.860
And we, of course, used Cython to speed up


00:42:38.860 --> 00:42:40.220
all the bottlenecks in it.


00:42:40.220 --> 00:42:43.500
It's pretty much entirely in Cython, actually.


00:42:43.500 --> 00:42:47.700
And yeah, the result is just amazing to this day.


00:42:47.700 --> 00:42:51.920
AsyncPG is one of the fastest Postgres clients


00:42:51.920 --> 00:42:53.660
on the planet across all languages.


00:42:53.660 --> 00:42:55.860
- Yeah, that's fascinating.


00:42:55.860 --> 00:42:57.660
You can see that it beats Node.js


00:42:57.660 --> 00:43:00.100
and go pretty handily there.


00:43:00.100 --> 00:43:02.220
- Yeah, we should probably update this chart, actually.


00:43:02.220 --> 00:43:05.260
I'm pretty sure that they updated PGLibrary for Node.js,


00:43:05.260 --> 00:43:06.860
so this is outdated.


00:43:06.860 --> 00:43:09.500
I think it's closer in performance to AsyncPG,


00:43:09.500 --> 00:43:12.940
but I think AsyncPG is still the fastest.


00:43:12.940 --> 00:43:14.380
- Yeah, cool, awesome.


00:43:14.380 --> 00:43:16.380
Well, very nice work there.


00:43:16.380 --> 00:43:19.520
So taking all these together, uv loop,


00:43:19.520 --> 00:43:23.680
async and await in the language, asyncpg,


00:43:23.680 --> 00:43:25.400
all of these are building up your skills


00:43:25.400 --> 00:43:28.120
to sort of almost build a database.


00:43:28.120 --> 00:43:30.520
And so then you went on and actually did build a database,


00:43:30.520 --> 00:43:31.360
right?


00:43:31.360 --> 00:43:32.180
- Yeah, pretty much.


00:43:32.180 --> 00:43:33.480
So we had this framework,


00:43:33.480 --> 00:43:37.400
which was like almost an ORM in Python for many years.


00:43:37.400 --> 00:43:39.880
And we built multiple different production applications


00:43:39.880 --> 00:43:40.720
for that.


00:43:40.720 --> 00:43:44.080
We shipped applications that were deployed to GE, Cisco,


00:43:44.080 --> 00:43:45.360
companies like that.


00:43:45.360 --> 00:43:47.820
And we knew it's something interesting,


00:43:47.820 --> 00:43:51.080
but we also knew that it has to be bigger


00:43:51.080 --> 00:43:54.400
than just a Python form, like it has to be a database.


00:43:54.400 --> 00:43:57.440
And it's a surprisingly long road


00:43:57.440 --> 00:44:02.160
to make something, to go this path essentially,


00:44:02.160 --> 00:44:04.360
because you have to define a query language,


00:44:04.360 --> 00:44:06.840
you have to define type system,


00:44:06.840 --> 00:44:08.400
you have to define standard library,


00:44:08.400 --> 00:44:10.360
you have to define protocols, how it works,


00:44:10.360 --> 00:44:11.560
how migrations work,


00:44:11.560 --> 00:44:14.160
all the different syntaxes for schema modeling.


00:44:14.160 --> 00:44:16.000
It's a huge thing.


00:44:16.000 --> 00:44:19.560
And yeah, with like all the right primitives


00:44:19.560 --> 00:44:22.760
in Python itself, we knew that we can start


00:44:22.760 --> 00:44:24.880
like morphing our code base


00:44:24.880 --> 00:44:27.760
into like this separate service essentially.


00:44:27.760 --> 00:44:32.760
And that was the necessary and required ground work


00:44:32.760 --> 00:44:34.520
to make it to be happen.


00:44:34.520 --> 00:44:37.520
Without it, we would probably not succeed.


00:44:37.520 --> 00:44:38.840
- Cool.


00:44:38.840 --> 00:44:40.860
So EdgeDB really written in Python?


00:44:40.860 --> 00:44:43.880
- It is, most of it.


00:44:43.880 --> 00:44:51.560
Yeah, mostly. The entire like IO service server is essentially a Cython thing.


00:44:51.560 --> 00:44:56.520
So it's in C and this is why if you look at benchmarks of HDB,


00:44:56.520 --> 00:44:59.720
it's actually pretty close to Postgres, to vanilla Postgres.


00:44:59.720 --> 00:45:02.840
Like the overhead of HDB is super low.


00:45:02.840 --> 00:45:10.280
And that is only possible because of Cython and like all low-level tips and tricks


00:45:10.280 --> 00:45:15.960
that we learned when we were working on uv loop and async pg so we really optimized it a lot


00:45:15.960 --> 00:45:21.640
the compiler part the thing that actually takes an hql query and compiles it to sql


00:45:21.640 --> 00:45:28.680
that thing is pure python and it runs in a separate process but we do some also tricks to make it fast


00:45:28.680 --> 00:45:34.360
like we cache things aggressively i mean in most applications you don't have thousands of queries


00:45:34.360 --> 00:45:37.200
you only have like 10, 50, 100.


00:45:37.200 --> 00:45:39.500
So they get cached pretty quickly,


00:45:39.500 --> 00:45:42.400
and then you don't even run Python anymore.


00:45:42.400 --> 00:45:45.760
>> You don't need to incredibly optimize


00:45:45.760 --> 00:45:49.140
the understanding of the query because like you said,


00:45:49.140 --> 00:45:53.740
it's not ad hoc stuff happening that happens at scale.


00:45:53.740 --> 00:45:55.920
>> Exactly. I mean,


00:45:55.920 --> 00:46:01.080
it's great when your compiler is exceptionally fast.


00:46:01.080 --> 00:46:06.280
But for database, and especially if it's smart around extracting constants,


00:46:06.280 --> 00:46:09.820
let's say you send select one, and then your next query is select two,


00:46:09.820 --> 00:46:12.320
essentially it's the same query, it's absolutely the same query,


00:46:12.320 --> 00:46:13.360
just different constants.


00:46:13.360 --> 00:46:15.920
So if you extract it and you cache the compiled query


00:46:15.920 --> 00:46:19.200
as if this wasn't a constant, but an argument to the query,


00:46:19.200 --> 00:46:22.560
then yeah, you don't need to compile it for the second time.


00:46:22.560 --> 00:46:23.560
So yeah.


00:46:23.560 --> 00:46:26.560
And I don't know Postgres super, super well,


00:46:26.560 --> 00:46:28.060
but I know some databases,


00:46:28.060 --> 00:46:32.500
they at their level, when they see a query,


00:46:32.500 --> 00:46:35.900
they're like, oh, I've seen this query before, they can cache the query plan


00:46:35.900 --> 00:46:39.740
and those types of... so that's like another level of performance and speed up.


00:46:39.740 --> 00:46:45.300
Yeah, we do that as well.


00:46:45.300 --> 00:46:51.140
I mean, we did it even in asyncPg, for example, asyncPg automatically prepares statements for you


00:46:51.140 --> 00:46:55.020
to enjoy this optimization so that Postgres doesn't have to reparse


00:46:55.020 --> 00:46:58.020
your SQL query, it can just execute the pre-cached plan.


00:46:58.020 --> 00:47:01.320
We do the same in HDB and many other things.


00:47:01.320 --> 00:47:04.680
This is why HDB is based on Postgres,


00:47:04.680 --> 00:47:07.360
but it fully envelopes Postgres because we want to be


00:47:07.360 --> 00:47:11.080
in full control of the underlying Postgres instance.


00:47:11.080 --> 00:47:12.820
>> Right. In some sense,


00:47:12.820 --> 00:47:14.540
this is a brand new database that's got


00:47:14.540 --> 00:47:17.740
some really cool features that I'm going to ask you about very soon.


00:47:17.740 --> 00:47:19.020
But in the other sense,


00:47:19.020 --> 00:47:24.920
it's got a lot of stability because it's a database level API


00:47:24.920 --> 00:47:29.920
the rethinking of a well-known core


00:47:29.920 --> 00:47:32.920
that people already trust.


00:47:32.920 --> 00:47:34.400
- Exactly, this is an interesting thing, actually.


00:47:34.400 --> 00:47:40.680
A lot of people are not 100% satisfied


00:47:40.680 --> 00:47:43.400
with relational databases for a variety of reasons.


00:47:43.400 --> 00:47:46.400
Somebody's not satisfied with scaling,


00:47:46.400 --> 00:47:51.600
some not satisfied with SQL,


00:47:51.600 --> 00:47:53.920
and some not satisfied with migrations


00:47:51.400 --> 00:47:56.240
and how rigid the schema is and how inconvenient it is to deal with a relational database.


00:47:56.240 --> 00:47:58.060
So it's a huge problem.


00:47:58.060 --> 00:48:03.280
You have a part of it which is just language design and standard library and type system,


00:48:03.280 --> 00:48:04.280
how that part works.


00:48:04.280 --> 00:48:06.600
The second is workflows around your database.


00:48:06.600 --> 00:48:11.800
The third is the engine of your database, like how it actually works.


00:48:11.800 --> 00:48:21.360
And EdgeDB wants to challenge everything, but we're also not dumb enough to challenge


00:48:21.360 --> 00:48:23.580
everything at the same time.


00:48:23.580 --> 00:48:28.540
We understand that just writing this whole thing from scratch is impossible.


00:48:28.540 --> 00:48:31.740
No company in the world will be able to pull it off.


00:48:31.740 --> 00:48:35.460
Well, maybe some companies will be able to, but definitely not a startup.


00:48:35.460 --> 00:48:37.180
But they have many, many employees.


00:48:37.180 --> 00:48:38.180
Exactly.


00:48:38.180 --> 00:48:39.180
And probably a giant company.


00:48:39.180 --> 00:48:40.180
And multi-billion dollar companies.


00:48:40.180 --> 00:48:41.180
Exactly.


00:48:41.180 --> 00:48:49.180
But so for us, the only viable strategy was to pick a database that is already trusted,


00:48:49.180 --> 00:48:55.380
that is already fast and universally loved, which is Postgres,


00:48:55.380 --> 00:48:59.580
and it's also incredibly capable, and just build on top of it.


00:48:59.580 --> 00:49:02.080
And it's not actually a new approach in databases,


00:49:02.080 --> 00:49:06.780
like lots of databases actually are built on like primitive key value databases,


00:49:06.780 --> 00:49:08.780
like LevelDB or something like that.


00:49:08.780 --> 00:49:11.220
It's a popular approach.


00:49:11.220 --> 00:49:12.620
We're just taking it further.


00:49:12.620 --> 00:49:17.460
We are saying that, hey, using a key-value storage won't buy us much.


00:49:17.460 --> 00:49:22.220
We are like high-level programming language requires a lot of code to be written,


00:49:22.220 --> 00:49:27.900
to properly be executed in good time.


00:49:27.900 --> 00:49:31.980
But SQL looks like this nice compile target.


00:49:31.980 --> 00:49:34.060
So this is why we use Postgres.


00:49:34.060 --> 00:49:35.420
>> Yeah, very cool.


00:49:35.420 --> 00:49:39.920
out of the TypeScript to JavaScript equivalent of the database query language in a sense.


00:49:39.920 --> 00:49:43.820
Yeah, pretty much. I mean, sometimes I explain HDB as LLVM.


00:49:43.820 --> 00:49:48.560
Like, imagine LLVM, it compiles your high-level code to low-level code,


00:49:48.560 --> 00:49:51.060
and then it's jitted, etc.


00:49:51.060 --> 00:49:55.660
And the same about HDB, we compile your high-level schema


00:49:55.660 --> 00:49:57.660
to a proper normalized table layout.


00:49:57.660 --> 00:50:01.520
We compile our HQL, high-level query language, down to SQL,


00:50:01.520 --> 00:50:03.620
and that SQL can actually be jitted by Postgres.


00:50:03.620 --> 00:50:08.620
So essentially, ultimately, your SQL might be executing


00:50:08.620 --> 00:50:13.200
with like native, at native code speed.


00:50:13.200 --> 00:50:16.600
Not now, but in the future.


00:50:16.600 --> 00:50:17.860
- Sure.


00:50:17.860 --> 00:50:21.980
So what's the elevator pitch for people who are out there,


00:50:21.980 --> 00:50:25.420
they're slightly, you know, not super thrilled


00:50:25.420 --> 00:50:27.260
about the database they're necessarily using,


00:50:27.260 --> 00:50:30.460
whatever that is, and they're kind of exploring.


00:50:32.100 --> 00:50:34.940
I picked up a few things that I think make it unique,


00:50:34.940 --> 00:50:36.060
but I want to ask you.


00:50:36.060 --> 00:50:37.860
It's your baby.


00:50:37.860 --> 00:50:41.660
>>All right, so I guess I'll give two pitches.


00:50:41.660 --> 00:50:47.660
One is super high level, and one is slightly more low level.


00:50:47.660 --> 00:50:51.940
A super high level pitch is that imagine you have a tool.


00:50:51.940 --> 00:50:55.260
And when it's a great tool, it becomes an extension


00:50:55.260 --> 00:50:56.540
of your hand, essentially.


00:50:56.540 --> 00:50:57.460
You don't notice it.


00:50:57.460 --> 00:50:59.260
You just do things, right?


00:50:59.260 --> 00:51:01.460
Current databases are not like that.


00:51:01.460 --> 00:51:06.740
They require lots and lots of mental overhead to work with them.


00:51:06.740 --> 00:51:09.580
Like what ORM library do you use in this language?


00:51:09.580 --> 00:51:13.820
>> Right. Is there lazy loading and N plus one stuff I got to consider or is it not?


00:51:13.820 --> 00:51:14.740
All those kinds of things.


00:51:14.740 --> 00:51:17.380
>> Exactly. Then you have to learn their API,


00:51:17.380 --> 00:51:18.980
and then you have to learn SQL and


00:51:18.980 --> 00:51:21.540
understand how those things interact with each other,


00:51:21.540 --> 00:51:24.540
and then you have to care about deployment and migrations.


00:51:24.540 --> 00:51:26.640
It's just so much headache.


00:51:26.640 --> 00:51:31.140
This alone explains why MongoDB was so popular and is so popular,


00:51:31.140 --> 00:51:32.960
because a lot of people just decided,


00:51:32.960 --> 00:51:35.280
"Okay, to help with that, I don't want to deal with this."


00:51:35.280 --> 00:51:37.840
>> I believe in the relational space altogether.


00:51:37.840 --> 00:51:42.920
>> Yeah, exactly. Just abandoning this train.


00:51:42.920 --> 00:51:48.000
We want to fix all of that in NGDB.


00:51:48.000 --> 00:51:50.200
When I give you a tool that you just don't notice,


00:51:50.200 --> 00:51:53.640
when I give you a data model that just feels


00:51:53.640 --> 00:51:57.880
native to Python or TypeScript or Go or any other language,


00:51:57.880 --> 00:51:59.680
you don't have to think in tables anymore.


00:51:59.680 --> 00:52:06.140
I'm going to give you a query language that is super easy to use and learn and compose


00:52:06.140 --> 00:52:08.380
and build query builders around.


00:52:08.380 --> 00:52:13.960
And essentially, we want to essentially kill the entire concept of form.


00:52:13.960 --> 00:52:15.120
We don't need it anymore.


00:52:15.120 --> 00:52:19.720
We are almost sorry that forms have to exist in a way.


00:52:19.720 --> 00:52:20.720
I was going to ask you about that.


00:52:20.720 --> 00:52:23.200
They're solving an incredibly difficult problem.


00:52:23.200 --> 00:52:25.560
This problem is called object impedance mismatch there.


00:52:25.560 --> 00:52:26.560
Yeah.


00:52:26.560 --> 00:52:29.480
to like objects, it's a super hard problem.


00:52:29.480 --> 00:52:32.440
I feel sorry that they have to go through this,


00:52:32.440 --> 00:52:34.440
but we just looked at this problem and decided,


00:52:34.440 --> 00:52:37.460
hey, can we actually just solve


00:52:37.460 --> 00:52:40.040
this object impedance problem in a different way?


00:52:40.040 --> 00:52:42.160
Can we just avoid solving it entirely?


00:52:42.160 --> 00:52:43.560
Can we just give you a database


00:52:43.560 --> 00:52:45.820
with the proper high-level data model


00:52:45.820 --> 00:52:47.840
that doesn't have this problem at all?


00:52:47.840 --> 00:52:49.520
Then suddenly you don't need ORMs.


00:52:49.520 --> 00:52:53.760
- Let's talk real quick about the actual way you define


00:52:53.760 --> 00:52:55.560
what would be the equivalent, I guess,


00:52:55.560 --> 00:52:59.780
of like a DDL table, create script,


00:52:59.780 --> 00:53:02.300
or somewhat related to that, maybe closer,


00:53:02.300 --> 00:53:03.800
is like an ORM class.


00:53:03.800 --> 00:53:05.240
Like it's kind of the--


00:53:05.240 --> 00:53:08.000
- Okay, can I start a little from afar?


00:53:08.000 --> 00:53:09.560
- Yeah, yeah, let's start back.


00:53:09.560 --> 00:53:11.520
- Okay, now it's gonna be the second pitch,


00:53:11.520 --> 00:53:14.180
which is slightly more detailed.


00:53:14.180 --> 00:53:19.180
So we say that HDB is a new kind of database.


00:53:19.180 --> 00:53:21.140
It's not just relational.


00:53:21.140 --> 00:53:24.000
We call it a graph relational database.


00:53:24.000 --> 00:53:27.160
So essentially, we are saying that we created an extension


00:53:27.160 --> 00:53:31.200
to the relational model.


00:53:31.200 --> 00:53:35.080
So what actually constitutes the graph relational model?


00:53:35.080 --> 00:53:39.800
It's first of all, in all of your rows,


00:53:39.800 --> 00:53:42.520
all of your tuples in your relational algebra,


00:53:42.520 --> 00:53:45.060
they essentially have a globally unique key.


00:53:45.060 --> 00:53:46.680
Now, this is a requirement.


00:53:46.680 --> 00:53:50.200
It's data independent, it's just UUID essentially.


00:53:50.200 --> 00:53:52.780
Every row in your database will have it.


00:53:52.780 --> 00:53:55.180
This is the first requirement, first modification.


00:53:55.180 --> 00:53:57.380
The second extension is links.


00:53:57.380 --> 00:54:02.300
The idea that links between data


00:54:02.300 --> 00:54:04.420
is like a first-class citizen of the model.


00:54:04.420 --> 00:54:06.580
You don't need join, you don't need foreign key.


00:54:06.580 --> 00:54:10.980
You just know that, hey, if this type links to another type,


00:54:10.980 --> 00:54:14.700
it's just gonna be like a relationship


00:54:14.700 --> 00:54:15.820
between the unique IDs.


00:54:15.820 --> 00:54:18.020
This is what unique IDs gives you.


00:54:18.020 --> 00:54:19.960
And a second thing is, a third thing,


00:54:19.960 --> 00:54:21.540
is that everything is a set.


00:54:21.540 --> 00:54:31.120
This, like, if you have an object that is connected to multiple other objects,


00:54:31.120 --> 00:54:33.020
this is a set of objects.


00:54:33.020 --> 00:54:36.120
If you have an object that has a bunch of properties,


00:54:36.120 --> 00:54:37.880
it's gonna be a set of properties.


00:54:37.880 --> 00:54:39.820
Even a single thing is a set as well.


00:54:39.820 --> 00:54:43.960
And this is what later enables HQL to be super composable.


00:54:43.960 --> 00:54:47.220
But these are just like three simple kind of axioms


00:54:47.220 --> 00:54:50.540
that are in the core of the model.


00:54:50.540 --> 00:54:55.540
So if we talk about like this schema snippet,


00:54:55.540 --> 00:55:00.860
where we have an object type block post,


00:55:00.860 --> 00:55:05.980
with required property content, which is text,


00:55:05.980 --> 00:55:10.260
and required link author, which is another type called user,


00:55:10.260 --> 00:55:13.180
it's gonna be compiled to a table in SQL


00:55:13.180 --> 00:55:16.940
with a column called content, with a column ID,


00:55:16.940 --> 00:55:19.500
which is gonna be a unique UUID


00:55:19.500 --> 00:55:21.600
for every blog post, it will have it automatically.


00:55:21.600 --> 00:55:22.940
It's immutable, it's read-only.


00:55:22.940 --> 00:55:25.540
You don't have to create them manually.


00:55:25.540 --> 00:55:29.020
And a user will also be a table,


00:55:29.020 --> 00:55:32.820
will also have IDs, and then we'll have a separate column,


00:55:32.820 --> 00:55:34.620
which is gonna be called author,


00:55:34.620 --> 00:55:37.140
in which we will have IDs of users.


00:55:37.140 --> 00:55:40.640
So ultimately, ultimately, like deep beneath


00:55:40.640 --> 00:55:43.540
what you see in EdgeDB is like this high-level schema.


00:55:43.540 --> 00:55:46.540
It's all compiled properly to the relational model.


00:55:46.540 --> 00:55:48.300
It's all normalized there.


00:55:48.300 --> 00:55:50.520
we're still relational, we still like exhibit


00:55:50.520 --> 00:55:52.480
like the same characteristics,


00:55:52.480 --> 00:55:56.080
it's just we're hiding a lot of this like low level things


00:55:56.080 --> 00:55:58.340
that you had to bother with,


00:55:58.340 --> 00:55:59.180
with this high level one,


00:55:59.180 --> 00:56:02.320
we're just abstracting away the low level stuff.


00:56:02.320 --> 00:56:06.520
- Is there a way to directly connect


00:56:06.520 --> 00:56:09.000
to that relational view?


00:56:09.000 --> 00:56:10.840
- You mean Postgres?


00:56:10.840 --> 00:56:12.080
- Yeah. - Postgres database?


00:56:12.080 --> 00:56:14.400
- Yeah, like the underlying--


00:56:14.400 --> 00:56:16.840
- I'm not sure that's really a good idea,


00:56:16.840 --> 00:56:19.940
But in SQLAlchemy, there's a way to go,


00:56:19.940 --> 00:56:23.440
"I just need to get out of here and send raw SQL for a moment."


00:56:23.440 --> 00:56:25.680
That feels like that's the same.


00:56:25.680 --> 00:56:27.680
I just need to go to the guts for a minute.


00:56:27.680 --> 00:56:33.180
Yeah. So with EdgeDB, the goal is for you to never actually need that.


00:56:33.180 --> 00:56:35.180
There is just one exception to this.


00:56:35.180 --> 00:56:37.180
Just one exception.


00:56:37.180 --> 00:56:40.020
But basically, our goal with EdgeQL,


00:56:40.020 --> 00:56:43.220
we knew that, first of all, we have to elevate the data


00:56:43.220 --> 00:56:45.220
and make it more high-level.


00:56:45.220 --> 00:56:51.220
And second of all, we knew that, hey, in order for a relational database to be successful,


00:56:51.220 --> 00:56:54.060
it just has to have query language, right?


00:56:54.060 --> 00:56:57.140
Because our data model is different, we have to come up with our own.


00:56:57.140 --> 00:56:59.540
This is how HQL was born.


00:56:59.540 --> 00:57:02.060
We spent years designing HQL.


00:57:02.060 --> 00:57:10.940
And the reason why is because we wanted it to be actually more powerful than SQL in many


00:57:10.940 --> 00:57:11.940
ways.


00:57:11.940 --> 00:57:15.060
have something that is expressible in SQL,


00:57:15.060 --> 00:57:17.820
but isn't expressible in HTML, we treat it as a bug immediately.


00:57:17.820 --> 00:57:20.700
If something is easier to do in SQL than in HTML, it's a bug.


00:57:20.700 --> 00:57:23.740
And this is why we spent so many years kind of refining this thing,


00:57:23.740 --> 00:57:26.580
to make HTML a capable thing.


00:57:26.580 --> 00:57:30.220
So basically, you never need to use SQL.


00:57:30.220 --> 00:57:33.980
You don't need to know about SQL or know about its existence.


00:57:33.980 --> 00:57:37.420
And this is a powerful thing, because when you use a norm library,


00:57:37.420 --> 00:57:39.100
you have to know about SQL.


00:57:39.100 --> 00:57:41.500
With HDB, no, we just learn one language,


00:57:41.500 --> 00:57:44.620
and you're good to go for the rest of your life, essentially.


00:57:44.620 --> 00:57:48.460
There's just one use case when you might need SQL.


00:57:48.460 --> 00:57:50.940
It's when, let's say, you're a big company


00:57:50.940 --> 00:57:55.580
and you're using some BI tools like Tableau or something like that.


00:57:55.580 --> 00:57:58.140
You have analysts that already know SQL.


00:57:58.140 --> 00:58:00.540
And we're going to do something about it.


00:58:00.540 --> 00:58:01.500
We're going to open like...


00:58:01.500 --> 00:58:03.820
- Like an adapter.


00:58:03.820 --> 00:58:05.340
- Adapter, exactly.


00:58:05.340 --> 00:58:09.340
It will allow you to just run SQL against the database in read-only mode.


00:58:09.340 --> 00:58:10.540
- That makes a lot of sense.


00:58:10.540 --> 00:58:12.940
Because there are these big BI tools.


00:58:12.940 --> 00:58:14.700
And you're like, if your data is here,


00:58:14.700 --> 00:58:16.460
do you really want to have some job


00:58:16.460 --> 00:58:19.900
to move it to another Postgres just to run an analysis on it?


00:58:19.900 --> 00:58:20.620
Yeah.


00:58:20.620 --> 00:58:21.300
Exactly.


00:58:21.300 --> 00:58:25.380
I mean, just like with us not attacking this problem all


00:58:25.380 --> 00:58:27.780
at once and implementing the engine and the language


00:58:27.780 --> 00:58:29.820
and everything else, here we also


00:58:29.820 --> 00:58:33.900
understand that we are not going to replace all the business


00:58:33.900 --> 00:58:36.300
intelligence infrastructure overnight.


00:58:36.300 --> 00:58:38.500
And we have to make it be compatible.


00:58:38.500 --> 00:58:39.780
It's not there yet.


00:58:39.780 --> 00:58:42.420
it will be a part of a future release.


00:58:42.420 --> 00:58:45.700
- You have a nice roadmap, which we'll cover in a minute,


00:58:45.700 --> 00:58:47.180
but like, I really love how you sort of--


00:58:47.180 --> 00:58:48.620
- Oh my God, it's so outdated.


00:58:48.620 --> 00:58:50.900
(laughs)


00:58:50.900 --> 00:58:54.180
I can just say it out loud, like the idea--


00:58:54.180 --> 00:58:56.260
- But let me, like just for people who wanna see,


00:58:56.260 --> 00:58:57.500
if they go there just visually,


00:58:57.500 --> 00:59:00.380
the way that you've laid this out of like where you are


00:59:00.380 --> 00:59:01.260
and where you're going,


00:59:01.260 --> 00:59:05.420
like so many libraries and products should model this


00:59:05.420 --> 00:59:09.460
'cause so often, you know, you'll reach out to the companies


00:59:09.460 --> 00:59:10.660
"Hey, it'd be great if you could do this.


00:59:10.660 --> 00:59:11.860
Oh yeah, it's on our roadmap."


00:59:11.860 --> 00:59:14.460
Like, "Oh yeah, well, what is that like some,


00:59:14.460 --> 00:59:15.940
where do you even have that?"


00:59:15.940 --> 00:59:17.500
So anyway, I think your roadmap is great,


00:59:17.500 --> 00:59:19.220
but give us the update.


00:59:19.220 --> 00:59:21.740
- It is beautiful and I encourage everybody


00:59:21.740 --> 00:59:22.740
to go and check it out.


00:59:22.740 --> 00:59:25.140
It's hdb.com/roadmap.


00:59:25.140 --> 00:59:26.300
It is slightly outdated.


00:59:26.300 --> 00:59:29.260
Lots of things that are in progress.


00:59:29.260 --> 00:59:32.860
- Yeah, this Formula car here, this is a 2021 series.


00:59:32.860 --> 00:59:35.340
They just redid the Formula One cars for 2022.


00:59:35.340 --> 00:59:38.260
So that's probably not what you're talking about.


00:59:38.260 --> 00:59:41.620
All right, so tell us what's coming for us.


00:59:41.620 --> 00:59:42.620
What's coming?


00:59:42.620 --> 00:59:45.900
It took us years for building HTTP 1.0.


00:59:45.900 --> 00:59:49.340
And during this time, we were almost encouraging people


00:59:49.340 --> 00:59:51.900
not to use HTTP because it's a relational database.


00:59:51.900 --> 00:59:53.740
If you build a business on an alpha version


00:59:53.740 --> 00:59:56.300
of relational database and it goes down,


00:59:56.300 --> 00:59:58.580
your business will go down with it most likely.


00:59:58.580 --> 01:00:00.180
So we didn't want that.


01:00:00.180 --> 01:00:02.380
And people should know you just released 1.0, right?


01:00:02.380 --> 01:00:03.740
That's a huge, huge thing.


01:00:03.740 --> 01:00:04.580
Well, congratulations.


01:00:04.580 --> 01:00:06.740
We launched 1.0 a week ago.


01:00:06.740 --> 01:00:11.860
It was on Hacker News number one for 13, maybe 14 hours.


01:00:11.860 --> 01:00:13.860
It was a pretty interesting event.


01:00:13.860 --> 01:00:16.820
We also had a live stream, us launching it,


01:00:16.820 --> 01:00:20.940
talking about the architecture of HDB, of the query language,


01:00:20.940 --> 01:00:22.260
comparing it to SQL.


01:00:22.260 --> 01:00:23.400
It's a great event.


01:00:23.400 --> 01:00:25.780
And I encourage you to check it out if you have time.


01:00:25.780 --> 01:00:29.300
And if you're interested, it's YouTube/hdb.


01:00:29.300 --> 01:00:29.860
Check it out.


01:00:29.860 --> 01:00:32.780
You'll find it there.


01:00:32.780 --> 01:00:36.260
But yeah, so it took us years to do 1.0 just right,


01:00:36.260 --> 01:00:39.260
to make sure that EdgeQL is right, that its design is sound,


01:00:39.260 --> 01:00:43.520
and that the schema is right, and the workflows, and CLI,


01:00:43.520 --> 01:00:46.460
and the client APIs, everything is just right,


01:00:46.460 --> 01:00:49.560
and that we are confident that, hey, we're not going to be changing it.


01:00:49.560 --> 01:00:52.620
We're not going to be retroactively fixing things.


01:00:52.620 --> 01:00:57.460
So it took us a long year, many years, but now it's out.


01:00:57.460 --> 01:01:01.060
And now we don't want to spend many years on HDB 2.0.


01:01:01.060 --> 01:01:02.920
We actually want to make it way quicker.


01:01:02.920 --> 01:01:04.360
We have the solid foundation.


01:01:04.360 --> 01:01:07.680
We can iterate much faster now.


01:01:07.680 --> 01:01:09.120
And this is what we're going to do.


01:01:09.120 --> 01:01:12.680
So our current target, internal target,


01:01:12.680 --> 01:01:19.400
is to release 2.0 sometime in May 2022, so relatively soon.


01:01:19.400 --> 01:01:24.480
And 2.0 will have a few features.


01:01:24.480 --> 01:01:26.800
One is almost implemented.


01:01:26.800 --> 01:01:29.000
It's a groupby statement.


01:01:29.000 --> 01:01:34.340
As I said, the idea of HQL is to actually surpass SQL in capabilities.


01:01:34.340 --> 01:01:39.040
And right now with HQL, it's already incredibly powerful.


01:01:39.040 --> 01:01:42.540
You can fetch that data hierarchies, you can compute things,


01:01:42.540 --> 01:01:46.340
you can use aggregate functions, you have subqueries, you have JSON.


01:01:46.340 --> 01:01:49.800
It's an incredibly powerful language right now,


01:01:49.800 --> 01:01:55.260
but a proper group by statements will give it proper analytical flavor.


01:01:55.260 --> 01:01:57.340
Now you will be able to actually create reports.


01:01:57.340 --> 01:01:59.340
and we have a great Groupby design.


01:01:59.340 --> 01:02:05.340
By the way, we try to make the HQL design process as open as possible.


01:02:05.340 --> 01:02:09.340
We have RFCs. It's github.com/hdb/rfcs.


01:02:09.340 --> 01:02:14.340
So if you're interested to look at how our Groupby is different from SQL Groupby


01:02:14.340 --> 01:02:16.340
and why it's better than SQL Groupby,


01:02:16.340 --> 01:02:19.340
you can just go ahead and read an RFC about our Groupby.


01:02:19.340 --> 01:02:21.340
So Groupby is going to be one thing.


01:02:21.340 --> 01:02:24.340
The second thing is going to be a proper explain for your queries,


01:02:24.340 --> 01:02:30.780
queries, like why is my query slow and we have some ideas on how to make it


01:02:30.780 --> 01:02:34.940
less cryptic than the default explain output that you get in most databases.


01:02:34.940 --> 01:02:41.140
And then there is an exciting thing and I hope that we'll have enough time to


01:02:41.140 --> 01:02:47.860
implement it, which is access control. So, EdgeDB is this like vertically


01:02:47.860 --> 01:02:52.500
integrated thing. So, you define your schema and in your schema you can define


01:02:52.500 --> 01:02:57.500
aliases, which is basically a view in your relational database.


01:02:57.500 --> 01:03:02.000
You can define fields or object types that are computed dynamically with HQL.


01:03:02.000 --> 01:03:06.500
So schema depends on HQL and HQL depends on schema in HDB.


01:03:06.500 --> 01:03:08.500
And they are intertwined.


01:03:08.500 --> 01:03:10.500
So we have this idea.


01:03:10.500 --> 01:03:15.500
It's not that it's super new, but in HDB it's going to be super powerful.


01:03:15.500 --> 01:03:21.500
It's that you'll be able to specify different policies on your schema type.


01:03:21.500 --> 01:03:28.060
like allow reading something or allow mutating something or disallow etc.


01:03:28.060 --> 01:03:30.540
And we don't want to hard code that.


01:03:30.540 --> 01:03:36.220
So essentially we are introducing this concept of context in a database.


01:03:36.220 --> 01:03:41.740
You'll be able to define sort of like global variables, like context variables in your schema,


01:03:41.740 --> 01:03:47.260
say a user ID in 64 and something else is true.


01:03:47.260 --> 01:03:51.340
And then when you just get your connection in your Python code,


01:03:51.340 --> 01:03:54.700
you say with context pass user ID,


01:03:54.700 --> 01:03:57.260
that is automatically passed to the database.


01:03:57.260 --> 01:04:03.860
In your schema, you can implement arbitrarily access logic on your schema type.


01:04:03.860 --> 01:04:06.940
And this logic will be automatically enforced in all your queries.


01:04:06.940 --> 01:04:08.740
Oh, fantastic. Yeah, that's really cool.


01:04:08.740 --> 01:04:11.740
The homepage is filtered, you're fetching data for report,


01:04:11.740 --> 01:04:15.540
and it only includes the data that your business logic allow


01:04:15.540 --> 01:04:17.660
it to be there.


01:04:17.660 --> 01:04:20.780
So basically, with HDB, you will have schema.


01:04:20.780 --> 01:04:23.100
And that schema not only will define


01:04:23.100 --> 01:04:25.460
just the data layout of your application,


01:04:25.460 --> 01:04:29.340
but also the access patterns and many other things in the future.


01:04:29.340 --> 01:04:34.460
Yeah, I really want to ask you about the query syntax,


01:04:34.460 --> 01:04:36.540
because I find it super interesting,


01:04:36.540 --> 01:04:39.140
especially also how it relates to like,


01:04:39.140 --> 01:04:41.540
ORMs and so on.


01:04:41.540 --> 01:04:44.060
But Michael out in the audience has a pretty neat question


01:04:44.060 --> 01:04:46.500
that sort of follows onto the roadmap first.


01:04:46.500 --> 01:04:50.660
So since EdgeDB is fundamentally Python,


01:04:50.660 --> 01:04:53.420
it'd be great to have a way to run user-defined functions


01:04:53.420 --> 01:04:56.820
in Python against, so like, stored procedures,


01:04:56.820 --> 01:05:00.460
but Python, not SQL.


01:05:00.460 --> 01:05:02.660
- Yeah, yeah, it's an interesting question.


01:05:02.660 --> 01:05:05.940
I mean, user-defined functions,


01:05:05.940 --> 01:05:08.060
well, first of all, there are like,


01:05:08.060 --> 01:05:11.340
couple of different planes, I would say,


01:05:11.340 --> 01:05:14.240
of user-defined functions in the context of HDB,


01:05:14.240 --> 01:05:17.740
because HDB has this notion of extensions.


01:05:17.740 --> 01:05:20.440
The API isn't public yet, but HDB, for example,


01:05:20.440 --> 01:05:21.940
supports GraphQL natively.


01:05:21.940 --> 01:05:25.340
You can just run HDB, let's say, on port 555.


01:05:25.340 --> 01:05:31.040
It's in the localhost, colon 555 slash db, mydb slash GraphQL.


01:05:31.040 --> 01:05:37.940
And we want you to be able to also define potentially


01:05:37.940 --> 01:05:41.900
and eventually, like user-defined API handlers there.


01:05:41.900 --> 01:05:46.100
So that with HDB, you would not need a back-end at all


01:05:46.100 --> 01:05:49.900
if your business logic is relatively simple.


01:05:49.900 --> 01:05:52.900
Oh, interesting. So if I've got like something on Netlify


01:05:52.900 --> 01:05:55.400
where it's pure static code,


01:05:55.400 --> 01:05:58.200
I just write a little JavaScript, some view or whatever,


01:05:58.200 --> 01:06:02.000
and it could theoretically do read-only stuff maybe


01:06:02.000 --> 01:06:03.300
to an HDB instance.


01:06:03.300 --> 01:06:05.500
Or write-only, yeah, absolutely.


01:06:05.500 --> 01:06:12.580
So yeah, we just want to kind of push this idea of back-endless development as far as we can.


01:06:12.580 --> 01:06:17.380
And because HDB has this incredibly powerful schema and will soon have access control,


01:06:17.380 --> 01:06:19.880
that already allows you to eliminate a lot of code, right?


01:06:19.880 --> 01:06:25.180
If only you could define some simple server-side, database-side function.


01:06:25.180 --> 01:06:26.880
A little bit of Python in there.


01:06:26.880 --> 01:06:30.540
A little bit of Python or JavaScript or maybe a raster or something


01:06:30.540 --> 01:06:35.140
that you can just make that request to Stripe API, do something and then glue things together.


01:06:35.140 --> 01:06:36.840
then maybe you don't need the backend at all.


01:06:36.840 --> 01:06:40.920
So this is our vision, eventually, to allow things like this.


01:06:40.920 --> 01:06:45.120
And second plane is user-defined functions within the database.


01:06:45.120 --> 01:06:48.800
And because we're using Postgres, those functions are going to be running inside Postgres.


01:06:48.800 --> 01:06:51.260
You will be able to call them from the query language, like,


01:06:51.260 --> 01:06:56.000
"Hey, just use NumPy to crunch this data for me, like write in HKEO."


01:06:56.000 --> 01:06:57.440
This is also possible.


01:06:57.440 --> 01:07:00.940
There are extensions for Postgres that allow you to do that.


01:07:00.940 --> 01:07:04.220
It's possible to define user-defined functions


01:07:04.220 --> 01:07:06.720
and post-receive in multiple different languages.


01:07:06.720 --> 01:07:08.820
Extensions for that are there.


01:07:08.820 --> 01:07:13.660
So yeah, it's an interesting thing for us to think about,


01:07:13.660 --> 01:07:17.020
and we are thinking about it, but probably not for 2.0.


01:07:17.020 --> 01:07:18.460
- Yeah, okay.


01:07:18.460 --> 01:07:19.300
Very cool.


01:07:19.300 --> 01:07:21.700
Let's talk about this statement here for a minute.


01:07:21.700 --> 01:07:23.860
There's a lot.


01:07:23.860 --> 01:07:25.620
I think this, I'll describe it in a second


01:07:25.620 --> 01:07:26.620
for people listening.


01:07:26.620 --> 01:07:30.340
I think this query syntax highlights a lot


01:07:30.340 --> 01:07:33.360
of probably what makes HDB unique


01:07:33.360 --> 01:07:35.680
and some of your motives here.


01:07:35.680 --> 01:07:40.180
So if you wanted to go and get say a movie,


01:07:40.180 --> 01:07:43.340
which has a relationship to an actor's table


01:07:43.340 --> 01:07:46.020
and you wanna do some sort of filter type thing,


01:07:46.020 --> 01:07:49.660
you would say select movie curly brace,


01:07:49.660 --> 01:07:53.140
look at that, title, that's the select projection.


01:07:53.140 --> 01:07:54.860
So movie.title basically,


01:07:54.860 --> 01:07:58.500
and then actors curly brace, name and email.


01:07:58.500 --> 01:08:00.060
So is that, is this part right here,


01:08:00.060 --> 01:08:03.460
this sub actors, is that traversing the relationship,


01:08:03.460 --> 01:08:04.980
that graph relationship?


01:08:04.980 --> 01:08:06.940
- Exactly, basically traversing the graph.


01:08:06.940 --> 01:08:08.460
- And then inside this like statement,


01:08:08.460 --> 01:08:09.820
you say order by dot name,


01:08:09.820 --> 01:08:11.980
you have this cool convention of dot,


01:08:11.980 --> 01:08:14.140
which if you're in one of these scopes,


01:08:14.140 --> 01:08:18.980
like curly bracket actors, then you can say dot,


01:08:18.980 --> 01:08:22.580
and it means dot name applies back to that, right?


01:08:22.580 --> 01:08:25.580
- Yes, and basically this is just syntax sugar.


01:08:25.580 --> 01:08:27.620
Nothing prevents you from spelling it out completely.


01:08:27.620 --> 01:08:31.300
like you say, you can say order by movie.actors.name.


01:08:31.300 --> 01:08:32.140
- Yeah.


01:08:32.140 --> 01:08:34.420
- Because you're already inside the actors essentially,


01:08:34.420 --> 01:08:36.140
we're just like giving you this.


01:08:36.140 --> 01:08:37.300
- Yeah, fantastic.


01:08:37.300 --> 01:08:39.860
Then another thing that stands out for the query syntax


01:08:39.860 --> 01:08:41.820
is you can define inline variables


01:08:41.820 --> 01:08:43.660
using the walrus operator, by the way.


01:08:43.660 --> 01:08:45.260
- Yeah. (laughs)


01:08:45.260 --> 01:08:47.740
- So you can say average review equals math mean


01:08:47.740 --> 01:08:51.660
dot reviews of the movie, then dot rating.


01:08:51.660 --> 01:08:54.540
And is this also traversing?


01:08:54.540 --> 01:08:56.140
- Exactly. - What is this?


01:08:56.140 --> 01:09:02.100
Yeah, so basically a movie type has a multi-link reviews.


01:09:02.100 --> 01:09:04.220
So multiple reviews can be attached to movies.


01:09:04.220 --> 01:09:08.740
And every review has, let's say, a five-star rating,


01:09:08.740 --> 01:09:10.660
an integer of 1 to 5.


01:09:10.660 --> 01:09:12.780
And this is how you quickly can say, hey,


01:09:12.780 --> 01:09:16.100
just calculate the mean number of--


01:09:16.100 --> 01:09:21.460
the mean value of all linked reviews and all their ratings.


01:09:21.460 --> 01:09:24.300
This-- somebody on Hacker News years ago


01:09:24.300 --> 01:09:27.980
aptly called HTL as a child of SQL and GraphQL.


01:09:27.980 --> 01:09:31.580
And I mean, it's funny, but there is truth to it.


01:09:31.580 --> 01:09:36.580
Because GraphQL made it extremely obvious to people


01:09:36.580 --> 01:09:43.580
that working with object hierarchies this way,


01:09:43.580 --> 01:09:44.700
when you can just have a query


01:09:44.700 --> 01:09:46.700
that just selects something deep, right?


01:09:46.700 --> 01:09:49.860
Is extremely important.


01:09:49.860 --> 01:09:51.940
People suddenly realize this is cool.


01:09:51.940 --> 01:09:54.200
Some companies even try to make GraphQL work


01:09:54.200 --> 01:09:56.520
for relational databases such as Hasura,


01:09:56.520 --> 01:09:57.760
and they have an amazing product.


01:09:57.760 --> 01:10:02.760
And the only problem is that GraphQL isn't actually,


01:10:02.760 --> 01:10:05.160
it wasn't designed for creating databases.


01:10:05.160 --> 01:10:08.080
It's an API, which is a REST replacement.


01:10:08.080 --> 01:10:10.860
So while it works for some things,


01:10:10.860 --> 01:10:13.120
good luck computing something in GraphQL.


01:10:13.120 --> 01:10:14.600
You just can't, you can fetch things,


01:10:14.600 --> 01:10:16.480
but you cannot compute like your average review


01:10:16.480 --> 01:10:19.240
is not possible to do in GraphQL.


01:10:19.240 --> 01:10:23.440
SQL, on the other hand, is very stubborn


01:10:23.440 --> 01:10:26.580
when you have to select anything nested.


01:10:26.580 --> 01:10:29.320
Like, it thinks in tables, you have to think in tables.


01:10:29.320 --> 01:10:31.220
You either like select super wide tables


01:10:31.220 --> 01:10:32.800
and then you have to write some Python code


01:10:32.800 --> 01:10:37.240
to kind of combine it back to your shape or use a norm.


01:10:37.240 --> 01:10:41.280
Or if you're using advanced database,


01:10:41.280 --> 01:10:43.880
you can use things like ArrayAg.


01:10:43.880 --> 01:10:48.880
But SQL, it doesn't shine problems like this.


01:10:49.040 --> 01:10:55.040
So yeah, with EdgeQL, we're kind of marrying those both worlds.


01:10:55.040 --> 01:10:58.360
You have this deep fetch syntax, and you


01:10:58.360 --> 01:11:02.200
have an ability to drop computation


01:11:02.200 --> 01:11:06.000
at any point of your query.


01:11:06.000 --> 01:11:08.920
There are a couple of other super important things


01:11:08.920 --> 01:11:11.600
about EdgeQL, if you want, I can--


01:11:11.600 --> 01:11:14.240
Yeah, we're getting short on time, but yeah, go ahead.


01:11:14.240 --> 01:11:14.740
Sure.


01:11:14.740 --> 01:11:18.880
So as I said before, sometimes the PhHDB is like this.


01:11:18.880 --> 01:11:20.880
OEM thing like compiler.


01:11:20.880 --> 01:11:24.480
So when we compile HQL query to a SQL,


01:11:24.480 --> 01:11:27.440
we have one important thing.


01:11:27.440 --> 01:11:30.960
Every HQL query, no matter how complex it is,


01:11:30.960 --> 01:11:34.400
it's always compiled to just one SQL query.


01:11:34.400 --> 01:11:37.680
And this is very important in the context of relational databases


01:11:37.680 --> 01:11:40.040
because when you have just one single query, it's atomic.


01:11:40.040 --> 01:11:43.000
So you don't need like an explicit transaction.


01:11:43.000 --> 01:11:47.520
You're already like working, you always work with the same snapshot update essentially.


01:11:47.520 --> 01:11:51.360
- Interesting. So you're not in this case, like going, doing a query for the movies


01:11:51.360 --> 01:11:57.760
and then doing a query for the actors and then doing a query for the reviews as three steps.


01:11:57.760 --> 01:12:02.240
You're just, it's basically a three-way join and then you're getting the data back out,


01:12:02.240 --> 01:12:04.800
something like that. - It's slightly more complicated than three-way join.


01:12:04.800 --> 01:12:08.240
- Yeah, I'm sure it is. - But yeah, basically, basically, yeah,


01:12:08.240 --> 01:12:13.200
that's the idea. For one HQL query, it's always one SQL query. It's very important. We use lots


01:12:13.200 --> 01:12:16.320
of interesting tricks to make it happen. And if you're interested about those tricks,


01:12:16.320 --> 01:12:21.360
youtube.com/hdbs and watch our live event to explain this all actually.


01:12:21.360 --> 01:12:25.840
But it's an important thing and then HQL is actually


01:12:25.840 --> 01:12:31.040
it's very composable so you can pack multiple different queries into one


01:12:31.040 --> 01:12:33.360
query so you can have a query that reads data,


01:12:33.360 --> 01:12:36.560
insert data, mutates data and introspects the


01:12:36.560 --> 01:12:41.040
schema all in one huge thing and it will execute quickly for you and


01:12:41.040 --> 01:12:46.160
return your data like in proper way ready for you to be consumed


01:12:46.160 --> 01:12:52.000
consumed. So, Edge Kill is extremely powerful in that regard. And this is what separates it from


01:12:52.000 --> 01:12:58.480
ORMs, because your ORM, be it SQLAlchemy or Prisma or something like that, they might have a high


01:12:58.480 --> 01:13:04.800
level API for some operations. But they also don't really restrict themselves on how many queries it


01:13:04.800 --> 01:13:10.080
will take to implement that API. Sometimes, plus one, yeah. Right. And if you benchmark it on local


01:13:10.080 --> 01:13:15.360
host, for example, databases on your laptop and your code executes on laptop, it appears to be


01:13:15.360 --> 01:13:20.480
fast. So you have three queries instead of one. So what? There is zero latency between


01:13:20.480 --> 01:13:21.840
your database and your code.


01:13:21.840 --> 01:13:25.200
And probably not full production levels of data.


01:13:25.200 --> 01:13:30.440
Yeah, sure. But when you move it to the dot data center, you will have latency between


01:13:30.440 --> 01:13:34.680
your code and the database. And even if you have like one millisecond latency between


01:13:34.680 --> 01:13:42.680
your queries, suddenly you just start losing performance a lot because your Python that


01:13:42.680 --> 01:13:46.160
uses or JavaScript that uses a more operation,


01:13:46.160 --> 01:13:48.480
you can actually fire 10 queries.


01:13:48.480 --> 01:13:51.020
This is easy, 10 queries is fine.


01:13:51.020 --> 01:13:54.580
Imagine just 10 milliseconds and just doing that,


01:13:54.580 --> 01:13:56.440
just latency, nothing else.


01:13:56.440 --> 01:13:58.200
You're just losing performance.


01:13:58.200 --> 01:14:00.520
With SDB, it's not a thing.


01:14:00.520 --> 01:14:04.260
>> Final question here. When I run this,


01:14:04.260 --> 01:14:06.040
what do I get back in Python?


01:14:06.040 --> 01:14:08.880
Obviously, there's a nice async


01:14:08.880 --> 01:14:12.080
and synchronous Python API to talk to this.


01:14:12.080 --> 01:14:15.480
>> Yeah. But when I run this query in Python, what do I get?


01:14:15.480 --> 01:14:17.760
>> It depends on how you run it.


01:14:17.760 --> 01:14:20.900
We offer you two modes,


01:14:20.900 --> 01:14:22.280
essentially, two output modes.


01:14:22.280 --> 01:14:24.880
Any HQL query can be compiled as JSON.


01:14:24.880 --> 01:14:26.080
In our Python client,


01:14:26.080 --> 01:14:29.240
you just say query JSON and it will return you JSON data,


01:14:29.240 --> 01:14:32.240
like ready to be pumped to your front end.


01:14:32.240 --> 01:14:33.840
Or you can just say query.


01:14:33.840 --> 01:14:37.360
When you say query, it will return you rich Python objects.


01:14:37.360 --> 01:14:38.920
It will have movie Python object,


01:14:38.920 --> 01:14:40.000
which with the title,


01:14:40.000 --> 01:14:42.520
a string attribute with an actors list,


01:14:42.520 --> 01:14:45.680
which will have actors objects within it, etc.


01:14:45.680 --> 01:14:49.280
It's also very compact on the IO level.


01:14:49.280 --> 01:14:53.120
We're not sending super fat tables or anything.


01:14:53.120 --> 01:14:55.800
The data is neatly serialized.


01:14:55.800 --> 01:14:58.760
No need for any duplication, anything.


01:14:58.760 --> 01:15:04.400
It's just like you have your native object data model in the database,


01:15:04.400 --> 01:15:07.880
you query it, and you get objects out of it.


01:15:07.880 --> 01:15:11.360
So you never have to think about any tables or anything.


01:15:11.360 --> 01:15:12.960
It's always high level.


01:15:12.960 --> 01:15:13.960
- Nice. All right.


01:15:13.960 --> 01:15:16.520
Final question, then we really do have to wrap it up.


01:15:16.520 --> 01:15:20.600
One of the things that's really nice about ORMs


01:15:20.600 --> 01:15:23.080
is I can say my thing dot,


01:15:23.080 --> 01:15:24.820
and I get a list in my editor


01:15:24.820 --> 01:15:29.160
of what I should be getting back from the database.


01:15:29.160 --> 01:15:30.780
Can I do that with this?


01:15:30.780 --> 01:15:32.880
I know the movie is basically defined


01:15:32.880 --> 01:15:37.160
in the GraphQL schema definition.


01:15:37.160 --> 01:15:39.560
Is there a way to do like a typeshed type thing?


01:15:39.560 --> 01:15:40.840
Yeah, EdgeDB, sorry.


01:15:40.840 --> 01:15:41.920
Yeah, sorry.


01:15:41.920 --> 01:15:44.560
In the EdgeDB schema language,


01:15:44.560 --> 01:15:46.720
but is there a way to do like a typeshed thing to say,


01:15:46.720 --> 01:15:50.080
well, that thing you get back looks like this?


01:15:50.080 --> 01:15:52.400
- Yes, unfortunately not in Python yet.


01:15:52.400 --> 01:15:55.040
In TypeScript, we just released our query builder


01:15:55.040 --> 01:16:00.040
and it's insane because the API of the query builder


01:16:00.040 --> 01:16:05.400
super closely replicates the layout of the HQL query.


01:16:05.880 --> 01:16:07.760
It's basically like one-to-one correspondence.


01:16:07.760 --> 01:16:09.760
It's like almost like same thing.


01:16:09.760 --> 01:16:12.760
And in TypeScript, we just focused on TypeScript first,


01:16:12.760 --> 01:16:15.040
then Python is next.


01:16:15.040 --> 01:16:18.000
But for TypeScript, yes, you reflect your schema


01:16:18.000 --> 01:16:20.000
with just one command line command.


01:16:20.000 --> 01:16:23.280
And in VS Code, you now have full autocomplete.


01:16:23.280 --> 01:16:24.800
You can express your queries in TypeScript,


01:16:24.800 --> 01:16:26.760
no matter how nested they are,


01:16:26.760 --> 01:16:28.940
no matter what kind of computation you do,


01:16:28.940 --> 01:16:30.280
it's still the same idea.


01:16:30.280 --> 01:16:31.920
Whatever query you build in your TypeScript


01:16:31.920 --> 01:16:33.240
is gonna be just single edge kill query,


01:16:33.240 --> 01:16:35.640
single SQL queries, it will be fast.


01:16:35.640 --> 01:16:38.580
And you have full auto-completion and more,


01:16:38.580 --> 01:16:41.980
you actually have full return type inference.


01:16:41.980 --> 01:16:43.340
You don't have to type anything.


01:16:43.340 --> 01:16:47.020
You have a query and your VS Code and TypeScript,


01:16:47.020 --> 01:16:51.220
they will know the type of the data that's going to be returned.


01:16:51.220 --> 01:16:52.280
>> Interesting. Okay.


01:16:52.280 --> 01:16:53.920
>> It works like magic.


01:16:53.920 --> 01:16:56.740
We're going to see if we can replicate


01:16:56.740 --> 01:17:00.380
this experience with Python and mypy.


01:17:00.380 --> 01:17:03.300
This is going to be our goal to make something like this happen.


01:17:03.300 --> 01:17:05.260
Right now, we just have this low level,


01:17:05.260 --> 01:17:07.820
well, relatively low level client API for Python.


01:17:07.820 --> 01:17:11.260
You can run any HQL query, you can get data for it,


01:17:11.260 --> 01:17:14.700
you can do it in async or sync, entirely up to you.


01:17:14.700 --> 01:17:17.700
But the typing integration specifically isn't there.


01:17:17.700 --> 01:17:23.620
And second part of this question is that we are looking in future


01:17:23.620 --> 01:17:26.980
at implementing a language server protocol for EdgeDB.


01:17:26.980 --> 01:17:30.260
So install EdgeDB locally and then VS Code will just connect to it.


01:17:30.260 --> 01:17:33.560
And then you would have your autocomplete for HQL queries,


01:17:33.560 --> 01:17:35.560
for schema files.


01:17:35.560 --> 01:17:37.320
This is going to be great.


01:17:37.320 --> 01:17:41.720
But I'm just not sure what kind of ETA we can put in it.


01:17:41.720 --> 01:17:43.800
Probably not 2.0.


01:17:43.800 --> 01:17:47.120
>> Yeah, looking forward to it.


01:17:47.120 --> 01:17:49.820
Very neat work on EdgeDB and obviously all the building


01:17:49.820 --> 01:17:51.920
blocks that we talked about at the beginning.


01:17:51.920 --> 01:17:53.120
Congratulations.


01:17:53.120 --> 01:17:54.080
>> Thank you, Michael.


01:17:54.080 --> 01:17:54.720
>> Yeah, you bet.


01:17:54.720 --> 01:17:59.560
All right, very quickly, lightning round, like quick.


01:17:59.560 --> 01:18:02.280
Favorite editor?


01:18:02.280 --> 01:18:03.240
>> VS Code.


01:18:03.240 --> 01:18:03.740
>> Okay.


01:18:03.740 --> 01:18:06.320
>> Although I enjoy Vim as well.


01:18:06.320 --> 01:18:06.960
>> Right on.


01:18:06.960 --> 01:18:11.000
And then notable PyPI package?


01:18:11.000 --> 01:18:13.160
>> I'll list mine, you look.


01:18:13.160 --> 01:18:15.040
Right, I'll list my Py as well.


01:18:15.040 --> 01:18:17.120
My Py is a great thing.


01:18:17.120 --> 01:18:18.080
Use my Py.


01:18:18.080 --> 01:18:18.480
>> Cool.


01:18:18.480 --> 01:18:19.480
Right on.


01:18:19.480 --> 01:18:19.880
All right.


01:18:19.880 --> 01:18:20.680
Final call to action.


01:18:20.680 --> 01:18:24.920
People are interested in your projects, probably primarily EdgeDB.


01:18:24.920 --> 01:18:26.200
What do you say?


01:18:26.200 --> 01:18:27.320
How to get started?


01:18:27.320 --> 01:18:28.160
>> Yeah, absolutely.


01:18:28.160 --> 01:18:28.920
It's ready for you.


01:18:28.920 --> 01:18:30.000
It's 1.0.


01:18:30.000 --> 01:18:32.800
It's stable.


01:18:32.800 --> 01:18:33.760
Follow us on Twitter.


01:18:33.760 --> 01:18:38.040
It's Twitter Edge Database without any underscores


01:18:38.040 --> 01:18:39.840
or dashes, just Edge Database.


01:18:39.840 --> 01:18:40.720
Follow us on Twitter.


01:18:40.720 --> 01:18:43.440
You will find the Discord link right in the Twitter


01:18:43.440 --> 01:18:44.680
description.


01:18:44.680 --> 01:18:46.000
So join our Discord.


01:18:46.000 --> 01:18:48.240
We try to grow a community.


01:18:48.240 --> 01:18:50.800
And yeah, build something amazing.


01:18:50.800 --> 01:18:55.640
EdgeDB-- I can say it with full confidence.


01:18:55.640 --> 01:18:59.960
HDB is the most amazing thing that ever happened to relational databases.


01:18:59.960 --> 01:19:01.600
So take a look at it.


01:19:01.600 --> 01:19:05.120
This is the beginning of hopefully a big movement.


01:19:05.120 --> 01:19:06.560
Yeah, fantastic.


01:19:06.560 --> 01:19:10.880
All right, let me put in one final Postscript question.


01:19:10.880 --> 01:19:11.680
Sorry.


01:19:11.680 --> 01:19:15.120
I really wanted to ask you this, and I think it matters for people considering adopting it.


01:19:15.120 --> 01:19:17.680
But do keep it super quick.


01:19:17.680 --> 01:19:18.640
What's the business model?


01:19:18.640 --> 01:19:23.000
Like when you guys release this thing, is it...


01:19:23.000 --> 01:19:24.000
How do people get it?


01:19:24.000 --> 01:19:25.720
Will there be a free version?


01:19:25.720 --> 01:19:26.760
What's the story?


01:19:26.760 --> 01:19:28.960
- So, HDB is fully open source.


01:19:28.960 --> 01:19:29.960
It's Apache to license.


01:19:29.960 --> 01:19:32.640
It's externally permissive, no strings attached.


01:19:32.640 --> 01:19:35.440
We'll make money by running HDB for you, essentially.


01:19:35.440 --> 01:19:37.120
We will have a hosted version of HDB.


01:19:37.120 --> 01:19:38.520
- HDB is a service, yeah.


01:19:38.520 --> 01:19:39.360
- Absolutely.


01:19:39.360 --> 01:19:40.880
And this is how most database companies


01:19:40.880 --> 01:19:42.120
make money these days.


01:19:42.120 --> 01:19:44.320
It's not anymore about enterprise version


01:19:44.320 --> 01:19:45.840
of your database so much.


01:19:45.840 --> 01:19:48.820
It is about, hey, can you run this database


01:19:48.820 --> 01:19:50.240
for us in a private cloud?


01:19:50.240 --> 01:19:52.080
- Back it up, scale it, give us all that.


01:19:52.080 --> 01:19:52.920
- Exactly.


01:19:52.920 --> 01:19:53.740
- Magic.


01:19:53.740 --> 01:19:55.540
- We're also actively working on that.


01:19:55.540 --> 01:19:57.180
Although you can run as you'd be right now


01:19:57.180 --> 01:20:01.180
on top of Aurora Postgres, RDS Postgres and Google Cloud.


01:20:01.180 --> 01:20:02.220
We have guides for that.


01:20:02.220 --> 01:20:04.940
So if you need to deploy your HDB application,


01:20:04.940 --> 01:20:06.380
we have your back,


01:20:06.380 --> 01:20:11.380
but we'll have this like native proper cloud version of HDB


01:20:11.380 --> 01:20:13.540
with which you will be able to just put like


01:20:13.540 --> 01:20:14.660
with one terminal command,


01:20:14.660 --> 01:20:18.140
you will be able to bootstrap a cloud database for yourself.


01:20:18.140 --> 01:20:19.260
It's gonna be amazing.


01:20:19.260 --> 01:20:20.340
- All right, fantastic.


01:20:20.340 --> 01:20:21.540
Thanks, Yuri.


01:20:21.540 --> 01:20:22.420
- Thank you.


01:20:22.420 --> 01:20:23.420
- Yeah, bye.

