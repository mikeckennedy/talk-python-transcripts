WEBVTT

00:00:00.001 --> 00:00:02.200
- Hello, hello.

00:00:02.200 --> 00:00:05.120
- Hello, how are you?

00:00:05.120 --> 00:00:06.300
- I'm doing well.

00:00:06.300 --> 00:00:09.240
So awesome to have you here on Talk Python

00:00:09.240 --> 00:00:12.220
and talking academics.

00:00:12.220 --> 00:00:14.060
I didn't tell you before we hit record,

00:00:14.060 --> 00:00:16.560
but I spent a long time at universities

00:00:16.560 --> 00:00:17.760
and I just love them.

00:00:17.760 --> 00:00:19.280
They're such cool places

00:00:19.280 --> 00:00:21.360
and it's gonna be really fun to get a look inside

00:00:21.360 --> 00:00:24.260
how Python's being used there.

00:00:24.260 --> 00:00:26.160
- Yeah, well, thank you so much for having me.

00:00:26.160 --> 00:00:28.420
And yes, I too love universities.

00:00:28.420 --> 00:00:31.080
It's kind of like all the coolest parts of humanity

00:00:31.080 --> 00:00:34.220
just kind of intermixing in one place.

00:00:34.220 --> 00:00:37.840
So yeah, I'd love to kind of peel back the curtain on how.

00:00:37.840 --> 00:00:39.440
- Yeah, so we're gonna talk about how,

00:00:39.440 --> 00:00:41.960
yeah, yeah, we're gonna talk about how you

00:00:41.960 --> 00:00:45.240
and your colleagues use Python and data science

00:00:45.240 --> 00:00:49.080
inside of your neurology research lab.

00:00:49.080 --> 00:00:50.400
But before we dive into that,

00:00:50.400 --> 00:00:52.400
let's just get a bit of background on yourself.

00:00:52.400 --> 00:00:53.960
Who are you?

00:00:53.960 --> 00:00:55.440
How did you get into Python?

00:00:55.440 --> 00:00:56.280
All those things.

00:00:56.280 --> 00:00:57.860
- Yeah, absolutely.

00:00:57.860 --> 00:00:59.160
So I'm Keelen Cooper.

00:00:59.160 --> 00:01:01.960
I'm a neuroscientist at the University of California,

00:01:01.960 --> 00:01:04.160
Irvine, so Southern California,

00:01:04.160 --> 00:01:05.880
about 15 minutes from the beach

00:01:05.880 --> 00:01:07.940
and an hour from the mountains.

00:01:07.940 --> 00:01:11.360
But I'm originally from the middle of nowhere, Indiana.

00:01:11.360 --> 00:01:17.660
And I started playing with computers and code

00:01:17.660 --> 00:01:20.080
when I was young, so like middle school-ish,

00:01:20.080 --> 00:01:23.280
just ripping apart computers and seeing what was in them

00:01:23.280 --> 00:01:25.400
and then trying to put them back together

00:01:25.400 --> 00:01:27.900
and feeling bad when they didn't work right after.

00:01:27.900 --> 00:01:30.840
And then the typical, you know,

00:01:30.840 --> 00:01:33.020
tweaking the software when you don't like what it does

00:01:33.020 --> 00:01:34.980
until you make it work.

00:01:34.980 --> 00:01:38.140
And then probably my senior year of high school

00:01:38.140 --> 00:01:41.020
is when I started teaching myself Python.

00:01:41.020 --> 00:01:42.500
And it was because we had to do some,

00:01:42.500 --> 00:01:44.580
for some government class, actually.

00:01:44.580 --> 00:01:46.180
- Oh, wow, okay.

00:01:46.180 --> 00:01:48.080
- And we had to learn,

00:01:48.080 --> 00:01:50.120
we were learning about the stock market.

00:01:50.120 --> 00:01:52.440
And every day you'd have to spend like 15 minutes

00:01:52.440 --> 00:01:54.260
going to like some stock website

00:01:54.260 --> 00:01:57.180
and like filling out your fake stocks.

00:01:57.180 --> 00:01:59.420
And so I wrote a really small Python script

00:01:59.420 --> 00:02:02.460
that would just pull the data from the website

00:02:02.460 --> 00:02:04.980
and populate like an Excel spreadsheet.

00:02:04.980 --> 00:02:06.340
And so every day the kids in the class

00:02:06.340 --> 00:02:09.620
were just like going through and like spending 15, 20 minutes

00:02:09.620 --> 00:02:13.100
by hand writing it down, and I would just sit there and-

00:02:13.100 --> 00:02:13.940
- That's awesome.

00:02:13.940 --> 00:02:14.780
- Wait.

00:02:14.780 --> 00:02:15.600
(Irvine laughs)

00:02:15.600 --> 00:02:17.140
And so that was kind of the first time I was like,

00:02:17.140 --> 00:02:20.200
wow, this whole automation thing is pretty sweet.

00:02:21.820 --> 00:02:23.860
And from there, Python just kind of,

00:02:23.860 --> 00:02:25.860
I caught the bug pretty early.

00:02:25.860 --> 00:02:28.300
Python was definitely the way to go.

00:02:28.300 --> 00:02:29.140
- Yeah.

00:02:29.140 --> 00:02:31.140
Was Python your first programming language?

00:02:31.140 --> 00:02:35.540
- I mean, first programming language

00:02:35.540 --> 00:02:37.260
was the Windows registry

00:02:37.260 --> 00:02:39.860
and trying to undo all of the mistakes

00:02:39.860 --> 00:02:41.460
that the operating system.

00:02:41.460 --> 00:02:42.300
But it was my first-

00:02:42.300 --> 00:02:43.220
- It's been a while.

00:02:43.220 --> 00:02:45.340
Yeah, it's been a while since I've been

00:02:45.340 --> 00:02:48.620
in the Windows registry, but good old Regedit.

00:02:48.620 --> 00:02:51.000
- I switched to Linux pretty quick.

00:02:51.840 --> 00:02:53.520
And yeah.

00:02:53.520 --> 00:02:54.760
- Are you still on Linux?

00:02:54.760 --> 00:02:57.840
- Mostly, my desktops are all Linux.

00:02:57.840 --> 00:02:59.740
My servers are obviously all Linux.

00:02:59.740 --> 00:03:02.280
I like Mac for a laptop just 'cause,

00:03:02.280 --> 00:03:06.800
you know, Linux has this thing where you tinker with it.

00:03:06.800 --> 00:03:08.820
And so then any small task you wanna do,

00:03:08.820 --> 00:03:11.200
you end up like rewriting some deep script

00:03:11.200 --> 00:03:12.240
in the operating system.

00:03:12.240 --> 00:03:13.580
And like two hours later, you're like,

00:03:13.580 --> 00:03:15.480
what was that small thing I was trying to do again?

00:03:15.480 --> 00:03:16.680
- Yeah, exactly.

00:03:16.680 --> 00:03:17.520
I got distracted.

00:03:17.520 --> 00:03:20.960
I was rewriting something in there and off we go, yeah.

00:03:20.960 --> 00:03:23.280
- Yeah, so Macs are nice 'cause you still have

00:03:23.280 --> 00:03:26.200
all the same Unix-like properties that are great,

00:03:26.200 --> 00:03:29.240
but you know, you pay a price for reliability,

00:03:29.240 --> 00:03:30.960
but it's pretty, pretty-

00:03:30.960 --> 00:03:32.880
- Yeah, you just sell a bit of your soul out,

00:03:32.880 --> 00:03:34.440
but boy, is that UI nice.

00:03:34.440 --> 00:03:37.440
And those little menu bar apps are handy.

00:03:37.440 --> 00:03:38.280
You know, I was-

00:03:38.280 --> 00:03:39.120
- It's a little thing.

00:03:39.120 --> 00:03:39.960
- That's right.

00:03:39.960 --> 00:03:44.960
I was been playing with running Ubuntu on my Mac M2 Pro,

00:03:46.640 --> 00:03:51.040
which it runs great, but it's an ARM version of Mac,

00:03:51.040 --> 00:03:53.200
or of Linux rather, well, both really.

00:03:53.200 --> 00:03:58.200
But boy, is there a limited supply of applications

00:03:58.200 --> 00:04:00.640
for an ARM Linux distribution?

00:04:00.640 --> 00:04:01.480
- Linux.

00:04:01.480 --> 00:04:02.680
- Let me tell you.

00:04:02.680 --> 00:04:06.500
But like just download the Debian package.

00:04:06.500 --> 00:04:08.280
Yeah, just download the Debian package.

00:04:08.280 --> 00:04:10.360
You just install it, like wrong platform,

00:04:10.360 --> 00:04:13.000
like again, over half.

00:04:13.000 --> 00:04:15.440
But yeah, I think it will change as,

00:04:15.440 --> 00:04:17.400
I think ARM's gonna start to take over Windows

00:04:17.400 --> 00:04:18.480
a little bit as well.

00:04:18.480 --> 00:04:21.840
And obviously the Mac world is basically transitioning.

00:04:21.840 --> 00:04:25.320
So anyone who has a Mac, yeah.

00:04:25.320 --> 00:04:28.920
- I think it's Qualcomm that just kind of started hinting

00:04:28.920 --> 00:04:31.880
that they were gonna try and really heavily compete

00:04:31.880 --> 00:04:36.880
with the M line of processors and have some pretty good specs.

00:04:36.880 --> 00:04:38.400
- Yeah, it'll be good.

00:04:38.400 --> 00:04:42.240
- I have an M3 and it's, it's pretty nice.

00:04:42.240 --> 00:04:43.840
- It is, it is really nice.

00:04:43.840 --> 00:04:46.160
And like I said, I'd like to run more stuff on it,

00:04:46.160 --> 00:04:51.160
but you know, it's still kind of Intel or x86 stuff

00:04:51.160 --> 00:04:53.320
for Linux and Windows.

00:04:53.320 --> 00:04:55.640
So it's a little hard to work with that,

00:04:55.640 --> 00:04:56.800
but still super fun.

00:04:56.800 --> 00:05:00.520
That's a long way to say it's a very long time.

00:05:00.520 --> 00:05:01.360
- Oh yes.

00:05:01.360 --> 00:05:02.200
- I've been a reg at it.

00:05:02.200 --> 00:05:03.020
(laughs)

00:05:03.020 --> 00:05:06.280
It sounds like you as well being not naming Windows

00:05:06.280 --> 00:05:07.120
too much.

00:05:07.120 --> 00:05:08.880
- Yeah, yeah, no, I, yeah.

00:05:08.880 --> 00:05:10.360
I'm so bad at Windows now.

00:05:10.360 --> 00:05:13.160
Like when I'm helping people with Python or something else

00:05:13.160 --> 00:05:14.320
and they show me their computer,

00:05:14.320 --> 00:05:18.320
there's always that like 10 minute learning curve of,

00:05:18.320 --> 00:05:22.600
okay, how do I do anything basic on this machine?

00:05:22.600 --> 00:05:25.880
Or even like the keyboard shortcuts you get so accustomed

00:05:25.880 --> 00:05:28.320
to when people don't have any of those little things

00:05:28.320 --> 00:05:30.480
that you're just like, how do I?

00:05:30.480 --> 00:05:31.320
- Honestly, that's it.

00:05:31.320 --> 00:05:33.080
- How do I select everything?

00:05:33.080 --> 00:05:34.720
- Yes, that is it.

00:05:34.720 --> 00:05:37.560
Like I did professional software development on Windows

00:05:37.560 --> 00:05:38.460
for a long, long time.

00:05:38.460 --> 00:05:40.000
I even wrote a bunch of Windows apps.

00:05:40.000 --> 00:05:41.320
It was great.

00:05:41.320 --> 00:05:44.320
But going back and forth too quickly that or Linux,

00:05:44.320 --> 00:05:46.480
like just the hotkeys, I just get broken.

00:05:46.480 --> 00:05:48.400
Not just on Windows.

00:05:48.400 --> 00:05:49.600
Also when I come back to Mac,

00:05:49.600 --> 00:05:51.440
like I'm just completely out of sorts.

00:05:51.440 --> 00:05:54.920
So yeah, it's fun.

00:05:54.920 --> 00:05:58.760
All right, well, let's talk academics and Python

00:05:58.760 --> 00:06:05.280
from a probably a OS, mostly agnostic perspective.

00:06:05.280 --> 00:06:08.580
But yeah, just give us a sense of the kind of research

00:06:08.580 --> 00:06:10.120
you do, what is your field?

00:06:10.120 --> 00:06:11.000
What do you study?

00:06:11.000 --> 00:06:11.840
Those kinds of things.

00:06:11.840 --> 00:06:14.400
So people get a sense of like, you know.

00:06:14.400 --> 00:06:16.120
- Why am I talking about this?

00:06:16.120 --> 00:06:17.440
- Where you're coming from as you talk

00:06:17.440 --> 00:06:19.000
about doing all these things.

00:06:19.000 --> 00:06:24.000
- Yeah, so the core of my work is pure neuroscience.

00:06:24.000 --> 00:06:29.280
So basic science, what we do mainly in the lab

00:06:29.280 --> 00:06:31.720
is we take really tiny wires.

00:06:31.720 --> 00:06:33.880
So they're like a fifth of the size of the human hair.

00:06:33.880 --> 00:06:36.000
And now we're using something called silicon probes,

00:06:36.000 --> 00:06:38.240
which are, they're manufactured the same way

00:06:38.240 --> 00:06:41.400
that a computer chips are manufactured on silicon.

00:06:41.400 --> 00:06:42.240
- Wow.

00:06:42.240 --> 00:06:44.200
- It's using photolithography.

00:06:44.200 --> 00:06:46.080
And so you have these really tiny--

00:06:46.080 --> 00:06:46.920
- You get a higher density that way,

00:06:46.920 --> 00:06:48.680
do you get like a bunch of little sensors

00:06:48.680 --> 00:06:50.560
on one attachment point or something?

00:06:50.560 --> 00:06:51.400
Okay.

00:06:51.400 --> 00:06:53.080
- So we used to build these little drives.

00:06:53.080 --> 00:06:55.440
I used to have one here, but I got rid of it.

00:06:55.440 --> 00:06:56.560
Little drives by hand.

00:06:56.560 --> 00:07:01.560
So you would just feed the wires in with the forceps.

00:07:01.560 --> 00:07:05.520
And so you'd get maybe 64 or 128 at most,

00:07:05.520 --> 00:07:07.280
depending on how much time you wanna sit there

00:07:07.280 --> 00:07:09.400
and feed the wires in.

00:07:09.400 --> 00:07:11.160
But now you can just get the manufactured.

00:07:11.160 --> 00:07:15.120
You pay a lot more, but you get twice, three times the sites.

00:07:15.120 --> 00:07:18.680
And the whole point is the more sites you have,

00:07:18.680 --> 00:07:22.920
the more neurons you can actually record from in the brain.

00:07:22.920 --> 00:07:25.440
- Yeah, you're not just saying this part of the brain lit up,

00:07:25.440 --> 00:07:26.960
but you could have a much better picture, right?

00:07:26.960 --> 00:07:31.040
- Yeah, yeah, so the constituent part of your brain

00:07:31.040 --> 00:07:31.920
is the neuron.

00:07:33.120 --> 00:07:38.040
And so of the millions and billions of neurons,

00:07:38.040 --> 00:07:40.520
depending on the species you're recording from,

00:07:40.520 --> 00:07:43.400
we can record maybe a few hundred of them,

00:07:43.400 --> 00:07:45.560
but that's usually sufficient to actually,

00:07:45.560 --> 00:07:47.440
in the specific region you study,

00:07:47.440 --> 00:07:49.000
and I can talk about that more,

00:07:49.000 --> 00:07:52.440
so to discern some sort of information from it.

00:07:52.440 --> 00:07:54.680
So really the data type we really care about

00:07:54.680 --> 00:07:57.240
is this tiny little electrical voltages

00:07:57.240 --> 00:07:59.120
that tell you what different neurons

00:07:59.120 --> 00:08:00.680
in the brain are talking about.

00:08:02.680 --> 00:08:04.680
And so you put the wires in,

00:08:04.680 --> 00:08:07.760
you record the conversations of a bunch of neurons,

00:08:07.760 --> 00:08:11.600
and particularly we're interested in two brain regions

00:08:11.600 --> 00:08:15.760
that are critical for memory, learning, and decision-making.

00:08:15.760 --> 00:08:17.040
And this is the hippocampus,

00:08:17.040 --> 00:08:19.240
which in humans is about the size of your pinky

00:08:19.240 --> 00:08:21.920
and a few inches in from your ear,

00:08:21.920 --> 00:08:23.360
and the prefrontal cortex,

00:08:23.360 --> 00:08:25.840
which most people know about right behind your forehead,

00:08:25.840 --> 00:08:28.000
important for learning, decision-making,

00:08:28.000 --> 00:08:30.000
and all those sorts of things.

00:08:30.000 --> 00:08:30.840
- Yeah.

00:08:30.840 --> 00:08:32.440
- So that's the core of my work,

00:08:32.440 --> 00:08:36.240
is I'm in the lab doing the actual data collection

00:08:36.240 --> 00:08:38.640
and building equipment to actually do that.

00:08:38.640 --> 00:08:40.440
But once you have all of that data,

00:08:40.440 --> 00:08:43.160
and the data keeps growing like most other fields,

00:08:43.160 --> 00:08:47.480
you gotta do a lot of pre-processing, which takes Python,

00:08:47.480 --> 00:08:49.520
you gotta do a lot of post-processing,

00:08:49.520 --> 00:08:51.680
which takes a lot of Python.

00:08:51.680 --> 00:08:54.320
And also we do something called neural decoding.

00:08:54.320 --> 00:08:57.680
So not only do we just like say descriptively

00:08:57.680 --> 00:08:59.320
what are these neurons doing,

00:08:59.320 --> 00:09:00.840
but we can go one step further and say,

00:09:01.320 --> 00:09:06.320
what actual information are these cells representing?

00:09:06.320 --> 00:09:12.080
So in the brain, we can kind of say,

00:09:12.080 --> 00:09:17.960
this is kind of the fundamental kind of information transfer

00:09:17.960 --> 00:09:22.520
and how information is manipulated in the brain

00:09:22.520 --> 00:09:25.480
and how it ships information from the environment

00:09:25.480 --> 00:09:28.960
into memory and how it uses that to make a decision.

00:09:28.960 --> 00:09:30.680
All of those kinds of things we can use.

00:09:30.680 --> 00:09:34.440
So we can do a lot of fancy modeling and statistics

00:09:34.440 --> 00:09:37.520
and more recently deep learning and those sorts of things.

00:09:37.520 --> 00:09:38.360
- Yeah, yeah.

00:09:38.360 --> 00:09:41.320
We'll have to come back to deep learning later.

00:09:41.320 --> 00:09:42.160
That'll be fun.

00:09:42.160 --> 00:09:43.000
- Yeah.

00:09:43.000 --> 00:09:43.800
(laughing)

00:09:43.800 --> 00:09:45.680
- Well, given your background.

00:09:45.680 --> 00:09:49.640
So for this hardware, do you write the software

00:09:49.640 --> 00:09:52.000
that actually talks directly to the hardware,

00:09:52.000 --> 00:09:54.120
or is there something that just records it

00:09:54.120 --> 00:09:56.480
and you grab some sort of custom file format

00:09:56.480 --> 00:09:57.800
and run with it?

00:09:57.800 --> 00:09:58.760
- Yeah, more recently.

00:09:59.160 --> 00:10:01.120
On the lab.

00:10:01.120 --> 00:10:04.640
So as time goes on, there's more and more companies

00:10:04.640 --> 00:10:06.680
that you can just buy off the shelf

00:10:06.680 --> 00:10:09.280
kind of recording platforms,

00:10:09.280 --> 00:10:12.960
mostly for the electrical engineering people.

00:10:12.960 --> 00:10:14.800
It's kind of like an audio amplifier

00:10:14.800 --> 00:10:16.880
'cause you're recording at millivolts in the brain.

00:10:16.880 --> 00:10:19.120
So you have to amplify it, write it to,

00:10:19.120 --> 00:10:22.480
if you're plugged in with a wire, write it to the computer.

00:10:22.480 --> 00:10:25.480
So all that takes software in various forms.

00:10:25.480 --> 00:10:28.600
And then we do a lot of animal research.

00:10:28.600 --> 00:10:32.960
So the tasks that the animals do

00:10:32.960 --> 00:10:36.360
are pretty much all automated.

00:10:36.360 --> 00:10:40.360
But recently in the lab, we've kind of had this resurgence

00:10:40.360 --> 00:10:42.320
of like developing kind of novel hardware

00:10:42.320 --> 00:10:44.600
and a lot of automation of behavior.

00:10:44.600 --> 00:10:48.600
So I've kind of rewritten most of our entire

00:10:48.600 --> 00:10:50.840
behavioral stacks, which is a lot of just,

00:10:50.840 --> 00:10:53.280
so microcontroller programming,

00:10:53.280 --> 00:10:55.720
which not a lot of that's in Python.

00:10:55.720 --> 00:10:57.560
A lot of that's just kind of like C++

00:10:57.560 --> 00:10:59.360
and those sorts of things.

00:10:59.360 --> 00:11:01.720
But we have cameras all over.

00:11:01.720 --> 00:11:03.480
So I wrote this kind of like camera server

00:11:03.480 --> 00:11:06.320
that streams all of the camera footage

00:11:06.320 --> 00:11:08.480
from a bunch of automated boxes

00:11:08.480 --> 00:11:11.960
to some like central server

00:11:11.960 --> 00:11:14.280
that just collects all of that data.

00:11:14.280 --> 00:11:17.320
So yeah, a lot of the behavioral stuff nowadays,

00:11:17.320 --> 00:11:19.080
we're just building in-house

00:11:19.080 --> 00:11:22.200
to collect all of the behavior data.

00:11:22.200 --> 00:11:24.760
The EFS stuff is now,

00:11:24.760 --> 00:11:27.240
especially because we're doing something

00:11:27.240 --> 00:11:28.240
called wireless recording.

00:11:28.240 --> 00:11:30.480
So instead of just having a wire plugged into the head,

00:11:30.480 --> 00:11:33.640
it just writes it to like an SD card or Bluetooth.

00:11:33.640 --> 00:11:37.160
That's just kind of all on chip.

00:11:37.160 --> 00:11:38.000
- Yeah.

00:11:38.000 --> 00:11:40.640
- And so it's just whatever the microcontroller language

00:11:40.640 --> 00:11:42.200
of the chip needs.

00:11:42.200 --> 00:11:44.440
- That's wild.

00:11:44.440 --> 00:11:51.000
I think it's surprising how much software

00:11:51.000 --> 00:11:52.920
and even hardware,

00:11:52.920 --> 00:11:54.720
but definitely software is involved

00:11:54.720 --> 00:11:58.800
for something that doesn't sound like a software discipline.

00:11:58.800 --> 00:12:01.000
- Yeah.

00:12:01.000 --> 00:12:02.680
- You wouldn't think of what you guys are doing

00:12:02.680 --> 00:12:05.760
as inherently almost like a software team,

00:12:05.760 --> 00:12:08.360
but there's a lot of software there.

00:12:08.360 --> 00:12:09.200
- Absolutely.

00:12:09.200 --> 00:12:10.760
And it's growing.

00:12:10.760 --> 00:12:14.320
So it used to be like 10, 20 years ago,

00:12:14.320 --> 00:12:15.840
more biology, I'd say,

00:12:15.840 --> 00:12:17.200
like more wet lab stuff.

00:12:17.200 --> 00:12:21.480
But 90% of what I do as kind of a neurobiologist

00:12:21.480 --> 00:12:24.280
is really just engineering style things.

00:12:24.280 --> 00:12:27.320
Like I'm more recently designing PCBs

00:12:27.320 --> 00:12:30.160
and I'm in the shop a lot,

00:12:30.160 --> 00:12:33.040
just like with saws and hammers and drills

00:12:33.040 --> 00:12:35.680
and like actually physically building things.

00:12:35.680 --> 00:12:37.480
And obviously a lot of code.

00:12:37.480 --> 00:12:39.840
And the coding part is becoming bigger and bigger

00:12:39.840 --> 00:12:42.480
to the point where in the field,

00:12:42.480 --> 00:12:44.000
I always say that the neuroscience

00:12:44.000 --> 00:12:48.120
is like about three decades behind astrophysics

00:12:48.120 --> 00:12:50.280
'cause all the problems that like neuroscientists

00:12:50.280 --> 00:12:51.960
like say we're facing now as a field,

00:12:51.960 --> 00:12:53.800
they have like three decades prior

00:12:53.800 --> 00:12:57.880
where in astrophysics, they're like,

00:12:57.880 --> 00:12:59.400
well, or in neuroscience, we're like,

00:12:59.400 --> 00:13:00.920
what do we do with all this data?

00:13:00.920 --> 00:13:01.760
This is weak.

00:13:01.760 --> 00:13:04.760
I mean, I'm collecting a hundred gigabytes an hour,

00:13:04.760 --> 00:13:06.360
if not more.

00:13:06.360 --> 00:13:07.200
What do we do?

00:13:07.200 --> 00:13:08.640
- That is a lot.

00:13:08.640 --> 00:13:11.600
- Yeah, but relative to like some of those big telescopes

00:13:11.600 --> 00:13:15.240
that are collecting like almost petabyte scale.

00:13:15.240 --> 00:13:16.680
- Yeah, yeah.

00:13:16.680 --> 00:13:18.080
I would say both ends of physics,

00:13:18.080 --> 00:13:20.560
like the very, very extreme ends of physics.

00:13:20.560 --> 00:13:22.920
So astrophysics, the very large

00:13:22.920 --> 00:13:24.640
and then particle physics, right?

00:13:24.640 --> 00:13:27.480
At CERN as well, they've got insane amounts of data.

00:13:27.480 --> 00:13:28.600
Yeah.

00:13:28.600 --> 00:13:29.720
- And that's what we're starting to see,

00:13:29.720 --> 00:13:30.800
I think in neuroscience too,

00:13:30.800 --> 00:13:32.720
is that kind of division of like,

00:13:32.720 --> 00:13:36.280
because the scale of data collection is so big,

00:13:36.280 --> 00:13:40.040
you're starting to need not just a single lab, but teams.

00:13:40.040 --> 00:13:42.120
So we have a few institutes now

00:13:42.120 --> 00:13:44.560
that are just pumping out terabytes of data.

00:13:44.560 --> 00:13:47.520
And so you start to see that division

00:13:47.520 --> 00:13:50.640
between the neuroscientists who are really in the lab,

00:13:50.640 --> 00:13:54.680
hands-on with actual neural tissue or the recording device,

00:13:54.680 --> 00:13:58.600
and the neuroscientists who are just take the data

00:13:58.600 --> 00:14:00.440
and analyze it and develop new models

00:14:00.440 --> 00:14:02.440
and statistical models.

00:14:02.440 --> 00:14:05.960
And also theory, there's always a dearth of theory

00:14:05.960 --> 00:14:08.800
in neuroscience, but the computational modeling

00:14:08.800 --> 00:14:10.920
is certainly getting a lot bigger

00:14:10.920 --> 00:14:13.520
within the last few decades as well,

00:14:13.520 --> 00:14:15.520
where people's entire job is just,

00:14:15.520 --> 00:14:18.960
how do we model some of these things in code?

00:14:18.960 --> 00:14:22.640
- Well, do you see,

00:14:22.640 --> 00:14:27.480
you probably run into different research groups,

00:14:27.480 --> 00:14:31.000
different teams that have different levels of sophistication

00:14:31.000 --> 00:14:34.800
from a software side, and do you see like a productivity

00:14:34.800 --> 00:14:38.160
or a quality difference jump out from like the kind of work

00:14:38.160 --> 00:14:41.000
or the velocity of work that people are doing there?

00:14:41.000 --> 00:14:42.160
- Absolutely.

00:14:42.200 --> 00:14:44.600
And it makes me almost like a,

00:14:44.600 --> 00:14:48.840
so a lot, I mean, it's a huge range.

00:14:48.840 --> 00:14:51.000
There are like very sophisticated labs.

00:14:51.000 --> 00:14:52.880
And usually those are the labs that have kind of

00:14:52.880 --> 00:14:55.600
just a pure software person on the team

00:14:55.600 --> 00:14:58.600
or people who are very inclined towards software,

00:14:58.600 --> 00:15:00.800
all the way to, and it makes me so sad

00:15:00.800 --> 00:15:03.000
when people are spending like weeks in a spreadsheet,

00:15:03.000 --> 00:15:05.800
just manually doing things by hand.

00:15:05.800 --> 00:15:06.880
- Yeah, I know.

00:15:06.880 --> 00:15:09.160
- You could do this in five minutes in Python,

00:15:09.160 --> 00:15:12.400
or like pandas, you could just load it and take it.

00:15:12.400 --> 00:15:14.480
- And not only could you do it faster,

00:15:14.480 --> 00:15:16.920
you could do it without any errors.

00:15:16.920 --> 00:15:17.760
- Yeah, more of a lot.

00:15:17.760 --> 00:15:20.800
- Right, none of those like, oh, I misread it

00:15:20.800 --> 00:15:25.800
and I shifted off by a cell, or I typed in,

00:15:25.800 --> 00:15:26.920
I missed something, right?

00:15:26.920 --> 00:15:30.040
'Cause the code just reads what's there, yeah.

00:15:30.040 --> 00:15:34.040
- Yeah, and so I think that a lot of,

00:15:34.040 --> 00:15:39.080
a lot of like graduate programs are starting to

00:15:39.080 --> 00:15:42.680
wake up to this fact that it's gonna be

00:15:42.680 --> 00:15:44.680
almost impossible to do any science

00:15:44.680 --> 00:15:47.400
without some degree of proficiency in coding.

00:15:47.400 --> 00:15:54.200
And I think a lot of, say grad students and postdocs

00:15:54.200 --> 00:15:57.120
and so on, when they actually sit down

00:15:57.120 --> 00:15:58.640
and try and analyze their data,

00:15:58.640 --> 00:16:00.040
whether there's just an Excel

00:16:00.040 --> 00:16:02.660
or they need to write a little Python script,

00:16:02.660 --> 00:16:04.400
that's kind of their first introduction is,

00:16:04.400 --> 00:16:07.880
oh, I have this data, I need to do something with it.

00:16:07.880 --> 00:16:10.680
I'm gonna Google exactly how do I read in this data

00:16:10.680 --> 00:16:13.880
or how do I do a T-test in Python

00:16:13.880 --> 00:16:16.680
or how do I plot something in Matplotlib?

00:16:16.680 --> 00:16:19.320
And that's kind of the level that they start getting into

00:16:19.320 --> 00:16:21.200
out of necessity.

00:16:21.200 --> 00:16:23.080
But the sophistication and the speed,

00:16:23.080 --> 00:16:25.880
because they're usually just teaching themselves,

00:16:25.880 --> 00:16:27.800
that's most of academia, it's just,

00:16:27.800 --> 00:16:30.800
you have a problem, spend a few days Googling

00:16:30.800 --> 00:16:33.120
and reading books until you find it.

00:16:33.120 --> 00:16:36.280
- And once it works, you can kind of just leave it.

00:16:36.280 --> 00:16:37.120
- Exactly.

00:16:37.120 --> 00:16:38.440
- You don't have to clean it up or anything, right?

00:16:38.440 --> 00:16:39.480
Yeah, okay.

00:16:39.480 --> 00:16:42.040
- Which results in a lot of, I mean,

00:16:42.040 --> 00:16:45.480
the progress of science doesn't go away,

00:16:45.480 --> 00:16:48.680
but the code is not robust.

00:16:48.680 --> 00:16:49.960
And so that's why you see things,

00:16:49.960 --> 00:16:52.080
especially in other fields of psychology

00:16:52.080 --> 00:16:53.960
and such like replication crises

00:16:53.960 --> 00:16:55.520
and people have done meta-analysis

00:16:55.520 --> 00:16:58.120
of running the same software stack

00:16:58.120 --> 00:17:00.320
on like 12 different data sets

00:17:00.320 --> 00:17:02.560
and you get different results.

00:17:02.560 --> 00:17:03.880
And so you start to kind of see

00:17:03.880 --> 00:17:08.880
that shaky foundation starting to bleed into the,

00:17:08.880 --> 00:17:11.200
like you said, the reliability.

00:17:11.200 --> 00:17:12.560
- Starting to have consequences,

00:17:12.560 --> 00:17:15.040
not just it's more work or something.

00:17:15.040 --> 00:17:16.560
- Yeah, exactly.

00:17:16.560 --> 00:17:17.400
- Yeah.

00:17:17.400 --> 00:17:21.440
Maybe we could start a bit by just talking

00:17:21.440 --> 00:17:23.040
about maybe the history,

00:17:23.040 --> 00:17:24.200
you know, diving into this a little bit more,

00:17:24.200 --> 00:17:29.200
just the history of programming in neuroscience.

00:17:29.200 --> 00:17:32.840
Now, I wasn't in neuroscience in any way,

00:17:32.840 --> 00:17:36.680
but I worked with a bunch of cognitive scientists

00:17:36.680 --> 00:17:40.680
studying how people solve problems

00:17:40.680 --> 00:17:42.640
and thought about things at a lab

00:17:42.640 --> 00:17:43.680
for one of my first jobs.

00:17:43.680 --> 00:17:46.000
And we studied all through eye tracking.

00:17:46.000 --> 00:17:46.840
- Yeah.

00:17:46.840 --> 00:17:49.040
- Yeah, like not the letter I,

00:17:49.040 --> 00:17:51.080
not the iPhone, but actual eyes.

00:17:51.080 --> 00:17:52.200
And it was fascinating.

00:17:52.200 --> 00:17:53.040
It was tons of data.

00:17:53.040 --> 00:17:53.880
It was really cool.

00:17:53.880 --> 00:17:54.720
And there were, like you described,

00:17:54.720 --> 00:17:56.920
a lot of people who would do sort of Excel stuff

00:17:56.920 --> 00:17:58.920
and they would take the data and they process it.

00:17:58.920 --> 00:18:02.080
And over time we just started to automate these things.

00:18:02.080 --> 00:18:03.680
And their first thought was,

00:18:03.680 --> 00:18:05.600
you're programming me out of a job.

00:18:05.600 --> 00:18:08.800
I'm like, no, no, no.

00:18:08.800 --> 00:18:10.600
This is the crappy part of your job.

00:18:10.600 --> 00:18:12.240
Like you're supposed to analyze the results

00:18:12.240 --> 00:18:14.280
and think about it and plan new stuff.

00:18:14.280 --> 00:18:16.560
And now you can just focus on that.

00:18:16.560 --> 00:18:17.840
Right, right.

00:18:17.840 --> 00:18:20.040
And as the software got better,

00:18:20.040 --> 00:18:22.800
you know, we just tackled bigger problems.

00:18:22.800 --> 00:18:25.720
So, you know, maybe give us a bit of a history

00:18:25.720 --> 00:18:27.880
of on your side.

00:18:27.880 --> 00:18:28.920
- Yeah, yeah.

00:18:28.920 --> 00:18:31.800
So I love the cognitive science part.

00:18:31.800 --> 00:18:35.160
That's my more background is cognitive science.

00:18:35.160 --> 00:18:37.880
I was my undergrad and grew up in science

00:18:37.880 --> 00:18:39.400
in a cognitive science department

00:18:39.400 --> 00:18:41.960
while also doing some wet lab neuroscience stuff.

00:18:41.960 --> 00:18:43.880
So it's fun.

00:18:43.880 --> 00:18:45.520
- Yeah, absolutely.

00:18:45.520 --> 00:18:47.680
Did you start out with like MATLAB and that kind of stuff?

00:18:47.680 --> 00:18:50.480
Is that where they told you you need to be?

00:18:50.480 --> 00:18:51.800
- Exactly, yeah.

00:18:51.800 --> 00:18:57.760
So a lot of, so neuroscience has certainly had,

00:18:57.760 --> 00:18:59.960
at least our branch of neuroscience,

00:18:59.960 --> 00:19:04.960
just because by the nature of recording voltages

00:19:04.960 --> 00:19:08.280
and you need to write to a computer.

00:19:08.280 --> 00:19:11.360
So there has been kind of a long history of,

00:19:11.360 --> 00:19:15.600
for as long as there's been even like punch card computers,

00:19:15.600 --> 00:19:21.200
people have kind of read in the data into the computer

00:19:21.200 --> 00:19:24.120
and done, you know, their statistics on that rather

00:19:24.120 --> 00:19:25.360
than something else.

00:19:25.360 --> 00:19:27.360
I'm just, I'm actually recently writing

00:19:27.360 --> 00:19:30.240
kind of a review article on kind of the history

00:19:30.240 --> 00:19:32.360
of data science and neuroscience.

00:19:32.360 --> 00:19:34.480
And I loved this paper.

00:19:34.480 --> 00:19:39.480
It was from 1938 and they took an EEG spectrum.

00:19:39.480 --> 00:19:46.480
And so EEG is just the continuous time series

00:19:46.480 --> 00:19:47.840
of brain voltage.

00:19:47.840 --> 00:19:49.480
So you're not in the brain recording.

00:19:49.480 --> 00:19:51.200
And this is, I think, from humans.

00:19:51.200 --> 00:19:54.040
And they took something called the Fourier transform,

00:19:54.040 --> 00:19:56.960
which that might not be as up to speed with that

00:19:56.960 --> 00:20:00.840
as you basically just take some oscillating signal

00:20:00.840 --> 00:20:03.200
and you break it down into its constituent parts.

00:20:03.200 --> 00:20:04.480
And most of you have seen it before

00:20:04.480 --> 00:20:06.600
if you've ever seen like an audio spectrogram,

00:20:06.600 --> 00:20:11.600
that's kind of the most notable visualization

00:20:11.600 --> 00:20:14.000
where you can kind of see the high frequencies.

00:20:14.000 --> 00:20:17.320
- Basically it pulls the frequencies out of the signal.

00:20:17.320 --> 00:20:18.160
- Exactly.

00:20:18.160 --> 00:20:19.000
- Yeah.

00:20:19.000 --> 00:20:22.000
- But the way they did this, and this is 1938,

00:20:22.000 --> 00:20:23.320
there's no computers.

00:20:23.320 --> 00:20:28.240
So they actually had a mechanical device

00:20:28.240 --> 00:20:31.520
where they would just take this EEG trace that was on tape

00:20:31.520 --> 00:20:35.000
and they would feed it into this like mechanical machine.

00:20:35.000 --> 00:20:37.600
And it would basically read kind of this black line

00:20:37.600 --> 00:20:38.440
on the tape.

00:20:38.440 --> 00:20:43.120
And so as it would crank the tape around this machine,

00:20:43.120 --> 00:20:44.880
depending on kind of the frequency

00:20:44.880 --> 00:20:46.360
that the line went up and down,

00:20:46.360 --> 00:20:48.240
that would read out the Fourier transform.

00:20:48.240 --> 00:20:49.920
So it was mechanical.

00:20:49.920 --> 00:20:50.760
- Wow.

00:20:50.760 --> 00:20:54.960
- So a lot of those cool devices back in the older days.

00:20:54.960 --> 00:20:56.320
- Yeah, that's impressive.

00:20:56.320 --> 00:21:00.120
- Now you can get that same thing with,

00:21:00.120 --> 00:21:02.200
in MATLAB you just type FFT,

00:21:02.200 --> 00:21:05.720
parenthesis, parenthesis, put your data in the middle

00:21:05.720 --> 00:21:07.880
and you get the same thing in microseconds.

00:21:07.880 --> 00:21:12.480
But neuroscience, at least my field,

00:21:12.480 --> 00:21:16.120
has kind of always had this kind of serendipitous relationship

00:21:16.120 --> 00:21:19.640
with computing generally, coding generally.

00:21:19.640 --> 00:21:22.840
And a lot of the code, I think earlier on

00:21:22.840 --> 00:21:24.600
was kind of was Fortran-ish

00:21:24.600 --> 00:21:26.120
and then it moved towards MATLAB.

00:21:26.120 --> 00:21:28.440
And MATLAB's kind of had its stake in the ground

00:21:28.440 --> 00:21:29.600
for a long time,

00:21:29.600 --> 00:21:33.240
just because that was the first kind of software

00:21:33.240 --> 00:21:37.800
that could really do array manipulations on well.

00:21:37.800 --> 00:21:39.080
And it was kind of a higher level

00:21:39.080 --> 00:21:41.400
than some of the lower level programming.

00:21:41.400 --> 00:21:44.080
So a lot of the older labs have,

00:21:44.080 --> 00:21:45.760
their entire code base and stack

00:21:45.760 --> 00:21:48.920
and analysis software in MATLAB.

00:21:48.920 --> 00:21:53.920
And so it's only been within maybe five to six, seven years,

00:21:53.920 --> 00:21:55.640
probably a bit longer, 10 years,

00:21:55.640 --> 00:21:58.920
that you've really seen Python start to supplant MATLAB

00:21:58.920 --> 00:22:02.760
as kind of the de facto programming language in labs,

00:22:02.760 --> 00:22:04.560
just because of the cost

00:22:04.560 --> 00:22:06.520
of trying to transfer everything over.

00:22:06.520 --> 00:22:10.240
And despite the fact that MATLAB isn't open source

00:22:10.240 --> 00:22:12.040
and it's extremely expensive,

00:22:12.040 --> 00:22:13.640
most universities have licenses.

00:22:13.640 --> 00:22:15.680
And so that kind of facilitates--

00:22:15.680 --> 00:22:16.640
- It's prepaid.

00:22:18.200 --> 00:22:19.600
- In a sense, yeah.

00:22:19.600 --> 00:22:20.440
But it is very expensive.

00:22:20.440 --> 00:22:21.760
- But it's still pretty expensive.

00:22:21.760 --> 00:22:23.600
- Especially if you get those little toolboxes,

00:22:23.600 --> 00:22:25.640
like wavelet decomposition toolbox,

00:22:25.640 --> 00:22:27.840
2000 bucks instead of a pip install.

00:22:27.840 --> 00:22:28.840
- Yeah.

00:22:28.840 --> 00:22:30.800
And again, we do a lot of signal processing.

00:22:30.800 --> 00:22:33.520
And so that's exactly the place you wanna be.

00:22:33.520 --> 00:22:36.480
And like MATLAB usually controls,

00:22:36.480 --> 00:22:40.600
because it has pretty good control over external hardware,

00:22:40.600 --> 00:22:43.200
you can run your behavior, your task,

00:22:43.200 --> 00:22:44.440
kind of in MATLAB codes.

00:22:44.440 --> 00:22:46.720
You can kind of do everything in one language

00:22:46.720 --> 00:22:48.600
as you would like to do in Python.

00:22:48.600 --> 00:22:53.280
But it's starting to kind of go away.

00:22:53.280 --> 00:22:55.280
And I think a lot of that is just because

00:22:55.280 --> 00:22:59.200
the allure of Python, which has so many tools,

00:22:59.200 --> 00:23:02.320
and because it's probably a lot easier to learn

00:23:02.320 --> 00:23:03.840
for most people than MATLAB,

00:23:03.840 --> 00:23:06.760
we're kind of starting to see that switch

00:23:06.760 --> 00:23:10.400
now that there's kind of more to offer, I'd say,

00:23:10.400 --> 00:23:14.560
a lot of scientists than MATLAB.

00:23:14.560 --> 00:23:16.440
- Yeah, you said 10, 12 years ago.

00:23:16.440 --> 00:23:20.520
Yeah, the difference in the external packages

00:23:20.520 --> 00:23:21.800
on PyPI you can get,

00:23:21.800 --> 00:23:26.800
and especially the ones for data science have just exploded.

00:23:26.800 --> 00:23:30.960
The choices and the stuff that's out there,

00:23:30.960 --> 00:23:34.200
it's pretty diverse and it's pretty crazy.

00:23:34.200 --> 00:23:36.800
- The only other one that I think

00:23:36.800 --> 00:23:38.960
is still in pretty strong competition with Python

00:23:38.960 --> 00:23:40.920
from the perspective of,

00:23:40.920 --> 00:23:42.840
we collaborate a lot with like mathematicians

00:23:42.840 --> 00:23:46.240
and statisticians, and R is there.

00:23:46.240 --> 00:23:49.520
Their usual favorite, just because statistics,

00:23:49.520 --> 00:23:51.440
like all the best statistical packages

00:23:51.440 --> 00:23:53.040
are still pretty much in R.

00:23:53.040 --> 00:23:56.520
And so that's where a lot of people live.

00:23:56.520 --> 00:24:00.120
ggplot's pretty good.

00:24:00.120 --> 00:24:03.240
- Yeah, that's interesting.

00:24:03.240 --> 00:24:06.080
It's really focused and it's really good at what it does.

00:24:06.080 --> 00:24:09.040
And one of the things that I think's worth

00:24:09.040 --> 00:24:10.120
just considering it,

00:24:10.120 --> 00:24:13.800
if somebody comes, let's say,

00:24:14.720 --> 00:24:17.600
brand new first year grad student comes into the lab

00:24:17.600 --> 00:24:18.440
and you're like, all right,

00:24:18.440 --> 00:24:19.600
what's your programming experience?

00:24:19.600 --> 00:24:23.120
Like, well, programmed the clock on the VCR.

00:24:23.120 --> 00:24:25.400
Like, okay, we're gonna have to start you somewhere

00:24:25.400 --> 00:24:26.240
or something, right?

00:24:26.240 --> 00:24:31.240
And you could teach them something really specific

00:24:31.240 --> 00:24:36.120
like MATLAB or something along those lines.

00:24:36.120 --> 00:24:38.680
But if they learn something like Julia,

00:24:38.680 --> 00:24:42.120
not like Julia, like Python, not Julia,

00:24:42.120 --> 00:24:47.120
maybe even not really R, but R is closer somewhat,

00:24:47.120 --> 00:24:51.120
is they learn not just a skill for the lab,

00:24:51.120 --> 00:24:54.760
but it's kind of almost any software job

00:24:54.760 --> 00:24:57.800
is potentially within reach with a little bit of,

00:24:57.800 --> 00:24:59.920
you know, learning about that area, right?

00:24:59.920 --> 00:25:02.560
Like if you know Python, you say, I want a job,

00:25:02.560 --> 00:25:05.760
there's a massive set of options out there.

00:25:05.760 --> 00:25:10.680
If you say, I know MATLAB or even Julia,

00:25:10.680 --> 00:25:14.880
it's like, okay, well, here's the few labs

00:25:14.880 --> 00:25:17.280
and the few research areas and the real,

00:25:17.280 --> 00:25:18.960
I just think it's something that-

00:25:18.960 --> 00:25:20.600
- A lot of engineering firms.

00:25:20.600 --> 00:25:23.120
- Yeah, yeah, I'm just thinking that like a lot of,

00:25:23.120 --> 00:25:27.480
a lot of academic folks should consider what happens

00:25:27.480 --> 00:25:32.080
if the student doesn't necessarily become a professor.

00:25:32.080 --> 00:25:32.920
You know what I mean?

00:25:32.920 --> 00:25:34.880
Which actually is a lot of the time, right?

00:25:34.880 --> 00:25:37.200
Or a professional researcher of some sort.

00:25:37.200 --> 00:25:39.480
And that's a really awesome skill to have

00:25:39.480 --> 00:25:41.640
on top of your degree.

00:25:41.640 --> 00:25:43.440
So I think that's just a big win for it.

00:25:43.440 --> 00:25:44.560
Then I'm happy to see that.

00:25:44.560 --> 00:25:47.440
- Yeah, and that literal situation just happened

00:25:47.440 --> 00:25:50.880
where a statistician that we were collaborating

00:25:50.880 --> 00:25:54.600
pretty closely with graduated, brilliant guy,

00:25:54.600 --> 00:25:58.640
and got a job at Microsoft.

00:25:58.640 --> 00:26:01.360
And so we were in a meeting after he was there

00:26:01.360 --> 00:26:03.800
and they were like, what's some advice that you have

00:26:03.800 --> 00:26:06.640
now that you've been, you know, in industry for a while?

00:26:06.640 --> 00:26:09.800
He's like, stop using R, learn Python.

00:26:09.800 --> 00:26:13.200
'Cause everyone here uses Python.

00:26:13.200 --> 00:26:16.000
And it took me a few months to kind of switch

00:26:16.000 --> 00:26:19.280
from the R worldview of, you know,

00:26:19.280 --> 00:26:21.320
caret hyphen to equals.

00:26:21.320 --> 00:26:22.520
- Yeah, yeah, yeah, yeah.

00:26:22.520 --> 00:26:27.520
- To actually, to work and collaborate with everyone

00:26:27.520 --> 00:26:29.960
'cause everyone's just using Python.

00:26:29.960 --> 00:26:30.800
- Yeah, very interesting.

00:26:30.800 --> 00:26:33.360
- From his perspective, and I'm sure it's not unique.

00:26:33.360 --> 00:26:36.600
- No, I'm sure that it's not either.

00:26:36.600 --> 00:26:39.960
I think, yeah, I just think it's not like a religious war.

00:26:39.960 --> 00:26:42.760
It's not like, oh, I think Python is absolutely better

00:26:42.760 --> 00:26:43.920
and you should just not use other stuff.

00:26:43.920 --> 00:26:48.320
I just think it's preparing people for stuff beyond school.

00:26:48.320 --> 00:26:51.160
It's a pretty interesting angle to take.

00:26:51.160 --> 00:26:52.640
- Yeah, yeah.

00:26:52.640 --> 00:26:54.080
And it's not like you can't learn other things.

00:26:54.080 --> 00:26:56.080
I think it's really good to learn other things,

00:26:56.080 --> 00:26:58.520
especially ones that are complimentary,

00:26:58.520 --> 00:27:00.040
where R can be complimentary,

00:27:00.040 --> 00:27:02.640
especially now that they have a lot of the like

00:27:02.640 --> 00:27:05.160
subsystem packages.

00:27:05.160 --> 00:27:09.280
So when I get R code, I usually just write like a sub process.

00:27:09.280 --> 00:27:10.160
I did this recently,

00:27:10.160 --> 00:27:12.560
just wrote like a sub process line to call the R script

00:27:12.560 --> 00:27:14.960
'cause I was too lazy to rewrite it.

00:27:14.960 --> 00:27:15.800
- Yeah, sure.

00:27:15.800 --> 00:27:19.000
- But there's other, like, I don't know,

00:27:19.000 --> 00:27:20.640
like Rust is probably a good one

00:27:20.640 --> 00:27:21.960
to probably try and bring to,

00:27:21.960 --> 00:27:24.920
or like lower level languages like C++.

00:27:24.920 --> 00:27:25.760
- Yeah.

00:27:25.760 --> 00:27:28.480
- If you need them for what you're doing.

00:27:28.480 --> 00:27:30.000
- Yeah, and it sounds like you guys do

00:27:30.000 --> 00:27:32.560
for talking to hardware and stuff like that.

00:27:32.560 --> 00:27:34.240
- Yeah, yeah, occasionally.

00:27:34.240 --> 00:27:37.040
Always there's a lot of things Python can't do.

00:27:37.040 --> 00:27:38.640
- Yeah, for sure.

00:27:38.640 --> 00:27:39.800
- It's really hard.

00:27:39.800 --> 00:27:41.440
- Yeah, break out some MicroPython

00:27:41.440 --> 00:27:44.640
when you gotta get your microcontrollers and stuff.

00:27:44.640 --> 00:27:48.240
So another thing is, I don't know how it's received.

00:27:48.240 --> 00:27:51.400
I know it took a while to kind of really catch on.

00:27:51.400 --> 00:27:54.920
And I think the thing that just broke the final barriers

00:27:54.920 --> 00:27:58.360
for open source being adopted,

00:27:58.360 --> 00:28:02.680
at least in business, was the AI stuff

00:28:02.680 --> 00:28:03.720
and the data science stuff.

00:28:03.720 --> 00:28:05.520
People are like, "Oh, we can't use this open source stuff.

00:28:05.520 --> 00:28:08.360
"We gotta have a SLA and some company we can sue

00:28:08.360 --> 00:28:09.920
"if our code doesn't work right,"

00:28:09.920 --> 00:28:12.520
or whatever, right, something crazy like that.

00:28:12.520 --> 00:28:15.280
And they're like, "But you understand all the AI

00:28:15.280 --> 00:28:16.360
"and all the data science.

00:28:16.360 --> 00:28:18.320
"We have to use this open source stuff."

00:28:18.320 --> 00:28:20.600
Like, all right, fine.

00:28:20.600 --> 00:28:23.360
What's the open source story for you guys?

00:28:24.440 --> 00:28:29.080
- Yeah, so I mean, academia is probably championed

00:28:29.080 --> 00:28:30.680
open source for a really long time,

00:28:30.680 --> 00:28:33.280
just because, I mean, open source back,

00:28:33.280 --> 00:28:34.400
I mean, even when I first started,

00:28:34.400 --> 00:28:36.280
was just if you read a paper

00:28:36.280 --> 00:28:38.900
and someone has some new fancy analysis,

00:28:38.900 --> 00:28:43.480
before it became a bigger push by funding agencies

00:28:43.480 --> 00:28:46.440
to actually post it to GitHub or some repository,

00:28:46.440 --> 00:28:47.880
I mean, you could just email people and be like,

00:28:47.880 --> 00:28:49.040
"Hey, I saw your paper.

00:28:49.040 --> 00:28:50.240
"I want that script,"

00:28:50.240 --> 00:28:52.280
and they would just send you a MATLAB file.

00:28:52.280 --> 00:28:56.520
And it would be just whatever they had written,

00:28:56.520 --> 00:28:57.520
but it was in MATLAB,

00:28:57.520 --> 00:29:00.000
and you'd have to kind of tear it apart yourself,

00:29:00.000 --> 00:29:01.720
and there's little to no documentation.

00:29:01.720 --> 00:29:03.240
You'd be lucky if there's comments,

00:29:03.240 --> 00:29:04.900
and it's spaghetti code.

00:29:04.900 --> 00:29:06.720
But you figured that out,

00:29:06.720 --> 00:29:09.400
and you kind of work backwards and deconstruct it,

00:29:09.400 --> 00:29:11.560
and eventually you kind of have their code.

00:29:11.560 --> 00:29:16.560
So that kind of ethos of just scientists are really good

00:29:16.560 --> 00:29:19.280
by and large of just sharing information

00:29:19.280 --> 00:29:20.280
and helping people out.

00:29:20.320 --> 00:29:22.320
If you have a question, just ask.

00:29:22.320 --> 00:29:24.720
It's kind of always been there.

00:29:24.720 --> 00:29:25.800
At least in our field,

00:29:25.800 --> 00:29:28.280
it's not as competitive as some other ones

00:29:28.280 --> 00:29:29.760
where you're just kind of like racing

00:29:29.760 --> 00:29:31.860
to get the next project out.

00:29:31.860 --> 00:29:34.400
It happens, but rarely.

00:29:34.400 --> 00:29:37.480
But now a lot of funding agencies,

00:29:37.480 --> 00:29:38.720
and just in general,

00:29:38.720 --> 00:29:40.360
people are just excited about,

00:29:40.360 --> 00:29:42.420
when you publish a paper,

00:29:42.420 --> 00:29:45.360
you put a GitHub link in the bottom of the paper,

00:29:45.360 --> 00:29:47.120
and then that links to the repository,

00:29:47.120 --> 00:29:49.800
and maybe it's not been updated in a while,

00:29:49.800 --> 00:29:51.640
but the code's there,

00:29:51.640 --> 00:29:53.520
and you can just take it and grab it.

00:29:53.520 --> 00:29:54.920
- For the reproducibility.

00:29:54.920 --> 00:29:57.120
How about using other things?

00:29:57.120 --> 00:29:59.280
Is there SciPy?

00:29:59.280 --> 00:30:01.320
I know for astronomy, there's Astropy.

00:30:01.320 --> 00:30:03.800
Is there a Neuropy?

00:30:03.800 --> 00:30:05.720
- There's starting to be.

00:30:05.720 --> 00:30:10.400
So it's really still more analysis-dependent

00:30:10.400 --> 00:30:12.280
and pre-process-dependent.

00:30:12.280 --> 00:30:14.320
So there's kind of this,

00:30:14.320 --> 00:30:15.520
it's still the early days

00:30:15.520 --> 00:30:18.140
where there's probably too many formats,

00:30:18.140 --> 00:30:21.560
just because no one can agree on what's the best one.

00:30:21.560 --> 00:30:23.240
So even a lot of the data formats

00:30:23.240 --> 00:30:25.280
are written kind of in Python

00:30:25.280 --> 00:30:26.720
to take whatever data you have

00:30:26.720 --> 00:30:29.360
and reformat it to something shareable.

00:30:29.360 --> 00:30:31.260
There's five or six of them floating around.

00:30:31.260 --> 00:30:34.120
There's probably two that are still duking it out

00:30:34.120 --> 00:30:35.480
to see which one will be the best,

00:30:35.480 --> 00:30:37.120
and probably five years from now,

00:30:37.120 --> 00:30:38.620
there's gonna be a better one.

00:30:38.620 --> 00:30:42.740
So data formats, certainly there's kind of this,

00:30:42.740 --> 00:30:45.840
there's a few that are neck and neck.

00:30:45.840 --> 00:30:47.560
Analysis pipelines, a lot of those

00:30:47.560 --> 00:30:48.600
are still done in-house,

00:30:48.600 --> 00:30:50.880
but there's starting to be a lot more toolkits

00:30:50.880 --> 00:30:52.620
and frameworks and packages.

00:30:52.620 --> 00:30:55.400
There's some really good ones

00:30:55.400 --> 00:30:57.800
that have more documentation written.

00:30:57.800 --> 00:31:00.800
They're on the PyPy repositories,

00:31:00.800 --> 00:31:03.320
so you can just pip install them and you have them.

00:31:03.320 --> 00:31:06.880
The computational neuroscience people are great at this.

00:31:06.880 --> 00:31:09.240
So all the neural simulation software,

00:31:09.240 --> 00:31:13.600
that is all really well-documented, really well-written.

00:31:13.600 --> 00:31:17.480
A lot of good example code and tutorials and so on.

00:31:17.480 --> 00:31:22.680
So yeah, we're starting to see this more robust

00:31:22.680 --> 00:31:29.660
ecosystem where you can just pull things.

00:31:29.660 --> 00:31:32.080
It still just kind of varies.

00:31:32.080 --> 00:31:35.520
There's probably still not one go-to place

00:31:35.520 --> 00:31:38.320
other than the standard data science toolkits.

00:31:38.320 --> 00:31:39.160
- Right, right.

00:31:39.160 --> 00:31:41.200
- If you're using PyPy-- - The pandas and so on.

00:31:41.200 --> 00:31:44.800
- Yeah, NumPy, Matplotlib, Pandas, scikit-learn,

00:31:44.800 --> 00:31:47.500
if you're doing deep learning, PyTorch or TensorFlow,

00:31:47.500 --> 00:31:53.200
all of those still apply to any data science stack.

00:31:53.200 --> 00:31:54.160
- Yeah, of course.

00:31:54.160 --> 00:31:58.160
What's your day-to-day stack look like

00:31:58.160 --> 00:32:00.320
if you're sitting down to do some analysis?

00:32:00.320 --> 00:32:04.720
- Yeah, so like I said, the standard,

00:32:04.720 --> 00:32:08.040
I have a VS Code, kind of like auto-complete,

00:32:08.040 --> 00:32:09.840
where I just write import in,

00:32:09.840 --> 00:32:13.540
and it just NumPy, Matplotlib, Pandas.

00:32:13.540 --> 00:32:15.920
Then I usually delete Pandas

00:32:15.920 --> 00:32:18.540
'cause unless I have a CSV file, I'm not using it.

00:32:18.540 --> 00:32:23.160
So NumPy, Matplotlib, I can probably do 75%

00:32:23.160 --> 00:32:24.540
of the things I wanna do.

00:32:24.540 --> 00:32:29.600
scikit-learn and SciPy, obviously,

00:32:29.600 --> 00:32:31.320
if I'm doing any stats with those things,

00:32:31.320 --> 00:32:33.640
those libraries are my go-to.

00:32:33.640 --> 00:32:35.340
And then over the last few years,

00:32:35.340 --> 00:32:37.100
I kind of just have my own,

00:32:37.100 --> 00:32:38.720
just 'cause you catch yourself

00:32:38.720 --> 00:32:41.320
writing the same functions over and over and over again.

00:32:41.320 --> 00:32:45.040
So just started building my kind of internal framework

00:32:45.040 --> 00:32:46.560
of just things I know I need.

00:32:46.560 --> 00:32:48.680
So if I'm working with LFP data,

00:32:48.680 --> 00:32:50.080
I have all my filters there.

00:32:50.080 --> 00:32:52.640
If I have spike data, I have all my spikes there.

00:32:52.640 --> 00:32:55.420
We do a lot of decoding,

00:32:55.420 --> 00:32:57.620
so developing deep learning algorithms

00:32:57.620 --> 00:32:58.980
to decode neural data.

00:32:58.980 --> 00:33:02.020
All of those are kind of listed there.

00:33:02.020 --> 00:33:06.080
So yeah, I started to understand

00:33:07.200 --> 00:33:09.680
my friends that work in Silicon Valley

00:33:09.680 --> 00:33:11.640
when they're like, "Oh, I'm on internal tools team,

00:33:11.640 --> 00:33:13.600
"internal tools team," and they don't talk about it.

00:33:13.600 --> 00:33:14.840
Like, their-- - Don't make anything?

00:33:14.840 --> 00:33:16.280
Come on, man.

00:33:16.280 --> 00:33:18.520
- Yeah, and then I started realizing,

00:33:18.520 --> 00:33:21.000
dude, internal tools make the difference

00:33:21.000 --> 00:33:23.200
between solving a problem in 10 minutes

00:33:23.200 --> 00:33:24.320
or solving it in an hour,

00:33:24.320 --> 00:33:26.280
where I can just sit down

00:33:26.280 --> 00:33:28.600
and have everything automated to come up.

00:33:28.600 --> 00:33:32.320
So yeah, the standard data science stack

00:33:32.320 --> 00:33:33.560
I use pretty frequently.

00:33:34.760 --> 00:33:37.240
Hardware stack, I mean, so VS Code,

00:33:37.240 --> 00:33:39.800
I just recently switched to,

00:33:39.800 --> 00:33:41.440
just 'cause everyone was talking about it

00:33:41.440 --> 00:33:45.640
from like Sublime, or I usually just edit it in a terminal.

00:33:45.640 --> 00:33:46.680
And I was like, "Oh, I'll try it out."

00:33:46.680 --> 00:33:48.440
Everyone's talking about it.

00:33:48.440 --> 00:33:51.080
It's one of the good things Microsoft has done.

00:33:51.080 --> 00:33:53.000
It's pretty sweet.

00:33:53.000 --> 00:33:54.800
- Yeah, it is pretty sweet.

00:33:54.800 --> 00:33:56.800
- So that's pretty nice.

00:33:56.800 --> 00:33:59.080
- Okay, and what do you do with the VS Code stuff?

00:33:59.080 --> 00:34:01.400
Are you just writing straight Python scripts,

00:34:01.400 --> 00:34:06.040
or are you doing VS Code on top of notebooks?

00:34:06.040 --> 00:34:06.880
- Yeah, so Jupyter's great.

00:34:06.880 --> 00:34:08.800
- It has that kind of text view

00:34:08.800 --> 00:34:11.120
of a notebook type of thing, I think.

00:34:11.120 --> 00:34:14.840
- Yeah, I used to use exclusively Python scripts,

00:34:14.840 --> 00:34:16.160
so just the .py,

00:34:16.160 --> 00:34:19.560
and then started seeing how great Jupyter was.

00:34:19.560 --> 00:34:21.560
And so then you start doing everything in Jupyter,

00:34:21.560 --> 00:34:24.040
and then you start to have all these convoluted notebooks,

00:34:24.040 --> 00:34:26.200
and notebook V1 through 7.

00:34:26.200 --> 00:34:28.560
So then you realize that you gotta find a balance

00:34:28.560 --> 00:34:31.760
between, you know, notebooks are great for presentation

00:34:31.760 --> 00:34:33.600
and for quickly testing,

00:34:33.600 --> 00:34:37.680
but the sooner you can get it into a class structure

00:34:37.680 --> 00:34:39.160
or a package or something.

00:34:39.160 --> 00:34:41.320
- Sort of productized version of it,

00:34:41.320 --> 00:34:43.200
you wanted to get it down into Python code

00:34:43.200 --> 00:34:44.880
a lot of times, probably.

00:34:44.880 --> 00:34:46.160
- Exactly, yeah, yeah, yeah.

00:34:46.160 --> 00:34:47.160
- Yeah, you're like, "All right."

00:34:47.160 --> 00:34:48.920
Like your internal tools you talked about.

00:34:48.920 --> 00:34:50.640
You're like, "All right, this is the library

00:34:50.640 --> 00:34:51.720
"you just call stuff, right?

00:34:51.720 --> 00:34:54.680
"That just belongs more as a package and not a..."

00:34:54.680 --> 00:34:56.760
- Exactly, yeah, yeah, yeah.

00:34:56.760 --> 00:35:00.200
So the sooner you can kind of condense,

00:35:00.200 --> 00:35:01.720
pull the code out of the notebook

00:35:01.720 --> 00:35:04.840
and just leave the notebooks for presentation,

00:35:04.840 --> 00:35:06.880
it's probably the best.

00:35:06.880 --> 00:35:08.040
- Yeah. - It's a lot of pipelines.

00:35:08.040 --> 00:35:09.920
So it's a lot of pre-processing pipelines.

00:35:09.920 --> 00:35:11.240
So you don't want, you know,

00:35:11.240 --> 00:35:14.120
50 cells of just moving data around.

00:35:14.120 --> 00:35:15.120
- Preparing, yeah.

00:35:15.120 --> 00:35:20.840
So you talked about having quite a bit of data,

00:35:20.840 --> 00:35:23.320
some of that being image-based.

00:35:23.320 --> 00:35:25.400
Sounds like a lot of work.

00:35:25.400 --> 00:35:27.800
Do you have like a big compute cluster?

00:35:27.800 --> 00:35:32.160
Do you just have like an ultra, an M3 ultra or whatever?

00:35:32.160 --> 00:35:33.680
That's not even how you use it, it's M2s.

00:35:33.680 --> 00:35:35.320
But do you have just a big machine

00:35:35.320 --> 00:35:37.240
or do you guys do cloud stuff?

00:35:37.240 --> 00:35:38.880
What's compute look like?

00:35:38.880 --> 00:35:42.280
- Yeah, so it depends on what I'm doing, what I need.

00:35:42.280 --> 00:35:44.520
Most things, let's be honest,

00:35:44.520 --> 00:35:49.520
I could probably just use Macbook or I have my own kind of,

00:35:49.520 --> 00:35:52.840
my desktop computer is really a super micro server.

00:35:53.920 --> 00:35:56.120
It just runs Linux.

00:35:56.120 --> 00:35:58.600
But then, you know, like if we're doing deep learning,

00:35:58.600 --> 00:35:59.600
you need GPUs.

00:35:59.600 --> 00:36:04.600
And so we have a nice set of GPUs we can pull.

00:36:04.600 --> 00:36:07.760
- Yeah, do you do your own training on LLMs

00:36:07.760 --> 00:36:09.640
and other deep learning things?

00:36:09.640 --> 00:36:11.240
Yeah.

00:36:11.240 --> 00:36:13.680
- The only LLM training I do is just for fun.

00:36:13.680 --> 00:36:17.960
But yeah, so all the deep learning stuff we have to train

00:36:17.960 --> 00:36:20.440
kind of in-house on our particular data.

00:36:21.480 --> 00:36:24.760
So that's, you know, all GPUs for that.

00:36:24.760 --> 00:36:27.920
A lot of the statistics we do are like permutations.

00:36:27.920 --> 00:36:30.800
So you need to kind of like parallelize them out into CPUs.

00:36:30.800 --> 00:36:33.920
So then I'll pull like a CPU cluster we have if I need it.

00:36:33.920 --> 00:36:38.040
But also I realize too.

00:36:38.040 --> 00:36:42.000
- Sorry, did you see Irvine have like a big compute resource?

00:36:42.000 --> 00:36:42.840
- There were a few.

00:36:42.840 --> 00:36:47.160
Yeah, they have a campus wide one that you can get on.

00:36:47.160 --> 00:36:51.240
And there's a few independent ones that I have access to.

00:36:51.240 --> 00:36:55.320
So GPU is kind of in a different place than CPUs are.

00:36:55.320 --> 00:36:56.680
So I can just kind of pick and choose.

00:36:56.680 --> 00:36:58.320
And then I have a few servers in the lab

00:36:58.320 --> 00:37:00.360
that I've just kind of put together

00:37:00.360 --> 00:37:04.640
that all my camera stuff, all my behavior,

00:37:04.640 --> 00:37:06.880
I kind of wrote it so it's cloud-based.

00:37:06.880 --> 00:37:09.520
So I can kind of just pull up my phone

00:37:09.520 --> 00:37:12.560
and look at the videos of what animals are doing and stuff.

00:37:12.560 --> 00:37:15.000
All that runs on just a server in the lab.

00:37:15.000 --> 00:37:20.520
So yeah, the compute is there when you need it.

00:37:20.520 --> 00:37:23.640
And I think as I've matured, I've kind of learned

00:37:23.640 --> 00:37:27.320
when to use what compute when and when it's worth

00:37:27.320 --> 00:37:31.440
taking the extra time to use it when you don't need to.

00:37:31.440 --> 00:37:34.840
And also when a lot of the times you don't even need it.

00:37:34.840 --> 00:37:37.480
So I know a lot of people when I see their code

00:37:37.480 --> 00:37:40.080
and they complain that it takes like an hour to run.

00:37:40.080 --> 00:37:46.240
I mean, just using multiprocessing in Python

00:37:46.920 --> 00:37:48.840
that in and of itself is enough

00:37:48.840 --> 00:37:52.120
to not need to use a cluster.

00:37:52.120 --> 00:37:52.960
- Right.

00:37:52.960 --> 00:37:55.560
- Or using a single thread for their analysis.

00:37:55.560 --> 00:37:56.400
- Right, for sure.

00:37:56.400 --> 00:38:00.920
Or just a bad programming patterns, design patterns.

00:38:00.920 --> 00:38:04.240
Like you're looping over the thing in the pandas data frame

00:38:04.240 --> 00:38:07.880
instead of doing vector operations in the pandas data frame

00:38:07.880 --> 00:38:09.800
like that kind of stuff, right?

00:38:09.800 --> 00:38:11.560
- A hundred percent, yeah.

00:38:11.560 --> 00:38:12.960
I mean, that was one of the first things

00:38:12.960 --> 00:38:14.760
that I usually teach.

00:38:14.760 --> 00:38:16.080
I have this little example script

00:38:16.080 --> 00:38:19.160
that shows like, why is it better to preallocate array

00:38:19.160 --> 00:38:22.480
rather than to just append to the bottom?

00:38:22.480 --> 00:38:23.320
- Yeah.

00:38:23.320 --> 00:38:24.160
- And it's like these things

00:38:24.160 --> 00:38:25.000
that we kind of take for granted now,

00:38:25.000 --> 00:38:27.800
but it's not intuitive unless you actually--

00:38:27.800 --> 00:38:29.200
- No, you learn it the hard way,

00:38:29.200 --> 00:38:32.040
but it sticks in your mind once you learn it.

00:38:32.040 --> 00:38:33.760
- Yeah, yeah.

00:38:33.760 --> 00:38:34.600
- Yeah, so how do you go about--

00:38:34.600 --> 00:38:35.640
- I think that's the issue.

00:38:35.640 --> 00:38:37.640
It's like people just take it for granted.

00:38:37.640 --> 00:38:38.480
- Yeah, for sure.

00:38:38.480 --> 00:38:40.000
Like, why didn't you know that?

00:38:40.000 --> 00:38:42.560
How do you onboard new people?

00:38:42.560 --> 00:38:44.240
If you get new grad students

00:38:44.240 --> 00:38:46.400
or people contribute, other contributors?

00:38:46.400 --> 00:38:50.480
- Yeah, it just kind of depends on the lab.

00:38:50.480 --> 00:38:52.480
Every lab kind of has their own structure

00:38:52.480 --> 00:38:57.280
of just kind of this hierarchy of expertise

00:38:57.280 --> 00:38:59.800
where like I started as an undergrad

00:38:59.800 --> 00:39:03.320
and I just volunteered in a lab at a different university

00:39:03.320 --> 00:39:06.160
and just volunteered my time,

00:39:06.160 --> 00:39:08.320
eventually could get paid.

00:39:08.320 --> 00:39:10.800
Just wanted to spend time in the lab and you could

00:39:10.800 --> 00:39:12.880
all the way to grad students

00:39:12.880 --> 00:39:14.280
who are there to get a PhD

00:39:14.280 --> 00:39:18.880
and have more kind of autonomy over their projects.

00:39:18.880 --> 00:39:21.320
A postdoc who has a PhD

00:39:21.320 --> 00:39:24.440
and five to eight years of experience

00:39:24.440 --> 00:39:27.000
and so can pretty work well.

00:39:27.000 --> 00:39:28.600
Then there's like staff scientists

00:39:28.600 --> 00:39:31.280
or even a lot of labs now are hiring just pure engineers

00:39:31.280 --> 00:39:33.360
or pure software people.

00:39:33.360 --> 00:39:34.320
- Okay.

00:39:34.320 --> 00:39:38.080
- Who need to, because there's such a need for that.

00:39:38.080 --> 00:39:41.480
And so, yeah, it really just depends

00:39:41.480 --> 00:39:43.840
on the lab specific situation

00:39:43.840 --> 00:39:45.280
and what their focus is on

00:39:45.280 --> 00:39:48.280
and what they need and those sorts of things.

00:39:48.280 --> 00:39:50.920
- Cool, I guess if you have a good NSF grant

00:39:50.920 --> 00:39:51.880
and you got some extra money,

00:39:51.880 --> 00:39:54.440
it might be money well spent to hire

00:39:54.440 --> 00:39:58.720
some student who has good programming skills, right?

00:39:58.720 --> 00:40:00.280
- Absolutely, yeah.

00:40:00.280 --> 00:40:01.120
- Yeah.

00:40:01.120 --> 00:40:05.040
One sec.

00:40:11.080 --> 00:40:12.320
All right, let's see.

00:40:12.320 --> 00:40:17.320
You talked about the video stuff

00:40:17.320 --> 00:40:21.080
that you're doing in the streaming video.

00:40:21.080 --> 00:40:24.200
Like, do you actually do analysis on that?

00:40:24.200 --> 00:40:27.080
Or is it just for you to go back and look at?

00:40:27.080 --> 00:40:28.200
- Oh yeah, yeah.

00:40:28.200 --> 00:40:29.320
We do analysis on that.

00:40:29.320 --> 00:40:33.400
There's actually a pretty cool deep learning package out now

00:40:33.400 --> 00:40:35.200
we didn't write it, another lab did

00:40:35.200 --> 00:40:38.040
where you just give it the video frame

00:40:38.040 --> 00:40:40.360
and it can automatically segment kind of,

00:40:40.360 --> 00:40:41.360
if it's an animal, right?

00:40:41.360 --> 00:40:43.200
So like where their paws are

00:40:43.200 --> 00:40:45.840
or where their like nose is looking.

00:40:45.840 --> 00:40:47.040
In some cases people have like,

00:40:47.040 --> 00:40:48.160
you're talking about eye tracking.

00:40:48.160 --> 00:40:50.760
They do eye tracking in like mice now.

00:40:50.760 --> 00:40:52.120
- They do eye tracking on mice?

00:40:52.120 --> 00:40:54.400
That was hard on humans in the '90s.

00:40:54.400 --> 00:40:55.920
- Yeah, there's a lot of VR.

00:40:55.920 --> 00:40:59.320
So they put kind of mice in this like VR system.

00:40:59.320 --> 00:41:01.240
- Oh wow.

00:41:01.240 --> 00:41:03.200
- And they can like see where their little mouse pupil

00:41:03.200 --> 00:41:05.760
is looking on like the screen.

00:41:05.760 --> 00:41:07.640
- Yeah, and do they show them different scenarios

00:41:07.640 --> 00:41:10.000
and they can detect that and they react to it?

00:41:10.000 --> 00:41:11.120
- Oh, absolutely, yeah.

00:41:11.120 --> 00:41:13.040
- Yeah, wow, okay.

00:41:13.040 --> 00:41:14.800
- Yeah.

00:41:14.800 --> 00:41:16.200
- Incredible.

00:41:16.200 --> 00:41:18.320
- So yeah, and a lot of stuff,

00:41:18.320 --> 00:41:21.360
at least in our field, the Nobel Prize was awarded for,

00:41:21.360 --> 00:41:25.360
you stick some electrodes in the hippocampus

00:41:25.360 --> 00:41:27.840
or your brain that's important for learning and memory.

00:41:27.840 --> 00:41:31.200
Then you have the animal kind of run around some environment

00:41:31.200 --> 00:41:33.920
and then you take some video data

00:41:33.920 --> 00:41:36.160
kind of where they were running the environment.

00:41:36.160 --> 00:41:39.360
And if you were only looking at the brain data,

00:41:39.360 --> 00:41:42.080
you can predict to like 90 some percent accuracy,

00:41:42.080 --> 00:41:44.000
the location of the animal.

00:41:44.000 --> 00:41:46.080
So you can show this kind of this correspondence

00:41:46.080 --> 00:41:49.200
that inside the brain is a map of kind of the environment.

00:41:49.200 --> 00:41:55.040
Our stuff, we're taking that a little one step further

00:41:55.040 --> 00:41:57.360
that says this map is not just for space,

00:41:57.360 --> 00:42:00.400
it's for non-spatial and other things too.

00:42:00.400 --> 00:42:04.480
That there's this kind of network of information

00:42:04.480 --> 00:42:06.400
in the brain that the animal can kind of like

00:42:06.400 --> 00:42:09.000
navigate through, even if they're just standing still,

00:42:09.000 --> 00:42:11.000
but thinking about some sort of problem.

00:42:11.000 --> 00:42:16.600
But we use video data to validate what the animal's doing

00:42:16.600 --> 00:42:20.280
or check what kind of tasks they're doing

00:42:20.280 --> 00:42:22.200
and so on and so forth.

00:42:22.200 --> 00:42:23.040
- Wow.

00:42:23.040 --> 00:42:24.800
- So yeah, a lot of multimodal heterogeneous data

00:42:24.800 --> 00:42:27.840
that each needs its own funky pre-processing

00:42:27.840 --> 00:42:29.680
and depending on the task at hand,

00:42:29.680 --> 00:42:33.720
you're writing something new to ask that question.

00:42:33.720 --> 00:42:34.560
- Amazing.

00:42:34.560 --> 00:42:35.400
So is that OpenCV?

00:42:35.400 --> 00:42:39.280
- My stuff is, yeah.

00:42:39.280 --> 00:42:41.440
Yeah, my stuff is OpenCV.

00:42:41.440 --> 00:42:46.440
Streamed over sockets and some Django webpage.

00:42:46.440 --> 00:42:48.960
It's fun, it's cool to build.

00:42:48.960 --> 00:42:50.560
- Yeah, that sounds really cool.

00:42:50.560 --> 00:42:53.280
- Yeah, absolutely.

00:42:53.280 --> 00:42:54.640
- So what kind of questions are you answering

00:42:54.640 --> 00:42:56.040
with the video?

00:42:56.040 --> 00:42:58.880
- Yeah.

00:42:58.880 --> 00:43:01.480
- Or is it just to correlate back with the time series

00:43:01.480 --> 00:43:03.520
of what you're measuring in the brain?

00:43:03.520 --> 00:43:05.960
- Yeah, so one thing I'm looking at is,

00:43:05.960 --> 00:43:09.040
so like I said, the Nobel Prize was for the spatial map.

00:43:09.040 --> 00:43:11.080
We're doing this non-spatial stuff.

00:43:11.080 --> 00:43:13.480
And so we kind of do both in the lab

00:43:13.480 --> 00:43:15.560
where we have an animal kind of run around

00:43:15.560 --> 00:43:17.520
and then we have an animal just kind of sit still

00:43:17.520 --> 00:43:19.360
and do some sort of mental task.

00:43:19.360 --> 00:43:22.600
In our case, they have to memorize a sequence of odors

00:43:22.600 --> 00:43:24.200
and if the sequence gets shuffled,

00:43:24.200 --> 00:43:26.160
they make a different choice.

00:43:26.160 --> 00:43:28.880
And so we're basically showing

00:43:31.880 --> 00:43:34.760
how does the brain work for the spatial part

00:43:34.760 --> 00:43:36.160
versus the non-spatial part?

00:43:36.160 --> 00:43:38.000
What's similar about these two things?

00:43:38.000 --> 00:43:40.400
What's different about these things?

00:43:40.400 --> 00:43:44.080
And we show that one of our recent papers was that

00:43:44.080 --> 00:43:47.880
the brain uses a lot of the similar mechanisms

00:43:47.880 --> 00:43:49.800
to navigate space as it does to navigate

00:43:49.800 --> 00:43:52.440
this kind of non-spatial odor task.

00:43:52.440 --> 00:43:53.280
- Oh, wow.

00:43:53.280 --> 00:43:55.160
- But we also showed that there's this mechanism

00:43:55.160 --> 00:43:58.000
that the brain uses to take kind of discrete memories

00:43:58.000 --> 00:44:00.800
and link them together into some kind of miracle.

00:44:01.800 --> 00:44:03.680
Best case being like this talk,

00:44:03.680 --> 00:44:07.640
we've been talking back and forth for 30 some minutes now

00:44:07.640 --> 00:44:10.440
and inside there's kind of chunks of the conversation.

00:44:10.440 --> 00:44:12.600
So if tomorrow someone was to ask you,

00:44:12.600 --> 00:44:14.960
what did you and that neuroscience guy talk about

00:44:14.960 --> 00:44:16.880
on your podcast?

00:44:16.880 --> 00:44:18.960
You would kind of rattle off this story of,

00:44:18.960 --> 00:44:22.040
oh, we talked about history of Python

00:44:22.040 --> 00:44:24.160
and this and this and this, right?

00:44:24.160 --> 00:44:27.240
This, this and this are each kind of discrete memories

00:44:27.240 --> 00:44:30.400
that in your brain you kind of lock together.

00:44:31.000 --> 00:44:31.840
- Right, okay.

00:44:31.840 --> 00:44:34.480
- So you could use them, make decisions about them

00:44:34.480 --> 00:44:36.400
and so on and so forth.

00:44:36.400 --> 00:44:39.320
- Think about it as a whole, not just the little ideas,

00:44:39.320 --> 00:44:40.160
every little idea of it,

00:44:40.160 --> 00:44:42.720
like just the big concept of it, right?

00:44:42.720 --> 00:44:43.560
- Exactly, yeah.

00:44:43.560 --> 00:44:46.000
And it's a fundamental thing that the brain does.

00:44:46.000 --> 00:44:48.200
Like people say humans are storytellers

00:44:48.200 --> 00:44:51.800
and your life is kind of the sequence of events of stories.

00:44:51.800 --> 00:44:54.600
And so you use that every single day

00:44:54.600 --> 00:44:56.120
and across a bunch of diseases,

00:44:56.120 --> 00:45:01.120
that's one of the first things to actually be impaired,

00:45:01.120 --> 00:45:04.440
whether it's addiction or schizophrenia or Alzheimer's,

00:45:04.440 --> 00:45:07.320
that kind of ability to link things in time

00:45:07.320 --> 00:45:09.680
and link them well and make decisions about them

00:45:09.680 --> 00:45:11.200
starts to get impaired.

00:45:11.200 --> 00:45:14.960
- Yeah, and that's not great when that happens,

00:45:14.960 --> 00:45:16.800
but that is what happens, right?

00:45:16.800 --> 00:45:18.520
- Absolutely, yeah.

00:45:18.520 --> 00:45:19.360
- Yeah.

00:45:19.360 --> 00:45:25.920
So I guess what are some of the,

00:45:25.920 --> 00:45:29.680
what are some of the software engineering practices,

00:45:29.680 --> 00:45:30.800
for lack of a better word,

00:45:30.800 --> 00:45:35.560
that you would recommend that maybe other grad students,

00:45:35.560 --> 00:45:39.240
professors who are feeling like they're not,

00:45:39.240 --> 00:45:41.800
they don't have their software game fully together,

00:45:41.800 --> 00:45:42.640
pay attention to it.

00:45:42.640 --> 00:45:44.200
And maybe what should they ignore, right?

00:45:44.200 --> 00:45:46.480
Like, should they pay attention to like source control

00:45:46.480 --> 00:45:47.600
and get up?

00:45:47.600 --> 00:45:49.920
Should they have unit tests or, you know,

00:45:49.920 --> 00:45:52.840
what should they pay attention to?

00:45:52.840 --> 00:45:54.480
- First off, no one writes tests.

00:45:55.400 --> 00:45:59.360
That is just, only the very few, very well put together,

00:45:59.360 --> 00:46:01.600
and usually people who just came from industry

00:46:01.600 --> 00:46:04.080
write tests, which is an issue.

00:46:04.080 --> 00:46:09.160
But yeah, first off, just learn Python.

00:46:09.160 --> 00:46:11.880
And I've said that hundreds of times,

00:46:11.880 --> 00:46:15.560
and I'm preaching to the choir in this audience.

00:46:15.560 --> 00:46:17.160
- You are, for sure.

00:46:17.160 --> 00:46:18.000
- Learn Python.

00:46:18.000 --> 00:46:22.640
Honestly, there's not much better you could learn now.

00:46:23.600 --> 00:46:28.600
And two, it's, you know,

00:46:28.600 --> 00:46:30.760
it's quintessential automation stuff.

00:46:30.760 --> 00:46:32.920
So it's really just think about the things

00:46:32.920 --> 00:46:34.680
that you're doing, like the spreadsheets,

00:46:34.680 --> 00:46:36.280
or, you know, the simple things.

00:46:36.280 --> 00:46:39.720
And really just ask yourself, you know,

00:46:39.720 --> 00:46:43.320
if you find yourself doing any repetitive tasks,

00:46:43.320 --> 00:46:44.600
that's a software problem.

00:46:44.600 --> 00:46:49.600
And those are the things to kind of look at first.

00:46:49.600 --> 00:46:51.920
And so you have your text editor in one window,

00:46:51.920 --> 00:46:54.160
Google in the other, and stack overflow

00:46:54.160 --> 00:46:55.040
your way to learning.

00:46:55.040 --> 00:46:56.600
And so the way people, I think,

00:46:56.600 --> 00:46:58.400
really do kind of teach themselves Python,

00:46:58.400 --> 00:47:01.720
it is probably the best way to learn.

00:47:01.720 --> 00:47:05.560
But nevertheless, I think there is a real need for,

00:47:05.560 --> 00:47:07.960
and again, we're starting to see more of it,

00:47:07.960 --> 00:47:10.360
just formal education, even if it's just a course.

00:47:10.360 --> 00:47:12.520
Our program is really great that they started

00:47:12.520 --> 00:47:15.000
to teach a Python course,

00:47:15.000 --> 00:47:16.840
just 'cause the students requested it,

00:47:16.840 --> 00:47:19.920
because they knew how important it was.

00:47:19.920 --> 00:47:23.920
- So you've got Python for neuroscience?

00:47:23.920 --> 00:47:24.760
- Exactly, yeah.

00:47:24.760 --> 00:47:25.600
- Okay, yeah.

00:47:25.600 --> 00:47:26.440
- That's what it is.

00:47:26.440 --> 00:47:28.440
I mean, you just work your way through if statements

00:47:28.440 --> 00:47:31.160
for loops, you know, data types.

00:47:31.160 --> 00:47:33.800
- But you probably also, I'm just guessing,

00:47:33.800 --> 00:47:35.960
you get a chance to work with some of these

00:47:35.960 --> 00:47:37.560
external libraries that are relevant

00:47:37.560 --> 00:47:40.280
to studies they're doing, right?

00:47:40.280 --> 00:47:42.920
Rather than, here's an example of stock market data.

00:47:42.920 --> 00:47:44.600
You're like, great, not a trader.

00:47:44.600 --> 00:47:48.000
I don't wanna be a programmer, why am I here, you know?

00:47:48.000 --> 00:47:49.320
- Yeah, it's really relevant.

00:47:49.320 --> 00:47:51.240
I think it's just kinda seeing like,

00:47:51.240 --> 00:47:53.560
oh yeah, I would do that this way,

00:47:53.560 --> 00:47:56.120
but this is so much easier if I use Python,

00:47:56.120 --> 00:47:57.800
and I can use it in Python,

00:47:57.800 --> 00:48:00.000
and just seeing that, oh, it's not as bad as,

00:48:00.000 --> 00:48:02.680
the mountain looks a lot higher

00:48:02.680 --> 00:48:05.000
when you're at the base than the summit, so.

00:48:05.000 --> 00:48:05.840
- It does.

00:48:05.840 --> 00:48:08.600
- Just kinda, you know, seeing it done once

00:48:08.600 --> 00:48:10.880
is usually enough to kinda tell people

00:48:10.880 --> 00:48:13.720
it's not as bad as you originally think.

00:48:13.720 --> 00:48:16.840
- Yeah, I feel like maybe I saw it this way.

00:48:16.840 --> 00:48:18.560
I certainly know a lot of other people see it this way.

00:48:18.560 --> 00:48:20.080
I mean, when I was younger,

00:48:20.080 --> 00:48:21.520
but a lot of people see it this way as well,

00:48:21.520 --> 00:48:26.520
is that like, you gotta be crazy smart to do programming.

00:48:26.520 --> 00:48:28.200
It's really challenging.

00:48:28.200 --> 00:48:31.840
It's, you know, kind of one of those things

00:48:31.840 --> 00:48:33.880
that only a few people can do,

00:48:33.880 --> 00:48:35.320
and then you get into it and you're like,

00:48:35.320 --> 00:48:39.200
oh, it's not a few really huge steps

00:48:39.200 --> 00:48:40.360
and things you've gotta solve.

00:48:40.360 --> 00:48:42.320
It's like a thousand small steps.

00:48:42.320 --> 00:48:45.240
And each one of the little small steps,

00:48:45.240 --> 00:48:46.240
you're like, that was actually easy.

00:48:46.240 --> 00:48:47.280
That's no big deal.

00:48:47.280 --> 00:48:48.280
What's the next step?

00:48:48.280 --> 00:48:49.200
And you get to the end, you're like,

00:48:49.200 --> 00:48:50.200
where was the big step?

00:48:50.200 --> 00:48:52.240
Where was it really hard, right?

00:48:52.240 --> 00:48:53.400
- Yeah, absolutely.

00:48:53.400 --> 00:48:55.440
- Yeah, do you have some experience

00:48:55.440 --> 00:48:59.000
where people in the department or people that worked with you

00:48:59.000 --> 00:49:00.280
are like, ah, I'm not a programmer.

00:49:00.280 --> 00:49:01.120
I don't wanna do this stuff.

00:49:01.120 --> 00:49:03.920
Then they kinda got into it and really found out

00:49:03.920 --> 00:49:06.640
that programming was something they really liked.

00:49:06.640 --> 00:49:10.040
Any converts out there?

00:49:10.040 --> 00:49:12.960
- Yeah, I would say so.

00:49:12.960 --> 00:49:17.020
Yeah, I think so.

00:49:17.020 --> 00:49:22.020
I think it's, I mean,

00:49:22.020 --> 00:49:24.100
I think there's kinda two kinds of people.

00:49:24.100 --> 00:49:26.660
There's people who program just because,

00:49:26.660 --> 00:49:29.700
what is it, the programming is an art book or whatever.

00:49:29.700 --> 00:49:32.860
They love it just for the sake of loving, right?

00:49:32.860 --> 00:49:37.060
And I'm probably closer to those kinds of people, right?

00:49:37.060 --> 00:49:40.060
I just think it's the coolest thing academically.

00:49:40.060 --> 00:49:42.900
But then there's the people who just kinda see it

00:49:42.900 --> 00:49:45.700
as it's a tool like anything else.

00:49:45.700 --> 00:49:48.100
And so you could be an expert in a drill

00:49:48.100 --> 00:49:50.780
or you could just know to pick up a drill.

00:49:50.780 --> 00:49:55.580
And I think that's kind of the majority of people

00:49:55.580 --> 00:49:58.420
is that it's just another tool in their toolkit to,

00:49:58.420 --> 00:49:59.460
especially for a scientist,

00:49:59.460 --> 00:50:02.300
just to answer the question that you're trying to answer.

00:50:02.300 --> 00:50:05.800
And I would even flip the reverse

00:50:05.800 --> 00:50:07.800
where there's been some times where I've

00:50:07.800 --> 00:50:11.020
maybe even used Python too much

00:50:11.020 --> 00:50:14.020
in the sense that I made a problem more,

00:50:14.020 --> 00:50:15.700
'cause it's like the automation dilemma, right?

00:50:15.700 --> 00:50:17.700
It's like, do I spend an hour automating this

00:50:17.700 --> 00:50:19.400
when I could do it in 10 minutes?

00:50:19.400 --> 00:50:22.700
- You gotta do it a lot of times

00:50:22.700 --> 00:50:23.900
and all of a sudden the hour's worth it.

00:50:23.900 --> 00:50:24.740
But if it turns out you don't.

00:50:24.740 --> 00:50:26.460
- It's like, I might need this a year from now,

00:50:26.460 --> 00:50:28.180
so I might as well just write the script,

00:50:28.180 --> 00:50:32.260
whereas I could just do it in Excel or something.

00:50:32.260 --> 00:50:33.660
- That's pretty standard,

00:50:33.660 --> 00:50:36.580
standard problems we all run into in programming.

00:50:36.580 --> 00:50:38.620
It's like, go write some code, do that.

00:50:38.620 --> 00:50:43.300
Or I could just be done with it for sure.

00:50:44.140 --> 00:50:47.100
All right, I think we've got time for a couple more topics.

00:50:47.100 --> 00:50:51.980
One thing that I think might be fun to talk about

00:50:51.980 --> 00:50:53.740
is publishing papers, right?

00:50:53.740 --> 00:50:55.300
Obviously, if you're in academics,

00:50:55.300 --> 00:50:57.540
especially in labs, you gotta publish papers.

00:50:57.540 --> 00:51:01.620
Do you use notebooks and stuff like that for your papers

00:51:01.620 --> 00:51:04.340
or is that just kind of separate?

00:51:04.340 --> 00:51:08.860
- Yeah, like I said, notebooks are great for presentation.

00:51:09.980 --> 00:51:13.980
So yeah, I use notebooks kind of for development

00:51:13.980 --> 00:51:16.260
just because you can quickly run code

00:51:16.260 --> 00:51:18.020
and go back up and move things around.

00:51:18.020 --> 00:51:21.180
And so I kind of like that ability to kind of just,

00:51:21.180 --> 00:51:24.700
a stream of consciousness, write code

00:51:24.700 --> 00:51:26.740
until you kind of see how it's kind of working,

00:51:26.740 --> 00:51:28.500
the prototype, and then refactor out

00:51:28.500 --> 00:51:32.460
into an actual .py document or a package or something.

00:51:32.460 --> 00:51:34.780
So that's kind of been my workflow

00:51:34.780 --> 00:51:35.700
and it works pretty well.

00:51:35.700 --> 00:51:38.780
But then when you actually have the code

00:51:38.780 --> 00:51:40.540
and it works and it's robust,

00:51:40.540 --> 00:51:43.540
you actually wanna put, there's a lot of figures,

00:51:43.540 --> 00:51:44.820
that's usually the main thing.

00:51:44.820 --> 00:51:46.380
So you kind of put all of that,

00:51:46.380 --> 00:51:49.460
here's the data, here's the pre-processing,

00:51:49.460 --> 00:51:52.100
here's the figure one, here's figure two, figure three,

00:51:52.100 --> 00:51:54.580
in the notebook just so it's reproducible

00:51:54.580 --> 00:51:57.020
and other people can download it

00:51:57.020 --> 00:51:59.180
and rerun your code and that sort of thing.

00:51:59.180 --> 00:52:02.300
So I think that's slowly becoming

00:52:02.300 --> 00:52:05.060
kind of the standard approach

00:52:05.060 --> 00:52:06.780
for those labs that use Python

00:52:06.780 --> 00:52:08.740
and they share their code openly.

00:52:08.740 --> 00:52:11.980
That's kind of how they do it.

00:52:11.980 --> 00:52:13.700
- Anything like executable books

00:52:13.700 --> 00:52:16.260
or any of those things that kind of produce

00:52:16.260 --> 00:52:21.060
printable output out of the notebooks?

00:52:21.060 --> 00:52:24.140
Like publish a little output out of the notebooks?

00:52:24.140 --> 00:52:27.380
- Yeah, so not a lot, but

00:52:27.380 --> 00:52:31.900
there's one of the journals, it's called eLife,

00:52:31.900 --> 00:52:32.740
it's kind of,

00:52:34.940 --> 00:52:36.740
it's trying to push the boundaries

00:52:36.740 --> 00:52:39.140
of what it means to publish a scientific paper.

00:52:39.140 --> 00:52:41.100
And so they kind of have,

00:52:41.100 --> 00:52:45.500
because most papers are really just on the web nowadays,

00:52:45.500 --> 00:52:47.540
the journals aren't really physical journals

00:52:47.540 --> 00:52:48.500
as much anymore.

00:52:48.500 --> 00:52:53.500
They kind of have papers as executable code

00:52:53.500 --> 00:52:55.740
where you can plot the figure in the browser

00:52:55.740 --> 00:52:57.940
and kind of run through the notebook.

00:52:57.940 --> 00:53:00.100
As an experiment, it's pretty cool

00:53:00.100 --> 00:53:02.580
to kind of see these new alternative ways

00:53:02.580 --> 00:53:07.580
to still convey the same findings,

00:53:07.580 --> 00:53:12.660
but you can play with it, you can kind of see how it goes.

00:53:12.660 --> 00:53:16.140
So the methods are kind of implicit in the output.

00:53:16.140 --> 00:53:19.700
- What's the name of the journal?

00:53:19.700 --> 00:53:21.140
- That's eLife, yeah.

00:53:21.140 --> 00:53:23.980
- eLife, okay, cool.

00:53:23.980 --> 00:53:25.380
Yeah, you probably, I suppose,

00:53:25.380 --> 00:53:28.860
need some way to capture the data output

00:53:28.860 --> 00:53:32.100
'cause you might not have access to the compute

00:53:32.100 --> 00:53:33.460
to recompute it.

00:53:33.460 --> 00:53:36.100
Somehow it's gotta sort of be a static version,

00:53:36.100 --> 00:53:37.820
but that sounds really cool.

00:53:37.820 --> 00:53:39.780
- Yeah, and especially for like,

00:53:39.780 --> 00:53:43.260
most recently, some of our like trained models,

00:53:43.260 --> 00:53:46.380
it's becoming more important to just share the weights

00:53:46.380 --> 00:53:50.380
and share those sorts of things too.

00:53:50.380 --> 00:53:52.020
You can't just share the code to train the thing

00:53:52.020 --> 00:53:54.020
if people don't have the compute

00:53:54.020 --> 00:53:56.500
to actually train them themselves.

00:53:56.500 --> 00:54:00.660
So it's kind of growing to not just sharing your data,

00:54:00.660 --> 00:54:01.780
not just sharing your code,

00:54:01.780 --> 00:54:03.940
but you need to share like the key derivatives

00:54:03.940 --> 00:54:07.140
of the pre-processing and those sorts of things.

00:54:07.140 --> 00:54:08.220
- Yeah.

00:54:08.220 --> 00:54:10.020
- Or even just sharing the version numbers

00:54:10.020 --> 00:54:15.020
'cause there's been the psychology or fMRI literature,

00:54:15.020 --> 00:54:17.220
there's like a bug in some version

00:54:17.220 --> 00:54:19.500
that made a lot of the results null.

00:54:19.500 --> 00:54:24.260
So, one person could use version 3.7 of a package,

00:54:24.260 --> 00:54:27.140
but that had a bug, but people don't know that.

00:54:27.140 --> 00:54:29.260
- Right, so they claim it's not reproducible,

00:54:29.260 --> 00:54:31.740
but it's really just not the same.

00:54:31.740 --> 00:54:32.580
- Algorithms.

00:54:32.580 --> 00:54:33.420
- Yeah, yeah.

00:54:33.420 --> 00:54:36.020
Or like across languages,

00:54:36.020 --> 00:54:37.780
like if you rerun the same analysis

00:54:37.780 --> 00:54:40.100
in MATLAB versus Python versus R,

00:54:40.100 --> 00:54:42.660
especially complex ones,

00:54:42.660 --> 00:54:45.620
there's a lot of little design decisions under the hood

00:54:45.620 --> 00:54:50.020
that might tweak exactly how that regression fits

00:54:50.020 --> 00:54:51.220
or exactly how that,

00:54:51.220 --> 00:54:54.700
if you're statistically sampling,

00:54:54.700 --> 00:54:56.740
how the sampling works under the hood of those.

00:54:56.740 --> 00:54:57.580
- Sure.

00:54:57.580 --> 00:55:00.620
Awesome, are you familiar

00:55:00.620 --> 00:55:03.500
with the Journal of Open Source Software?

00:55:03.500 --> 00:55:04.340
- Yeah, yeah.

00:55:04.340 --> 00:55:06.140
- I had the books on there.

00:55:06.140 --> 00:55:08.500
Yeah, I had them on quite a while ago.

00:55:08.500 --> 00:55:12.940
I think they're trying to solve an interesting problem of,

00:55:12.940 --> 00:55:17.220
if you take the time to create a really nice package

00:55:17.220 --> 00:55:18.980
for your area,

00:55:18.980 --> 00:55:21.420
you might have not taken your time writing the paper

00:55:21.420 --> 00:55:22.980
and so you wouldn't get credit

00:55:22.980 --> 00:55:25.980
'cause you don't have as many papers to publish.

00:55:25.980 --> 00:55:28.500
So, they let you publish your open source work there,

00:55:28.500 --> 00:55:30.140
which I think is pretty cool.

00:55:30.860 --> 00:55:31.700
- Yeah, we--

00:55:31.700 --> 00:55:32.540
- What do you think about that?

00:55:32.540 --> 00:55:34.740
- Yeah, we kind of had that same problem.

00:55:34.740 --> 00:55:40.620
One of the, I run a nonprofit called Continual AI.

00:55:40.620 --> 00:55:44.180
It does artificial intelligence and outreach and research

00:55:44.180 --> 00:55:46.900
and we have conferences and all sorts of events.

00:55:46.900 --> 00:55:48.180
But one of the main things we've done

00:55:48.180 --> 00:55:50.420
is we built a deep learning library

00:55:50.420 --> 00:55:52.740
on top of PyTorch called Avalanche.

00:55:52.740 --> 00:55:57.020
And so, we had a really great community

00:55:57.020 --> 00:55:59.860
of mostly volunteers who just saw the need in the field

00:55:59.860 --> 00:56:01.100
and put it together.

00:56:01.100 --> 00:56:04.700
But then again, it's like a lot of us are academics,

00:56:04.700 --> 00:56:06.020
how do you present this?

00:56:06.020 --> 00:56:08.700
And so, you write wrapper papers

00:56:08.700 --> 00:56:10.860
around kind of the framework.

00:56:10.860 --> 00:56:15.380
So, that's kind of been the de facto way of like,

00:56:15.380 --> 00:56:16.980
it's not really a paper,

00:56:16.980 --> 00:56:19.940
but you still need to like, share it

00:56:19.940 --> 00:56:22.260
and get credit for it and put your name on it.

00:56:22.260 --> 00:56:25.820
So, yeah, it's certainly an issue.

00:56:25.820 --> 00:56:28.460
I'm starting to see it not even just with software,

00:56:28.460 --> 00:56:29.420
but even with hardware,

00:56:29.420 --> 00:56:33.140
because hardware is becoming more open source in our field.

00:56:33.140 --> 00:56:35.420
So, you just kind of write like a paper

00:56:35.420 --> 00:56:38.060
about the hardware solution to some problem.

00:56:38.060 --> 00:56:40.580
- That's cool.

00:56:40.580 --> 00:56:43.020
- It's better than a patent.

00:56:43.020 --> 00:56:46.300
- Yeah, it's definitely better than a patent.

00:56:46.300 --> 00:56:49.820
Patents, while they serve a purpose, are pretty evil.

00:56:49.820 --> 00:56:54.340
Let's wrap things up with maybe just,

00:56:54.340 --> 00:56:57.460
you know, you mentioned Continual AI.

00:56:57.460 --> 00:56:58.900
Tell people a bit about that.

00:56:59.740 --> 00:57:03.340
- Yeah, so it's the largest non-profit

00:57:03.340 --> 00:57:05.060
for continual learning.

00:57:05.060 --> 00:57:07.380
Continual learning in a nutshell is,

00:57:07.380 --> 00:57:10.620
say I have a neural network

00:57:10.620 --> 00:57:14.380
and I train my neural network to classify cats.

00:57:14.380 --> 00:57:16.580
And I classify cats to 90% accuracy.

00:57:16.580 --> 00:57:19.020
And we're like, yeah, this is why neural networks are great.

00:57:19.020 --> 00:57:21.340
I take that same trained neural network on cats

00:57:21.340 --> 00:57:24.100
and I train it on, say, dogs.

00:57:24.100 --> 00:57:26.620
It does really well, 90% accuracy on dogs.

00:57:26.620 --> 00:57:29.220
We're really excited why neural networks are so great.

00:57:29.220 --> 00:57:31.860
But the issue is if I take that, again, the same network,

00:57:31.860 --> 00:57:34.620
I just trained it on dogs, I'd previously trained it on cats.

00:57:34.620 --> 00:57:37.820
I try and test it on cats again,

00:57:37.820 --> 00:57:40.260
it's gonna forget pretty much everything

00:57:40.260 --> 00:57:41.180
it learned about cats.

00:57:41.180 --> 00:57:42.820
And this is an old, old problem,

00:57:42.820 --> 00:57:44.620
back in like, you know, the good old days

00:57:44.620 --> 00:57:47.020
when neural networks were connectionist models

00:57:47.020 --> 00:57:48.940
and it was computer scientists,

00:57:48.940 --> 00:57:50.580
it was the cognitive scientists.

00:57:50.580 --> 00:57:52.340
They noticed--

00:57:52.340 --> 00:57:54.860
- It's like over-training or something like that, right?

00:57:54.860 --> 00:57:55.700
Kind of over-fitting to the dog.

00:57:55.700 --> 00:57:58.500
- They're all related, yeah, it's very similar.

00:57:58.500 --> 00:57:59.980
Catastrophic forgetting,

00:57:59.980 --> 00:58:01.700
they call it the sequential learning problem,

00:58:01.700 --> 00:58:03.020
which is why I'm really interested in it

00:58:03.020 --> 00:58:05.220
'cause I'm really interested in continual learning

00:58:05.220 --> 00:58:07.060
and sequential memory.

00:58:07.060 --> 00:58:08.020
Or in neuroscience,

00:58:08.020 --> 00:58:10.220
it's called the stability plasticity problem.

00:58:10.220 --> 00:58:12.460
So when do you learn, when do you remember?

00:58:12.460 --> 00:58:15.700
And so over the last,

00:58:15.700 --> 00:58:19.300
since we started the organization in 2018,

00:58:19.300 --> 00:58:21.700
the field has kind of exploded

00:58:21.700 --> 00:58:26.300
just because there's such a need for overcoming this

00:58:26.300 --> 00:58:27.700
across a lot of use cases.

00:58:27.700 --> 00:58:30.860
So like a lot of times you could only see the data once.

00:58:30.860 --> 00:58:33.180
So the way you solve the problem generally

00:58:33.180 --> 00:58:35.300
is you just shuffle in cats and dogs

00:58:35.300 --> 00:58:37.660
into the same dataset and retrain your model.

00:58:37.660 --> 00:58:39.580
But now the neural networks

00:58:39.580 --> 00:58:41.020
are getting bigger and bigger and bigger,

00:58:41.020 --> 00:58:43.220
retraining is getting costlier and costlier.

00:58:43.220 --> 00:58:45.180
You can't just have,

00:58:45.180 --> 00:58:46.580
can't train a network on petabytes

00:58:46.580 --> 00:58:48.740
every time you wanna update it.

00:58:48.740 --> 00:58:50.940
That's even if you have access to the data

00:58:50.940 --> 00:58:54.340
and the storage to save it and so on and so forth.

00:58:54.340 --> 00:58:57.540
So clever ways to solve the problem.

00:58:57.540 --> 00:59:00.060
So we're kind of around that.

00:59:00.060 --> 00:59:02.900
We have neuroscientists, we have computer scientists,

00:59:02.900 --> 00:59:06.180
AI researchers across academia, industry,

00:59:06.180 --> 00:59:09.020
all that are just a bunch of people

00:59:09.020 --> 00:59:10.340
really interested in this problem.

00:59:10.340 --> 00:59:13.820
They just come together and share papers, share ideas.

00:59:13.820 --> 00:59:15.100
We just had a conference.

00:59:15.100 --> 00:59:17.980
We sponsor a lot of competitions

00:59:18.340 --> 00:59:20.740
for people to kind of put forward an idea

00:59:20.740 --> 00:59:25.020
to some problem that we kind of put out every year.

00:59:25.020 --> 00:59:26.580
So it's been really, really exciting

00:59:26.580 --> 00:59:28.900
to kind of see the community grow over the years

00:59:28.900 --> 00:59:31.820
and all the tools and fun things

00:59:31.820 --> 00:59:33.420
that's kind of come out of that.

00:59:33.420 --> 00:59:35.780
- Well, it's definitely a hot topic right now.

00:59:35.780 --> 00:59:38.940
You know, I know the cognitive scientists

00:59:38.940 --> 00:59:42.820
and neuroscientists studied neural networks and stuff.

00:59:42.820 --> 00:59:44.780
And it was kind of like, well, maybe this model stuff.

00:59:44.780 --> 00:59:47.300
And then now we're in the time of LLMs

00:59:47.300 --> 00:59:48.860
and the world has gone crazy.

00:59:48.860 --> 00:59:51.500
- Absolutely.

00:59:51.500 --> 00:59:55.020
- So I guess I said we would close out with a continual AI,

00:59:55.020 --> 00:59:56.620
but let me just ask, you know,

00:59:56.620 --> 00:59:59.780
what are your thoughts on LLMs, where this stuff's going?

00:59:59.780 --> 01:00:03.220
I mean, we all have exposure to it in different ways,

01:00:03.220 --> 01:00:05.620
but you've got this understanding

01:00:05.620 --> 01:00:07.820
of what they're trying to model it on quite a bit.

01:00:07.820 --> 01:00:11.700
So, you know, what do you guys in your space think of it?

01:00:11.700 --> 01:00:15.780
- So, and I was, so the first lab I joined

01:00:15.780 --> 01:00:18.740
was a, well, the first real lab I joined

01:00:18.740 --> 01:00:21.780
was a neuroscience lab where we were sticking wires

01:00:21.780 --> 01:00:24.660
in brains and actually doing real neuroscience.

01:00:24.660 --> 01:00:27.300
But I also started kind of simultaneously working

01:00:27.300 --> 01:00:31.860
with a cognitive scientist where we were working

01:00:31.860 --> 01:00:35.300
on the original word to Vec.

01:00:35.300 --> 01:00:38.620
So this is in my mind, like the grandfather of the LLM.

01:00:38.620 --> 01:00:40.380
So this is the model that like overnight

01:00:40.380 --> 01:00:43.620
took Google Translate from being meh to pretty good.

01:00:44.700 --> 01:00:46.620
And it's just really at the heart of it,

01:00:46.620 --> 01:00:48.460
just an auto encoder.

01:00:48.460 --> 01:00:51.260
But we were really excited then doing kind

01:00:51.260 --> 01:00:56.260
of semantic modeling of just how much further

01:00:56.260 --> 01:00:59.900
kind of deep learning could take language modeling.

01:00:59.900 --> 01:01:02.340
And then we were actually using it

01:01:02.340 --> 01:01:03.860
to study catastrophic forgetting.

01:01:03.860 --> 01:01:06.460
So does word to Vec catastrophically forget?

01:01:06.460 --> 01:01:08.820
And the punchline is it does.

01:01:08.820 --> 01:01:11.420
And that kind of got me jumped into really excited

01:01:11.420 --> 01:01:13.180
about continual learning and so on.

01:01:14.220 --> 01:01:17.860
So I saw kind of that trajectory then

01:01:17.860 --> 01:01:20.060
and then kind of stepped out of it for a few years

01:01:20.060 --> 01:01:23.180
and dug more deep into pure neuroscience

01:01:23.180 --> 01:01:26.260
and artificial intelligence from other angles.

01:01:26.260 --> 01:01:30.500
But I'd always been just so fascinated by this idea

01:01:30.500 --> 01:01:33.900
of like, say you take an AI and it could read every book

01:01:33.900 --> 01:01:35.380
or it could read the internet.

01:01:35.380 --> 01:01:37.740
Like, what would you be able to get?

01:01:37.740 --> 01:01:40.180
And that was kind of, in my mind, like, well,

01:01:40.180 --> 01:01:42.580
seeing word to Vec try and do the same thing

01:01:42.580 --> 01:01:43.900
and training it on my laptop,

01:01:43.900 --> 01:01:46.820
like, well, you know, it's gonna take a minute

01:01:46.820 --> 01:01:48.100
till we get there.

01:01:48.100 --> 01:01:53.380
And I underestimated that drastically.

01:01:53.380 --> 01:01:57.780
- It was like almost no progress, almost no progress.

01:01:57.780 --> 01:02:00.060
Wow, what just happened, right?

01:02:00.060 --> 01:02:01.700
- Yeah, absolutely.

01:02:01.700 --> 01:02:06.700
And I think it's a testament to statistical learning

01:02:06.700 --> 01:02:10.780
more than anything, which is just how much information

01:02:10.780 --> 01:02:14.460
can you just soak up and put together in a fancy new way

01:02:14.460 --> 01:02:15.660
and regurgitate back.

01:02:15.660 --> 01:02:19.660
I think the next big leap is going to be

01:02:19.660 --> 01:02:24.420
adding more cognition to that progress.

01:02:24.420 --> 01:02:28.460
So adding, when an agent has a goal,

01:02:28.460 --> 01:02:31.780
when an agent kind of has to break down a series of steps

01:02:31.780 --> 01:02:32.900
to get to that goal,

01:02:32.900 --> 01:02:37.420
those kinds of things we don't see as much of.

01:02:38.620 --> 01:02:42.940
And that will kind of be the next big push, I think,

01:02:42.940 --> 01:02:44.820
that'll kind of take all the cool things

01:02:44.820 --> 01:02:49.020
that LLMs can do now and kind of blow everyone away.

01:02:49.020 --> 01:02:50.140
If you could take the internet

01:02:50.140 --> 01:02:52.660
and put it on a seven gigabyte file,

01:02:52.660 --> 01:02:54.980
what can that get you?

01:02:54.980 --> 01:02:56.220
But what if you could take the internet,

01:02:56.220 --> 01:02:57.540
put it on a seven gigabyte file,

01:02:57.540 --> 01:03:00.460
but actually have some sort of logic and direction

01:03:00.460 --> 01:03:03.220
and the agent itself can actually navigate

01:03:03.220 --> 01:03:04.540
through its own thoughts?

01:03:06.100 --> 01:03:07.620
That's gonna take us, I think,

01:03:07.620 --> 01:03:09.740
right to the borderline of...

01:03:09.740 --> 01:03:14.660
- Terminator?

01:03:14.660 --> 01:03:16.340
- Not Terminator.

01:03:16.340 --> 01:03:17.180
- I'm just kidding.

01:03:17.180 --> 01:03:18.020
- It won't be Terminator.

01:03:18.020 --> 01:03:19.260
No, it won't be Terminator.

01:03:19.260 --> 01:03:23.940
It'll be a really an intelligence system.

01:03:23.940 --> 01:03:26.140
- Yeah, it's gonna be super interesting.

01:03:26.140 --> 01:03:29.540
You know, you've got all this prompt engineering

01:03:29.540 --> 01:03:34.540
and these clever ways to kind of get the current LLMs

01:03:35.580 --> 01:03:39.420
in the right mindset, which is probably a personification.

01:03:39.420 --> 01:03:41.980
But you can tell it things like,

01:03:41.980 --> 01:03:43.460
here, I want you to tell me how to do this.

01:03:43.460 --> 01:03:44.460
And it'll come up with some answer.

01:03:44.460 --> 01:03:47.860
You can say, I want you to think step by step.

01:03:47.860 --> 01:03:48.700
And then all of a sudden

01:03:48.700 --> 01:03:50.420
you get a real different type of answer

01:03:50.420 --> 01:03:52.220
where it pulls out the pieces

01:03:52.220 --> 01:03:53.460
and it thinks about how it does it.

01:03:53.460 --> 01:03:56.740
And I think it's gonna be interesting.

01:03:56.740 --> 01:04:01.060
It's kind of like, it feels like kind of that kind of stuff,

01:04:01.060 --> 01:04:03.220
but it just, it already knows how to think.

01:04:03.220 --> 01:04:05.140
You don't have to give it little weird clues

01:04:05.140 --> 01:04:06.620
like you're an expert in this

01:04:06.620 --> 01:04:07.500
and you're really good at it.

01:04:07.500 --> 01:04:09.740
Now I want to ask you a question about, oh, I'm good at it.

01:04:09.740 --> 01:04:11.780
Okay, I'll answer better.

01:04:11.780 --> 01:04:12.740
- Yeah, I don't know.

01:04:12.740 --> 01:04:14.260
My favorite definition of AI

01:04:14.260 --> 01:04:17.060
is it's whatever computers can't do yet.

01:04:17.060 --> 01:04:17.980
- Yeah.

01:04:17.980 --> 01:04:19.820
- Because like, you know, 30 years ago,

01:04:19.820 --> 01:04:21.740
if we had this conversation, it'd be like,

01:04:21.740 --> 01:04:23.180
so what do you think of deep blue?

01:04:23.180 --> 01:04:24.620
Do you think deep blue,

01:04:24.620 --> 01:04:28.300
the AI that has a problem chest,

01:04:28.300 --> 01:04:32.300
can think and is it gonna take all our jobs?

01:04:32.300 --> 01:04:33.900
Or it's gonna be, what can Watson do?

01:04:33.900 --> 01:04:35.900
Is it gonna think and take all our jobs?

01:04:35.900 --> 01:04:39.020
And you know, that was solved with tree search,

01:04:39.020 --> 01:04:42.620
which undergraduates in their second year CS class

01:04:42.620 --> 01:04:43.460
are learning.

01:04:43.460 --> 01:04:45.220
It's just a standard, it's search.

01:04:45.220 --> 01:04:46.820
People don't even think of searches.

01:04:46.820 --> 01:04:50.260
- What if we just loaded every possible outcome

01:04:50.260 --> 01:04:51.780
into the chest thing and the steps

01:04:51.780 --> 01:04:54.060
and we just try to take, traverse each step

01:04:54.060 --> 01:04:55.780
and see where it takes us, right?

01:04:55.780 --> 01:04:56.620
- Exactly.

01:04:56.620 --> 01:04:59.300
So, I mean, there's always gonna be a room to grow,

01:04:59.300 --> 01:05:02.180
but from a cognitive science perspective,

01:05:02.180 --> 01:05:04.380
I think something far more interesting rather,

01:05:04.380 --> 01:05:05.620
you know, I think it's cool to see

01:05:05.620 --> 01:05:06.740
what computers can actually do.

01:05:06.740 --> 01:05:08.820
And I think they can do a hell of a lot more,

01:05:08.820 --> 01:05:11.260
but I think it's more interesting to kind of

01:05:11.260 --> 01:05:12.860
ask the more philosophical question

01:05:12.860 --> 01:05:14.740
of what does that actually mean for us?

01:05:14.740 --> 01:05:16.020
'Cause every step of the way,

01:05:16.020 --> 01:05:19.060
when we develop something new in artificial intelligence,

01:05:19.060 --> 01:05:20.340
it tells us something a lot deeper

01:05:20.340 --> 01:05:22.260
about our own intelligence too.

01:05:22.260 --> 01:05:23.100
- Yeah.

01:05:23.100 --> 01:05:24.460
- Where back in the 50s and 60s,

01:05:24.460 --> 01:05:26.980
they thought the chest meant intelligence.

01:05:26.980 --> 01:05:30.140
And so now we're kind of seeing with LLMs,

01:05:30.140 --> 01:05:31.620
if someone just reads a bunch of books

01:05:31.620 --> 01:05:33.020
and can memorize a bunch of books,

01:05:33.020 --> 01:05:34.420
does that mean they're intelligent?

01:05:34.420 --> 01:05:36.540
'Cause that's effectively what an LLM can do.

01:05:36.540 --> 01:05:37.540
- Yeah.

01:05:37.540 --> 01:05:38.380
- It can read a bunch of books.

01:05:38.380 --> 01:05:40.060
- It comes across as intelligent, right?

01:05:40.060 --> 01:05:41.740
It comes across that way to people like,

01:05:41.740 --> 01:05:42.940
"Oh, you have all the answers,"

01:05:42.940 --> 01:05:44.660
but it doesn't mean you're good

01:05:44.660 --> 01:05:46.900
at problem solving necessarily.

01:05:46.900 --> 01:05:47.740
- Exactly.

01:05:47.740 --> 01:05:49.940
And so I think we're kind of peeling at this onion

01:05:49.940 --> 01:05:51.780
and we're kind of segmenting intelligence

01:05:51.780 --> 01:05:55.100
into its different categories

01:05:55.100 --> 01:05:56.900
to really kind of break it apart

01:05:56.900 --> 01:05:59.660
just from this vague word of intelligence

01:06:00.780 --> 01:06:02.740
into actually what are the parts

01:06:02.740 --> 01:06:04.060
that make something intelligent?

01:06:04.060 --> 01:06:05.180
What does it really mean?

01:06:05.180 --> 01:06:08.420
And what are still the things that we thought were hard

01:06:08.420 --> 01:06:09.700
and are really easy,

01:06:09.700 --> 01:06:11.620
or the things that we thought were easy and really hard?

01:06:11.620 --> 01:06:15.100
'Cause any LLM you have now can't chew gum

01:06:15.100 --> 01:06:18.220
and walk to the store and buy you something to eat

01:06:18.220 --> 01:06:20.380
and then play you in chess.

01:06:20.380 --> 01:06:25.100
And so the general and general AI isn't just there

01:06:25.100 --> 01:06:27.940
to make it sound grander.

01:06:27.940 --> 01:06:29.540
It's there because that's actually something

01:06:29.540 --> 01:06:31.460
that makes humans very, very unique

01:06:31.460 --> 01:06:33.860
is that I can have this conversation with you,

01:06:33.860 --> 01:06:38.860
write code, prepare an omelet, walk a dog,

01:06:38.860 --> 01:06:41.780
and do all of these things all at once.

01:06:41.780 --> 01:06:43.100
And I started as a baby.

01:06:43.100 --> 01:06:45.500
- Yeah.

01:06:45.500 --> 01:06:46.820
And have feelings and thoughts

01:06:46.820 --> 01:06:48.940
and introspection about it and all that.

01:06:48.940 --> 01:06:51.580
- Yeah, hopes, dreams, like ketchup and not tomatoes

01:06:51.580 --> 01:06:53.620
and all sorts of other things.

01:06:53.620 --> 01:06:55.220
- Yeah.

01:06:55.220 --> 01:06:56.460
Yeah, super interesting.

01:06:56.460 --> 01:07:00.260
So are you pretty positive on where stuff's going?

01:07:00.260 --> 01:07:03.420
- Oh yeah, absolutely.

01:07:03.420 --> 01:07:07.340
I think I'm less concerned about the AI itself

01:07:07.340 --> 01:07:10.620
and I'm more concerned about just how we react to it.

01:07:10.620 --> 01:07:13.620
And if we act intelligent, we react well.

01:07:13.620 --> 01:07:17.580
We went through the industrial revolution.

01:07:17.580 --> 01:07:19.580
We've went through the steel age.

01:07:19.580 --> 01:07:22.660
We're starting to go through the cognitive revolution

01:07:22.660 --> 01:07:25.340
or whatever people are gonna call this 100 years ago.

01:07:26.340 --> 01:07:28.740
I think by and large, people are gonna be okay.

01:07:28.740 --> 01:07:32.820
I think we just need to have good policies,

01:07:32.820 --> 01:07:34.700
make sure that people do it responsibly,

01:07:34.700 --> 01:07:35.540
people do it well.

01:07:35.540 --> 01:07:36.940
And that's gonna be the hard part

01:07:36.940 --> 01:07:39.420
is just how do we manage the transition well?

01:07:39.420 --> 01:07:42.140
How do we take a whole labor force

01:07:42.140 --> 01:07:46.020
whose jobs will be gone?

01:07:46.020 --> 01:07:48.900
Like there's no economic incentive to keep their jobs

01:07:48.900 --> 01:07:52.340
and retrain them in a really smart and sensible way

01:07:52.340 --> 01:07:54.340
so people's livelihoods don't just go away

01:07:54.340 --> 01:07:56.140
to maximize the dollar.

01:07:56.140 --> 01:08:02.340
Those are kind of problems that are gonna need good policy

01:08:02.340 --> 01:08:05.780
and clever solutions and a lot of research

01:08:05.780 --> 01:08:08.140
to actually sit down and handle well.

01:08:08.140 --> 01:08:10.620
But AI isn't gonna go anywhere

01:08:10.620 --> 01:08:13.220
just like computers haven't went anywhere.

01:08:13.220 --> 01:08:14.580
- Yeah.

01:08:14.580 --> 01:08:18.060
- But it's not a terminator that we should worry about.

01:08:18.060 --> 01:08:18.900
- No, absolutely.

01:08:18.900 --> 01:08:19.740
It's certainly not.

01:08:19.740 --> 01:08:20.580
I was joking.

01:08:20.580 --> 01:08:22.420
We should worry about disinformation.

01:08:22.420 --> 01:08:25.020
(both laughing)

01:08:25.020 --> 01:08:26.340
And politics and news.

01:08:26.340 --> 01:08:28.420
- I mean, and I think, I don't know.

01:08:28.420 --> 01:08:30.820
I mean, I think people get so hung up on all the negatives

01:08:30.820 --> 01:08:31.740
that we kind of forget

01:08:31.740 --> 01:08:34.580
like we're developing these tools for a reason.

01:08:34.580 --> 01:08:36.140
Scientists are spending so much time

01:08:36.140 --> 01:08:37.540
and we're excited about them for a reason.

01:08:37.540 --> 01:08:41.940
One being that I used to work on proteins

01:08:41.940 --> 01:08:44.700
trying to find the structure of proteins.

01:08:44.700 --> 01:08:47.060
And that was one protein a year.

01:08:47.060 --> 01:08:49.060
It would take one year to find the structure of protein.

01:08:49.060 --> 01:08:50.540
And now I can run this.

01:08:50.540 --> 01:08:52.140
I took the same sequence that we found

01:08:52.140 --> 01:08:53.340
and ran it through AlphaFold

01:08:53.340 --> 01:08:56.180
which is DeepMind's protein folding software.

01:08:56.180 --> 01:08:58.540
They could do it in five minutes.

01:08:58.540 --> 01:08:59.380
- Amazing.

01:08:59.380 --> 01:09:00.660
- I mean, those are the things that'll really like

01:09:00.660 --> 01:09:03.620
catalyze science and technology and healthcare

01:09:03.620 --> 01:09:07.180
and actually solve the problems we wanna solve.

01:09:07.180 --> 01:09:08.020
So that's where I think--

01:09:08.020 --> 01:09:08.860
- Find new energy sources.

01:09:08.860 --> 01:09:11.780
I think I heard even some AI stuff

01:09:11.780 --> 01:09:15.180
coming up with some new battery chemistry potentially.

01:09:15.180 --> 01:09:16.020
- Everything.

01:09:16.020 --> 01:09:16.980
- Yeah.

01:09:16.980 --> 01:09:20.900
- How do you appropriately kind of harness

01:09:20.900 --> 01:09:23.700
like a fusion ring and like a topomag reactor

01:09:23.700 --> 01:09:25.020
or something like that.

01:09:25.020 --> 01:09:29.940
Everything, even to how do you route a PCB

01:09:29.940 --> 01:09:32.540
like millions of traces effectively.

01:09:32.540 --> 01:09:36.380
So it's a tool for the mind

01:09:36.380 --> 01:09:38.820
and it's not gonna put our minds out of work.

01:09:38.820 --> 01:09:39.940
Like you said a long time ago

01:09:39.940 --> 01:09:41.740
when you were in your eye tracking lab.

01:09:41.740 --> 01:09:42.580
- Yeah, exactly.

01:09:42.580 --> 01:09:43.940
I got a different view of that thing.

01:09:43.940 --> 01:09:45.460
Yeah, exactly.

01:09:45.460 --> 01:09:47.380
The same reason that none of us wanna sit around

01:09:47.380 --> 01:09:50.140
and churn butter and go till the fields

01:09:50.140 --> 01:09:52.980
and walk to work.

01:09:52.980 --> 01:09:56.580
- I don't dislike my clothes washer, not at all.

01:09:56.580 --> 01:09:59.180
Yeah, awesome.

01:09:59.180 --> 01:10:01.380
All right, well, thanks for giving us a look

01:10:01.380 --> 01:10:04.780
inside your lab, inside your research and the field

01:10:04.780 --> 01:10:07.380
and then just sharing what you brought it up to.

01:10:07.380 --> 01:10:08.860
It's been great.

01:10:08.860 --> 01:10:09.780
- Yeah, yeah, yeah.

01:10:09.780 --> 01:10:10.860
Thanks for having me.

01:10:12.460 --> 01:10:14.100
Yeah, it's been really great to,

01:10:14.100 --> 01:10:17.940
at least for the years that I've been in research

01:10:17.940 --> 01:10:20.820
seeing how pivotal Python has been.

01:10:20.820 --> 01:10:22.780
And I think that's one of the big things

01:10:22.780 --> 01:10:26.540
that probably goes unnoticed by a lot of developers

01:10:26.540 --> 01:10:27.820
when they're actually writing their code

01:10:27.820 --> 01:10:29.660
to solve whatever problem they're solving

01:10:29.660 --> 01:10:34.660
is that, I mean, someone who's wrote the NumPy library

01:10:34.660 --> 01:10:38.460
or the scikit-learn library or Jupyter notebooks

01:10:38.460 --> 01:10:40.980
has actively played a part in curing diseases

01:10:40.980 --> 01:10:42.660
and making people's lives better.

01:10:42.660 --> 01:10:46.140
And those stories usually don't kind of come

01:10:46.140 --> 01:10:47.580
to the forefront.

01:10:47.580 --> 01:10:50.020
- Yeah, it's not a direct line, right?

01:10:50.020 --> 01:10:53.860
But the research was done and facilitated

01:10:53.860 --> 01:10:57.740
by these open source tools and then discoveries were made.

01:10:57.740 --> 01:10:58.860
- But like we said, that's the difference

01:10:58.860 --> 01:11:00.740
between people getting cured in 10 years

01:11:00.740 --> 01:11:01.900
or getting cured in a year.

01:11:01.900 --> 01:11:03.940
And that's thousands of lives.

01:11:03.940 --> 01:11:06.820
And so you might not think about it

01:11:06.820 --> 01:11:08.780
when you're sitting behind your desk,

01:11:08.780 --> 01:11:10.700
making something usable.

01:11:10.700 --> 01:11:12.380
But for every day, a PhD student doesn't have

01:11:12.380 --> 01:11:14.660
to like pull their hair out and debug some software

01:11:14.660 --> 01:11:16.260
when it's well-written and it works well,

01:11:16.260 --> 01:11:19.820
that's a day that they can find something new.

01:11:19.820 --> 01:11:20.980
- That's awesome, yeah.

01:11:20.980 --> 01:11:23.260
Very inspiring.

01:11:23.260 --> 01:11:24.380
Let's leave it there, Keelen.

01:11:24.380 --> 01:11:26.060
Thank you for being on the show.

01:11:26.060 --> 01:11:27.060
Yeah, it's been great to talk to you.

01:11:27.060 --> 01:11:27.900
Thanks for coming.

01:11:27.900 --> 01:11:28.940
Yeah, thanks for coming.

