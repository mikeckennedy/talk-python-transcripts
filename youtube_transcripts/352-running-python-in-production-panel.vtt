WEBVTT

00:00:00.000 --> 00:00:05.000
Emily Hennig-Glyph, welcome to Talk Python to Me.


00:00:05.000 --> 00:00:09.760
Oh, hold on.


00:00:09.760 --> 00:00:11.080
Great to have you here.


00:00:11.080 --> 00:00:14.060
I thought I had put my stuff into silence mode,


00:00:14.060 --> 00:00:15.760
but no, I have not.


00:00:15.760 --> 00:00:17.140
I did, but apparently not enough.


00:00:17.140 --> 00:00:20.460
Anyway, so good to have you here on the show.


00:00:20.460 --> 00:00:22.560
And I'm super excited about talking about


00:00:22.560 --> 00:00:24.680
running Python in production.


00:00:24.680 --> 00:00:27.960
And I'm glad that it's more than just one of you,


00:00:27.960 --> 00:00:31.160
because I think everyone has their own perspective


00:00:31.160 --> 00:00:34.240
and their own context and whatnot.


00:00:34.240 --> 00:00:36.720
Do you work for a small company or a large company


00:00:36.720 --> 00:00:39.160
or do you have many people on the team or just a couple?


00:00:39.160 --> 00:00:41.760
And I think that really influences


00:00:41.760 --> 00:00:43.800
what you might cover,


00:00:43.800 --> 00:00:46.500
some of the decisions you might make and so on.


00:00:46.500 --> 00:00:47.880
But before we get to that,


00:00:47.880 --> 00:00:50.200
let's just start off with a little bit of background.


00:00:50.200 --> 00:00:52.200
Emily, it's been a while since you've been on the show.


00:00:52.200 --> 00:00:54.560
Maybe tell people a bit about yourself.


00:00:54.560 --> 00:00:57.200
- Yeah, absolutely.


00:00:57.200 --> 00:00:58.040
This is painful.


00:00:58.040 --> 00:00:59.600
We actually have a new website


00:00:59.600 --> 00:01:00.840
that we're gonna be launching soon.


00:01:00.840 --> 00:01:01.680
So it's fun to see the brand.


00:01:01.680 --> 00:01:04.360
- And here I'm showing your old one.


00:01:04.360 --> 00:01:05.360
No, it looks great.


00:01:05.360 --> 00:01:06.600
It looks good.


00:01:06.600 --> 00:01:07.520
Nice picture of you there.


00:01:07.520 --> 00:01:08.800
- Thanks.


00:01:08.800 --> 00:01:10.080
Yep, so I'm Emily Morehouse.


00:01:10.080 --> 00:01:14.080
I am the director of engineering at CuddleSoft.


00:01:14.080 --> 00:01:17.040
We are a digital product development company.


00:01:17.040 --> 00:01:21.400
So we kind of touch on anything from web, mobile,


00:01:21.400 --> 00:01:24.480
IOT, DevOps, we really touch the whole stack


00:01:24.480 --> 00:01:28.240
and get to work with a lot of different industries.


00:01:28.240 --> 00:01:31.560
And then I also am a Python core developer


00:01:31.560 --> 00:01:34.620
and the PyCon chair for this year.


00:01:34.620 --> 00:01:39.620
- Yeah, you just happened to grab that role


00:01:39.620 --> 00:01:45.320
right when COVID hit and conferences got insanely complicated


00:01:45.320 --> 00:01:46.380
and uncertain.


00:01:46.380 --> 00:01:49.260
How did you juggle all that?


00:01:49.260 --> 00:01:52.640
- Yeah, it was a really big bummer,


00:01:52.640 --> 00:01:56.160
I think because PyCon is really such an important piece


00:01:56.160 --> 00:01:58.960
of our community and getting to see people in person


00:01:58.960 --> 00:02:01.480
and connect on a regular basis.


00:02:01.480 --> 00:02:03.280
But of course we wanted to do the thing


00:02:03.280 --> 00:02:05.720
that was gonna keep everyone the most safe.


00:02:05.720 --> 00:02:08.880
So kind of last minute going online


00:02:08.880 --> 00:02:11.240
and then doing a full online conference


00:02:11.240 --> 00:02:14.000
and then still hoping that things will settle down this year


00:02:14.000 --> 00:02:15.780
so that in-person is something


00:02:15.780 --> 00:02:17.480
that feels very safe for us to do.


00:02:17.480 --> 00:02:19.200
But I was grateful.


00:02:19.200 --> 00:02:21.900
I actually wound up staying on for this third year as chair


00:02:21.900 --> 00:02:24.660
just so I could have that sort of like last hurrah


00:02:24.660 --> 00:02:26.980
of actually getting to be in person.


00:02:26.980 --> 00:02:28.220
Yeah, yeah.


00:02:28.220 --> 00:02:29.260
- Yeah, I hope so.


00:02:29.260 --> 00:02:30.100
Awesome.


00:02:30.100 --> 00:02:31.040
Well, thanks for all your hard work on it,


00:02:31.040 --> 00:02:33.860
even if we didn't get to meet in Pittsburgh.


00:02:33.860 --> 00:02:34.700
- Thanks.


00:02:34.700 --> 00:02:35.540
- Yeah, you bet.


00:02:35.540 --> 00:02:38.700
Glyph, you wanna go next?


00:02:38.700 --> 00:02:40.860
Tell people about yourself.


00:02:40.860 --> 00:02:42.900
- Yeah, well, I'm Glyph.


00:02:42.900 --> 00:02:46.300
I am probably best known for Twisted.


00:02:46.300 --> 00:02:49.780
I've worked on a variety of production Python environments


00:02:49.780 --> 00:02:50.620
in my career.


00:02:50.620 --> 00:02:58.340
I am currently in the process of exploring some options for something independent, all


00:02:58.340 --> 00:03:03.420
of which are secret and I can't really say anything about here yet.


00:03:03.420 --> 00:03:06.060
Most recently of pilot.com.


00:03:06.060 --> 00:03:11.840
They are a fantastic company and I'd very much recommend people work there.


00:03:11.840 --> 00:03:16.460
And we also ran a ton of Python in production over there.


00:03:16.460 --> 00:03:21.180
So I'm sure that folks in the Python podcasting space


00:03:21.180 --> 00:03:23.900
have probably heard me occasionally before.


00:03:23.900 --> 00:03:25.980
So I won't belabor my introduction.


00:03:25.980 --> 00:03:26.820
- Yeah, sounds good.


00:03:26.820 --> 00:03:28.520
Well, good to have you here again.


00:03:28.520 --> 00:03:32.260
Henrik, welcome, welcome.


00:03:32.260 --> 00:03:34.380
- Yes, thank you for having me.


00:03:34.380 --> 00:03:37.620
I think more or less my first Python podcast in my life.


00:03:37.620 --> 00:03:38.460
(laughing)


00:03:38.460 --> 00:03:39.420
- Well, it's awesome to have you.


00:03:39.420 --> 00:03:43.340
You do so much writing and you have such an influence on


00:03:43.340 --> 00:03:45.900
through like conferences and presentations.


00:03:45.900 --> 00:03:46.860
You should definitely be here.


00:03:46.860 --> 00:03:49.100
So it's long overdue.


00:03:49.100 --> 00:03:49.980
Welcome.


00:03:49.980 --> 00:03:50.820
- That's great to hear


00:03:50.820 --> 00:03:52.900
because I don't think about it like myself,


00:03:52.900 --> 00:03:54.540
but so I'm Hinek.


00:03:54.540 --> 00:03:57.300
I work for a smaller posting company.


00:03:57.300 --> 00:03:58.860
We are like a traditional web poster.


00:03:58.860 --> 00:04:01.360
I've been working there for now like 14 years,


00:04:01.360 --> 00:04:02.460
which is a very long time,


00:04:02.460 --> 00:04:03.660
which is like a thousand years


00:04:03.660 --> 00:04:05.260
in Silicon Valley time, I think.


00:04:05.260 --> 00:04:11.260
And everything I do, I do in Python, basically.


00:04:11.260 --> 00:04:15.880
They're like from web services to simple web pages.


00:04:15.880 --> 00:04:20.880
over proxies, applications, you name it,


00:04:20.880 --> 00:04:22.720
we use Python for it.


00:04:22.720 --> 00:04:24.880
- Oh, fantastic.


00:04:24.880 --> 00:04:29.240
Do you like control VMs and provision VMs and stuff


00:04:29.240 --> 00:04:30.200
and that kind of thing?


00:04:30.200 --> 00:04:32.640
Or what type of work are you doing?


00:04:32.640 --> 00:04:36.800
- We are more on the, no, we don't sell VMs.


00:04:36.800 --> 00:04:39.720
We don't sell anything where you can have root on it.


00:04:39.720 --> 00:04:42.040
So we are selling a platform basically.


00:04:42.040 --> 00:04:42.960
- Got it.


00:04:42.960 --> 00:04:46.360
Mostly PHP, like it's, it is what it is.


00:04:46.360 --> 00:04:47.200
- Yeah, sure.


00:04:47.200 --> 00:04:49.240
At least you can control it all in Python.


00:04:49.240 --> 00:04:50.080
- Yeah.


00:04:50.080 --> 00:04:51.080
- Well, fantastic.


00:04:51.080 --> 00:04:53.760
And so the reason we're all here today actually is


00:04:53.760 --> 00:04:55.320
it's your fault Henrik.


00:04:55.320 --> 00:04:56.160
- Yes. - Sort of.


00:04:56.160 --> 00:05:00.400
So you wrote this article back about a year ago.


00:05:00.400 --> 00:05:01.560
- Yeah, check the date.


00:05:01.560 --> 00:05:02.400
- Yeah, I know.


00:05:02.400 --> 00:05:05.360
But we've been talking about getting the four of us together


00:05:05.360 --> 00:05:06.320
for a while, haven't we?


00:05:06.320 --> 00:05:08.600
It's been a bit of a journey.


00:05:08.600 --> 00:05:13.040
So we didn't mean for it to be that long,


00:05:13.040 --> 00:05:17.160
but I don't think there's anything that is dated about this.


00:05:17.160 --> 00:05:19.000
So it's totally fine.


00:05:19.000 --> 00:05:22.280
- What I meant is that it was like right before Corona.


00:05:22.280 --> 00:05:26.880
I was writing this article on my phone


00:05:26.880 --> 00:05:28.840
while listening to a podcast in a van


00:05:28.840 --> 00:05:31.400
going to a Husky farm in Finland.


00:05:31.400 --> 00:05:36.280
- A Husky farm, like the dogs?


00:05:36.280 --> 00:05:38.680
- Yeah, yeah, I did the husky safari basically,


00:05:38.680 --> 00:05:41.520
like riding a husky sled, mushing.


00:05:41.520 --> 00:05:44.040
- Yeah, sounds interesting.


00:05:44.040 --> 00:05:47.000
- It was, it was my last trip before Corona,


00:05:47.000 --> 00:05:48.020
which makes it kind of funny


00:05:48.020 --> 00:05:51.380
because I talk about conferences later on, which yeah.


00:05:51.380 --> 00:05:55.440
- Yeah, that kind of got put on hold,


00:05:55.440 --> 00:05:57.920
but well, we can replace it with things like this


00:05:57.920 --> 00:05:59.440
in other conversations.


00:05:59.440 --> 00:06:02.120
So in this article, you talked about,


00:06:02.120 --> 00:06:03.640
the title is Python in Production.


00:06:03.640 --> 00:06:05.800
Of course, we'll link to it in the show notes.


00:06:05.800 --> 00:06:08.300
and you said you were missing a key part


00:06:08.300 --> 00:06:10.140
from the public Python discourse


00:06:10.140 --> 00:06:11.900
and would like to help change that.


00:06:11.900 --> 00:06:14.220
Basically, we should have more conversations


00:06:14.220 --> 00:06:16.540
about running in productions.


00:06:16.540 --> 00:06:18.240
So let me see if I get this right.


00:06:18.240 --> 00:06:20.400
You're a huge proponent of microservices.


00:06:20.400 --> 00:06:22.840
Everything should just be a bunch of small microservices


00:06:22.840 --> 00:06:25.200
and everyone else is doing it wrong?


00:06:25.200 --> 00:06:27.960
I'm just kidding, you actually take a different view


00:06:27.960 --> 00:06:31.160
than that, but we're gonna go through,


00:06:31.160 --> 00:06:33.480
you know, sort of some of the themes in your article,


00:06:33.480 --> 00:06:34.880
some of the other ones out there,


00:06:34.880 --> 00:06:38.760
And then also just all of us talk about


00:06:38.760 --> 00:06:40.480
sort of what we're doing in production,


00:06:40.480 --> 00:06:43.360
some of the considerations and trade-offs.


00:06:43.360 --> 00:06:45.200
So a lot of fun there.


00:06:45.200 --> 00:06:50.200
I think, you know, let's talk about cloud computing first.


00:06:50.200 --> 00:06:53.280
I'll pick one of these out of here


00:06:53.280 --> 00:06:54.640
and then we can touch on the whole


00:06:54.640 --> 00:06:58.740
microservice monolith thing as well.


00:06:58.740 --> 00:07:02.560
So, you know, Glyph, I'll just pick you.


00:07:02.560 --> 00:07:04.360
We have this trade-off, right?


00:07:04.360 --> 00:07:08.140
we could go and create a VM, set up our own system,


00:07:08.140 --> 00:07:10.640
and it's totally portable, could run in a data center,


00:07:10.640 --> 00:07:12.360
it could run in the cloud or whatever,


00:07:12.360 --> 00:07:14.940
or we could go all in with Lambda


00:07:14.940 --> 00:07:19.240
and other very specialized services tied to AWS


00:07:19.240 --> 00:07:21.340
or to Azure or whatever.


00:07:21.340 --> 00:07:23.760
What are your thoughts on this whole


00:07:23.760 --> 00:07:25.640
running in the cloud story?


00:07:25.640 --> 00:07:30.400
- So, I mean, there's as many dimensions to that question


00:07:30.400 --> 00:07:34.760
as there are services in AWS,


00:07:34.760 --> 00:07:38.760
which is to say like a higher order than ALF null infinity.


00:07:38.760 --> 00:07:40.520
- Exactly.


00:07:40.520 --> 00:07:44.780
- But the way that I look at that question


00:07:44.780 --> 00:07:47.680
is you have to look at each service kind of one at a time.


00:07:47.680 --> 00:07:53.060
And the way that I would generally suggest people decide


00:07:53.060 --> 00:07:54.320
whether or not it's a good idea


00:07:54.320 --> 00:07:56.200
to adopt a particular service


00:07:56.200 --> 00:08:00.360
has to do with the way that their operational footprint


00:08:00.360 --> 00:08:03.600
how it works in terms of overhead.


00:08:03.600 --> 00:08:08.600
So for example, should you run your own Postgres


00:08:08.600 --> 00:08:10.720
or should you use RDS?


00:08:10.720 --> 00:08:13.480
Almost always you should just use RDS


00:08:13.480 --> 00:08:16.240
because the operational footprint of that is


00:08:16.240 --> 00:08:19.800
Amazon configures and manages


00:08:19.800 --> 00:08:22.920
the tremendous complexity of operating


00:08:22.920 --> 00:08:25.440
a relational data store in production.


00:08:25.440 --> 00:08:27.880
And when you need to set that up for development,


00:08:27.880 --> 00:08:29.480
because like part of production


00:08:29.480 --> 00:08:34.480
and having a development environment that matches closely enough that it works well,


00:08:34.480 --> 00:08:40.480
and that you can test things and know for sure that you're getting adequate test coverage,


00:08:40.480 --> 00:08:43.480
is you can just run a Postgres Docker container.


00:08:43.480 --> 00:08:45.480
And functionally, for your infrastructure, it's probably the same.


00:08:45.480 --> 00:08:53.480
You rarely need to do deep configuration that is meaningful to your application


00:08:53.480 --> 00:08:57.480
between your local development Postgres container and your RDS instance.


00:08:57.480 --> 00:09:00.820
as that slider moves further and further towards like,


00:09:00.820 --> 00:09:02.560
well, actually our data store configuration


00:09:02.560 --> 00:09:04.320
is really part of our application.


00:09:04.320 --> 00:09:07.360
Well, actually we need to like tune things very closely.


00:09:07.360 --> 00:09:09.260
Even running your own data store might make sense.


00:09:09.260 --> 00:09:12.240
That's a pretty unusual circumstance,


00:09:12.240 --> 00:09:15.160
but that you can look at that for other aspects


00:09:15.160 --> 00:09:17.020
of your platform as well.


00:09:17.020 --> 00:09:20.620
Routing, like load balancing, caching,


00:09:20.620 --> 00:09:21.900
is that part of your app?


00:09:21.900 --> 00:09:24.080
Do you care about it in development?


00:09:24.080 --> 00:09:26.760
If it breaks in an interesting way,


00:09:26.760 --> 00:09:29.560
is that going to take you down?


00:09:29.560 --> 00:09:32.880
And look at each of those issues for each cloud service.


00:09:32.880 --> 00:09:34.760
How expensive is it gonna be for you


00:09:34.760 --> 00:09:37.800
to replicate it in development?


00:09:37.800 --> 00:09:40.520
And how accurate is that reflection going to be


00:09:40.520 --> 00:09:41.720
of what's in production?


00:09:41.720 --> 00:09:44.840
And always try to pick the answer


00:09:44.840 --> 00:09:46.460
that is the lowest overhead


00:09:46.460 --> 00:09:48.560
for your particular team configuration.


00:09:48.560 --> 00:09:54.460
That said, the tricky part is this changes


00:09:54.460 --> 00:09:56.520
as your team grows.


00:09:56.520 --> 00:09:58.920
and as your service gets more complex.


00:09:58.920 --> 00:10:01.040
One of the things that I imagine


00:10:01.040 --> 00:10:03.200
I'm gonna touch on a few times is that


00:10:03.200 --> 00:10:04.240
probably the most interesting


00:10:04.240 --> 00:10:05.840
Python and production experience I had


00:10:05.840 --> 00:10:09.440
was running pilot.com's application,


00:10:09.440 --> 00:10:12.440
which started in a very different place than it ended up.


00:10:12.440 --> 00:10:14.220
And I'm very happy with the way that that went,


00:10:14.220 --> 00:10:19.220
but we started in an incredibly like super macro service,


00:10:19.220 --> 00:10:23.480
just one big Python container and like nothing else


00:10:23.480 --> 00:10:28.480
towards picking up application load balancers and lambdas


00:10:28.480 --> 00:10:32.080
and all kinds of other stuff


00:10:32.080 --> 00:10:34.500
that eventually became part of that infrastructure


00:10:34.500 --> 00:10:36.200
as the team grew and we had more


00:10:36.200 --> 00:10:39.540
of a dedicated infrastructure, like operational footprint


00:10:39.540 --> 00:10:42.200
that we could actually manage because it was staffed.


00:10:42.200 --> 00:10:43.960
- Yeah, yeah, that makes a lot of sense.


00:10:43.960 --> 00:10:46.360
It definitely changes as your team changes.


00:10:46.360 --> 00:10:47.920
Emily, what do you think?


00:10:47.920 --> 00:10:49.940
What's your view on this?


00:10:49.940 --> 00:10:52.000
How much of the cloud should you bite off


00:10:52.000 --> 00:10:55.200
and where's the trade-offs?


00:10:55.200 --> 00:10:57.360
- Yeah, I agree with a lot of the things that Glyph said.


00:10:57.360 --> 00:10:59.020
I think that once you get to the point


00:10:59.020 --> 00:11:00.360
where you're adding complexity


00:11:00.360 --> 00:11:02.880
to your local development environment,


00:11:02.880 --> 00:11:04.800
that's usually a red flag for me.


00:11:04.800 --> 00:11:07.200
And you have to be doing something


00:11:07.200 --> 00:11:09.440
that gives you a lot of value.


00:11:09.440 --> 00:11:13.040
So for example, we'll use like Firestore


00:11:13.040 --> 00:11:16.920
as an offline database for mobile applications.


00:11:16.920 --> 00:11:20.960
And whether you're using that or you're using CouchDB,


00:11:20.960 --> 00:11:25.440
whatever choice you're making there, you're going to have some sort of added complexity locally.


00:11:25.440 --> 00:11:33.760
So yeah, I totally agree with like, RDS is a really easy swap. And if it's RDS on AWS, or


00:11:33.760 --> 00:11:41.200
moving to GCP or Heroku or whatnot, your portability between those different ecosystems


00:11:41.200 --> 00:11:47.360
is going to be pretty straightforward. But if you want to rewrite your Lambda functions to use


00:11:47.360 --> 00:11:51.920
cloud run instead. It's not just a drag and drop sort of thing.


00:11:51.920 --> 00:11:56.000
Right. You don't just page a connection string and now it's all good again.


00:11:56.000 --> 00:12:03.120
Yeah. And I think it's going to depend on where the company is at. Again, for us,


00:12:03.120 --> 00:12:10.400
we're often looking at what our client needs. So if they're a client that doesn't have a technical


00:12:10.400 --> 00:12:14.400
team that they just want to let this run on its own and they don't want to manage it,


00:12:15.520 --> 00:12:21.360
That's going to impact whether we choose heroku or aws. so like really looking at where you're at now


00:12:21.360 --> 00:12:27.280
And what sort of support you need in the future? I think is a big question to ask for sure


00:12:27.280 --> 00:12:33.040
Which way does that gauge go for you if they are kind of hands-off and not super technical?


00:12:33.040 --> 00:12:35.200
Do you give them heroku or what do you give them?


00:12:35.200 --> 00:12:38.480
Yep. Yeah, if they're non-technical we give them heroku


00:12:38.480 --> 00:12:40.400
um


00:12:40.400 --> 00:12:42.400
If they are technical


00:12:42.400 --> 00:12:44.480
Even then that kind of depends. Um


00:12:44.480 --> 00:12:51.240
a lot of times it's AWS or GCP just kind of depending on what other pieces of the ecosystem that they need or


00:12:51.240 --> 00:12:55.800
Since we work with a lot of existing tech companies a lot of times they say hey


00:12:55.800 --> 00:13:00.800
We are a GCP company or an AWS company and then we just say cool we can do either


00:13:00.800 --> 00:13:05.000
Right, and if they're already there you might as well just keep going with that, right?


00:13:05.000 --> 00:13:07.680
Yeah, definitely, but I will say that like


00:13:07.680 --> 00:13:11.760
95% of the time anything that's like


00:13:12.280 --> 00:13:18.600
web application or API based, it's going to be in a Docker container anyway, just to give


00:13:18.600 --> 00:13:20.600
us that portability.


00:13:20.600 --> 00:13:25.040
Sure. Henrik, thoughts?


00:13:25.040 --> 00:13:32.480
I have very, very little first-hand experience with cloud services because we use none.


00:13:32.480 --> 00:13:33.480
We use...


00:13:33.480 --> 00:13:36.560
It would be kind of odd for a cloud hosting company to use somebody else's cloud. Although


00:13:36.560 --> 00:13:39.560
I know that people are doing it. It totally happens, right?


00:13:39.560 --> 00:13:40.560
Yeah.


00:13:40.560 --> 00:13:43.360
reselling the big clouds.


00:13:43.360 --> 00:13:44.360
That's true.


00:13:44.360 --> 00:13:45.360
Yeah.


00:13:45.360 --> 00:13:46.360
Yeah.


00:13:46.360 --> 00:13:51.560
We run our own hardware in own cages in a shared data center, like military grade.


00:13:51.560 --> 00:13:56.640
I once almost got tasered because I took a photo from the outside.


00:13:56.640 --> 00:14:00.360
Security came running immediately.


00:14:00.360 --> 00:14:06.440
So the one thing we run outside is Sentry because that makes sense.


00:14:06.440 --> 00:14:08.520
And I didn't want to run it anymore myself.


00:14:08.520 --> 00:14:14.280
But there's also the thing that Europeans in general and Germans in particular are not


00:14:14.280 --> 00:14:21.080
very excited when you put their data on other people's servers, particularly of US companies.


00:14:21.080 --> 00:14:28.360
So often it is also like a competitive advantage for us to just say, our data literally does


00:14:28.360 --> 00:14:30.400
not leave Berlin.


00:14:30.400 --> 00:14:35.400
- Right, that's certainly something that here in the US


00:14:35.400 --> 00:14:38.880
it's easy to kind of forget about, right?


00:14:38.880 --> 00:14:41.280
Oh, these just, we think of, oh, it's just the big clouds.


00:14:41.280 --> 00:14:42.900
Right, these are big cloud companies.


00:14:42.900 --> 00:14:45.140
But really those are US cloud companies, right?


00:14:45.140 --> 00:14:47.920
And if you're in Europe or somewhere else


00:14:47.920 --> 00:14:51.260
that that's another angle to think about, right?


00:14:51.260 --> 00:14:54.960
- Yeah, I have maybe one thing to add as a user


00:14:54.960 --> 00:14:58.620
that as a user, I don't care that US East one is down.


00:14:58.620 --> 00:15:03.620
But you will know, you'll still know.


00:15:03.620 --> 00:15:07.620
Yeah, this is what I see happening, right? Like when people rely too much on cloud services,


00:15:07.620 --> 00:15:11.620
that half of the internet is down when some...


00:15:11.620 --> 00:15:15.620
...that many people are not talking about.


00:15:15.620 --> 00:15:19.620
Yeah, for sure. So maybe we can wrap this up real quick,


00:15:19.620 --> 00:15:23.620
but I do want to add just one thing. A roller out there in the audience says,


00:15:23.620 --> 00:15:27.620
I prefer my $5 DigitalOcean VM and just my


00:15:27.620 --> 00:15:32.620
MongoDB, Postgres, Python.


00:15:32.620 --> 00:15:37.620
So how often do you think about, especially I guess,


00:15:37.620 --> 00:15:40.620
how often do you think about price?


00:15:40.620 --> 00:15:45.620
If you look at the price for AWS, it can add up.


00:15:45.620 --> 00:15:48.620
And for some companies that doesn't matter, right?


00:15:48.620 --> 00:15:51.620
Just having infrastructure is great.


00:15:51.620 --> 00:15:55.620
But for others, maybe they don't have revenue yet


00:15:55.620 --> 00:15:57.860
profitable and they're really trying to squeeze by.


00:15:57.860 --> 00:16:02.060
Like where, where do you land on?


00:16:02.060 --> 00:16:03.380
Like, let's save you some money.


00:16:03.380 --> 00:16:08.280
We could do this for $10, but we're going to do it for 500 because it's the right


00:16:08.280 --> 00:16:10.500
architecture to run this distributed thing.


00:16:10.500 --> 00:16:12.500
You know, what are your thoughts?


00:16:12.500 --> 00:16:14.220
What do you tell your customers?


00:16:14.220 --> 00:16:15.420
Sure.


00:16:15.420 --> 00:16:24.140
so I think the cost benefit often comes down to picking an ecosystem.


00:16:24.140 --> 00:16:26.700
that's going to be super stable for them, where we can say,


00:16:26.700 --> 00:16:30.860
"Hey, yeah, this is going to cost you a few hundred dollars a month,


00:16:30.860 --> 00:16:35.780
but if you need somebody to step in and start to manage your system for you,


00:16:35.780 --> 00:16:41.340
you know, a couple of developer hours will easily outshine their cost


00:16:41.340 --> 00:16:43.060
for their cloud hosting."


00:16:43.060 --> 00:16:45.020
So that kind of puts it in perspective.


00:16:45.020 --> 00:16:49.740
A lot of these clients are already people who have spent multiple thousands,


00:16:49.740 --> 00:16:51.940
you know, tens to hundreds of thousands of dollars


00:16:51.940 --> 00:16:56.280
actually building their software in the first place. So as long as you're, you know, on


00:16:56.280 --> 00:16:59.440
a much lower order of magnitude, you're typically okay.


00:16:59.440 --> 00:17:04.740
Yeah, that's true. If you, especially if you're not technical, and you've got to hire someone


00:17:04.740 --> 00:17:11.900
in to kind of fix it, then yeah, the sort of failure is a big problem.


00:17:11.900 --> 00:17:17.860
One thing that I'd love to add on to that is, well, two things. First of all, on the


00:17:17.860 --> 00:17:23.840
the notion of price and sort of related to which technologies you should use.


00:17:23.840 --> 00:17:27.760
I think the question you constantly need to be asking is really never


00:17:27.760 --> 00:17:30.100
ask about one side of the equation.


00:17:30.100 --> 00:17:32.560
Never ask about features or price.


00:17:32.560 --> 00:17:36.800
You always want to be looking at a price performance ratio and that


00:17:36.800 --> 00:17:39.880
performance shouldn't necessarily, in fact, usually should not be like


00:17:39.880 --> 00:17:44.780
metrics like gigabytes or, you know, throughput or anything like that.


00:17:44.780 --> 00:17:48.940
you should be looking at, do you need what the product offers?


00:17:48.940 --> 00:17:50.740
And what is it going to save you time on?


00:17:50.740 --> 00:17:53.780
So like when Emily says, if it's going to save you development


00:17:53.780 --> 00:17:55.780
time, that is gold.


00:17:55.780 --> 00:17:59.140
You always want to go err on the side of saving development


00:17:59.140 --> 00:17:59.620
time.


00:17:59.620 --> 00:18:00.880
Developers are very expensive.


00:18:00.880 --> 00:18:01.780
We're very finicky.


00:18:01.780 --> 00:18:07.340
And anything that you develop, you also need to maintain.


00:18:07.340 --> 00:18:09.220
So one of the big benefits of cloud services


00:18:09.220 --> 00:18:12.620
is think of that price not just in terms of development cost,


00:18:12.620 --> 00:18:14.380
but are you going to need to maintain it?


00:18:14.380 --> 00:18:18.040
And on the flip side, do you need this thing at all?


00:18:18.040 --> 00:18:21.780
Quite like Hinnick was talking about having,


00:18:21.780 --> 00:18:23.980
just not using cloud at all,


00:18:23.980 --> 00:18:25.740
and yet he successfully develops


00:18:25.740 --> 00:18:27.640
and deploys many services in production


00:18:27.640 --> 00:18:29.520
and they all seem fine.


00:18:29.520 --> 00:18:33.560
And so I think that there's often kind of this


00:18:33.560 --> 00:18:36.620
tool obsession where we look at features, features, features


00:18:36.620 --> 00:18:38.700
and assume that features equals benefits,


00:18:38.700 --> 00:18:41.120
but features are only benefits to you if you need them.


00:18:41.120 --> 00:18:43.780
If you don't need them, they're additional costs.


00:18:43.780 --> 00:18:46.820
you have to learn stuff about every single one


00:18:46.820 --> 00:18:48.180
of those features.


00:18:48.180 --> 00:18:51.500
The time your developers spend learning the surface


00:18:51.500 --> 00:18:54.300
of the AWS API is a cost you have to think about.


00:18:54.300 --> 00:18:56.100
And so like it's quite often just better


00:18:56.100 --> 00:18:57.740
to not use the cloud,


00:18:57.740 --> 00:19:00.180
'cause it's cheaper to not figure it all out


00:19:00.180 --> 00:19:02.380
if you know how expensive it's gonna be


00:19:02.380 --> 00:19:03.620
in your own infrastructure.


00:19:03.620 --> 00:19:06.020
- Or as Emily pointed out, if it's in a Docker container,


00:19:06.020 --> 00:19:07.940
you may run it in the cloud now,


00:19:07.940 --> 00:19:12.080
but it's fairly portable and not super tied to it.


00:19:13.020 --> 00:19:15.520
Paul Everett out in the audience has a quick question.


00:19:15.520 --> 00:19:18.900
He says, "We talk about pinning dependencies to control change.


00:19:18.900 --> 00:19:23.940
But when we talk about cloud computing, we say let things like AWS handle it.


00:19:23.940 --> 00:19:26.940
You know, you're sort of, that's kind of a dependency on their


00:19:26.940 --> 00:19:30.320
compatibility of each one of those services you take on.


00:19:30.320 --> 00:19:31.820
What do you think about


00:19:31.820 --> 00:19:36.460
the stability of those APIs and those services over time?"


00:19:36.460 --> 00:19:39.420
I think Azure maybe is a little more


00:19:40.580 --> 00:19:45.540
changing than AWS, you know, things come and go, but still,


00:19:45.540 --> 00:19:52.100
it's something to consider, right? It's another thing you've got to deal with churn on, I guess.


00:19:52.100 --> 00:20:00.180
Yeah, and I think it depends on like how quickly you're jumping on new services.


00:20:00.180 --> 00:20:06.900
So we actually started using ECS right after it was released, and it's come a long way since then.


00:20:07.940 --> 00:20:12.900
and both like the product and our proficiency has come a long way. So I think that


00:20:12.900 --> 00:20:18.820
taking any sort of like new service with a heavy dose of skepticism and making sure that it's


00:20:18.820 --> 00:20:24.820
something that is really stable, that's going to fulfill the need, it's an important thing to look


00:20:24.820 --> 00:20:29.700
at. Yeah, that's a really good point. All right, let's move on. We touched on this enough, I think.


00:20:31.220 --> 00:20:33.520
Let's talk about microservices.


00:20:33.520 --> 00:20:37.520
I was joking with Henik about that at the beginning.


00:20:37.520 --> 00:20:40.120
So we have this spectrum.


00:20:40.120 --> 00:20:43.220
We can have just one code base,


00:20:43.220 --> 00:20:47.120
one process that runs in microWZG or gunicorn or whatever,


00:20:47.120 --> 00:20:50.820
or we could have a little flask API


00:20:50.820 --> 00:20:53.220
that does user management and login,


00:20:53.220 --> 00:20:56.820
another part that does, you know, the catalog or whatever.


00:20:56.820 --> 00:20:59.420
We have a bunch of these little services, these microservices,


00:20:59.420 --> 00:21:02.060
and then put them all together.


00:21:02.060 --> 00:21:05.020
I have thoughts on this, but where are your thoughts


00:21:05.020 --> 00:21:05.520
across this?


00:21:05.520 --> 00:21:06.400
Who wants to jump in?


00:21:06.400 --> 00:21:07.020
Just go first.


00:21:07.020 --> 00:21:13.580
Like anybody?


00:21:13.580 --> 00:21:14.100
Yes, you.


00:21:14.100 --> 00:21:15.260
Go for it.


00:21:15.260 --> 00:21:15.780
OK, sorry.


00:21:15.780 --> 00:21:24.580
My opinion at this point is, I think, quite public.


00:21:24.580 --> 00:21:27.660
I think you should start with a monolith first


00:21:27.660 --> 00:21:33.500
for this simple reason that microservices come with a lot of adjacent complexity,


00:21:33.500 --> 00:21:37.740
which we basically just talked about with cloud services, right? Like, you cannot have


00:21:37.740 --> 00:21:42.700
microservices without service discovery, you cannot have microservices without tracing,


00:21:42.700 --> 00:21:49.100
because every error becomes like, I thought it was called a distributed murder mystery.


00:21:49.100 --> 00:21:55.740
And you're trying to find the fault of it.


00:21:55.740 --> 00:22:00.860
There's things that people don't think about, like retries need to be kept.


00:22:00.860 --> 00:22:07.180
Otherwise, you're gonna get exponential growth and you denial service yourself and stuff like that.


00:22:07.180 --> 00:22:14.540
And so I mean, it's a general good idea to have as few moving parts as possible,


00:22:14.540 --> 00:22:17.100
which already someone said about cloud computing.


00:22:17.100 --> 00:22:22.140
And because more moving parts are always harder to make reliable, right?


00:22:22.140 --> 00:22:26.220
And Martin Fowler calls it the microservice premium, which I like.


00:22:26.220 --> 00:22:28.780
And it's again, it's a trade-off.


00:22:28.780 --> 00:22:31.420
Is this premium worth it to you?


00:22:31.420 --> 00:22:38.060
And I think you need a lot more experience to make this trade-off than many people think.


00:22:38.060 --> 00:22:41.340
That's my experience.


00:22:42.780 --> 00:22:49.020
You probably start simple and then with just two or three pieces, and then you end up with 20 and you're like, well, how do we get here?


00:22:49.020 --> 00:22:54.580
Yeah, yeah, and they don't really know why, right? Like people want boundaries.


00:22:54.580 --> 00:23:00.740
Like I cannot speak for huge teams, because one of the peculiarities of my job is that our team is very small with a lot of responsibility.


00:23:00.740 --> 00:23:06.620
But there are big teams that have boundaries that do not come with a network partition.


00:23:07.620 --> 00:23:14.500
So it's a trade off. And I think that most people need more experience to actually make this trade off.


00:23:14.500 --> 00:23:34.900
Yeah, I would I very much agree with that. Particularly the people who tend to be asking this question are often asking it because they're at a small company, they have a small team, they saw a really cool white paper, or a presentation by somebody at Google and Netflix.


00:23:34.900 --> 00:23:38.540
And they're like, wow, all this stuff about microservices sounds great.


00:23:38.540 --> 00:23:45.020
Fault isolation and distributed tracing and, you know, use whatever language you


00:23:45.020 --> 00:23:45.320
want.


00:23:45.320 --> 00:23:46.900
And I'll get back to that one in a second.


00:23:46.900 --> 00:23:52.980
and again, like I said before, you, you will need to think about everything


00:23:52.980 --> 00:23:55.420
in terms of cost benefit and not just benefit.


00:23:55.420 --> 00:24:03.420
And the folks at Google and Netflix are talking about 10,000 person teams.


00:24:03.460 --> 00:24:05.900
And like, how do you manage complexity at that scale?


00:24:05.900 --> 00:24:10.260
How do you deal with the problems that come with that type of organization?


00:24:10.260 --> 00:24:17.080
And so asking, like, I also, even the shape of this debate has, has long


00:24:17.080 --> 00:24:20.760
bothered me because the terms that we're using, right, do we, do we want


00:24:20.760 --> 00:24:22.860
monoliths or microservices?


00:24:22.860 --> 00:24:28.720
Asking that question is like saying, well, when we have a wheel, do we want it to be


00:24:28.720 --> 00:24:31.760
like an 18 wheeler, like truck wheel?


00:24:31.760 --> 00:24:35.040
or do we want it to be like one of those wheels that comes on like a micromachines car?


00:24:35.040 --> 00:24:41.440
And the answer is, I don't, I don't know, like, what are you, what are you putting on the vehicle


00:24:41.440 --> 00:24:47.040
that this wheel is going to be attached to? Like, it really depends. And for the question of


00:24:47.040 --> 00:24:50.960
like, how big do you want your service to be? Which is, I think, a better question than do


00:24:50.960 --> 00:24:59.040
you want a microservice or a monolith? It comes down to what is the surface area to volume ratio


00:24:59.040 --> 00:25:04.540
of your team. It takes about 12 people to run a microservice, I would say, like a dozen


00:25:04.540 --> 00:25:10.080
people per service is roughly what you should be thinking about. Plus, there's the fixed


00:25:10.080 --> 00:25:14.680
overhead of a microservice architecture where you need service discovery and tracing and


00:25:14.680 --> 00:25:18.860
logging and like a whole bunch of other stuff, which you probably need in today's modern


00:25:18.860 --> 00:25:22.760
fancy cloud environment. If you're going to be able to leverage services like Honeycomb


00:25:22.760 --> 00:25:28.480
CloudWatch and like, just manage all your logs and not have to deal with that yourself.


00:25:28.480 --> 00:25:35.200
Then you're talking about maybe a six person team that can just do infra.


00:25:35.200 --> 00:25:40.400
And if you are at a three person startup and thinking, huh, that sounds like a lot of people,


00:25:40.400 --> 00:25:41.400
you want to model it.


00:25:41.400 --> 00:25:48.200
You want one piece of code you can maintain because the benefit of having something like


00:25:48.200 --> 00:25:55.440
a very fine grained microservice architecture is that you can say, we're going to have each


00:25:55.440 --> 00:26:01.200
Each team own its little piece and we're going to move a lot of the complexity of orchestrating


00:26:01.200 --> 00:26:07.280
from code to configuration because our operations team can like deal with the configuration


00:26:07.280 --> 00:26:11.720
and manage their process around testing configurations.


00:26:11.720 --> 00:26:15.600
But if you're a small development team, you want code you can write unit tests for.


00:26:15.600 --> 00:26:19.520
You want code that you can run and understand the way that you run and understand everything


00:26:19.520 --> 00:26:20.520
else.


00:26:20.520 --> 00:26:24.200
you push everything into YAML files and INI files and cloud APIs.


00:26:24.200 --> 00:26:27.280
What is your development environment look like anymore?


00:26:27.280 --> 00:26:28.640
How do you test those changes?


00:26:28.640 --> 00:26:28.960
Like,


00:26:28.960 --> 00:26:31.680
right, even developing on your own machine becomes tricky.


00:26:31.680 --> 00:26:32.760
Yeah, exactly. Yeah.


00:26:32.760 --> 00:26:39.120
And I think the big takeaway is that the team needs to match what microservices are optimized for.


00:26:39.120 --> 00:26:41.160
Yeah, exactly.


00:26:41.160 --> 00:26:41.800
Really good point.


00:26:41.800 --> 00:26:48.720
Emily, I suspect the people you suggest use Heroku probably are not receiving 10 microservices.


00:26:48.720 --> 00:26:50.160
Over there. Are they?


00:26:50.160 --> 00:26:57.020
No, definitely not. I think one of the things that we typically have built in is a certain


00:26:57.020 --> 00:27:02.380
amount of ability to scale independently. And so we typically do have two different


00:27:02.380 --> 00:27:07.260
workers on Heroku. So we're going to have, you know, a Django application and a Celery


00:27:07.260 --> 00:27:11.300
task worker. And then we know that we can kind of scale those two independently. But


00:27:11.300 --> 00:27:16.300
that's where we really see the division of load.


00:27:16.300 --> 00:27:20.740
So that's my lens that I look at monolith


00:27:20.740 --> 00:27:24.860
versus microservices with is really,


00:27:24.860 --> 00:27:26.700
do I need to scale them independently?


00:27:26.700 --> 00:27:29.180
- Yeah, and I certainly think having some kind of,


00:27:29.180 --> 00:27:32.120
we're gonna kick off the long running work over there.


00:27:32.120 --> 00:27:34.380
So it's not happening as part of a web request.


00:27:34.380 --> 00:27:35.800
That certainly makes sense.


00:27:35.800 --> 00:27:41.020
Even things just like sending a group of people an email.


00:27:41.020 --> 00:27:45.260
It often takes too long if the group is large enough


00:27:45.260 --> 00:27:47.920
before the request will timeout and wreck your servers


00:27:47.920 --> 00:27:48.820
and all sorts of stuff.


00:27:48.820 --> 00:27:49.660
So yeah.


00:27:49.660 --> 00:27:51.220
- Yep, definitely.


00:27:51.220 --> 00:27:54.220
But I think developer experience is a really big one.


00:27:54.220 --> 00:27:57.140
We have had the pleasure of working with


00:27:57.140 --> 00:28:00.280
another like very large tech company,


00:28:00.280 --> 00:28:02.700
like multiple hundreds of employees


00:28:02.700 --> 00:28:05.820
and they had a monolithic Rails app.


00:28:05.820 --> 00:28:08.660
And it was absolute hell to work with as a developer


00:28:08.660 --> 00:28:12.820
because you're constantly having hundreds of PRs open at a time.


00:28:12.820 --> 00:28:14.940
You open a PR and within 20 minutes,


00:28:14.940 --> 00:28:17.300
you have a merge conflict with somebody else.


00:28:17.300 --> 00:28:20.180
And you really, at that point,


00:28:20.180 --> 00:28:22.380
it makes sense from a developer perspective too


00:28:22.380 --> 00:28:26.620
to be able to divide it up and say, "Okay, this is your area of expertise.


00:28:26.620 --> 00:28:28.020
This is your area of expertise."


00:28:28.020 --> 00:28:30.460
And at least set up those partitions.


00:28:30.460 --> 00:28:32.860
But you can do that in a monolith as well.


00:28:32.860 --> 00:28:35.620
It just takes a little bit of awareness


00:28:35.620 --> 00:28:37.780
and slicing the problem a little differently.


00:28:37.780 --> 00:28:48.780
Yeah. So let me think of a, let me throw out an idea that I just thought of that I'm not sure I'm advocating this or even that is a good idea.


00:28:48.780 --> 00:28:55.780
But one of the problems you have is sort of you have this big monoliths like you were touching on Emily is a lot of people are changing the same bits of code.


00:28:55.780 --> 00:29:00.780
And they're kind of in all over the place. So the microservices is one way to solve that problem.


00:29:00.780 --> 00:29:03.180
What about trying to think about,


00:29:03.180 --> 00:29:06.280
could we package up some of the functionality


00:29:06.280 --> 00:29:09.620
of what our application does or area


00:29:09.620 --> 00:29:12.620
into Python packages that we can then install


00:29:12.620 --> 00:29:14.900
and use in the main app?


00:29:14.900 --> 00:29:18.240
Bad idea, good idea?


00:29:18.240 --> 00:29:20.860
- I mean, it's interesting,


00:29:20.860 --> 00:29:23.540
but it's also another level of complexity, right?


00:29:23.540 --> 00:29:24.780
- Yeah, yeah, yeah.


00:29:24.780 --> 00:29:27.460
Got to run your own private server or something.


00:29:27.460 --> 00:29:30.700
- I would actually say that that is a prerequisite


00:29:30.700 --> 00:29:35.900
to microservices. Specifically, one of the things that people often forget about the


00:29:35.900 --> 00:29:39.660
whole service architecture thing, and this comes down to the, if you remember, I said


00:29:39.660 --> 00:29:46.980
I was going to talk about choose your own language kind of thinking before. One of the


00:29:46.980 --> 00:29:52.980
things that people often choose microservice architecture for badly is this idea that they


00:29:52.980 --> 00:29:56.060
want to experiment with different programming languages because they want to use the right


00:29:56.060 --> 00:30:00.660
tool for the right job. And number one, just the cognitive overhead of jumping between


00:30:00.660 --> 00:30:06.580
Haskell and OCaml and Python and Rust, like on your back end is like, way, way higher


00:30:06.580 --> 00:30:12.140
than most people think. But even forgetting about the sort of human cognitive overhead,


00:30:12.140 --> 00:30:19.500
your service architecture, your service fabric needs to be logging and recording metrics


00:30:19.500 --> 00:30:23.940
and dealing with load balancers and dealing with data stores in a consistent way. And


00:30:23.940 --> 00:30:26.080
That task by itself is complex enough


00:30:26.080 --> 00:30:27.980
that you probably need a library,


00:30:27.980 --> 00:30:30.660
which means every supported language in your environment


00:30:30.660 --> 00:30:32.460
needs to have packages installed


00:30:32.460 --> 00:30:34.340
that are maintained by your infrastructure team


00:30:34.340 --> 00:30:36.500
and not by your application teams.


00:30:36.500 --> 00:30:38.540
And that means before you can even think


00:30:38.540 --> 00:30:40.460
about microservices, you have to be able


00:30:40.460 --> 00:30:43.220
to split your workflow into multiple


00:30:43.220 --> 00:30:46.260
different package repositories,


00:30:46.260 --> 00:30:48.980
different source control, different teams, different CI.


00:30:48.980 --> 00:30:51.340
Like you need to be able to do that first


00:30:51.340 --> 00:30:54.620
before you can reasonably split things across


00:30:54.620 --> 00:30:57.820
like multiple actual services.


00:30:57.820 --> 00:31:00.100
That doesn't necessarily mean you need to like


00:31:00.100 --> 00:31:01.540
not have a quote unquote monolith


00:31:01.540 --> 00:31:05.700
because you can put a monorepo


00:31:05.700 --> 00:31:07.620
into that kind of multiple package,


00:31:07.620 --> 00:31:10.340
multiple library workflow and that's also fine,


00:31:10.340 --> 00:31:13.220
but you do need to be able to have multiple work streams


00:31:13.220 --> 00:31:16.900
going that end up in the same service package.


00:31:16.900 --> 00:31:17.900
- Yeah, absolutely.


00:31:17.900 --> 00:31:20.400
Another thing is versioning across the services, right?


00:31:20.400 --> 00:31:22.720
the definition, like if you're using SQLAlchemy,


00:31:22.720 --> 00:31:26.160
the user shape has to match all the parts


00:31:26.160 --> 00:31:28.720
that talk to the database that might touch a user object


00:31:28.720 --> 00:31:30.240
or something like that.


00:31:30.240 --> 00:31:32.120
So I guess I'll wrap it up with a quick thought


00:31:32.120 --> 00:31:36.120
that for me, microservices feel like I'm trading code


00:31:36.120 --> 00:31:38.340
and developer complexity for operational


00:31:38.340 --> 00:31:40.240
and DevOps complexity.


00:31:40.240 --> 00:31:43.520
And I personally feel much more comfortable managing


00:31:43.520 --> 00:31:45.360
and working with code complexity


00:31:45.360 --> 00:31:47.080
than like infrastructure complexity.


00:31:47.080 --> 00:31:49.200
But if like your team and your organization


00:31:49.200 --> 00:31:51.740
It's all about managing infrastructure complexity


00:31:51.740 --> 00:31:54.180
in DevOps and you have a bunch of junior devs,


00:31:54.180 --> 00:31:56.180
maybe microservices make sense.


00:31:56.180 --> 00:31:57.020
I don't know.


00:31:57.020 --> 00:32:00.820
It kind of depends, but my vote's for the monolith side


00:32:00.820 --> 00:32:03.320
because I'd rather manage the software complexity.


00:32:03.320 --> 00:32:05.780
Yeah.


00:32:05.780 --> 00:32:07.940
All right, let's talk about security.


00:32:07.940 --> 00:32:11.300
I mean, we've had some crazy stuff.


00:32:11.300 --> 00:32:14.560
I think it's a log for Jmean.


00:32:14.560 --> 00:32:16.220
There's a .com.


00:32:16.220 --> 00:32:18.320
I think that is a .com.


00:32:18.320 --> 00:32:21.640
- Yeah, so like security is clearly on the,


00:32:21.640 --> 00:32:22.920
(laughs)


00:32:22.920 --> 00:32:24.440
it's something we always have to think about,


00:32:24.440 --> 00:32:26.920
but something, right, that recently Log4J


00:32:26.920 --> 00:32:28.840
obviously being a Java and not Python thing,


00:32:28.840 --> 00:32:33.240
but it's the one thing that makes me nervous


00:32:33.240 --> 00:32:36.260
about running stuff in production, honestly, right?


00:32:36.260 --> 00:32:40.000
We've got stuff like a status cake


00:32:40.000 --> 00:32:43.440
or various other things that you can fire up


00:32:43.440 --> 00:32:46.080
or uptime or whatever that will tell you


00:32:46.080 --> 00:32:48.240
if your site is down and send you notifications


00:32:48.240 --> 00:32:49.720
and things like that.


00:32:49.720 --> 00:32:52.400
But the security one is a little bit scary.


00:32:52.400 --> 00:32:56.280
So how do you approach thinking about this?


00:32:56.280 --> 00:32:58.160
Henrik, maybe you go first.


00:32:58.160 --> 00:33:01.560
Hosting other people's code is like a next level.


00:33:01.560 --> 00:33:04.720
It's like meta security.


00:33:04.720 --> 00:33:06.560
Yeah.


00:33:06.560 --> 00:33:10.960
The one flag I want to wave here is defense in depth,


00:33:10.960 --> 00:33:13.320
which is something that's very dear to my heart,


00:33:13.320 --> 00:33:16.080
and which I feel is--


00:33:16.080 --> 00:33:18.640
Yeah, which could be a bit more popular.


00:33:18.640 --> 00:33:22.760
Because every significant attack nowadays is a multi-stage one.


00:33:22.760 --> 00:33:25.200
It doesn't matter if it's like owning your Chrome


00:33:25.200 --> 00:33:27.480
or owning a server.


00:33:27.480 --> 00:33:29.520
It's usually multiple stages.


00:33:29.520 --> 00:33:34.140
So you shouldn't make it as hard as possible to the attackers,


00:33:34.140 --> 00:33:39.000
even though they have entered your infrastructure


00:33:39.000 --> 00:33:40.120
at this point.


00:33:40.120 --> 00:33:43.300
So for me, it means that I treat our own network, which


00:33:43.300 --> 00:33:44.040
is very private.


00:33:44.040 --> 00:33:49.800
You need a VPN to get in and everything, as if it had intruders inside it.


00:33:49.800 --> 00:33:53.080
And that's our standard.


00:33:53.080 --> 00:34:00.880
So you should hash your passwords as the maintainer of Argon2 CFFI, of course, using Argon2, but


00:34:00.880 --> 00:34:02.440
use whatever.


00:34:02.440 --> 00:34:12.240
We use TLS even in private networks, because I know that cloud providers have virtual LANs,


00:34:12.240 --> 00:34:15.240
which are also often encrypted, but still, it's just another layer.


00:34:15.240 --> 00:34:21.000
And you cannot have enough layers to protect yourself at this point,


00:34:21.000 --> 00:34:24.000
because if someone intrudes you, you don't want them to sniff passwords


00:34:24.000 --> 00:34:26.440
out of your traffic and things like that.


00:34:26.440 --> 00:34:28.120
- Yeah, absolutely. - The list goes on.


00:34:28.120 --> 00:34:30.120
Yeah, it definitely does.


00:34:30.120 --> 00:34:31.880
Emily?


00:34:31.880 --> 00:34:33.720
Security thoughts?


00:34:33.720 --> 00:34:38.480
Yeah, luckily, this isn't one that we've necessarily had to worry too much about.


00:34:38.480 --> 00:34:43.960
I think the worst thing that's happened for us is a DDoS attack, and that's about it.


00:34:43.960 --> 00:34:50.100
So for me, I think definitely staying on top of dependency management, keeping things up


00:34:50.100 --> 00:34:58.060
to date, which is not necessarily always the easiest thing, especially the Python 2.3 transition,


00:34:58.060 --> 00:35:01.260
upgrading Django is sometimes a little bit more complex than you'd want it to be.


00:35:01.260 --> 00:35:05.460
But I think that getting those security updates and making sure that you're on an LTS version


00:35:05.460 --> 00:35:06.460
is really important.


00:35:06.460 --> 00:35:09.820
- LTS being long-term support, yeah, absolutely.


00:35:09.820 --> 00:35:10.660
- Yep.


00:35:10.660 --> 00:35:14.300
- Yeah, that's a good point.


00:35:14.300 --> 00:35:15.740
So one of the things that I think,


00:35:15.740 --> 00:35:16.880
you know, I made the,


00:35:16.880 --> 00:35:19.820
I was picking on the log4j thing,


00:35:19.820 --> 00:35:24.260
but one of the problems that made this a little bit harder,


00:35:24.260 --> 00:35:25.340
I mean, this is gonna be something


00:35:25.340 --> 00:35:26.340
we live with for a long time.


00:35:26.340 --> 00:35:29.040
It's gonna be a nightmare, but the consequences of it.


00:35:29.040 --> 00:35:33.940
But one of the problems was that the fixed version


00:35:33.940 --> 00:35:38.540
of log4j, which for those who didn't know,


00:35:38.540 --> 00:35:43.060
the log4j problem is if you can basically get a server


00:35:43.060 --> 00:35:46.500
to print a message with any of your input,


00:35:46.500 --> 00:35:49.540
like this URL was invalid or this email tried to log in


00:35:49.540 --> 00:35:52.820
and failed, you can own the computer,


00:35:52.820 --> 00:35:54.420
which is really, really bad.


00:35:54.420 --> 00:35:57.380
So it has to be fixed like straight away.


00:35:57.380 --> 00:36:01.260
But the problem was the fixed version was on a newer version


00:36:01.260 --> 00:36:02.260
like Java 8.


00:36:02.260 --> 00:36:04.420
So if you were running Java 7,


00:36:04.420 --> 00:36:06.380
you had to both not just upgrade your library,


00:36:06.380 --> 00:36:08.260
but then upgrade your whole runtime,


00:36:08.260 --> 00:36:09.860
which might be problematic.


00:36:09.860 --> 00:36:13.020
So, Emily, that makes me think that,


00:36:13.020 --> 00:36:17.020
you know, you probably, one of the good rules to go by


00:36:17.020 --> 00:36:20.720
is don't let your frameworks get too far out of date.


00:36:20.720 --> 00:36:22.500
You don't have to be on the latest Django,


00:36:22.500 --> 00:36:24.740
but don't stay on Django 1


00:36:24.740 --> 00:36:26.820
when Django 4 is about to be released.


00:36:26.820 --> 00:36:31.220
Or don't stay on Python 3.6


00:36:31.220 --> 00:36:33.860
when you could be on the new one or something like that?


00:36:33.860 --> 00:36:35.360
How do you all feel about that?


00:36:35.360 --> 00:36:40.140
- Yeah, and I think that like looking at it


00:36:40.140 --> 00:36:43.100
from an open source maintainer's perspective,


00:36:43.100 --> 00:36:46.780
making sure that you have the ability


00:36:46.780 --> 00:36:49.300
to kind of hotfix previous versions


00:36:49.300 --> 00:36:51.860
and be very clear about which versions you're supporting


00:36:51.860 --> 00:36:53.740
and which ones you're not.


00:36:53.740 --> 00:36:56.480
That way you make it easy for a user to know like,


00:36:56.480 --> 00:36:59.460
yeah, I'm not gonna get the security update


00:36:59.460 --> 00:37:02.660
and I need to upgrade and have that done ahead of time


00:37:02.660 --> 00:37:04.860
to stay on top of things.


00:37:04.860 --> 00:37:06.300
- Yeah.


00:37:06.300 --> 00:37:10.300
Henrik or Glyph, old frameworks, what do you think?


00:37:10.300 --> 00:37:12.880
- So, I mean, I think that this is a,


00:37:12.880 --> 00:37:16.160
I don't think I can find this right away,


00:37:16.160 --> 00:37:18.620
but I remember one of my more popular tweets


00:37:18.620 --> 00:37:21.540
was one of those sort of two buttons memes


00:37:21.540 --> 00:37:23.060
where the guy can't choose.


00:37:23.060 --> 00:37:25.440
And on one side you've got get owned


00:37:25.440 --> 00:37:27.580
because your dependencies are out of date


00:37:27.580 --> 00:37:30.220
and you have no way to immediately update them


00:37:30.220 --> 00:37:33.060
or get owned because you're automatically updating


00:37:33.060 --> 00:37:34.220
from an upstream that you don't know


00:37:34.220 --> 00:37:36.060
if you can trust or not.


00:37:36.060 --> 00:37:37.340
And that's kind of,


00:37:37.340 --> 00:37:42.340
so the way that I sort of split that difference in practice


00:37:42.340 --> 00:37:47.400
is you really want to make sure that


00:37:47.400 --> 00:37:50.540
it's not just about like regularly upgrading


00:37:50.540 --> 00:37:51.700
because you can always say like,


00:37:51.700 --> 00:37:53.980
oh yeah, we'll regularly upgrade,


00:37:53.980 --> 00:37:57.140
but you've only got a fixed budget for security, right?


00:37:57.140 --> 00:38:02.140
it's possible to spend all of your time spinning your wheels trying to increase the cost for


00:38:02.140 --> 00:38:04.140
attackers across every possible access.


00:38:04.140 --> 00:38:05.140
Sorry, access.


00:38:05.140 --> 00:38:09.780
And I like what you got to ship features and deliver stuff.


00:38:09.780 --> 00:38:12.740
That's really exactly such a balance.


00:38:12.740 --> 00:38:13.740
Yeah.


00:38:13.740 --> 00:38:16.740
Thinking about Hennig's suggestion of defense in depth, the way that I like to think about


00:38:16.740 --> 00:38:20.860
that is you want to raise the bar to a certain minimal level in a bunch of different areas


00:38:20.860 --> 00:38:27.740
and then not get too obsessed with getting that last 5% of security on each possible access.


00:38:27.740 --> 00:38:33.260
So for dependencies, the way that I think about that is have the, you know,


00:38:33.260 --> 00:38:37.260
very widely available automation that already does this stuff like Dependabot.


00:38:37.260 --> 00:38:42.060
Make sure you are getting those PRs automatically.


00:38:42.060 --> 00:38:47.500
Pin everything so that you're never dealing with a library upgrade in the middle of feature


00:38:47.500 --> 00:38:51.060
your library upgrade work should always be,


00:38:51.060 --> 00:38:52.580
I am upgrading this library now.


00:38:52.580 --> 00:38:56.260
And 90% of the time, if you have that set up,


00:38:56.260 --> 00:39:00.940
where you've got a build that is running on every PR


00:39:00.940 --> 00:39:03.680
that builds your whole dependency structure,


00:39:03.680 --> 00:39:05.780
that's got everything pinned and hashes pinned


00:39:05.780 --> 00:39:10.140
and everything, and then is also regularly receiving


00:39:10.140 --> 00:39:13.820
these PR updates, most attackers who are doing things


00:39:13.820 --> 00:39:15.960
with supply chain attacks aren't all that clever.


00:39:15.960 --> 00:39:19.980
And so they will just end up trying to pop your CI


00:39:19.980 --> 00:39:21.980
and you'll see that, you'll get some kind of error.


00:39:21.980 --> 00:39:24.020
You'll probably notice.


00:39:24.020 --> 00:39:26.880
Not necessarily, attackers can be very sophisticated,


00:39:26.880 --> 00:39:29.940
but like you wanna have everything,


00:39:29.940 --> 00:39:34.940
every library running in your nicely isolated CI environment


00:39:34.940 --> 00:39:39.500
on your GitHub actions or whatever first.


00:39:39.500 --> 00:39:43.060
And again, you want those changes to all be like


00:39:43.060 --> 00:39:44.460
same code with the old dependency,


00:39:44.460 --> 00:39:45.700
same code with the new dependency.


00:39:45.700 --> 00:39:48.260
And every so often you'll get one very expensive upgrade


00:39:48.260 --> 00:39:51.420
that you really gotta do and you gotta make time for.


00:39:51.420 --> 00:39:54.460
But if you're not upgrading all the super easy,


00:39:54.460 --> 00:39:58.380
almost free, like just hit the green button


00:39:58.380 --> 00:40:00.780
on the PR that's working,


00:40:00.780 --> 00:40:02.480
if you're not doing that all the time,


00:40:02.480 --> 00:40:04.140
then when you do get to those big upgrades,


00:40:04.140 --> 00:40:06.540
you will be upgrading 50 dependencies at a time.


00:40:06.540 --> 00:40:07.700
- Yeah, it's gonna be rough, yeah.


00:40:07.700 --> 00:40:10.340
- Yeah, you really need to think about the cost to you


00:40:10.340 --> 00:40:11.540
as the defender.


00:40:11.540 --> 00:40:12.780
And the way that you reduce that cost


00:40:12.780 --> 00:40:16.800
on dependency upgrades is spending just a little bit


00:40:16.800 --> 00:40:20.440
of time every week, tending that automation


00:40:20.440 --> 00:40:22.500
and looking for those upgrades that are really gonna take


00:40:22.500 --> 00:40:23.680
some development work.


00:40:23.680 --> 00:40:25.320
And there are fewer than you might think.


00:40:25.320 --> 00:40:27.840
Like quite often feels like a really big task


00:40:27.840 --> 00:40:30.000
because most people get stuck in this,


00:40:30.000 --> 00:40:33.960
oh no, it's time to do the dependency upgrades this quarter


00:40:33.960 --> 00:40:36.480
and you have like a seven week project


00:40:36.480 --> 00:40:38.520
that you're like trying to figure out which dependency


00:40:38.520 --> 00:40:40.200
is the one that's making all your tests fail.


00:40:40.200 --> 00:40:41.640
And you're like changing 50 lines


00:40:41.640 --> 00:40:43.480
and your requirements.txt all at once.


00:40:43.480 --> 00:40:45.280
If you don't do that,


00:40:45.280 --> 00:40:47.360
and by the time you're upgrading the one library


00:40:47.360 --> 00:40:50.200
that really does have a big breaking API change,


00:40:50.200 --> 00:40:52.040
it's not actually that hard,


00:40:52.040 --> 00:40:54.560
as long as everything else is already up to date.


00:40:54.560 --> 00:40:57.480
- Yeah, and usually there's one or two libraries


00:40:57.480 --> 00:41:00.080
that are massive, like Django or Flask.


00:41:00.080 --> 00:41:01.560
And then it's all the little dependencies


00:41:01.560 --> 00:41:05.440
that probably require no effort on your part.


00:41:05.440 --> 00:41:09.600
So one other thing that I switched to,


00:41:09.600 --> 00:41:11.600
you talked about dependabot, which is really great.


00:41:11.600 --> 00:41:14.300
I have Dependabot turned on for my stuff,


00:41:14.300 --> 00:41:16.700
but I started using pip compile,


00:41:16.700 --> 00:41:19.940
where it'll go and basically you give it an in file


00:41:19.940 --> 00:41:22.140
and it'll build your requirements.txt,


00:41:22.140 --> 00:41:24.880
and it'll even say like, this thing is here


00:41:24.880 --> 00:41:27.380
because it depends, you installed Flask,


00:41:27.380 --> 00:41:29.780
that's why it's dangerous, is here, for example.


00:41:29.780 --> 00:41:33.380
And I really like having that 'cause it's just,


00:41:33.380 --> 00:41:36.560
this week I'll go and I'll run it


00:41:36.560 --> 00:41:38.860
and it'll tell me what the new requirements are.


00:41:38.860 --> 00:41:41.500
I'm actively knowing that's happening,


00:41:41.500 --> 00:41:43.900
and I'll sort of process it and go with it.


00:41:43.900 --> 00:41:44.860
What do you all think?


00:41:44.860 --> 00:41:47.400
Emily, are you using Dependabot or something else?


00:41:47.400 --> 00:41:51.220
- Yeah, we do use Dependabot.


00:41:51.220 --> 00:41:54.660
I think another interesting like integral piece


00:41:54.660 --> 00:41:56.580
of being able to upgrade your dependencies


00:41:56.580 --> 00:42:00.300
is having tests that give you the confidence that you can.


00:42:00.300 --> 00:42:02.420
So do you feel confident to say,


00:42:02.420 --> 00:42:06.900
yes, our upgraded dependencies passed our test suite,


00:42:06.900 --> 00:42:08.100
therefore we can upgrade,


00:42:08.100 --> 00:42:10.120
or is there something that is gonna require somebody else


00:42:10.120 --> 00:42:12.080
and go in and look at it.


00:42:12.080 --> 00:42:14.360
But yeah, I think we've come a really long way


00:42:14.360 --> 00:42:16.080
in terms of dependency management.


00:42:16.080 --> 00:42:20.520
I do not miss the giant requirements.txt files


00:42:20.520 --> 00:42:23.000
that had all the dependencies of dependencies


00:42:23.000 --> 00:42:24.440
of dependencies all the way down


00:42:24.440 --> 00:42:26.620
and you didn't know what you had installed


00:42:26.620 --> 00:42:28.080
versus another library.


00:42:28.080 --> 00:42:28.920
- Yeah, exactly.


00:42:28.920 --> 00:42:31.080
- I also like things like pip compile


00:42:31.080 --> 00:42:35.040
because it lets you have a little bit more control


00:42:35.040 --> 00:42:37.680
over the child dependencies


00:42:37.680 --> 00:42:41.880
versus relying on a top level library like Django


00:42:41.880 --> 00:42:43.680
to specify their own requirements


00:42:43.680 --> 00:42:46.520
in a way that works for your organization.


00:42:46.520 --> 00:42:47.360
- Yeah, cool.


00:42:47.360 --> 00:42:48.520
Henrik?


00:42:48.520 --> 00:42:50.720
- Oh yeah, we use pip-tools too.


00:42:50.720 --> 00:42:52.480
I've blogged about it at some point


00:42:52.480 --> 00:42:56.200
that I like this approach with having small sharp tools


00:42:56.200 --> 00:42:59.440
that work well and pip-tools is one of them.


00:42:59.440 --> 00:43:00.720
- Yeah, absolutely.


00:43:00.720 --> 00:43:02.800
So I also use Dependabot, like I said,


00:43:02.800 --> 00:43:05.760
and if you go and run pip-tools,


00:43:05.760 --> 00:43:08.160
and then you commit that back to the repo,


00:43:08.160 --> 00:43:10.120
Dependabot will notice that that's been upgraded


00:43:10.120 --> 00:43:11.800
and it will automatically close the PR.


00:43:11.800 --> 00:43:14.500
So there's kind of a nice match between them as well.


00:43:14.500 --> 00:43:17.200
- Yeah, the answers to all these questions


00:43:17.200 --> 00:43:19.720
are really so much simpler than they used to be,


00:43:19.720 --> 00:43:21.360
you know, five, six years ago.


00:43:21.360 --> 00:43:25.120
I've been using requires.io for probably almost a decade


00:43:25.120 --> 00:43:29.200
and Dependabot is much better,


00:43:29.200 --> 00:43:30.720
largely because it defaults


00:43:30.720 --> 00:43:33.000
to just sending you those individual upgrades


00:43:33.000 --> 00:43:34.600
and you can really tune how much stuff


00:43:34.600 --> 00:43:36.400
that's gonna try to do it once.


00:43:36.400 --> 00:43:40.980
So yeah, mostly the answer on this is like,


00:43:40.980 --> 00:43:42.760
make something that builds your Docker container


00:43:42.760 --> 00:43:46.520
or whatever your fully realized application artifact is,


00:43:46.520 --> 00:43:51.520
run it all the time and have part of that process be like,


00:43:51.520 --> 00:43:53.560
freeze your dependencies, pin everything.


00:43:53.560 --> 00:43:55.000
You need to make sure that everything is pinned


00:43:55.000 --> 00:43:57.760
so that you get very reliable, repeatable builds.


00:43:57.760 --> 00:43:59.220
But having done that,


00:44:00.040 --> 00:44:05.040
you can really just bask in the cornucopia of tools


00:44:05.040 --> 00:44:06.640
that we have available to do this now


00:44:06.640 --> 00:44:08.160
that make it all pretty easy.


00:44:08.160 --> 00:44:10.660
- Yeah, it's definitely getting easier and easier.


00:44:10.660 --> 00:44:13.820
Let's talk about performance a little bit.


00:44:13.820 --> 00:44:16.300
I guess maybe I'll show just really quickly,


00:44:16.300 --> 00:44:19.000
I'll throw out there that at sneak.io,


00:44:19.000 --> 00:44:23.100
as in YK.io, they've got some stuff where you can put in


00:44:23.100 --> 00:44:26.600
like a package or something like that.


00:44:26.600 --> 00:44:28.200
Let's see.


00:44:28.200 --> 00:44:29.600
I don't remember where you...


00:44:29.600 --> 00:44:32.180
where you go to do it, but you can basically put in like a Python package,


00:44:32.180 --> 00:44:34.580
it'll give you a security report for it. So that's,


00:44:34.580 --> 00:44:38.380
I don't know how accurate that turns out to be for everything, but it's,


00:44:38.380 --> 00:44:40.880
it's something, but let's talk about performance.


00:44:40.880 --> 00:44:43.540
And one thing I'd like to touch on is actually,


00:44:43.540 --> 00:44:46.100
can we just say one more thing about security before we move on?


00:44:46.100 --> 00:44:50.060
Because a Henek mentioned encryption and not trusting your local network at the


00:44:50.060 --> 00:44:52.060
beginning. And one other thing I wanted to mention,


00:44:52.060 --> 00:44:55.620
speaking of tools that are much better than they used to be,


00:44:55.660 --> 00:45:04.960
One popular idiom is to like have a production mode that has all your encryption on and a development mode where you like just turn it all off for convenience.


00:45:04.960 --> 00:45:16.280
And I'm a big fan of setting up like an entry in your hosts file for each developer and having some infrastructure for provisioning certificates for individual developer machines.


00:45:16.540 --> 00:45:18.900
So that encryption is just always on.


00:45:18.900 --> 00:45:21.300
Nobody ever makes a connection without TLS on it.


00:45:21.300 --> 00:45:27.100
Even your like local API stubs still have some kind of, TLS on them.


00:45:27.100 --> 00:45:30.540
Because it's actually not all that hard, particularly with let's encrypt.


00:45:30.540 --> 00:45:34.720
You get a couple of DNS plugins and you can easily vend those certificates to your dev team.


00:45:34.720 --> 00:45:36.480
It takes a couple of days of work at most.


00:45:36.480 --> 00:45:42.820
And, having done that, not only are you more secure because you just don't even have that switch


00:45:42.840 --> 00:45:46.480
anymore to like accidentally be sending everything in plain text.


00:45:46.480 --> 00:45:49.800
But also you spot a surprising number of configuration issues.


00:45:49.800 --> 00:45:55.800
And like you get to see how you're like for real certificates work


00:45:55.800 --> 00:45:57.280
while you're doing development.


00:45:57.280 --> 00:46:00.200
And that can really help a lot of developers like understand what's going on


00:46:00.200 --> 00:46:04.280
with the somewhat tricky world of of HTTPS.


00:46:04.280 --> 00:46:06.760
All right. It's just running a little bit closer to production.


00:46:06.760 --> 00:46:09.200
Yeah. Yeah.


00:46:09.200 --> 00:46:11.000
All right. Let's talk about performance.


00:46:11.000 --> 00:46:13.760
And I'll just put this up on the screen because I think it's a fun thing.


00:46:13.760 --> 00:46:15.760
Have you all seen locust.io?


00:46:15.760 --> 00:46:20.280
Yeah, we use it regularly for load testing.


00:46:20.280 --> 00:46:22.600
Do you? Yeah. Maybe tell people about it real quick.


00:46:22.600 --> 00:46:25.080
I've used it once or twice and it's fantastic.


00:46:25.080 --> 00:46:30.120
Yeah, definitely. So it's a tool that allows you to essentially write a script


00:46:30.120 --> 00:46:33.840
that will emulate requests to your server


00:46:33.840 --> 00:46:35.840
and then you can give it a variety of...


00:46:37.920 --> 00:46:41.280
Wow, mom brain with no sleep makes me forget words.


00:46:41.280 --> 00:46:42.920
(laughing)


00:46:42.920 --> 00:46:44.320
But basically just like different parameters


00:46:44.320 --> 00:46:46.160
that you can specify.


00:46:46.160 --> 00:46:48.240
So it makes it really easy to say like,


00:46:48.240 --> 00:46:52.280
here is the approximate randomized behavior


00:46:52.280 --> 00:46:53.680
for a single user,


00:46:53.680 --> 00:46:56.440
and then scale it up to hundreds or thousands of users


00:46:56.440 --> 00:46:58.680
and see how your server handles it.


00:46:58.680 --> 00:47:00.400
- Right, you give it a Python script,


00:47:00.400 --> 00:47:01.920
which is really interesting, right?


00:47:01.920 --> 00:47:03.200
You create a class and you say,


00:47:03.200 --> 00:47:05.280
here's a typical user of this type,


00:47:05.280 --> 00:47:07.480
and it does different things like,


00:47:07.480 --> 00:47:10.040
it'll call the index page, it'll call the about page,


00:47:10.040 --> 00:47:11.560
it'll go do a search.


00:47:11.560 --> 00:47:14.120
And you can say things like,


00:47:14.120 --> 00:47:17.400
there's gonna be a certain amount of delay between pages.


00:47:17.400 --> 00:47:20.160
And then you can, as you said, scale that up and say like,


00:47:20.160 --> 00:47:25.160
I want 2,700 regular users and 50 admin users


00:47:25.160 --> 00:47:28.840
and let them go crawl around on the site


00:47:28.840 --> 00:47:30.200
and do what they do, right?


00:47:30.200 --> 00:47:32.440
- Yeah.


00:47:32.440 --> 00:47:33.900
- Yeah, so super cool.


00:47:33.900 --> 00:47:36.760
And the, like the real time dashboard is neat.


00:47:36.760 --> 00:47:39.760
So if you want to know about your performance,


00:47:39.760 --> 00:47:42.640
you could use this, but how do you all think


00:47:42.640 --> 00:47:45.000
about performance before the apps,


00:47:45.000 --> 00:47:46.900
either you're running or delivering,


00:47:46.900 --> 00:47:49.940
what's fast enough, what's just wasting your time,


00:47:49.940 --> 00:47:52.400
giving the last millisecond of response time?


00:47:52.400 --> 00:47:57.800
- So I'm gonna make the bold statement


00:47:57.800 --> 00:48:01.360
that for the vast majority of developers,


00:48:01.360 --> 00:48:03.360
Python is fast enough.


00:48:03.360 --> 00:48:05.240
- Oh yeah, absolutely.


00:48:05.240 --> 00:48:07.860
It is fast enough to saturate a database.


00:48:07.860 --> 00:48:09.460
And once your database is saturated,


00:48:09.460 --> 00:48:11.220
you have different problems.


00:48:11.220 --> 00:48:14.620
There's definitely things for which it is a problem.


00:48:14.620 --> 00:48:17.620
Like you cannot saturate an LDAP server, for example.


00:48:17.620 --> 00:48:18.860
I know that because I tried


00:48:18.860 --> 00:48:21.580
and it's one of our go services.


00:48:21.580 --> 00:48:26.000
But it would be nice if Python could be faster.


00:48:26.000 --> 00:48:29.320
And I'm very excited about GDL's performance task force


00:48:29.320 --> 00:48:30.660
at Microsoft, it's great.


00:48:32.700 --> 00:48:37.700
But I feel like the indifference that the no-jill movement


00:48:37.700 --> 00:48:42.780
has been shown, kind of shows that nobody really thinks


00:48:42.780 --> 00:48:44.760
that intensively about it anymore.


00:48:44.760 --> 00:48:48.140
Like for most people, it's fine.


00:48:48.140 --> 00:48:50.440
It's not good, it's not great, it's fine.


00:48:50.440 --> 00:48:53.040
And I mean, Instagram is printing money with it, so.


00:48:53.040 --> 00:48:57.580
- They absolutely are.


00:48:57.580 --> 00:49:00.020
Yeah, you know, you can go and put your site


00:49:00.020 --> 00:49:04.340
into PageSpeed Insights and see what you get.


00:49:04.340 --> 00:49:08.340
And yeah, I think once you get down


00:49:08.340 --> 00:49:11.040
to several millisecond response time per page,


00:49:11.040 --> 00:49:15.700
it just, you know, there's not a whole lot you can do


00:49:15.700 --> 00:49:16.520
to make it faster.


00:49:16.520 --> 00:49:20.380
There's not a lot of benefit to doing that work, right?


00:49:20.380 --> 00:49:22.820
- It's mostly tuning a database with the right indexes


00:49:22.820 --> 00:49:24.980
and caching, that's the two things.


00:49:24.980 --> 00:49:25.820
- Yeah.


00:49:25.820 --> 00:49:28.340
- And everything else is like the last 10% or something.


00:49:28.340 --> 00:49:29.160
- Yeah, absolutely.


00:49:29.160 --> 00:49:31.600
- Well, what I wanted to definitely emphasize here


00:49:31.600 --> 00:49:33.160
and hear your thoughts,


00:49:33.160 --> 00:49:35.600
I feel like there's so many times I go to some page


00:49:35.600 --> 00:49:36.920
and doesn't necessarily, some site,


00:49:36.920 --> 00:49:39.280
doesn't necessarily have to be Python.


00:49:39.280 --> 00:49:41.580
It's just some database fact page.


00:49:41.580 --> 00:49:43.360
And you go there and it's sitting on


00:49:43.360 --> 00:49:45.500
what seems like one of their primary pages.


00:49:45.500 --> 00:49:47.800
And it's like five seconds till it responds


00:49:47.800 --> 00:49:49.480
or several seconds even.


00:49:49.480 --> 00:49:51.680
It's like, what is this thing doing?


00:49:51.680 --> 00:49:55.600
And I just, I know they don't have indexes in their database.


00:49:55.600 --> 00:49:56.720
They just, they can't.


00:49:58.080 --> 00:50:02.180
So, you know, I just want to put out a plea for please use


00:50:02.180 --> 00:50:05.120
like some database profiling feature.


00:50:05.120 --> 00:50:07.800
Please look at your queries and please put an index.


00:50:07.800 --> 00:50:09.320
That's so incredibly easy.


00:50:09.320 --> 00:50:12.080
Like any of y'all want to rant on that with me?


00:50:12.080 --> 00:50:15.120
- I need to bring up one tool before we talk about this


00:50:15.120 --> 00:50:17.880
and it's called PG Mustard.


00:50:17.880 --> 00:50:18.720
- Okay.


00:50:18.720 --> 00:50:21.120
- Because I've never been able to fully understand


00:50:21.120 --> 00:50:22.440
and explain statement.


00:50:22.440 --> 00:50:25.560
Like I learned it many times and then I forgot it again.


00:50:25.560 --> 00:50:27.280
And PG Mustard is amazing.


00:50:27.280 --> 00:50:31.320
you just take an explain, you copy paste it into a web app


00:50:31.320 --> 00:50:33.840
and it tells you exactly what's going wrong.


00:50:33.840 --> 00:50:35.160
- Oh, nice.


00:50:35.160 --> 00:50:37.400
- And I've shaved, like I had like one query


00:50:37.400 --> 00:50:39.640
which is like very big, it's from a financial system.


00:50:39.640 --> 00:50:43.880
And I've, I think like 66% of the current runtime


00:50:43.880 --> 00:50:45.160
I was able to shave off.


00:50:45.160 --> 00:50:46.920
- Yeah.


00:50:46.920 --> 00:50:47.800
- Just because there was an index,


00:50:47.800 --> 00:50:51.700
but it was set up wrong and it was amazing.


00:50:51.700 --> 00:50:54.240
- Yeah, so here's a really beautiful visual thing.


00:50:54.240 --> 00:50:57.900
And it's also a bit of like a profiler.


00:50:57.900 --> 00:51:00.480
So it says on this part of the query statement,


00:51:00.480 --> 00:51:02.300
you spent 0.4% of the time


00:51:02.300 --> 00:51:05.060
and this part you spent 58% of the time.


00:51:05.060 --> 00:51:07.080
- Yeah, it also tells you what to do.


00:51:07.080 --> 00:51:07.980
That's the best part.


00:51:07.980 --> 00:51:09.900
It doesn't just tell you what's in it,


00:51:09.900 --> 00:51:14.860
but do this, make this index, things like that.


00:51:14.860 --> 00:51:15.700
- Okay.


00:51:15.700 --> 00:51:18.180
I've never seen this before.


00:51:18.180 --> 00:51:19.100
This is fantastic.


00:51:19.100 --> 00:51:23.880
Emily, thoughts on indexes?


00:51:23.880 --> 00:51:25.880
Join my plea.


00:51:25.880 --> 00:51:32.040
Yeah, I mean, so I think that piece of it is definitely very important, like making


00:51:32.040 --> 00:51:35.960
sure that you're doing those sort of basic things to get you to that, you know, 80 to


00:51:35.960 --> 00:51:40.080
90% performance potential.


00:51:40.080 --> 00:51:46.240
But I would also argue that these days, in a vast majority of applications, you're going


00:51:46.240 --> 00:51:49.120
to have a decoupled front end from your back end.


00:51:49.120 --> 00:51:55.960
And I would argue that making sure that you're implementing best practices for user experience


00:51:55.960 --> 00:52:01.000
on your front end is going to give you so much more payoff than trying to optimize that


00:52:01.000 --> 00:52:05.160
API call by a few milliseconds.


00:52:05.160 --> 00:52:10.460
So previously I had pulled up the PageSpeed Insights before, right?


00:52:10.460 --> 00:52:15.520
And at pagespeed.web.dev from Google, I believe.


00:52:15.520 --> 00:52:21.120
And what's really interesting about that is if you go and put your site into there, it


00:52:21.120 --> 00:52:23.360
doesn't feel fantastic to do it, by the way.


00:52:23.360 --> 00:52:28.720
So if you go and you put your site in here, you at some point might get a good number.


00:52:28.720 --> 00:52:32.840
I'm getting 100 out of 100 on the TalkByThen training site right now, but that's because


00:52:32.840 --> 00:52:37.200
I spent three days addressing every little thing.


00:52:37.200 --> 00:52:39.120
Like this image is not sized right.


00:52:39.120 --> 00:52:42.460
This JavaScript is not bundled with that JavaScript.


00:52:42.460 --> 00:52:44.720
This element is being resized by the browser.


00:52:44.720 --> 00:52:47.400
you should make it the same size by default


00:52:47.400 --> 00:52:49.640
and just all of these little things.


00:52:49.640 --> 00:52:53.880
And it wasn't even about the server response time,


00:52:53.880 --> 00:52:55.500
which was always pretty low.


00:52:55.500 --> 00:52:57.680
It's about all the other stuff.


00:52:57.680 --> 00:53:00.520
It's like, how does it feel to the user to get to the page


00:53:00.520 --> 00:53:05.520
rather than what is the HTML out of the server response time?


00:53:05.520 --> 00:53:07.600
That's what you're talking about, right?


00:53:07.600 --> 00:53:08.440
That kind of stuff?


00:53:08.440 --> 00:53:09.260
- Yep.


00:53:09.260 --> 00:53:10.100
Yeah, yeah, definitely.


00:53:10.100 --> 00:53:12.840
- Awesome, all right.


00:53:12.840 --> 00:53:15.900
So I have so many feelings about this.


00:53:15.900 --> 00:53:19.920
This is probably the number two topic for me behind packaging.


00:53:19.920 --> 00:53:22.800
So yeah, so those of you not listening on the live stream,


00:53:22.800 --> 00:53:24.580
if this next part sounds choppy, it's


00:53:24.580 --> 00:53:26.280
because I talked for an hour and a half,


00:53:26.280 --> 00:53:29.520
and Michael had to edit it down.


00:53:29.520 --> 00:53:30.360
>> Just cut him off.


00:53:30.360 --> 00:53:31.320
Just had to cut him off.


00:53:31.320 --> 00:53:33.760
He lost his voice.


00:53:33.760 --> 00:53:36.200
>> But seriously, the thing that I think is most important


00:53:36.200 --> 00:53:41.920
is quite often the parts of your application that end up


00:53:41.920 --> 00:53:46.920
being the performance issues are once you're past this step.


00:53:46.920 --> 00:53:48.480
Now there are lots of like,


00:53:48.480 --> 00:53:50.760
you all have been mostly talking about websites


00:53:50.760 --> 00:53:53.700
except for Henek mentioning LDAP, which is an interesting.


00:53:53.700 --> 00:53:57.960
- I've never really thought about scaling that one, no.


00:53:57.960 --> 00:54:01.160
- I have also scaled LDAP.


00:54:01.160 --> 00:54:03.720
And so the two major applications


00:54:03.720 --> 00:54:05.640
that I've dealt with performance issues on


00:54:05.640 --> 00:54:08.760
are an internal calendaring service


00:54:08.760 --> 00:54:10.680
that I maintained a large company


00:54:10.680 --> 00:54:12.120
that you can figure out which one it is


00:54:12.120 --> 00:54:13.600
by reading my Wikipedia page.


00:54:13.600 --> 00:54:18.920
And pilot.com's internal bookkeeping automations.


00:54:18.920 --> 00:54:21.320
And in both of those, so number one,


00:54:21.320 --> 00:54:25.200
the calendar service was an API with no front end.


00:54:25.200 --> 00:54:28.320
The front end was maintained by the client teams


00:54:28.320 --> 00:54:30.600
that were not even doing web stuff.


00:54:30.600 --> 00:54:34.960
And the way that we had to performance test that


00:54:34.960 --> 00:54:39.960
involved standing up our own custom load generation tool


00:54:39.960 --> 00:54:44.960
and running it as kind of a qualification process for our deployments.


00:54:44.960 --> 00:54:51.960
And the reason that I bring up that one is it's interesting because we had to figure out what our actual interesting load patterns were.


00:54:51.960 --> 00:54:58.960
We couldn't use any of these like standard HTTP load generation things because we needed very specific data.


00:54:58.960 --> 00:55:03.960
And that often ends up being the problem that you're facing.


00:55:03.960 --> 00:55:09.480
We on that service in particular, we had performance problems that arose because we added too many


00:55:09.480 --> 00:55:10.900
indexes.


00:55:10.900 --> 00:55:13.920
So we were having problems on the right side of the equation, right?


00:55:13.920 --> 00:55:19.240
Every time you add an index, you're, you're optimizing read at the expense of write.


00:55:19.240 --> 00:55:23.740
And usually it's like a lot of read performance with that for a little write performance,


00:55:23.740 --> 00:55:25.360
but eventually it does add up.


00:55:25.360 --> 00:55:26.360
It does.


00:55:26.360 --> 00:55:27.360
Yeah.


00:55:27.360 --> 00:55:29.920
You can, you can go out in the audience says, yeah, you gotta be careful adding too many


00:55:29.920 --> 00:55:32.100
indexes as well.


00:55:32.100 --> 00:55:36.720
You know, there's two parts to that, right, Cliff?


00:55:36.720 --> 00:55:38.640
One part is when you write something,


00:55:38.640 --> 00:55:40.880
the indexes have to be computed for that thing that's


00:55:40.880 --> 00:55:41.440
going in.


00:55:41.440 --> 00:55:44.400
And the other is more indexes mean more stuff in memory.


00:55:44.400 --> 00:55:46.360
And so another really important aspect


00:55:46.360 --> 00:55:50.520
is, does the totality of your indexes reside in memory,


00:55:50.520 --> 00:55:52.800
or does it have to get paged out?


00:55:52.800 --> 00:55:54.600
And so you would hit that problem,


00:55:54.600 --> 00:55:56.680
both of those problems, you would run into


00:55:56.680 --> 00:55:58.440
by having too many indexes.


00:55:58.440 --> 00:56:00.400
Right, and you really need to-- so you


00:56:00.400 --> 00:56:04.960
need to be ready to measure things because you don't necessarily know.


00:56:04.960 --> 00:56:09.400
Like, I mean, this is that, you know, old chestnut about, not really,


00:56:09.400 --> 00:56:12.600
you know, premature optimization, not knowing what the hotspots are until you


00:56:12.600 --> 00:56:14.680
run them, but that also means, so there's two things about that.


00:56:14.680 --> 00:56:17.200
One, the tools for doing this are not great.


00:56:17.200 --> 00:56:22.280
Like the one that I really wish were good and just isn't is speed center,


00:56:22.280 --> 00:56:26.120
which, twisted and PII PII used to monitor their performance over time.


00:56:26.120 --> 00:56:28.600
Like what's the performance of each revision of the code is.


00:56:29.520 --> 00:56:34.080
And there's nothing like, you know, GitHub actions or Travis CI,


00:56:34.080 --> 00:56:38.280
there's no sort of leader in that field that will just tell you like,


00:56:38.280 --> 00:56:41.360
"Hey, your performance regressed by 10% on this commit."


00:56:41.360 --> 00:56:44.640
And that is the tool which I desperately want to exist.


00:56:44.640 --> 00:56:47.640
And so most of the things that I do are trying to approximate that.


00:56:47.640 --> 00:56:52.280
Part of that is making sure you have metrics in production that are telling you


00:56:52.280 --> 00:56:53.960
so that you notice when things are slow,


00:56:53.960 --> 00:56:57.400
you don't want to be having users telling you or even really like,


00:56:58.080 --> 00:57:00.320
If you're getting the bad performance metrics


00:57:00.320 --> 00:57:01.920
out of your load testing tool,


00:57:01.920 --> 00:57:03.700
and that's a surprise to you,


00:57:03.700 --> 00:57:05.720
that means you're probably not instrumenting enough


00:57:05.720 --> 00:57:07.160
in prod to know like,


00:57:07.160 --> 00:57:09.080
oh, users are seeing some slowness here.


00:57:09.080 --> 00:57:11.520
'Cause you're also gonna get things where like,


00:57:11.520 --> 00:57:13.000
your database is doing great,


00:57:13.000 --> 00:57:14.680
everything seems like it's super fast,


00:57:14.680 --> 00:57:16.480
but your queries are actually really slow.


00:57:16.480 --> 00:57:17.720
They're just all running in memory.


00:57:17.720 --> 00:57:19.040
And then you hit the cliff


00:57:19.040 --> 00:57:20.840
where suddenly you're hitting the disk.


00:57:20.840 --> 00:57:22.680
And now everything's much, much slower


00:57:22.680 --> 00:57:24.360
and none of your code changed.


00:57:24.360 --> 00:57:27.120
And your data only grew by like 10%.


00:57:27.120 --> 00:57:31.480
And being able to spot stuff like that means you have to be looking at perf in prod.


00:57:31.480 --> 00:57:34.320
You can't do synthetic tests for everything.


00:57:34.320 --> 00:57:44.920
And it's and particularly if you have a large site with a lot of users, it's very easy to miss if your, you know, 95th percentile is falling off a cliff, right?


00:57:44.920 --> 00:57:51.880
Like you have to you have to be looking at at your core tiles and like all of these different things, not just like average performance.


00:57:53.280 --> 00:57:57.720
And the second part of that is the data,


00:57:57.720 --> 00:58:00.360
custom data generation for your synthetic tests.


00:58:00.360 --> 00:58:01.920
So for example, on the,


00:58:01.920 --> 00:58:04.040
so the calendar service had those issues


00:58:04.040 --> 00:58:07.280
that I just mentioned and pilot service had this issue


00:58:07.280 --> 00:58:10.860
where most of the performance stuff was not the database.


00:58:10.860 --> 00:58:14.840
It was talking to APIs to pull in financial transactions


00:58:14.840 --> 00:58:16.080
and analyze them.


00:58:16.080 --> 00:58:18.240
And it was those APIs being slow,


00:58:18.240 --> 00:58:21.760
us being silly and not talking to those APIs in parallel,


00:58:21.760 --> 00:58:26.960
data volumes just being huge, like thousands and thousands and thousands of transactions,


00:58:26.960 --> 00:58:32.480
excuse me, in a single call. And that you have to know that that's going to happen. And you have to


00:58:32.480 --> 00:58:40.880
be able to on demand, add to your test suite or your performance test suite, new types of data.


00:58:40.880 --> 00:58:46.480
And that performance tool with where you like write Python code looks like a great way to do that. I


00:58:46.480 --> 00:58:47.920
I actually had never used that one.


00:58:47.920 --> 00:58:49.160
- This thing is glorious.


00:58:49.160 --> 00:58:50.000
- Yeah.


00:58:50.000 --> 00:58:52.080
What was it, locust.io?


00:58:52.080 --> 00:58:52.920
- Locust.io, yeah.


00:58:52.920 --> 00:58:56.200
And it has the dynamic sort of graphs and dashboards


00:58:56.200 --> 00:58:58.400
show you sort of as it ramps up and as you change it.


00:58:58.400 --> 00:59:01.560
Yeah, it's, I think that might give you like the right,


00:59:01.560 --> 00:59:04.040
'cause you basically structure with Python


00:59:04.040 --> 00:59:07.520
how it hammers on the server, which is pretty neat.


00:59:07.520 --> 00:59:10.100
- Yeah, and the one thing I'd say about that was,


00:59:10.100 --> 00:59:12.140
is you need to do that.


00:59:12.140 --> 00:59:14.240
You will need to write custom stuff.


00:59:14.240 --> 00:59:16.240
Don't just assume you can like add a couple indexes.


00:59:16.240 --> 00:59:19.240
Like you should just add a couple indexes at first


00:59:19.240 --> 00:59:21.800
if performance is not your primary concern.


00:59:21.800 --> 00:59:24.040
But having done that, you have to know


00:59:24.040 --> 00:59:25.800
you're gonna need to think about perf


00:59:25.800 --> 00:59:29.320
and like write code to monitor it.


00:59:29.320 --> 00:59:31.600
- Yeah, absolutely.


00:59:31.600 --> 00:59:35.000
All right, I think we're just about out of time,


00:59:35.000 --> 00:59:37.400
although we barely scratched the surface


00:59:37.400 --> 00:59:40.040
of all the stuff we could talk about.


00:59:40.040 --> 00:59:42.040
Let me ask, let's close out with this question.


00:59:42.040 --> 00:59:45.960
Do any of you have, sounds like maybe


00:59:45.960 --> 00:59:52.280
you've thought about this, you have CI performance checks


00:59:52.280 --> 00:59:54.600
or failures or anything like that, right?


00:59:54.600 --> 00:59:56.440
Like we have run our tests, the build


00:59:56.440 --> 00:59:58.700
doesn't pass if the tests don't pass,


00:59:58.700 --> 01:00:00.960
but do you have something like that for performance?


01:00:00.960 --> 01:00:07.000
That's the thing I want to exist, and I've never managed.


01:00:07.000 --> 01:00:09.800
I've done things that approximate it within tests,


01:00:09.800 --> 01:00:11.840
but never gotten it really--


01:00:11.840 --> 01:00:13.440
I have nothing like that either.


01:00:13.440 --> 01:00:15.840
Emily?


01:00:15.840 --> 01:00:20.640
No, I mean, I think the closest approximation that we get is we focus a lot on


01:00:20.640 --> 01:00:23.600
uh


01:00:23.600 --> 01:00:25.280
Like cypress tests for front end


01:00:25.280 --> 01:00:31.760
So actually the user going through and and working with the application and I think the closest thing that we could get at this point


01:00:31.760 --> 01:00:38.080
is just uh setting our max timeout in our like http service


01:00:38.080 --> 01:00:44.000
Bumping that down and saying like if anything's taking over 10 seconds to respond when we run the test then it should fail


01:00:44.560 --> 01:00:49.280
But no, I don't think we don't do any regular performance testing.


01:00:49.280 --> 01:00:51.280
Yeah. Henik?


01:00:51.280 --> 01:00:53.280
We do not know.


01:00:53.280 --> 01:00:56.560
Yeah, but we all kind of are like, that was kind of nice to have, I think.


01:00:56.560 --> 01:00:59.760
But yeah. There's a lot to set it up though, right?


01:00:59.760 --> 01:01:01.760
You've got to have enough data in the database for it to be meaningful.


01:01:01.760 --> 01:01:03.760
And that's tricky to do in CI.


01:01:03.760 --> 01:01:05.760
It would be cool though.


01:01:05.760 --> 01:01:07.760
All right, go ahead, Emily.


01:01:07.760 --> 01:01:09.760
I was just going to say, I think Glyph makes a really good point.


01:01:09.760 --> 01:01:11.760
I think that's a really good point, that the load testing


01:01:11.760 --> 01:01:14.760
and the manual testing of performance is great,


01:01:14.760 --> 01:01:17.760
especially when it's a prerequisite to launch.


01:01:17.760 --> 01:01:20.760
But there's no way that you're going to be able to replicate


01:01:20.760 --> 01:01:24.760
anything in production, and the best thing that you can do


01:01:24.760 --> 01:01:27.760
is monitor prod as closely as you can.


01:01:27.760 --> 01:01:30.760
Yeah, absolutely. Some of that real-time monitoring.


01:01:30.760 --> 01:01:33.760
Fantastic. All right, well, thank you all for being here.


01:01:33.760 --> 01:01:35.760
This has been super interesting to chat about.


01:01:35.760 --> 01:01:37.760
Before you got here, let me...


01:01:37.760 --> 01:01:40.120
I think I'll just put it down to one of the final two


01:01:40.120 --> 01:01:42.920
questions so that we don't take too long.


01:01:42.920 --> 01:01:44.880
But if you're going to write some Python code,


01:01:44.880 --> 01:01:45.840
what editor to use?


01:01:45.840 --> 01:01:47.560
Let's go clockwise.


01:01:47.560 --> 01:01:48.400
Henik, how about you?


01:01:48.400 --> 01:01:51.040
What are you writing code with these days?


01:01:51.040 --> 01:01:53.080
- Well, I have a long story of editors.


01:01:53.080 --> 01:01:56.040
I've used almost all of them at some point.


01:01:56.040 --> 01:01:58.160
Usually stopped using because I got crippled,


01:01:58.160 --> 01:01:59.720
like the Emacs Pinky.


01:01:59.720 --> 01:02:04.720
Nowadays, I usually use either Vim in a console or VS Code.


01:02:04.720 --> 01:02:06.240
- Okay, right on.


01:02:06.240 --> 01:02:07.060
Glyf?


01:02:07.060 --> 01:02:12.940
There's an implicit thing in this question where it sounds like you're recommending the


01:02:12.940 --> 01:02:13.940
thing that you use.


01:02:13.940 --> 01:02:17.860
I want to be clear that I'm not doing that.


01:02:17.860 --> 01:02:18.860
Don't do as I do.


01:02:18.860 --> 01:02:21.660
Yeah, I use Emacs.


01:02:21.660 --> 01:02:27.700
But with about 10 megabytes of custom Elisp, which I'm never going to share with anyone.


01:02:27.700 --> 01:02:28.700
You shouldn't use it.


01:02:28.700 --> 01:02:29.700
Just use VS Code.


01:02:29.700 --> 01:02:30.700
Awesome.


01:02:30.700 --> 01:02:31.700
Emily?


01:02:31.700 --> 01:02:32.700
VS Code all day.


01:02:32.700 --> 01:02:33.700
Okay.


01:02:33.700 --> 01:02:35.700
I'm not sure if I'm going to be able to do that.


01:02:35.700 --> 01:02:37.700
I'm not sure if I'm going to be able to do that.


01:02:37.700 --> 01:02:39.700
I'm not sure if I'm going to be able to do that.


01:02:39.700 --> 01:02:41.700
I'm not sure if I'm going to be able to do that.


01:02:41.700 --> 01:02:43.700
I'm not sure if I'm going to be able to do that.


01:02:43.700 --> 01:02:45.700
I'm not sure if I'm going to be able to do that.


01:02:45.700 --> 01:02:47.700
I'm not sure if I'm going to be able to do that.


01:02:47.700 --> 01:02:49.700
I'm not sure if I'm going to be able to do that.


01:02:49.700 --> 01:02:51.700
I'm not sure if I'm going to be able to do that.


01:02:51.700 --> 01:02:53.700
I'm not sure if I'm going to be able to do that.


01:02:53.700 --> 01:02:55.700
I'm not sure if I'm going to be able to do that.


01:02:55.700 --> 01:02:57.700
I'm not sure if I'm going to be able to do that.


01:02:57.700 --> 01:03:00.700
get your experience.


01:03:00.700 --> 01:03:01.900
Thanks so much for having us.


01:03:01.900 --> 01:03:02.740
Thanks for having us.


01:03:02.740 --> 01:03:03.500
Yeah, you bet.

