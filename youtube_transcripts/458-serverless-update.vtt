WEBVTT

00:00:00.000 --> 00:00:03.960
>> Tony, welcome to Talk Python To Me.

00:00:03.960 --> 00:00:06.080
>> Thank you. Thanks for having me.

00:00:06.080 --> 00:00:08.000
>> Fantastic to have you here.

00:00:08.000 --> 00:00:11.400
It's going to be really fun to talk about serverless.

00:00:11.400 --> 00:00:13.600
The joke with the Cloud is,

00:00:13.600 --> 00:00:15.520
well, I know you call it the Cloud,

00:00:15.520 --> 00:00:17.320
but it's really just somebody else's computer.

00:00:17.320 --> 00:00:19.240
But we're not even talking about computer,

00:00:19.240 --> 00:00:20.440
we're just talking about functions.

00:00:20.440 --> 00:00:21.600
Maybe it's someone else's function.

00:00:21.600 --> 00:00:23.400
I don't know, we're going to find out.

00:00:23.400 --> 00:00:28.120
>> Yeah. I saw a recent article about server-free.

00:00:28.120 --> 00:00:32.000
Recently, somebody trying to move completely.

00:00:32.000 --> 00:00:33.960
Because as you might know,

00:00:33.960 --> 00:00:36.960
serverless doesn't mean actually no servers.

00:00:36.960 --> 00:00:40.080
>> Of course. Server-free.

00:00:40.080 --> 00:00:44.520
We could just get the thing to run on the BitTorrent network.

00:00:44.520 --> 00:00:45.120
>> Right.

00:00:45.120 --> 00:00:47.120
>> Okay. I don't know.

00:00:47.120 --> 00:00:48.600
I don't know. We'll figure it out.

00:00:48.600 --> 00:00:50.040
But it's going to be super fun.

00:00:50.040 --> 00:00:53.960
We're going to talk about your experience working with serverless.

00:00:53.960 --> 00:00:57.040
We'll talk about some of the choices people have out there,

00:00:57.040 --> 00:01:00.080
and also some of the tools that we can

00:01:00.080 --> 00:01:04.320
use to do things like observe and test our serverless code.

00:01:04.320 --> 00:01:07.960
For that though, tell us a bit about yourself.

00:01:07.960 --> 00:01:13.360
>> Sure. I'm actually a career changer.

00:01:13.360 --> 00:01:17.960
I worked in the cable industry for about 10 years,

00:01:17.960 --> 00:01:23.040
and doing a lot of different things from installing,

00:01:23.040 --> 00:01:26.960
knock at the door cable guy to working on more of the outside plant,

00:01:26.960 --> 00:01:28.960
but at some point,

00:01:28.960 --> 00:01:34.280
I was seeing limits of career path there.

00:01:34.280 --> 00:01:37.360
My brother-in-law is a software engineer,

00:01:37.360 --> 00:01:41.000
and I had already started going back to school,

00:01:41.000 --> 00:01:42.360
finishing my degree, and I was like, "Okay,

00:01:42.360 --> 00:01:45.200
well, maybe I should look into this."

00:01:45.200 --> 00:01:47.360
I took an intro to programming class.

00:01:47.360 --> 00:01:48.680
It was in Python,

00:01:48.680 --> 00:01:52.480
and that led me down this path.

00:01:52.480 --> 00:01:54.840
Now for the past four years or so,

00:01:54.840 --> 00:01:56.920
I've been working professionally in the software world,

00:01:56.920 --> 00:02:01.560
started out in a QA role at an IoT company,

00:02:01.560 --> 00:02:07.840
and now doing a lot of serverless programming in Python these days.

00:02:07.840 --> 00:02:12.960
Second company now, but that does some school bus safety products.

00:02:12.960 --> 00:02:14.840
>> Interesting. Very cool.

00:02:14.840 --> 00:02:18.920
>> Yeah. But a lot of Python, a lot of serverless.

00:02:18.920 --> 00:02:22.080
>> Well, serverless and IoT,

00:02:22.080 --> 00:02:24.240
I feel like they go pretty hand in hand.

00:02:24.240 --> 00:02:29.320
>> Yes. Another thing is with serverless,

00:02:29.320 --> 00:02:33.400
is when you have very spiky traffic,

00:02:33.400 --> 00:02:35.080
like if you think about school buses,

00:02:35.080 --> 00:02:38.960
that you have a lot coming on twice a day.

00:02:38.960 --> 00:02:43.640
>> Exactly, like the 8 AM shift and then the 2.30 to 3.00 shift.

00:02:43.640 --> 00:02:45.880
>> Yeah. That's a really good use case for

00:02:45.880 --> 00:02:48.880
serverless or something like that.

00:02:48.880 --> 00:02:53.280
>> Are you enjoying doing the programming stuff,

00:02:53.280 --> 00:02:54.640
instead of the cable stuff?

00:02:54.640 --> 00:02:58.000
>> Absolutely. Sometimes I live in Michigan,

00:02:58.000 --> 00:03:04.320
so I look outside and look at the snow coming down or these storms.

00:03:04.320 --> 00:03:07.840
Some people are like, "You don't miss being outside?"

00:03:07.840 --> 00:03:10.120
I'm like, "Maybe every once in a while,

00:03:10.120 --> 00:03:12.880
but I can go walk outside on a nice day."

00:03:12.880 --> 00:03:15.120
>> You can choose to go outside.

00:03:15.120 --> 00:03:17.960
You're not made to go outside in the sleet or rain.

00:03:17.960 --> 00:03:18.920
>> Yeah.

00:03:18.920 --> 00:03:22.560
>> Yeah, absolutely. We just had a mega storm here,

00:03:22.560 --> 00:03:27.280
and just the huge tall trees here in Oregon just fell left and right.

00:03:27.280 --> 00:03:29.920
In every direction that I look,

00:03:29.920 --> 00:03:34.280
there's a large tree on top of one of the houses of my neighbors.

00:03:34.280 --> 00:03:35.000
>> Oh, man.

00:03:35.000 --> 00:03:36.240
>> Maybe a house or two over.

00:03:36.240 --> 00:03:40.720
But it just took out everything that was a cable in the air was taken out.

00:03:40.720 --> 00:03:43.080
It's just been a swarm of people who are out in

00:03:43.080 --> 00:03:47.360
13 degree Fahrenheit, negative nine Celsius weather.

00:03:47.360 --> 00:03:50.240
I'm thinking, not really choosing to be out there today probably.

00:03:50.240 --> 00:03:51.800
>> Right.

00:03:51.800 --> 00:03:56.640
>> Excellent. Well, thanks for that introduction.

00:03:56.640 --> 00:04:01.280
I guess maybe a lot of people probably know what serverless is,

00:04:01.280 --> 00:04:03.880
but I'm sure there's a lot who are not even really

00:04:03.880 --> 00:04:07.280
aware of what serverless programming is.

00:04:07.280 --> 00:04:10.160
Let's talk about what's the idea,

00:04:10.160 --> 00:04:12.320
what's the zen of this?

00:04:12.320 --> 00:04:18.680
>> Yeah. I made the joke that serverless doesn't mean there are no servers.

00:04:18.880 --> 00:04:22.320
Hopefully, I don't butcher it too much,

00:04:22.320 --> 00:04:25.320
but it's more like functions as a service.

00:04:25.320 --> 00:04:27.840
There's other things that can be serverless too,

00:04:27.840 --> 00:04:31.320
like there's serverless databases or

00:04:31.320 --> 00:04:34.920
a lot of different services that can be serverless,

00:04:34.920 --> 00:04:38.200
meaning you don't have to think about how to operate them,

00:04:38.200 --> 00:04:40.400
how to think about scaling them up.

00:04:40.400 --> 00:04:46.240
You don't have to spin up VMs or Kubernetes clusters or anything.

00:04:46.240 --> 00:04:48.600
You don't have to think about that part.

00:04:48.600 --> 00:04:52.280
It's just your code that goes into it.

00:04:52.280 --> 00:04:55.880
Serverless functions are probably what people are most familiar with,

00:04:55.880 --> 00:04:56.960
and that's, I'm sure,

00:04:56.960 --> 00:04:59.120
what we'll talk about most today.

00:04:59.120 --> 00:05:01.960
Yeah, that's really the idea.

00:05:01.960 --> 00:05:05.360
You don't have to manage the server.

00:05:05.360 --> 00:05:08.280
>> Sure. That's a huge barrier.

00:05:08.280 --> 00:05:13.920
I remember when I first started getting into web apps and programming,

00:05:13.920 --> 00:05:16.680
and then another level when I got into Python

00:05:16.680 --> 00:05:20.040
because I had not done that much Linux work.

00:05:20.040 --> 00:05:21.800
Getting stuff up running,

00:05:21.800 --> 00:05:23.320
it was really tricky.

00:05:23.320 --> 00:05:25.600
Then having the concern of,

00:05:25.600 --> 00:05:27.360
is it secure?

00:05:27.360 --> 00:05:29.640
How do I patch it? How do I back it up?

00:05:29.640 --> 00:05:31.680
How do I keep it going?

00:05:31.680 --> 00:05:35.400
All of those things, they're non-trivial.

00:05:35.400 --> 00:05:38.640
>> Right. Yeah. There's a lot to think about.

00:05:38.640 --> 00:05:41.560
If you work at an organization,

00:05:41.560 --> 00:05:43.840
it's probably different everywhere you go too,

00:05:43.840 --> 00:05:47.120
that how they manage their servers and things.

00:05:47.120 --> 00:05:52.280
Putting some stuff in the Cloud brings some commonality to it too.

00:05:52.280 --> 00:05:58.320
You can learn how the Azure Cloud or Google Cloud or AWS,

00:05:58.320 --> 00:06:02.200
how those things work and have some common ground too.

00:06:02.200 --> 00:06:11.600
>> Yeah, for sure. I also feel more accessible to the developers in a larger group,

00:06:11.600 --> 00:06:17.280
in a sense that not a DevOps team that takes care of the servers,

00:06:17.280 --> 00:06:20.160
or a production engineers where you hand them your code.

00:06:20.160 --> 00:06:22.280
It's a little closer to just,

00:06:22.280 --> 00:06:26.960
I have a function and then I get it up there and it continues to be the function.

00:06:26.960 --> 00:06:29.360
>> That is a different mindset too.

00:06:29.360 --> 00:06:34.280
You see it all the way through from writing your code to deploying it.

00:06:34.280 --> 00:06:39.720
Yeah. Without maybe an entire DevOps team that you just say,

00:06:39.720 --> 00:06:42.280
"Here you go, go deploy this."

00:06:42.280 --> 00:06:48.240
>> In my world, I mostly have virtual machines.

00:06:48.240 --> 00:06:51.320
I've moved over to a Docker cluster.

00:06:51.320 --> 00:06:57.480
I think I've got 17 different things running in the Docker cluster at the moment.

00:06:57.480 --> 00:07:02.040
But both of those are really different than serverless.

00:07:02.040 --> 00:07:05.120
It's been working well for me.

00:07:05.120 --> 00:07:09.200
But when I think about serverless,

00:07:09.200 --> 00:07:10.480
let me know if this is true.

00:07:10.480 --> 00:07:16.680
It feels like you don't need to have as much of a Linux,

00:07:16.680 --> 00:07:22.520
or server, or an ops experience to create these things.

00:07:22.520 --> 00:07:27.120
>> Yeah. I would say you could probably get away with almost none.

00:07:27.120 --> 00:07:35.080
At the simplest form with AWS, for instance,

00:07:35.080 --> 00:07:36.560
their Lambda functions,

00:07:36.560 --> 00:07:39.920
you can, and that's the one I'm most familiar with.

00:07:39.920 --> 00:07:42.600
Forgive me for using them as an example for everything.

00:07:42.600 --> 00:07:46.040
There's a lot of different serverless options.

00:07:46.040 --> 00:07:49.680
But you could go into the AWS console and you could

00:07:49.680 --> 00:07:55.880
actually write your Python code right in the console, deploy that.

00:07:55.880 --> 00:07:57.920
They have function URLs now.

00:07:57.920 --> 00:07:59.680
You could actually have,

00:07:59.680 --> 00:08:01.520
I mean, within a matter of minutes,

00:08:01.520 --> 00:08:04.800
you could have a serverless function set up.

00:08:04.800 --> 00:08:10.240
>> Yeah. AWS Lambda, that's the one.

00:08:10.240 --> 00:08:11.360
>> Yeah.

00:08:11.360 --> 00:08:14.080
>> Lambda being, I guess, a simple function.

00:08:14.080 --> 00:08:15.400
We have Lambdas in Python.

00:08:15.400 --> 00:08:16.920
They can only be one line.

00:08:16.920 --> 00:08:20.120
I'm sure you can have more than one line in the AWS Lambda.

00:08:20.120 --> 00:08:23.400
>> Yeah. There are limitations though with Lambda

00:08:23.400 --> 00:08:27.440
that are definitely some pain points that I ran into.

00:08:27.440 --> 00:08:29.560
>> Oh, really? Okay. What are some of the limitations?

00:08:29.560 --> 00:08:33.560
>> Yeah. Package size is one.

00:08:33.560 --> 00:08:39.000
If you start thinking about all these amazing packages on PyPI,

00:08:39.000 --> 00:08:44.320
you do have to start thinking about how many you're going to bring in.

00:08:44.320 --> 00:08:48.160
I don't know the exact limits off the top of my head,

00:08:48.160 --> 00:08:51.920
but it's pretty quick Google search on their package size.

00:08:51.920 --> 00:08:54.200
It might be like 50 megabytes zipped,

00:08:54.200 --> 00:09:00.080
but 250 when you decompress it to do a zip base.

00:09:00.080 --> 00:09:04.080
Then they do have containerized Lambda functions

00:09:04.080 --> 00:09:06.320
that go up to a 10 gig limit, so that helps.

00:09:06.320 --> 00:09:08.000
>> Interesting. Okay.

00:09:08.000 --> 00:09:12.000
>> Yeah. Those ones used to be less performant,

00:09:12.000 --> 00:09:14.760
but they're catching up to where they're.

00:09:14.760 --> 00:09:17.760
That was really on something called cold starts.

00:09:17.760 --> 00:09:19.880
But they're getting, I think,

00:09:19.880 --> 00:09:24.440
pretty close to it not being a very big difference,

00:09:24.440 --> 00:09:26.480
whether you dockerize or zip these functions.

00:09:26.480 --> 00:09:31.360
But yeah, so when you start just like pip install and everything,

00:09:31.360 --> 00:09:34.040
you've got to think about how to get that code into

00:09:34.040 --> 00:09:38.880
your function and how much it's going to bring in.

00:09:38.880 --> 00:09:44.760
Yeah, that definitely was a limitation that had to quickly learn.

00:09:44.760 --> 00:09:49.960
>> Yeah. I guess it's probably trying to do pip install -r effectively.

00:09:49.960 --> 00:09:51.200
>> Yeah.

00:09:51.200 --> 00:09:54.240
>> It's like you can't go overboard with this, right?

00:09:54.240 --> 00:09:56.920
>> Right. Yeah. When you start bringing in packages,

00:09:56.920 --> 00:10:02.680
like maybe some of the scientific packages,

00:10:02.680 --> 00:10:05.560
you're definitely going to be hitting some size limits.

00:10:05.560 --> 00:10:07.920
>> Okay. With the containerized ones,

00:10:07.920 --> 00:10:12.200
basically you could probably give it a Docker file and a command to run in it.

00:10:12.200 --> 00:10:16.720
It can build those images before and then just execute and just do a Docker run.

00:10:16.720 --> 00:10:20.080
>> Yeah. I think how those ones work is you store

00:10:20.080 --> 00:10:23.480
an image on their container registry,

00:10:23.480 --> 00:10:27.160
Amazon's ECR, I think.

00:10:27.160 --> 00:10:29.240
Then you point it at that and yeah,

00:10:29.240 --> 00:10:36.640
it'll execute your handler function when the Lambda gets called.

00:10:36.640 --> 00:10:39.040
>> Yeah. Excellent. Yeah.

00:10:39.040 --> 00:10:41.040
So out in the audience, Kim says,

00:10:41.040 --> 00:10:46.640
AWS does make a few packages available directly just by default in Lambda.

00:10:46.640 --> 00:10:49.680
>> Yeah. Yeah. Bodo,

00:10:49.680 --> 00:10:52.560
which if you're dealing with AWS and Python,

00:10:52.560 --> 00:10:55.800
you're using the Bodo package.

00:10:55.800 --> 00:10:57.640
Yeah. That's included for you.

00:10:57.640 --> 00:11:02.640
So that's definitely helpful in any of their transitive dependencies would be there.

00:11:02.640 --> 00:11:06.400
I think Bodo used to even include requests,

00:11:06.400 --> 00:11:10.720
but then I think they eventually dropped that with some SSL stuff.

00:11:10.720 --> 00:11:17.000
But yeah, you can't just pip install anything and not think of it,

00:11:17.000 --> 00:11:19.560
depending on how you package these up.

00:11:19.560 --> 00:11:21.560
>> Sure. That makes sense.

00:11:21.560 --> 00:11:25.040
Of course, they would include their own Python libraries, right?

00:11:25.040 --> 00:11:28.800
>> Yeah. It's not exactly small.

00:11:28.800 --> 00:11:33.320
I think Bodo core used to be like 60 megabytes,

00:11:33.320 --> 00:11:36.880
but I think they've done some work to really get that down.

00:11:36.880 --> 00:11:40.760
>> Yeah. That's not too bad.

00:11:40.760 --> 00:11:42.720
I feel like Bodo core,

00:11:42.720 --> 00:11:45.240
Bodo 3, those are constantly changing.

00:11:45.240 --> 00:11:46.440
Constantly.

00:11:46.440 --> 00:11:51.920
>> Yeah. Well, as fast as AWS add services,

00:11:51.920 --> 00:11:54.360
they'll probably keep changing quickly.

00:11:54.360 --> 00:11:57.480
>> Yeah. I feel like those are auto-generated maybe,

00:11:57.480 --> 00:12:00.120
just from looking at the way the API looks at it,

00:12:00.120 --> 00:12:01.960
the way they look written.

00:12:01.960 --> 00:12:05.480
>> Yeah. That's probably the case.

00:12:05.480 --> 00:12:11.720
Yeah. I know they do that with their infrastructure as code,

00:12:11.720 --> 00:12:14.320
CDK, it's all like TypeScript originally,

00:12:14.320 --> 00:12:16.880
and then you have your Python bindings for it.

00:12:16.880 --> 00:12:19.420
>> Right. It makes sense,

00:12:19.420 --> 00:12:23.000
but in the same time, when you see a change,

00:12:23.000 --> 00:12:24.560
it doesn't necessarily mean,

00:12:24.560 --> 00:12:26.960
there's a new important aspect added.

00:12:26.960 --> 00:12:29.320
It's probably just, I don't know,

00:12:29.320 --> 00:12:34.000
people have actually pulled up the console for AWS,

00:12:34.000 --> 00:12:36.720
but just the amount of services that are there,

00:12:36.720 --> 00:12:39.280
and then each one of those has its own full API,

00:12:39.280 --> 00:12:41.000
a little bit of the one of those has changed.

00:12:41.000 --> 00:12:42.480
We regenerated it,

00:12:42.480 --> 00:12:45.360
but it might be for some part that you never, never call.

00:12:45.360 --> 00:12:48.200
You might only work with S3 and it's only changed.

00:12:48.200 --> 00:12:48.720
>> Yeah.

00:12:48.720 --> 00:12:50.440
>> I don't know, EC2 stuff.

00:12:50.440 --> 00:12:52.880
>> Right. Yeah, exactly.

00:12:52.880 --> 00:12:55.080
>> Yeah, indeed. All right.

00:12:55.080 --> 00:12:57.160
Well, let's talk real quickly about some of

00:12:57.160 --> 00:13:00.680
the places where we could do serverless.

00:13:00.680 --> 00:13:02.760
We've mentioned AWS Lambda.

00:13:02.760 --> 00:13:08.640
I also maybe touch on just one million request free per month.

00:13:08.640 --> 00:13:15.320
>> Yeah. Jumping into AWS sometimes sounds scary,

00:13:15.320 --> 00:13:17.280
but they have a pretty generous free tier.

00:13:17.280 --> 00:13:20.520
Definitely do your research on some of the security of this.

00:13:20.520 --> 00:13:24.380
But yeah, a million requests free per month.

00:13:24.380 --> 00:13:27.040
You probably have to look into that a little bit because

00:13:27.040 --> 00:13:31.080
you have your memory configurations too.

00:13:31.080 --> 00:13:33.180
There's probably, I don't

00:13:33.180 --> 00:13:35.160
know exactly how that works within their free tier,

00:13:35.160 --> 00:13:38.360
but you're charged with Lambda at least,

00:13:38.360 --> 00:13:44.760
it's your invocation time and memory and also amount of requests.

00:13:44.760 --> 00:13:48.240
>> I'm always confused when I look at that and go,

00:13:48.240 --> 00:13:50.960
okay, with all of those variables,

00:13:50.960 --> 00:13:52.920
is that a lot? I know it's a lot,

00:13:52.920 --> 00:13:55.320
but it's hard for me to conceptualize.

00:13:55.320 --> 00:13:57.040
Well, I use a little more memory than I thought,

00:13:57.040 --> 00:13:58.200
so it costs, wait a minute,

00:13:58.200 --> 00:13:59.680
how do I know how much memory I use?

00:13:59.680 --> 00:14:00.720
>> Yeah.

00:14:00.720 --> 00:14:02.120
>> What does it mean in practice?

00:14:02.120 --> 00:14:05.440
>> Yeah, it's built by how you configure it too.

00:14:05.440 --> 00:14:09.440
If you say I need a Lambda with 10 gigs of memory,

00:14:09.440 --> 00:14:15.640
you're being built at that 10 gigabyte price threshold.

00:14:15.640 --> 00:14:24.240
There is a really cool tool called AWS Lambda Power Tuner.

00:14:24.240 --> 00:14:29.680
Yeah, what that'll do is it creates a state machine in AWS.

00:14:29.680 --> 00:14:32.720
I think I did send you a link to that one.

00:14:32.720 --> 00:14:37.120
The Power Tuner will create

00:14:37.120 --> 00:14:39.560
a state machine that invocates your Lambda

00:14:39.560 --> 00:14:41.840
with several different memory configurations.

00:14:41.840 --> 00:14:45.680
You can say I want either the best cost-optimized version

00:14:45.680 --> 00:14:49.400
or the best performance-optimized version.

00:14:49.400 --> 00:14:52.080
That'll tell you, it'll say,

00:14:52.080 --> 00:15:01.040
your best with a Lambda configured at 256 megabytes for memory.

00:15:01.240 --> 00:15:05.800
Sorry, yeah, for the link, this is Power Tools.

00:15:05.800 --> 00:15:07.560
This is a different amazing package.

00:15:07.560 --> 00:15:08.120
>> Yeah.

00:15:08.120 --> 00:15:10.240
>> Maybe I didn't send you the Power Tuner.

00:15:10.240 --> 00:15:11.200
I should, okay.

00:15:11.200 --> 00:15:12.880
>> It's news to me.

00:15:12.880 --> 00:15:14.560
>> Okay, sorry. Yeah.

00:15:14.560 --> 00:15:16.960
They have similar names.

00:15:16.960 --> 00:15:20.360
>> Yeah. There's only so many ways to describe stuff.

00:15:20.360 --> 00:15:22.480
>> Right. Yeah, okay.

00:15:22.480 --> 00:15:23.600
They have it right in their hand up.

00:15:23.600 --> 00:15:23.640
>> This one probably.

00:15:23.640 --> 00:15:26.040
>> Yeah. It is an open-source package,

00:15:26.040 --> 00:15:27.800
so there's probably a GitHub link in there.

00:15:27.800 --> 00:15:31.000
But yeah, this will tell you,

00:15:31.000 --> 00:15:34.080
the best way to optimize your Lambda function,

00:15:34.080 --> 00:15:37.440
at least as far as memory is concerned.

00:15:37.440 --> 00:15:39.240
Yeah, really good tool.

00:15:39.240 --> 00:15:40.360
It gives you a visualization,

00:15:40.360 --> 00:15:42.080
gives you a graph that will say,

00:15:42.080 --> 00:15:45.840
here's where cost and performance meet.

00:15:45.840 --> 00:15:47.680
>> Okay. Yeah, that's cool.

00:15:47.680 --> 00:15:51.800
>> Yeah. It's really excellent for figuring that out.

00:15:51.800 --> 00:15:54.360
Yeah, at least in AWS land.

00:15:54.360 --> 00:15:56.720
I don't know if some of the other Cloud providers

00:15:56.720 --> 00:15:58.120
have something similar to this,

00:15:58.120 --> 00:16:03.560
but yeah, it's definitely a really helpful tool.

00:16:03.560 --> 00:16:06.440
>> Sure. Yeah. Like I said,

00:16:06.440 --> 00:16:07.840
I'm confused and I've been doing

00:16:07.840 --> 00:16:09.240
Cloud stuff for a long time when I look at it.

00:16:09.240 --> 00:16:11.960
>> Yeah. Well, there's some interesting things here.

00:16:11.960 --> 00:16:16.640
You can actually have a Lambda invocation that

00:16:16.640 --> 00:16:20.240
costs less with a higher memory configuration,

00:16:20.240 --> 00:16:22.200
because it'll run faster.

00:16:22.200 --> 00:16:26.240
I think Lambda builds by the millisecond now.

00:16:26.800 --> 00:16:28.920
Because it runs faster,

00:16:28.920 --> 00:16:30.440
it can be cheaper to run.

00:16:30.440 --> 00:16:33.400
>> Well, that explains all the rust that's been getting read.

00:16:33.400 --> 00:16:35.280
>> Yeah.

00:16:35.280 --> 00:16:37.760
>> There's a real number behind this.

00:16:37.760 --> 00:16:40.000
I mean, we need to go faster, right?

00:16:40.000 --> 00:16:46.120
Okay. I think maybe AWS Lambda is one of

00:16:46.120 --> 00:16:48.080
the very first ones as well to

00:16:48.080 --> 00:16:50.800
come on with this concept of serverless.

00:16:50.800 --> 00:16:53.560
>> Yeah. I don't know for sure,

00:16:53.560 --> 00:16:55.240
but it probably is.

00:16:55.240 --> 00:16:57.400
Then your other big Cloud providers have them.

00:16:57.400 --> 00:17:02.160
Now you're actually even seeing them come up with a lot of,

00:17:02.160 --> 00:17:07.160
like Vercel has some type of serverless function.

00:17:07.160 --> 00:17:09.760
I don't know what they're using behind it,

00:17:09.760 --> 00:17:12.840
but it's almost like they just put a nicer UI

00:17:12.840 --> 00:17:15.480
around AWS Lambda or whichever Cloud provider

00:17:15.480 --> 00:17:17.880
that's potentially backing this up.

00:17:17.880 --> 00:17:19.800
>> It may well be that.

00:17:19.800 --> 00:17:21.680
They're just reselling their flavor

00:17:21.680 --> 00:17:23.400
of somebody else's Cloud.

00:17:23.400 --> 00:17:26.440
>> Yeah, it could be because the Vercel obviously they have

00:17:26.440 --> 00:17:32.560
a really nice suite of products with a good UI, very usable.

00:17:32.560 --> 00:17:36.120
>> Vercel, some of them people can try.

00:17:36.120 --> 00:17:40.560
Then we've got the two other hyperscale Clouds,

00:17:40.560 --> 00:17:43.240
I guess you call them. Google Cloud has serverless, right?

00:17:43.240 --> 00:17:44.720
>> Yeah.

00:17:44.720 --> 00:17:47.120
>> I'm not sure which ones.

00:17:47.120 --> 00:17:50.320
They might just be called Cloud Functions.

00:17:50.320 --> 00:17:52.440
Yeah, Azure also has.

00:17:52.440 --> 00:17:54.880
>> Cloud Run. They got Cloud Run and Cloud Functions.

00:17:54.880 --> 00:17:56.880
I have no idea what the difference is there.

00:17:56.880 --> 00:18:03.880
>> Yeah. Azure also has a serverless product.

00:18:03.880 --> 00:18:08.120
I'd imagine there's probably even more that we're not aware of.

00:18:08.120 --> 00:18:11.600
But yeah, it's nice to not think

00:18:11.600 --> 00:18:16.680
about setting up servers for something.

00:18:16.680 --> 00:18:19.200
>> I think maybe, is it FOSS?

00:18:19.200 --> 00:18:20.560
Yeah, Function as a Service. Let's see.

00:18:20.560 --> 00:18:26.760
>> Yeah. If we search for F-A-S instead of PASS or IaaS,

00:18:26.760 --> 00:18:30.720
there's Almeda, Intel.

00:18:30.720 --> 00:18:32.440
I saw that IBM had some.

00:18:32.440 --> 00:18:37.600
There's also we've got DigitalOcean.

00:18:37.600 --> 00:18:39.720
I'm a big fan of DigitalOcean because I feel

00:18:39.720 --> 00:18:42.600
like their pricing is really fair,

00:18:42.600 --> 00:18:44.680
and they've got good documentation and stuff.

00:18:44.680 --> 00:18:52.120
They've got serverless functions that you can.

00:18:52.120 --> 00:18:53.480
I don't use these.

00:18:53.480 --> 00:18:56.160
>> Yeah. I haven't used these either.

00:18:56.160 --> 00:19:03.000
As far as cost, especially for small personal projects and

00:19:03.000 --> 00:19:06.720
things where you don't need to have a server on all the time,

00:19:06.720 --> 00:19:12.360
they're pretty nice if you have a website that you need something,

00:19:12.360 --> 00:19:14.200
server-side where you got to have some Python,

00:19:14.200 --> 00:19:16.280
but you don't need a server going all the time.

00:19:16.280 --> 00:19:16.760
Yeah, it's-

00:19:16.760 --> 00:19:19.720
>> Okay. Maybe I have a static site,

00:19:19.720 --> 00:19:21.320
but then I want this one thing to

00:19:21.320 --> 00:19:23.640
happen if somebody clicks a button, something like that.

00:19:23.640 --> 00:19:25.520
>> Yeah. Absolutely.

00:19:25.520 --> 00:19:27.280
You could be completely static,

00:19:27.280 --> 00:19:32.440
but have something that is that one function call that you do need.

00:19:32.440 --> 00:19:35.960
>> Exactly. Then you also pointed out

00:19:35.960 --> 00:19:39.160
that Cloudflare has some form of serverless.

00:19:39.160 --> 00:19:41.680
>> Yeah. I haven't used these either,

00:19:41.680 --> 00:19:44.480
but yeah, I do know that they have

00:19:44.480 --> 00:19:49.320
some type of functions as a service as well.

00:19:49.320 --> 00:19:51.960
>> I don't know what frameworks or languages,

00:19:51.960 --> 00:19:53.680
they let you write them in there.

00:19:53.680 --> 00:19:58.120
I use bunny.net for my CDN.

00:19:58.120 --> 00:20:00.120
It's just absolutely awesome platform.

00:20:00.120 --> 00:20:03.120
I really, really love it. One of the things that they've started offering,

00:20:03.120 --> 00:20:04.480
I can get this stupid,

00:20:04.480 --> 00:20:06.880
completely useless cookie banner to go away,

00:20:06.880 --> 00:20:14.040
is they've offered what they call Edge Compute.

00:20:14.040 --> 00:20:15.600
>> Oh, yeah. Okay.

00:20:15.600 --> 00:20:16.880
>> What you would do,

00:20:16.880 --> 00:20:19.720
I don't know where to find it, somewhere maybe.

00:20:19.720 --> 00:20:24.960
But basically, the CDN has 115,

00:20:24.960 --> 00:20:28.680
120 points of presence all over the world where,

00:20:28.680 --> 00:20:30.240
this one's close to Brazil,

00:20:30.240 --> 00:20:32.680
this one's close to Australia, whatever.

00:20:32.680 --> 00:20:38.040
But you can actually run serverless functions on those things.

00:20:38.040 --> 00:20:42.920
You deploy them so the code actually executes in 115 locations.

00:20:42.920 --> 00:20:43.720
>> Yes.

00:20:43.720 --> 00:20:46.520
>> Probably Cloudflare or something like that as well, but I don't know.

00:20:46.520 --> 00:20:52.520
>> Yeah. AWS, they have Lambda at the Edge.

00:20:52.520 --> 00:20:58.880
That goes hand in hand with their CDN CloudFront, I believe.

00:20:58.880 --> 00:21:01.160
Yeah. They have something similar like that where you have

00:21:01.160 --> 00:21:07.840
a Lambda that's going to perform it because it's distributed across their CDNs.

00:21:07.840 --> 00:21:10.520
>> Yeah. CDNs, that's a whole nother world.

00:21:10.520 --> 00:21:12.440
They're getting really advanced.

00:21:12.440 --> 00:21:14.120
>> Yeah.

00:21:14.120 --> 00:21:18.400
>> Yeah. Maybe that's a different show.

00:21:18.400 --> 00:21:19.600
It's not a show today.

00:21:19.600 --> 00:21:24.520
But it's just the idea of you distribute the compute on the CDN.

00:21:24.520 --> 00:21:27.160
It's pretty nice. The drawback is it's just JavaScript,

00:21:27.160 --> 00:21:31.160
which is okay, but it's not the same as Python.

00:21:31.160 --> 00:21:32.880
>> Yes. Yeah.

00:21:32.880 --> 00:21:36.520
>> I wonder if you could do PyScript there.

00:21:36.520 --> 00:21:38.720
>> Yeah. That's an interesting thought.

00:21:38.720 --> 00:21:42.440
Yeah. We're getting closer and closer to Python in the browser.

00:21:42.440 --> 00:21:46.560
>> Yeah. My JavaScript includes this little bit of WebAssembly.

00:21:46.560 --> 00:21:48.080
I don't like semicolons,

00:21:48.080 --> 00:21:49.600
but go ahead and run it anyway.

00:21:49.600 --> 00:21:51.040
>> Yeah.

00:21:51.040 --> 00:21:55.440
>> Out in the audience, it looks like Cloudflare probably does support Python.

00:21:55.440 --> 00:22:01.440
>> Okay. Yeah. There's so many options out there for serverless functions,

00:22:01.440 --> 00:22:03.640
especially if you're already in,

00:22:03.640 --> 00:22:10.200
if you're maybe deploying some static stuff over Cloudflare or Brazil.

00:22:10.200 --> 00:22:15.960
Yeah. It's sometimes nice just to be all in on one service.

00:22:15.960 --> 00:22:23.200
>> Yeah. It really is. Let's talk about choosing serverless over other things.

00:22:23.200 --> 00:22:25.200
You've actually laid out two really good examples,

00:22:25.200 --> 00:22:28.560
or maybe three even with the static site example.

00:22:28.560 --> 00:22:33.720
But I've got bursts of activity.

00:22:33.720 --> 00:22:34.720
>> Yeah.

00:22:34.720 --> 00:22:36.840
>> Really focused time, but really,

00:22:36.840 --> 00:22:41.280
really incredibly low usage other times.

00:22:41.280 --> 00:22:46.080
>> Yeah. You think of your Black Friday traffic.

00:22:46.080 --> 00:22:50.440
To not have to think of how many servers to be

00:22:50.440 --> 00:22:55.160
provisioned for something like that or if you don't know.

00:22:55.160 --> 00:22:57.240
I think there's probably some, well,

00:22:57.240 --> 00:23:00.040
I actually know there's been some pretty popular articles

00:23:00.040 --> 00:23:03.040
about people leaving the Cloud.

00:23:03.040 --> 00:23:09.600
If you know your scale and you know exactly what you need,

00:23:09.600 --> 00:23:17.200
you probably can save money by just having your own infrastructure setup.

00:23:17.200 --> 00:23:21.680
But if you don't know or it's very spiky,

00:23:21.680 --> 00:23:24.240
you don't need to have a server that's consuming

00:23:24.240 --> 00:23:27.200
a lot of power running 24 hours a day,

00:23:27.200 --> 00:23:32.000
you can just invoke a function as you need.

00:23:32.000 --> 00:23:37.880
>> Yeah. There's a super interesting series by David Heinemann Hansen,

00:23:37.880 --> 00:23:43.640
Ruby on Rails fame and from Basecamp about how Basecamp has left the Cloud and how

00:23:43.640 --> 00:23:49.280
they're saving $7 million and getting better performance over five years.

00:23:49.280 --> 00:23:50.480
>> Yeah.

00:23:50.480 --> 00:23:52.080
>> That's a big investment.

00:23:52.080 --> 00:23:56.320
They bought, they paid $600,000 for hardware.

00:23:56.320 --> 00:23:57.560
>> Yeah.

00:23:57.560 --> 00:23:59.120
>> Only so many people can do that.

00:23:59.120 --> 00:24:06.520
>> Right. You got to have that running somewhere with backup power.

00:24:06.520 --> 00:24:11.200
>> What they ended up doing for this one is they went with

00:24:11.200 --> 00:24:17.360
some service called DEFT Cloud hosting which is like white glove.

00:24:17.360 --> 00:24:23.800
White labeled is the word I'm looking for where it just looks like it's your hardware,

00:24:23.800 --> 00:24:28.360
but they put it into a mega data center and they'll have

00:24:28.360 --> 00:24:30.600
the hardware shipped to them and somebody will just come

00:24:30.600 --> 00:24:33.520
out and install it into racks and go, "Here's your IP address."

00:24:33.520 --> 00:24:34.720
>> Right. Yeah.

00:24:34.720 --> 00:24:39.760
>> Like a virtual VM or a VM in a Cloud,

00:24:39.760 --> 00:24:42.360
but it takes three weeks to boot.

00:24:42.360 --> 00:24:44.240
>> Right. Yeah.

00:24:44.240 --> 00:24:48.840
>> Which is almost, I'm diving into it because it's

00:24:48.840 --> 00:24:53.840
almost the exact opposite of the serverless benefits, right?

00:24:53.840 --> 00:24:54.680
>> Right. Yeah.

00:24:54.680 --> 00:24:55.920
>> This is insane stability.

00:24:55.920 --> 00:24:59.000
I have this thing for five years.

00:24:59.000 --> 00:24:59.840
>> Yeah.

00:24:59.840 --> 00:25:02.760
>> 4,000 CPUs we've installed and we're using them for

00:25:02.760 --> 00:25:04.640
the next five years rather than

00:25:04.640 --> 00:25:07.480
how many milliseconds am I going to run this code for?

00:25:07.480 --> 00:25:09.280
>> Right. Exactly. Yeah.

00:25:09.280 --> 00:25:12.120
It's definitely the far opposite.

00:25:12.120 --> 00:25:16.560
Yeah. Maybe serverless isn't for every use case,

00:25:16.560 --> 00:25:20.480
but it's definitely a nice tool to have in the toolbox.

00:25:20.480 --> 00:25:23.520
Even working in serverless,

00:25:23.520 --> 00:25:26.560
eventually you're going to need maybe to

00:25:26.560 --> 00:25:29.840
interact with the database that's got to be on all the time.

00:25:29.840 --> 00:25:32.480
It's a good tool,

00:25:32.480 --> 00:25:37.160
but it's definitely not the one size fits all solution.

00:25:37.160 --> 00:25:39.080
>> Yeah. Let's talk databases in a second.

00:25:39.080 --> 00:25:44.960
But for, when does it make sense to say we're going to put this?

00:25:44.960 --> 00:25:46.640
Let's suppose I have an API, right?

00:25:46.640 --> 00:25:50.240
That's a pretty, an API is a real similar equivalent

00:25:50.240 --> 00:25:51.960
to what a serverless thing is.

00:25:51.960 --> 00:25:53.200
Like I'm going to call this API,

00:25:53.200 --> 00:25:54.120
things are going to happen. I'm going to call

00:25:54.120 --> 00:25:55.920
this function and things are going to happen.

00:25:55.920 --> 00:26:00.600
Let's suppose I have an API and it has eight endpoints.

00:26:00.600 --> 00:26:03.920
It's written in FastAPI or whatever it is.

00:26:03.920 --> 00:26:07.880
It might make sense to have that as serverless, right?

00:26:07.880 --> 00:26:10.040
You don't want to run a server and all that kind of thing.

00:26:10.040 --> 00:26:12.800
But what if I have an API with 200 endpoints?

00:26:12.800 --> 00:26:14.320
Where is the point where like,

00:26:14.320 --> 00:26:15.960
there are so many little serverless things,

00:26:15.960 --> 00:26:16.960
I don't even know where to look.

00:26:16.960 --> 00:26:18.800
They're everywhere. Which version is this one?

00:26:18.800 --> 00:26:21.400
You know what I mean? Where's that trade-off and

00:26:21.400 --> 00:26:24.160
how do you and the people you work with think about that?

00:26:24.160 --> 00:26:29.240
>> Yeah. I guess that's a good question.

00:26:29.240 --> 00:26:34.080
I mean, as you start getting into these micro-services,

00:26:34.080 --> 00:26:36.360
how small do you want to break these up?

00:26:36.360 --> 00:26:39.760
There is some different thoughts on that.

00:26:39.760 --> 00:26:42.880
Even like a Lambda function, for instance,

00:26:42.880 --> 00:26:46.120
if you put this behind an API,

00:26:46.120 --> 00:26:53.360
you can use a single Lambda function for your entire REST API,

00:26:53.360 --> 00:26:56.440
even if it is 200 endpoints.

00:26:56.440 --> 00:27:00.720
>> Okay. You put the whole app there and then when a request comes in,

00:27:00.720 --> 00:27:02.560
it routes to whatever part of your app.

00:27:02.560 --> 00:27:04.560
>> Theoretically, yeah.

00:27:04.560 --> 00:27:12.240
There's a package called AWS Power Tools for Python.

00:27:12.240 --> 00:27:12.800
>> That's the one I kind of love.

00:27:12.800 --> 00:27:15.200
>> Yes. I know the similar name.

00:27:15.200 --> 00:27:19.200
They have a really good event resolver.

00:27:19.200 --> 00:27:26.760
It almost looks like Flask or some of the other Python web frameworks.

00:27:26.760 --> 00:27:29.080
You can have this resolver,

00:27:29.080 --> 00:27:33.120
whether it's API gateway and AWS are different.

00:27:33.120 --> 00:27:38.240
They have a few different options for the API itself.

00:27:38.240 --> 00:27:40.480
But yeah, in theory,

00:27:40.480 --> 00:27:45.480
you could have your entire API behind a single Lambda function.

00:27:45.480 --> 00:27:48.320
But then that's probably not optimal.

00:27:48.320 --> 00:27:54.000
That's where you have to figure out how to break that up.

00:27:54.000 --> 00:27:57.480
They do that same,

00:27:57.480 --> 00:28:00.840
the decorators, app.post.

00:28:00.840 --> 00:28:02.120
>> Yeah.

00:28:02.120 --> 00:28:05.240
>> Your endpoints and you can have

00:28:05.240 --> 00:28:12.400
them have variables in there where maybe you have ID as your lookup,

00:28:12.400 --> 00:28:21.680
and it can slash user slash ID is going to find a single user.

00:28:21.680 --> 00:28:26.440
In their documentation, they actually address this a little bit.

00:28:26.640 --> 00:28:31.360
They call it either a micro function pattern

00:28:31.360 --> 00:28:36.080
where maybe every single endpoint has its own Lambda function.

00:28:36.080 --> 00:28:38.440
But yeah, that's a lot of overhead to maintain.

00:28:38.440 --> 00:28:40.400
If you had, like you said, 200 endpoints,

00:28:40.400 --> 00:28:42.720
you have 200 Lambdas.

00:28:42.720 --> 00:28:48.120
>> You got to upgrade them all at the same time so they have the right data models.

00:28:48.120 --> 00:28:48.520
>> Yeah, exactly.

00:28:48.520 --> 00:28:50.120
>> Yeah, that's not really.

00:28:50.120 --> 00:28:55.440
>> Yeah. There's definitely some even conflicting views on this.

00:28:55.440 --> 00:28:58.480
How micro do you want to go?

00:28:58.480 --> 00:29:03.440
I was able to go to AWS reInvent in November,

00:29:03.440 --> 00:29:07.120
and they actually pitched this hybrid.

00:29:07.120 --> 00:29:10.040
Maybe if you take your CRUD operations,

00:29:10.040 --> 00:29:14.320
and maybe you have your create,

00:29:14.320 --> 00:29:18.920
update, and delete all on one Lambda with its configuration for those,

00:29:18.920 --> 00:29:21.920
but your read is on another Lambda.

00:29:21.920 --> 00:29:23.360
Maybe your CRUD operations,

00:29:23.360 --> 00:29:25.920
they all interact with a relational database,

00:29:25.920 --> 00:29:31.680
but your reader just does reads from a Dynamo database,

00:29:31.680 --> 00:29:34.040
where you sync that data up.

00:29:34.040 --> 00:29:40.400
You could have your permissions separated for each of those Lambda functions.

00:29:40.400 --> 00:29:44.320
People reading from an API don't always need

00:29:44.320 --> 00:29:48.200
the same permissions as updating, deleting.

00:29:48.200 --> 00:29:51.040
Yeah, there's a lot of different ways to break that up,

00:29:51.040 --> 00:29:53.320
and how micro do you go with this?

00:29:53.320 --> 00:29:54.040
Definitely.

00:29:54.040 --> 00:29:55.440
>> How micro can you go?

00:29:55.440 --> 00:29:56.040
>> Yeah.

00:29:56.040 --> 00:29:58.720
>> Yeah, because it sounds to me like if you have many,

00:29:58.720 --> 00:30:01.280
many of them, then all of a sudden you're back to like, "Wait,

00:30:01.280 --> 00:30:04.560
I did this because I didn't want to be in DevOps,

00:30:04.560 --> 00:30:07.280
and now I'm a different kind of DevOps."

00:30:07.280 --> 00:30:11.800
>> Yeah. Yeah. Yeah, that package,

00:30:11.800 --> 00:30:17.400
the Power Tools does a lot of heavy lifting for you.

00:30:17.400 --> 00:30:21.680
At PyCon, there was a talk on serverless that,

00:30:21.680 --> 00:30:25.320
the way they described the Power Tools package was

00:30:25.320 --> 00:30:30.360
that they said it codified your serverless best practices.

00:30:30.360 --> 00:30:33.800
It's really true. There's so many different tools in there.

00:30:33.800 --> 00:30:39.360
There's a structured logger that works really well with Lambda,

00:30:39.360 --> 00:30:45.880
and you don't even have to use the AWS login services.

00:30:45.880 --> 00:30:50.160
If you want to use Datadog or Splunk or something else,

00:30:50.160 --> 00:30:54.360
it's just a structured logger and how you aggregate them is up to you,

00:30:54.360 --> 00:30:56.480
and you can even customize how you format them,

00:30:56.480 --> 00:31:00.400
but it works really well with Lambda.

00:31:00.400 --> 00:31:04.200
>> You probably could actually capture exceptions and

00:31:04.200 --> 00:31:07.440
stuff with something like Sentry even, right?

00:31:07.440 --> 00:31:08.200
>> Oh, yeah.

00:31:08.200 --> 00:31:09.840
>> Python code, there's no reason you couldn't.

00:31:09.840 --> 00:31:14.640
>> Right. Exactly. Yeah. Some of that comes into

00:31:14.640 --> 00:31:17.840
packaging up those libraries for that.

00:31:17.840 --> 00:31:20.920
You do have to think of some of that stuff, but like Datadog.

00:31:20.920 --> 00:31:22.280
>> Long and small.

00:31:22.280 --> 00:31:24.120
>> Datadog, for instance,

00:31:24.120 --> 00:31:28.160
they provide something called a Lambda layer or a Lambda extension,

00:31:28.160 --> 00:31:32.880
which is another way to package code up that just makes it a little bit easier.

00:31:32.880 --> 00:31:37.040
Yeah, there's a lot of different ways to attack some of these problems.

00:31:37.040 --> 00:31:38.320
>> A lot of that stuff,

00:31:38.320 --> 00:31:40.400
even though they have nice libraries for them,

00:31:40.400 --> 00:31:44.080
it's really just calling a HTTP endpoint and you could go,

00:31:44.080 --> 00:31:46.040
"Okay, we need something really light."

00:31:46.040 --> 00:31:47.840
I don't know if request is already included,

00:31:47.840 --> 00:31:50.920
or whether some got to be some HTTP thing already included.

00:31:50.920 --> 00:31:52.640
We're just going to directly call it,

00:31:52.640 --> 00:31:54.560
not showing all these packages.

00:31:54.560 --> 00:31:56.520
>> Sure. Yeah.

00:31:56.520 --> 00:32:01.080
>> Yeah. This code looks nice.

00:32:01.080 --> 00:32:04.080
This Power Tools code,

00:32:04.080 --> 00:32:07.040
it looks like well-written Python code.

00:32:07.040 --> 00:32:13.800
>> They do some really amazing stuff and they bring in Pydantic too.

00:32:13.800 --> 00:32:18.000
Being mostly in serverless,

00:32:18.000 --> 00:32:23.320
I've never really gotten to use FastAPI and leverage Pydantic as much,

00:32:23.320 --> 00:32:26.000
but with Power Tools, you really can.

00:32:26.000 --> 00:32:30.000
They'll package up Pydantic for you and so you can

00:32:30.000 --> 00:32:37.160
actually have Pydantic models for validation on these.

00:32:37.160 --> 00:32:39.880
It's like a Lambda function, for instance,

00:32:39.880 --> 00:32:42.080
it always receives an event.

00:32:42.080 --> 00:32:44.520
There's always two arguments to the handler function,

00:32:44.520 --> 00:32:46.160
it's event and context.

00:32:46.160 --> 00:32:55.960
Event is always a dictionary in Python and so they can always look different.

00:32:55.960 --> 00:32:57.800
>> Yeah.

00:32:57.800 --> 00:33:03.680
>> Yeah. If you look in the Power Tools GitHub,

00:33:03.680 --> 00:33:06.160
their tests, they have,

00:33:06.160 --> 00:33:10.200
okay, here's what an event from API.

00:33:10.200 --> 00:33:13.720
>> API gateway proxy event.json or whatever, right?

00:33:13.720 --> 00:33:16.880
>> Yes. They have examples.

00:33:16.880 --> 00:33:21.200
Yes. You don't want to parse that out by yourself.

00:33:21.200 --> 00:33:22.280
>> No.

00:33:22.280 --> 00:33:26.040
>> They have Pydantic models

00:33:26.040 --> 00:33:28.480
or they might actually just be Python data classes,

00:33:28.480 --> 00:33:32.640
but that you can say,

00:33:32.640 --> 00:33:37.120
yeah, this function is going to be for an API gateway proxy event,

00:33:37.120 --> 00:33:40.960
or it's going to be an S3 event or whatever it is.

00:33:40.960 --> 00:33:42.960
There's so many different ways to receive

00:33:42.960 --> 00:33:46.280
events from different AWS services.

00:33:46.280 --> 00:33:50.960
Yeah, Power Tools gives you some nice validation.

00:33:50.960 --> 00:33:52.680
Yeah, you might just say, okay,

00:33:52.680 --> 00:33:54.120
yeah, the body of this event,

00:33:54.120 --> 00:33:57.840
even though I don't care about all this other stuff that they include,

00:33:57.840 --> 00:34:02.320
the path headers, query string parameters.

00:34:02.320 --> 00:34:04.040
But I just need the body of this.

00:34:04.040 --> 00:34:06.280
You just say, okay, event.body,

00:34:06.280 --> 00:34:09.720
and you can validate that further.

00:34:09.720 --> 00:34:13.920
The event body is going to be a Pydantic model that you created.

00:34:13.920 --> 00:34:16.440
>> There's a lot of different pieces in here.

00:34:16.440 --> 00:34:19.760
If I was working on this and it didn't already have Pydantic models,

00:34:19.760 --> 00:34:24.760
I would take this and go to JSON Pydantic.

00:34:24.760 --> 00:34:27.040
>> I didn't even know this existed.

00:34:27.040 --> 00:34:27.640
>> Yeah, it is.

00:34:27.640 --> 00:34:28.160
>> Okay.

00:34:28.160 --> 00:34:31.360
>> Boom, put that right in there and boom, there you go.

00:34:31.360 --> 00:34:36.960
It parses it onto a nested object tree of the model.

00:34:36.960 --> 00:34:37.240
>> Very nice.

00:34:37.240 --> 00:34:38.400
>> They already give it to you.

00:34:38.400 --> 00:34:39.320
They already give it to you.

00:34:39.320 --> 00:34:39.640
>> Yeah.

00:34:39.640 --> 00:34:41.200
>> Just take what they give you.

00:34:41.200 --> 00:34:46.120
>> Yeah. Those specific events might be data classes instead of Pydantic,

00:34:46.120 --> 00:34:50.680
just because that way you don't have to package Pydantic up in your Lambda.

00:34:50.680 --> 00:34:54.760
But yeah, if you're already figuring out a way to package Power Tools,

00:34:54.760 --> 00:34:58.760
you're close enough that you probably just include Pydantic too.

00:34:58.760 --> 00:35:04.640
But yeah, I think they just added

00:35:04.640 --> 00:35:10.560
this feature where it'll actually generate OpenAPI schema for you.

00:35:10.560 --> 00:35:13.840
I think FastAPI does that as well.

00:35:13.840 --> 00:35:19.200
Yeah, so that's something you can leverage Power Tools to do now as well.

00:35:19.200 --> 00:35:22.360
>> Excellent. Then you can actually take the OpenAPI schema and generate

00:35:22.360 --> 00:35:25.600
a Python client port on top of that, I think.

00:35:25.600 --> 00:35:27.000
>> Yeah.

00:35:27.000 --> 00:35:29.040
>> It's robots all the way down.

00:35:29.040 --> 00:35:29.640
>> Right.

00:35:29.640 --> 00:35:31.000
>> A lot of little turtles all the way down.

00:35:31.000 --> 00:35:39.440
>> Yeah. I haven't used those OpenAPI generated clients very much.

00:35:39.440 --> 00:35:41.360
I was always skeptical of them.

00:35:41.360 --> 00:35:44.840
>> I always feel heartless,

00:35:44.840 --> 00:35:46.760
or soulless, I guess is the word.

00:35:46.760 --> 00:35:48.200
It's boring. It's just like, "Okay,

00:35:48.200 --> 00:35:50.000
here's another star org, star star,

00:35:50.000 --> 00:35:51.800
KW orgs thing where it's like,

00:35:51.800 --> 00:35:56.600
couldn't you just write some reasonable defaults and give me some keyword argument?"

00:35:56.600 --> 00:35:59.880
That's how I feel. But if it's better than nothing, it's better than nothing.

00:35:59.880 --> 00:36:05.320
>> Right. Yeah. You can see Power Tools,

00:36:05.320 --> 00:36:08.640
they took a lot of influence from FastAPI.

00:36:08.640 --> 00:36:10.360
>> It does seem like it, yeah, for sure.

00:36:10.360 --> 00:36:16.280
>> Yeah. It's definitely really powerful and you get some of those same benefits.

00:36:16.280 --> 00:36:19.000
>> This is new to me. It looks quite nice.

00:36:19.000 --> 00:36:21.760
Another comment by Kim is,

00:36:21.760 --> 00:36:24.120
"Tended to use serverless functions for

00:36:24.120 --> 00:36:26.880
either things that run briefly like once a month on a schedule,

00:36:26.880 --> 00:36:31.360
or the code that processes stuff coming in on an AWS,

00:36:31.360 --> 00:36:33.640
SQS, simple queuing service,

00:36:33.640 --> 00:36:36.720
queue of unknown schedule."

00:36:36.720 --> 00:36:42.840
Maybe that's an interesting segue into how do you call your serverless code?

00:36:42.840 --> 00:36:46.520
>> Yeah. As we touched on,

00:36:46.520 --> 00:36:51.440
there's a lot of different ways from AWS, for instance, to do it.

00:36:51.760 --> 00:36:56.840
Yeah. AWS Lambda has Lambda function URLs,

00:36:56.840 --> 00:36:58.240
but I haven't used those as much.

00:36:58.240 --> 00:37:02.240
But if you just look at the different options in Power Tools, for instance,

00:37:02.240 --> 00:37:09.100
you can have a load balancer where you set the endpoint to invoke a Lambda.

00:37:09.100 --> 00:37:11.640
You can have API Gateway,

00:37:11.640 --> 00:37:14.840
which is another service they have.

00:37:14.840 --> 00:37:17.080
There's a lot of different ways.

00:37:17.080 --> 00:37:23.760
Yeah, SQS. That's almost getting into a way of streaming,

00:37:23.760 --> 00:37:27.200
or an asynchronous way of processing data.

00:37:27.200 --> 00:37:32.480
Yeah. Maybe in AWS, you're using a queue,

00:37:32.480 --> 00:37:34.880
that's filling up and you say,

00:37:34.880 --> 00:37:39.520
"Okay, yeah, every time this queue is at this size or this time frame,

00:37:39.520 --> 00:37:42.920
invoke this Lambda and process all these messages."

00:37:42.920 --> 00:37:49.480
There's a lot of different ways to invoke a Lambda function.

00:37:49.480 --> 00:37:56.200
If it's really as simple as you can invoke them from the AWS CLI.

00:37:56.200 --> 00:38:00.280
But yeah, most people probably have some API around it.

00:38:00.280 --> 00:38:04.520
>> Yeah. Almost make them look like just HTTP endpoints.

00:38:04.520 --> 00:38:05.760
>> Right. Yeah.

00:38:05.760 --> 00:38:09.000
>> Yeah. Mark out there says,

00:38:09.000 --> 00:38:11.640
"Not heard talk of ECS, I don't think,

00:38:11.640 --> 00:38:18.480
but I've been running web services using Fargate serverless tasks on ECS for years now."

00:38:18.480 --> 00:38:19.000
>> Yes.

00:38:19.000 --> 00:38:20.840
>> Are you familiar with this? I haven't done it.

00:38:20.840 --> 00:38:24.040
>> Yeah. I'm vaguely familiar with it,

00:38:24.040 --> 00:38:30.440
but yeah, this is like a serverless compute for containers.

00:38:30.440 --> 00:38:34.160
I haven't used this personally.

00:38:34.160 --> 00:38:40.720
But yeah, very similar concept where it scales up for you.

00:38:40.720 --> 00:38:43.440
Yeah, you don't have to have things running all the time,

00:38:43.440 --> 00:38:46.000
but yeah, it can be dockerized applications.

00:38:46.000 --> 00:38:47.840
In fact, the company I work for now,

00:38:47.840 --> 00:38:50.200
they do this with their Ruby on Rails applications.

00:38:50.200 --> 00:38:55.360
They dockerize them and run with Fargate.

00:38:55.360 --> 00:38:59.760
>> Creating Docker containers of these things,

00:38:59.760 --> 00:39:03.440
the less familiar you are with running that,

00:39:03.440 --> 00:39:05.880
XStack, the better it is in Docker.

00:39:05.880 --> 00:39:06.440
You know what I mean?

00:39:06.440 --> 00:39:08.120
>> Yeah.

00:39:08.120 --> 00:39:10.640
>> I could run straight Python,

00:39:10.640 --> 00:39:12.640
but if it's Ruby on Rails or PHP,

00:39:12.640 --> 00:39:14.080
maybe it's going into a container.

00:39:14.080 --> 00:39:16.160
That would make me feel a little bit better about it.

00:39:16.160 --> 00:39:18.200
>> Yeah. Especially if you're in that workflow of

00:39:18.200 --> 00:39:21.280
handing something over to a DevOps team.

00:39:21.280 --> 00:39:24.560
You can say, here's an image or a container or

00:39:24.560 --> 00:39:27.360
Docker file that will work for you.

00:39:27.360 --> 00:39:30.400
That's maybe a little bit easier than

00:39:30.400 --> 00:39:33.880
trying to explain how to set up an environment or something.

00:39:33.880 --> 00:39:34.600
>> Yeah.

00:39:34.600 --> 00:39:38.800
>> Yeah. Fargate's a really good serverless option too.

00:39:38.800 --> 00:39:41.880
>> Excellent. What about performance?

00:39:41.880 --> 00:39:45.560
You talked about having a whole API apps,

00:39:45.560 --> 00:39:48.280
like FastAPI, Flask, or whatever.

00:39:48.280 --> 00:39:49.360
>> Yeah.

00:39:49.360 --> 00:39:54.160
>> Startup of those apps can be non-trivial, basically.

00:39:54.160 --> 00:39:55.840
Then on the other side,

00:39:55.840 --> 00:39:57.560
we've got databases and stuff.

00:39:57.560 --> 00:39:59.960
One of the bits of magic of databases is

00:39:59.960 --> 00:40:02.680
the connection pooling that happens.

00:40:02.680 --> 00:40:05.360
The first connection might take 500 milliseconds,

00:40:05.360 --> 00:40:07.280
but the next one takes one,

00:40:07.280 --> 00:40:09.320
because it's already open effectively, right?

00:40:09.320 --> 00:40:12.480
>> Yeah. That's definitely something you really have to

00:40:12.480 --> 00:40:15.560
take into consideration is how much you can do.

00:40:15.560 --> 00:40:17.720
That's where some of that observability,

00:40:17.720 --> 00:40:23.120
some of the tracing that you can do and profiling is really powerful.

00:40:23.120 --> 00:40:26.440
Yeah. AWS Lambda, for instance,

00:40:26.440 --> 00:40:30.880
they have something called cold starts.

00:40:30.880 --> 00:40:31.920
>> Yeah. Okay.

00:40:31.920 --> 00:40:36.680
>> Yeah. The first time a Lambda gets invoked,

00:40:36.680 --> 00:40:41.280
or maybe you have 10 Lambdas that get called at the same time,

00:40:41.280 --> 00:40:44.680
that's going to invoke 10 separate Lambda functions.

00:40:44.680 --> 00:40:47.400
That's great for the scale, right?

00:40:47.400 --> 00:40:50.000
That's really nice.

00:40:50.000 --> 00:40:51.400
But on a cold start,

00:40:51.400 --> 00:40:55.960
it's usually a little bit slower invocation because it has to initialize.

00:40:55.960 --> 00:40:59.720
I think what's happening behind the scenes is they're

00:40:59.720 --> 00:41:03.600
moving your code over that's going to get executed.

00:41:03.600 --> 00:41:08.560
Anything that happens outside of your handler function,

00:41:08.560 --> 00:41:10.560
so importing libraries,

00:41:10.560 --> 00:41:14.760
sometimes you're establishing a database connection,

00:41:14.760 --> 00:41:21.520
maybe you're loading some environment variables or some secrets.

00:41:21.520 --> 00:41:27.480
Yeah. Performance is something to consider.

00:41:27.480 --> 00:41:31.200
>> Yeah. You mentioned Rust.

00:41:31.200 --> 00:41:34.320
Yeah, there's probably some more performant run times

00:41:34.320 --> 00:41:37.080
for some of these serverless functions.

00:41:37.080 --> 00:41:40.640
I've even heard some people say,

00:41:40.640 --> 00:41:43.920
okay, for client-facing things,

00:41:43.920 --> 00:41:45.800
we're not going to use serverless.

00:41:45.800 --> 00:41:47.560
We just want that performance.

00:41:47.560 --> 00:41:52.600
That cold start definitely can have an impact on you.

00:41:52.600 --> 00:41:56.040
>> Yeah. On both ends that I've pointed out.

00:41:56.040 --> 00:42:00.120
The app start, but also the database stuff with the connection.

00:42:00.120 --> 00:42:03.080
>> Right. Yeah. Relational databases too.

00:42:03.080 --> 00:42:05.280
That's an interesting thing.

00:42:05.280 --> 00:42:08.240
>> What do you guys do? You mentioned Dynamo already.

00:42:08.240 --> 00:42:13.920
>> Yeah. Dynamo, really performant for a lot of connections.

00:42:13.920 --> 00:42:17.520
Dynamo is a serverless database.

00:42:17.520 --> 00:42:18.880
That can scale.

00:42:18.880 --> 00:42:21.520
You can query it over and over.

00:42:21.760 --> 00:42:28.520
It doesn't reuse a connection in the same way that a SQL database would.

00:42:28.520 --> 00:42:31.720
That's an excellent option.

00:42:31.720 --> 00:42:35.600
But if you do have to connect to a relational database,

00:42:35.600 --> 00:42:37.640
and you have a lot of invocations,

00:42:37.640 --> 00:42:44.720
you can use a proxy if you're all in on AWS.

00:42:44.720 --> 00:42:47.080
Again, sorry for this is really AWS heavy.

00:42:47.080 --> 00:42:51.080
But if you're using their relational database service, RDS,

00:42:51.080 --> 00:42:53.320
you can use RDS proxy,

00:42:53.320 --> 00:42:57.680
which will use a pool of connections for your Lambda function.

00:42:57.680 --> 00:42:58.760
>> Interesting.

00:42:58.760 --> 00:43:02.760
>> Yeah. That can give you a lot of performance,

00:43:02.760 --> 00:43:09.160
or at least you won't be running out of connections to your database.

00:43:09.160 --> 00:43:13.440
Another thing too is just how you structure that connection.

00:43:13.440 --> 00:43:15.120
I mentioned cold Lambdas,

00:43:15.120 --> 00:43:18.400
you obviously have warm Lambdas too.

00:43:18.400 --> 00:43:21.760
A Lambda has its handler function.

00:43:21.760 --> 00:43:27.120
Anything outside of the handler function can get reused on a warm Lambda.

00:43:27.120 --> 00:43:29.400
You can establish the connection to a database,

00:43:29.400 --> 00:43:33.200
and it'll get reused on every invocation that it can.

00:43:33.200 --> 00:43:37.800
>> That's cool. Do you have to do anything explicit to make it do that?

00:43:37.800 --> 00:43:41.640
>> It just has to be outside of that handler function.

00:43:41.640 --> 00:43:46.280
Kind of at your top level of your file.

00:43:46.400 --> 00:43:51.080
>> Excellent. It makes me think almost one thing you would consider is

00:43:51.080 --> 00:43:55.200
profiling the import statement almost.

00:43:55.200 --> 00:43:56.120
>> Yeah.

00:43:56.120 --> 00:43:58.960
>> That's what we normally do, but there's a library called

00:43:58.960 --> 00:44:04.960
import profiler that actually lets you time how long different things take to import.

00:44:04.960 --> 00:44:06.120
It could take a while,

00:44:06.120 --> 00:44:11.720
especially if you come not from a native Python way of thinking.

00:44:11.720 --> 00:44:15.200
In C# or C++ or something,

00:44:15.200 --> 00:44:19.600
you say hash include or using such and such.

00:44:19.600 --> 00:44:23.080
That's a compiler type thing that really has no cost.

00:44:23.080 --> 00:44:23.880
>> Yeah.

00:44:23.880 --> 00:44:26.800
>> There's code execution when you import something in Python,

00:44:26.800 --> 00:44:28.760
and some of these can take a while, right?

00:44:28.760 --> 00:44:32.560
>> Yes. There's a lot of tools for that.

00:44:32.560 --> 00:44:35.160
There's some I think even maybe specific for Lambda.

00:44:35.160 --> 00:44:39.320
I know Datadog has a profiler that gives you this,

00:44:39.320 --> 00:44:41.720
I forget what the graphic is called.

00:44:41.720 --> 00:44:42.680
>> Flame graph?

00:44:42.680 --> 00:44:45.000
>> Flame graph, yeah. That'll give you a flame graph,

00:44:45.000 --> 00:44:46.240
and show like, "Okay, yeah,

00:44:46.240 --> 00:44:49.760
it took this long to make your database connection,

00:44:49.760 --> 00:44:52.200
this long to import Pydantic,

00:44:52.200 --> 00:44:58.240
and it took this long to make a call to DynamoDB."

00:44:58.240 --> 00:45:00.720
You actually break that up.

00:45:00.720 --> 00:45:02.560
AWS has X-Ray, I think,

00:45:02.560 --> 00:45:04.520
which does something similar too.

00:45:04.520 --> 00:45:08.240
Yeah, it's definitely something to consider.

00:45:09.240 --> 00:45:16.680
Just what you're packaging is definitely something to watch for.

00:45:16.680 --> 00:45:21.600
I mentioned using Pants to package Lambdas.

00:45:21.600 --> 00:45:27.600
Hopefully, I don't butcher how this works behind the scenes,

00:45:27.600 --> 00:45:30.120
but they're using Rust,

00:45:30.120 --> 00:45:34.360
and they'll actually infer your dependencies for you.

00:45:34.360 --> 00:45:39.360
They have an integration with AWS Lambda.

00:45:39.360 --> 00:45:42.000
They also have it for Google Cloud Functions.

00:45:42.000 --> 00:45:43.720
It'll go through, you say,

00:45:43.720 --> 00:45:46.480
"Here's my AWS Lambda function.

00:45:46.480 --> 00:45:50.800
This is the file for it and the function that needs to be called."

00:45:50.800 --> 00:45:56.480
It's going to create a zip file for you that has your Lambda code in it,

00:45:56.480 --> 00:45:59.680
and it's going to find all those dependencies you need.

00:46:01.240 --> 00:46:06.320
By default, it's going to include Bodo that you need if you're using Bodo.

00:46:06.320 --> 00:46:12.400
If you're going to use PyMySQL or whatever library,

00:46:12.400 --> 00:46:16.080
it's going to pull all those in and zip that up for you.

00:46:16.080 --> 00:46:19.040
If you just open up that zip and you see,

00:46:19.040 --> 00:46:23.520
especially if you're sharing code across your code base,

00:46:23.520 --> 00:46:24.960
maybe you have a shared function

00:46:24.960 --> 00:46:28.440
to make some of these database connections or calls.

00:46:29.520 --> 00:46:32.680
You see everything that's going to go in there.

00:46:32.680 --> 00:46:34.720
-Wow. -Yeah.

00:46:34.720 --> 00:46:37.360
How like Pants does it is it's file-based.

00:46:37.360 --> 00:46:40.240
Sometimes just for ease of imports,

00:46:40.240 --> 00:46:44.640
you might throw a lot of stuff in your init.py file

00:46:44.640 --> 00:46:46.760
and say, "Okay, yeah, from..."

00:46:46.760 --> 00:46:51.280
You bubble up all your things that you want to import in there.

00:46:52.360 --> 00:46:59.880
Well, if one of those imports is also using OpenCV

00:46:59.880 --> 00:47:02.040
and you don't need that,

00:47:02.040 --> 00:47:04.920
then Pants is going to say, "Oh, he's importing this,

00:47:04.920 --> 00:47:08.920
and because it's file-based, now this Lambda needs OpenCV,"

00:47:08.920 --> 00:47:16.520
which is a massive package that's going to impact your performance,

00:47:16.520 --> 00:47:21.160
especially on those cold starts because that code has to be moved over.

00:47:21.160 --> 00:47:22.640
Yeah, that's pretty interesting.

00:47:22.640 --> 00:47:25.720
So kind of an alternative to saying,

00:47:25.720 --> 00:47:29.080
"Here's my requirements or my pyproject.toml,

00:47:29.080 --> 00:47:30.680
my lock file or whatever,"

00:47:30.680 --> 00:47:33.320
that just lists everything the entire program might use.

00:47:33.320 --> 00:47:36.320
This could say, "You're going to import this function,"

00:47:36.320 --> 00:47:38.040
and to do that, it imports these things,

00:47:38.040 --> 00:47:40.360
which import those things, and then it just says,

00:47:40.360 --> 00:47:42.600
"Okay, that means here's what you need," right?

00:47:42.600 --> 00:47:43.960
Right, yeah.

00:47:43.960 --> 00:47:46.640
Yeah, it's definitely one of the best ways

00:47:46.640 --> 00:47:49.960
that I found to package up Lambda functions.

00:47:49.960 --> 00:47:52.680
I think some of the other tooling might do some of this too,

00:47:52.680 --> 00:47:57.680
but yeah, a lot of times it would require requirements.txt,

00:47:57.680 --> 00:47:59.600
but if you have a large code base too

00:47:59.600 --> 00:48:05.200
where maybe you do have this shared module for that,

00:48:05.200 --> 00:48:07.400
maybe you have 30 different Lambda functions

00:48:07.400 --> 00:48:10.440
that are all going to use some kind of helper function,

00:48:10.440 --> 00:48:12.240
it's just going to go and grab that,

00:48:12.240 --> 00:48:14.120
and it doesn't have to be pip installable.

00:48:14.120 --> 00:48:17.040
Pants is smart enough to just be like, "Okay, it needs this code,"

00:48:17.040 --> 00:48:20.120
and so, but yeah, you just have to be careful.

00:48:20.120 --> 00:48:22.720
Yeah, yeah, and there's so many other cool things

00:48:22.720 --> 00:48:26.360
that Pants is doing that they have some really nice stuff

00:48:26.360 --> 00:48:29.160
for testing and linting and formatting.

00:48:29.160 --> 00:48:33.360
It's, yeah, there's a lot of really good stuff

00:48:33.360 --> 00:48:35.480
that they're doing, so.

00:48:35.480 --> 00:48:38.560
- Yeah, I had Benji on the show to talk about Pants.

00:48:38.560 --> 00:48:39.800
That was fun.

00:48:39.800 --> 00:48:42.800
Yeah, so let me go back to this picture.

00:48:42.800 --> 00:48:43.640
Is this the picture?

00:48:43.640 --> 00:48:46.720
I have a lot of things open on my screen now.

00:48:46.720 --> 00:48:50.840
There, so on my server setup that I described,

00:48:50.840 --> 00:48:52.560
which is a bunch of Docker containers

00:48:52.560 --> 00:48:55.120
running on one big machine,

00:48:55.120 --> 00:48:57.280
I can go in there and I can say,

00:48:57.280 --> 00:48:59.360
"Tail this log and see all the traffic

00:48:59.360 --> 00:49:00.840
to all the different containers."

00:49:00.840 --> 00:49:02.880
I can tail another log and just see

00:49:02.880 --> 00:49:05.400
like the logging, logbook, log guru,

00:49:05.400 --> 00:49:08.520
whatever output of that, or just web traffic.

00:49:08.520 --> 00:49:10.760
Like there's different ways to just go.

00:49:10.760 --> 00:49:12.640
I'm just going to sit back and look at it for a minute

00:49:12.640 --> 00:49:15.240
to make sure it's chilling, right?

00:49:15.240 --> 00:49:19.600
If everything's so transient, not so easy in the same way.

00:49:19.600 --> 00:49:21.000
So what do you do?

00:49:21.000 --> 00:49:24.040
- Yeah, so yeah, Power Tools does,

00:49:24.040 --> 00:49:27.840
they have their structured logger that helps a lot.

00:49:27.840 --> 00:49:28.880
But yeah, you have to kind of like

00:49:28.880 --> 00:49:30.680
aggregate these logs somewhere, right?

00:49:30.680 --> 00:49:33.480
Because yeah, you can't, you know,

00:49:33.480 --> 00:49:35.920
a Lambda function, you can't like SSH into, right?

00:49:35.920 --> 00:49:37.240
So yeah.

00:49:37.240 --> 00:49:39.160
- You can't, it's running too long.

00:49:39.160 --> 00:49:40.000
- Yeah, yeah.

00:49:41.240 --> 00:49:45.280
So yeah, you need to have some way to aggregate these.

00:49:45.280 --> 00:49:50.280
So like AWS has CloudWatch where that will like by default

00:49:50.280 --> 00:49:52.240
kind of log all of your standard out.

00:49:52.240 --> 00:49:57.200
So even like a print statement would go to CloudWatch

00:49:57.200 --> 00:49:59.280
just by default.

00:49:59.280 --> 00:50:01.160
But you probably want to like structure these better

00:50:01.160 --> 00:50:05.160
with most likely in, you know, JSON format,

00:50:05.160 --> 00:50:08.400
just most tooling around those is going to help you.

00:50:08.400 --> 00:50:12.520
So yeah, the Power Tools structured logger is really good.

00:50:12.520 --> 00:50:16.280
And you can even like,

00:50:16.280 --> 00:50:18.280
you can have like a single log statement,

00:50:18.280 --> 00:50:20.320
but you can append different keys to it.

00:50:20.320 --> 00:50:24.360
And it's pretty powerful,

00:50:24.360 --> 00:50:26.520
especially 'cause you don't want to like,

00:50:26.520 --> 00:50:29.320
I think like, so if you just like printed something

00:50:29.320 --> 00:50:31.040
in a Lambda function, for instance,

00:50:31.040 --> 00:50:34.120
that's going to be like a different row on each of your,

00:50:34.120 --> 00:50:36.920
like by like the default CloudWatch,

00:50:36.920 --> 00:50:41.000
like it'll be, how it breaks it up is really odd

00:50:41.000 --> 00:50:43.560
unless you have some kind of structure to them.

00:50:43.560 --> 00:50:44.400
- Okay.

00:50:44.400 --> 00:50:47.660
- And so, yeah, so definitely something to consider.

00:50:47.660 --> 00:50:52.000
Something else you can do is, yeah,

00:50:52.000 --> 00:50:54.920
there's metrics you can do.

00:50:54.920 --> 00:50:57.160
So like how it works with like CloudWatch,

00:50:57.160 --> 00:50:58.600
they have a specific format.

00:50:58.600 --> 00:51:01.800
And if you use that format, you can,

00:51:01.800 --> 00:51:05.620
it'll automatically pull that in as a metric.

00:51:05.620 --> 00:51:08.360
And like Datadog has something similar

00:51:08.360 --> 00:51:10.480
where you can actually kind of like go in there.

00:51:10.480 --> 00:51:12.800
You can look at your logs and say like,

00:51:12.800 --> 00:51:15.680
find a value and be like, I want this to be a metric now.

00:51:15.680 --> 00:51:18.760
And so that's really powerful.

00:51:18.760 --> 00:51:20.080
- Oh, the metric sounds cool.

00:51:20.080 --> 00:51:23.000
So I see logging and tracing.

00:51:23.000 --> 00:51:24.880
What's the difference between those things?

00:51:24.880 --> 00:51:27.360
Like to me, tracing is a level,

00:51:27.360 --> 00:51:28.900
just a high level of logging.

00:51:28.900 --> 00:51:31.080
- Yeah, tracing,

00:51:33.280 --> 00:51:36.860
and hopefully I do the justice differentiated too.

00:51:36.860 --> 00:51:39.360
I feel like tracing does have a lot more to do

00:51:39.360 --> 00:51:43.100
with your performance or maybe even closer

00:51:43.100 --> 00:51:46.000
to like tracking some of these metrics, right?

00:51:46.000 --> 00:51:53.820
I've used the Datadog tracer a lot

00:51:53.820 --> 00:51:57.280
and I've used the AWS like X-Ray,

00:51:57.280 --> 00:51:59.400
their tracing utility a little bit too.

00:51:59.400 --> 00:52:02.340
And so like those will show you.

00:52:02.340 --> 00:52:04.940
So like maybe you are reaching out to a database.

00:52:04.940 --> 00:52:08.960
- Almost like a APM application performance monitoring

00:52:08.960 --> 00:52:13.180
where it says you spent this much time in a SQL query

00:52:13.180 --> 00:52:17.060
and this much time in high dantic serialization.

00:52:17.060 --> 00:52:20.900
Whereas a user has been sent a message.

00:52:20.900 --> 00:52:22.100
- Right, exactly.

00:52:22.100 --> 00:52:22.940
Yeah, yeah.

00:52:22.940 --> 00:52:24.820
Yep, tracing definitely is probably more

00:52:24.820 --> 00:52:27.820
around your performance and yeah, things like that.

00:52:27.820 --> 00:52:29.820
- It's kind of insane that they can do that.

00:52:29.820 --> 00:52:33.380
You see it in the Django debug tool

00:52:33.380 --> 00:52:34.860
or in the pyramid debug tool,

00:52:34.860 --> 00:52:36.220
but they'll be like, here's your code

00:52:36.220 --> 00:52:37.500
and here's all your SQL queries

00:52:37.500 --> 00:52:38.540
and here's how long they took.

00:52:38.540 --> 00:52:39.820
And it's like, wow,

00:52:39.820 --> 00:52:41.820
that thing is reaching deep down in there.

00:52:41.820 --> 00:52:44.700
- The Datadog one is very interesting

00:52:44.700 --> 00:52:46.660
because like it just knows

00:52:46.660 --> 00:52:48.940
like that this is a SQL connection

00:52:48.940 --> 00:52:50.540
and it tells you like, oh, okay,

00:52:50.540 --> 00:52:52.460
this SQL connection took this long.

00:52:52.460 --> 00:52:54.700
And it was like, I didn't tell it to even trace that.

00:52:54.700 --> 00:52:57.860
Like it just like, it knows really well.

00:52:57.860 --> 00:52:58.700
Yeah, so like-

00:52:58.700 --> 00:53:00.380
- It doesn't even know a SQL connection's open.

00:53:00.380 --> 00:53:01.580
It's another to say,

00:53:01.580 --> 00:53:03.820
and here's what it sent over SSL, by the way.

00:53:03.820 --> 00:53:05.260
Like how do you get in there?

00:53:05.260 --> 00:53:06.100
- Yeah, yeah.

00:53:06.100 --> 00:53:07.620
So-

00:53:07.620 --> 00:53:09.900
- It's in process so it can do it.

00:53:09.900 --> 00:53:11.700
It is impressive to see those things that work.

00:53:11.700 --> 00:53:12.540
All right, so that's probably

00:53:12.540 --> 00:53:14.100
what the tracing is about, right?

00:53:14.100 --> 00:53:15.420
- Yes, yeah, yeah.

00:53:15.420 --> 00:53:17.300
Definitely probably more around performance.

00:53:17.300 --> 00:53:19.860
You can put some different things in tracing too.

00:53:19.860 --> 00:53:23.140
Like I've used it to say like,

00:53:23.140 --> 00:53:25.380
we talked about those like database connections to say like,

00:53:25.380 --> 00:53:28.820
oh yeah, this is reusing a connection here.

00:53:28.820 --> 00:53:31.700
'Cause I was trying to like debug some stuff on,

00:53:31.700 --> 00:53:33.340
am I creating a connection too many times?

00:53:33.340 --> 00:53:34.180
So I don't wanna be.

00:53:34.180 --> 00:53:37.100
So yeah, you can put some other useful things

00:53:37.100 --> 00:53:38.780
in tracing as well.

00:53:38.780 --> 00:53:42.180
- Yeah, and Pat out in the audience, oops, move around.

00:53:42.180 --> 00:53:44.820
When using many microservices,

00:53:44.820 --> 00:53:48.340
like single execution involves many services basically,

00:53:48.340 --> 00:53:50.740
it's hard to follow the logs between the services

00:53:50.740 --> 00:53:52.780
and tracing helps tie that together.

00:53:52.780 --> 00:53:54.420
- Yeah, yeah, that's for sure.

00:53:54.540 --> 00:53:55.380
- Yeah.

00:53:55.380 --> 00:53:57.980
- All right, let's close this out Tony

00:53:57.980 --> 00:54:00.420
with one more thing that I'm not sure

00:54:00.420 --> 00:54:02.420
how constructive it can be.

00:54:02.420 --> 00:54:05.420
There probably is some ways, but testing.

00:54:05.420 --> 00:54:10.020
- Yeah, yeah, that's definitely.

00:54:10.020 --> 00:54:12.260
- If you could set up your own Lambda cluster,

00:54:12.260 --> 00:54:14.380
you might just run that for yourself, right?

00:54:14.380 --> 00:54:17.220
So yeah, I didn't like this, right?

00:54:17.220 --> 00:54:18.980
- Yeah, to some extent you can, right?

00:54:18.980 --> 00:54:21.300
Like there's a Lambda Docker image

00:54:21.300 --> 00:54:23.980
that you could run locally and you can do that.

00:54:23.980 --> 00:54:27.700
But if your Lambda is reaching out to DynamoDB,

00:54:27.700 --> 00:54:31.500
I guess there's technically a DynamoDB container as well.

00:54:31.500 --> 00:54:35.100
Like you could, it's a lot of overhead to set this up,

00:54:35.100 --> 00:54:37.500
but rather than just doing like, you know,

00:54:37.500 --> 00:54:42.220
flask start or, you know, whatever the command is

00:54:42.220 --> 00:54:43.060
to like spin up a flask.

00:54:43.060 --> 00:54:46.260
- I pressed the go button in my IDE and now it's.

00:54:46.260 --> 00:54:49.460
- Yeah, so that's definitely,

00:54:49.460 --> 00:54:52.020
and there's more and more tooling coming out,

00:54:52.020 --> 00:54:54.380
you know, that's coming out for this kind of stuff.

00:54:54.380 --> 00:54:58.580
But if you can like unit test,

00:54:58.580 --> 00:55:01.580
there's no reason you can't just like, you know,

00:55:01.580 --> 00:55:05.260
run unit tests locally.

00:55:05.260 --> 00:55:08.260
But when you start getting into the integration test,

00:55:08.260 --> 00:55:10.260
you're probably getting to the point where

00:55:10.260 --> 00:55:14.460
maybe you just deploy to actual services.

00:55:14.460 --> 00:55:18.180
And, you know, it's always trade-offs, right?

00:55:18.180 --> 00:55:20.500
Like there's costs associated with it.

00:55:20.500 --> 00:55:22.340
There's the overhead of like, okay,

00:55:22.340 --> 00:55:25.540
how can I deploy to an isolated environment,

00:55:25.540 --> 00:55:27.900
but maybe it interacts with another microservice.

00:55:27.900 --> 00:55:32.900
So yeah, so there's definitely trade-offs, but testing.

00:55:32.900 --> 00:55:35.220
- I can see that you might come up with

00:55:35.220 --> 00:55:38.940
like a QA environment, almost like a mirror image

00:55:38.940 --> 00:55:41.220
that doesn't share any data.

00:55:41.220 --> 00:55:42.060
- Yeah.

00:55:42.060 --> 00:55:43.980
- It's definitely close, but then you're running,

00:55:43.980 --> 00:55:45.300
I mean, that's a pretty big commitment

00:55:45.300 --> 00:55:49.260
'cause you're running a whole replica of whatever you have.

00:55:49.260 --> 00:55:50.420
- Right, yeah.

00:55:50.420 --> 00:55:53.460
And so, yeah, QA environments are great,

00:55:53.460 --> 00:55:56.700
but you might even want lower than QA.

00:55:56.700 --> 00:55:59.980
You might want to have a dev or like a,

00:55:59.980 --> 00:56:03.340
one place I worked at,

00:56:03.340 --> 00:56:07.820
we would spin up an entire environment for every PR.

00:56:07.820 --> 00:56:11.300
So you could actually, yeah.

00:56:11.300 --> 00:56:14.220
Like when you created a PR, that environment got spun up

00:56:14.220 --> 00:56:17.180
and it ran your integration tests and system tests

00:56:17.180 --> 00:56:21.140
against that environment, which simulated

00:56:21.140 --> 00:56:22.740
your prod environment a little bit better

00:56:22.740 --> 00:56:25.180
than running locally on your machine.

00:56:25.180 --> 00:56:30.180
So certainly a challenge to test this.

00:56:30.180 --> 00:56:33.860
Yeah, and there's always these like one-off things too,

00:56:33.860 --> 00:56:37.620
right, like you can't really simulate

00:56:37.620 --> 00:56:41.580
like that memory limitation of a Lambda locally,

00:56:41.580 --> 00:56:44.820
as much as when you deploy it and things like that, so.

00:56:44.820 --> 00:56:46.700
- Yeah, yeah.

00:56:46.700 --> 00:56:49.220
That would be much, much harder.

00:56:49.220 --> 00:56:51.220
Maybe you could run a Docker container

00:56:51.220 --> 00:56:53.020
and put a memory limit on it.

00:56:53.020 --> 00:56:53.860
You know, that might work.

00:56:53.860 --> 00:56:55.620
- Yeah, yeah, maybe.

00:56:55.620 --> 00:56:57.820
- You're back into like more and more DevOps

00:56:57.820 --> 00:56:58.660
to avoid DevOps.

00:56:58.660 --> 00:57:00.660
- Right, yeah, yeah.

00:57:00.660 --> 00:57:04.100
- So there it goes, but interesting.

00:57:04.100 --> 00:57:06.500
All right, well, anything else you want to add

00:57:06.500 --> 00:57:08.460
to this conversation before we wrap it up?

00:57:08.460 --> 00:57:09.620
About out of time here.

00:57:09.620 --> 00:57:13.700
- Yeah, I guess, I don't know if I have it.

00:57:13.700 --> 00:57:15.500
Hopefully we covered enough.

00:57:15.500 --> 00:57:17.540
- There's just a lot of like, yeah,

00:57:17.540 --> 00:57:18.780
there's a lot of good resources.

00:57:18.780 --> 00:57:20.540
The tooling that I've mentioned,

00:57:20.540 --> 00:57:24.820
like Power Tools and Pants, just amazing communities.

00:57:24.820 --> 00:57:26.900
Like Power Tools has a Discord,

00:57:26.900 --> 00:57:28.180
and you can go on there and ask for help,

00:57:28.180 --> 00:57:30.060
and they're super helpful.

00:57:30.060 --> 00:57:31.620
Pants has a Slack channel.

00:57:31.620 --> 00:57:34.900
You can join their Slack and ask about things.

00:57:34.900 --> 00:57:37.780
And so those two communities have been really good

00:57:37.780 --> 00:57:39.340
and really helpful in this.

00:57:39.340 --> 00:57:42.700
A lot of good talks that are available on YouTube too.

00:57:42.700 --> 00:57:45.260
So just, yeah, there's definitely resources out there

00:57:45.260 --> 00:57:49.180
and a lot of people have fought this for a while, so.

00:57:49.180 --> 00:57:50.860
- Yeah, excellent.

00:57:50.860 --> 00:57:53.100
You know, to start from just create a function

00:57:53.100 --> 00:57:54.300
and start typing.

00:57:54.300 --> 00:57:56.100
- Yeah, yeah.

00:57:56.100 --> 00:57:57.220
- Cool.

00:57:57.220 --> 00:57:59.020
All right, well, before you get out of here though,

00:57:59.020 --> 00:58:03.820
let's get your recommendation for a PyPI package.

00:58:03.820 --> 00:58:05.580
Something notable, something fun.

00:58:05.580 --> 00:58:09.260
- I probably, you know, we've talked a lot about it,

00:58:09.260 --> 00:58:11.500
but Power Tools is definitely one

00:58:11.500 --> 00:58:14.820
that is like everyday getting used for me.

00:58:14.820 --> 00:58:18.380
So the, yeah, Power Tools for Lambda and Python,

00:58:18.380 --> 00:58:21.460
they actually support other languages too.

00:58:21.460 --> 00:58:24.420
So they have like the same functionality for like,

00:58:24.420 --> 00:58:27.220
you know, Node.js, you know, for like TypeScript and .NET.

00:58:27.220 --> 00:58:32.220
And so, yeah, but this one definitely leveraging Power Tools

00:58:32.220 --> 00:58:39.460
and Pydantic together just really made like a serverless

00:58:39.460 --> 00:58:40.780
a lot of fun to write.

00:58:40.780 --> 00:58:44.420
So yeah, definitely doing great things there.

00:58:44.860 --> 00:58:45.700
- Excellent.

00:58:45.700 --> 00:58:47.180
Well, I'll put all those things in the show notes.

00:58:47.180 --> 00:58:49.740
And it's been great to talk to you.

00:58:49.740 --> 00:58:54.740
Thanks for sharing your journey down the serverless path.

00:58:54.740 --> 00:58:56.980
- Yep, thanks for having me.

00:58:56.980 --> 00:58:57.820
- You bet.

00:58:57.820 --> 00:58:58.660
- Enjoy chatting.

