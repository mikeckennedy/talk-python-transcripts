WEBVTT

00:00:00.000 --> 00:00:05.000
- Hello, hello, hello everyone out there.


00:00:05.000 --> 00:00:09.400
Rob, Tom, nice to have you all on the show.


00:00:09.400 --> 00:00:10.800
- Yeah, thanks for having us.


00:00:10.800 --> 00:00:11.840
- Yeah, you bet.


00:00:11.840 --> 00:00:13.200
If you're out there watching the live stream,


00:00:13.200 --> 00:00:14.760
please put some comments,


00:00:14.760 --> 00:00:16.160
and we'll try to make that part of the show.


00:00:16.160 --> 00:00:19.000
If you're watching later, thanks for watching.


00:00:19.000 --> 00:00:20.840
All right, let's kick this off, guys.


00:00:20.840 --> 00:00:25.440
Rob, Tom, welcome to Talk Python To Me.


00:00:25.440 --> 00:00:26.280
- Thank you.


00:00:28.160 --> 00:00:30.280
- It's good to have you both here.


00:00:30.280 --> 00:00:33.320
We get to combine a bunch of fun topics


00:00:33.320 --> 00:00:36.640
and important topics, data science, Python,


00:00:36.640 --> 00:00:41.120
the cloud, big data, as in physically lots of data


00:00:41.120 --> 00:00:43.500
to deal with, and then also climate change


00:00:43.500 --> 00:00:47.020
and being proactive about studying that,


00:00:47.020 --> 00:00:49.880
trying to make predictions and do science


00:00:49.880 --> 00:00:51.200
on huge amounts of data.


00:00:51.200 --> 00:00:54.400
- For sure, looking forward to it.


00:00:54.400 --> 00:00:55.720
- Yeah, this'll be fun.


00:00:55.720 --> 00:00:56.600
- Yeah, absolutely.


00:00:56.600 --> 00:00:58.760
Before we get into those, let's just start real quickly.


00:00:58.760 --> 00:01:01.200
How'd you two get into programming in Python?


00:01:01.200 --> 00:01:02.240
Rob, start with you.


00:01:02.240 --> 00:01:06.720
- Yeah, sure, so I've been a developer for,


00:01:06.720 --> 00:01:08.920
I don't know, let's say 14 years.


00:01:08.920 --> 00:01:13.380
I started at a shop that was doing Sybase Power Builder.


00:01:13.380 --> 00:01:16.200
- That goes back a ways.


00:01:16.200 --> 00:01:17.800
- That's back a ways.


00:01:17.800 --> 00:01:21.000
And I actually, I come from a math background,


00:01:21.000 --> 00:01:23.720
so I didn't know a lot about programming


00:01:23.720 --> 00:01:27.480
and started using Python just sort of like on the side


00:01:27.480 --> 00:01:31.040
to parse some bank statements and do some personal stuff


00:01:31.040 --> 00:01:35.720
and started actually integrating some of our source control


00:01:35.720 --> 00:01:40.360
at the company with Python and had to write


00:01:40.360 --> 00:01:43.400
some C extensions, so got into the Python source code


00:01:43.400 --> 00:01:47.400
and started reading that code and being like,


00:01:47.400 --> 00:01:49.840
oh, this is how programming should work.


00:01:49.840 --> 00:01:50.880
This is really good code.


00:01:51.800 --> 00:01:54.800
That year went to my first PyCon.


00:01:54.800 --> 00:01:55.920
It was just like all in.


00:01:55.920 --> 00:01:58.160
I need to get a different job


00:01:58.160 --> 00:02:00.160
where I'm not doing Power Builder.


00:02:00.160 --> 00:02:03.600
Yeah, really, I kind of credit Python and the code base


00:02:03.600 --> 00:02:07.640
in setting me on a better development path, for sure.


00:02:07.640 --> 00:02:08.840
- Oh, that's super cool.


00:02:08.840 --> 00:02:10.920
PyCon's a fun experience, isn't it?


00:02:10.920 --> 00:02:12.160
- Oh, yeah.


00:02:12.160 --> 00:02:14.000
- Yeah, it's like my geek holiday,


00:02:14.000 --> 00:02:16.880
but sadly, the geek holiday has been canceled


00:02:16.880 --> 00:02:18.000
the last two years.


00:02:18.000 --> 00:02:18.840
- Oh, no.


00:02:18.840 --> 00:02:20.240
- Yeah.


00:02:20.240 --> 00:02:21.240
- Tom, how about you?


00:02:21.240 --> 00:02:25.720
- Kind of similar to a lot of your guests, I think.


00:02:25.720 --> 00:02:29.360
Was in grad school and had to pick up programming


00:02:29.360 --> 00:02:31.280
for research and simulations.


00:02:31.280 --> 00:02:34.920
This was for economics.


00:02:34.920 --> 00:02:38.480
They started us on MATLAB and Fortran,


00:02:38.480 --> 00:02:40.600
which I think goes back maybe further.


00:02:40.600 --> 00:02:43.120
I don't know, almost as far as you can go.


00:02:43.120 --> 00:02:46.080
And anyway, I didn't really care for MATLAB,


00:02:46.080 --> 00:02:48.920
so moved over to Python pretty quickly.


00:02:48.920 --> 00:02:53.880
And then just started enjoying the data analysis side


00:02:53.880 --> 00:02:56.720
more than the research side.


00:02:56.720 --> 00:02:59.280
And got into the whole open source ecosystem


00:02:59.280 --> 00:03:03.840
around pandas and stats models and econometrics libraries.


00:03:03.840 --> 00:03:07.400
So started contributing to open source, dropped out,


00:03:07.400 --> 00:03:09.880
got a job in data science stuff,


00:03:09.880 --> 00:03:12.640
and then moved on to Anaconda,


00:03:12.640 --> 00:03:14.360
where I worked on open source libraries


00:03:14.360 --> 00:03:17.520
like pandas and Dask for a few years.


00:03:17.520 --> 00:03:21.160
- Yeah, in a weird turn of coincidence,


00:03:21.160 --> 00:03:24.280
I was just, the previous episode was with Stan Sievert,


00:03:24.280 --> 00:03:26.400
who you worked with over there, right, at Anaconda?


00:03:26.400 --> 00:03:29.840
- Yeah, yeah, so he's the director of community innovation.


00:03:29.840 --> 00:03:32.320
And then, yeah, so it was a great place to work at.


00:03:32.320 --> 00:03:33.160
Really enjoyed it.


00:03:33.160 --> 00:03:36.400
And then I came onto this team at Microsoft


00:03:36.400 --> 00:03:39.840
almost a year ago now, working on the planetary computer.


00:03:39.840 --> 00:03:41.280
- Yeah, cool.


00:03:41.280 --> 00:03:44.240
Well, the planetary computer stuff sounds super neat.


00:03:44.240 --> 00:03:46.360
You get to play with all the high-end computers


00:03:46.360 --> 00:03:48.400
and the big data and whatnot, right?


00:03:48.400 --> 00:03:49.440
- Yeah, it's a lot of fun.


00:03:49.440 --> 00:03:51.320
Although I did have a chance to play on,


00:03:51.320 --> 00:03:52.160
I think it was Summit,


00:03:52.160 --> 00:03:55.000
which is one of our nation's super computers.


00:03:55.000 --> 00:03:57.200
- Yeah, that's great. - That was a lot of fun.


00:03:57.200 --> 00:03:59.720
- Okay, well, it's hard to beat that, right?


00:03:59.720 --> 00:04:01.560
That's one of the ones that's like,


00:04:01.560 --> 00:04:03.280
takes up a whole room, a huge room.


00:04:03.280 --> 00:04:05.880
That's pretty fantastic. - Yeah, definitely.


00:04:05.880 --> 00:04:08.440
- Awesome, all right, well, what are you two doing today?


00:04:08.440 --> 00:04:10.880
You're both on the planetary computer project.


00:04:10.880 --> 00:04:12.880
Are you, you're working at Microsoft.


00:04:12.880 --> 00:04:14.080
What are you doing there?


00:04:15.200 --> 00:04:17.560
- Yeah, so we're on a pretty small team


00:04:17.560 --> 00:04:19.720
that's building out a planetary computer,


00:04:19.720 --> 00:04:23.480
which really is sort of three components,


00:04:23.480 --> 00:04:27.440
which is a data catalog, hosting a lot,


00:04:27.440 --> 00:04:29.640
petabytes, petabytes of data,


00:04:29.640 --> 00:04:31.760
openly licensed satellite imagery


00:04:31.760 --> 00:04:36.120
and other datasets on Azure's blob storage.


00:04:36.120 --> 00:04:41.160
We're building APIs and running API services


00:04:41.160 --> 00:04:46.160
that ETL the data, encode metadata


00:04:46.160 --> 00:04:48.120
according to the stack specification,


00:04:48.120 --> 00:04:49.520
which we can get into later,


00:04:49.520 --> 00:04:52.640
about that, those datasets,


00:04:52.640 --> 00:04:55.600
putting them into a Postgres database


00:04:55.600 --> 00:04:58.240
and then building API services on top of that.


00:04:58.240 --> 00:05:02.080
That's a lot of what I do is manage the ETL pipelines


00:05:02.080 --> 00:05:07.080
and the APIs, and then expose that data to users,


00:05:07.080 --> 00:05:10.920
environmental data scientists,


00:05:10.920 --> 00:05:14.280
and really anybody, it's just publicly accessible.


00:05:14.280 --> 00:05:15.920
And yeah, that's sort of my side.


00:05:15.920 --> 00:05:18.080
And then there's a compute platform,


00:05:18.080 --> 00:05:20.080
which Tom can talk about.


00:05:20.080 --> 00:05:22.680
- Yeah, so all this is like in service


00:05:22.680 --> 00:05:24.760
of environmental sustainability.


00:05:24.760 --> 00:05:27.960
And so we have, our primary users are like people


00:05:27.960 --> 00:05:31.440
who know how to code, mostly in Python,


00:05:31.440 --> 00:05:34.440
but they're not developers.


00:05:34.440 --> 00:05:36.720
And so, you know, we don't want them having to worry


00:05:36.720 --> 00:05:39.080
about things like Kubernetes or whatever


00:05:39.080 --> 00:05:42.560
to set up a distributed compute cluster.


00:05:42.560 --> 00:05:44.760
So that's where kind of this hub comes in


00:05:44.760 --> 00:05:48.000
is it's a place where users can go,


00:05:48.000 --> 00:05:52.280
log in, get a nice, convenient computing platform


00:05:52.280 --> 00:05:54.360
built on top of JupyterHub and Dask,


00:05:54.360 --> 00:05:57.000
where they can scale out to these really large workflows


00:05:57.000 --> 00:05:59.160
to do whatever analysis they need,


00:05:59.160 --> 00:06:02.480
produce whatever derived datasets they need


00:06:02.480 --> 00:06:05.680
for them to pass along to their decision makers


00:06:05.680 --> 00:06:07.840
in environmental sustainability.


00:06:07.840 --> 00:06:11.000
- Yeah, that's super cool, the platform you're building.


00:06:11.000 --> 00:06:16.080
People who might have some Python skills,


00:06:16.080 --> 00:06:17.640
some data science skills,


00:06:17.640 --> 00:06:21.000
but not necessarily high-end cloud programming, right?


00:06:21.000 --> 00:06:24.320
With handling lots of data, setting up clusters,


00:06:24.320 --> 00:06:25.760
all those kinds of things.


00:06:25.760 --> 00:06:28.000
You just push a button, end up in a notebook.


00:06:28.000 --> 00:06:31.560
The notebook is nearby petabytes of data, right?


00:06:31.560 --> 00:06:32.440
- Right, exactly.


00:06:32.440 --> 00:06:35.400
So we'll talk a lot about like cloud native computing


00:06:36.440 --> 00:06:37.600
or data analysis.


00:06:37.600 --> 00:06:40.680
And so really what that means is just putting the compute


00:06:40.680 --> 00:06:43.440
as close as the data as possible.


00:06:43.440 --> 00:06:46.320
So in the same Azure region.


00:06:46.320 --> 00:06:48.120
- So you just need a big hard drive.


00:06:48.120 --> 00:06:50.880
- Really, really, really big hard drive.


00:06:50.880 --> 00:06:53.360
- That's what the cloud is, it's one big hard drive.


00:06:53.360 --> 00:06:54.720
- Exactly, it is, yeah.


00:06:54.720 --> 00:06:56.560
So super neat.


00:06:56.560 --> 00:06:57.400
Before we get into it though,


00:06:57.400 --> 00:06:58.880
let's just maybe talk real briefly


00:06:58.880 --> 00:07:02.120
about Microsoft and the environment.


00:07:02.120 --> 00:07:06.320
This obviously is an initiative you all are putting together


00:07:06.320 --> 00:07:11.240
to help climate scientists study the climate and whatnot.


00:07:11.240 --> 00:07:14.080
But I was really excited to see last year


00:07:14.080 --> 00:07:16.400
that you all announced that Microsoft


00:07:16.400 --> 00:07:18.880
will be carbon negative by 2030.


00:07:18.880 --> 00:07:20.920
- Yeah, for sure.


00:07:20.920 --> 00:07:25.080
I mean, Microsoft and prior to me joining Microsoft,


00:07:25.080 --> 00:07:26.440
I didn't know any of this,


00:07:26.440 --> 00:07:31.000
but Microsoft has been on the forefront of corporate efforts


00:07:31.000 --> 00:07:34.280
and environmental sustainability for a long time.


00:07:34.280 --> 00:07:38.840
And there's been an internal carbon tax


00:07:38.840 --> 00:07:41.000
that we place on business groups


00:07:41.000 --> 00:07:44.360
that there's actual payments made


00:07:44.360 --> 00:07:46.400
based on how much carbon emission


00:07:46.400 --> 00:07:48.440
each business group creates.


00:07:48.440 --> 00:07:51.720
And that's been used to fund


00:07:51.720 --> 00:07:54.080
the environmental sustainability team and all these efforts.


00:07:54.080 --> 00:07:59.080
And that sort of culminated into these four focus areas


00:07:59.080 --> 00:08:02.520
and commitments that were announced in 2020.


00:08:02.520 --> 00:08:04.880
So carbon's a big one,


00:08:04.880 --> 00:08:07.200
not just carbon negative by 2030,


00:08:07.200 --> 00:08:11.840
but by 2050, actually having removed more carbon


00:08:11.840 --> 00:08:15.560
than Microsoft has ever produced since its inception.


00:08:15.560 --> 00:08:18.480
And that's over scope one, scope two, and scope three,


00:08:18.480 --> 00:08:21.600
which means accounting for downstream


00:08:21.600 --> 00:08:24.320
and upstream providers.


00:08:24.320 --> 00:08:30.200
And then there's a couple more focus areas around waste.


00:08:30.200 --> 00:08:33.280
So by 2030, achieving zero waste


00:08:33.280 --> 00:08:37.800
and around water, becoming water positive


00:08:37.800 --> 00:08:40.360
and ensuring accessibility to clean drinking


00:08:40.360 --> 00:08:44.160
and sanitation water for more than 1.5 million people.


00:08:44.160 --> 00:08:46.400
There's an ecosystem element too,


00:08:46.400 --> 00:08:49.760
by 2025, protecting more land than we use.


00:08:49.760 --> 00:08:54.680
And then also creating a planetary computer,


00:08:54.680 --> 00:08:57.120
which is really using Azure's resources


00:08:58.040 --> 00:09:01.320
in the effort to model, monitor,


00:09:01.320 --> 00:09:04.800
and ultimately manage Earth's natural systems.


00:09:04.800 --> 00:09:06.640
And yeah, so this-


00:09:06.640 --> 00:09:08.640
- That's awesome, that's the part you all come in, right?


00:09:08.640 --> 00:09:09.480
- Yeah, exactly.


00:09:09.480 --> 00:09:11.600
The planetary computers in that ecosystem commitment.


00:09:11.600 --> 00:09:15.000
And yeah, that's what we're working towards.


00:09:15.000 --> 00:09:17.000
- Yeah, very cool.


00:09:17.000 --> 00:09:18.760
Removing all the historical carbon,


00:09:18.760 --> 00:09:20.280
I think is pretty fantastic.


00:09:20.280 --> 00:09:22.920
And being carbon negative, right?


00:09:22.920 --> 00:09:24.720
So much stuff runs on Azure


00:09:24.720 --> 00:09:26.680
and on these couple of large clouds


00:09:26.680 --> 00:09:28.120
that that actually is a statement


00:09:28.120 --> 00:09:33.120
about a large portion of the data center usage as well.


00:09:33.120 --> 00:09:34.080
- For sure.


00:09:34.080 --> 00:09:35.960
- How many data centers does Azure have?


00:09:35.960 --> 00:09:37.240
Like three or four, right?


00:09:37.240 --> 00:09:39.920
- I think it's the most.


00:09:39.920 --> 00:09:41.280
I think it's the most out of any of them.


00:09:41.280 --> 00:09:42.160
- It's a lot, right?


00:09:42.160 --> 00:09:44.120
It's over 50 or something like that?


00:09:44.120 --> 00:09:45.520
Large data centers?


00:09:45.520 --> 00:09:47.360
I don't remember, but it's a big number.


00:09:47.360 --> 00:09:48.520
- They're real number all the time too, yeah.


00:09:48.520 --> 00:09:50.120
- Yeah, yeah, it's like constant.


00:09:50.120 --> 00:09:51.560
So that's a big deal.


00:09:51.560 --> 00:09:53.320
Super cool.


00:09:53.320 --> 00:09:54.440
All right.


00:09:54.440 --> 00:09:56.920
Well, let's talk about this planetary computer.


00:09:56.920 --> 00:10:00.040
You told us a little bit about the motivation there


00:10:00.040 --> 00:10:02.960
and it's made up of three parts, right?


00:10:02.960 --> 00:10:05.440
- Yep.


00:10:05.440 --> 00:10:07.040
- All right, yeah, so tell us about it.


00:10:07.040 --> 00:10:10.520
- Yeah, so there's technically four parts


00:10:10.520 --> 00:10:14.320
because really, we recognize that technology


00:10:14.320 --> 00:10:15.280
for technology's sake


00:10:15.280 --> 00:10:18.000
is just kind of spinning your wheels, right?


00:10:18.000 --> 00:10:21.080
We have to be building all of this data,


00:10:21.080 --> 00:10:22.600
all this data access,


00:10:22.600 --> 00:10:27.600
the analytics platform towards applying data and insights


00:10:27.600 --> 00:10:29.440
to actually making an impact


00:10:29.440 --> 00:10:31.440
on environmental sustainability concerns.


00:10:31.440 --> 00:10:34.440
And that's done not by us, an engineering team,


00:10:34.440 --> 00:10:37.120
like kind of trying to figure out the climate scientists,


00:10:37.120 --> 00:10:40.800
right, we're engaging with organizations


00:10:40.800 --> 00:10:42.800
to build out applications specifically


00:10:42.800 --> 00:10:44.800
on these data and services


00:10:44.800 --> 00:10:49.320
and partnering with organizations that have specific goals.


00:10:49.320 --> 00:10:54.320
So there's an applications pillar to the planetary computer,


00:10:54.320 --> 00:10:56.200
but from an engineering standpoint,


00:10:56.200 --> 00:10:59.800
we're mostly focused on the data catalog,


00:10:59.800 --> 00:11:04.520
the APIs and the hub that we had touched on briefly.


00:11:04.520 --> 00:11:06.280
- Yeah, yeah, and then the applications


00:11:06.280 --> 00:11:09.280
is what the partners and other people building on top of it


00:11:09.280 --> 00:11:10.760
are really doing, right?


00:11:10.760 --> 00:11:13.040
- Exactly, and we participate in that


00:11:13.040 --> 00:11:16.960
and help bring different organizations together


00:11:16.960 --> 00:11:19.440
to build out the applications


00:11:19.440 --> 00:11:23.800
and use the money that we have


00:11:23.800 --> 00:11:26.040
to actually fund applications


00:11:26.040 --> 00:11:29.920
that are specifically aimed at different use cases.


00:11:29.920 --> 00:11:31.320
- Yeah, yeah, very cool.


00:11:31.320 --> 00:11:32.960
So there are some other things


00:11:32.960 --> 00:11:34.440
that are somewhat like this, right?


00:11:34.440 --> 00:11:36.680
Like Google Earth Engine and AWS,


00:11:36.680 --> 00:11:38.720
and probably could describe this yourself.


00:11:38.720 --> 00:11:41.880
You wanna do a compare and contrast for us?


00:11:41.880 --> 00:11:43.120
- Sure. - Either of you?


00:11:44.480 --> 00:11:49.480
- Yeah, so Google Earth Engine is sort of the bar that's set


00:11:49.480 --> 00:11:54.080
as far as using cloud compute resources for earth science.


00:11:54.080 --> 00:11:57.800
And it's an amazing platform


00:11:57.800 --> 00:11:59.560
that's been around for a long time


00:11:59.560 --> 00:12:03.120
and is really just like a giant compute cluster


00:12:03.120 --> 00:12:06.400
that has interfaces into an API


00:12:06.400 --> 00:12:08.760
and sort of like a JavaScript interface into it


00:12:08.760 --> 00:12:13.120
that you can run geospatial analytics.


00:12:13.120 --> 00:12:16.400
And so it's a great, like I said, a great tool.


00:12:16.400 --> 00:12:18.600
Can't sing its praises enough.


00:12:18.600 --> 00:12:20.600
One of the aspects of it


00:12:20.600 --> 00:12:25.400
that make it less useful in certain contexts


00:12:25.400 --> 00:12:29.160
is that it is a little bit of a black box, right?


00:12:29.160 --> 00:12:31.080
The operations, the geospatial operations


00:12:31.080 --> 00:12:32.160
that you can do on it,


00:12:32.160 --> 00:12:34.400
the way that you can manipulate the data


00:12:34.400 --> 00:12:37.720
are sort of whatever Google Earth Engine provides.


00:12:37.720 --> 00:12:40.120
If you wanted to run a PyTorch model


00:12:40.120 --> 00:12:42.080
against a large set of satellite imagery,


00:12:42.080 --> 00:12:43.560
that's like a lot more difficult.


00:12:43.560 --> 00:12:45.680
You can't really do that inside of Google Earth Engine.


00:12:45.680 --> 00:12:47.760
You have to like ship data out and ship data in


00:12:47.760 --> 00:12:51.920
and getting data in and out of the system is a little tough


00:12:51.920 --> 00:12:54.040
'cause it's like sort of a singular solution


00:12:54.040 --> 00:12:57.280
and they can optimize a lot based on that.


00:12:57.280 --> 00:13:01.440
So the approach we're taking is more a modular approach,


00:13:01.440 --> 00:13:04.920
leaning heavily on the open source ecosystems of tools,


00:13:04.920 --> 00:13:09.080
trying to make sure that the open source users


00:13:09.080 --> 00:13:12.320
are first-class users that we're thinking of first.


00:13:12.320 --> 00:13:15.280
And that if people wanna just use our data,


00:13:15.280 --> 00:13:17.680
we just have Cloud Optimized GeoTIFF,


00:13:17.680 --> 00:13:20.240
these flat file formats on Blob Storage,


00:13:20.240 --> 00:13:21.080
go ahead and use it.


00:13:21.080 --> 00:13:21.960
You don't have to use any of the other stuff


00:13:21.960 --> 00:13:23.120
that we're building.


00:13:23.120 --> 00:13:26.400
But if you wanna do spatiotemporal searches over it,


00:13:26.400 --> 00:13:29.000
we provide an API that's free access


00:13:29.000 --> 00:13:30.800
that allows you to do searches


00:13:30.800 --> 00:13:33.000
and get metadata about the data


00:13:33.000 --> 00:13:35.800
so you don't have to actually read in the petabytes.


00:13:36.920 --> 00:13:39.840
And then also providing the hub experience,


00:13:39.840 --> 00:13:42.840
which brings together that really rich


00:13:42.840 --> 00:13:45.480
open source ecosystem of Python tooling,


00:13:45.480 --> 00:13:49.480
including our tooling and we're also building out


00:13:49.480 --> 00:13:52.040
other mechanisms to access this data.


00:13:52.040 --> 00:13:55.740
But the current focus is really on that Python data science.


00:13:55.740 --> 00:13:59.440
But yeah, considering the open source ecosystem


00:13:59.440 --> 00:14:02.480
sort of as our user experience


00:14:02.480 --> 00:14:06.600
and try to treat that as like the first-class use case.


00:14:06.600 --> 00:14:08.160
- Yeah, that's fantastic.


00:14:08.160 --> 00:14:09.800
Tom, tell me if I have this right.


00:14:09.800 --> 00:14:12.960
I feel like my limited experience working with this


00:14:12.960 --> 00:14:15.240
is you've got these incredible amounts of data,


00:14:15.240 --> 00:14:16.800
but they're super huge.


00:14:16.800 --> 00:14:19.640
You all built these APIs that let you ask questions


00:14:19.640 --> 00:14:21.000
and filter it down into like,


00:14:21.000 --> 00:14:23.440
like I just want the map data for this,


00:14:23.440 --> 00:14:25.560
you know, polygon or whatever.


00:14:25.560 --> 00:14:27.520
And then you provide a Jupyter Notebook


00:14:27.520 --> 00:14:30.400
and the compute to do stuff on that result.


00:14:30.400 --> 00:14:32.480
Is that pretty good?


00:14:32.480 --> 00:14:34.480
- Yeah, that's pretty good.


00:14:34.480 --> 00:14:37.880
If you just think like the API is so crucial to have


00:14:37.880 --> 00:14:39.560
and we'll get into what it's built on,


00:14:39.560 --> 00:14:43.040
but just for like the Python analogy here is like,


00:14:43.040 --> 00:14:46.400
imagine that you only had lists for your data structure.


00:14:46.400 --> 00:14:47.920
You didn't have dictionaries.


00:14:47.920 --> 00:14:52.320
And now you have to like traverse this entire list of files


00:14:52.320 --> 00:14:55.400
to figure out where is this one at,


00:14:55.400 --> 00:14:57.240
like in space on earth, where is it at?


00:14:57.240 --> 00:14:59.760
Or what time period is it covering?


00:14:59.760 --> 00:15:01.920
And you know, the nice thing about the API


00:15:01.920 --> 00:15:05.280
is you're able to do very fast lookups


00:15:05.280 --> 00:15:07.520
over space and time with that


00:15:07.520 --> 00:15:10.000
to get down to your subset that you care about


00:15:10.000 --> 00:15:14.240
and then bring it into memory on,


00:15:14.240 --> 00:15:16.680
ideally on machines that are in the same Azure region,


00:15:16.680 --> 00:15:20.560
bring those datasets into memory using tools like X-Array


00:15:20.560 --> 00:15:23.240
or pandas and Dask, things like that.


00:15:23.240 --> 00:15:24.240
- Yeah, very cool.


00:15:24.240 --> 00:15:28.120
So Robbie, you mentioned the Postgres database.


00:15:28.120 --> 00:15:30.960
Does that, do you like parse this data


00:15:30.960 --> 00:15:32.440
and generate the metadata and all that


00:15:32.440 --> 00:15:34.640
and then store some of that information in the database


00:15:34.640 --> 00:15:35.920
so you get to it super quick


00:15:35.920 --> 00:15:38.280
and then you've got the raw files as blob storage,


00:15:38.280 --> 00:15:39.640
something like that?


00:15:39.640 --> 00:15:40.480
- Yeah, for sure.


00:15:40.480 --> 00:15:45.360
I mean, that's as much metadata that you can capture


00:15:45.360 --> 00:15:49.600
and to describe the data so that you can kind of,


00:15:49.600 --> 00:15:51.240
you know, do what Tom said and like ignore the stuff


00:15:51.240 --> 00:15:52.080
that you don't care about


00:15:52.080 --> 00:15:54.080
and just get to the area that you care about.


00:15:54.080 --> 00:15:59.080
We try to extract that and we do that according to a spec


00:16:00.240 --> 00:16:01.760
that is, it's really interesting,


00:16:01.760 --> 00:16:03.880
like community driven spec that,


00:16:03.880 --> 00:16:06.040
one of the biggest complaints about dealing


00:16:06.040 --> 00:16:09.040
with satellite imagery and this Earth's observation imagery


00:16:09.040 --> 00:16:11.400
is that it's kind of a mess.


00:16:11.400 --> 00:16:14.000
There's a lot of different scientific variables


00:16:14.000 --> 00:16:16.640
and sensor variables and things.


00:16:16.640 --> 00:16:19.080
So there's been a community effort over the past,


00:16:19.080 --> 00:16:23.440
I'd say three or four years to develop specifications


00:16:23.440 --> 00:16:26.440
that make this type of information machine readable.


00:16:26.440 --> 00:16:29.040
And so we've kind of bought fully into that


00:16:29.040 --> 00:16:33.000
and have processes to look at the data,


00:16:33.000 --> 00:16:35.320
extract the stack metadata,


00:16:35.320 --> 00:16:39.040
which is just a JSON schema specification with extensions,


00:16:39.040 --> 00:16:42.800
and then write that into Postgres.


00:16:42.800 --> 00:16:45.280
And one of the things that we, you know,


00:16:45.280 --> 00:16:47.560
have been trying to do for like transparency


00:16:47.560 --> 00:16:49.240
and contribution to open source


00:16:49.240 --> 00:16:53.600
is a lot of that ETL code base, those Python,


00:16:53.600 --> 00:16:56.280
the Python code that actually works over the files


00:16:56.280 --> 00:16:59.000
and extracts the metadata is open source


00:16:59.000 --> 00:17:02.480
in the stack utils GitHub organization.


00:17:02.480 --> 00:17:05.800
So we're trying to contribute to that sort of body of work


00:17:05.800 --> 00:17:08.680
of how to generate stack metadata


00:17:08.680 --> 00:17:11.200
for these different data types.


00:17:11.200 --> 00:17:14.280
- You want like the metadata for the exact same image


00:17:14.280 --> 00:17:18.760
that's coming from like the USGS public sector data set,


00:17:18.760 --> 00:17:22.000
you want the stack metadata to be identical for that,


00:17:22.000 --> 00:17:26.120
whether you're using our API or Google Earth engines


00:17:26.120 --> 00:17:27.680
who also provides a stack API.


00:17:27.680 --> 00:17:29.400
And so like we're working together


00:17:29.400 --> 00:17:33.240
on these kind of like shared core infrastructure libraries.


00:17:33.240 --> 00:17:34.200
- Yeah, nice.


00:17:34.200 --> 00:17:36.280
Well, let's dive into some of the data actually


00:17:36.280 --> 00:17:39.080
and talk a little bit about all these datasets.


00:17:39.080 --> 00:17:44.080
So a lot of data, as we said over here,


00:17:44.080 --> 00:17:47.800
maybe highlight some of the important datasets


00:17:47.800 --> 00:17:49.760
that you all have on offer.


00:17:49.760 --> 00:17:54.160
- So Sentinel 2 is our largest


00:17:55.280 --> 00:17:57.560
and is incredibly important.


00:17:57.560 --> 00:18:02.560
It's multi-spectral imagery, optical imagery


00:18:02.560 --> 00:18:07.640
that is a 10 meter resolution.


00:18:07.640 --> 00:18:10.280
So it's the highest resolution.


00:18:10.280 --> 00:18:11.760
And when we talk about satellites,


00:18:11.760 --> 00:18:14.120
we often talk about what is the resolution that's captured


00:18:14.120 --> 00:18:16.160
because something like Landsat,


00:18:16.160 --> 00:18:19.480
which we also have Landsat 8 is 30 meter resolution.


00:18:19.480 --> 00:18:21.920
So once you get down to like street level,


00:18:21.920 --> 00:18:24.360
you can't really see everything's blurry, right?


00:18:25.200 --> 00:18:29.400
- Each pixel represents 30 meters on the ground.


00:18:29.400 --> 00:18:31.160
- Exactly. - Right, okay.


00:18:31.160 --> 00:18:33.360
- So Sentinel is 10 meter.


00:18:33.360 --> 00:18:34.680
You get a lot clearer picture.


00:18:34.680 --> 00:18:36.920
You can track if you're doing


00:18:36.920 --> 00:18:40.320
sort of deforestation monitoring, for instance,


00:18:40.320 --> 00:18:43.520
like you can really track the edge of the deforestation


00:18:43.520 --> 00:18:44.760
a lot better with 10 meter imagery.


00:18:44.760 --> 00:18:46.160
- Right, or glaciers,


00:18:46.160 --> 00:18:48.440
you wanna understand the boundary of it or something.


00:18:48.440 --> 00:18:49.360
- Exactly.


00:18:49.360 --> 00:18:52.120
And it's still pretty low resolution


00:18:52.120 --> 00:18:54.120
compared to commercially available imagery,


00:18:54.120 --> 00:18:56.360
but as far as open datasets,


00:18:56.360 --> 00:19:00.400
it's a high resolution, it's passively collected.


00:19:00.400 --> 00:19:02.560
I think the revisit rate is,


00:19:02.560 --> 00:19:03.600
oh, I should have this offhand.


00:19:03.600 --> 00:19:05.520
I think it's eight days.


00:19:05.520 --> 00:19:09.720
So you can really do like monitoring use cases with that.


00:19:09.720 --> 00:19:13.080
It generates petabytes and petabytes of data.


00:19:13.080 --> 00:19:15.080
So it's a lot to sort of work over.


00:19:15.080 --> 00:19:17.480
I mean, generating the stack metadata for that,


00:19:17.480 --> 00:19:20.840
it's like you gotta fire up like 10,000 cores


00:19:20.840 --> 00:19:23.120
to kind of run through that.


00:19:23.120 --> 00:19:25.600
And you end up actually reaching the limits


00:19:25.600 --> 00:19:29.120
of how fast you can read and write from different services.


00:19:29.120 --> 00:19:34.120
But yeah, but it's a really great dataset.


00:19:34.120 --> 00:19:38.240
A lot of work is being done against Sentinel-2.


00:19:38.240 --> 00:19:39.280
- So a lot of what I'm seeing


00:19:39.280 --> 00:19:43.320
and I'm reading through here is this annually,


00:19:43.320 --> 00:19:45.400
or this from 2000 to 2006,


00:19:45.400 --> 00:19:47.640
or like the one we were just speaking about is


00:19:47.640 --> 00:19:51.680
since, you know, from 2016.


00:19:51.680 --> 00:19:53.200
So this data is getting refreshed


00:19:53.200 --> 00:19:55.240
and can I ask questions like,


00:19:55.240 --> 00:19:59.400
how did this polygon of map look two years ago


00:19:59.400 --> 00:20:00.960
versus last year versus today?


00:20:00.960 --> 00:20:02.640
- Totally, yeah.


00:20:02.640 --> 00:20:05.160
And you can do that with the sort of API to say,


00:20:05.160 --> 00:20:06.760
okay, here's my polygon of interest.


00:20:06.760 --> 00:20:09.160
This is over my house or whatever,


00:20:09.160 --> 00:20:11.840
you know, fetch me all the images,


00:20:11.840 --> 00:20:14.200
but a lot of satellite imagery,


00:20:14.200 --> 00:20:16.960
I mean, most of it is clouds.


00:20:16.960 --> 00:20:18.600
It's just the earth is covered in clouds.


00:20:18.600 --> 00:20:19.920
You're gonna get a lot of clouds.


00:20:19.920 --> 00:20:23.440
So there's also a metadata about the cloudiness.


00:20:23.440 --> 00:20:26.400
So you can say, okay, well, give me these images over time,


00:20:26.400 --> 00:20:30.640
but I want the scenes to be under 10% cloudy.


00:20:30.640 --> 00:20:34.840
- Right, I'm willing for it to not be exactly 365 days apart,


00:20:34.840 --> 00:20:37.760
but maybe 350 because I get a clear view if I do that,


00:20:37.760 --> 00:20:38.760
something like this.


00:20:38.760 --> 00:20:41.960
- Exactly, and then you could make a little time-lapse


00:20:41.960 --> 00:20:44.760
of how that area has changed over time.


00:20:44.760 --> 00:20:48.720
And in fact, I think there was somebody


00:20:48.720 --> 00:20:51.400
who actually demoed a time-lapse


00:20:51.400 --> 00:20:54.080
of a similar type of time-lapse,


00:20:54.080 --> 00:20:55.280
just grabbing the satellite imagery


00:20:55.280 --> 00:20:57.640
and turning it into a video over an area.


00:20:57.640 --> 00:20:59.360
I forget who exactly that was.


00:20:59.360 --> 00:21:02.240
- Yeah, very neat.


00:21:02.240 --> 00:21:05.160
Yeah, that one, the Sentinel, the large one,


00:21:05.160 --> 00:21:07.880
the revisit time is every five days.


00:21:07.880 --> 00:21:09.960
That's a lot of data. - Five days.


00:21:09.960 --> 00:21:11.000
Yep. - Yeah.


00:21:11.000 --> 00:21:14.000
- Yeah, yeah, it ends up a lot of data, a lot of clouds.


00:21:14.000 --> 00:21:16.200
A lot of clouds in the cloud.


00:21:16.200 --> 00:21:19.560
- Yeah, what about some of these other ones here?


00:21:19.560 --> 00:21:22.560
Got the DayMet, which is gridded estimates


00:21:22.560 --> 00:21:24.960
of weather parameters in North America.


00:21:24.960 --> 00:21:26.840
That's pretty interesting. - Yeah.


00:21:26.840 --> 00:21:29.960
Yeah, so DayMet's actually an example of...


00:21:29.960 --> 00:21:34.760
So a lot of our data is geospatial, like satellite imagery,


00:21:34.760 --> 00:21:36.240
or things that are derived from that,


00:21:36.240 --> 00:21:39.680
like elevation datasets, where you're using the imagery


00:21:39.680 --> 00:21:43.720
to figure out what's the elevation of the land,


00:21:43.720 --> 00:21:46.080
or things like land cover datasets.


00:21:46.080 --> 00:21:48.040
So if you scroll down just a tad,


00:21:48.040 --> 00:21:50.400
the land cover dataset there,


00:21:50.400 --> 00:21:52.600
that's based on Sentinel, actually.


00:21:52.600 --> 00:21:56.080
And so this is saying, for every pixel in Sentinel,


00:21:56.080 --> 00:21:58.040
they took like a mosaic over a year.


00:21:58.040 --> 00:22:02.280
What is that pixel being used for?


00:22:02.280 --> 00:22:07.280
Is it water, trees, buildings, roads, things like that?


00:22:07.280 --> 00:22:11.000
So those are examples based off of satellite imagery


00:22:12.440 --> 00:22:14.440
or aerial photography.


00:22:14.440 --> 00:22:16.160
And then DayMet's an example of something


00:22:16.160 --> 00:22:20.720
that's like the output of a climate or a weather model.


00:22:20.720 --> 00:22:23.640
So these are typically higher dimensional.


00:22:23.640 --> 00:22:26.120
You're gonna have things like temperature,


00:22:26.120 --> 00:22:30.200
well, maximum, minimum temperature, water, pressure, vapor,


00:22:30.200 --> 00:22:32.360
all sorts of things that are stored


00:22:32.360 --> 00:22:36.120
in this really big, n-dimensional cube


00:22:36.120 --> 00:22:38.400
at various coordinates.


00:22:38.400 --> 00:22:40.680
So latitude, longitude, time,


00:22:40.720 --> 00:22:42.720
maybe height above surface.


00:22:42.720 --> 00:22:47.080
So those are stored in typically in formats like XAR,


00:22:47.080 --> 00:22:50.480
which is this cloud native,


00:22:50.480 --> 00:22:52.360
very friendly to object storage,


00:22:52.360 --> 00:22:54.760
way of storing chunked n-dimensional arrays.


00:22:54.760 --> 00:22:56.480
- Is it like streaming friendly?


00:22:56.480 --> 00:22:58.360
You can stream part of it and seek into it,


00:22:58.360 --> 00:22:59.200
that kind of thing?


00:22:59.200 --> 00:23:01.440
- Exactly, and all the metadata is consolidated,


00:23:01.440 --> 00:23:03.240
so you can load in the whole dataset


00:23:03.240 --> 00:23:07.440
in like less than a few hundred milliseconds,


00:23:07.440 --> 00:23:10.680
but then access a specific subset very efficiently.


00:23:10.680 --> 00:23:12.560
- Sure, yeah, very neat.


00:23:12.560 --> 00:23:16.360
Another one that's not directly based off of satellites


00:23:16.360 --> 00:23:20.880
is the high resolution electricity access, I'm guessing.


00:23:20.880 --> 00:23:23.240
And I guess you could sort of approximate it from lights,


00:23:23.240 --> 00:23:25.480
but is it, do you think it's light off the satellite?


00:23:25.480 --> 00:23:27.400
- I think it is from, Ron, do you know?


00:23:27.400 --> 00:23:28.240
Yeah, so I think it's from-


00:23:28.240 --> 00:23:31.280
- Yeah, it's VIRS satellite, okay.


00:23:31.280 --> 00:23:33.200
So it is off of basically just steady and light,


00:23:33.200 --> 00:23:34.040
interesting.


00:23:35.040 --> 00:23:37.680
And we have a few more that are coming online shortly,


00:23:37.680 --> 00:23:39.360
which are kind of more tabular.


00:23:39.360 --> 00:23:44.360
So there's things like US Census gives you like the polygons.


00:23:44.360 --> 00:23:49.160
So, you know, the state of Iowa has these counties


00:23:49.160 --> 00:23:51.640
or census blocks, which are this shape.


00:23:51.640 --> 00:23:53.220
So giving you all those shapes,


00:23:53.220 --> 00:23:55.920
and it has this population, things like that.


00:23:55.920 --> 00:23:59.000
Things like GBIF has, which is, I think on there now,


00:23:59.000 --> 00:24:02.040
has occurrences of like, I think they're like observations


00:24:02.040 --> 00:24:04.920
of somebody spotted this animal or plant


00:24:04.920 --> 00:24:08.160
at this latitude, longitude, at this time, things like that.


00:24:08.160 --> 00:24:10.360
So lots of different types of data.


00:24:10.360 --> 00:24:11.940
- Interesting, a mink was spotted


00:24:11.940 --> 00:24:13.280
running through the streets, okay.


00:24:13.280 --> 00:24:14.800
- Yeah, yeah.


00:24:14.800 --> 00:24:16.160
- You have one for agriculture.


00:24:16.160 --> 00:24:19.080
That's pretty interesting if you were doing something


00:24:19.080 --> 00:24:20.440
with agriculture and farming


00:24:20.440 --> 00:24:23.040
and trying to do ML against that.


00:24:23.040 --> 00:24:24.560
- Well, yeah, that's interesting


00:24:24.560 --> 00:24:28.560
because that's actually run by the National Agriculture,


00:24:30.000 --> 00:24:35.000
I think the FDA, but that's actually aerial imagery,


00:24:35.000 --> 00:24:40.440
RGB, red, green, blue, and then also infrared aerial imagery


00:24:40.440 --> 00:24:43.240
that's collected every, about every three years.


00:24:43.240 --> 00:24:47.840
So that's an example of high resolution imagery


00:24:47.840 --> 00:24:52.200
that's more than, I think it's one meter resolution.


00:24:52.200 --> 00:24:54.520
- Yeah, you can see the little trees and stuff, right?


00:24:54.520 --> 00:24:55.360
- Yeah, exactly. - On the coastline.


00:24:55.360 --> 00:24:57.360
It's very, very accurate, yeah.


00:24:57.360 --> 00:24:59.720
- Great data set specific to the US.


00:24:59.720 --> 00:25:03.360
So again, like Sentinel-2 is global in scope,


00:25:03.360 --> 00:25:06.000
but if you are doing things in the United States,


00:25:06.000 --> 00:25:09.120
NAIP is a great data set to use.


00:25:09.120 --> 00:25:13.440
- Yeah, you've got the USGS 3D elevation for topology.


00:25:13.440 --> 00:25:14.280
That's cool.


00:25:14.280 --> 00:25:19.280
Let's see, and then you have some additional data sets.


00:25:19.280 --> 00:25:21.560
What's the difference between the main ones


00:25:21.560 --> 00:25:22.400
and these additional ones?


00:25:22.400 --> 00:25:23.560
Why are they separated?


00:25:23.560 --> 00:25:29.520
- So we're catching up to where our stack API is.


00:25:29.520 --> 00:25:33.440
Our stack API has all of the data sets we host,


00:25:33.440 --> 00:25:38.280
but the AI for Earth program,


00:25:38.280 --> 00:25:40.360
which hosts all these data sets,


00:25:40.360 --> 00:25:42.640
has been going on since 2017.


00:25:42.640 --> 00:25:45.520
So there's plenty of data sets that they've been hosting


00:25:45.520 --> 00:25:48.320
that haven't yet made their way into the API.


00:25:48.320 --> 00:25:51.760
And that's just because we're getting there.


00:25:51.760 --> 00:25:52.800
It's a bunch of work.


00:25:52.800 --> 00:25:54.280
- I see, so for these additional ones,


00:25:54.280 --> 00:25:56.640
maybe I could directly access them out of blob storage,


00:25:56.640 --> 00:25:58.680
but I can't ask API questions?


00:25:58.680 --> 00:25:59.520
- Exactly.


00:25:59.520 --> 00:26:00.360
- Okay.


00:26:00.360 --> 00:26:03.320
- And then another point, which is kind of interesting,


00:26:03.320 --> 00:26:05.160
talking back to the tabular data,


00:26:05.160 --> 00:26:08.360
is that some of these data formats aren't quite,


00:26:08.360 --> 00:26:12.400
I mean, rasters and imagery fits really nicely in stack,


00:26:12.400 --> 00:26:15.520
and we know how to do spatiotemporal queries over them,


00:26:15.520 --> 00:26:17.440
but some of these data formats,


00:26:17.440 --> 00:26:22.000
they're not as mature as maybe the raster data format,


00:26:22.000 --> 00:26:23.880
or it's not as clear how to host them


00:26:23.880 --> 00:26:25.440
in a cloud optimized format,


00:26:25.440 --> 00:26:28.360
and then host them in a spatiotemporal API.


00:26:28.360 --> 00:26:30.160
So we're actually having to do work to say,


00:26:30.160 --> 00:26:31.480
okay, what are the standards?


00:26:31.480 --> 00:26:33.240
Is it like geo parquet,


00:26:33.240 --> 00:26:36.240
or what are the formats that we're gonna be using


00:26:36.240 --> 00:26:37.320
in hosting these data sets?


00:26:37.320 --> 00:26:39.640
And then how do we actually index the metadata


00:26:39.640 --> 00:26:40.480
through the API?


00:26:40.480 --> 00:26:43.560
So there's a lot of sort of data format specification,


00:26:43.560 --> 00:26:44.840
metadata specification work


00:26:44.840 --> 00:26:48.960
before we can actually host all of these in the API.


00:26:48.960 --> 00:26:50.880
- Yeah, yeah, really nice.


00:26:50.880 --> 00:26:53.360
A lot of good data here, and quite large.


00:26:53.360 --> 00:26:55.600
Let's talk about the ETL for just a minute,


00:26:55.640 --> 00:26:58.680
'cause you threw out some crazy numbers there.


00:26:58.680 --> 00:27:00.880
We're looking at the Sentinel-2 data,


00:27:00.880 --> 00:27:03.160
and it gets refreshed every five days,


00:27:03.160 --> 00:27:04.680
and it's the earth.


00:27:04.680 --> 00:27:09.160
Talk us through what has to happen there.


00:27:09.160 --> 00:27:11.200
- Yeah, so for the Sentinel,


00:27:11.200 --> 00:27:14.000
it's actually daily,


00:27:14.000 --> 00:27:16.160
so it's passive satellite collection.


00:27:16.160 --> 00:27:19.280
So the satellites are just always monitoring,


00:27:19.280 --> 00:27:21.720
always grabbing new imagery,


00:27:21.720 --> 00:27:25.200
and so that comes off to ground stations


00:27:25.200 --> 00:27:27.160
through the European Space Agency.


00:27:27.160 --> 00:27:30.720
And then we have some partners who are taking that,


00:27:30.720 --> 00:27:33.720
converting it to the Cloud Optimus GeoTIFF format,


00:27:33.720 --> 00:27:34.960
putting it on blob storage,


00:27:34.960 --> 00:27:39.120
at which point we run our ingest pipelines,


00:27:39.120 --> 00:27:43.560
look for new imagery, extract the stack metadata,


00:27:43.560 --> 00:27:45.560
and insert that into the database.


00:27:45.560 --> 00:27:46.600
And we just have that running


00:27:46.600 --> 00:27:49.760
in an Azure service called Azure Batch,


00:27:49.760 --> 00:27:54.160
which allows us to run parallel tasks on clusters


00:27:54.160 --> 00:27:56.200
that can auto-scale.


00:27:56.200 --> 00:28:00.560
So if we're doing an ingest of a dataset for the first time,


00:28:00.560 --> 00:28:02.520
there's gonna be a lot of files to process,


00:28:02.520 --> 00:28:05.520
and we can scale that up.


00:28:05.520 --> 00:28:08.280
And it runs Docker containers,


00:28:08.280 --> 00:28:10.760
so we just have a project that defines


00:28:10.760 --> 00:28:12.520
the Docker commands that can run,


00:28:12.520 --> 00:28:16.520
and then we can submit tasks for chunks of the files


00:28:16.520 --> 00:28:18.200
that we are processing.


00:28:18.200 --> 00:28:19.800
That creates the stack items,


00:28:19.800 --> 00:28:21.840
and then another separate process


00:28:21.840 --> 00:28:23.200
actually takes the stack items


00:28:23.200 --> 00:28:26.400
and inserts it into the database.


00:28:26.400 --> 00:28:27.240
- That's cool.


00:28:27.240 --> 00:28:30.840
So it's a little bit like data-driven


00:28:30.840 --> 00:28:35.840
rather than a little bit like Azure Functions or AWS Lambda,


00:28:35.840 --> 00:28:39.320
but processing, we just gotta get all this data


00:28:39.320 --> 00:28:42.200
and just work through it kind of at scale.


00:28:42.200 --> 00:28:43.040
- Yeah, for sure.


00:28:43.040 --> 00:28:44.480
Right now, it's a little bit,


00:28:44.480 --> 00:28:47.160
you know, we're still building the plane


00:28:47.160 --> 00:28:49.640
as we're flying it,


00:28:49.640 --> 00:28:52.640
but the next iteration is actually gonna be


00:28:52.640 --> 00:28:55.960
a lot more reactive and based on another Azure service


00:28:55.960 --> 00:28:57.800
called Event Grid,


00:28:57.800 --> 00:29:00.160
where you can get notifications of new blobs


00:29:00.160 --> 00:29:03.120
going into storage and then put messages into queues


00:29:03.120 --> 00:29:06.800
that can then turn into these Azure batch tasks


00:29:06.800 --> 00:29:07.640
that are running.


00:29:07.640 --> 00:29:08.480
- Right, I see.


00:29:08.480 --> 00:29:10.480
So you just get something that drops it in the blob storage


00:29:10.480 --> 00:29:12.360
and it kicks off everything from there


00:29:12.360 --> 00:29:13.600
and you don't have to worry about it.


00:29:13.600 --> 00:29:14.920
- Yep.


00:29:14.920 --> 00:29:18.080
- And then we publish those to our users,


00:29:18.080 --> 00:29:19.640
saying, "Hey, this is ready now,"


00:29:19.800 --> 00:29:23.560
if they subscribe to that Event Grid topic.


00:29:23.560 --> 00:29:24.400
- Oh, that's cool.


00:29:24.400 --> 00:29:27.040
There's a way to get notified of refreshes


00:29:27.040 --> 00:29:28.800
and things like that?


00:29:28.800 --> 00:29:29.640
- Not yet.


00:29:29.640 --> 00:29:30.960
We're hoping to get that end of year,


00:29:30.960 --> 00:29:33.040
but yeah, the idea is that we would have


00:29:33.040 --> 00:29:35.960
basically a live feed of new imagery.


00:29:35.960 --> 00:29:38.480
I mean, what I would really like to see


00:29:38.480 --> 00:29:39.880
just for myself, my own interest,


00:29:39.880 --> 00:29:43.120
is to be able to have my areas of interest


00:29:43.120 --> 00:29:45.640
and then just go to a page that shows


00:29:45.640 --> 00:29:48.480
almost an Instagram feed of Sentinel images


00:29:48.480 --> 00:29:49.640
over that area.


00:29:49.640 --> 00:29:51.560
It's like, "Oh, this new one, it's not cloudy.


00:29:51.560 --> 00:29:52.960
"Look at that one."


00:29:52.960 --> 00:29:55.120
You know, it's something I'm monitoring.


00:29:55.120 --> 00:29:58.600
But yeah, generally we'll be publishing new stack items


00:29:58.600 --> 00:30:00.440
so that if you're running AI models


00:30:00.440 --> 00:30:02.960
off of the imagery as it comes in,


00:30:02.960 --> 00:30:05.560
you can do that processing based off of events.


00:30:05.560 --> 00:30:06.400
- Yeah, that'd be cool.


00:30:06.400 --> 00:30:07.760
I'm only interested in Greenland.


00:30:07.760 --> 00:30:09.920
I don't care if you've updated Arizona or not.


00:30:09.920 --> 00:30:12.240
Just tell me if Greenland has changed,


00:30:12.240 --> 00:30:14.520
then I'm gonna rerun my model on it or something.


00:30:14.520 --> 00:30:15.920
- Right.


00:30:15.920 --> 00:30:17.040
Cool.


00:30:17.040 --> 00:30:18.200
All right, let's see.


00:30:18.200 --> 00:30:22.760
So that's the data part, data catalog.


00:30:22.760 --> 00:30:24.240
And then we have the API and the hub,


00:30:24.240 --> 00:30:25.080
which I wanna get to,


00:30:25.080 --> 00:30:28.160
but I kinda wanna just sort of put some perspective


00:30:28.160 --> 00:30:30.200
on what people have been doing with this,


00:30:30.200 --> 00:30:33.160
some of your partner stuff under the applications thing.


00:30:33.160 --> 00:30:36.160
So Tom, which ones do you think we should highlight


00:30:36.160 --> 00:30:38.080
from those that are interesting?


00:30:38.080 --> 00:30:42.320
- We kinda talked about the land cover data set.


00:30:42.320 --> 00:30:47.320
So we worked with Impact Observatory and Esri to do that.


00:30:47.320 --> 00:30:49.800
And so like they were a,


00:30:49.800 --> 00:30:51.800
we had some tips about how to use Azure Batch


00:30:51.800 --> 00:30:54.520
'cause that's a very big Azure Batch job


00:30:54.520 --> 00:30:56.600
to generate that land cover map.


00:30:56.600 --> 00:30:59.240
So pulling down the Sentinel data that we're hosting


00:30:59.240 --> 00:31:01.120
and then running their model over it.


00:31:01.120 --> 00:31:06.120
So that was a fun data set to see come together


00:31:06.120 --> 00:31:08.640
and then use now.


00:31:08.640 --> 00:31:13.640
The carbon plan, carbon monitoring app,


00:31:13.640 --> 00:31:17.280
risk assessment application.


00:31:17.280 --> 00:31:18.800
That's like a really cool,


00:31:18.800 --> 00:31:23.120
well, so it's a cool like JavaScript application


00:31:23.120 --> 00:31:25.760
that you can view risks on.


00:31:25.760 --> 00:31:29.640
So these companies are buying like carbon offsets


00:31:29.640 --> 00:31:35.720
that are force trees that are planted to offset carbon.


00:31:35.720 --> 00:31:39.280
But there's a problem that we know about now


00:31:39.280 --> 00:31:42.240
is like the wildfires are burning down


00:31:42.240 --> 00:31:44.000
some of those forests.


00:31:44.000 --> 00:31:44.840
And so- - Right.


00:31:44.840 --> 00:31:46.400
It doesn't help if you planted a bunch of trees


00:31:46.400 --> 00:31:48.720
to offset your carbon if they go up in smoke, right?


00:31:48.720 --> 00:31:49.680
- Right, yeah.


00:31:49.680 --> 00:31:54.000
So carbon plan did a bunch of research, first of all,


00:31:54.000 --> 00:31:57.600
on essentially a hub.


00:31:57.600 --> 00:32:00.080
They did the research before our hub existed,


00:32:00.080 --> 00:32:03.880
but we were working with these community members to,


00:32:03.880 --> 00:32:07.280
and they have a very similar setup to what we have now,


00:32:07.280 --> 00:32:11.680
to do the research, to train the models and all that,


00:32:11.680 --> 00:32:15.720
that goes into this visualization here of how likely,


00:32:15.720 --> 00:32:19.720
what are the different risks for each plot of land


00:32:19.720 --> 00:32:20.800
in the US?


00:32:20.800 --> 00:32:24.640
Yeah, so that was a great collaboration there.


00:32:24.640 --> 00:32:25.480
- Yeah, this is neat.


00:32:25.480 --> 00:32:26.840
One of the things I was wondering


00:32:26.840 --> 00:32:28.720
when I was looking at these is,


00:32:28.720 --> 00:32:31.360
you all are hosting this large amounts of data


00:32:31.360 --> 00:32:33.520
and you're offering compute to study them.


00:32:33.520 --> 00:32:37.080
How does something like carbon plan take that data


00:32:37.080 --> 00:32:40.160
and build this seemingly independent website?


00:32:40.160 --> 00:32:42.400
- Yeah, yeah.


00:32:42.400 --> 00:32:44.200
- Does that run directly on that data


00:32:44.200 --> 00:32:46.200
or do they like export some stuff


00:32:46.200 --> 00:32:47.480
and then run it on their side?


00:32:47.480 --> 00:32:48.600
Or what's the story?


00:32:48.600 --> 00:32:50.240
- Yep, so this was,


00:32:50.240 --> 00:32:53.340
they would have been doing all like the heavy duty compute


00:32:53.340 --> 00:32:57.440
ahead of time to train the models and everything


00:32:57.440 --> 00:33:01.280
to gather the statistics necessary to power this.


00:33:01.280 --> 00:33:02.120
So then at that point,


00:33:02.120 --> 00:33:04.960
it's just a static JavaScript application


00:33:04.960 --> 00:33:07.320
just running in your browser now.


00:33:07.320 --> 00:33:08.440
- How interesting.


00:33:08.440 --> 00:33:09.840
- And I think that's a good point


00:33:09.840 --> 00:33:14.160
'cause it's running against our data,


00:33:14.160 --> 00:33:16.980
but it's running in their own infrastructure, right?


00:33:16.980 --> 00:33:19.640
So it's sort of on the planetary computer,


00:33:19.640 --> 00:33:21.000
but it's like really in this case,


00:33:21.000 --> 00:33:24.880
like using the planetary computer data sets


00:33:24.880 --> 00:33:28.120
in sort of a production setting,


00:33:28.120 --> 00:33:30.520
an infrastructure that they own,


00:33:30.520 --> 00:33:32.720
which is a use case we really wanna support.


00:33:32.720 --> 00:33:37.360
If they need to use search


00:33:37.360 --> 00:33:39.600
in order to find the images that they need,


00:33:39.600 --> 00:33:40.960
they can use our stack APIs,


00:33:40.960 --> 00:33:45.520
but really it's like just an application running in Azure


00:33:45.520 --> 00:33:48.800
that in certain cases with our grants program


00:33:48.800 --> 00:33:52.400
will end up supporting and sponsoring Azure subscriptions


00:33:52.400 --> 00:33:54.680
to run this type of infrastructure.


00:33:54.680 --> 00:33:55.560
But at the end of the day,


00:33:55.560 --> 00:33:58.760
it's really just applications running in the cloud.


00:33:58.760 --> 00:34:00.480
- Right, it's just better if that it's in Azure


00:34:00.480 --> 00:34:01.440
that it's nearby,


00:34:01.440 --> 00:34:03.040
but they could run it anywhere technically, right?


00:34:03.040 --> 00:34:06.180
And just get signed blob storage access or whatever.


00:34:06.180 --> 00:34:09.280
- Yeah, we'll throttle access at a certain point


00:34:09.280 --> 00:34:11.880
if you're trying to egress too much, but.


00:34:11.880 --> 00:34:13.200
- Yeah, I can imagine.


00:34:13.200 --> 00:34:15.000
- Yeah. - Yeah.


00:34:15.000 --> 00:34:15.960
Yeah, very cool.


00:34:15.960 --> 00:34:17.880
I can come over here and zoom in on Portland


00:34:17.880 --> 00:34:21.080
and it looks like we're in a decent bit of greenness still.


00:34:21.080 --> 00:34:22.200
It does rain up here a lot.


00:34:22.200 --> 00:34:23.760
Same for Seattle.


00:34:23.760 --> 00:34:26.520
- Yeah, yeah. - Yeah, quite cool.


00:34:26.520 --> 00:34:28.320
You talked about this grant program.


00:34:28.320 --> 00:34:29.680
What's the story with that?


00:34:30.680 --> 00:34:31.760
People out there listening, they're like,


00:34:31.760 --> 00:34:33.360
"I wanna get into working with this data


00:34:33.360 --> 00:34:35.000
"and building things."


00:34:35.000 --> 00:34:36.360
Grant might sound good to them.


00:34:36.360 --> 00:34:37.280
What is that?


00:34:37.280 --> 00:34:38.480
- Awesome, yeah.


00:34:38.480 --> 00:34:41.800
Look up AI for Earth grants.


00:34:41.800 --> 00:34:45.400
We have rounds of supporting


00:34:45.400 --> 00:34:49.600
folks that are doing environmental sustainability work.


00:34:49.600 --> 00:34:53.240
And there's sort of a range of grant rewards.


00:34:53.240 --> 00:34:57.040
The lowest level is like giving Azure credits.


00:34:58.460 --> 00:35:03.460
Being able to sponsor an account or sponsor resources


00:35:03.460 --> 00:35:06.000
for applications that are being developed


00:35:06.000 --> 00:35:07.560
or research that's being done


00:35:07.560 --> 00:35:10.080
for environmental sustainability.


00:35:10.080 --> 00:35:12.760
And we have folks running the grants program


00:35:12.760 --> 00:35:14.600
and go take the applications.


00:35:14.600 --> 00:35:18.160
And there's different classes that we have


00:35:18.160 --> 00:35:21.080
and summits for each of the classes.


00:35:21.080 --> 00:35:23.800
And then there's more involved grants and larger grants


00:35:23.800 --> 00:35:28.440
as usually as people sort of show progress.


00:35:28.440 --> 00:35:32.840
We actually can end up bringing additional resources


00:35:32.840 --> 00:35:36.840
or paid projects to accomplish specific goals.


00:35:36.840 --> 00:35:39.120
But yeah, if anybody's out there


00:35:39.120 --> 00:35:42.680
and they're doing work in environmental sustainability


00:35:42.680 --> 00:35:44.320
that could benefit from the cloud,


00:35:44.320 --> 00:35:45.960
we'd love to work with you.


00:35:45.960 --> 00:35:47.760
- Cool. - And maybe, yeah.


00:35:47.760 --> 00:35:50.920
Just to clarify, so there's,


00:35:50.920 --> 00:35:52.240
the grants are great for,


00:35:52.240 --> 00:35:55.000
like if you have a complex deployment


00:35:55.000 --> 00:35:56.800
that's using a ton of Azure services


00:35:56.800 --> 00:35:59.400
and you wanna like integrate this all together


00:35:59.400 --> 00:36:01.960
and use the planetary computer data,


00:36:01.960 --> 00:36:04.160
then the grants are a great approach.


00:36:04.160 --> 00:36:06.480
If you're just like an individual researcher


00:36:06.480 --> 00:36:07.880
or a team of researchers


00:36:07.880 --> 00:36:12.200
or whoever who wants to use this data,


00:36:12.200 --> 00:36:14.440
the data's there, it's publicly accessible.


00:36:14.440 --> 00:36:18.600
And if you need a place to compute from,


00:36:18.600 --> 00:36:20.480
that's in Azure, so close to the data


00:36:20.480 --> 00:36:22.920
and you don't already have an Azure subscription,


00:36:22.920 --> 00:36:25.960
then you can sign up for a planetary computer account.


00:36:25.960 --> 00:36:30.440
And so like that's a way lower bar of barrier to entry.


00:36:30.440 --> 00:36:32.280
There's, you just sign up for an account,


00:36:32.280 --> 00:36:33.360
you get approved by us


00:36:33.360 --> 00:36:35.800
and then you're off to the races.


00:36:35.800 --> 00:36:36.640
- That's a great point.


00:36:36.640 --> 00:36:40.640
If you think you need a grant to use the cloud,


00:36:40.640 --> 00:36:42.520
try using the planetary computer first


00:36:42.520 --> 00:36:43.920
'cause you might not.


00:36:43.920 --> 00:36:44.760
- Yeah, very good.


00:36:44.760 --> 00:36:47.480
So what's the business model around this?


00:36:47.480 --> 00:36:49.520
Is there going to be a fee for it?


00:36:49.520 --> 00:36:50.860
Is there some free level?


00:36:50.860 --> 00:36:53.940
Is it always free but restricted how you can use it?


00:36:55.280 --> 00:36:56.440
- So we have- - Right now it's in


00:36:56.440 --> 00:36:57.880
like a private beta, right?


00:36:57.880 --> 00:37:00.200
I can come down and request access to it?


00:37:00.200 --> 00:37:01.200
- Yeah, it's a preview.


00:37:01.200 --> 00:37:05.160
We're still like getting access by requiring requests


00:37:05.160 --> 00:37:08.800
and there's a larger number of requests


00:37:08.800 --> 00:37:10.300
we're approving over time.


00:37:10.300 --> 00:37:14.520
We're still coming up with the eventual


00:37:14.520 --> 00:37:17.840
final sort of target.


00:37:17.840 --> 00:37:22.680
Most likely it will be some sort of limits


00:37:22.680 --> 00:37:25.760
around what you can do as far as compute,


00:37:25.760 --> 00:37:27.080
as far as like data storage,


00:37:27.080 --> 00:37:28.780
once we have features around that.


00:37:28.780 --> 00:37:32.760
And with clear off-boarding of like,


00:37:32.760 --> 00:37:35.000
if you're an enterprise organization


00:37:35.000 --> 00:37:37.060
that wants to utilize this technology,


00:37:37.060 --> 00:37:40.600
there should be paid services that allow you


00:37:40.600 --> 00:37:42.800
to just as easily do it as you're doing


00:37:42.800 --> 00:37:44.680
on the planetary computer.


00:37:44.680 --> 00:37:49.640
But if you're doing low usage use cases


00:37:49.640 --> 00:37:54.560
or if your use cases is super environmental,


00:37:54.560 --> 00:37:56.680
sustainability focused,


00:37:56.680 --> 00:37:58.680
and you apply for a grant,


00:37:58.680 --> 00:38:02.880
we could end up, you're still using a paid service


00:38:02.880 --> 00:38:06.400
but we're covering those costs through our grants program.


00:38:06.400 --> 00:38:09.200
So we're still figuring that out as far as,


00:38:09.200 --> 00:38:12.800
I don't see this as something that we're trying to


00:38:12.800 --> 00:38:15.880
turn into a paid service necessarily.


00:38:15.880 --> 00:38:20.360
I think that there's a number of enterprise level services


00:38:20.360 --> 00:38:24.960
that could end up looking a lot like the planetary computer,


00:38:24.960 --> 00:38:29.960
but really we wanna continue to support uses,


00:38:29.960 --> 00:38:33.880
particularly for environmental sustainability use cases


00:38:33.880 --> 00:38:35.320
through this avenue.


00:38:35.320 --> 00:38:40.600
- One of the nice things about our overall approach is,


00:38:40.600 --> 00:38:44.800
since we're so invested in the open source side of things


00:38:44.800 --> 00:38:48.120
is if we're, you might've requested an account a while ago


00:38:48.120 --> 00:38:49.960
and we're like very slowly going through them


00:38:49.960 --> 00:38:52.360
'cause there's just like so much to do,


00:38:52.360 --> 00:38:54.640
but if we're too slow approving your account,


00:38:54.640 --> 00:38:56.680
then you can replicate the hub


00:38:56.680 --> 00:38:58.420
in your own Azure subscription.


00:38:58.420 --> 00:39:03.080
So if we're blocking you or if your needs are just like


00:39:03.080 --> 00:39:06.420
so vastly beyond what we can provide


00:39:06.420 --> 00:39:07.760
within this one subscription,


00:39:07.760 --> 00:39:12.000
then yeah, you can go ahead and do your own setup on Azure


00:39:12.000 --> 00:39:15.840
and get access to our data from your own subscription.


00:39:15.840 --> 00:39:19.920
- Right, because the blob storage is public, right?


00:39:19.920 --> 00:39:21.000
- Exactly, yep.


00:39:21.000 --> 00:39:23.760
- Okay, yeah, very nice.


00:39:23.760 --> 00:39:25.880
Maybe the next two things to talk about


00:39:25.880 --> 00:39:27.920
are the API and the hub,


00:39:27.920 --> 00:39:31.440
but I think maybe those would be good to see together.


00:39:31.440 --> 00:39:32.280
What do you think?


00:39:32.280 --> 00:39:33.600
- Yeah, yeah, definitely.


00:39:33.600 --> 00:39:35.700
- I think I'll let you talk us through


00:39:35.700 --> 00:39:37.840
some scenarios here, Tom.


00:39:37.840 --> 00:39:40.840
- Cool, yeah, so I'm, in this case,


00:39:40.840 --> 00:39:45.840
I've logged into the hub here, so I've, this is a, yeah.


00:39:45.840 --> 00:39:47.200
- Before you go further,


00:39:47.200 --> 00:39:50.440
there's a choice you get when you go there.


00:39:50.440 --> 00:39:54.000
You've got an account and you click start my notebook up.


00:39:54.000 --> 00:39:54.840
- Yeah.


00:39:54.840 --> 00:39:55.760
- It's actually gonna fire up a machine


00:39:55.760 --> 00:39:57.480
and it gives you four choices, right?


00:39:57.480 --> 00:40:00.840
Python with four cores and 32 gigs of memory


00:40:00.840 --> 00:40:02.080
and a Pangea notebook.


00:40:02.080 --> 00:40:06.160
It gives you R with eight cores and R geospatial


00:40:06.160 --> 00:40:09.680
and GPU PyTorch, as well as QGIS,


00:40:09.680 --> 00:40:11.280
which I don't really know what that is.


00:40:11.280 --> 00:40:13.000
Maybe tell us about getting started.


00:40:13.000 --> 00:40:14.480
- QGIS, yeah, yeah.


00:40:14.480 --> 00:40:16.840
So this is a JupyterHub deployment.


00:40:16.840 --> 00:40:19.700
So JupyterHub's this really nice project.


00:40:19.700 --> 00:40:21.760
I think it came out of UC Berkeley


00:40:21.760 --> 00:40:24.820
when they were kind of teaching classes,


00:40:24.820 --> 00:40:27.900
data science courses to like thousands of students at once.


00:40:27.900 --> 00:40:31.560
And, you know, even with like Conda or whatever,


00:40:31.560 --> 00:40:33.320
you don't wanna be trying to manage


00:40:33.320 --> 00:40:37.320
a thousand students' Conda installations or whatever.


00:40:37.320 --> 00:40:38.800
So that's just a nightmare.


00:40:38.800 --> 00:40:41.760
So they had this kind of cloud-based setup


00:40:41.760 --> 00:40:45.880
where you just log in with your credentials or whatever,


00:40:45.880 --> 00:40:48.180
and you get access to a compute environment


00:40:48.180 --> 00:40:50.220
to do your homework in that case


00:40:50.220 --> 00:40:54.040
or do your geospatial data analysis in this case.


00:40:54.040 --> 00:40:57.200
And so this kind of, you mentioned Pangea,


00:40:57.200 --> 00:41:02.600
this is this ecosystem of geophysicists, geoscientists


00:41:02.600 --> 00:41:06.120
who are trying to do scalable geoscience on the cloud


00:41:06.120 --> 00:41:08.320
that Anaconda was involved with.


00:41:09.280 --> 00:41:12.360
And so they kind of pioneered this concept


00:41:12.360 --> 00:41:15.680
of a JupyterHub deployment on Kubernetes


00:41:15.680 --> 00:41:19.760
that's tied to Dask.


00:41:19.760 --> 00:41:21.200
So you can create,


00:41:21.200 --> 00:41:23.840
easily get a single node compute environment here.


00:41:23.840 --> 00:41:26.080
In this case, he's in the Python environment


00:41:26.080 --> 00:41:28.000
or multiple nodes,


00:41:28.000 --> 00:41:30.880
a cluster of machines to do your analysis


00:41:30.880 --> 00:41:33.720
using Dask and Dask gateway.


00:41:33.720 --> 00:41:38.720
- Yeah, it's just a Kubernetes-based computing environment.


00:41:38.720 --> 00:41:40.160
- That's cool.


00:41:40.160 --> 00:41:41.720
And I noticed right away the Dask integration,


00:41:41.720 --> 00:41:44.680
which is for like this massive amounts of data, right?


00:41:44.680 --> 00:41:46.760
'Cause it allows you to scale across machines


00:41:46.760 --> 00:41:49.800
or stream data where you don't have enough to store


00:41:49.800 --> 00:41:51.160
in memory and things like that.


00:41:51.160 --> 00:41:52.000
- Yep, exactly.


00:41:52.000 --> 00:41:55.440
So this is a great thing that we get for Python.


00:41:55.440 --> 00:41:57.000
So Dask is Python specific.


00:41:57.000 --> 00:41:59.240
We do have the other environments like R


00:41:59.240 --> 00:42:03.200
for if you're doing geospatial in R,


00:42:03.200 --> 00:42:06.000
which there's a lot of really great libraries there.


00:42:06.000 --> 00:42:06.960
That's an option.


00:42:06.960 --> 00:42:09.200
That is unfortunately single node.


00:42:09.200 --> 00:42:12.680
There's not really a Dask equivalent there,


00:42:12.680 --> 00:42:15.800
but there's some cool stuff that's being worked on


00:42:15.800 --> 00:42:19.040
like multi-D plier and things like that.


00:42:19.040 --> 00:42:20.760
Anyway, and then there's--


00:42:20.760 --> 00:42:22.520
- People haven't, yeah, cool.


00:42:22.520 --> 00:42:25.280
People haven't seen Dask running in Jupyter notebook.


00:42:25.280 --> 00:42:27.840
There's the whole cluster visualization


00:42:27.840 --> 00:42:30.440
and the sort of progress computation stuff


00:42:30.440 --> 00:42:32.480
is super neat to see it go.


00:42:32.480 --> 00:42:33.320
- Yeah, yeah.


00:42:33.320 --> 00:42:36.200
So it's when you're doing these distributed computations,


00:42:36.200 --> 00:42:38.960
it's really key to have an understanding


00:42:38.960 --> 00:42:40.840
of what your cluster's up to.


00:42:40.840 --> 00:42:45.840
It's just crucial to be able to have that information there.


00:42:45.840 --> 00:42:48.960
- And then the example code that you've got there,


00:42:48.960 --> 00:42:52.440
the cloudless mosaic Sentinel-2 notebook,


00:42:52.440 --> 00:42:57.440
it just has the basic create me a cluster in Dask,


00:42:59.240 --> 00:43:04.240
get the client, create four, up to four to 24 workers,


00:43:04.240 --> 00:43:06.720
and then off it goes, right?


00:43:06.720 --> 00:43:08.200
- Yeah, exactly.


00:43:08.200 --> 00:43:10.880
- What is the limits and how has that worked, right?


00:43:10.880 --> 00:43:12.640
As part of getting an account on there,


00:43:12.640 --> 00:43:14.760
you get access to this cluster?


00:43:14.760 --> 00:43:16.040
- Yep, so this is the first thing


00:43:16.040 --> 00:43:18.160
that we talked about today that does require an account.


00:43:18.160 --> 00:43:19.920
So the hub requires an account,


00:43:19.920 --> 00:43:23.240
but accessing the stack API, which we'll see in a second,


00:43:23.240 --> 00:43:25.880
even downloading the data does not require an account.


00:43:25.880 --> 00:43:28.240
You can just do that anonymously.


00:43:28.240 --> 00:43:30.640
- Yeah, and in this case, I think the limit's like


00:43:30.640 --> 00:43:34.840
a thousand cores, something like that,


00:43:34.840 --> 00:43:37.720
or some memory limit as well.


00:43:37.720 --> 00:43:41.160
So that's the limit that you run into there.


00:43:41.160 --> 00:43:43.700
So you can get quite a bit out of this.


00:43:43.700 --> 00:43:47.080
- Yeah, that's real computing there.


00:43:47.080 --> 00:43:48.920
- Yeah, yeah, definitely.


00:43:48.920 --> 00:43:50.400
- A lot of processing power.


00:43:50.400 --> 00:43:53.180
- And in this case, we're using Dask adaptive mode.


00:43:53.180 --> 00:43:56.040
So we're saying, right now there's nothing to do.


00:43:56.040 --> 00:43:57.200
It's just sitting around idly.


00:43:57.200 --> 00:43:59.520
So I have three or four workers,


00:43:59.520 --> 00:44:01.800
but once I start to actually do a computation


00:44:01.800 --> 00:44:02.760
that's using Dask,


00:44:02.760 --> 00:44:06.000
it'll automatically scale up in the background,


00:44:06.000 --> 00:44:08.560
which is a neat feature of Dask.


00:44:08.560 --> 00:44:10.440
Yeah, and so the basic computation,


00:44:10.440 --> 00:44:12.140
the problem that we're trying to do here is


00:44:12.140 --> 00:44:13.360
we have some area of interest,


00:44:13.360 --> 00:44:16.300
which I think is over Redmond, Washington,


00:44:16.300 --> 00:44:17.840
Microsoft headquarters,


00:44:17.840 --> 00:44:20.320
which we're defining as this bounding box.


00:44:20.320 --> 00:44:21.400
- Square, yeah.


00:44:21.400 --> 00:44:22.240
- Yeah, yeah, so that--


00:44:22.240 --> 00:44:23.080
- Heck.


00:44:23.080 --> 00:44:25.480
- Yeah, some sort of, I think that's a polygon,


00:44:25.480 --> 00:44:27.040
a square polygon, but anyway.


00:44:27.720 --> 00:44:30.080
We draw that out and then we say,


00:44:30.080 --> 00:44:35.120
okay, give me all of the Sentinel-2 items


00:44:35.120 --> 00:44:36.400
that cover that area.


00:44:36.400 --> 00:44:38.560
So again, back to what we were talking about at the start


00:44:38.560 --> 00:44:41.160
is like, if you just had files and blob storage,


00:44:41.160 --> 00:44:44.680
that'd be extremely difficult to do.


00:44:44.680 --> 00:44:47.280
But thanks to this nice stack API,


00:44:47.280 --> 00:44:48.480
which we can connect to here


00:44:48.480 --> 00:44:51.320
at planetarycomputer.microsoft.com,


00:44:51.320 --> 00:44:52.400
we're able to quickly say,


00:44:52.400 --> 00:44:56.980
hey, give me all the images from 2016 to 2020


00:44:56.980 --> 00:44:58.960
from Sentinel that cover,


00:44:58.960 --> 00:45:01.920
that intersect with our area of interest here.


00:45:01.920 --> 00:45:03.800
And we're even throwing in a query here saying,


00:45:03.800 --> 00:45:06.200
hey, I only want scenes where the cloud cover


00:45:06.200 --> 00:45:10.800
is less than 25% according to the metadata.


00:45:10.800 --> 00:45:13.320
- Very likely summer in Seattle 'cause the weather--


00:45:13.320 --> 00:45:14.160
- Yeah.


00:45:14.160 --> 00:45:15.200
- Not so much. - Much fewer.


00:45:15.200 --> 00:45:16.040
Yeah, much fewer.


00:45:16.040 --> 00:45:18.760
So quickly within a second or two,


00:45:18.760 --> 00:45:23.760
we get back the 138 scenes items out of the,


00:45:23.760 --> 00:45:25.680
I don't know how many there are in total,


00:45:25.680 --> 00:45:27.360
but like hundreds of thousands,


00:45:27.360 --> 00:45:31.160
millions of individual stack items that--


00:45:31.160 --> 00:45:33.160
- 20 million.


00:45:33.160 --> 00:45:34.880
- 20 million, okay.


00:45:34.880 --> 00:45:36.160
That comprise Sentinel too.


00:45:36.160 --> 00:45:38.300
So we're quickly able to filter that down.


00:45:38.300 --> 00:45:42.040
Next up, we have a bit of signing.


00:45:42.040 --> 00:45:45.000
So this is that bit that we talked about where,


00:45:45.000 --> 00:45:47.360
you know, you can do all this in Anno's MIDI,


00:45:47.360 --> 00:45:50.160
but in order to actually access the data,


00:45:50.160 --> 00:45:51.440
we have you sign the items,


00:45:51.440 --> 00:45:55.000
which basically appends this little token to the URLs.


00:45:55.000 --> 00:45:56.440
And then at that point,


00:45:56.440 --> 00:46:01.440
they can be opened up by any geospatial program


00:46:01.440 --> 00:46:03.000
like QGIS or--


00:46:03.000 --> 00:46:05.720
- It converts a private block storage URL


00:46:05.720 --> 00:46:07.640
to a temporary public one.


00:46:07.640 --> 00:46:09.040
- Yeah, exactly.


00:46:09.040 --> 00:46:09.880
- Okay. - Exactly.


00:46:09.880 --> 00:46:11.360
- So do that.


00:46:11.360 --> 00:46:12.960
- One of the great,


00:46:12.960 --> 00:46:16.000
I don't know, it's just like this kind of incidental


00:46:16.000 --> 00:46:19.920
happenstance that stack and Dask


00:46:19.920 --> 00:46:22.600
actually pair extremely nicely.


00:46:22.600 --> 00:46:24.560
If you think about Dask, the way it operates


00:46:24.560 --> 00:46:28.560
is it's all about lazily operating,


00:46:28.560 --> 00:46:32.480
lazily constructing a task graph of computations.


00:46:32.480 --> 00:46:37.480
And then at the end of your, whatever you're doing,


00:46:37.480 --> 00:46:39.480
computing that all at once.


00:46:39.480 --> 00:46:42.200
That just gives really nice rooms for optimizations


00:46:42.200 --> 00:46:45.060
and maximizing parallelization wherever possible.


00:46:45.060 --> 00:46:49.080
The thing about like geospatial is,


00:46:49.080 --> 00:46:50.640
again, if you didn't have stack,


00:46:50.640 --> 00:46:53.680
you'd have to open up these files


00:46:53.680 --> 00:46:56.480
to understand where on earth is it?


00:46:56.480 --> 00:46:59.280
Like what latitude, longitude does it cover?


00:46:59.280 --> 00:47:01.400
- Right, you have to open up all 20 million files


00:47:01.400 --> 00:47:03.600
and then look and see what metadata says in it, right?


00:47:03.600 --> 00:47:07.840
- Yeah, and in this case, we have like 138 times three files.


00:47:07.840 --> 00:47:12.840
So 600, whatever, 450, 600 items, files here.


00:47:12.840 --> 00:47:15.360
Opening each one of those takes a few,


00:47:15.360 --> 00:47:17.840
maybe 200, 400, 500 milliseconds.


00:47:17.840 --> 00:47:21.000
So it's not awful, but it's too slow


00:47:21.000 --> 00:47:24.960
to really do interactively on any scale


00:47:24.960 --> 00:47:28.120
of any large number of stack items.


00:47:28.120 --> 00:47:30.160
So that's where it stacks great.


00:47:30.160 --> 00:47:31.180
It has all the metadata.


00:47:31.180 --> 00:47:33.340
So we know that this TIFF file,


00:47:33.340 --> 00:47:35.260
this Cloud Optimized GeoTIFF file


00:47:35.260 --> 00:47:37.000
that contains the actual data,


00:47:37.000 --> 00:47:39.080
we know exactly where it is on earth,


00:47:39.080 --> 00:47:40.680
what latitude, longitude it covers,


00:47:40.680 --> 00:47:43.080
what time period it covers, what asset.


00:47:43.080 --> 00:47:44.640
It actually represents wavelength.


00:47:44.640 --> 00:47:47.640
So we're able to very quickly stack these together


00:47:47.640 --> 00:47:50.200
into this X-ray data array.


00:47:50.200 --> 00:47:53.540
In this case, it's fairly small since we've chopped it down.


00:47:53.540 --> 00:47:56.080
If we leave out the filtering,


00:47:56.080 --> 00:47:57.560
it'd be much, much larger


00:47:57.560 --> 00:47:59.080
'cause these are really large scenes.


00:47:59.080 --> 00:48:02.080
But anyway, we're able to really quickly


00:48:02.080 --> 00:48:03.560
generate these data arrays.


00:48:03.560 --> 00:48:06.320
And then using Dask, using our Dask cluster,


00:48:06.320 --> 00:48:08.420
we can actually load those, persist those


00:48:08.420 --> 00:48:12.300
in distributed memory on all the workers on our cluster.


00:48:12.300 --> 00:48:14.840
So that's like- - Yeah, very cool.


00:48:14.840 --> 00:48:15.800
- Very easy.


00:48:15.800 --> 00:48:18.600
Like it's like a few lines of code,


00:48:18.600 --> 00:48:20.360
single function call,


00:48:20.360 --> 00:48:22.760
but it like represents years of effort


00:48:22.760 --> 00:48:25.800
to build up these stack specification


00:48:25.800 --> 00:48:28.120
and all the metadata and then the integration into Dask.


00:48:28.120 --> 00:48:30.000
So it's just a fantastic,


00:48:30.000 --> 00:48:31.560
fantastic result that we have.


00:48:31.560 --> 00:48:33.480
- Yeah, and it's super cool once you,


00:48:33.480 --> 00:48:38.480
once you just called data.persist on the Dask array,


00:48:38.480 --> 00:48:42.320
you could just see in the dashboard of Dask,


00:48:42.320 --> 00:48:44.880
like all of these clusters firing up


00:48:44.880 --> 00:48:48.080
and all this data getting processed and yeah, very-


00:48:48.080 --> 00:48:48.920
- Yep, exactly.


00:48:48.920 --> 00:48:52.320
So in this case, since we have that adaptive mode,


00:48:52.320 --> 00:48:54.920
we'll see additional workers come online here.


00:48:54.920 --> 00:48:56.800
As we start to stress the cluster, it's saying,


00:48:56.800 --> 00:48:58.440
oh, I've got a bunch of unfinished tasks.


00:48:58.440 --> 00:49:01.040
I should bring online some more workers


00:49:01.040 --> 00:49:03.680
and that'll take either a few seconds


00:49:03.680 --> 00:49:06.880
if there's empty space on our cluster or a bit longer.


00:49:06.880 --> 00:49:09.160
And then- - Yeah, I feel like


00:49:09.160 --> 00:49:11.240
with this, if it just sat there and said,


00:49:11.240 --> 00:49:13.720
it's gonna take two minutes and just spun


00:49:13.720 --> 00:49:16.040
with a little star, the Jupyter star, that would be boring.


00:49:16.040 --> 00:49:18.040
But it has this cool animated little dashboard


00:49:18.040 --> 00:49:19.440
and it's like, I'll just, I'm gonna just watch it go.


00:49:19.440 --> 00:49:20.280
Look at it go.


00:49:20.280 --> 00:49:22.680
It's kind of like defragging your hard dive


00:49:22.680 --> 00:49:23.520
with the old days.


00:49:23.520 --> 00:49:24.360
(laughing)


00:49:24.360 --> 00:49:26.120
It's 'cause you watch these little bars go across.


00:49:26.120 --> 00:49:28.760
It's very bizarre, bizarrely satisfying.


00:49:28.760 --> 00:49:30.680
- Yep, I will definitely just spend some time


00:49:30.680 --> 00:49:32.200
sitting here watching it.


00:49:32.200 --> 00:49:33.040
(laughing)


00:49:33.040 --> 00:49:35.160
You know, it's simply like monitoring.


00:49:35.160 --> 00:49:36.680
There's like a lot of communication here.


00:49:36.680 --> 00:49:38.240
There shouldn't be, but really I'm just


00:49:38.240 --> 00:49:40.040
watching the lines move.


00:49:40.040 --> 00:49:41.080
- While the thing is working,


00:49:41.080 --> 00:49:44.020
let me take a question from the live stream.


00:49:45.440 --> 00:49:49.800
Simperia asks, can users bring their own data


00:49:49.800 --> 00:49:53.440
to this sort of processing or, you know,


00:49:53.440 --> 00:49:55.120
'cause you've got the datasets that you have,


00:49:55.120 --> 00:49:58.760
is there a way to bring other research data over?


00:49:58.760 --> 00:50:02.040
- Yeah, so the answer now is like, yes,


00:50:02.040 --> 00:50:05.120
but you kind of have to do a lot of effort


00:50:05.120 --> 00:50:07.920
to get it there.


00:50:07.920 --> 00:50:11.000
Like, so your own data, you probably,


00:50:11.000 --> 00:50:13.480
maybe you do have like your own stack API


00:50:13.480 --> 00:50:16.080
and database setup and all of that,


00:50:16.080 --> 00:50:19.360
but that's publicly accessible or you have a token for.


00:50:19.360 --> 00:50:22.240
So most users don't already have that.


00:50:22.240 --> 00:50:24.080
So you can't, there's this real divide


00:50:24.080 --> 00:50:25.960
between the datasets that we provide


00:50:25.960 --> 00:50:30.040
with our nice stack API and like your own custom dataset


00:50:30.040 --> 00:50:32.560
that might be a pile of files and blob storage.


00:50:32.560 --> 00:50:34.640
And you could access it that way, certainly,


00:50:34.640 --> 00:50:36.640
but there's kind of a divide there.


00:50:36.640 --> 00:50:37.680
So that is definitely something


00:50:37.680 --> 00:50:39.280
that we're interested in improving


00:50:39.280 --> 00:50:43.720
is making user datasets like that are private to you,


00:50:43.720 --> 00:50:47.520
feel as nice to work with as our own public datasets.


00:50:47.520 --> 00:50:49.560
- Yeah, another thing that I saw when I was looking through


00:50:49.560 --> 00:50:52.640
is said under the datasets available, it says,


00:50:52.640 --> 00:50:53.720
or if you have your own data


00:50:53.720 --> 00:50:55.880
and you'd like to contribute, contact us.


00:50:55.880 --> 00:50:57.920
And that's a slightly different question.


00:50:57.920 --> 00:51:02.640
They were just asking, you know, that's the one question


00:51:02.640 --> 00:51:04.000
was, well, I have my own data, I wanna use it.


00:51:04.000 --> 00:51:07.120
This is like how I've, I work at a university or something.


00:51:07.120 --> 00:51:07.960
I've got all this data,


00:51:07.960 --> 00:51:09.240
I wanna make it available to the world.


00:51:09.240 --> 00:51:10.600
What's the story with that?


00:51:10.600 --> 00:51:14.240
- Rob, do you wanna do that one?


00:51:14.240 --> 00:51:18.040
- Yeah, so we have a backlog of datasets


00:51:18.040 --> 00:51:20.680
that we're onboarding onto Azure Blob Storage


00:51:20.680 --> 00:51:23.800
and then importing into the API.


00:51:23.800 --> 00:51:25.200
Still working through that backlog,


00:51:25.200 --> 00:51:28.560
but always on the lookout for good datasets


00:51:28.560 --> 00:51:31.760
that have real use cases in environmental sustainability.


00:51:31.760 --> 00:51:34.480
If there's a group that's doing some research


00:51:34.480 --> 00:51:35.800
or doing building applications


00:51:35.800 --> 00:51:38.560
that have environmental sustainability impact


00:51:38.560 --> 00:51:39.800
and they need a dataset,


00:51:39.800 --> 00:51:41.800
that certainly bumps it up on our list.


00:51:41.800 --> 00:51:43.560
So yeah, I would love to hear from anybody


00:51:43.560 --> 00:51:48.120
that has datasets that you're looking to expose publicly,


00:51:48.120 --> 00:51:50.680
host on the planetary computer for anybody to use


00:51:50.680 --> 00:51:54.720
and need a place to host it, yeah.


00:51:54.720 --> 00:51:55.640
- Yeah, very cool.


00:51:55.640 --> 00:51:59.520
All right, Tom, your graph stopped moving around.


00:51:59.520 --> 00:52:01.040
Let's see what might be done.


00:52:01.040 --> 00:52:03.680
- Yeah, so we spent quite a while loading up the data


00:52:04.760 --> 00:52:06.960
and then that's just how it goes.


00:52:06.960 --> 00:52:08.800
You spend a bunch of time loading up data


00:52:08.800 --> 00:52:10.160
and then once it's in memory,


00:52:10.160 --> 00:52:12.200
computations tend to be pretty quick.


00:52:12.200 --> 00:52:15.760
So in this case, we're taking a median over time.


00:52:15.760 --> 00:52:18.080
- Is this the median of the image?


00:52:18.080 --> 00:52:20.080
What is that a median of?


00:52:20.080 --> 00:52:22.240
I heard that means for like a list of the numbers.


00:52:22.240 --> 00:52:23.920
I'm not sure what it means for an image.


00:52:23.920 --> 00:52:25.600
- Yeah, so this is a median over time.


00:52:25.600 --> 00:52:28.120
So our stack here, our data arrays,


00:52:28.120 --> 00:52:32.320
a four dimensional array


00:52:32.320 --> 00:52:34.480
and the dimensions are time, first of all.


00:52:34.480 --> 00:52:37.840
So we had like 138 time slices,


00:52:37.840 --> 00:52:42.080
wavelength, so these red, green, blue, near infrared,


00:52:42.080 --> 00:52:45.560
Sentinel captures like 10 or 12 wavelengths


00:52:45.560 --> 00:52:48.400
and then latitude and longitude.


00:52:48.400 --> 00:52:51.520
So we took the median over time


00:52:51.520 --> 00:52:55.520
and the idea here is that like stuff like roads


00:52:55.520 --> 00:53:01.960
and mountains and forests tend not to move over time.


00:53:02.760 --> 00:53:05.520
They're static relatively


00:53:05.520 --> 00:53:06.840
compared to something like clouds.


00:53:06.840 --> 00:53:09.760
So again, clouds are always a problem.


00:53:09.760 --> 00:53:11.440
And once you take the median over time,


00:53:11.440 --> 00:53:13.480
you kind of get like the average image


00:53:13.480 --> 00:53:15.480
over this entire time period,


00:53:15.480 --> 00:53:17.360
which turns out to be an image


00:53:17.360 --> 00:53:20.840
that doesn't have too many clouds in it.


00:53:20.840 --> 00:53:21.960
- Yeah, it might have no clouds


00:53:21.960 --> 00:53:24.720
because if you kind of averaged them out across all of them


00:53:24.720 --> 00:53:26.320
'cause you already filtered it down pretty low.


00:53:26.320 --> 00:53:27.160
Yeah.


00:53:27.160 --> 00:53:29.640
- Yeah, so now we can see a picture of the Seattle area


00:53:29.680 --> 00:53:32.760
where it's a cloud free composite or a cloudless mosaic.


00:53:32.760 --> 00:53:33.880
- Yeah, beautiful.


00:53:33.880 --> 00:53:36.120
Looks like you got, maybe that's,


00:53:36.120 --> 00:53:37.920
what is that, Lake Washington


00:53:37.920 --> 00:53:40.120
and you've got Rainier there and all sorts of good stuff.


00:53:40.120 --> 00:53:40.960
Yeah.


00:53:40.960 --> 00:53:41.800
- Yeah, I'm sure.


00:53:41.800 --> 00:53:44.360
I actually do not know the geography that well,


00:53:44.360 --> 00:53:46.040
but I have been looking at lots of pictures.


00:53:46.040 --> 00:53:50.000
We tend to use this as our example area a lot, so.


00:53:50.000 --> 00:53:51.000
- Yeah, super cool.


00:53:51.000 --> 00:53:53.400
- Anyway, and one nice thing here is like,


00:53:53.400 --> 00:53:57.440
so we're again, investing heavily in open source,


00:53:57.440 --> 00:54:00.520
investing in building off of open source.


00:54:00.520 --> 00:54:03.720
So we have like all the power of X-Ray to use.


00:54:03.720 --> 00:54:05.920
X-Ray is this like very general purpose


00:54:05.920 --> 00:54:07.960
in-dimensional array computing library.


00:54:07.960 --> 00:54:11.520
It kind of combines the best of NumPy and pandas.


00:54:11.520 --> 00:54:14.760
In this case, we can do something like a group by,


00:54:14.760 --> 00:54:15.800
so if you're familiar with pandas,


00:54:15.800 --> 00:54:16.680
you're familiar with group bys,


00:54:16.680 --> 00:54:18.280
we can group by time.month.


00:54:18.280 --> 00:54:20.520
So I wanna do like a monthly mosaic.


00:54:20.520 --> 00:54:23.920
Maybe I don't wanna combine images from January,


00:54:23.920 --> 00:54:26.400
which might have snow in them with images from July,


00:54:26.400 --> 00:54:27.520
which wouldn't have as much.


00:54:27.520 --> 00:54:28.360
So I can do a--


00:54:28.360 --> 00:54:30.600
- You can do like 12 different images


00:54:30.600 --> 00:54:31.920
or something like that for,


00:54:31.920 --> 00:54:34.960
here's what it kind of averaged out to be in February.


00:54:34.960 --> 00:54:37.840
- Exactly, and so now we have a stack of images,


00:54:37.840 --> 00:54:40.440
12 of them, and we can go ahead and,


00:54:40.440 --> 00:54:43.220
representing a median.


00:54:43.220 --> 00:54:44.840
So we have multiple years


00:54:44.840 --> 00:54:47.000
and we group all of the ones from January together


00:54:47.000 --> 00:54:49.520
and take the median of those.


00:54:49.520 --> 00:54:53.000
And then we get a nice little group


00:54:53.000 --> 00:54:56.040
of cloud-free mosaics here, one for each month.


00:54:56.400 --> 00:54:57.240
- Yeah, and sure enough,


00:54:57.240 --> 00:54:59.280
there is a little less snow around Rainier


00:54:59.280 --> 00:55:00.400
in the summer than in the winter,


00:55:00.400 --> 00:55:02.560
as you would in Cascades.


00:55:02.560 --> 00:55:03.400
- Yep, definitely.


00:55:03.400 --> 00:55:06.760
So that's like a fun little introductory example


00:55:06.760 --> 00:55:07.800
to what the hub gives you.


00:55:07.800 --> 00:55:10.280
It gets you the single node environment,


00:55:10.280 --> 00:55:12.200
which that alone is quite a bit,


00:55:12.200 --> 00:55:14.920
you don't have to mess with fighting


00:55:14.920 --> 00:55:17.240
to get the right set of libraries installed,


00:55:17.240 --> 00:55:18.720
which can be especially challenging


00:55:18.720 --> 00:55:20.600
when you're interfacing with like the C


00:55:20.600 --> 00:55:23.560
and C++ libraries like GDAL.


00:55:23.560 --> 00:55:25.640
So that environment is all set up,


00:55:25.640 --> 00:55:28.240
mostly compatible, should all work for you


00:55:28.240 --> 00:55:29.080
on a single node.


00:55:29.080 --> 00:55:31.640
And then if you do have these larger computations,


00:55:31.640 --> 00:55:34.760
we saw it took a decent while to load the data,


00:55:34.760 --> 00:55:38.520
even with these fast interop between the storage machines


00:55:38.520 --> 00:55:41.800
and the compute machines in the same Azure region,


00:55:41.800 --> 00:55:43.600
but you can scale that out on enough machines


00:55:43.600 --> 00:55:45.400
that your computations complete


00:55:45.400 --> 00:55:47.000
in a reasonable amount of time.


00:55:47.000 --> 00:55:49.200
- Yeah, and because the animations,


00:55:49.200 --> 00:55:51.120
you don't even mind.


00:55:51.120 --> 00:55:52.460
It's super cool.


00:55:52.460 --> 00:55:54.720
So you use the API to really narrow it down


00:55:54.720 --> 00:55:58.120
from 20 million to like 150 or 138 images


00:55:58.120 --> 00:56:00.480
and then keep running on it.


00:56:00.480 --> 00:56:02.160
So one thing that I was wondering


00:56:02.160 --> 00:56:03.840
when I was looking at this is,


00:56:03.840 --> 00:56:09.200
what libraries come included that I can import


00:56:09.200 --> 00:56:11.800
and which ones, if there's something that's not there,


00:56:11.800 --> 00:56:13.680
maybe I really wanna use HTTPS


00:56:13.680 --> 00:56:15.480
and you only have requests or whatever.


00:56:15.480 --> 00:56:18.000
Like, is there a way to get additional libraries


00:56:18.000 --> 00:56:19.960
and packages and stuff in there?


00:56:19.960 --> 00:56:20.800
- Yeah, yeah.


00:56:20.800 --> 00:56:25.520
So we do have a focus on geospatial.


00:56:25.520 --> 00:56:29.560
So that's like, we'll have most of that there already.


00:56:29.560 --> 00:56:34.560
So, X-ray, Dask, Rasterio and all those things.


00:56:34.560 --> 00:56:38.920
But if there is something there, our container.


00:56:38.920 --> 00:56:42.600
So these are all Docker images built from Conda environments


00:56:42.600 --> 00:56:46.080
and that all comes from this repository,


00:56:46.080 --> 00:56:49.680
Microsoft/planetary-computer-containers.


00:56:49.680 --> 00:56:51.760
So if you just, you want HTTPS,


00:56:51.760 --> 00:56:53.880
you add it to the environment.yaml


00:56:53.880 --> 00:56:55.840
and we'll get a new image built


00:56:55.840 --> 00:56:59.000
and then available from the planetary computer.


00:56:59.000 --> 00:57:01.080
And so these are public images.


00:57:01.080 --> 00:57:03.360
They're just on the Microsoft Container Registry.


00:57:03.360 --> 00:57:07.080
So if you want to use our image,


00:57:07.080 --> 00:57:10.560
like you don't wanna fight with getting a compatible version


00:57:10.560 --> 00:57:14.440
of say PyTorch and LibJPG.


00:57:14.440 --> 00:57:15.840
Not that I was doing that recently,


00:57:15.840 --> 00:57:19.200
but if you wanna avoid that pain,


00:57:19.200 --> 00:57:21.400
then you can just use our images locally,


00:57:21.400 --> 00:57:22.680
like from your laptop.


00:57:22.680 --> 00:57:26.480
And you can even like connect to our Dask gateway


00:57:26.480 --> 00:57:29.080
using our images from your local laptop


00:57:29.080 --> 00:57:31.080
and do like some really fun setups there.


00:57:31.080 --> 00:57:31.920
- Yeah, I see.


00:57:31.920 --> 00:57:34.800
'Cause most of the work would be happening in the clusters,


00:57:34.800 --> 00:57:36.800
the Dask clusters, not locally anyway.


00:57:36.800 --> 00:57:38.560
- Yeah, so all the compute happens there


00:57:38.560 --> 00:57:40.240
and then you bring back this little image


00:57:40.240 --> 00:57:42.920
that's your plot, your result.


00:57:42.920 --> 00:57:44.040
- Okay, yeah, very cool.


00:57:44.040 --> 00:57:46.360
So how do I get mine in here?


00:57:46.360 --> 00:57:48.360
Like I see the containers


00:57:48.360 --> 00:57:50.440
and I see you have the last commit here.


00:57:50.440 --> 00:57:52.680
- Yeah, so there's one per.


00:57:52.680 --> 00:57:55.680
Right now, honestly, the easiest way is to send me,


00:57:55.680 --> 00:57:58.040
open up an issue and I'll take care of it for you


00:57:58.040 --> 00:58:00.000
just 'cause I haven't got this continuous deployment


00:58:00.000 --> 00:58:02.520
quite working out, but there's an environment,


00:58:02.520 --> 00:58:03.760
the YAML file there.


00:58:03.760 --> 00:58:05.320
- Oh yeah, you go see,


00:58:05.320 --> 00:58:08.280
yeah, there's quite a few packages in here already.


00:58:08.280 --> 00:58:11.560
- Yep, and those are just the ones we explicitly asked for.


00:58:11.560 --> 00:58:15.040
And then all their dependencies get pulled into a lock file


00:58:15.040 --> 00:58:16.720
and then built into a Docker images.


00:58:16.720 --> 00:58:19.840
And so this is building off a project from Pangeo,


00:58:19.840 --> 00:58:23.640
that group of geo scientists that I mentioned earlier,


00:58:23.640 --> 00:58:25.320
who have been struggling with this problem


00:58:25.320 --> 00:58:27.080
for several years now.


00:58:27.080 --> 00:58:29.800
So they have a really nice Docker eyes set up


00:58:29.800 --> 00:58:32.840
and we're just building off that base image.


00:58:32.840 --> 00:58:36.300
- Cool, yeah, based on the Pangeo container, very cool.


00:58:36.300 --> 00:58:42.080
Sam Apria asks, how long is the temporary URL active for,


00:58:42.080 --> 00:58:44.680
the signed URL, the blob storage?


00:58:45.720 --> 00:58:48.160
- So that actually depends on whether or not


00:58:48.160 --> 00:58:50.560
you're authenticated.


00:58:50.560 --> 00:58:52.540
We have some controls to say,


00:58:52.540 --> 00:58:57.680
the Planetary Computer Hub requires access,


00:58:57.680 --> 00:58:59.120
but also you get an API token,


00:58:59.120 --> 00:59:02.320
which gives you a little bit longer lasting tokens.


00:59:02.320 --> 00:59:09.000
But I forget what the actual current expiries are.


00:59:09.000 --> 00:59:13.920
If you use the Planetary Computer Python library,


00:59:13.920 --> 00:59:16.320
you just pip install Planetary Industrial Computer


00:59:16.320 --> 00:59:19.320
and use that .sign method,


00:59:19.320 --> 00:59:24.940
it will actually request a token.


00:59:24.940 --> 00:59:29.040
And then as the token is going to expire,


00:59:29.040 --> 00:59:30.160
it requests a new token.


00:59:30.160 --> 00:59:32.560
So it reads this token and caches it,


00:59:32.560 --> 00:59:35.520
but it should be long enough for,


00:59:35.520 --> 00:59:39.340
actually pulling down the data files


00:59:39.340 --> 00:59:41.240
that we have available, right?


00:59:41.240 --> 00:59:43.480
Because we're working against


00:59:43.480 --> 00:59:45.960
smaller cloud optimized formats.


00:59:45.960 --> 00:59:48.480
There aren't these 100 gig files


00:59:48.480 --> 00:59:49.680
that you should have to pull down


00:59:49.680 --> 00:59:54.680
and need a single SAS token to last for a really long time.


00:59:54.680 --> 00:59:58.820
So you can re-request if you need a new one as it expires.


00:59:58.820 --> 01:00:01.240
And like I said, that library actually takes care


01:00:01.240 --> 01:00:03.240
of the logic for you there.


01:00:03.240 --> 01:00:05.000
- Oh, that's cool, yeah, very nice.


01:00:05.000 --> 01:00:08.080
All right, guys, really good work with this.


01:00:08.080 --> 01:00:09.920
And it seems like it's early days.


01:00:09.920 --> 01:00:11.800
It seems like it's getting started.


01:00:11.800 --> 01:00:14.680
There's probably gonna be a lot more going on with this.


01:00:14.680 --> 01:00:15.880
- Yeah, for sure.


01:00:15.880 --> 01:00:17.360
- Really fun. - I'm gonna go out on a limb


01:00:17.360 --> 01:00:20.640
and make a big prediction that understanding the climate


01:00:20.640 --> 01:00:22.600
and climate change is gonna be more important,


01:00:22.600 --> 01:00:24.360
not less important in the future.


01:00:24.360 --> 01:00:27.700
So I suspect that's also gonna grow some interest.


01:00:27.700 --> 01:00:29.240
- Might, it might, you know,


01:00:29.240 --> 01:00:34.240
and the new report at PCC is making some heavy predictions.


01:00:34.240 --> 01:00:39.120
And, you know, within the decade,


01:00:39.120 --> 01:00:42.600
you know, we might reach, you know, plus 1.5 Celsius.


01:00:42.600 --> 01:00:45.760
And, you know, we're already in it.


01:00:45.760 --> 01:00:47.040
We're already feeling the effects.


01:00:47.040 --> 01:00:50.960
And, you know, this is the data about our earth


01:00:50.960 --> 01:00:52.600
and it's gonna become more and more important


01:00:52.600 --> 01:00:57.600
as we, you know, mitigate and adapt to these effects.


01:00:57.600 --> 01:00:59.640
So, yeah, I agree.


01:00:59.640 --> 01:01:00.480
I think that's a good prediction.


01:01:00.480 --> 01:01:04.560
- Yeah, if we, thanks, if we are gonna plan our way out


01:01:04.560 --> 01:01:06.720
of it and plan for the future and, you know,


01:01:06.720 --> 01:01:07.720
science our way out of it,


01:01:07.720 --> 01:01:09.520
we're gonna need stuff like this.


01:01:09.520 --> 01:01:10.880
So well done.


01:01:10.880 --> 01:01:14.160
All right, I think we're about out of time.


01:01:14.160 --> 01:01:16.960
So let me ask you both the final two questions here.


01:01:16.960 --> 01:01:18.480
If you're gonna write some Python code,


01:01:18.480 --> 01:01:19.700
what editor do you use?


01:01:19.700 --> 01:01:22.880
Rob?


01:01:22.880 --> 01:01:24.320
- VS Code.


01:01:24.320 --> 01:01:26.640
- I suspect I could guess that, but yeah.


01:01:26.640 --> 01:01:29.700
- Yeah, actually I was a big Emacs user.


01:01:29.700 --> 01:01:34.640
And then when I got this job, switched over to VS Code


01:01:35.780 --> 01:01:37.940
'cause it just integrated better with Windows


01:01:37.940 --> 01:01:42.940
and then really got into the PyLance and the typing system,


01:01:42.940 --> 01:01:45.220
you know, doing type annotations


01:01:45.220 --> 01:01:47.420
and basically having a compiler for the Python code.


01:01:47.420 --> 01:01:48.660
Like really it changed,


01:01:48.660 --> 01:01:50.980
instead of having all of the types in my head


01:01:50.980 --> 01:01:52.660
and having to like worry about all that,


01:01:52.660 --> 01:01:55.260
actually having the type hinting


01:01:55.260 --> 01:01:57.260
was something I wasn't doing a year ago.


01:01:57.260 --> 01:01:59.880
And now it's like drastically improved


01:01:59.880 --> 01:02:01.380
my development experience.


01:02:01.380 --> 01:02:02.380
- It's a huge difference.


01:02:02.380 --> 01:02:04.520
Yeah, and I'm all about that as well.


01:02:04.760 --> 01:02:09.520
People talk about the types being super important


01:02:09.520 --> 01:02:12.320
for things like mypy and other stuff.


01:02:12.320 --> 01:02:14.200
And you know, in a lot of cases it can be,


01:02:14.200 --> 01:02:16.160
but to me, the primary use case is


01:02:16.160 --> 01:02:18.000
when I hit dot after a thing,


01:02:18.000 --> 01:02:19.880
I wanted to tell me what I can do.


01:02:19.880 --> 01:02:22.120
And if I have to go to the documentation,


01:02:22.120 --> 01:02:23.960
then it's kind of like something is failing.


01:02:23.960 --> 01:02:25.240
I shouldn't need documentation.


01:02:25.240 --> 01:02:27.000
I should be able to just, you know,


01:02:27.000 --> 01:02:29.640
auto-complete my way through the world mostly.


01:02:29.640 --> 01:02:30.480
- Totally.


01:02:30.480 --> 01:02:34.160
And I come from a, I was a Scala developer for,


01:02:34.160 --> 01:02:36.400
you know, six, about six years.


01:02:36.400 --> 01:02:39.040
So I was used to very heavy, heavily typed system


01:02:39.040 --> 01:02:41.820
and kind of got away with it from Python.


01:02:41.820 --> 01:02:42.660
I was like, you know what?


01:02:42.660 --> 01:02:43.700
I like that there's not types,


01:02:43.700 --> 01:02:46.480
but I feel like the Python ecosystem


01:02:46.480 --> 01:02:47.800
is really hitting that sweet spot


01:02:47.800 --> 01:02:49.840
of like introducing enough typing,


01:02:49.840 --> 01:02:50.800
where it's really great.


01:02:50.800 --> 01:02:52.800
- And then the inference flies along


01:02:52.800 --> 01:02:54.280
for the rest of the program, yeah.


01:02:54.280 --> 01:02:55.120
- Totally.


01:02:55.120 --> 01:02:56.040
- Yeah.


01:02:56.040 --> 01:02:58.360
All right, Tom, how about you?


01:02:58.360 --> 01:03:00.240
- VS Code as well for most stuff.


01:03:00.240 --> 01:03:03.960
And then Emacs for Magit,


01:03:03.960 --> 01:03:08.160
the Git client and then a bit of Vim every now and then.


01:03:08.160 --> 01:03:09.600
- Right on.


01:03:09.600 --> 01:03:10.640
Very cool.


01:03:10.640 --> 01:03:14.240
All right, then the other question is for either of you,


01:03:14.240 --> 01:03:18.040
there's like a cool, notable PyPI or Conda package


01:03:18.040 --> 01:03:19.680
that you're like, oh, I came across this.


01:03:19.680 --> 01:03:20.520
It was amazing.


01:03:20.520 --> 01:03:21.680
People should know about it.


01:03:21.680 --> 01:03:24.680
Any ideas?


01:03:24.680 --> 01:03:25.500
- Tom, you got one?


01:03:25.500 --> 01:03:26.340
- Sure.


01:03:26.340 --> 01:03:28.280
I'll go with Seaborn.


01:03:28.280 --> 01:03:31.580
It's a plotting library from Michael Wascom


01:03:31.580 --> 01:03:32.760
built on top of Matplotlib.


01:03:32.760 --> 01:03:36.480
It's just really great for exploratory data analysis.


01:03:36.480 --> 01:03:40.320
It's just, yeah, easily, you know,


01:03:40.320 --> 01:03:43.320
easily create these great visualizations


01:03:43.320 --> 01:03:46.360
for mostly tabular data sets, but not exclusively.


01:03:46.360 --> 01:03:47.200
- Oh, that's interesting.


01:03:47.200 --> 01:03:48.720
I know Seaborn and I knew Matplotlib.


01:03:48.720 --> 01:03:50.360
I didn't realize that Seaborn was like,


01:03:50.360 --> 01:03:52.400
let's make Matplotlib easier.


01:03:52.400 --> 01:03:55.840
- Yeah, essentially for this very specific use case,


01:03:55.840 --> 01:03:58.600
you know, Matplotlib is extremely flexible,


01:03:58.600 --> 01:03:59.800
but there's a lot of boilerplate


01:03:59.800 --> 01:04:02.560
and Seaborn just wraps that all up nicely.


01:04:02.560 --> 01:04:03.600
- Yeah, super cool.


01:04:03.600 --> 01:04:06.600
All right, well, thank you so much for being here.


01:04:06.600 --> 01:04:07.500
Final call to action.


01:04:07.500 --> 01:04:08.340
People want to get started


01:04:08.340 --> 01:04:10.240
with Microsoft Planetary Computer.


01:04:10.240 --> 01:04:12.160
Maybe they've got some climate research.


01:04:12.160 --> 01:04:13.000
What do they do?


01:04:13.000 --> 01:04:15.920
- Planetarycomputer.microsoft.com.


01:04:15.920 --> 01:04:18.040
That'll get you anywhere you need to go.


01:04:18.040 --> 01:04:20.080
And then if you want an account,


01:04:20.080 --> 01:04:23.160
then it's /account/request, I believe.


01:04:23.160 --> 01:04:25.800
- Yeah, there's a big request access right at the top.


01:04:25.800 --> 01:04:26.720
You can click that.


01:04:26.720 --> 01:04:27.560
Awesome.


01:04:27.560 --> 01:04:28.800
- Yeah, exactly.


01:04:28.800 --> 01:04:30.640
- All right, Rob, Tom, thank you for being here


01:04:30.640 --> 01:04:32.400
and thanks for all the good work.


01:04:32.880 --> 01:04:33.720
- Thanks for having us.


01:04:33.720 --> 01:04:34.560
- This was great.


01:04:34.560 --> 01:04:36.240
- Yep, bye.


01:04:36.240 --> 01:04:37.080
- See ya.


01:04:37.080 --> 01:04:39.400
Hello?

