WEBVTT

00:00:00.000 --> 00:00:05.040
>> Hey, Jody. >> Hey, how are you?


00:00:05.040 --> 00:00:09.480
>> Awesome to have you here on YouTube. And just in a second on the podcast. Everyone out


00:00:09.480 --> 00:00:13.560
there who's watching, please put comments and thoughts in the live chat, and we'll try


00:00:13.560 --> 00:00:19.640
to make those part of the show. With that, Jody, welcome to Talk Python to Me.


00:00:19.640 --> 00:00:22.640
>> Thank you. I am so thrilled to be on the show.


00:00:22.640 --> 00:00:26.320
>> I'm so thrilled to have you on the show. I've been a fan of your work for a while,


00:00:26.320 --> 00:00:28.760
and we got a chance to get to know each other


00:00:28.760 --> 00:00:30.700
at this year's PyCon.


00:00:30.700 --> 00:00:34.840
And so now here you are on the podcast as well.


00:00:34.840 --> 00:00:35.680
Welcome.


00:00:35.680 --> 00:00:36.800
- Yeah, thank you.


00:00:36.800 --> 00:00:39.640
We had some very nice Mexican food actually,


00:00:39.640 --> 00:00:42.200
or maybe Utah Mexican.


00:00:42.200 --> 00:00:44.480
I don't know quite how I would interpret it.


00:00:44.480 --> 00:00:46.000
It was very good though.


00:00:46.000 --> 00:00:47.640
- It was very good, yeah.


00:00:47.640 --> 00:00:48.880
The food was excellent.


00:00:48.880 --> 00:00:51.840
I thought the parties were great at the conference


00:00:51.840 --> 00:00:56.120
and people who are maybe still holding out on going


00:00:56.120 --> 00:01:01.000
I think personally, I really enjoyed being there. So happy.


00:01:01.000 --> 00:01:06.200
I would say I think it's probably the best conference that I go to yearly.


00:01:06.200 --> 00:01:14.680
And it's like the vibe is so nice. Yeah, it really is. Now, on this show,


00:01:14.680 --> 00:01:22.360
we're going to talk about how data scientists, you're one of them, how data scientists use Python,


00:01:22.360 --> 00:01:26.040
which is somewhat different than maybe a software developer.


00:01:26.040 --> 00:01:30.360
We have, which I guess I'll put myself solidly into that camp.


00:01:30.360 --> 00:01:34.040
I do a bunch of web development, make APIs, I build apps and ship them.


00:01:34.040 --> 00:01:35.800
That's quite a different story.


00:01:35.800 --> 00:01:39.240
And I'm going to have a, I think we have a really great time


00:01:39.240 --> 00:01:40.280
talking about those things.


00:01:40.280 --> 00:01:43.640
But before we do, let's get a little, get to know you a bit.


00:01:43.640 --> 00:01:46.200
How'd you get into programming, Python, data science?


00:01:46.200 --> 00:01:52.280
- Yeah, so probably going hand in hand with maybe not being a developer.


00:01:52.280 --> 00:01:55.700
My story is perhaps a little unconventional.


00:01:55.700 --> 00:01:59.220
So my background is academic, like a lot of data scientists.


00:01:59.220 --> 00:02:02.660
And unsurprisingly, the first language that I learned


00:02:02.660 --> 00:02:06.380
was R because I was doing psychology and health sciences


00:02:06.380 --> 00:02:07.940
and a lot of statistics.


00:02:07.940 --> 00:02:12.460
And I was procrastinating once during my PhD.


00:02:12.460 --> 00:02:15.660
You will find any excuse to not work on your thesis.


00:02:15.660 --> 00:02:17.420
And I think I was reading, oh, you know,


00:02:17.420 --> 00:02:19.580
people who are into statistics,


00:02:19.580 --> 00:02:21.940
you should really learn Python, it's the future.


00:02:21.940 --> 00:02:28.660
I was like, I should learn Python. So I sat down and because I really don't want to write that next chapter. I just exactly exactly


00:02:28.660 --> 00:02:35.140
Um, so I remember it like I actually had this long weekend and I worked my way through I think it was um


00:02:35.140 --> 00:02:40.420
Zed Shaw's learn Python the hard way. This is showing my age, I think and um


00:02:40.420 --> 00:02:43.860
I loved it. Like I completed the course in three days


00:02:43.860 --> 00:02:49.220
And then I didn't know what to do with Python because the stats libraries weren't as developed back then


00:02:49.380 --> 00:02:55.380
So I just put it aside for a couple of years and ended up picking it up again when I started


00:02:55.380 --> 00:03:01.060
working in industry, because obviously I've left academia. And you sort of fairly quickly,


00:03:01.060 --> 00:03:05.620
once you start in data science, move away from more sort of statistical stuff to machine learning.


00:03:05.620 --> 00:03:11.540
And Python really has the libraries for that. So yeah, that's my journey. It's a little bit


00:03:11.540 --> 00:03:17.220
bibs and bobs and stops and starts. But once I kind of picked up Python, it really was love


00:03:17.220 --> 00:03:23.300
at first sight. Oh, that's excellent. What's your PhD in? Computer science, of course,


00:03:23.300 --> 00:03:28.980
right? Of course, of course. You know, it's so funny. You are the third person to ask me


00:03:28.980 --> 00:03:34.260
in two weeks and no one has asked me this question for like two years. My PhD was in hurt feelings.


00:03:34.260 --> 00:03:43.620
Hurt feelings? Yeah. Okay. I say this a little bit blithely. So my PhD being in psychology,


00:03:43.620 --> 00:03:47.380
I was really interested in emotions research and relationships research.


00:03:47.380 --> 00:03:51.620
So I kind of wanted to see what happens to people emotionally


00:03:51.620 --> 00:03:54.540
when close relationships go bad.


00:03:54.540 --> 00:03:58.220
And it's hurt feelings like things like,


00:03:58.220 --> 00:04:01.940
you know, infidelities, rejections, all of that.


00:04:01.940 --> 00:04:05.940
So I was just studying what generates like and


00:04:05.940 --> 00:04:11.940
regulates the intensity of hurt and studied that for four and a half years.


00:04:12.260 --> 00:04:13.700
- Yeah, sounds interesting.


00:04:13.700 --> 00:04:16.100
I'm sure there was a lot of data to process.


00:04:16.100 --> 00:04:17.820
- There was a lot of data to process


00:04:17.820 --> 00:04:21.620
and a lot of very interesting statistics.


00:04:21.620 --> 00:04:24.620
So that was sort of how I got into data science.


00:04:24.620 --> 00:04:26.420
I fell in love with stats in undergrad


00:04:26.420 --> 00:04:29.620
and just kept going down that path.


00:04:29.620 --> 00:04:33.620
- I think a lot of people are drawn to data science


00:04:33.620 --> 00:04:36.940
not with the intent of waking up one day


00:04:36.940 --> 00:04:38.660
and saying, "I'm gonna be a data scientist,"


00:04:38.660 --> 00:04:40.700
but they're excited or inspired


00:04:40.700 --> 00:04:42.140
about something tangential


00:04:42.140 --> 00:04:44.660
and they're like, well, I really need to get something


00:04:44.660 --> 00:04:47.420
better than Excel to work on this, right?


00:04:47.420 --> 00:04:49.220
- Absolutely, yeah, yeah.


00:04:49.220 --> 00:04:51.540
And we'll probably talk about this a little bit later


00:04:51.540 --> 00:04:54.660
about why data scientists use programming.


00:04:54.660 --> 00:04:57.220
And it kind of is like in some ways


00:04:57.220 --> 00:05:00.020
that need to jump from something way more powerful


00:05:00.020 --> 00:05:01.720
and reproducible than Excel.


00:05:01.720 --> 00:05:04.840
- Yeah, yeah, for sure.


00:05:04.840 --> 00:05:05.980
So how about now?


00:05:05.980 --> 00:05:08.220
You said you've left academics.


00:05:08.220 --> 00:05:11.420
What are you doing these days?


00:05:11.420 --> 00:05:15.860
Yeah, so that leap from academia was a long time ago now.


00:05:15.860 --> 00:05:19.100
I think that was like seven years, again, showing my age.


00:05:19.100 --> 00:05:23.620
So for six of those years, I was a data scientist.


00:05:23.620 --> 00:05:27.240
So day-to-day was pretty varied,


00:05:27.240 --> 00:05:31.100
but the job I have now is very different.


00:05:31.100 --> 00:05:34.540
So I currently work as a developer advocate at JetBrains.


00:05:34.540 --> 00:05:37.980
And the way I would describe my job is,


00:05:37.980 --> 00:05:41.980
I'm a liaison between data scientists and JetBrains.


00:05:41.980 --> 00:05:44.740
So I try and advocate for our tools


00:05:44.740 --> 00:05:46.760
to be as good as they can be.


00:05:46.760 --> 00:05:50.020
And I try to recommend ways that people can use our tools


00:05:50.020 --> 00:05:51.060
if I think it's useful,


00:05:51.060 --> 00:05:52.780
but I'm definitely not marketing or sales.


00:05:52.780 --> 00:05:55.260
It's more, if I think this is the right fit for you,


00:05:55.260 --> 00:05:56.340
I'll do it.


00:05:56.340 --> 00:06:01.340
So it's like the way I achieve that is really up to me.


00:06:01.340 --> 00:06:05.180
For me, I really kind of,


00:06:06.720 --> 00:06:10.240
I like to do a mixture of what I call internal and external activities.


00:06:10.240 --> 00:06:14.080
So external activities are actually kind of only tangentially related to the


00:06:14.080 --> 00:06:17.560
products. So this would be an example of an external activity.


00:06:17.560 --> 00:06:22.160
It's just getting out there and educating people about data science or educating


00:06:22.160 --> 00:06:27.520
data scientists about technical topics, things like conference talks or webinars,


00:06:27.520 --> 00:06:30.520
you know, all this sort of stuff.


00:06:31.880 --> 00:06:36.880
And then internal stuff is more focused on maybe things a bit more related to the


00:06:36.880 --> 00:06:40.680
product. So if I think there's a feature that people would be really interested in, I


00:06:40.680 --> 00:06:45.280
might make a video about it or create a blog post.


00:06:45.280 --> 00:06:47.840
So, yeah, it's a real hodgepodge.


00:06:47.840 --> 00:06:53.000
So this week, for example, I've been working on actually a


00:06:53.000 --> 00:06:57.760
materials for a free workshop that they're organizing at EuroPython.


00:06:57.760 --> 00:07:00.000
So I'm going to be volunteering to help out that.


00:07:00.000 --> 00:07:02.460
It's completely unrelated to anything I'm doing at JetBrains.


00:07:02.460 --> 00:07:04.960
It's just a volunteer activity.


00:07:04.960 --> 00:07:07.420
But last week I was at a conference, week before that.


00:07:07.420 --> 00:07:09.880
So you can see the jobs pretty varied.


00:07:09.880 --> 00:07:13.120
- I think developer evangelists,


00:07:13.120 --> 00:07:14.920
it seems like such a fun job.


00:07:14.920 --> 00:07:17.300
I had your colleague, Paul Everett,


00:07:17.300 --> 00:07:19.200
on and we actually talked,


00:07:19.200 --> 00:07:20.840
it's quite a while ago, a couple of years ago,


00:07:20.840 --> 00:07:21.680
three, four years,


00:07:21.680 --> 00:07:23.680
and we had a whole episode on,


00:07:23.680 --> 00:07:27.360
like a panel on what is the developer advocate,


00:07:27.360 --> 00:07:29.320
developer relations job.


00:07:29.320 --> 00:07:32.320
But it just seems like such a great mix of,


00:07:32.320 --> 00:07:35.640
you still get to travel a little bit, see people,


00:07:35.640 --> 00:07:37.280
but you also get to write code


00:07:37.280 --> 00:07:42.280
and work on influencing technology and products and stuff.


00:07:42.280 --> 00:07:46.720
- Yeah, and I think the thing that I started to appreciate


00:07:46.720 --> 00:07:48.600
about the job a few months in is,


00:07:48.600 --> 00:07:50.680
you have a platform with this job,


00:07:50.680 --> 00:07:53.360
and that means you can choose to promote the message


00:07:53.360 --> 00:07:54.480
that you want.


00:07:54.480 --> 00:07:59.280
And a message that, no surprise, is very meaningful for me


00:07:59.280 --> 00:08:01.320
is data science is for everyone.


00:08:01.320 --> 00:08:02.800
Like I hate the gatekeeping


00:08:02.800 --> 00:08:05.060
that can happen in tech communities.


00:08:05.060 --> 00:08:07.420
I think it's quite bad in terms of like


00:08:07.420 --> 00:08:10.460
people being intimidated by math in data science.


00:08:10.460 --> 00:08:13.180
And like, I'm here to say to you,


00:08:13.180 --> 00:08:15.120
if you want it, it's for you.


00:08:15.120 --> 00:08:16.500
It is a very cool field.


00:08:16.500 --> 00:08:19.980
And yeah, it doesn't matter what background you come from.


00:08:19.980 --> 00:08:21.180
- I absolutely agree.


00:08:21.180 --> 00:08:24.100
And I was kind of hinting at that saying like


00:08:24.100 --> 00:08:25.840
a lot of people who don't see themselves


00:08:25.840 --> 00:08:27.460
as developers or programmers,


00:08:27.460 --> 00:08:30.900
like still find really great places,


00:08:30.900 --> 00:08:34.500
really great fits in data science and in programming as well.


00:08:34.500 --> 00:08:36.640
And I also want to second that I don't think


00:08:36.640 --> 00:08:38.220
you really need that much math.


00:08:38.220 --> 00:08:39.780
Maybe if you're trying to build


00:08:39.780 --> 00:08:43.380
the next machine learning model platform,


00:08:43.380 --> 00:08:44.900
then yes, okay.


00:08:44.900 --> 00:08:46.260
But that's not what most people do.


00:08:46.260 --> 00:08:49.060
They take the data, they clean it up,


00:08:49.060 --> 00:08:50.420
they do interesting visualizations


00:08:50.420 --> 00:08:53.860
and maybe put it into some framework for production, right?


00:08:53.860 --> 00:08:58.860
Yeah. And the nice thing is the field is in such a point where you have so many


00:08:58.860 --> 00:09:03.220
frameworks or tools that will handle a lot of this stuff for you.


00:09:03.220 --> 00:09:07.620
Like, I'm not saying you don't need any understanding of what's going on under the hood, but


00:09:07.620 --> 00:09:09.060
you can learn it incrementally.


00:09:09.060 --> 00:09:13.580
And a lot of it is like with software development, where you develop that that smell or


00:09:13.580 --> 00:09:16.620
that instinct for when something is not right.


00:09:16.620 --> 00:09:22.760
That will benefit you more than, you know, knowing how backpropagation


00:09:22.760 --> 00:09:24.400
works from a calculus perspective,


00:09:24.400 --> 00:09:26.320
like that stuff is maybe a bit too much.


00:09:26.320 --> 00:09:28.480
You don't necessarily need it.


00:09:28.480 --> 00:09:31.680
- Yeah, well, let's get into the main topic


00:09:31.680 --> 00:09:33.680
and talk a little bit about, you know,


00:09:33.680 --> 00:09:37.760
how does programming in Python differ


00:09:37.760 --> 00:09:40.240
on the data science side than say,


00:09:40.240 --> 00:09:43.400
you know, me as somebody who builds web apps.


00:09:43.400 --> 00:09:47.280
- Yeah, and maybe we can start by doing an orientation


00:09:47.280 --> 00:09:49.720
to like, what does a data scientist do?


00:09:49.720 --> 00:09:51.480
'Cause I think this confuses a lot of people.


00:09:51.480 --> 00:09:52.400
Yeah, yeah.


00:09:52.400 --> 00:09:57.400
So basically the role of a data scientist is to sort of like,


00:09:57.400 --> 00:10:02.880
like the reason you would hire a data scientist is you have a bunch of data and


00:10:02.880 --> 00:10:07.940
you have an instinct that you can use that data to either improve your internal


00:10:07.940 --> 00:10:11.280
processes or sell some sort of IP.


00:10:11.280 --> 00:10:14.400
So the reason, you know,


00:10:14.400 --> 00:10:19.200
we differ from BI analysts is BI analysts are doing analysis,


00:10:19.200 --> 00:10:21.960
but it's more about business as usual, which is really important.


00:10:22.080 --> 00:10:24.160
You absolutely need BI analysts.


00:10:24.160 --> 00:10:25.620
How are sales going?


00:10:25.620 --> 00:10:27.600
How much have we made versus last year?


00:10:27.600 --> 00:10:29.240
Like those kinds of charts, right?


00:10:29.240 --> 00:10:31.540
Like absolutely fundamental questions.


00:10:31.540 --> 00:10:35.380
Um, so you need to be an analyst before you need a data scientist, but your data


00:10:35.380 --> 00:10:39.600
scientists are more there to push the envelope in a data driven way.


00:10:39.600 --> 00:10:43.140
So we have two main outputs.


00:10:43.140 --> 00:10:48.040
I would say you can either create an analysis and do a report, or you can build


00:10:48.040 --> 00:10:50.920
some sort of model that will go into production.


00:10:51.520 --> 00:10:58.000
So an example might be as a business, I have an instinct that I can get my customers to


00:10:58.000 --> 00:11:03.620
buy more things based on people like them also buying those things.


00:11:03.620 --> 00:11:08.240
So in that case, your data scientists might be able to build you a recommendation engine


00:11:08.240 --> 00:11:13.280
and this, you know, will have a business outcome.


00:11:13.280 --> 00:11:17.200
Developers obviously, on the other hand, have a very different goal.


00:11:17.200 --> 00:11:20.160
Their goal is to create robust software systems.


00:11:20.160 --> 00:11:27.420
So the concerns that they have are things like latency, server load, downtime, things


00:11:27.420 --> 00:11:28.420
like that.


00:11:28.420 --> 00:11:30.620
And it's very interesting.


00:11:30.620 --> 00:11:33.500
And we'll talk about it a bit more when we talk about code, if we kind of get into that


00:11:33.500 --> 00:11:34.500
topic.


00:11:34.500 --> 00:11:41.020
But basically, data scientists are not really interested in creating code for the long term,


00:11:41.020 --> 00:11:45.760
whereas the code becomes the product that software developers write often.


00:11:45.760 --> 00:11:48.640
you have to think about things like legacy systems,


00:11:48.640 --> 00:11:51.280
because eventually every Greenfield project


00:11:51.280 --> 00:11:53.720
becomes a legacy system if it lasts for long enough.


00:11:53.720 --> 00:11:55.080
- Yeah, if you're lucky, right?


00:11:55.080 --> 00:11:57.600
Because the alternative is it never really got used


00:11:57.600 --> 00:11:59.120
or it didn't add that much value


00:11:59.120 --> 00:12:01.360
and got discarded, shut down, all right.


00:12:01.360 --> 00:12:03.520
So even though people talk about


00:12:03.520 --> 00:12:05.120
how much they don't want legacy code


00:12:05.120 --> 00:12:08.600
or how they kind of don't necessarily wanna work on it


00:12:08.600 --> 00:12:11.100
'cause they wanna work on something new and shiny,


00:12:12.120 --> 00:12:16.200
That's kind of the success side of software development, right?


00:12:16.200 --> 00:12:17.800
Yep, exactly.


00:12:17.800 --> 00:12:28.520
I do think it's super interesting, the different life cycle of code on the data science side,


00:12:28.520 --> 00:12:35.960
because you might be just looking to explore a concept or understand an idea better and not


00:12:35.960 --> 00:12:41.960
necessarily ever intend to put it into production in the traditional software sense, right?


00:12:41.960 --> 00:12:46.960
So I've seen some pretty interesting code written


00:12:46.960 --> 00:12:50.500
that people would look at and go,


00:12:50.500 --> 00:12:52.340
oh my goodness, what is,


00:12:52.340 --> 00:12:55.040
there's not even a function here.


00:12:55.040 --> 00:12:56.080
How is this possible?


00:12:56.080 --> 00:12:58.800
You know, it's like copy and paste reuse almost.


00:12:58.800 --> 00:13:03.080
And yet it really does go from having no idea


00:13:03.080 --> 00:13:05.380
to pictures and understanding,


00:13:05.380 --> 00:13:07.600
and then maybe handing that off potentially


00:13:07.600 --> 00:13:10.860
to be written more robustly and better.


00:13:10.860 --> 00:13:11.700
Mm-hmm.


00:13:11.700 --> 00:13:12.780
Mm-hmm.


00:13:12.780 --> 00:13:13.820
Yeah, exactly.


00:13:13.820 --> 00:13:16.820
And it's really interesting.


00:13:16.820 --> 00:13:21.500
Like, they're kind of two very different processes.


00:13:21.500 --> 00:13:24.740
And that point actually where engineering


00:13:24.740 --> 00:13:28.300
and research meets is a very, very interesting one.


00:13:28.300 --> 00:13:30.420
And I've seen it work in multiple different ways


00:13:30.420 --> 00:13:32.220
in multiple different workplaces.


00:13:32.220 --> 00:13:36.060
So for example, I've worked in places


00:13:36.060 --> 00:13:38.800
where the data scientists were completely sequestered


00:13:38.800 --> 00:13:40.420
away from the engineers.


00:13:40.420 --> 00:13:43.540
And they really wouldn't be that much discussion between the engineers and the data


00:13:43.540 --> 00:13:48.040
scientists during the research phase, which I do not advise.


00:13:48.040 --> 00:13:52.600
So what that means is the data scientists will come at the end and hand over this


00:13:52.600 --> 00:13:57.040
chunk of perhaps very difficult to read


00:13:57.040 --> 00:14:00.700
code to an engineer and be like, hey, so we need to implement this.


00:14:00.700 --> 00:14:02.320
And the engineer is like, what is this?


00:14:02.320 --> 00:14:06.260
OK, I will schedule that for the next six months.


00:14:07.620 --> 00:14:13.900
And then I've seen, you know, or I've been a data scientist embedded within a software development team.


00:14:13.900 --> 00:14:19.220
And in that case, your project is marching in lockstep with what the engineers are doing.


00:14:19.220 --> 00:14:27.620
And from the very start, you know, you've been discussing important things like, you know, maybe you need to build a model that has latency constraints.


00:14:27.620 --> 00:14:33.740
You need to think about this as the data scientist in terms of like the model that you run, but also how it's implemented.


00:14:34.100 --> 00:14:35.780
So yeah.


00:14:35.780 --> 00:14:37.100
Right.


00:14:37.100 --> 00:14:38.460
Like how much memory does it use?


00:14:38.460 --> 00:14:41.900
Cause if you run it on your own machine by yourself, then, well, it's kind of the


00:14:41.900 --> 00:14:46.260
limit of your computer sort of sometimes, but if you're running a thousand of them


00:14:46.260 --> 00:14:49.820
concurrently, cause people are interacting at the website all of a sudden that might


00:14:49.820 --> 00:14:50.780
make a difference.


00:14:50.780 --> 00:14:52.100
Exactly.


00:14:52.100 --> 00:14:56.300
Um, or like one of the most interesting problems I think I ever solved in my career


00:14:56.300 --> 00:14:59.340
was basically I was working at a job board.


00:14:59.340 --> 00:15:04.020
We were trying to improve the search using natural language processing.


00:15:04.020 --> 00:15:08.820
So we had this idea that we could build a model


00:15:08.820 --> 00:15:10.920
that found out the probabilistic relations


00:15:10.920 --> 00:15:13.120
between skills and job titles.


00:15:13.120 --> 00:15:15.540
So if someone typed a skill into the search,


00:15:15.540 --> 00:15:17.100
we could expand it with job titles


00:15:17.100 --> 00:15:19.620
and then find all of the jobs that we indexed with that


00:15:19.620 --> 00:15:23.560
at search time and vice versa with job titles and skills.


00:15:23.560 --> 00:15:26.020
But the thing is we need to find those relations


00:15:26.020 --> 00:15:26.940
at search time.


00:15:26.940 --> 00:15:29.580
Like that is a very low latency system.


00:15:29.580 --> 00:15:31.220
And it was super interesting


00:15:31.220 --> 00:15:33.800
because we had to think about how we could search


00:15:33.800 --> 00:15:38.080
that vector space in really, really quickly.


00:15:38.080 --> 00:15:40.400
Like instead of having to calculate the distance


00:15:40.400 --> 00:15:42.720
between that and every single vector,


00:15:42.720 --> 00:15:45.040
we had to work out how to do that more efficiently.


00:15:45.040 --> 00:15:48.080
And that sort of stuff I really like


00:15:48.080 --> 00:15:50.760
because it's so applied and it's so,


00:15:50.760 --> 00:15:54.400
like it's this really nice intersection


00:15:54.400 --> 00:15:56.680
between computer science and data science, I think.


00:15:56.680 --> 00:15:57.820
It's super cool.


00:15:57.820 --> 00:16:00.020
- That is neat.


00:16:00.020 --> 00:16:01.880
One of the things I really like about working


00:16:01.880 --> 00:16:06.540
with programming broadly is how concrete it is, right?


00:16:06.540 --> 00:16:07.760
You came from academics,


00:16:07.760 --> 00:16:11.040
you know, I was in grad school for a while as well.


00:16:11.040 --> 00:16:13.320
And it's, you could debate on and on


00:16:13.320 --> 00:16:15.880
about a certain idea or concept.


00:16:15.880 --> 00:16:17.460
And it's like, well, you might be right.


00:16:17.460 --> 00:16:21.280
Or I'm here, you push a button and you get the answer


00:16:21.280 --> 00:16:24.800
or it runs or like, there's a really nice feedback


00:16:24.800 --> 00:16:26.780
of like, I built this thing and it's,


00:16:26.780 --> 00:16:29.200
look, it's really connecting these people.


00:16:29.200 --> 00:16:30.960
And, you know, then it comes down to,


00:16:30.960 --> 00:16:33.880
Can you do it in real time and other things like that?


00:16:33.880 --> 00:16:37.080
But that's a really cool aspect of programming.


00:16:37.080 --> 00:16:41.360
- Yeah, and I think it's kind of a shame


00:16:41.360 --> 00:16:43.500
that a lot of places do set up their engineering


00:16:43.500 --> 00:16:46.020
and data science teams so separately.


00:16:46.020 --> 00:16:47.840
Sure, we have quite different roles


00:16:47.840 --> 00:16:52.380
and we have quite different backgrounds sometimes.


00:16:52.380 --> 00:16:55.760
But I really think that having the two teams


00:16:55.760 --> 00:16:57.560
at least planning things together,


00:16:57.560 --> 00:17:00.640
you can really actually learn a lot from each other


00:17:00.640 --> 00:17:02.280
about how to approach problems.


00:17:02.280 --> 00:17:03.120
Yeah.


00:17:03.120 --> 00:17:06.120
- Well, when you were describing,


00:17:06.120 --> 00:17:07.760
either having those groups really separated


00:17:07.760 --> 00:17:09.680
or working really closely together,


00:17:09.680 --> 00:17:12.240
maybe a analogous relationship


00:17:12.240 --> 00:17:14.940
that people could relate with


00:17:14.940 --> 00:17:17.200
is maybe front end developers


00:17:17.200 --> 00:17:20.960
and people building the APIs in the backend, right?


00:17:20.960 --> 00:17:25.400
Like the people doing React or Angular or Vue


00:17:25.400 --> 00:17:28.880
or whatever it is, you know, in the web design,


00:17:28.880 --> 00:17:33.880
Having those completely separated as well is also terrible.


00:17:33.880 --> 00:17:35.040
Not a good idea.


00:17:35.040 --> 00:17:36.240
- It doesn't make any sense.


00:17:36.240 --> 00:17:38.880
And I can totally understand it from the point of view


00:17:38.880 --> 00:17:42.800
of team composition, because it is, I think,


00:17:42.800 --> 00:17:45.280
better to have all your data scientists together


00:17:45.280 --> 00:17:47.560
because they can learn from each other.


00:17:47.560 --> 00:17:50.320
But then I think having, I don't want to use the squad term


00:17:50.320 --> 00:17:52.280
'cause I know it's become a little bit unpopular to use it,


00:17:52.280 --> 00:17:56.080
but this idea of project-oriented teams,


00:17:56.080 --> 00:17:57.480
I think are quite important.


00:17:58.640 --> 00:17:59.480
Yeah.


00:17:59.480 --> 00:18:01.600
So,


00:18:01.600 --> 00:18:04.920
I guess maybe let's dive a little bit more


00:18:04.920 --> 00:18:07.000
into the research side of things


00:18:07.000 --> 00:18:09.960
that I wanna ask you about, why Python?


00:18:09.960 --> 00:18:12.800
But, you know, let's talk about


00:18:12.800 --> 00:18:14.840
how the research process works


00:18:14.840 --> 00:18:18.240
and maybe why that results in different priorities


00:18:18.240 --> 00:18:22.000
and styles of code and styles of engineering.


00:18:22.000 --> 00:18:25.960
- Yeah, so I think it starts at a similar point to,


00:18:25.960 --> 00:18:27.800
you know, all software projects,


00:18:27.800 --> 00:18:32.480
which is business comes to you and they have some sort of goal.


00:18:32.480 --> 00:18:37.240
Sometimes it's very vague and you need to interpret that and turn it into an


00:18:37.240 --> 00:18:38.480
executable project.


00:18:38.480 --> 00:18:44.120
But where the sort of uncertainty starts and like where it sort of becomes a


00:18:44.120 --> 00:18:47.040
research project rather than a project.


00:18:47.040 --> 00:18:50.240
I don't know if I described that very well,


00:18:50.240 --> 00:18:54.800
but it becomes research versus something you're building concretely is


00:18:55.320 --> 00:19:04.320
you don't even know at the start of a research project, whether it's even possible to answer the question that you're being asked or build the internal product that you're being asked for.


00:19:04.320 --> 00:19:08.440
So you might not understand the domain entirely right.


00:19:08.440 --> 00:19:10.560
You're trying to gain understanding even.


00:19:10.560 --> 00:19:18.880
Yeah. And like in the very worst cases, you won't even know if you have the data because maybe your company has so much data and it's so poorly organized.


00:19:18.880 --> 00:19:24.040
Again, something I've seen that you don't even know if the data exists to answer this question.


00:19:24.440 --> 00:19:27.360
So first is going and getting your data.


00:19:27.360 --> 00:19:31.240
And you spend quite a lot of time with the data because the data will be the one that


00:19:31.240 --> 00:19:35.600
tells you the story. It'll tell you whether what you even want is possible.


00:19:35.600 --> 00:19:40.960
And you probably like heard data scientists hammering on about, you know, garbage in,


00:19:40.960 --> 00:19:45.280
garbage out. Like you can build the most beautiful, sophisticated model you want.


00:19:45.280 --> 00:19:48.160
But if you have crap data where there's no signal.


00:19:48.160 --> 00:19:52.360
You're not going to get anything because it's just not there.


00:19:52.360 --> 00:19:55.560
like the relationship you're looking for is not there.


00:19:55.560 --> 00:20:01.640
Yeah, the side of that I've heard is 80% of the work is actually the data


00:20:01.640 --> 00:20:04.840
cleanup, data wrangling, data gathering before you just


00:20:04.840 --> 00:20:08.760
magically hit it with a plot or something, right?


00:20:08.760 --> 00:20:12.360
Absolutely, and it's interesting because that


00:20:12.360 --> 00:20:16.200
data cleaning, data wrangling step also doesn't happen in one go,


00:20:16.200 --> 00:20:19.400
especially if you're building a model. So what will happen is you'll try


00:20:19.400 --> 00:20:22.040
something out and you'll be like, okay it didn't quite work,


00:20:22.040 --> 00:20:26.440
maybe I need to manipulate the data in a different way, or I need to create this new variable.


00:20:26.440 --> 00:20:30.840
And then you'll go again. And it's this super iterative process where you have this


00:20:30.840 --> 00:20:38.120
tightly coupled relationship between both the models and the data. So it really is sort of,


00:20:38.120 --> 00:20:41.800
you know, how I was talking about the instinct. This is sort of where that comes in, because


00:20:41.800 --> 00:20:46.360
you're going to spend like 80% of your time honing your skills. But it's the most, I think,


00:20:46.360 --> 00:20:52.760
valuable part of the process. And if the signal's there, you can usually get away with using


00:20:52.760 --> 00:20:59.720
really dumb and simple models. Things that are unfashionable now, like decision trees or linear


00:20:59.720 --> 00:21:05.160
regression, you can get away with them because you've just got such good data that just go with


00:21:05.160 --> 00:21:12.280
a simpler model. It's got all the advantages. So yeah, this is sort of, I think what makes


00:21:12.280 --> 00:21:18.760
it different that you're sort of moving towards a goal, but you don't know what that goal is.


00:21:18.760 --> 00:21:26.840
Estimation is always hard, right? What I found is best is really just timeboxing each step,


00:21:26.840 --> 00:21:31.960
seeing if you are up to where you thought you'd be up to by a certain point. And if not,


00:21:31.960 --> 00:21:35.800
you need to just keep having those discussions with the business stakeholders because


00:21:35.800 --> 00:21:41.800
otherwise they're going to not be very happy if you've spent six months just looking at something


00:21:41.800 --> 00:21:43.480
and you have nothing.


00:21:43.480 --> 00:21:44.320
- What have you built?


00:21:44.320 --> 00:21:47.720
Well, I have some notebooks I can show you.


00:21:47.720 --> 00:21:51.380
- I have 40,000 notebooks and they're all terrible.


00:21:51.380 --> 00:21:53.960
- Yeah.


00:21:53.960 --> 00:21:56.160
Speaking of data, Diego on the audience


00:21:56.160 --> 00:21:57.600
has an interesting question.


00:21:57.600 --> 00:21:59.360
How big are the data sets businesses


00:21:59.360 --> 00:22:00.800
will bring to you typically?


00:22:00.800 --> 00:22:04.400
Enough that you don't need to go out and find more data.


00:22:04.400 --> 00:22:05.960
- Yeah, this is a good question.


00:22:05.960 --> 00:22:09.440
So I hate to be, it depends, you know.


00:22:10.320 --> 00:22:15.280
I get to say that though, because, you know, I was a lead data scientist, so I earned that


00:22:15.280 --> 00:22:16.280
rank.


00:22:16.280 --> 00:22:19.960
It really does depend on the problem you need to solve.


00:22:19.960 --> 00:22:27.480
So typically, business will have enough data to cover at least some of the use cases.


00:22:27.480 --> 00:22:31.800
So to give you a really concrete example, this job board that I was talking about that


00:22:31.800 --> 00:22:36.960
I worked at, we actually had like a bunch of different job boards across Europe.


00:22:36.960 --> 00:22:41.880
So we had some that were a lot bigger like Germany or the UK, and we had some that were


00:22:41.880 --> 00:22:45.360
really small like Poland or Spain.


00:22:45.360 --> 00:22:51.080
And we wanted to build these multi-language models or models maybe for different languages.


00:22:51.080 --> 00:22:53.000
We played around with both.


00:22:53.000 --> 00:22:58.840
And I don't think we really had enough data to support the models in these smaller languages.


00:22:58.840 --> 00:23:02.560
So the models were just not as good quality because we didn't have enough data.


00:23:02.560 --> 00:23:04.400
But for the bigger languages we did.


00:23:04.400 --> 00:23:08.320
And then it sort of becomes a case of, okay, well, we have more data for these particular


00:23:08.320 --> 00:23:12.200
websites because they're the most, like, they're the ones that are bringing the most revenue.


00:23:12.200 --> 00:23:15.700
So then it sort of became like, well, okay, maybe it's good enough that we improve the


00:23:15.700 --> 00:23:17.800
search on the most important ones.


00:23:17.800 --> 00:23:21.440
And for the smaller ones, we just wait until we accumulate more data.


00:23:21.440 --> 00:23:26.800
So yeah, most of the time I found that there's a way to make it work for at least part of


00:23:26.800 --> 00:23:29.000
the solution.


00:23:29.000 --> 00:23:33.440
And then sometimes, like in the case of my last job, we had something like 170 billion


00:23:33.440 --> 00:23:42.240
auctions per day. So we had so much data, we even had problems processing it.


00:23:42.240 --> 00:23:48.720
That's the other side of the story is when you've got too much and then how do you throw it away?


00:23:48.720 --> 00:23:55.280
You've got this auction story. Another one that comes to mind is the Large Hadron Collider.


00:23:55.280 --> 00:24:01.200
They've got layers and layers of chips on hardware and then


00:24:01.200 --> 00:24:06.560
Chips or machines right next to the collectors and then on it where it's all about. How do we throw away?


00:24:06.560 --> 00:24:09.940
You know terabytes of data down to get it to megabytes


00:24:09.940 --> 00:24:12.240
per second, right?


00:24:12.240 --> 00:24:16.720
yeah, and it's interesting because what you can end up in this within those situations is


00:24:16.720 --> 00:24:24.240
Even then you can have underrepresented groups. So for example, we had we're working with advertisers and


00:24:24.240 --> 00:24:28.080
apps, you know, basically trading ads and


00:24:28.560 --> 00:24:33.120
We ended up with some apps that were just so small that you were like even with all this data


00:24:33.120 --> 00:24:38.480
I really don't have enough to represent this particular combination in this country. So


00:24:38.480 --> 00:24:41.840
Yeah, yeah


00:24:41.840 --> 00:24:44.720
Interesting very interesting so


00:24:44.720 --> 00:24:48.160
Why python


00:24:48.160 --> 00:24:54.480
You know, you started out in r and of course any distraction from writing a phd is it's a good distraction


00:24:54.480 --> 00:24:56.880
but I I do think


00:24:57.120 --> 00:25:00.720
there's been a really interesting sort of graph.


00:25:00.720 --> 00:25:02.960
Like if people go and look at,


00:25:02.960 --> 00:25:05.660
what is it, Stack Overflow Insights.


00:25:05.660 --> 00:25:09.520
If you go look at Stack Overflow Insights,


00:25:09.520 --> 00:25:14.280
they had a really great, is this the right one?


00:25:14.280 --> 00:25:15.440
No, it's the survey.


00:25:15.440 --> 00:25:19.580
They have a really great, not their survey,


00:25:19.580 --> 00:25:24.280
graph that shows you, I don't know where to find it live,


00:25:24.280 --> 00:25:26.680
but a really graph that shows you the popularity


00:25:26.680 --> 00:25:28.840
of Python over time.


00:25:28.840 --> 00:25:31.880
And there's just this huge inflection point around 2012.


00:25:31.880 --> 00:25:34.720
And I feel like that's when a lot of the data science


00:25:34.720 --> 00:25:38.860
libraries really came around and took off.


00:25:38.860 --> 00:25:44.120
So it seems like there was a big inflection at one point,


00:25:44.120 --> 00:25:45.640
but why?


00:25:45.640 --> 00:25:50.460
- Yeah, so to be honest,


00:25:50.460 --> 00:25:54.520
I can talk about why I like Python from my background.


00:25:54.520 --> 00:25:59.320
I couldn't really tell you exactly what caused that takeoff, but, you know,


00:25:59.320 --> 00:26:02.520
apart from, you know, this idea that the libraries were maturing enough.


00:26:02.520 --> 00:26:07.720
The thing is looking even at current surveys,


00:26:07.720 --> 00:26:12.320
around 60% of data scientists do not have a software development or a software


00:26:12.320 --> 00:26:15.600
engineering background. So for people like us,


00:26:15.600 --> 00:26:18.520
we don't really understand, like it sounds terrible.


00:26:18.520 --> 00:26:24.200
We don't really understand basic constructs in how a programming language works.


00:26:24.200 --> 00:26:29.320
And that can actually mean that going to some sort of compiled language even can be quite


00:26:29.320 --> 00:26:30.600
a steep learning curve.


00:26:30.600 --> 00:26:31.600
Sure.


00:26:31.600 --> 00:26:33.240
Pointers to pointers, for example.


00:26:33.240 --> 00:26:36.280
Like, no, yeah, yeah, yeah.


00:26:36.280 --> 00:26:42.440
Or, I don't know, having to deal with the fact that in Java, everything is a class.


00:26:42.440 --> 00:26:44.520
You're just like, what is this?


00:26:44.520 --> 00:26:48.480
It's like, but of course you understand why if you have that background.


00:26:48.480 --> 00:26:52.600
But if you're trying to learn it yourself, you then have a lot of background you need


00:26:52.600 --> 00:26:53.600
to cover.


00:26:53.600 --> 00:26:57.040
But in Python and in R as well, you don't need to cover those things.


00:26:57.040 --> 00:26:59.220
It's super easy to prototype.


00:26:59.220 --> 00:27:02.160
It's super easy to script.


00:27:02.160 --> 00:27:06.640
The flexibility of Python is what makes it, I think, the perfect prototyping language.


00:27:06.640 --> 00:27:08.120
And that's essentially what you're doing.


00:27:08.120 --> 00:27:09.880
You're prototyping.


00:27:09.880 --> 00:27:17.400
So we talked a little bit earlier about like, why not just Excel?


00:27:17.400 --> 00:27:22.240
We didn't quite say that, but this was sort of what we were maybe getting at.


00:27:22.240 --> 00:27:25.600
And yeah, we could do some of our work in Excel.


00:27:25.600 --> 00:27:28.360
I have tried this.


00:27:28.360 --> 00:27:33.220
And first I can tell you Excel really starts to struggle when you have too many calculations


00:27:33.220 --> 00:27:35.160
going on under the hood.


00:27:35.160 --> 00:27:37.040
Gets very, very slow.


00:27:37.040 --> 00:27:42.740
But to be honest, it's just cleaner to code this sort of logic.


00:27:42.740 --> 00:27:47.220
It's much more reproducible when you need to do this iterative sort of stuff.


00:27:47.220 --> 00:27:51.420
And it also means that you can use much more powerful tools.


00:27:51.420 --> 00:27:58.180
So you can say use APIs that developers have made to process your data.


00:27:58.180 --> 00:27:59.180
You can use powerful-


00:27:59.180 --> 00:28:00.180
Or get data, right?


00:28:00.180 --> 00:28:04.400
Like I need live currency conversion data, right?


00:28:04.400 --> 00:28:05.400
So much easier than Excel.


00:28:05.400 --> 00:28:12.380
Yes, yes, yes, exactly. Like you can like scrape data or you can, yeah, pull data in


00:28:12.380 --> 00:28:20.720
off an API, or you can use powerful tools like Spark to process 170 billion auctions


00:28:20.720 --> 00:28:26.900
per day in order to reduce it down to something manageable. So yeah, it just gives you a lot


00:28:26.900 --> 00:28:33.900
more power. But at the same time, why we use programming languages is like, it's just such


00:28:33.900 --> 00:28:39.660
a different focus. So we, it's a bit overkill to use something like Java. I know some people do


00:28:39.660 --> 00:28:44.540
do natural language processing in Java, but that's more on the engineering side to build


00:28:44.540 --> 00:28:52.220
maintainable systems. - One of the things I like to say when thinking about how people who are


00:28:52.220 --> 00:28:59.020
coming from a tangential interest like biology or whatever, is you can be really effective with


00:28:59.020 --> 00:29:04.620
Python and I suspect R as well with a really partial understanding of what Python is and what


00:29:04.620 --> 00:29:09.660
it does. Right? Like you pointed out, you don't even have to know what a class is or even really


00:29:09.660 --> 00:29:16.460
how to create a function. You just, I can put these six magical incantations in a file and then


00:29:16.460 --> 00:29:21.900
I can do way more than I otherwise could, right? Then you learn more, you make it better and better


00:29:21.900 --> 00:29:26.700
as you kind of gain experience. >> Pretty much. And this is where I started. Like, obviously,


00:29:26.700 --> 00:29:32.380
I learned what functions and classes were when I first started programming. But in the end,


00:29:32.380 --> 00:29:41.980
maybe it's not the best thing and we can sort of maybe get into this. I suppose part of the


00:29:41.980 --> 00:29:46.860
confusion or not confusion, but internal debate I've had over the years is how good does data


00:29:46.860 --> 00:29:53.580
science code really need to be? How much would data scientists benefit from knowing more about


00:29:54.540 --> 00:29:58.620
computer science topics or software engineering topics, maybe more to the point.


00:29:58.620 --> 00:30:03.580
And, you know, because like the thing is, every field has so much to learn.


00:30:03.580 --> 00:30:07.740
Don't even get started on what's happening with large language models at the moment. Like,


00:30:07.740 --> 00:30:11.900
it's just overwhelming. Should we take some of our precious time and learn


00:30:11.900 --> 00:30:15.820
software engineering concepts? I'm not sure. Like, I'm not sure if I have the answer to that.


00:30:15.820 --> 00:30:24.140
I think it really depends on what kind of data scientists you are. If what you are is


00:30:24.140 --> 00:30:26.980
is someone doing research, as you described before,


00:30:26.980 --> 00:30:30.020
and you're like, do we, is there a trend


00:30:30.020 --> 00:30:34.660
between the type of device that they use


00:30:34.660 --> 00:30:37.100
to buy their thing at our store


00:30:37.100 --> 00:30:40.020
and how much they're buying on the second,


00:30:40.020 --> 00:30:41.640
you know, how much are likely they'll come back?


00:30:41.640 --> 00:30:43.200
Like if they're using an iPhone,


00:30:43.200 --> 00:30:45.260
do they tend to spend more


00:30:45.260 --> 00:30:46.500
than if they're using an Android?


00:30:46.500 --> 00:30:49.620
And is that a thing that we should consider?


00:30:49.620 --> 00:30:52.780
Or, you know, is there any, like that kind of exploration,


00:30:53.860 --> 00:30:56.300
you can judge whether or not you should make that exploration.


00:30:56.300 --> 00:30:58.300
But just put that aside for a minute.


00:30:58.300 --> 00:31:01.300
That kind of stuff, like once you know that answer,


00:31:01.300 --> 00:31:02.860
maybe you don't need to run that code again.


00:31:02.860 --> 00:31:03.500
Maybe you don't care.


00:31:03.500 --> 00:31:06.820
You just want to kind of discover if there is a trend.


00:31:06.820 --> 00:31:10.620
And there, maybe you need to know software engineering techniques,


00:31:10.620 --> 00:31:12.500
but should you be writing unit tests for that?


00:31:12.500 --> 00:31:15.140
I'd say maybe not, honestly.


00:31:15.140 --> 00:31:18.740
On the other hand, if your job is to create a model that's


00:31:18.740 --> 00:31:21.580
going to go into production, that's going to run behind a Flask


00:31:21.580 --> 00:31:26.280
or FastAPI endpoints, then you're kind of in the realm of


00:31:26.280 --> 00:31:29.640
continuously running for many people over a long time.


00:31:29.640 --> 00:31:32.800
And I think that really is a different situation.


00:31:32.800 --> 00:31:34.660
Yeah.


00:31:34.660 --> 00:31:38.360
Like, I think this is where you actually move from data science to machine


00:31:38.360 --> 00:31:39.080
learning engineering.


00:31:39.080 --> 00:31:42.960
Um, this term has a lot of different definitions.


00:31:42.960 --> 00:31:47.140
Um, for me, I base my definition of ML engineers on the two people that I've


00:31:47.140 --> 00:31:50.900
worked with who were like true full stack kind of


00:31:50.900 --> 00:31:56.180
people who could go from, you know, research and prototyping


00:31:56.180 --> 00:31:57.380
through to deployment.


00:31:57.380 --> 00:32:02.100
And they were data scientists who really cared


00:32:02.100 --> 00:32:06.420
enough to actually learn how to do proper engineering and they could


00:32:06.420 --> 00:32:07.780
actually deploy their own things.


00:32:07.780 --> 00:32:12.660
But then this leads to another one of my very favourite topics, which is who is


00:32:12.660 --> 00:32:15.020
responsible for apps in production?


00:32:15.620 --> 00:32:18.560
And here's the thing.


00:32:18.560 --> 00:32:23.900
So I think as good as your data scientist is going to be or your ML engineer, let's say an ML


00:32:23.900 --> 00:32:26.860
engineer, let's say that they can actually deploy their own code.


00:32:26.860 --> 00:32:30.900
If they're then responsible for that code in production.


00:32:30.900 --> 00:32:37.340
That then eats up the time that they can be prototyping and researching new things for


00:32:37.340 --> 00:32:42.740
you. So the conclusion I've come to over time, and again, this is a matter


00:32:42.740 --> 00:32:50.660
a debate. This is just my opinion. Basically, I think if your company is above any sort of level


00:32:50.660 --> 00:32:56.180
of size or complexity in terms of the data products it has, I think you really do need


00:32:56.180 --> 00:33:02.340
dedicated data science and engineering teams. Because in the end, no matter how good your data


00:33:02.340 --> 00:33:06.820
scientist code is going to be, it needs to be implemented by the person who's going to maintain


00:33:06.820 --> 00:33:11.780
it. And maybe they're not the ones writing the code from scratch. Maybe they can adapt the data


00:33:11.780 --> 00:33:13.200
a scientist code if it's good enough.


00:33:13.200 --> 00:33:17.940
But in the end, they need to be comfortable and familiar enough with that code to be


00:33:17.940 --> 00:33:22.680
like, yeah, if I get pinged at three in the morning, I'm OK knowing what to do with


00:33:22.680 --> 00:33:23.680
this code.


00:33:23.680 --> 00:33:30.380
Yeah. So I think it's just easier to scale these teams in parallel rather than trying to


00:33:30.380 --> 00:33:33.540
hire this like all in one person who can do everything.


00:33:33.540 --> 00:33:34.700
They're impossible to hire.


00:33:34.700 --> 00:33:39.820
Like I've only ever met two over the course of my career and quickly they become


00:33:39.820 --> 00:33:42.780
overwhelmed by having to maintain projects.


00:33:42.780 --> 00:33:46.380
Right, is that the best use of their time? Yeah, and like it's


00:33:46.380 --> 00:33:49.980
maybe it's not necessarily even if it's the best use of their time.


00:33:49.980 --> 00:33:54.140
It's more like then who's going to do your research?


00:33:54.140 --> 00:33:57.660
Because now you've used up that resource on maintaining


00:33:57.660 --> 00:34:02.620
two or three projects. Right, absolutely. Chris May's got an interesting question


00:34:02.620 --> 00:34:05.980
out here in the audience. This kind of turns us on its head a little bit. It


00:34:05.980 --> 00:34:08.780
says development teams tend to work better when they focus on writing and


00:34:08.780 --> 00:34:13.340
or factoring code to make it testable and understandable.


00:34:13.340 --> 00:34:16.140
And we've talked a little bit about maybe stuff


00:34:16.140 --> 00:34:18.700
that data scientists shouldn't care about or whatever.


00:34:18.700 --> 00:34:23.420
So are there ideas that are like good practices


00:34:23.420 --> 00:34:26.320
for data scientists and teams of them?


00:34:26.320 --> 00:34:29.740
- Yeah, this is actually a really great question.


00:34:29.740 --> 00:34:34.860
So basically it's an interesting thing with data scientists


00:34:34.860 --> 00:34:37.180
that unlike software developers,


00:34:37.180 --> 00:34:40.160
we often tend to work alone on projects


00:34:40.160 --> 00:34:42.100
or maybe in very, very small teams,


00:34:42.100 --> 00:34:45.200
like maybe two or three people.


00:34:45.200 --> 00:34:47.440
And I think it's probably a hangover


00:34:47.440 --> 00:34:49.800
from the fact a lot of us are ex-academics.


00:34:49.800 --> 00:34:52.520
We're just used to having, like, it's not great.


00:34:52.520 --> 00:34:53.360
(laughing)


00:34:53.360 --> 00:34:54.200
But it's sort of-


00:34:54.200 --> 00:34:56.560
- A whiteboard, an office in the corner,


00:34:56.560 --> 00:34:58.280
and no one knows what you're doing.


00:34:58.280 --> 00:35:00.120
- Exactly, and no one cares.


00:35:00.120 --> 00:35:04.080
That paper that three people read took me three years.


00:35:05.880 --> 00:35:10.880
So what I think has been neglected, you know, aside from


00:35:10.880 --> 00:35:15.540
learning, you know, software engineering best practices is more fundamental things,


00:35:15.540 --> 00:35:17.860
which is like writing maintainable code.


00:35:17.860 --> 00:35:22.860
And I don't mean maintainable in the sense of it's a system that needs to be able


00:35:22.860 --> 00:35:24.260
to run regularly.


00:35:24.260 --> 00:35:29.500
It's more like this is a piece of code that I can come back to in six months and


00:35:29.500 --> 00:35:34.240
understand what I was doing because, you know, research projects can be shelved


00:35:34.240 --> 00:35:38.400
forever, but maybe they need to be revisited and built upon.


00:35:38.400 --> 00:35:44.480
So this was actually a topic I got really interested when I first moved to


00:35:44.480 --> 00:35:49.080
industry, like this idea of reproducibility with data science projects.


00:35:49.080 --> 00:35:53.400
It's about the code, but it's also about things like dependency management, which


00:35:53.400 --> 00:35:57.880
is notoriously difficult in Python to get


00:35:57.880 --> 00:36:00.040
reproducible environments later.


00:36:00.040 --> 00:36:02.400
And even the operating system, right?


00:36:02.680 --> 00:36:05.800
If Linux has really dramatically changed over time,


00:36:05.800 --> 00:36:10.000
then maybe your old dependency, you want to keep that one,


00:36:10.000 --> 00:36:12.240
but it won't run on the new operating system


00:36:12.240 --> 00:36:15.160
or there's a whole spectrum of challenges there.


00:36:15.160 --> 00:36:16.480
- Exactly, exactly.


00:36:16.480 --> 00:36:19.000
And it's sort of something that can be solved


00:36:19.000 --> 00:36:23.240
with maybe using poetry, which is a little bit more robust,


00:36:23.240 --> 00:36:26.000
but even then, you've still got it,


00:36:26.000 --> 00:36:27.800
like the it runs on my machine effect


00:36:27.800 --> 00:36:30.200
where your machine will not be the same machine.


00:36:31.360 --> 00:36:39.200
Increasingly, there's actually a move towards doing more sort of cloud-based stuff for data science, which solves a few of these problems.


00:36:39.200 --> 00:36:49.280
And it also solves the additional problem where data scientists often need to do remote development for various reasons, like you need access to GPUs in order to train models.


00:36:49.280 --> 00:36:58.720
So, you know, obviously, if you have a server, you have a Docker container which has environment specifications, you can power up that exact same environment.


00:36:58.720 --> 00:37:01.080
And that actually helps with that reproducibility a lot.


00:37:01.080 --> 00:37:11.880
And then another point which I think is really important for data scientists and can be neglected is literate programming.


00:37:11.880 --> 00:37:20.960
So this is an idea from Donald Knuth, and it's this idea that you should write your code in such a way that it's actually understandable later.


00:37:20.960 --> 00:37:28.240
With data science work, it's also that you really need to document a lot of the implicit


00:37:28.240 --> 00:37:33.400
kind of assumptions that you make or decisions that you make as part of the research process.


00:37:33.400 --> 00:37:39.540
And this is one of the reasons, probably a good segue, why Jupyter is so important.


00:37:39.540 --> 00:37:42.260
Jupyter notebooks are designed to be research documents.


00:37:42.260 --> 00:37:46.640
So this is why you have the markdown cells if you've seen a Jupyter notebook, because


00:37:46.640 --> 00:37:53.120
It's this idea that you really, really need to document, along with the code, the decisions that you made.


00:37:53.120 --> 00:37:54.920
Like, why did you choose this sample?


00:37:54.920 --> 00:38:01.240
Why did you decide to create the inputs to your models the way that you did it?


00:38:01.240 --> 00:38:02.640
You need to document all this stuff.


00:38:02.640 --> 00:38:06.800
So, yeah, reproducibility is a super interesting topic.


00:38:06.800 --> 00:38:15.080
And I think it's something that really needs to be thought about carefully, even if you're not collaborating with anyone else.


00:38:15.160 --> 00:38:19.800
because otherwise your piece of research is going to be worthless in three months because you're not going to remember what you did.


00:38:19.800 --> 00:38:25.160
I think notebooks are quite interesting. They go a long ways to solving that when


00:38:25.160 --> 00:38:31.000
when used in the right way, you can just jam a bunch of non-understandable stuff in there and it's just


00:38:31.000 --> 00:38:35.720
well now it's not understandable, but it's in a web page instead of in an editor, but yeah


00:38:35.720 --> 00:38:38.520
I think as in


00:38:38.520 --> 00:38:43.240
You know not just programmers but tech in general we're just bad at


00:38:44.200 --> 00:38:52.680
thinking about the long-term life cycle of information and compute. For example, I got a


00:38:52.680 --> 00:38:59.000
new heat pump to replace the furnace at my house. The manual for it came on a CD drive, and I'm like,


00:38:59.000 --> 00:39:03.080
"What? I don't think I have a CD. Where did I put that? I would go dig through


00:39:03.080 --> 00:39:11.160
a closet full of electronics. I'm not sure I can read that." And CDs seem so ubiquitous for so long,


00:39:11.160 --> 00:39:16.760
And just simple little mismatches like that just get worse over time.


00:39:16.760 --> 00:39:24.200
And it's going to be tough to keep some of this older research and reproducibility around.


00:39:24.200 --> 00:39:32.440
Yeah, it's super interesting that there are packages I used to use, you know, back when I


00:39:32.440 --> 00:39:37.080
first started in natural language processing. Some of them haven't been updated from Python 2.


00:39:37.720 --> 00:39:43.480
So I can't use them anymore. Because they were just some, probably like a PhD project and no


00:39:43.480 --> 00:39:47.640
one really had the time or energy to maintain it after that person graduated.


00:39:47.640 --> 00:39:52.040
Right. And the person graduated, got a job and doesn't really care that much anymore,


00:39:52.040 --> 00:39:57.240
potentially. Not enough to keep it going. Yeah. It's not even necessarily their fault. It's just


00:39:57.240 --> 00:40:06.200
life. Let's talk about some of the libraries and tools. You mentioned Jupyter. I think Jupyter is


00:40:07.320 --> 00:40:14.920
one of the absolute cornerstones. But Jupyter or Jupyter Lab? What are your thoughts?


00:40:14.920 --> 00:40:22.840
Yeah, so it's funny actually for years I was just working in Jupyter, playing Jupyter on my computer.


00:40:22.840 --> 00:40:25.960
Maybe give people a quick summary of the difference just so.


00:40:25.960 --> 00:40:32.920
Yes, yes, very good idea. So basically Jupyter is, I suppose you could call it an editor,


00:40:33.560 --> 00:40:41.400
It's basically an interactive document which you run against a Python kernel, or you can run it


00:40:41.400 --> 00:40:46.040
against different language kernels. There are R, there are Julia, there are Kotlin notebooks.


00:40:46.040 --> 00:40:52.040
Should I give my little advertisement for JetBrains? So basically what you can do is you can


00:40:52.040 --> 00:40:57.240
run code in cell blocks, then you can also create markdown cells in between them,


00:40:57.240 --> 00:41:03.240
and this allows you to basically have markdown chunks and then cell chunks. JupyterLab


00:41:03.240 --> 00:41:08.840
is hosted remotely. So you have basically a bunch of other functionality built in so you can open


00:41:08.840 --> 00:41:14.360
terminals, you can create scripts, things like that. But basically it's like a little Jupyter


00:41:14.360 --> 00:41:20.200
ecosystem which is designed to be remotely hosted and it can be accessed simultaneously


00:41:20.200 --> 00:41:28.920
by several people. So I would say Jupyter is good if you are just starting out and you're


00:41:28.920 --> 00:41:31.080
you're dealing with small data sets,


00:41:31.080 --> 00:41:33.480
maybe you're even retrieving things from databases,


00:41:33.480 --> 00:41:36.160
but you're not saving anything, you know,


00:41:36.160 --> 00:41:38.880
too heavy locally, you're not, you know,


00:41:38.880 --> 00:41:40.320
using a huge amount of memory,


00:41:40.320 --> 00:41:42.720
like maybe unless you got one of those new M2 Macs


00:41:42.720 --> 00:41:46.360
and, you know, server in your office, so go for it.


00:41:46.360 --> 00:41:47.200
- Exactly.


00:41:47.200 --> 00:41:48.040
- Yeah.


00:41:48.040 --> 00:41:51.440
JupyterLab, I think is good.


00:41:51.440 --> 00:41:54.720
It basically, you need to access different types of machines.


00:41:54.720 --> 00:41:58.660
So maybe you need to be able to access GPU machines easily.


00:41:58.660 --> 00:42:00.640
You kind of want that remote first experience


00:42:00.640 --> 00:42:03.760
where you don't have to then connect to a remote machine.


00:42:03.760 --> 00:42:07.820
And I have found JupyterLab helpful in the past for sharing,


00:42:07.820 --> 00:42:09.520
but the thing you can't do with JupyterLab


00:42:09.520 --> 00:42:11.160
is real-time collaboration.


00:42:11.160 --> 00:42:13.120
And that's a bit of a pain in the butt.


00:42:13.120 --> 00:42:15.960
Obviously, since I started at JetBrains,


00:42:15.960 --> 00:42:19.140
I kind of, you know, like I'm using our tools


00:42:19.140 --> 00:42:20.360
and I like them a lot.


00:42:20.360 --> 00:42:24.820
- Yeah, I was gonna ask, is this PyCharm, Dataspell?


00:42:24.820 --> 00:42:26.840
When you actually do that,


00:42:26.840 --> 00:42:29.280
Are you using some of those type of tools?


00:42:29.280 --> 00:42:30.200
- Yeah, I am.


00:42:30.200 --> 00:42:33.240
So I won't turn this into too much of an advertisement


00:42:33.240 --> 00:42:34.080
for our tools,


00:42:34.080 --> 00:42:37.040
because it's not really the point of me being here.


00:42:37.040 --> 00:42:39.080
But we've kind of tried,


00:42:39.080 --> 00:42:42.200
or my teams have tried to solve some of these problems


00:42:42.200 --> 00:42:45.560
that you might have with just using plain Jupyter notebooks


00:42:45.560 --> 00:42:47.440
or even working with JupyterLab,


00:42:47.440 --> 00:42:52.660
maybe a bit more like robustly.


00:42:53.640 --> 00:42:58.040
So we have actually three data science projects, products.


00:42:58.040 --> 00:43:00.760
We have PyCharm and Dataspell, which you've mentioned.


00:43:00.760 --> 00:43:03.360
They're desktop IDEs with the ability


00:43:03.360 --> 00:43:05.500
to connect to remote machines,


00:43:05.500 --> 00:43:07.160
but they're not really collaborative,


00:43:07.160 --> 00:43:09.000
but they do give you like, you know,


00:43:09.000 --> 00:43:12.040
really like nice experience with using Jupyter,


00:43:12.040 --> 00:43:15.120
debugging and co-completion and all those sort of things.


00:43:15.120 --> 00:43:18.240
We have another one, which is DataLore.


00:43:18.240 --> 00:43:20.520
And this falls into those managed notebooks


00:43:20.520 --> 00:43:21.360
that I was talking about.


00:43:21.360 --> 00:43:23.760
that's cloud hosted.


00:43:23.760 --> 00:43:27.560
And the nice thing about data law actually is you can do real time collaboration.


00:43:27.560 --> 00:43:29.320
So it sort of helps overcome...


00:43:29.320 --> 00:43:30.320
Google Cloud style, sort of.


00:43:30.320 --> 00:43:32.480
Yes, it's the same technology, actually.


00:43:32.480 --> 00:43:39.400
So, yeah, so it's kind of a very interesting thing, because there will be times where,


00:43:39.400 --> 00:43:43.080
you know, maybe you're not working on a project with a data scientist, but you need them to


00:43:43.080 --> 00:43:45.160
have a look at your work.


00:43:45.160 --> 00:43:50.000
And when I was working with JupyterLab, what we would do is we would clone the notebook


00:43:50.000 --> 00:43:53.160
to our own folder and then we were in the same environment.


00:43:53.160 --> 00:43:54.000
So it was okay.


00:43:54.000 --> 00:43:56.960
But then you would rerun the whole thing again.


00:43:56.960 --> 00:43:59.400
And sometimes it would be pretty time consuming.


00:43:59.400 --> 00:44:02.280
Data lore is an alternative to that,


00:44:02.280 --> 00:44:06.160
may or may not be kind of your style,


00:44:06.160 --> 00:44:08.280
but it's pretty cool because you can actually


00:44:08.280 --> 00:44:11.720
just invite someone to the same notebook instance


00:44:11.720 --> 00:44:14.480
that you're in and you're basically hosting them


00:44:14.480 --> 00:44:17.360
and they have access to everything that you've already run.


00:44:17.360 --> 00:44:20.440
So it's like true kind of real time.


00:44:20.440 --> 00:44:23.400
- That's nice, because sometimes it has,


00:44:23.400 --> 00:44:25.400
a cell has to run for 30 minutes,


00:44:25.400 --> 00:44:26.880
but then it has this nice little answer


00:44:26.880 --> 00:44:29.000
and you can work with that afterwards, right?


00:44:29.000 --> 00:44:32.360
- Exactly, or you want a model to be available


00:44:32.360 --> 00:44:35.600
and maybe you haven't saved it or something like,


00:44:35.600 --> 00:44:39.100
yeah, like this is just a way around


00:44:39.100 --> 00:44:40.600
some of these friction points.


00:44:40.600 --> 00:44:43.640
- Yeah, absolutely.


00:44:43.640 --> 00:44:45.760
I wanna circle back just really quickly


00:44:45.760 --> 00:44:48.960
for a testimony, I guess, out in the audience.


00:44:48.960 --> 00:44:52.280
Michael says, "I started teaching basic Git, Docker,


00:44:52.280 --> 00:44:56.320
and Python packaging to bioinformatics students at UCLA,


00:44:56.320 --> 00:44:58.720
and it's made a huge difference in the handoff."


00:44:58.720 --> 00:45:02.400
And I think for actual projects,


00:45:02.400 --> 00:45:05.000
I just think, as we were talking about


00:45:05.000 --> 00:45:06.840
what should people learn at data science


00:45:06.840 --> 00:45:07.760
and what they shouldn't, yeah,


00:45:07.760 --> 00:45:10.680
a little bit of the fluency with some of these tools


00:45:10.680 --> 00:45:12.240
is really helpful.


00:45:12.240 --> 00:45:13.880
- I absolutely agree.


00:45:13.880 --> 00:45:19.720
Like I know it can be really overwhelming, especially Git, initially for students who...


00:45:19.720 --> 00:45:20.920
- Git is overwhelming.


00:45:20.920 --> 00:45:21.420
- Yeah.


00:45:21.420 --> 00:45:22.620
Yeah.


00:45:22.620 --> 00:45:23.800
I would say I'm...


00:45:23.800 --> 00:45:26.840
Because I tend to end up thinking by myself.


00:45:26.840 --> 00:45:27.340
Yeah, yeah.


00:45:27.340 --> 00:45:34.120
But this sort of falls into the reproducibility stuff that I was talking about earlier.


00:45:34.120 --> 00:45:37.240
And it's super, super important.


00:45:37.240 --> 00:45:41.320
Like, and once you get comfortable with like just basic use of these tools, you can get really far.


00:45:41.320 --> 00:45:42.360
- Yeah.


00:45:43.560 --> 00:45:46.920
Okay, back to some of the tools, Jupyter, JupyterLab.


00:45:46.920 --> 00:45:51.960
What about JupyterLite? Have you played with JupyterLite?


00:45:51.960 --> 00:45:57.480
Only a teeny tiny bit because of this workshop that I'm going to be helping out with at


00:45:57.480 --> 00:46:01.720
EuroPython. So they're going to be running the whole thing in JupyterLite, hopefully.


00:46:01.720 --> 00:46:05.240
A couple of bugs to solve, but I think they're overcomable.


00:46:05.240 --> 00:46:11.560
But yeah, it's a really interesting alternative to Google Colab, actually.


00:46:12.760 --> 00:46:20.360
Yeah, JupyterLite, take Pyodide, which is CPython running a WebAssembly,


00:46:20.360 --> 00:46:26.280
and then build a bunch of the data science libraries like Matplotlib and stuff in WebAssembly.


00:46:26.280 --> 00:46:33.080
And then the benefit is you don't need a complex server to handle the compute and run arbitrary


00:46:33.080 --> 00:46:37.000
Python code, which is a little sketchy. You just run it on the front end in WebAssembly,


00:46:37.000 --> 00:46:38.000
which is pretty cool.


00:46:38.000 --> 00:46:43.080
I interviewed the folks at PySport a little while ago.


00:46:43.080 --> 00:46:50.280
And it's just the ability to just take your code


00:46:50.280 --> 00:46:54.760
and run all these-- if I go to the right spot--


00:46:54.760 --> 00:46:59.920
go and run all these different pieces on your front end


00:46:59.920 --> 00:47:02.800
without worrying about a server, I think, is super cool.


00:47:02.800 --> 00:47:04.280
Not if I get that right or not.


00:47:04.280 --> 00:47:11.880
But anyway, I think running it on top of people using it, on top of the browsers like you do


00:47:11.880 --> 00:47:16.280
JavaScript is an interesting thing to throw into the mix for notebooks.


00:47:16.280 --> 00:47:21.800
>> Yeah, and I think actually a lot of these projects coming out using Pyodide are really


00:47:21.800 --> 00:47:24.760
interesting. Obviously, PyScript is the big one from last year.


00:47:24.760 --> 00:47:31.640
>> Yeah, absolutely. Yeah, I think PyScript actually has really lots of interesting


00:47:34.120 --> 00:47:39.400
possibilities beyond just the data science side, right? Whereas Pyodide is a little more focused on just


00:47:39.400 --> 00:47:44.920
I think really providing the data science tools on the client side


00:47:44.920 --> 00:47:49.960
So we'll see we'll see where PyScript goes if they can they can make an equivalent of


00:47:49.960 --> 00:47:53.320
Vue.js or something like that where people can start building


00:47:53.320 --> 00:47:56.520
Legitimate


00:47:56.520 --> 00:48:01.160
Front-end interactive web apps like, you know, like airbnb or google maps or something


00:48:01.240 --> 00:48:03.600
but with Python, that's gonna unlock something


00:48:03.600 --> 00:48:06.560
that has been locked away for a really long time.


00:48:06.560 --> 00:48:09.760
With Pyodide, that's like a nine or 10 meg download.


00:48:09.760 --> 00:48:11.360
That's too much for the front end,


00:48:11.360 --> 00:48:14.040
just for like a public facing site generally


00:48:14.040 --> 00:48:14.880
at the start of time,


00:48:14.880 --> 00:48:18.360
but they're moving it to MicroPython as an option.


00:48:18.360 --> 00:48:19.720
And that's a couple hundred K,


00:48:19.720 --> 00:48:22.440
which is like these other front end frameworks.


00:48:22.440 --> 00:48:23.800
So it's very exciting.


00:48:23.800 --> 00:48:24.960
I think that's gonna be,


00:48:24.960 --> 00:48:27.000
that's definitely the most exciting thing in that area.


00:48:27.000 --> 00:48:29.320
But all right, back to data science, let's see.


00:48:29.320 --> 00:48:30.480
Where do you wanna go next?


00:48:30.480 --> 00:48:32.360
You want to talk pandas maybe?


00:48:32.360 --> 00:48:33.600
- Yeah, let's jump into pandas,


00:48:33.600 --> 00:48:36.040
which is the other biggie


00:48:36.040 --> 00:48:38.240
when you're talking about data science.


00:48:38.240 --> 00:48:40.960
So what pandas is really important for is,


00:48:40.960 --> 00:48:42.720
it's basically the entry point


00:48:42.720 --> 00:48:44.240
of you working with your data.


00:48:44.240 --> 00:48:46.200
So it's a library,


00:48:46.200 --> 00:48:50.700
which basically allows you to work with data frames.


00:48:50.700 --> 00:48:52.680
Data frames are basically tables.


00:48:52.680 --> 00:48:55.880
And from there, you can do data manipulation,


00:48:55.880 --> 00:48:58.400
you can explore your data and visualize it.


00:48:58.400 --> 00:49:03.020
And it also is an entry point to passing your data into models.


00:49:03.020 --> 00:49:07.340
Sometimes it'll need additional transformations, but say scikit-learn,


00:49:07.340 --> 00:49:11.220
which we can talk about in a sec, you can basically pass, you know,


00:49:11.220 --> 00:49:14.180
pandas data frames directly into scikit-learn models.


00:49:14.180 --> 00:49:19.620
Pandas also, because of its popularity,


00:49:19.620 --> 00:49:24.460
it's kind of opened up this easy access to like grid


00:49:24.480 --> 00:49:28.960
computing and other types of processing database stuff


00:49:28.960 --> 00:49:32.400
that you don't really need to learn those tools,


00:49:32.400 --> 00:49:33.600
but you get to take advantage of.


00:49:33.600 --> 00:49:36.400
And so two things that come to mind for me are Dask.


00:49:36.400 --> 00:49:37.240
- Yes.


00:49:37.240 --> 00:49:38.080
- Right?


00:49:38.080 --> 00:49:43.080
It's kind of like a Panda's code,


00:49:43.080 --> 00:49:45.400
but instead you can say,


00:49:45.400 --> 00:49:48.600
actually run this across this cluster of machines


00:49:48.600 --> 00:49:52.360
or larger than memory or stuff on my personal computer,


00:49:52.360 --> 00:49:56.600
or even just take advantage of all 10 cores on my M2


00:49:56.600 --> 00:49:58.960
instead of the one.


00:49:58.960 --> 00:49:59.800
- Yes.


00:49:59.800 --> 00:50:02.120
Yeah.


00:50:02.120 --> 00:50:03.080
- Have you done anything with Dask?


00:50:03.080 --> 00:50:04.080
Are you a fan of it?


00:50:04.080 --> 00:50:07.700
- The thing was, so Dask,


00:50:07.700 --> 00:50:10.040
I was kind of there when Dask was new


00:50:10.040 --> 00:50:13.840
and let's just say they find out a lot of the bugs.


00:50:13.840 --> 00:50:15.920
So what ended up happening


00:50:15.920 --> 00:50:17.960
was I ended up learning PySpark instead.


00:50:17.960 --> 00:50:20.960
So I went down a different kind of route,


00:50:20.960 --> 00:50:23.580
but I think they solve very similar problems.


00:50:23.580 --> 00:50:26.340
It's just Dask is much more similar to Pandas.


00:50:26.340 --> 00:50:29.540
And so you don't really need to deal with learning.


00:50:29.540 --> 00:50:32.840
It's similar, but it's a new API.


00:50:32.840 --> 00:50:34.460
- Yeah, another one that I was thinking of,


00:50:34.460 --> 00:50:38.360
I just had these guys on the show, sort of, is Ponder.


00:50:38.360 --> 00:50:41.340
- Oh, I have not heard of this.


00:50:41.340 --> 00:50:45.780
- So Ponder, they were at startup row at PyCon


00:50:45.780 --> 00:50:48.260
and they basically build on top of Moden,


00:50:48.260 --> 00:50:50.880
which is important, moden.pandas as PD.


00:50:50.880 --> 00:50:53.920
And what it does is it, instead of pulling all the data back


00:50:53.920 --> 00:50:57.600
and executing the commands on your machine in memory,


00:50:57.600 --> 00:50:59.080
which maybe that data transfer is huge,


00:50:59.080 --> 00:51:01.920
it actually runs it inside of Postgres and other data,


00:51:01.920 --> 00:51:04.040
and I think PySpark as well.


00:51:04.040 --> 00:51:06.920
Like it translates all these pandas commands


00:51:06.920 --> 00:51:09.800
to SQL commands to run inside the database


00:51:09.800 --> 00:51:14.160
where the data is, which is also a pretty interesting thing.


00:51:14.160 --> 00:51:15.280
- That is amazing.


00:51:15.280 --> 00:51:16.880
So yeah, it's just interpreting the code


00:51:16.880 --> 00:51:18.040
in a completely different way.


00:51:18.040 --> 00:51:20.920
you can do like query planning and optimize.


00:51:20.920 --> 00:51:22.320
- Yeah, exactly.


00:51:22.320 --> 00:51:27.320
They said that df.describe is like 300 lines of SQL.


00:51:27.320 --> 00:51:29.040
It's really, really tough.


00:51:29.040 --> 00:51:30.880
But once this thing writes it, then it's good to go.


00:51:30.880 --> 00:51:33.160
And I think the reason I bring this up is like,


00:51:33.160 --> 00:51:34.440
you don't have to write that code.


00:51:34.440 --> 00:51:36.200
You just have to know pandas.


00:51:36.200 --> 00:51:38.400
And then all of a sudden there's these libraries


00:51:38.400 --> 00:51:39.900
that'll do either grid computing


00:51:39.900 --> 00:51:43.760
or really complex SQL queries that you don't care about.


00:51:43.760 --> 00:51:45.240
You don't care to write or so on.


00:51:45.240 --> 00:51:48.000
So I think it's pandas is interesting on its own,


00:51:48.000 --> 00:51:51.160
but it's almost like a gateway to the broader data science community.


00:51:51.160 --> 00:51:55.280
Agreed. Agreed. And it's such a de facto,


00:51:55.280 --> 00:52:00.040
I think for data analysis now or data manipulation transformation.


00:52:00.040 --> 00:52:04.360
Yeah. Like I don't see it going away anytime soon.


00:52:04.360 --> 00:52:09.400
And actually pandas 2.0 just came out and instead of being,


00:52:09.400 --> 00:52:13.240
yeah, instead of pandas is numpy under the hood,


00:52:13.640 --> 00:52:17.000
which is fast, but it's not really equipped to deal


00:52:17.000 --> 00:52:21.080
with certain kinds of structures like strings,


00:52:21.080 --> 00:52:24.000
because it's not really what NumPy is about.


00:52:24.000 --> 00:52:25.680
And also missing values,


00:52:25.680 --> 00:52:28.080
the way that it handles that is pretty janky.


00:52:28.080 --> 00:52:33.080
So yeah, it's been rewritten with PyArrow under the hood.


00:52:33.080 --> 00:52:37.880
And yeah, apparently the performance is so much better.


00:52:37.880 --> 00:52:41.580
So something I need to sit down and actually try,


00:52:41.580 --> 00:52:43.000
it's been out for like a month


00:52:43.000 --> 00:52:45.120
and I'm feeling a bit bad, but yeah.


00:52:45.120 --> 00:52:45.960
- Yeah, that's cool.


00:52:45.960 --> 00:52:49.800
It probably has support for some of the serialization


00:52:49.800 --> 00:52:52.440
formats for back to let it, lack of a better term,


00:52:52.440 --> 00:52:56.360
like I said, parquet and some of those types of things.


00:52:56.360 --> 00:52:59.040
I think that comes straight out of PyArrow.


00:52:59.040 --> 00:53:00.360
Yeah.


00:53:00.360 --> 00:53:01.200
- Yeah.


00:53:01.200 --> 00:53:02.040
- Excellent.


00:53:02.040 --> 00:53:03.000
So that kind of brings me to a trade-off


00:53:03.000 --> 00:53:05.680
I wanted to talk to you about before we get off of Pandas


00:53:05.680 --> 00:53:09.480
is, you know, although it sounds like Pandas 2.0,


00:53:09.480 --> 00:53:12.360
it makes this less important, but you know,


00:53:12.360 --> 00:53:15.000
Another sort of competitor that came out is Polars,


00:53:15.000 --> 00:53:21.280
which is a data framing library for Python written in Rust.


00:53:21.280 --> 00:53:23.720
Many of the things are written in Rust these days


00:53:23.720 --> 00:53:24.920
when they care about performance.


00:53:24.920 --> 00:53:25.880
It's like a big trend.


00:53:25.880 --> 00:53:28.420
It's the new C extensions of Python.


00:53:28.420 --> 00:53:32.600
But this one is supposed to also be way faster


00:53:32.600 --> 00:53:37.600
than Pandas 1, and I think it's also based on PyArrow,


00:53:37.600 --> 00:53:39.040
amongst other things.


00:53:40.120 --> 00:53:42.600
but the details are not super important.


00:53:42.600 --> 00:53:43.880
More what I wanted to ask you is like,


00:53:43.880 --> 00:53:45.320
well, here's another way.


00:53:45.320 --> 00:53:46.560
This is a totally different API.


00:53:46.560 --> 00:53:48.200
It doesn't try to be compatible.


00:53:48.200 --> 00:53:50.000
So you got to learn it.


00:53:50.000 --> 00:53:52.400
So the question is, as a data scientist,


00:53:52.400 --> 00:53:54.960
as a data science team leader,


00:53:54.960 --> 00:53:56.280
how should you think about,


00:53:56.280 --> 00:54:00.440
do we keep chasing the shiny new thing


00:54:00.440 --> 00:54:02.960
or do we stick with stuff that one,


00:54:02.960 --> 00:54:04.160
people know like pandas,


00:54:04.160 --> 00:54:07.820
but two also extends into this broader space


00:54:07.820 --> 00:54:09.280
as a gateway, as we described.


00:54:09.280 --> 00:54:12.000
Like, what are your thoughts here?


00:54:12.000 --> 00:54:14.560
- Yeah, like this is a super interesting question.


00:54:14.560 --> 00:54:19.000
So data scientists in some ways have the luxury


00:54:19.000 --> 00:54:24.000
of being able to maybe use newer packages faster,


00:54:24.000 --> 00:54:29.800
because we build these small kind of atomic projects


00:54:29.800 --> 00:54:33.200
that we can just update to the next library


00:54:33.200 --> 00:54:34.920
that we feel like using in the next project.


00:54:34.920 --> 00:54:36.780
And maybe we're the only ones who ever look at that code.


00:54:36.780 --> 00:54:37.680
So it's cool.


00:54:38.640 --> 00:54:41.080
The problem is though, of course,


00:54:41.080 --> 00:54:45.120
is if someone else needs to look at your code,


00:54:45.120 --> 00:54:47.280
they are gonna need to be able to read it,


00:54:47.280 --> 00:54:49.280
which is not maybe the biggest problem.


00:54:49.280 --> 00:54:52.800
The biggest problem of course is any new library.


00:54:52.800 --> 00:54:54.400
You have less documentation


00:54:54.400 --> 00:54:56.920
and you have less entries on stack overflows.


00:54:56.920 --> 00:54:59.120
So I would say you need to make a trade-off


00:54:59.120 --> 00:55:03.240
between the time you're not only gonna spend learning it,


00:55:03.240 --> 00:55:06.480
but also debugging it, 'cause it's gonna be slower,


00:55:06.480 --> 00:55:09.000
that you ChatGPT doesn't know much about polars.


00:55:09.000 --> 00:55:13.640
Basically, you're essentially going to need


00:55:13.640 --> 00:55:14.800
to trade that off against,


00:55:14.800 --> 00:55:16.680
are you gonna see a benefit from that?


00:55:16.680 --> 00:55:20.800
So do you actually have problems


00:55:20.800 --> 00:55:22.840
with processing your data fast enough?


00:55:22.840 --> 00:55:25.200
If you're working on small data sets, probably not.


00:55:25.200 --> 00:55:28.280
If you're not, then maybe try something pandas


00:55:28.280 --> 00:55:29.400
or pandas adjacent.


00:55:29.400 --> 00:55:34.380
- Yeah, yeah, that sort of community support side


00:55:34.380 --> 00:55:35.220
is important.


00:55:35.220 --> 00:55:37.400
I'm pretty sure there are a lot of data scientists out there


00:55:37.400 --> 00:55:41.900
who are the one data scientist at their organization.


00:55:41.900 --> 00:55:42.900
And so it's not like,


00:55:42.900 --> 00:55:45.340
oh, we'll go ask the other expert down the hall


00:55:45.340 --> 00:55:48.980
because if it's not you, there's no answer, right?


00:55:48.980 --> 00:55:50.820
- Exactly, exactly.


00:55:50.820 --> 00:55:55.660
I do think though, like, again, it's good to be curious.


00:55:55.660 --> 00:55:58.780
It's good to try out new things as well.


00:55:58.780 --> 00:56:00.980
And again, part of being a data scientist


00:56:00.980 --> 00:56:03.380
is you can experiment a bit more, so.


00:56:03.380 --> 00:56:04.220
- Yeah.


00:56:04.220 --> 00:56:09.220
You know, 2017, 18, sort of the peak Python 2 versus 3


00:56:09.220 --> 00:56:15.200
tension, I guess, maybe one year before then.


00:56:15.200 --> 00:56:19.380
I noticed that the data scientists were like,


00:56:19.380 --> 00:56:20.500
I don't know what y'all are arguing about.


00:56:20.500 --> 00:56:22.340
We're done with this.


00:56:22.340 --> 00:56:24.300
What we're arguing about is,


00:56:24.300 --> 00:56:26.180
when can we take the Python 2 code out


00:56:26.180 --> 00:56:28.580
to absolutely 100% drop support for it,


00:56:28.580 --> 00:56:30.460
not when are we moving over?


00:56:30.460 --> 00:56:33.080
Whereas people running that Django site


00:56:33.080 --> 00:56:37.560
been around for eight years that's still on Python 2. They're starting to get nervous because they


00:56:37.560 --> 00:56:43.000
don't want to rewrite it because it works but they know they're going to have to. And I feel like


00:56:43.000 --> 00:56:49.560
the, you know, we talked about the legacy code is sort of the success story that is dreaded of


00:56:49.560 --> 00:56:55.080
software on the computer science side. Because that it's less of a thing in data science,


00:56:55.080 --> 00:56:59.320
it's easier to go, well this next project that we're starting in a couple months, we can start


00:56:59.320 --> 00:57:06.200
with newer tools. Yep and I actually remember the point where I decided okay this is the last


00:57:06.200 --> 00:57:14.040
project I'm doing into because the thing that was keeping me into was actually one of those


00:57:14.040 --> 00:57:18.440
libraries that I mentioned which you know built by a university and I was like you know what I'm


00:57:18.440 --> 00:57:23.320
just going to go find some alternative tool. I think at that time Spacey which is a very well


00:57:23.320 --> 00:57:28.760
known NLP library, actually, based here in Berlin.


00:57:28.760 --> 00:57:29.760
Yeah, exactly.


00:57:29.760 --> 00:57:31.760
Basically a neighbor of yours.


00:57:31.760 --> 00:57:32.760
That's right.


00:57:32.760 --> 00:57:37.800
But I think Spacey was really getting off its feet in that time.


00:57:37.800 --> 00:57:40.880
So I was like, you know what, I'm just going to switch over to this new library and try


00:57:40.880 --> 00:57:42.560
that and it's excellent.


00:57:42.560 --> 00:57:44.520
So I didn't look back.


00:57:44.520 --> 00:57:46.520
Yeah, Spacey's cool.


00:57:46.520 --> 00:57:52.280
Ines Montani is doing really great work and everyone over at Explosion AI.


00:57:52.280 --> 00:57:53.120
- I mean, that's the thing.


00:57:53.120 --> 00:57:54.960
Sometimes it seems like a hassle, right?


00:57:54.960 --> 00:57:57.300
But if it forces you out of your comfort zone


00:57:57.300 --> 00:57:59.680
to pick stuff that's being actively developed,


00:57:59.680 --> 00:58:01.040
maybe it's worth it, right?


00:58:01.040 --> 00:58:01.940
- Exactly.


00:58:01.940 --> 00:58:04.360
- All right, we're getting short on time.


00:58:04.360 --> 00:58:06.000
So you wanna give us a lightning round


00:58:06.000 --> 00:58:07.680
and the other important libraries


00:58:07.680 --> 00:58:10.600
you think data scientists should pay attention to?


00:58:10.600 --> 00:58:13.120
- Yeah, so let's just quickly go


00:58:13.120 --> 00:58:14.760
through the visualization side of things.


00:58:14.760 --> 00:58:17.020
So visualization is massive.


00:58:17.020 --> 00:58:19.640
So matplotlib is really the biggie


00:58:19.640 --> 00:58:21.320
and it's what a lot of libraries


00:58:21.320 --> 00:58:25.240
actually built on top of in Python.


00:58:25.240 --> 00:58:27.640
So the syntax is not that friendly.


00:58:27.640 --> 00:58:30.040
So there's a lot of alternatives.


00:58:30.040 --> 00:58:34.640
So Seaborn is a very popular one.


00:58:34.640 --> 00:58:37.080
We actually have an internal one called Let's Plot,


00:58:37.080 --> 00:58:38.880
which is a port of ggplot2.


00:58:38.880 --> 00:58:40.200
And there's another one called Plot9.


00:58:40.200 --> 00:58:43.000
And I think there actually may even be one called ggplot.


00:58:43.000 --> 00:58:46.240
- Some of the fancy new ones that people hear about,


00:58:46.240 --> 00:58:48.400
they're actually internally just controlling


00:58:48.400 --> 00:58:50.880
Matplotlib in a cleaner API, right?


00:58:50.880 --> 00:58:52.720
- Pretty much, and let me tell you,


00:58:52.720 --> 00:58:55.240
Matplotlib needs a clean API, it's a bit,


00:58:55.240 --> 00:58:58.120
let's say, archaic.


00:58:58.120 --> 00:59:01.760
- Give it some props for its XKCD graph style.


00:59:01.760 --> 00:59:06.760
I mean, that is pretty cool that you can get it to do that.


00:59:06.760 --> 00:59:10.120
- I actually have done,


00:59:10.120 --> 00:59:12.580
I've done XKCD graphs in Python as well.


00:59:12.580 --> 00:59:16.340
It's very, yeah, it's very,


00:59:16.340 --> 00:59:18.620
let's say it's a goal that you aim for


00:59:18.620 --> 00:59:21.860
to do like elite visualizations.


00:59:21.860 --> 00:59:24.900
- Yeah, well, you know, it's fun


00:59:24.900 --> 00:59:27.620
and XKCD is amazing in a lot of ways.


00:59:27.620 --> 00:59:32.300
However, I think it also can serve an important role


00:59:32.300 --> 00:59:36.460
when you're presenting to like leaders of an organization,


00:59:36.460 --> 00:59:38.260
non-technical people, 'cause if they look


00:59:38.260 --> 00:59:42.180
and see a beautiful, pristine production already,


00:59:42.180 --> 00:59:44.060
sort of like, we're done.


00:59:44.060 --> 00:59:45.660
You don't know, this is the product, no, we're done.


00:59:45.660 --> 00:59:47.220
Look, you look, you already got it.


00:59:47.220 --> 00:59:49.300
But if it comes out and sort of cartoony,


00:59:49.300 --> 00:59:51.580
kind of like wireframing for UI design,


00:59:51.580 --> 00:59:54.420
you're like, oh, there are no expectations it's done.


00:59:54.420 --> 00:59:55.380
It's XKCD.


00:59:55.380 --> 00:59:57.300
We're gonna get you the real graphs later, right?


00:59:57.300 --> 00:59:59.980
That's, there might be some value there.


00:59:59.980 --> 01:00:02.540
- Like a psychological effect where you make it look


01:00:02.540 --> 01:00:04.860
like a hand-drawn prototype.


01:00:04.860 --> 01:00:07.660
- Exactly, it looks just hand-drawn, it's barely done.


01:00:07.660 --> 01:00:08.500
- That's right.


01:00:08.500 --> 01:00:09.900
- And it's really just theme equals.


01:00:09.900 --> 01:00:11.660
- It just didn't take me two days.


01:00:11.660 --> 01:00:15.100
- scikit-learn, you mentioned that before.


01:00:15.100 --> 01:00:18.580
- Yes, so there are a whole bunch of libraries


01:00:18.580 --> 01:00:19.740
for doing machine learning.


01:00:19.740 --> 01:00:22.100
So I could learn is kind of your all in one


01:00:22.100 --> 01:00:23.800
for classic machine learning,


01:00:23.800 --> 01:00:26.580
but then you have this whole other branch of data science


01:00:26.580 --> 01:00:29.700
which is around neural nets or deep learning.


01:00:29.700 --> 01:00:34.580
So you have Keras, you have TensorFlow,


01:00:34.580 --> 01:00:39.580
you have PyTorch, and then you have a package


01:00:39.580 --> 01:00:43.820
for working with a lot of like these generative AI models


01:00:43.820 --> 01:00:46.740
or large language models called Transformers


01:00:46.740 --> 01:00:49.300
from a company called Hugging Face.


01:00:49.300 --> 01:00:53.020
So all of these are actually super accessible.


01:00:53.020 --> 01:00:55.380
I wouldn't say TensorFlow and PyTorch can be tricky,


01:00:55.380 --> 01:00:57.940
but Keras is like a friendly front end for them.


01:00:57.940 --> 01:01:00.240
And actually, if anyone is interested


01:01:00.240 --> 01:01:02.540
in getting into this side of things,


01:01:02.540 --> 01:01:05.860
there's a book called "Deep Learning in Python"


01:01:05.860 --> 01:01:09.500
by a AI researcher at Google called Francois Chollet.


01:01:11.340 --> 01:01:13.940
- Yeah, it is actually, I think,


01:01:13.940 --> 01:01:17.180
the most popular book ever on Manning.


01:01:17.180 --> 01:01:20.780
So it's an amazing book.


01:01:20.780 --> 01:01:22.260
I can only recommend it.


01:01:22.260 --> 01:01:24.440
And it's very gentle for beginners


01:01:24.440 --> 01:01:26.600
who have no background in the area.


01:01:26.600 --> 01:01:27.660
- Okay, yeah, cool.


01:01:27.660 --> 01:01:29.620
I'll put that in the show notes.


01:01:29.620 --> 01:01:30.780
- Awesome.


01:01:30.780 --> 01:01:32.100
- Yeah.


01:01:32.100 --> 01:01:34.660
All right, well, there are many other things


01:01:34.660 --> 01:01:35.980
we can talk about.


01:01:35.980 --> 01:01:37.740
Maybe just let's close this out


01:01:37.740 --> 01:01:42.740
with a quick shout out to your PyCon talk.


01:01:42.740 --> 01:01:48.700
Eventually, someday, I'm sure that the talks


01:01:48.700 --> 01:01:51.060
for PyCon will be on YouTube.


01:01:51.060 --> 01:01:54.020
They were last year, but I looked back


01:01:54.020 --> 01:01:55.820
and I was so excited near the end of the conference.


01:01:55.820 --> 01:01:57.460
I'm like, look, the talks are up.


01:01:57.460 --> 01:01:59.660
And I was talking to someone like, look, here's your talk.


01:01:59.660 --> 01:02:01.380
They're like, no, that's my talk from last year.


01:02:01.380 --> 01:02:02.820
I'm like, oh, yeah.


01:02:02.820 --> 01:02:05.620
So it was maybe three or four months delayed


01:02:05.620 --> 01:02:08.700
I feel it actually came out to maybe this midsummer,


01:02:08.700 --> 01:02:11.140
or the video of Virginia talk will be out,


01:02:11.140 --> 01:02:16.100
but maybe just give people a quick elevator pitch


01:02:16.100 --> 01:02:17.380
of your talk here.


01:02:17.380 --> 01:02:20.300
- Yeah, so I decided to give this talk


01:02:20.300 --> 01:02:24.140
because I kind of had to learn things the hard way


01:02:24.140 --> 01:02:26.540
in terms of performance with Python.


01:02:26.540 --> 01:02:29.920
So basically I used to do everything with loops


01:02:29.920 --> 01:02:32.740
and then I had to start working with larger amounts of data


01:02:32.740 --> 01:02:34.580
and it just doesn't scale.


01:02:34.580 --> 01:02:37.580
So over time, as I got better with Python,


01:02:37.580 --> 01:02:39.220
I learned more about NumPy,


01:02:39.220 --> 01:02:41.740
which is another important data science library.


01:02:41.740 --> 01:02:43.380
And it basically allows you to do


01:02:43.380 --> 01:02:44.980
what's called vectorized operations.


01:02:44.980 --> 01:02:48.780
So in this talk, I basically talk about like the math,


01:02:48.780 --> 01:02:51.320
but what behind why vectorized operations work.


01:02:51.320 --> 01:02:53.060
You don't need any math background to understand it.


01:02:53.060 --> 01:02:54.380
It's very gentle.


01:02:54.380 --> 01:02:58.380
And then just show like why some of these operations work


01:02:58.380 --> 01:03:01.420
in NumPy and how you can, you know,


01:03:01.420 --> 01:03:06.660
implement it yourself to get like really like massive gains in performance speed.


01:03:06.660 --> 01:03:08.580
Yeah, that's incredible.


01:03:08.580 --> 01:03:13.140
Move a lot of that stuff down into like a C or a rust layer and just let it do its


01:03:13.140 --> 01:03:15.540
magic instead of looping in Python.


01:03:15.540 --> 01:03:16.980
Yeah, exactly.


01:03:16.980 --> 01:03:17.620
Yeah.


01:03:17.620 --> 01:03:18.020
Very cool.


01:03:18.020 --> 01:03:23.180
So I don't know when, but eventually this will be out as a video people can check out


01:03:23.180 --> 01:03:23.700
from you now.


01:03:23.700 --> 01:03:25.380
They know to go look for it.


01:03:25.380 --> 01:03:26.060
Yeah.


01:03:26.060 --> 01:03:27.660
I think the port team is still recovering.


01:03:27.660 --> 01:03:29.220
So much work.


01:03:29.220 --> 01:03:30.060
I know.


01:03:30.860 --> 01:03:32.040
I know it.


01:03:32.040 --> 01:03:34.460
All right, well, Jody, it's been great to have you


01:03:34.460 --> 01:03:35.300
on the show.


01:03:35.300 --> 01:03:37.540
Before you get out of here, final two questions.


01:03:37.540 --> 01:03:38.940
If you're gonna write some Python code,


01:03:38.940 --> 01:03:40.780
what editor are you using these days?


01:03:40.780 --> 01:03:45.380
- So I'm actually using all three that I talked about.


01:03:45.380 --> 01:03:47.620
I use PyCharm if I need to do something


01:03:47.620 --> 01:03:50.340
like a bit more on the engineering side,


01:03:50.340 --> 01:03:52.580
which is not that often for me.


01:03:52.580 --> 01:03:56.340
Dataspel if I'm doing sort of very local development


01:03:56.340 --> 01:03:58.420
and doing more of the research side.


01:03:58.420 --> 01:04:02.200
And then if I need some GPUs, I'm using Datalore.


01:04:02.200 --> 01:04:05.860
So a bit boring, but using all of our tools


01:04:05.860 --> 01:04:07.460
and I really like them.


01:04:07.460 --> 01:04:08.520
- Yeah, they are good.


01:04:08.520 --> 01:04:09.620
All right.


01:04:09.620 --> 01:04:12.040
And then notable PyPI package,


01:04:12.040 --> 01:04:14.000
something you wanna give a shout out to,


01:04:14.000 --> 01:04:15.660
or if you prefer a conda package,


01:04:15.660 --> 01:04:17.660
there's a lot of intersection here.


01:04:17.660 --> 01:04:19.500
- Yeah, I think my favorite package


01:04:19.500 --> 01:04:21.540
at the moment is Transformers.


01:04:21.540 --> 01:04:23.140
It is amazing.


01:04:23.140 --> 01:04:25.420
And the documentation that Hugging Face have put together


01:04:25.420 --> 01:04:26.240
is so good.


01:04:26.240 --> 01:04:30.840
just the work they're doing in open data science is so, so important.


01:04:30.840 --> 01:04:33.440
So, like big props to Hugging Face.


01:04:33.440 --> 01:04:35.440
We should really support the work that they're doing.


01:04:35.440 --> 01:04:36.540
Excellent.


01:04:36.540 --> 01:04:37.640
All right.


01:04:37.640 --> 01:04:41.340
Well, thanks for being on the show and sharing your experience.


01:04:41.340 --> 01:04:42.940
Thank you so much for having me.


01:04:42.940 --> 01:04:44.440
I had an absolute blast.


01:04:44.440 --> 01:04:45.540
Yeah, same.


01:04:45.540 --> 01:04:46.140
Bye.


01:04:46.140 --> 01:04:46.940
Bye.


01:04:46.940 --> 01:04:56.940
[BLANK_AUDIO]

