WEBVTT

00:00:00.000 --> 00:00:05.000
- Mark Guido, welcome to Talk Python to Me.


00:00:05.000 --> 00:00:06.340
- Hi, hello.


00:00:06.340 --> 00:00:09.580
- It's fantastic to have you here.


00:00:09.580 --> 00:00:12.000
I'm so excited about all the things


00:00:12.000 --> 00:00:14.340
that are happening around Python performance.


00:00:14.340 --> 00:00:18.000
I feel like there's just a bunch of new ideas springing up


00:00:18.000 --> 00:00:21.660
and people working on it and yeah, it's exciting times.


00:00:21.660 --> 00:00:24.260
- Definitely.


00:00:24.260 --> 00:00:27.640
- Yeah, and you two are of course,


00:00:27.640 --> 00:00:29.120
right at the center of it.


00:00:29.120 --> 00:00:32.040
But before we talk about the performance work


00:00:32.040 --> 00:00:32.880
that you are all doing,


00:00:32.880 --> 00:00:35.800
as well as some of the other initiatives going along,


00:00:35.800 --> 00:00:37.040
maybe in parallel there,


00:00:37.040 --> 00:00:40.720
let's just get started with a little bit of background.


00:00:40.720 --> 00:00:42.200
Guido, you've been on the show before,


00:00:42.200 --> 00:00:44.080
you're a creator of Python,


00:00:44.080 --> 00:00:47.560
you hardly need an introduction to most people out there.


00:00:47.560 --> 00:00:50.960
But you have recently made a couple of big changes


00:00:50.960 --> 00:00:54.160
in your life, I thought I'd just ask you how that's going.


00:00:54.160 --> 00:00:56.780
You retired and we were all super happy for you on that.


00:00:56.780 --> 00:00:58.600
And then you said, you know what,


00:00:58.600 --> 00:01:00.140
I kind of want to play with code some more.


00:01:00.140 --> 00:01:01.360
And now you're at Microsoft.


00:01:01.360 --> 00:01:03.040
What's the story there?


00:01:03.040 --> 00:01:07.160
- Oh, I just liked the idea of retiring.


00:01:07.160 --> 00:01:12.160
So I tried to see how many times in a lifetime I can retire.


00:01:12.160 --> 00:01:15.240
Starting with my retirement from BDFL,


00:01:15.240 --> 00:01:20.920
which didn't stop me from staying super active


00:01:20.920 --> 00:01:21.940
in the community.


00:01:24.760 --> 00:01:29.460
But when I retired from Dropbox a little over two years ago,


00:01:29.460 --> 00:01:33.800
I really thought that that was it, that I believed it.


00:01:33.800 --> 00:01:34.640
- Yeah.


00:01:34.640 --> 00:01:36.200
- And everybody else believed it too.


00:01:36.200 --> 00:01:38.280
Dropbox certainly believed it.


00:01:38.280 --> 00:01:41.580
They were very sad to see me go.


00:01:41.580 --> 00:01:44.080
I was sad to go, but I thought there was time.


00:01:44.080 --> 00:01:49.080
And I sort of, I had a few great months decompressing,


00:01:54.400 --> 00:01:59.400
going on bike rides with my wife and family, fun stuff.


00:01:59.400 --> 00:02:02.600
And then the pandemic hit.


00:02:02.600 --> 00:02:03.440
- Yeah.


00:02:03.440 --> 00:02:05.960
- And a bunch of things got harder.


00:02:05.960 --> 00:02:09.040
The fortunately the bike rides eventually got restored


00:02:09.040 --> 00:02:12.120
but other activities like eating out


00:02:12.120 --> 00:02:14.020
was a lot more stressful.


00:02:14.020 --> 00:02:17.160
Basically just life was a lot more stressful in general.


00:02:17.160 --> 00:02:18.540
- Right, and human interaction


00:02:18.540 --> 00:02:22.060
was definitely strunken down to a kernel.


00:02:22.060 --> 00:02:29.420
Yeah, and I somehow I thought, well, I want to have something to do. I want to


00:02:29.420 --> 00:02:34.780
do more sort of software development in the team.


00:02:34.780 --> 00:02:42.460
And the Python core development team didn't really cut it for me because it's


00:02:42.460 --> 00:02:49.820
sort of diffuse and volunteer-based and sometimes you get stuck waiting for months for the steering


00:02:49.820 --> 00:02:59.180
council to sort of approve of or reject a certain idea that you've worked on.


00:02:59.180 --> 00:03:05.020
So I asked around and I found that Microsoft was super interested in hiring me


00:03:05.020 --> 00:03:13.260
and that was now, well tomorrow exactly a month, a year, tomorrow a year ago


00:03:14.380 --> 00:03:28.220
I started at Microsoft. In the beginning I just had to find my way around at Microsoft.


00:03:28.220 --> 00:03:35.180
Eventually I figured I should pick a project and after looking around and realizing I


00:03:35.180 --> 00:03:41.900
couldn't really turn the world of machine learning upside down. I figured I'd


00:03:42.940 --> 00:03:48.860
stay closer to home and see if Microsoft was interested in funding a team working on


00:03:48.860 --> 00:03:58.620
speeding up CPython. And I was actually inspired by Mark's proposals that were going around at the


00:03:58.620 --> 00:04:07.340
time. So I convinced Microsoft to sort of start a small team and get Mark on board.


00:04:08.460 --> 00:04:15.020
Yeah, that's fantastic. I also feel a little bit like machine learning is amazing, but I don't have


00:04:15.020 --> 00:04:20.460
a lot of experience with it. And whenever I work with it, I always kind of feel on the outside of


00:04:20.460 --> 00:04:27.100
it. But this core performance of Python, that helps everybody, right? Including even Microsoft,


00:04:27.100 --> 00:04:33.260
right? It maybe saves them energy on Azure when they're running Python workloads or whatever.


00:04:36.300 --> 00:04:38.300
So you're enjoying your time, you happy you're there?


00:04:38.300 --> 00:04:40.300
I'm very happy.


00:04:40.300 --> 00:04:45.300
Yeah, a lot of freedom to basically pursue what you are, right?


00:04:45.300 --> 00:04:50.300
And it's nice that the new Microsoft is very open source friendly.


00:04:50.300 --> 00:04:55.300
At least in many cases, obviously not everywhere.


00:04:55.300 --> 00:05:00.300
But sort of our department is very open source friendly.


00:05:00.300 --> 00:05:04.300
Things like Visual Studio Code are all open source.


00:05:04.300 --> 00:05:13.180
And so there was great support with management for sort of the way I said I wanted to do this project,


00:05:13.180 --> 00:05:15.860
which is completely out in the open.


00:05:15.860 --> 00:05:24.020
Everything we do is sort of just merged into main as soon as we can.


00:05:24.020 --> 00:05:27.980
We work with the core developers.


00:05:27.980 --> 00:05:31.900
we don't have like a private fork of Python


00:05:31.900 --> 00:05:34.100
where we do amazing stuff.


00:05:34.100 --> 00:05:37.620
And then we knock on the steering council's door


00:05:37.620 --> 00:05:41.820
and say, "Hey, we'd like to merge this."


00:05:41.820 --> 00:05:45.180
- Yeah, you're not gonna drop six months of work


00:05:45.180 --> 00:05:46.820
just in one block, right?


00:05:46.820 --> 00:05:49.240
It's there for everyone to see.


00:05:49.240 --> 00:05:50.080
- Exactly.


00:05:50.080 --> 00:05:53.320
- I think that's really, really positive.


00:05:53.320 --> 00:05:57.460
And wow, what a change, not just from Microsoft,


00:05:57.460 --> 00:06:00.140
but so many companies to work that way


00:06:00.140 --> 00:06:02.300
compared to 10, 15 years ago.


00:06:02.300 --> 00:06:05.820
Yeah, absolutely.


00:06:05.820 --> 00:06:08.460
Now, before I get to Mark, I just wanna,


00:06:08.460 --> 00:06:11.320
you know, a bunch of people are excited that you're here.


00:06:11.320 --> 00:06:13.820
And Luis out in the audience said,


00:06:13.820 --> 00:06:15.700
"Wow, it's Guido, I can't thank you enough


00:06:15.700 --> 00:06:18.020
"for your amazing Python and all the community."


00:06:18.020 --> 00:06:18.860
Awesome.


00:06:18.860 --> 00:06:21.060
- Great to hear.


00:06:21.060 --> 00:06:21.900
- Yeah.


00:06:21.900 --> 00:06:23.700
Mark, how about you?


00:06:23.700 --> 00:06:26.300
How'd you get into this Python performance thing?


00:06:26.300 --> 00:06:28.940
I know you did some stuff with HotPie back in the day.


00:06:28.940 --> 00:06:32.020
- Yeah, that was sort of my PhD work.


00:06:32.020 --> 00:06:36.460
So I guess I kind of got into the performance


00:06:36.460 --> 00:06:37.780
almost before the Python.


00:06:37.780 --> 00:06:42.020
So I was doing sort of compiler work, masters,


00:06:42.020 --> 00:06:44.700
and obviously just, you know,


00:06:44.700 --> 00:06:48.280
you need to write scripts and just get stuff done.


00:06:48.280 --> 00:06:51.300
And, you know, often just Python is just a language


00:06:51.300 --> 00:06:52.140
to get stuff done.


00:06:52.140 --> 00:06:55.540
And then it's that, I think I'm in Rigo,


00:06:55.540 --> 00:06:58.580
sort of, I think one of his sort of credits


00:06:58.580 --> 00:06:59.740
in one of his papers or something,


00:06:59.740 --> 00:07:01.060
he says, "Thank you for Python


00:07:01.060 --> 00:07:02.780
"for being such a great language to use


00:07:02.780 --> 00:07:05.220
"and such a challenge to optimize."


00:07:05.220 --> 00:07:08.540
So it's doubly good if you're coming at it from a sort of,


00:07:08.540 --> 00:07:10.720
so it provides this great intellectual challenge


00:07:10.720 --> 00:07:12.540
when you're actually trying to optimize it.


00:07:12.540 --> 00:07:14.380
And it's a really nice language to use as well.


00:07:14.380 --> 00:07:16.780
So it's doubly good.


00:07:16.780 --> 00:07:19.500
- It is doubly good, it's doubly good.


00:07:19.500 --> 00:07:21.220
Yeah, and before we move on really quick,


00:07:21.220 --> 00:07:22.860
Paul Everett says, "It's really impressive


00:07:22.860 --> 00:07:25.500
of how the in the open work has been done.


00:07:25.500 --> 00:07:27.020
Yeah, totally agree.


00:07:27.020 --> 00:07:28.060
- Hi, Paul.


00:07:28.060 --> 00:07:29.100
- Yeah, keep that going.


00:07:29.100 --> 00:07:30.800
Hey, Paul, happy to see you here.


00:07:30.800 --> 00:07:35.020
Now, we're gonna talk about making Python faster,


00:07:35.020 --> 00:07:38.380
but I wanna start this conversation


00:07:38.380 --> 00:07:41.180
with a bit of a hypothetical question,


00:07:41.180 --> 00:07:44.460
but sort of set the stage and ask,


00:07:44.460 --> 00:07:47.380
how much does Python really need to be faster?


00:07:47.380 --> 00:07:49.780
Because on one hand,


00:07:51.020 --> 00:07:53.260
Sure, there's a lot more performance we can do


00:07:53.260 --> 00:07:55.660
if you're going to say, well, we're going to solve the nbody


00:07:55.660 --> 00:08:00.940
problem using C++ or C# versus Python.


00:08:00.940 --> 00:08:04.540
It's going to be faster with the native value types and whatnot.


00:08:04.540 --> 00:08:06.780
On the other, people are building amazing software


00:08:06.780 --> 00:08:08.860
that runs really fast with Python already.


00:08:08.860 --> 00:08:12.900
We've got the C optimizations for things like NumPy


00:08:12.900 --> 00:08:16.780
and SQL alchemies, transformation layer,


00:08:16.780 --> 00:08:18.500
serialization layer, and so on.


00:08:18.500 --> 00:08:20.900
So a lot of times that kind of brings it back


00:08:20.900 --> 00:08:21.740
to C performance.


00:08:21.740 --> 00:08:25.380
So how much do you think Python really needs


00:08:25.380 --> 00:08:28.760
to be optimized already?


00:08:28.760 --> 00:08:32.220
Not that more is always better, faster is always better,


00:08:32.220 --> 00:08:34.400
but I just kind of want to set the stage


00:08:34.400 --> 00:08:36.100
and get your two thoughts on that.


00:08:36.100 --> 00:08:43.020
- Well, I always think back to my experience at Dropbox,


00:08:43.020 --> 00:08:48.080
where there was a large server called the meta server,


00:08:48.080 --> 00:09:00.480
which did sort of almost all the server side work, like anything that hits www.dropbox.com hits that server.


00:09:00.480 --> 00:09:10.080
And that server was initially a small prototype written in Python. The client was actually also a small prototype written in Python.


00:09:10.080 --> 00:09:16.480
And to this day, both the server and the client at Dropbox, as far as I know,


00:09:16.480 --> 00:09:20.720
unless in the last two years, they totally ripped it apart, but I don't think they did.


00:09:20.720 --> 00:09:27.120
They tweaked it, but it's still all now very large Python applications.


00:09:27.120 --> 00:09:36.960
And so Dropbox really sort of feels the speed of Python


00:09:36.960 --> 00:09:41.960
in its budget because they have thousands,


00:09:41.960 --> 00:09:44.440
I don't know how many thousands of machines


00:09:44.440 --> 00:09:48.760
that all run this enormous Python application.


00:09:48.760 --> 00:09:49.600
And yes-


00:09:49.600 --> 00:09:50.740
- If it was four times faster,


00:09:50.740 --> 00:09:54.180
that's not just for a quarter of the machines,


00:09:54.180 --> 00:09:58.120
that's less DevOps, less admin, all sorts of stuff, right?


00:09:58.120 --> 00:10:02.080
- Oh, even if it was 4% faster, they would notice.


00:10:02.080 --> 00:10:03.920
- Yeah.


00:10:04.920 --> 00:10:07.560
The other area where I think it's really relevant


00:10:07.560 --> 00:10:13.260
has to do with the multi-core side of things, right?


00:10:13.260 --> 00:10:17.220
I have a PC over there, 16 cores.


00:10:17.220 --> 00:10:19.020
My new laptop has 10 cores.


00:10:19.020 --> 00:10:23.700
Although with Python, it's hard to take true advantage


00:10:23.700 --> 00:10:27.160
of that side of modern CPU performance


00:10:27.160 --> 00:10:28.620
if it's not IO bound, right?


00:10:28.620 --> 00:10:33.800
- Yeah, so the, I don't know how deep you want me


00:10:33.800 --> 00:10:42.920
go into that and Mark can stop me if I'm going too deep too. But there are existing patterns


00:10:42.920 --> 00:10:53.080
that work reasonably well if you have a server application that sort of handles multiple


00:10:53.080 --> 00:11:00.120
fairly independent requests. Like if you're building a multi-core web application


00:11:03.080 --> 00:11:09.560
you can use multi-processing or pre-forking or a variety of ways of running a Python


00:11:09.560 --> 00:11:15.480
interpreter on each core that you have, each independently handling requests.


00:11:15.480 --> 00:11:21.160
And you can do that if you have 64 cores, you run 64 Python processes.


00:11:21.160 --> 00:11:24.920
Right, that's just a number in a micro-WSGI config file. It's nothing.


00:11:25.800 --> 00:11:35.240
Yeah, but it works for applications that are designed to handle


00:11:35.240 --> 00:11:43.880
multiple independent requests in a scalable fashion. There are other algorithms that


00:11:43.880 --> 00:11:52.120
you would want to execute where it's much more complicated to employ all your cores efficiently.


00:11:54.040 --> 00:11:56.040
Yeah, absolutely.


00:11:56.040 --> 00:12:00.040
That's still a nut that Python hasn't cracked.


00:12:00.040 --> 00:12:08.040
And I'm assuming you're asking this question because Sam Gross, a very smart developer at Facebook, claims that he has cracked it.


00:12:08.040 --> 00:12:16.040
Yeah, and perhaps he has. It's an interesting idea. We'll dive into that a little bit later.


00:12:16.040 --> 00:12:21.880
I'm more asking it just because I see a lot of people say that Python is too slow.


00:12:21.880 --> 00:12:25.640
And then I also see a lot of people being very successful with it.


00:12:25.640 --> 00:12:31.640
And it not being slow in practice, or not being much slower than other things.


00:12:31.640 --> 00:12:36.600
And so I more want to set the stage of like the context matters, right?


00:12:36.600 --> 00:12:39.880
This Dropbox example you have, it really matters to them.


00:12:39.880 --> 00:12:43.560
You know, my course website where people take courses,


00:12:43.560 --> 00:12:45.960
the response time of the pages is 40 milliseconds.


00:12:45.960 --> 00:12:48.560
If it was 38, it doesn't matter.


00:12:48.560 --> 00:12:50.640
It's really fast, it's fine.


00:12:50.640 --> 00:12:53.660
So I think, but if I was trying to do computational biology


00:12:53.660 --> 00:12:56.480
in Python, I would really want to be able to take advantage


00:12:56.480 --> 00:12:58.200
of those 16 cores, right?


00:12:58.200 --> 00:13:02.320
So there's just such a variety of perspectives


00:13:02.320 --> 00:13:04.320
where it matters.


00:13:04.320 --> 00:13:06.600
Mark, what are your thoughts on all this?


00:13:06.600 --> 00:13:10.120
- Well, it's just a case of saving energy, saving time.


00:13:10.120 --> 00:13:13.240
Just, it just makes the whole thing nicer to use.


00:13:13.240 --> 00:13:20.920
So I mean, there's a lot of just if development in data science and it's that responsiveness,


00:13:20.920 --> 00:13:26.000
the whole, you know, just breaking your train of thought because things take too long versus


00:13:26.000 --> 00:13:28.240
just keeping in the flow and all this sort of stuff.


00:13:28.240 --> 00:13:30.480
It's just nice to have something that's faster.


00:13:30.480 --> 00:13:33.480
I mean, it's not just the big companies saving money as well.


00:13:33.480 --> 00:13:36.280
I mean, it's just keeps everyone's server budgets down.


00:13:36.280 --> 00:13:41.320
I mean, if you just need a smaller virtual instance because you can serve the requests


00:13:41.320 --> 00:13:49.560
up fast enough because Python's faster. So I think it's just generally a sort of responsible


00:13:49.560 --> 00:13:53.460
thing to do. I mean, it's also just, you know, people expect technology to move forwards


00:13:53.460 --> 00:13:58.560
and there's this feeling of, you know, falling behind or not, you know, people wanting to


00:13:58.560 --> 00:14:01.320
move other languages because of the perceived performance.


00:14:01.320 --> 00:14:05.400
Right. I do think that that's an issue, you know, I'm moving to Go because it has better


00:14:05.400 --> 00:14:08.360
or async support, or we're rewriting this in Rust


00:14:08.360 --> 00:14:11.240
for whatever reason.


00:14:11.240 --> 00:14:13.200
Sometimes that might make sense, but other times


00:14:13.200 --> 00:14:16.080
I feel like that's just a shame, and it could be used better.


00:14:16.080 --> 00:14:17.800
A couple of questions from the audience


00:14:17.800 --> 00:14:21.120
I just want to throw out there.


00:14:21.120 --> 00:14:24.080
Let's see.


00:14:24.080 --> 00:14:29.720
One was, Guido, especially, you must


00:14:29.720 --> 00:14:31.640
be really proud to hear about the Mars


00:14:31.640 --> 00:14:35.600
helicopter and the lander and Python in space,


00:14:35.600 --> 00:14:39.160
how did you feel when you heard about the helicopter


00:14:39.160 --> 00:14:42.520
using Python and the lander using Python and Flask


00:14:42.520 --> 00:14:43.560
and things like that?


00:14:43.560 --> 00:14:53.880
- It wasn't really a surprise given how popular Python is


00:14:53.880 --> 00:14:55.400
amongst scientists.


00:14:57.240 --> 00:15:04.280
So I didn't throw a party but it made me feel good. I mean it's definitely


00:15:04.280 --> 00:15:12.040
sort of one of those accomplishments for a piece of technology if it's actually shot into space.


00:15:12.040 --> 00:15:22.040
You know you've made a difference. I remember like 30 years ago or more when I


00:15:23.480 --> 00:15:31.080
helped some coding on a European project called Amoeba, which was like a little distributed


00:15:31.080 --> 00:15:37.800
operating system. And one of the things that they always boasted was that


00:15:37.800 --> 00:15:44.040
our software runs on the European Space Station. And that's very important.


00:15:44.040 --> 00:15:50.920
Yeah, so yeah, I totally get the feeling and I hope that everyone who contributed to Python


00:15:51.800 --> 00:15:56.800
also sort of feels that their contribution has.


00:15:56.800 --> 00:16:00.200
- That sense of awe, if you look up in the night sky


00:16:00.200 --> 00:16:02.080
and you see that little, that bright star


00:16:02.080 --> 00:16:04.880
that's actually Mars and you think, yeah, it's up there.


00:16:04.880 --> 00:16:07.760
Yeah, fantastic.


00:16:07.760 --> 00:16:10.880
All right, let's dive into some of the performance stuff


00:16:10.880 --> 00:16:12.140
that you all have been doing.


00:16:12.140 --> 00:16:15.920
So maybe Guido, start us out with the team.


00:16:15.920 --> 00:16:18.760
So you've got a group of folks working together.


00:16:18.760 --> 00:16:21.400
It's not just you and also now Mark Shannon


00:16:21.400 --> 00:16:23.200
is working with you as well, right?


00:16:23.200 --> 00:16:25.840
- That's correct.


00:16:25.840 --> 00:16:29.320
The sort of in March or so,


00:16:29.320 --> 00:16:34.320
the initial team was Eric Snow, Mark and myself.


00:16:34.320 --> 00:16:39.840
And since I think, since early October,


00:16:39.840 --> 00:16:44.880
we've got a fourth team member, Brent Booker,


00:16:44.880 --> 00:16:48.140
who is also a Python core dev,


00:16:48.140 --> 00:16:50.860
since I think since about a year and a half.


00:16:50.860 --> 00:16:53.820
He's a really smart guy.


00:16:53.820 --> 00:16:57.140
So now we have four people,


00:16:57.140 --> 00:17:00.140
except you should really discount me as a team member


00:17:00.140 --> 00:17:04.680
because I spend most of my time in meetings


00:17:04.680 --> 00:17:09.680
either with a team or with other things


00:17:09.680 --> 00:17:12.600
going on at Microsoft in practice.


00:17:12.600 --> 00:17:15.660
- Sure, how closely do you work with say


00:17:15.660 --> 00:17:19.020
the VS Code Python plugin team and other parts,


00:17:19.020 --> 00:17:21.780
or is this more a focused effort?


00:17:21.780 --> 00:17:24.100
- This is more focused.


00:17:24.100 --> 00:17:26.120
I know those people.


00:17:26.120 --> 00:17:31.540
I've not met anyone in person, of course.


00:17:31.540 --> 00:17:35.980
I've not met, I've not been to a Microsoft office


00:17:35.980 --> 00:17:39.540
since I started there, which is really crazy.


00:17:39.540 --> 00:17:44.060
But what we're doing is really quite separate


00:17:44.060 --> 00:17:48.220
from other Python-related projects at Microsoft.


00:17:48.220 --> 00:17:53.220
But I do get called into meetings to give my opinion


00:17:53.220 --> 00:17:56.980
or what I know about how the community is feeling


00:17:56.980 --> 00:17:59.280
or how the core dev team is feeling


00:17:59.280 --> 00:18:04.280
about various things that are interesting to Microsoft


00:18:04.280 --> 00:18:09.400
or sometimes things that management is concerned about.


00:18:09.400 --> 00:18:11.620
- Yeah, excellent.


00:18:12.580 --> 00:18:14.940
It might be worth saying this, not just Microsoft as well.


00:18:14.940 --> 00:18:16.700
We've got contributors from,


00:18:16.700 --> 00:18:19.420
there's quite a few other core developers are helping out.


00:18:19.420 --> 00:18:21.900
So it's a broader effort.


00:18:21.900 --> 00:18:22.740
- Yeah, fantastic.


00:18:22.740 --> 00:18:24.700
And Mark, what's your role on the team?


00:18:24.700 --> 00:18:28.780
- I don't really have sort of official roles,


00:18:28.780 --> 00:18:33.780
but I guess I'm sort of doing as a fair bit


00:18:33.780 --> 00:18:36.580
of sort of technical sort of architectural side of stuff,


00:18:36.580 --> 00:18:40.620
obviously, 'cause this is like my field, so.


00:18:40.620 --> 00:18:41.580
- Right.


00:18:41.580 --> 00:18:43.720
- But I think-- - You're a nice grand chief.


00:18:43.720 --> 00:18:44.720
- Yeah, I guess so.


00:18:44.720 --> 00:18:49.080
- All right, Guido, you gave a talk


00:18:49.080 --> 00:18:52.440
at the Python Language Summit in May this year,


00:18:52.440 --> 00:18:54.560
talking about FasterPython, this team,


00:18:54.560 --> 00:18:55.840
some of the work that you're doing.


00:18:55.840 --> 00:18:57.280
So I thought that might be a good place


00:18:57.280 --> 00:18:59.560
to start the conversation.


00:18:59.560 --> 00:19:03.680
- Yeah, some of the content there is a little outdated, but.


00:19:03.680 --> 00:19:06.400
- Well, you just have to let me know


00:19:06.400 --> 00:19:09.600
when things have changed, so.


00:19:09.600 --> 00:19:16.160
One of the questions you ask is, can we make CPython specifically faster?


00:19:16.160 --> 00:19:17.920
And I think that's also worth pointing out, right?


00:19:17.920 --> 00:19:19.920
There's many runtimes.


00:19:19.920 --> 00:19:21.920
Often they're called interpreters.


00:19:21.920 --> 00:19:26.080
I prefer to the runtime word because sometimes they compile and they don't interpret.


00:19:26.080 --> 00:19:28.080
So anyway, there's...


00:19:28.080 --> 00:19:30.080
Sometimes they're called virtual machines.


00:19:30.080 --> 00:19:32.720
Yeah, there's many Python virtual machines.


00:19:32.720 --> 00:19:38.480
PyPy, CPython, you know, traditionally there's been Jython and IronPython,


00:19:38.480 --> 00:19:41.160
although I don't know if they're doing anything.


00:19:41.160 --> 00:19:43.440
But your focus and your energy is about


00:19:43.440 --> 00:19:45.320
how do we make the Python people get,


00:19:45.320 --> 00:19:48.120
if they just go to their terminal and type Python,


00:19:48.120 --> 00:19:49.600
the main Python faster,


00:19:49.600 --> 00:19:51.400
'cause that's what people are using, right?


00:19:51.400 --> 00:19:52.800
For the most part?


00:19:52.800 --> 00:19:54.320
- Yeah, that sort of,


00:19:54.320 --> 00:19:58.560
I don't have specific numbers or sources,


00:19:58.560 --> 00:20:02.960
but I believe that like between 95 and 99%


00:20:02.960 --> 00:20:07.360
of people using Python are using some version of CPython,


00:20:07.360 --> 00:20:10.520
hopefully not too many of them are still using Python 2.


00:20:10.520 --> 00:20:13.280
- Yeah, I would totally agree with that.


00:20:13.280 --> 00:20:15.840
And I would think it would trend more towards the 99


00:20:15.840 --> 00:20:18.700
and less towards the 95 for sure.


00:20:18.700 --> 00:20:21.040
Maybe a fork of CPython that they've done


00:20:21.040 --> 00:20:24.000
something weird too, but yeah, I would say CPython.


00:20:24.000 --> 00:20:28.440
So you asked the question, can we speed up CPython?


00:20:28.440 --> 00:20:29.880
And Teddy out in the live stream,


00:20:29.880 --> 00:20:31.800
I don't know if I'll be able to catch his comment exactly.


00:20:31.800 --> 00:20:32.640
Yeah, there he is.


00:20:32.640 --> 00:20:36.200
You know, what will we lose in making Python faster


00:20:36.200 --> 00:20:38.640
if anything, for example, what are the trade-offs?


00:20:38.640 --> 00:20:40.960
So you point out, well, can we make it two times faster,


00:20:40.960 --> 00:20:44.960
10 times faster, and then without breaking anybody's code?


00:20:44.960 --> 00:20:47.840
Right, because I think we just went through a two to three


00:20:47.840 --> 00:20:50.180
type of thing that was way more drawn out


00:20:50.180 --> 00:20:51.760
than I feel like it should have been.


00:20:51.760 --> 00:20:54.280
We don't want to reset that again, do we?


00:20:54.280 --> 00:20:59.040
- No, well, obviously the numbers on this slide


00:20:59.040 --> 00:21:00.400
are just teasers.


00:21:00.400 --> 00:21:01.780
- Of course.


00:21:01.780 --> 00:21:04.080
- I don't know how to do it.


00:21:04.080 --> 00:21:10.880
I think Mark has a plan, but that doesn't necessarily mean he knows how to do it exactly either.


00:21:10.880 --> 00:21:21.200
The key thing is, and sort of to answer your audience question, without breaking on anybody's code.


00:21:21.200 --> 00:21:31.840
So we're really trying to sort of not have there be any downsides to adopting this new version of Python,


00:21:32.640 --> 00:21:44.400
which is unusual because definitely if you use PiPi, which is I think the only sort of competitor that


00:21:44.400 --> 00:21:58.240
competes on speed that is still alive, and in some use, you pay in terms of how well does it work


00:21:58.240 --> 00:22:04.880
with extension modules. It doesn't work with all extension modules and with some extension modules


00:22:04.880 --> 00:22:14.720
it works but it's slower. There are various limitations and that in particular is something


00:22:14.720 --> 00:22:25.680
that has kept many similar attempts back. If we just give this up we can have x y and z right but


00:22:27.040 --> 00:22:29.040
those turn out to be pretty big compromises.


00:22:29.040 --> 00:22:38.720
Absolutely, and sometimes, I mean quite often extension modules are the issue. Sometimes there are also things where


00:22:38.720 --> 00:22:42.640
Python's runtime semantics are not fully specified.


00:22:42.640 --> 00:22:45.600
It's not defined by the language


00:22:45.600 --> 00:22:52.000
when exactly objects are finalized when they go out of scope.


00:22:54.240 --> 00:23:00.880
In practice, there's a lot of code around there that in very subtle ways depends on CPython's


00:23:00.880 --> 00:23:09.440
finalization semantics based on reference counting. And so anything, and this is also


00:23:09.440 --> 00:23:16.720
something that PyPy learned, and I think, oh, Piston, which is definitely alive and open source.


00:23:16.720 --> 00:23:21.040
You should talk to the Piston guys if you haven't already.


00:23:23.680 --> 00:23:28.000
But their first version, which they developed many years ago with Dropbox,


00:23:28.000 --> 00:23:38.320
suffered from sort of imprecise finalization semantics.


00:23:38.320 --> 00:23:46.960
And they found with sort of early tests on the Dropbox server code that there was too much


00:23:47.760 --> 00:23:56.320
behavior that sort of didn't work right because objects weren't always finalized at the same time


00:23:56.320 --> 00:24:03.600
or sometimes in the same order as they were in standard CPython. Oh, interesting.


00:24:03.600 --> 00:24:09.680
There's no promises about that, right? It just says, well, when you're done with it, it goes away


00:24:09.680 --> 00:24:13.520
pretty much eventually. If it's a reference count, it might go away quickly. If it's


00:24:13.520 --> 00:24:20.480
a cycle it might go way slower. That's correct and unfortunately this is one of those


00:24:20.480 --> 00:24:25.760
sort of unspecified parts of the language where people in practice all depend on


00:24:25.760 --> 00:24:34.720
this or not everybody obviously but many large production code bases do


00:24:34.720 --> 00:24:40.400
end up depending on that. Not sort of intentionally, it's not that a bunch of


00:24:42.800 --> 00:24:45.920
application architects got together and said,


00:24:45.920 --> 00:24:51.600
"We're going to depend on precise finalization based on reference counting."


00:24:51.600 --> 00:25:01.040
It's more that those servers, like the 5 million lines of server code that Dropbox had when I left,


00:25:01.040 --> 00:25:05.840
were written by hundreds of different engineers, some of whom


00:25:05.840 --> 00:25:10.400
wrote only one function or two lines of code, some of whom sort of


00:25:10.400 --> 00:25:17.440
maintained several entire subsystems for years but sort of collectively it's a very large number


00:25:17.440 --> 00:25:24.000
of people who don't all have the same understanding of how Python works and which part is part of the


00:25:24.000 --> 00:25:30.560
sort of the promises of the language and which is just sort of how the implementation happens to


00:25:30.560 --> 00:25:36.480
work and right some of those are pretty obvious I mean there are some sometimes there are


00:25:36.480 --> 00:25:44.160
functions where the documentation says, well, if you sort of, you can use this, but it's not


00:25:44.160 --> 00:25:50.160
guaranteed that this function exists or that it always behaves the same way. But the sort of


00:25:50.160 --> 00:25:57.840
the finalization behavior is pretty implicit. Yeah, Mark, what are your thoughts here?


00:25:57.840 --> 00:26:02.000
Well, I mean, there's people just expectations is derived from what they use. The trouble with


00:26:02.000 --> 00:26:03.680
The problem with documentation is like instructions,


00:26:03.680 --> 00:26:05.040
they don't always get read.


00:26:05.040 --> 00:26:09.680
And also it's not just finalizations,


00:26:09.680 --> 00:26:10.960
it's also reclaiming memory.


00:26:10.960 --> 00:26:15.960
So anything that has different memory management system


00:26:15.960 --> 00:26:19.480
might just need more memory.


00:26:19.480 --> 00:26:21.120
Reference counting is pretty good


00:26:21.120 --> 00:26:22.400
at reclaiming memory quickly


00:26:22.400 --> 00:26:26.280
and will run near the limit of what you have available.


00:26:26.280 --> 00:26:30.040
Whereas a sort of more tracing garbage collector like PyPy


00:26:30.040 --> 00:26:32.040
doesn't always work so well like that.


00:26:32.040 --> 00:26:34.800
I mean, one thing we are gonna change


00:26:34.800 --> 00:26:36.320
is the performance characteristics.


00:26:36.320 --> 00:26:38.080
Now that should generally be a good thing,


00:26:38.080 --> 00:26:40.480
but there may be people who rely


00:26:40.480 --> 00:26:43.240
on more consistent performance.


00:26:43.240 --> 00:26:47.000
- You may end up unearthing race conditions,


00:26:47.000 --> 00:26:49.280
potentially that no one really knew was there.


00:26:49.280 --> 00:26:51.960
I mean, but I would not blame you for making Python faster


00:26:51.960 --> 00:26:56.440
and people who write bad, poorly thread-safe code


00:26:56.440 --> 00:26:57.440
fall into some trap there.


00:26:57.440 --> 00:26:58.400
But I guess that, you know,


00:26:58.400 --> 00:27:01.400
There's even those kinds of unintended consequences, I guess.


00:27:01.400 --> 00:27:04.400
That one sounds like pretty low risk, to be honest.


00:27:04.400 --> 00:27:05.400
Yeah.


00:27:05.400 --> 00:27:10.400
Yeah, I mean, also the warm-up time.


00:27:10.400 --> 00:27:11.400
We'll get a warm-up time.


00:27:11.400 --> 00:27:14.400
Now, what will happen is, of course, it's just getting faster,


00:27:14.400 --> 00:27:17.400
so it's no slower to start with, but it still has the perception


00:27:17.400 --> 00:27:20.400
that it now takes a while to get up to speed, whereas previously


00:27:20.400 --> 00:27:24.400
it used to get up to speed very quickly because it didn't really get up to speed.


00:27:24.400 --> 00:27:28.400
but it stayed the same speed.


00:27:28.400 --> 00:27:32.400
But these are subtle things, but they're detectable changes that people may notice.


00:27:32.400 --> 00:27:40.400
There are also, like any optimizer,


00:27:40.400 --> 00:27:46.400
there are certain situations where the optimization doesn't really work.


00:27:46.400 --> 00:27:52.400
It's not necessarily a pessimization, but somehow it's not any faster than previous versions.


00:27:52.400 --> 00:27:56.800
while other similar code may run much faster.


00:27:56.800 --> 00:28:01.380
And so you have this strange effect that


00:28:01.380 --> 00:28:07.000
you make a small tweak to your code,


00:28:07.000 --> 00:28:10.720
which you think should not affect performance at all.


00:28:10.720 --> 00:28:15.720
Or you're not sort of aware that suddenly you've made


00:28:15.720 --> 00:28:18.220
that part of your code 20% slower.


00:28:20.640 --> 00:28:21.480
- Yeah.


00:28:21.480 --> 00:28:23.440
- It's just gonna be so different.


00:28:23.440 --> 00:28:24.920
- It is one of our design goals


00:28:24.920 --> 00:28:28.240
not to have these surprising sort of performance edges,


00:28:28.240 --> 00:28:30.020
but yeah, there's a lot of cases


00:28:30.020 --> 00:28:31.880
where it will definitely make a difference


00:28:31.880 --> 00:28:33.640
and things will get a bit slower.


00:28:33.640 --> 00:28:35.920
- Yeah, there are very subtle things


00:28:35.920 --> 00:28:39.000
that can have huge performance differences


00:28:39.000 --> 00:28:41.680
that I think people who are newer to Python run into,


00:28:41.680 --> 00:28:44.940
like, oh, I see you can do this comprehension.


00:28:44.940 --> 00:28:47.560
And I had square brackets, but I saw they had parentheses.


00:28:47.560 --> 00:28:48.920
So that's the same thing, right?


00:28:48.920 --> 00:28:52.800
Well, not so much, not so much.


00:28:52.800 --> 00:28:54.280
Not if it's a million lines of code


00:28:54.280 --> 00:28:55.640
or a million lines of data.


00:28:55.640 --> 00:28:59.480
All right, so I think, yeah,


00:28:59.480 --> 00:29:01.900
that's a great way to think about it.


00:29:01.900 --> 00:29:04.840
Not making it break a lot of code is,


00:29:04.840 --> 00:29:08.080
I think, as much as it's exciting to think


00:29:08.080 --> 00:29:09.500
about completely reinventing it,


00:29:09.500 --> 00:29:13.280
it's super important that we just have a lot of consistency


00:29:13.280 --> 00:29:15.000
now that we've kind of just moved beyond


00:29:15.000 --> 00:29:17.360
the Python two versus three type of thing.


00:29:18.360 --> 00:29:23.080
I think also it's worth mentioning, Guido, you gave a shout out to Sam Gross's proposal.


00:29:23.080 --> 00:29:26.760
The stuff you're doing is not Sam Gross's proposal.


00:29:26.760 --> 00:29:30.920
It's not about, even from what I can see from the outside, that much about threading.


00:29:30.920 --> 00:29:36.520
It's more about how do I make just the fundamental stuff of Python go faster. Is that right?


00:29:36.520 --> 00:29:42.760
That's right. These are like completely sort of different developments.


00:29:43.800 --> 00:29:49.360
When we started this, we didn't actually know Sam or that there was anyone who was working


00:29:49.360 --> 00:29:50.880
on something like that.


00:29:50.880 --> 00:29:58.400
But there had been previous attempts to remove the gill, which is what Sam has done.


00:29:58.400 --> 00:30:04.800
And the most recent one of those was by Larry Hastings, who came up with a great name, the


00:30:04.800 --> 00:30:05.800
Galectomy.


00:30:05.800 --> 00:30:08.240
That's a fantastic name, yeah.


00:30:08.240 --> 00:30:22.080
a lot of time in it, but in the end I think he had to give up because the baseline performance


00:30:22.080 --> 00:30:30.560
was just significantly slower than Vanilla Interpreter. And I believe it also didn't


00:30:30.560 --> 00:30:38.160
scale all that well, although I don't remember whether it sort of stopped scaling at 5 or 10


00:30:38.160 --> 00:30:47.040
or 20 cores. But right, yeah, claims that he's sort of got the baseline performance, I think,


00:30:47.040 --> 00:30:58.160
within 10% or so often a lot three dot nine, which is what he's worked off. Right. And he also claims


00:30:58.160 --> 00:31:03.680
that he has a very scalable solution. And he obviously put much more effort in it,


00:31:03.680 --> 00:31:11.200
much more time in it than Larry ever had. Yeah, it sounds like Facebook is putting some effort into


00:31:11.200 --> 00:31:17.600
funding his work on that, which is great. Yeah, but but I it feels like a very sort of


00:31:17.600 --> 00:31:25.440
bottom up project. It feels like Yeah. Sam thought that that this was an interesting challenge. And


00:31:25.440 --> 00:31:31.760
he sort of convinced himself that he could do it and he sort of gradually worked on all the


00:31:31.760 --> 00:31:39.440
different problems that he encountered on the way and he convinced his manager that this was a good


00:31:39.440 --> 00:31:47.520
use of his time. It's my theory because that's usually how these projects go but you always


00:31:47.520 --> 00:31:55.040
never have management say oh we gotta fund an engineer to make faster or make a multi-core


00:31:55.040 --> 00:31:58.000
or whatever, find a good engineer.


00:31:58.000 --> 00:32:00.920
- It's probably like that Dropbox story you told.


00:32:00.920 --> 00:32:05.320
We have all these servers, there's a lot to maintain.


00:32:05.320 --> 00:32:07.160
Hey, what if we could have fewer of them?


00:32:07.160 --> 00:32:09.160
What if we could do better?


00:32:09.160 --> 00:32:12.640
That's something a manager that could totally get behind.


00:32:12.640 --> 00:32:16.520
All right, so you all are adopting what I see


00:32:16.520 --> 00:32:19.320
as going as the Shannon plan, as in Mark Shannon,


00:32:19.320 --> 00:32:21.300
the guest in the top left here.


00:32:21.300 --> 00:32:22.560
That's fantastic.


00:32:22.560 --> 00:32:24.900
I remember talking about this as well,


00:32:24.900 --> 00:32:27.440
that you had posted this thing,


00:32:27.440 --> 00:32:28.680
when was this back?


00:32:28.680 --> 00:32:29.680
A little over a year ago,


00:32:29.680 --> 00:32:32.360
so interesting time in there, right?


00:32:32.360 --> 00:32:35.520
You had talked about making Python faster


00:32:35.520 --> 00:32:38.400
over the next four releases by a factor of five,


00:32:38.400 --> 00:32:39.480
which is pretty awesome.


00:32:39.480 --> 00:32:42.040
And you have a concrete plan to sort of


00:32:42.040 --> 00:32:46.280
make changes along each yearly release


00:32:46.280 --> 00:32:47.800
to add a little bit of performance


00:32:47.800 --> 00:32:49.940
because of geometric growth,


00:32:49.940 --> 00:32:51.840
make it quite a bit faster over time.


00:32:51.840 --> 00:32:54.840
[silence]


00:32:54.840 --> 00:32:58.480
Yeah. So, do you want me to run through these?


00:32:58.480 --> 00:33:00.480
Yeah, yeah. Tell us about your plan.


00:33:00.480 --> 00:33:02.980
You've got four stages, and maybe we could talk through each stage


00:33:02.980 --> 00:33:04.980
and focus on some of the tech there.


00:33:04.980 --> 00:33:07.980
The way we're implementing it is now


00:33:07.980 --> 00:33:09.980
kind of a bit of a jumble of stage one and two.


00:33:09.980 --> 00:33:11.980
But the basic idea is that


00:33:11.980 --> 00:33:16.480
dynamic languages, the key performance improvement


00:33:16.480 --> 00:33:18.480
is always based on specialization.


00:33:18.480 --> 00:33:28.560
obviously, most of the time the code does mostly the same thing as it did last time. And even in


00:33:28.560 --> 00:33:35.920
non-loopy code, a web server, there's still a big loop level, a request response level.


00:33:35.920 --> 00:33:40.320
So you're still hitting the same code, and those codes are doing much the same thing. And the idea


00:33:40.320 --> 00:33:47.600
is that you multiply the code so it works for those particular cases, so you should specialize


00:33:47.600 --> 00:33:52.800
it. So the obvious sort of simple stuff is, you know, like binary arithmetic and you have


00:33:52.800 --> 00:33:56.920
a special version of adding integers and a special version for floats. Obviously Python


00:33:56.920 --> 00:34:01.120
is much more special versions for different calling, different things and different attributes


00:34:01.120 --> 00:34:07.560
and all this sort of stuff. And that's the sort of the key first stage. I mean, that's


00:34:07.560 --> 00:34:13.240
mixed in with the second stage, which is really much more to just doing lots and lots of little


00:34:13.240 --> 00:34:21.160
bits and tweaks and memory layout. So that's to do better memory layout. You know, modern CPUs


00:34:21.160 --> 00:34:26.840
are, you know, extremely efficient, but they still have to fetch from, you know, speed light issues


00:34:26.840 --> 00:34:32.120
with fetching stuff from memory. So, you know, how things are laid out in memory is key performance.


00:34:32.120 --> 00:34:39.000
And it's sort of just those sort of little bits and tweaks here and just kind of writing the code


00:34:39.000 --> 00:34:42.360
as we would have if it had been written for speed in the first place. So a lot of those, you know,


00:34:42.360 --> 00:34:46.460
you know, CPython is old and it's just sort of evolved.


00:34:46.460 --> 00:34:49.080
And a lot of it has, there's lots of potential


00:34:49.080 --> 00:34:51.680
for just sort of rearranging data structures


00:34:51.680 --> 00:34:54.180
and rearranging the code and so on.


00:34:54.180 --> 00:34:56.540
And these all add up, you know, a few percent here,


00:34:56.540 --> 00:34:57.380
a few percent there.


00:34:57.380 --> 00:35:01.620
And it doesn't take many of those to get a decent speed up.


00:35:01.620 --> 00:35:03.400
So that's the sort of first two stages.


00:35:03.400 --> 00:35:06.000
And as those ones where we have some pretty concrete idea


00:35:06.000 --> 00:35:07.180
of what we're doing.


00:35:07.180 --> 00:35:08.240
- Right, and this is the kind of stuff


00:35:08.240 --> 00:35:09.760
that will benefit everybody, right?


00:35:09.760 --> 00:35:10.880
We all use numbers.


00:35:10.880 --> 00:35:14.000
We all do comparisons, we all do addition,


00:35:14.000 --> 00:35:15.320
call functions and so on.


00:35:15.320 --> 00:35:17.600
- Yeah, I mean, the way we're sort of trending


00:35:17.600 --> 00:35:19.960
with performance in the moment is that sort of,


00:35:19.960 --> 00:35:23.120
you know, sort of webby type code,


00:35:23.120 --> 00:35:24.960
but web backend sort of code,


00:35:24.960 --> 00:35:27.720
you'd be looking at kind of where we are now,


00:35:27.720 --> 00:35:30.040
I'd know it's a 25, 30% speed up.


00:35:30.040 --> 00:35:32.080
Whereas if it's a machine learning,


00:35:32.080 --> 00:35:33.400
a sort of numerical code,


00:35:33.400 --> 00:35:36.480
it's more likely to be sort of 10% region.


00:35:36.480 --> 00:35:38.840
Obviously we'd hope to push both up,


00:35:38.840 --> 00:35:42.720
and, but we're more, I don't think we're particularly


00:35:42.720 --> 00:35:45.920
focused on either, it's just often the case of where,


00:35:45.920 --> 00:35:47.520
you know, the next sort of obvious


00:35:47.520 --> 00:35:50.120
sort of convenient speed up lies.


00:35:50.120 --> 00:35:54.200
And although everyone talks about speed ups


00:35:54.200 --> 00:35:55.840
and I've been doing the same myself,


00:35:55.840 --> 00:35:57.000
I mean, it's best to think of really


00:35:57.000 --> 00:35:59.340
at the time something takes to execute.


00:35:59.340 --> 00:36:02.180
So it's often to shaving off 1% of the time


00:36:02.180 --> 00:36:04.480
rather than speeding up by 1%.


00:36:04.480 --> 00:36:09.120
And because, obviously, as the overall runtime shrinks,


00:36:09.120 --> 00:36:11.920
what were marginal improvements become more valuable.


00:36:11.920 --> 00:36:15.440
Shaving off 0.2% might be not worth it now,


00:36:15.440 --> 00:36:17.760
but once you sped something up by a factor of three or four,


00:36:17.760 --> 00:36:19.760
then that suddenly becomes a percent


00:36:19.760 --> 00:36:22.480
and it's worth the effort sort of thing.


00:36:22.480 --> 00:36:23.320
- Right, absolutely.


00:36:23.320 --> 00:36:26.640
Once addition becomes that much faster,


00:36:26.640 --> 00:36:29.780
then it makes a big knock on effect.


00:36:29.780 --> 00:36:32.600
- Yeah, which leads on to stages three and four.


00:36:32.600 --> 00:36:35.240
So, just-in-time compilation has always hailed


00:36:35.240 --> 00:36:38.040
as the way to speed up interpreted languages.


00:36:38.040 --> 00:36:39.120
- Now, before you move on,


00:36:39.120 --> 00:36:41.640
let me just sort of list out what you have on stage two


00:36:41.640 --> 00:36:43.280
for people who haven't dove into this,


00:36:43.280 --> 00:36:46.720
because I think some of the concrete details,


00:36:46.720 --> 00:36:48.680
people hear this in the abstract,


00:36:48.680 --> 00:36:49.520
they kind of want to know,


00:36:49.520 --> 00:36:51.720
okay, well, what actually are some of the things


00:36:51.720 --> 00:36:52.640
you all are considering?


00:36:52.640 --> 00:36:55.160
So, improved performance for integers


00:36:55.160 --> 00:36:57.600
less than one machine word.


00:36:57.600 --> 00:37:00.240
It's been a long time since I've done C++.


00:37:00.240 --> 00:37:02.360
Is a word two bytes, how big is a word?


00:37:02.360 --> 00:37:04.200
- Well, word is how big depends on the machine.


00:37:04.200 --> 00:37:07.240
So that'd be 64 bits for pretty much anything now.


00:37:07.240 --> 00:37:10.320
Apart from like a little tiny embedded systems,


00:37:10.320 --> 00:37:11.880
which is 32 still.


00:37:11.880 --> 00:37:13.720
- So that's a lot of numbers, right?


00:37:13.720 --> 00:37:15.940
That's many of the numbers you work with


00:37:15.940 --> 00:37:18.000
are less than 2 billion or whatever that is.


00:37:18.000 --> 00:37:20.320
- Yeah, basically there are two types of integers.


00:37:20.320 --> 00:37:23.240
There's the big ones that are used for cryptography


00:37:23.240 --> 00:37:24.840
and other such things,


00:37:24.840 --> 00:37:28.200
where it's a number in a sort of mathematical sense,


00:37:28.200 --> 00:37:30.560
but it's really sort of some elaborate code.


00:37:30.560 --> 00:37:32.400
And then there's numbers that actually represent


00:37:32.400 --> 00:37:33.920
the number of things or the number of times


00:37:33.920 --> 00:37:35.120
you're going to do something.


00:37:35.120 --> 00:37:38.800
And those are all relatively tiny and they'll all fit.


00:37:38.800 --> 00:37:43.800
So, but the long ones used for cryptography


00:37:43.800 --> 00:37:46.880
and so on are relatively rare and they're quite expensive.


00:37:46.880 --> 00:37:48.840
So it's the other ones we want to optimize for


00:37:48.840 --> 00:37:51.040
because when you see an integer,


00:37:51.040 --> 00:37:52.440
that's the integers you get.


00:37:52.440 --> 00:37:55.080
They aren't in the quadrillion range,


00:37:55.080 --> 00:37:56.800
they're in the thousands.


00:37:56.800 --> 00:37:58.160
- Right, right, exactly.


00:37:58.160 --> 00:38:01.680
a loop index or an array index or something.


00:38:01.680 --> 00:38:05.680
Some languages, one that I'm thinking of


00:38:05.680 --> 00:38:09.520
that also maybe is kind of close to where Guido is right now


00:38:09.520 --> 00:38:12.360
also in Microsoft space is C#,


00:38:12.360 --> 00:38:16.400
which treats integers sometimes as value types


00:38:16.400 --> 00:38:18.500
and sometimes as reference types.


00:38:18.500 --> 00:38:21.580
So that when you're doing like loops and other stuff,


00:38:21.580 --> 00:38:25.600
they operate more like C++ numbers


00:38:25.600 --> 00:38:30.400
less like pi, you know, pointers to pi long objects.


00:38:30.400 --> 00:38:32.000
Have you considered any of that kind of stuff?


00:38:32.000 --> 00:38:33.600
Is that what you're thinking?


00:38:33.600 --> 00:38:36.080
- Yeah, well, an obvious thing,


00:38:36.080 --> 00:38:40.480
an old thing as well, is to have tagged integers.


00:38:40.480 --> 00:38:42.400
So basically, you know,


00:38:42.400 --> 00:38:44.160
where we would normally have a pointer,


00:38:44.160 --> 00:38:46.240
we've got a whole bunch of zeros at the end.


00:38:46.240 --> 00:38:49.360
64 bits, a machine is three,


00:38:49.360 --> 00:38:50.480
and then for alignment,


00:38:50.480 --> 00:38:52.960
there's effectively four zeros at the end.


00:38:52.960 --> 00:38:59.680
So we're using a sixteenth of the possible numbers that a pointer could hold, four pointers,


00:38:59.680 --> 00:39:04.800
which means leaves a bunch of integers and floating point numbers. So there's a number of


00:39:04.800 --> 00:39:10.880
what's called tagging schemes. For example, LuaJIT, which is a very fast implementation of Lua, uses


00:39:10.880 --> 00:39:16.080
what's called NAND boxing, which is everything's a floating point number, but there is sufficiently


00:39:16.080 --> 00:39:20.720
something like two to the 53, which is a huge number of not a numbers in the floating point


00:39:20.720 --> 00:39:24.320
range so you could use a lot of those for integers or


00:39:24.320 --> 00:39:27.680
pointers. Now that's a little problematic with 64-bit pointers because obviously


00:39:27.680 --> 00:39:33.280
64 bits is bigger than 53. But there are other schemes where you


00:39:33.280 --> 00:39:37.360
so again a simple scheme is that basically the


00:39:37.360 --> 00:39:42.160
least significant bit is one for pointers and zero for integers or vice


00:39:42.160 --> 00:39:46.720
versa. And that basically just gives you


00:39:46.720 --> 00:39:49.920
full machine performance for integers because


00:39:49.920 --> 00:39:55.680
there's just basically anything up to 63 bits fits in a 64-bit integer and that's basically all of


00:39:55.680 --> 00:40:02.000
your numbers. And because it's shifted across all the machine arithmetic works as normal and


00:40:02.000 --> 00:40:06.640
overflows, you just overflow checks a machine, a single machine instruction and things like this.


00:40:06.640 --> 00:40:12.880
And that's again pretty standard in any sort of like fast Lisp implementation


00:40:14.160 --> 00:40:19.160
and older small talk and other sort of historical languages.


00:40:19.160 --> 00:40:24.320
JavaScript tends to use things like this NAND boxing


00:40:24.320 --> 00:40:26.640
I was talking about because all of the numbers


00:40:26.640 --> 00:40:28.240
are floating point numbers.


00:40:28.240 --> 00:40:29.080
- Right.


00:40:29.080 --> 00:40:33.440
So another one that stands out here


00:40:33.440 --> 00:40:35.840
is zero overhead exception handling.


00:40:35.840 --> 00:40:38.480
Guido, that's making it into 3.11 already, right?


00:40:38.480 --> 00:40:41.280
- Mark, didn't that?


00:40:41.280 --> 00:40:42.400
- Yes, yeah, that is.


00:40:42.400 --> 00:40:47.320
So that's basically just what we used to have


00:40:47.320 --> 00:40:50.520
is we'd have a little setup and sort of tear down


00:40:50.520 --> 00:40:53.200
except instruction for every time we wanted


00:40:53.200 --> 00:40:56.280
to sort of controlled block of code inside a try,


00:40:56.280 --> 00:40:58.640
as you try finally, but also with statements.


00:40:58.640 --> 00:41:02.600
But we've ditched those in favor of just a table lookup.


00:41:02.600 --> 00:41:03.760
So if there's an exception now,


00:41:03.760 --> 00:41:04.760
it's just looked up in a table,


00:41:04.760 --> 00:41:07.700
which is what the JVM Java virtual machine does.


00:41:07.700 --> 00:41:10.280
- Yeah, excellent.


00:41:10.280 --> 00:41:15.880
ZeroVerhead is a slightly optimistic term. It's obviously not zero overhead, but it is less


00:41:15.880 --> 00:41:20.920
You'll have a harder time finding it in the profiler. There's a little bit of memory


00:41:20.920 --> 00:41:24.120
that you didn't have before


00:41:24.120 --> 00:41:26.520
that's a lookup table, but


00:41:26.520 --> 00:41:30.840
it really is zero overhead if no exceptions happen, right?


00:41:30.840 --> 00:41:34.280
Not quite


00:41:34.280 --> 00:41:39.080
Just because there is extra memories that causes other things but also


00:41:39.960 --> 00:41:44.080
In all because of like tracing guarantees,


00:41:44.080 --> 00:41:47.200
sometimes we have to insert a NOP where the try was.


00:41:47.200 --> 00:41:50.440
So there's still some slight overhead.


00:41:50.440 --> 00:41:52.480
Then potentially in future when we compile code,


00:41:52.480 --> 00:41:55.040
that should effectively become zero though.


00:41:55.040 --> 00:41:56.440
But it's definitely reduced.


00:41:56.440 --> 00:42:01.160
- Mark, Apple surprised the world


00:42:01.160 --> 00:42:03.080
and they took their phone chips


00:42:03.080 --> 00:42:05.000
and turned them into desktop chips.


00:42:05.000 --> 00:42:07.200
And that seemed to actually work pretty well


00:42:07.200 --> 00:42:08.760
with their ARM stuff.


00:42:08.760 --> 00:42:15.720
Does the switch, not just having basically just x86 and 64-bit stuff to think about,


00:42:15.720 --> 00:42:18.840
but now you also have this ARM stuff, does that make life harder or easier?


00:42:18.840 --> 00:42:22.360
Does it open up possibilities or is it another thing to deal with?


00:42:22.360 --> 00:42:24.760
It's just harder because it's...


00:42:24.760 --> 00:42:27.400
But I mean, we were never excluding those anyway.


00:42:27.400 --> 00:42:34.760
So, and we may want to look to the future of sort of RISC-V and, you know, it's...


00:42:34.760 --> 00:42:41.000
So currently CPython is portable. That's a key thing. Portability is,


00:42:41.000 --> 00:42:47.880
you know, it rather depends on testing. It's all very well saying it's perfectly portable, but


00:42:47.880 --> 00:42:52.600
if you have never tested on a platform, you may have surprises. But it's all written in C,


00:42:52.600 --> 00:42:58.840
and portability is a sort of serious consideration. So, I mean, things like those tagging I was just


00:42:58.840 --> 00:43:04.280
talking about, that's technically not portable C, but it's technically, I mean, a lot of things


00:43:04.280 --> 00:43:09.640
aren't technically portable C, but in effect are. I mean, technically it's impossible to write a


00:43:09.640 --> 00:43:14.680
memory allocator in C because the specification says once you've called free you can't access


00:43:14.680 --> 00:43:18.600
the memory, which makes it kind of difficult to write something that handles the memory.


00:43:18.600 --> 00:43:25.880
But you know, these are oddities, but in practice, you know, if you write sensible C code,


00:43:25.880 --> 00:43:33.240
it you should expect to be portable. So we are kind of basing around that. I mean, like some other


00:43:33.960 --> 00:43:37.640
virtual machines, particularly the JavaScript ones, are effectively written,


00:43:37.640 --> 00:43:40.680
their interpreters are often written in Assembler or some variant of it.


00:43:40.680 --> 00:43:45.720
There's definitely a performance advantage in that, but I'm not convinced it's great enough


00:43:45.720 --> 00:43:50.520
to lose the portability and the maintenance overhead.


00:43:50.520 --> 00:43:55.160
Yeah, and one of the things that you focused on, Guido, was that you wanted this to be,


00:43:55.160 --> 00:43:59.560
to keep, one of the constraints is you said you want to keep the code maintainable,


00:43:59.560 --> 00:44:06.040
Right? This is important. Why does that matter so much rather than if we can get 20% speed up if Mark


00:44:06.040 --> 00:44:15.000
refreshes his assembly language skills? Well, it would leave most of the core development team


00:44:15.000 --> 00:44:25.400
behind. And so suddenly, Mark would be very, very valuable contributor because he's the only one who


00:44:25.400 --> 00:44:28.600
understands that assembly code that's just how it goes.


00:44:28.600 --> 00:44:29.100
Yeah.


00:44:29.100 --> 00:44:35.480
And I don't think that that would be healthy for the Python ecosystem.


00:44:35.480 --> 00:44:43.960
If the technology we used was so hard to understand and so hard to learn,


00:44:43.960 --> 00:44:48.760
making it so hard to maintain,


00:44:50.600 --> 00:44:58.680
then as an open source project we would lose velocity.


00:44:58.680 --> 00:45:10.360
The only thing that that would cause to happen in the core team might be people decide


00:45:10.360 --> 00:45:18.280
to move more code to Python code because now the interpreter is faster anyway so they can


00:45:18.280 --> 00:45:23.960
sort of they don't have to write so much in C code, but then of course, likely it's actually


00:45:23.960 --> 00:45:28.920
going to be slower, at least that's that particular bit of code. That's an interesting intention to


00:45:28.920 --> 00:45:34.040
think about if you could make the interpreter dramatically faster, you could actually do more


00:45:34.040 --> 00:45:41.240
Python and less C. I don't know, it would have to be there's some big number where that happens,


00:45:41.240 --> 00:45:43.560
right? It's not just a 10%, but maybe.


00:45:43.560 --> 00:45:53.080
That could be in the distant future, but nevertheless, I wouldn't want the C code


00:45:53.080 --> 00:45:59.080
to be unreadable for most of the core developers.


00:45:59.080 --> 00:46:00.760
Yeah, I agree. That makes a lot of sense.


00:46:00.760 --> 00:46:06.680
So, being a C expert is not a requirement for being a core developer. In practice,


00:46:06.680 --> 00:46:13.800
quite a few of the core developers are really good C coders and we sort of we support each


00:46:13.800 --> 00:46:20.200
other in that we have we sort of we take pride in it and we help each other out. I mean code


00:46:20.200 --> 00:46:28.280
reviews are incredibly important and we will happily help newbies to sort of get up to speed


00:46:28.280 --> 00:46:34.360
with C. But if we if we had a considerable portion that was written in Assembler


00:46:35.480 --> 00:46:41.000
And then it would have to be written in sort of multiple assemblers,


00:46:41.000 --> 00:46:48.120
or there would also have to be a C version for platforms where we don't even have


00:46:48.120 --> 00:46:52.360
access to the assembler or nobody has bothered to write that assembler code yet.


00:46:52.360 --> 00:46:57.640
All these things make things even more complicated than they already are.


00:46:57.640 --> 00:47:04.600
Right, and the portability and the approachability of it is certainly a huge benefit.


00:47:04.600 --> 00:47:14.200
Two other constraints that you had here, maybe you could just elaborate on real quick, is don't break stable ABI compatibility and don't break limited API compatibility.


00:47:14.200 --> 00:47:29.800
Yeah, so the ABI, the stable ABI is the application binary interface, and that guarantees that extension modules that use a limited set of CAPI functions


00:47:29.800 --> 00:47:34.600
don't have to be recompiled for each new Python version.


00:47:34.600 --> 00:47:40.000
And so you can in theory have a wheel containing binary code


00:47:40.000 --> 00:47:44.600
and that binary code it will still be platform specific


00:47:44.600 --> 00:47:47.600
but it won't be Python version specific.


00:47:47.600 --> 00:47:50.600
Right. Okay. Yeah, that's very nice.


00:47:50.600 --> 00:47:54.200
That's sort of that we don't want to break that.


00:47:54.200 --> 00:47:58.600
It is a terrible constraint because it means we can't move


00:47:58.600 --> 00:48:03.160
fields like the reference count or the type field around in the object.


00:48:03.160 --> 00:48:09.640
And many, many other things as well. But it nevertheless, it is an important property because


00:48:09.640 --> 00:48:14.600
people depend on that. Sure. And the API compatibility. Well, that's pretty clear.


00:48:14.600 --> 00:48:21.880
You don't want people to have to rewrite. Yeah, the limited API is also the limited API is sort of


00:48:21.880 --> 00:48:26.600
the compile time version of the stable ABI. I think it's the same set of functions,


00:48:26.600 --> 00:48:37.400
except the stable ABI actually means that you don't have to recompile. The limited API


00:48:37.400 --> 00:48:48.440
offers the same and I think a slightly larger set of API functions, where if you do recompile,


00:48:49.000 --> 00:48:57.160
you're guaranteed to get the same behavior. And again, our API is pretty large


00:48:57.160 --> 00:49:04.360
and a few things have snuck into the limited API and the stable ABI that are


00:49:04.360 --> 00:49:10.680
actually difficult to maintain and that are


00:49:12.920 --> 00:49:20.840
difficult to support with changes that we want to make. And so sometimes this holds us back,


00:49:20.840 --> 00:49:25.960
but at the same time we don't want to break the promises that were made to the Python community


00:49:25.960 --> 00:49:34.360
about API compatibility. We don't want to say, "Oh sorry folks, we made everything 20% faster,


00:49:34.360 --> 00:49:42.200
but alas you're going to have to use a new API and all your extensions. Just recompiling isn't


00:49:42.200 --> 00:49:49.240
going to be good enough, some functions suddenly have three arguments instead of two, or no longer


00:49:49.240 --> 00:49:59.080
exists, or return memory that you own instead of returning a borrowed reference. And we don't want


00:49:59.080 --> 00:50:05.640
to do any of those things because that just would break the entire ecosystem in a way that


00:50:05.640 --> 00:50:11.640
would be as bad as the Python 3 transition. Right, and it's just not worth it.


00:50:11.640 --> 00:50:16.240
- All right, let's go back to the Shannon plan.


00:50:16.240 --> 00:50:19.740
So we talked about stage one and stage two.


00:50:19.740 --> 00:50:23.740
Mark, I see here, this is Python 3.10 and Python 3.11.


00:50:23.740 --> 00:50:24.960
Is that, are those the numbers


00:50:24.960 --> 00:50:26.040
where they're actually gonna make it in?


00:50:26.040 --> 00:50:29.400
Or is it, do we have to do like a plus plus or plus equal?


00:50:29.400 --> 00:50:32.720
- I think a plus one would be appropriate.


00:50:32.720 --> 00:50:34.160
- All right, plus equals one.


00:50:34.160 --> 00:50:39.560
- Yeah, so, I mean, maybe we're a bit faster


00:50:39.560 --> 00:50:43.080
because obviously I envisioned this was basically me


00:50:43.080 --> 00:50:44.860
and one other developer,


00:50:44.860 --> 00:50:50.720
plus maybe sort of some sort of reasonable buy-in


00:50:50.720 --> 00:50:53.420
from the wider core development team.


00:50:53.420 --> 00:50:54.920
So it wasn't sort of doing the work


00:50:54.920 --> 00:50:56.640
sort of entirely in isolation or,


00:50:56.640 --> 00:51:01.680
but yeah, it was still having extra hands


00:51:01.680 --> 00:51:03.720
will definitely help things.


00:51:03.720 --> 00:51:04.560
- Sure.


00:51:04.560 --> 00:51:06.720
So back when you were thinking,


00:51:06.720 --> 00:51:09.400
this was written at the 3.9 timeframe, right?


00:51:09.400 --> 00:51:10.600
and you're like, okay, well, the next version,


00:51:10.600 --> 00:51:12.080
maybe we can do this, the version after that.


00:51:12.080 --> 00:51:13.600
And by the time it really got going,


00:51:13.600 --> 00:51:16.800
it's more like 3.11, 3.12 and so on, right?


00:51:16.800 --> 00:51:17.960
- Yeah, it's just around the time,


00:51:17.960 --> 00:51:20.240
I think we switched from 3.9 to 3.10 development,


00:51:20.240 --> 00:51:22.240
I think I was sort of thinking this joke.


00:51:22.240 --> 00:51:27.480
- Okay, so stage three out of the four stages you have


00:51:27.480 --> 00:51:31.480
is I guess Python 3.13 now,


00:51:31.480 --> 00:51:35.300
which is a miniature JIT compiler.


00:51:35.300 --> 00:51:38.680
Is that a right characterization?


00:51:38.680 --> 00:51:40.680
I think that's not the compiler that's,


00:51:40.680 --> 00:51:43.240
well, I suppose it will be smaller, but the--


00:51:43.240 --> 00:51:45.720
- Maybe the parts it applies to,


00:51:45.720 --> 00:51:46.560
the parts that get compiled.


00:51:46.560 --> 00:51:49.040
- Yeah, so-- - It's more, I'm trying to say.


00:51:49.040 --> 00:51:53.360
- I think the idea is that you want to compile


00:51:53.360 --> 00:51:55.960
all of the code where it's sort of performance matters


00:51:55.960 --> 00:51:57.660
that it's sort of hot code.


00:51:57.660 --> 00:52:02.040
But it makes life easier


00:52:02.040 --> 00:52:04.360
if you just compile little chunks of code


00:52:04.360 --> 00:52:07.440
and sort of stitch them together afterwards,


00:52:07.440 --> 00:52:09.640
because it's very easy to fall back into the interpreter


00:52:09.640 --> 00:52:12.960
and for the interpreter to jump into sort of compiled code.


00:52:12.960 --> 00:52:15.720
And you can sort of just hang these bits of compiled code


00:52:15.720 --> 00:52:19.680
off by individual byte codes where they sort of start from.


00:52:19.680 --> 00:52:24.000
Obviously that's not fantastic for performance


00:52:24.000 --> 00:52:25.840
because you're having to fall back into interpreter


00:52:25.840 --> 00:52:30.840
which limits your ability to infer things


00:52:30.840 --> 00:52:32.600
about the state of things.


00:52:32.600 --> 00:52:35.720
So obviously if you've said earlier,


00:52:35.720 --> 00:52:38.680
specialization, you have to do a lot of type checks and other sort of checks.


00:52:38.680 --> 00:52:42.440
If you've done a whole bunch of checks, if you then fall back into the interpreter, you


00:52:42.440 --> 00:52:43.920
have to throw away all that information.


00:52:43.920 --> 00:52:50.160
If you compile a bigger region of code, which is of the stage four, then you've already


00:52:50.160 --> 00:52:53.800
know something about the code and you can sort of apply those compilations.


00:52:53.800 --> 00:53:00.360
The problem with trying to do big regions up front is that if you choose poorly, you


00:53:00.360 --> 00:53:03.920
can make performance worse.


00:53:03.920 --> 00:53:08.080
This is a real issue for, well, existing ones.


00:53:08.080 --> 00:53:10.480
I think we're gonna talk about some of the other


00:53:10.480 --> 00:53:12.520
historical sort of compilers in the past,


00:53:12.520 --> 00:53:14.920
and that this is a real issue for those,


00:53:14.920 --> 00:53:17.520
that they're just trying to compile a method at a time,


00:53:17.520 --> 00:53:21.360
regardless of whether that is a sensible unit to compile.


00:53:21.360 --> 00:53:24.560
- Right, it's sometimes hard to do optimizations


00:53:24.560 --> 00:53:25.920
when it's too small, right?


00:53:25.920 --> 00:53:28.680
- Yeah, and also it's very expensive


00:53:28.680 --> 00:53:30.240
to do regions that are too big,


00:53:31.200 --> 00:53:33.600
or just in the bounded in the wrong places.


00:53:33.600 --> 00:53:36.760
Okay, yeah, that definitely sounds tricky.


00:53:36.760 --> 00:53:39.760
Guido, there was a question earlier about,


00:53:39.760 --> 00:53:41.920
you know, mypyC work and the mypy stuff,


00:53:41.920 --> 00:53:44.960
and you are really central to that, right?


00:53:44.960 --> 00:53:46.760
Doing a lot of work there.


00:53:46.760 --> 00:53:48.640
How do you, both of you, either of you,


00:53:48.640 --> 00:53:52.360
feel about using type annotations


00:53:52.360 --> 00:53:55.200
as some sort of guide to this compiler?


00:53:55.200 --> 00:53:57.660
For example, Cython lets you say,


00:53:57.660 --> 00:54:00.080
you know, X colon int as a parameter,


00:54:00.080 --> 00:54:03.160
and it'll take that as meaning something


00:54:03.160 --> 00:54:04.760
when you compile with Cython.


00:54:04.760 --> 00:54:07.520
It seems like, you know, Mark is talking about


00:54:07.520 --> 00:54:11.080
knowing the types and guessing them correctly matters


00:54:11.080 --> 00:54:12.520
in terms of what's fast here.


00:54:12.520 --> 00:54:15.720
Is there any thought or appetite


00:54:15.720 --> 00:54:18.360
for using type annotations to mean more than


00:54:18.360 --> 00:54:20.600
static analysis?


00:54:20.600 --> 00:54:24.980
- Well, there, there,


00:54:24.980 --> 00:54:29.440
there is the, I mean, it's a great idea.


00:54:29.440 --> 00:54:36.640
And I think for smaller code bases, something like mypyC will prove to be viable.


00:54:36.640 --> 00:54:48.000
Or for code bases where there is an incredible motivation to make this happen.


00:54:48.000 --> 00:54:52.520
I could see that happen at Instagram, for example.


00:54:54.720 --> 00:55:04.560
But in general, most people haven't annotated their code completely and correctly.


00:55:04.560 --> 00:55:11.200
And so if you were to switch to using something like mypyC,


00:55:11.200 --> 00:55:22.960
you'd find that basically it wouldn't work in a large number of cases.


00:55:22.960 --> 00:55:29.920
and it would basically sort of it would it's a different language and it has different semantics


00:55:29.920 --> 00:55:39.840
and it has sort of different rules and and so you have to write to that. I can see there's a


00:55:39.840 --> 00:55:45.120
big challenge to say hey everybody we can do this great stuff if you type annotate it and only four


00:55:45.120 --> 00:55:51.040
percent of people have properly annotated their code and then there's also the option the possibility


00:55:51.040 --> 00:55:57.360
that it's incorrectly annotated, in which case it probably makes it worse in some way of a crash or


00:55:57.360 --> 00:56:06.800
something. MyPriceC will generally crash if a type is detected that doesn't match the annotation.


00:56:06.800 --> 00:56:16.480
Yeah, so and if you annotate stuff with simple types, you can get quite good speed up. So number


00:56:19.200 --> 00:56:23.520
is generally designed for numerical stuff, but again it's the simple types, integers, floats,


00:56:23.520 --> 00:56:30.400
Cython obviously will do this, Number does it dynamically, Cython statically, and the


00:56:30.400 --> 00:56:36.800
Number model for example is similar to the model that Julia language uses. Essentially you compile


00:56:36.800 --> 00:56:41.920
a method at a time, but you make as many specializations as you need for the particular


00:56:41.920 --> 00:56:49.760
types and I can give very good performance for that sort of numerical code, but the problem is


00:56:49.760 --> 00:56:55.440
that saying something is a particular type doesn't tell you very much about it. It doesn't tell you


00:56:55.440 --> 00:57:00.000
what attributes an instance of it may or may not have. It depends, you know, because you can,


00:57:00.000 --> 00:57:06.800
it's not like Java or C++ where having a particular class means it has those instance


00:57:06.800 --> 00:57:11.920
attributes and they will exist or at least, you know, they'll be there exist in a particular


00:57:11.920 --> 00:57:16.400
place and they can be checked very efficiently because they have dictionary lookup and so on.


00:57:16.400 --> 00:57:22.080
These things get a bit fuzzy. So 72 bytes into this C object is where you find the name or


00:57:22.080 --> 00:57:27.760
something like that, right? Yeah. So because we basically, because anything might not be


00:57:27.760 --> 00:57:34.480
as the annotation say effectively at the virtual machine level, we have to check everything. And


00:57:34.480 --> 00:57:39.040
And if we're going to check it anyway, we may as well just check it once up ahead


00:57:39.040 --> 00:57:42.320
as we first do the compilation, whatever, specialization,


00:57:42.320 --> 00:57:44.880
and then assume it's going to be like that.


00:57:44.880 --> 00:57:50.400
Because if the annotations are correct, then that's just as efficient.


00:57:50.400 --> 00:57:54.320
And if the annotations are wrong, we still get some performance benefit.


00:57:54.320 --> 00:57:55.680
And it's robust as well.


00:57:55.680 --> 00:57:57.280
So there's really no...


00:57:57.280 --> 00:58:03.680
The only advantage of the annotations is for this sort of very loopy code


00:58:03.680 --> 00:58:07.440
where we can do things like loop transformations and so on,


00:58:07.440 --> 00:58:10.640
because we can infer the types from the arguments


00:58:10.640 --> 00:58:13.040
of enough of the function to do that stuff.


00:58:13.040 --> 00:58:14.960
And that works great for numerical stuff,


00:58:14.960 --> 00:58:17.280
but for more general code is problematic.


00:58:17.280 --> 00:58:19.040
What about slots?


00:58:19.040 --> 00:58:24.400
Slots are an interesting, not frequently used aspect of Python types


00:58:24.400 --> 00:58:28.400
that seem to change how things are laid out a little bit.


00:58:28.400 --> 00:58:29.700
Yeah.


00:58:29.700 --> 00:58:30.900
Does that--


00:58:30.900 --> 00:58:35.020
- Well, mypyC actually, one of mypyC's main tricks


00:58:35.020 --> 00:58:40.020
is that it turns every class into a class with slots.


00:58:40.020 --> 00:58:42.480
- Okay.


00:58:42.480 --> 00:58:45.600
- Which if you know how slots work,


00:58:45.600 --> 00:58:49.200
you will immediately see the limitation


00:58:49.200 --> 00:58:53.000
because it means there are no dynamic attributes at all.


00:58:53.000 --> 00:58:56.700
- Yeah, but these are what you get for your fields


00:58:56.700 --> 00:58:57.540
and that's it.


00:58:57.540 --> 00:58:59.460
- Yeah, I mean, if you don't have dynamic attributes,


00:58:59.460 --> 00:59:02.480
- Though it gives you pretty efficient memory use.


00:59:02.480 --> 00:59:05.120
I mean, it's not so far off Java.


00:59:05.120 --> 00:59:07.240
- And more predictability about what's there


00:59:07.240 --> 00:59:10.280
and what's not, which is why it came to mind, yeah.


00:59:10.280 --> 00:59:12.640
- Yeah, yeah, I mean, they definitely have their use.


00:59:12.640 --> 00:59:13.960
- Yep.


00:59:13.960 --> 00:59:17.480
All right, Mark, that was your four-stage plan,


00:59:17.480 --> 00:59:22.480
hoping to make 1.5 times as fast as before each time,


00:59:22.480 --> 00:59:26.000
which if you do that over four releases,


00:59:26.000 --> 00:59:27.800
you end up with five times faster, right?


00:59:27.800 --> 00:59:29.760
That's the standard plan.


00:59:29.760 --> 00:59:30.600
Where are we on this?


00:59:30.600 --> 00:59:33.940
How's it going for you and everyone on the team?


00:59:33.940 --> 00:59:38.880
- So I say it's a bit of a jumble of stages one and two


00:59:38.880 --> 00:59:40.800
that we're implementing,


00:59:40.800 --> 00:59:43.080
largely because it's a larger,


00:59:43.080 --> 00:59:44.640
more diverse team than I was expecting.


00:59:44.640 --> 00:59:47.720
So it makes sense to just sort of spread things.


00:59:47.720 --> 00:59:49.400
- Yeah. - Yeah.


00:59:49.400 --> 00:59:51.000
- Yeah, you'll work on operators,


00:59:51.000 --> 00:59:53.840
you go work on zero overhead exception handling and-


00:59:53.840 --> 00:59:54.680
- Yeah, yeah.


00:59:56.240 --> 00:59:59.800
I mean, I would say from where we are now,


00:59:59.800 --> 01:00:02.040
I was probably a bit optimistic with stage one,


01:00:02.040 --> 01:00:06.380
but stage two seems to have a lot of potential still.


01:00:06.380 --> 01:00:08.120
There's always little bits of the interpreter


01:00:08.120 --> 01:00:10.600
we can tweak and improve.


01:00:10.600 --> 01:00:12.160
So between the two of them,


01:00:12.160 --> 01:00:14.940
I'm confident we'll get this projected


01:00:14.940 --> 01:00:16.560
over twice the speed.


01:00:16.560 --> 01:00:17.400
- That's fantastic.


01:00:17.400 --> 01:00:19.500
So the course you're on right now,


01:00:19.500 --> 01:00:21.720
if let's just say stage one and two happen,


01:00:21.720 --> 01:00:24.140
and for some reason the JIT stuff doesn't,


01:00:24.140 --> 01:00:25.880
that's still a big contribution.


01:00:25.880 --> 01:00:28.380
What do you think in terms of speed up for that?


01:00:28.380 --> 01:00:31.520
- Well, again, it's gonna depend.


01:00:31.520 --> 01:00:33.520
- I know it matters so much, but like, you know.


01:00:33.520 --> 01:00:35.640
- I mean, I just wanna, 'cause like,


01:00:35.640 --> 01:00:38.520
currently we have a sort of set of benchmarks


01:00:38.520 --> 01:00:39.360
that we're using.


01:00:39.360 --> 01:00:41.600
I mean, not possibly the, I mean,


01:00:41.600 --> 01:00:42.960
the more benchmarks is always better.


01:00:42.960 --> 01:00:45.600
So it's a broad set, individually,


01:00:45.600 --> 01:00:47.560
the benchmarks, some of them aren't great,


01:00:47.560 --> 01:00:51.160
but collectively a foremost sort of useful data set.


01:00:51.160 --> 01:00:54.080
But I mean, with speed ups from up like up to 60%


01:00:54.080 --> 01:00:55.680
down to zero, so.


01:00:55.680 --> 01:00:56.520
- Yeah.


01:00:56.520 --> 01:00:58.440
- It's definitely a spread.


01:00:58.440 --> 01:01:02.360
So it can, you know, try it out would be the thing.


01:01:02.360 --> 01:01:05.440
I mean, you can download 3.11 alpha one


01:01:05.440 --> 01:01:08.800
and alpha two should be out in a few days at all time now.


01:01:08.800 --> 01:01:13.320
So presumably before this publish a podcast.


01:01:13.320 --> 01:01:16.160
So people can download it and play with it.


01:01:16.160 --> 01:01:17.400
- Yeah, that's fantastic.


01:01:17.400 --> 01:01:20.440
I, you know, thank you for this.


01:01:20.440 --> 01:01:24.440
I think even 50, 60%, if it stay there,


01:01:24.440 --> 01:01:25.880
That's pretty incredible.


01:01:25.880 --> 01:01:29.080
I mean, Guido, this language has been around for 30 years.


01:01:29.080 --> 01:01:31.020
People have been trying to optimize it for a long time.


01:01:31.020 --> 01:01:31.960
It's incredible, right?


01:01:31.960 --> 01:01:35.080
And then, you know, to do this sort of change now,


01:01:35.080 --> 01:01:36.760
that would be really significant.


01:01:36.760 --> 01:01:42.000
- Yeah, this is an area that we haven't spent much time on


01:01:42.000 --> 01:01:47.000
previously for various reasons.


01:01:47.000 --> 01:01:50.360
I mean, people have spent a lot of time


01:01:50.360 --> 01:01:54.740
on sort of making the string of the objects fast,


01:01:54.740 --> 01:01:57.180
making dictionary operations fast,


01:01:57.180 --> 01:01:59.740
making the memory efficient,


01:01:59.740 --> 01:02:03.200
adding functionality that the sort of Python has generally,


01:02:03.200 --> 01:02:08.120
I think, had more of a focus on functionality


01:02:08.120 --> 01:02:10.580
than on speed.


01:02:10.580 --> 01:02:13.340
And so for me, this is also a change in mindset.


01:02:13.340 --> 01:02:15.220
And I'm still learning a lot.


01:02:15.220 --> 01:02:17.380
Mark actually teaches me a lot


01:02:17.380 --> 01:02:20.060
about how to think about this stuff.


01:02:20.060 --> 01:02:24.160
And I decided to buy this horrible book.


01:02:24.160 --> 01:02:27.440
Well, it's a great book, "Computer Architecture,"


01:02:27.440 --> 01:02:32.440
but it's also like, it weighs more than a 17-inch laptop.


01:02:32.440 --> 01:02:35.280
- Wow.


01:02:35.280 --> 01:02:37.540
- Classic text, but not a light read.


01:02:37.540 --> 01:02:40.480
- Yeah, down into, beyond the software layer,


01:02:40.480 --> 01:02:42.600
into the hardware bits.


01:02:42.600 --> 01:02:47.600
- It makes me amazed that we have any performance at all


01:02:48.540 --> 01:02:50.900
and that any performance is predictable


01:02:50.900 --> 01:02:53.740
because we're doing everything wrong


01:02:53.740 --> 01:02:57.700
from the perspective of giving the CPU


01:02:57.700 --> 01:02:59.060
something to work with.


01:02:59.060 --> 01:03:02.140
I mean, all the algorithms described in there,


01:03:02.140 --> 01:03:05.080
branch prediction, speculative execution,


01:03:05.080 --> 01:03:08.460
caching of instructions,


01:03:08.460 --> 01:03:12.860
all that is aimed at small loops of numerical code.


01:03:12.860 --> 01:03:14.620
And we have none of that.


01:03:14.620 --> 01:03:17.380
- Yeah, exactly, exactly.


01:03:17.380 --> 01:03:20.300
C of LC is not a numerical loop, definitely not.


01:03:20.300 --> 01:03:23.260
All right, well, I think that might be it


01:03:23.260 --> 01:03:24.980
for the time we have.


01:03:24.980 --> 01:03:27.980
I got a couple of questions from the audience out there.


01:03:27.980 --> 01:03:30.660
Toon Army Captain says,


01:03:30.660 --> 01:03:32.340
"I'm interested in Guido's thoughts


01:03:32.340 --> 01:03:36.280
"about the Microsoft funded effort


01:03:36.280 --> 01:03:38.260
"versus the developer in residence,


01:03:38.260 --> 01:03:40.040
"particularly in terms of the major work


01:03:40.040 --> 01:03:42.840
"of the language in the CPython runtime going forward."


01:03:42.840 --> 01:03:45.620
I think these are both good things,


01:03:45.620 --> 01:03:47.140
both really good things.


01:03:47.140 --> 01:03:49.120
They seem super different to me.


01:03:49.120 --> 01:03:52.520
- I think it's great that we have a developer in residence.


01:03:52.520 --> 01:03:55.500
It's a very different role than what we're doing here.


01:03:55.500 --> 01:03:59.100
The team at Microsoft is, at least,


01:03:59.100 --> 01:04:02.420
we're trying to be super focused on performance


01:04:02.420 --> 01:04:04.940
to the exclusion of almost everything else,


01:04:04.940 --> 01:04:09.700
except all those constraints I mentioned, of course.


01:04:09.700 --> 01:04:14.180
The developer in residence is focused on


01:04:15.460 --> 01:04:25.460
the community, other core developers, but also contributors.


01:04:25.460 --> 01:04:27.780
Lukasz is great.


01:04:27.780 --> 01:04:34.060
He's the perfect guy for that role.


01:04:34.060 --> 01:04:40.100
And his work is completely orthogonal to what we're doing.


01:04:40.100 --> 01:04:49.580
And I hope that somehow the PSF finds funds for keeping the developer in residence role


01:04:49.580 --> 01:04:53.340
and maybe even expanding it for many years.


01:04:53.340 --> 01:04:59.660
It seems to me like a really important role to smooth the edges of people contributing


01:04:59.660 --> 01:05:01.700
to CPython.


01:05:01.700 --> 01:05:06.240
And the difference of what Mark and you all are doing is, you know, heads down, focused


01:05:06.240 --> 01:05:12.820
on writing one type of code, whereas Lukas is there to make it easier for everyone else


01:05:12.820 --> 01:05:15.080
to do whatever they were going to do.


01:05:15.080 --> 01:05:21.560
And I think one sort of a horizontal scale of the CPython team and the other is very


01:05:21.560 --> 01:05:24.300
focused, which is also needed.


01:05:24.300 --> 01:05:33.840
And it's actually amazing that we've been able to do all the work that we've been doing


01:05:33.840 --> 01:05:38.480
over the past 30 years on Python without a developer in residence.


01:05:38.480 --> 01:05:42.160
I think in the early years I was probably


01:05:42.160 --> 01:05:48.800
taking up that role but the last decade or two there just have


01:05:48.800 --> 01:05:53.680
been too many issues, too many peps for


01:05:53.680 --> 01:05:59.440
for me to sort of get everything going and sort of having... I was


01:05:59.440 --> 01:06:03.600
always working part-time on Python and part-time working on my day job.


01:06:03.600 --> 01:06:12.720
Lukasz is working full-time on Python and he has a somewhat specific mandate


01:06:12.720 --> 01:06:22.880
to help contributions go smoother,


01:06:22.880 --> 01:06:31.280
make working with the issue tracker easier, and that


01:06:31.280 --> 01:06:38.400
developers. Contributors must be encouraged and rewarded and currently often the way the


01:06:38.400 --> 01:06:44.640
bugs.python.org experience is it's a very old web app and it looks that way


01:06:44.640 --> 01:06:52.960
and it's difficult to learn how to do various things with that thing


01:06:52.960 --> 01:07:00.400
and so Lukasz is really helping people. Yeah, it's fantastic. Of course there's also the


01:07:00.400 --> 01:07:05.200
the somewhat separate project of switching


01:07:05.200 --> 01:07:10.200
from bugspython.org to a purely GitHub based tracker.


01:07:10.200 --> 01:07:12.920
- Yeah, I was just thinking of that


01:07:12.920 --> 01:07:14.360
as you were speaking there.


01:07:14.360 --> 01:07:15.340
Do you think that'll help?


01:07:15.340 --> 01:07:18.720
I feel like people are more familiar with that workflow.


01:07:18.720 --> 01:07:20.880
- People are more familiar.


01:07:20.880 --> 01:07:24.200
It's more integrated with the pull request flow


01:07:24.200 --> 01:07:26.140
that we already have on GitHub.


01:07:26.140 --> 01:07:29.400
I think it will be great.


01:07:29.400 --> 01:07:38.400
expectations is that I think it'll be actually happening before the end of this year or very early next year.


01:07:38.400 --> 01:07:46.400
That'd be fantastic. The code's already there, the work's already there, might as well have the conversations and the issues and whatnot there.


01:07:46.400 --> 01:07:53.400
Alright guys, I think we are definitely over time, but I really appreciate, first of all, the work that you're doing,


01:07:53.400 --> 01:07:57.600
Mark on this project, and Guido on the last 30 years.


01:07:57.600 --> 01:07:58.240
This is amazing.


01:07:58.240 --> 01:08:00.720
You can see out in the comments how appreciative folks


01:08:00.720 --> 01:08:03.040
are of all the work you've done.


01:08:03.040 --> 01:08:05.040
So thank you for that.


01:08:05.040 --> 01:08:08.720
Let's close with a final call to action.


01:08:08.720 --> 01:08:10.260
You have the small team working on it.


01:08:10.260 --> 01:08:12.560
I'm sure the community can help in some way.


01:08:12.560 --> 01:08:14.040
What do you want from people?


01:08:14.040 --> 01:08:17.040
How can they help you, either now or in the future?


01:08:22.320 --> 01:08:24.560
Well, I mean, it's just contributed to CPython.


01:08:24.560 --> 01:08:28.960
So I mean, I don't think it's specifically performance.


01:08:28.960 --> 01:08:32.560
I mean, like all the contributions help improve,


01:08:32.560 --> 01:08:35.720
you know, co-quality and reliability


01:08:35.720 --> 01:08:37.440
are still very important.


01:08:37.440 --> 01:08:41.440
So I don't think particularly people,


01:08:41.440 --> 01:08:42.920
anything particularly can do,


01:08:42.920 --> 01:08:45.280
but we do have a sort of ideas repo


01:08:45.280 --> 01:08:48.640
if people do have sort of things they wanna suggest


01:08:48.640 --> 01:08:51.520
or bounce ideas around or whatever.


01:08:51.520 --> 01:08:55.540
Maybe they could test their workloads on alpha versions


01:08:55.540 --> 01:08:56.380
of things that have-- - Yeah, I mean,


01:08:56.380 --> 01:08:57.840
that would be fantastic.


01:08:57.840 --> 01:08:59.920
We don't really have a setup for where people


01:08:59.920 --> 01:09:02.780
can put that information, but if just open an issue


01:09:02.780 --> 01:09:05.920
on the ideas thing and post some data, it'd be fantastic.


01:09:05.920 --> 01:09:10.920
- We'd love it for people to sort of try to use


01:09:10.920 --> 01:09:14.820
the new code and see how it works out for them.


01:09:14.820 --> 01:09:17.260
- Yeah, fantastic.


01:09:17.260 --> 01:09:20.560
All right, well, thank you both for being here.


01:09:20.560 --> 01:09:22.420
It's been great.


01:09:22.420 --> 01:09:23.260
- Our pleasure.


01:09:23.260 --> 01:09:24.080
- Yeah, thank you.


01:09:24.080 --> 01:09:24.920
- Yeah.


01:09:24.920 --> 01:09:25.760
Thanks.


01:09:25.760 --> 01:09:35.760
[BLANK_AUDIO]

