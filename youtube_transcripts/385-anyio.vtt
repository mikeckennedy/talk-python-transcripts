WEBVTT

00:00:00.000 --> 00:00:05.000
Alex, welcome to Talk Python to Me.


00:00:05.000 --> 00:00:05.840
- Thank you.


00:00:05.840 --> 00:00:08.160
- Yeah, it's fantastic to have you here.


00:00:08.160 --> 00:00:12.760
You have so many cool open source projects out there.


00:00:12.760 --> 00:00:15.820
We're here to talk about any IO,


00:00:15.820 --> 00:00:20.820
but actually several of them I've covered on Python Bytes


00:00:20.820 --> 00:00:23.200
on the other podcasts that I run.


00:00:23.200 --> 00:00:26.720
And we've talked about SQL Code Gen and TypeGuard.


00:00:27.640 --> 00:00:30.560
And I didn't associate that with you specifically


00:00:30.560 --> 00:00:31.920
and back over to NEIO.


00:00:31.920 --> 00:00:34.840
So yeah, a lot of cool projects you got going on there.


00:00:34.840 --> 00:00:36.440
- Yeah, too many actually.


00:00:36.440 --> 00:00:40.520
I managed to hand over a couple of them to other people,


00:00:40.520 --> 00:00:44.060
Seaboard 2 and Sphinx Autodoc type hints,


00:00:44.060 --> 00:00:48.480
because I'm really stressed thing at the moment.


00:00:48.480 --> 00:00:50.840
I barely have time for all of the projects


00:00:50.840 --> 00:00:51.880
that I'm maintaining.


00:00:51.880 --> 00:00:54.000
- I can imagine.


00:00:54.000 --> 00:00:56.960
That's, you know, how do you juggle all that?


00:00:56.960 --> 00:01:00.180
- I know it's, I'm sure you have a full-time job


00:01:00.180 --> 00:01:01.960
and you have all these different projects, right?


00:01:01.960 --> 00:01:03.280
- Yes, yes.


00:01:03.280 --> 00:01:08.680
Basically I get the equivalent of a writer's block


00:01:08.680 --> 00:01:09.880
from time to time.


00:01:09.880 --> 00:01:14.600
So when that happens, I just either don't try to code at all


00:01:14.600 --> 00:01:17.160
or I just switch to another project.


00:01:17.160 --> 00:01:19.360
- Yeah, true.


00:01:19.360 --> 00:01:21.880
If you're talking about type hints versus async programming,


00:01:21.880 --> 00:01:23.360
like if you're stuck on one,


00:01:23.360 --> 00:01:25.520
you probably are not stuck on the other, right?


00:01:25.520 --> 00:01:26.520
- Yeah.


00:01:26.520 --> 00:01:27.360
- Yeah, interesting.


00:01:27.360 --> 00:01:29.280
Well, we're gonna have a lot of fun


00:01:29.280 --> 00:01:30.640
talking about all of them.


00:01:30.640 --> 00:01:32.980
I doubt there's gonna be any writer's block


00:01:32.980 --> 00:01:36.000
or speaker's block here, podcaster's block.


00:01:36.000 --> 00:01:36.840
It'll be good.


00:01:36.840 --> 00:01:37.740
We'll have a good time chatting about it


00:01:37.740 --> 00:01:38.840
and sharing with everyone.


00:01:38.840 --> 00:01:41.520
Before we get to that though, let's hear your story.


00:01:41.520 --> 00:01:43.480
How'd you get into programming in Python?


00:01:43.480 --> 00:01:47.680
- I got into programming at the age of eight.


00:01:47.680 --> 00:01:53.200
It was on an MSX compatible machine.


00:01:53.200 --> 00:01:57.080
I started with BASIC, as so many others did.


00:01:57.080 --> 00:02:04.800
I did some simple text-based games at first,


00:02:04.800 --> 00:02:09.160
just playing around.


00:02:09.160 --> 00:02:15.920
At some point, I got Commodore 128,


00:02:15.920 --> 00:02:20.920
and I did some simple demos, graphical demos with it.


00:02:22.900 --> 00:02:25.480
Then I got an Amiga 500.


00:02:25.480 --> 00:02:28.600
- Oh yeah, the Amigas were cool.


00:02:28.600 --> 00:02:30.020
They were special.


00:02:30.020 --> 00:02:31.020
- Yeah.


00:02:31.020 --> 00:02:36.020
So I doubled in almost basic


00:02:36.020 --> 00:02:41.400
than other kinds of tools also.


00:02:41.400 --> 00:02:44.420
I don't really remember that much of it.


00:02:44.420 --> 00:02:50.420
Then at some point I did something with Mac,


00:02:50.920 --> 00:02:55.560
that is macOS classic, there was this tool called HyperCard.


00:02:55.560 --> 00:03:00.720
It's a precursor for Flash, basically.


00:03:00.720 --> 00:03:05.040
So that's something I did some things with,


00:03:05.040 --> 00:03:07.200
simple games and whatnot.


00:03:07.200 --> 00:03:08.040
- Yeah, okay.


00:03:08.040 --> 00:03:13.040
- Then, skipping forward a bit,


00:03:13.040 --> 00:03:19.320
I got into PC programming, like C, C++,


00:03:20.840 --> 00:03:30.840
mostly C. And then I think it was in the latter half of 2005.


00:03:30.840 --> 00:03:37.720
No, actually it was much earlier, 1999.


00:03:37.720 --> 00:03:43.720
I started with Perl, hated it.


00:03:43.720 --> 00:03:52.680
Then I think the next step was in 2005 when I got to learn PHP.


00:03:52.680 --> 00:03:55.240
Hated that too.


00:03:55.240 --> 00:04:01.760
And then finally in 2007 I got to know Python.


00:04:01.760 --> 00:04:08.000
Then that was love at first sight, really.


00:04:08.000 --> 00:04:19.080
At that point it was I think 2.5 and of course I stuck with it.


00:04:19.080 --> 00:04:30.240
I did some Java professionally for a while, but I never really got to love it.


00:04:30.240 --> 00:04:36.000
It had this corporate, industrial feeling to it.


00:04:36.000 --> 00:04:40.280
I'm not dressed up enough to program my Java today.


00:04:40.280 --> 00:04:41.560
Let me go get my tie.


00:04:41.560 --> 00:04:42.960
I'll be right back.


00:04:42.960 --> 00:04:43.960
Yeah.


00:04:43.960 --> 00:04:46.440
So Python was really cool.


00:04:46.440 --> 00:04:51.320
When I started learning it, my first practical application


00:04:51.320 --> 00:04:57.200
I made in, what, 30 minutes after starting to learn it.


00:04:57.200 --> 00:05:01.920
So it's really staggeringly easy to learn.


00:05:01.920 --> 00:05:03.840
And that's one thing I love about it.


00:05:03.840 --> 00:05:11.960
It really is. It's one of the few languages you can be really successful with, with a


00:05:11.960 --> 00:05:17.120
partial understanding of what's going on. You don't even have to know what a class is


00:05:17.120 --> 00:05:21.520
or what modules are. You can just write a few functions in a file.


00:05:21.520 --> 00:05:24.600
It's almost like it's English.


00:05:24.600 --> 00:05:31.880
Yeah, indeed. Very cool. Raul out in the audience says, "Third time's a charm." The third language


00:05:31.880 --> 00:05:36.840
you found the one you like there. Excellent. And how about now? What are you doing these days?


00:05:36.840 --> 00:05:47.800
I've been working for several years on a project, a very complicated project where,


00:05:47.800 --> 00:05:56.680
this is always a hard part to describe it. It's a sort of working wellness application.


00:05:58.440 --> 00:06:09.000
I'm part of a bigger team. I'm the lead backend developer. It collects IoT data and visualizes it


00:06:09.000 --> 00:06:18.440
and it provides all sorts of peripheral services to it. So this is the first time I really had to


00:06:18.440 --> 00:06:25.640
spread my wings with databases. Oh yeah, okay. What technologies are you using there?


00:06:28.200 --> 00:06:35.880
Well, on the back end we use timescale DB, which is a post-credential extension.


00:06:35.880 --> 00:06:39.000
This is for storing that time series data.


00:06:39.000 --> 00:06:47.720
Then on the back end, we use my framework called Asphalt.


00:06:47.720 --> 00:06:55.320
I don't know if you've encountered that one. I think it's really cool,


00:06:56.680 --> 00:07:00.200
But it's not in widespread use.


00:07:00.200 --> 00:07:03.320
It's not a web framework per se.


00:07:03.320 --> 00:07:05.760
It's more like a generic framework


00:07:05.760 --> 00:07:07.520
where you can compose applications


00:07:07.520 --> 00:07:12.600
from a mix of premade components and custom-made components.


00:07:12.600 --> 00:07:14.400
What's it called?


00:07:14.400 --> 00:07:15.280
Sorry?


00:07:15.280 --> 00:07:15.780
Asphalt.


00:07:15.780 --> 00:07:16.800
What was it called?


00:07:16.800 --> 00:07:18.680
Asphalt, like the road?


00:07:18.680 --> 00:07:19.180
Yes.


00:07:19.180 --> 00:07:25.400
[INTERPOSING VOICES]


00:07:25.400 --> 00:07:28.520
Yeah, that's no, no, no, no, no.


00:07:28.520 --> 00:07:29.020
Guessing no.


00:07:29.020 --> 00:07:32.440
I did a search and I just found a snake.


00:07:32.440 --> 00:07:34.040
Yeah, that's a good thing.


00:07:34.040 --> 00:07:37.880
That Python, the snake on some asphalt road.


00:07:37.880 --> 00:07:38.920
Yeah, you gotta be careful here.


00:07:38.920 --> 00:07:40.280
Okay.


00:07:40.280 --> 00:07:43.880
Is it a little bit like Flask or what's the?


00:07:43.880 --> 00:07:46.760
Well, Flask is a web framework.


00:07:46.760 --> 00:07:48.920
This is a generic framework.


00:07:48.920 --> 00:07:51.240
You can build any kind of applications with it.


00:07:51.240 --> 00:07:53.160
Doesn't have to be involved with web.


00:07:53.800 --> 00:07:54.800
You can either write command line--


00:07:54.800 --> 00:07:57.000
>> I see, any network thing, not necessarily HTTP.


00:07:57.000 --> 00:08:00.000
So it could be UDP or it could be just--


00:08:00.000 --> 00:08:02.640
>> It doesn't even have to do any networking at all.


00:08:02.640 --> 00:08:05.280
You can build command line tools with it.


00:08:05.280 --> 00:08:10.280
And you can just have this mix of components


00:08:10.280 --> 00:08:15.720
and the YAML configuration to give settings to them all.


00:08:15.720 --> 00:08:22.400
I think this really would require a whole different session.


00:08:22.880 --> 00:08:24.840
It does sound like it would be a whole different session,


00:08:24.840 --> 00:08:28.940
but this is news to me and very interesting.


00:08:28.940 --> 00:08:31.300
- Yeah, I haven't really advertised much.


00:08:31.300 --> 00:08:34.300
I'm working on version five at the moment,


00:08:34.300 --> 00:08:38.940
which does incorporate any I/O support and all the,


00:08:38.940 --> 00:08:45.760
it brings the tech up to date with the current standards.


00:08:45.760 --> 00:08:52.260
- Okay, yeah, this looks very asynchronous based.


00:08:52.260 --> 00:08:54.860
It's an async I/O based micro framework


00:08:54.860 --> 00:08:57.460
for network oriented applications, it says.


00:08:57.460 --> 00:08:58.280
- Yeah.


00:08:58.280 --> 00:09:03.760
- Built upon UV loop, which is, you know,


00:09:03.760 --> 00:09:05.980
how all the good Python async things


00:09:05.980 --> 00:09:07.860
seem to be backed these days.


00:09:07.860 --> 00:09:14.840
So it has a lot of sort of modern Python features.


00:09:14.840 --> 00:09:17.060
It's got async I/O, it's got UV loop,


00:09:17.060 --> 00:09:21.320
it's got type hints, those sorts of things.


00:09:21.320 --> 00:09:26.320
When you started in Python in 2007, none of those existed.


00:09:26.320 --> 00:09:30.480
How do you see the recent changes to Python


00:09:30.480 --> 00:09:32.260
in the last five years or so?


00:09:32.260 --> 00:09:39.240
- I would say that Python has been developing


00:09:39.240 --> 00:09:44.120
at an incredible speed and I really love it.


00:09:44.120 --> 00:09:49.240
So many useful stuff coming out with every release.


00:09:49.240 --> 00:09:50.080
- I agree.


00:09:50.080 --> 00:09:57.080
>>Yeah, basically from 3.5 to 3.8 or something.


00:09:57.080 --> 00:10:01.080
There were just so many amazing features that came out then.


00:10:01.080 --> 00:10:03.580
And now we're seeing these libraries built upon it, right?


00:10:03.580 --> 00:10:04.580
>>Right.


00:10:04.580 --> 00:10:05.580
>>Right.


00:10:05.580 --> 00:10:08.580
All right, well, let's transition over


00:10:08.580 --> 00:10:11.080
to our main topic that we're going to talk about, which


00:10:11.080 --> 00:10:13.080
is what I reached out to you for,


00:10:13.080 --> 00:10:15.580
not realizing the other two interesting projects that I


00:10:15.580 --> 00:10:18.080
already gave a shout out to are also yours.


00:10:18.080 --> 00:10:20.080
We'll get to those if we got time.


00:10:20.080 --> 00:10:27.080
So with Python in 3.4, we had AsyncIO introduced,


00:10:27.080 --> 00:10:30.080
the actual frameworks that supported that.


00:10:30.080 --> 00:10:33.080
And then when it really came into its own was Python 3.5,


00:10:33.080 --> 00:10:36.080
when the async and await keywords were added to the language.


00:10:36.080 --> 00:10:43.080
And Python came out of the box with some support for great async programming.


00:10:43.080 --> 00:10:47.080
But then there are these other libraries that developed on top of that


00:10:47.080 --> 00:10:50.380
of that to maybe make certain use cases easier


00:10:50.380 --> 00:10:53.420
or add new capabilities and any IO falls


00:10:53.420 --> 00:10:54.700
into that realm, right?


00:10:54.700 --> 00:10:58.940
- Yeah, so before we talk about any IO,


00:10:58.940 --> 00:11:00.620
we should talk about Trio.


00:11:00.620 --> 00:11:03.360
Have you heard about Trio?


00:11:03.360 --> 00:11:05.340
- Yes, I have heard about Trio.


00:11:05.340 --> 00:11:10.340
I even had Nathaniel on the show,


00:11:10.340 --> 00:11:11.740
but it's been a little while.


00:11:11.740 --> 00:11:15.980
That was back in 2018, I talked to Nathaniel.


00:11:15.980 --> 00:11:19.980
Nathaniel Smith. So there's probably quite a few changes since then, actually.


00:11:19.980 --> 00:11:20.980
Yeah.


00:11:20.980 --> 00:11:22.980
Yeah, let's talk about Trio.


00:11:22.980 --> 00:11:26.980
Yeah, actually the last version of Trio was released just yesterday.


00:11:26.980 --> 00:11:40.980
So, the thing about NEIO is that it's an effort to basically bring the Trio features to AsyncIO LAN.


00:11:40.980 --> 00:11:45.740
So Trio is fundamentally incompatible with AsyncIO.


00:11:45.740 --> 00:11:49.060
There is a compatibility layer called Trio AsyncIO,


00:11:49.060 --> 00:11:52.700
but it's far from perfect.


00:11:52.700 --> 00:11:58.700
So what any I/O does really is allow users to,


00:11:58.700 --> 00:12:03.940
allow developers to add these features from Trio


00:12:03.940 --> 00:12:09.140
to their AsyncIO applications and libraries one by one


00:12:09.140 --> 00:12:13.060
one without making a commitment.


00:12:13.060 --> 00:12:23.620
For example, at my work, I use any I/O for just a handful of tasks.


00:12:23.620 --> 00:12:33.140
I think we should talk about the features.


00:12:37.260 --> 00:12:47.180
So one thing at least I should say to dispel any confusion is that the Trio and AsyncIO are both


00:12:47.180 --> 00:12:57.180
like top-level Async frameworks in that they provide an event loop and in the IEO does not.


00:12:57.180 --> 00:13:03.660
So it's kind of a meta Async framework. So it transforms on top of the different frameworks.


00:13:03.660 --> 00:13:10.380
Yeah, so it builds on top of these frameworks and their underlying primitives.


00:13:10.380 --> 00:13:25.500
Yeah, so for people who are not familiar, Trio adds things like this concept of grouped tasks.


00:13:25.500 --> 00:13:31.260
So normally in AsyncIO, you start one task, you start another. They're kind of unrelated, but


00:13:31.260 --> 00:13:34.860
even if they're conceptually solving parts of the same problem.


00:13:34.860 --> 00:13:38.380
And with Trio, you can do things like create what's called a nursery,


00:13:38.380 --> 00:13:41.900
and then you can have them all run, or you could potentially cancel


00:13:41.900 --> 00:13:49.260
unstarted tasks. And there's other coordination type of operations as well.


00:13:49.260 --> 00:13:51.260
That's the kind of stuff that Trio adds.


00:13:51.260 --> 00:14:00.860
Yeah, so the point of any I/O is, as I said, to bring these Trio features


00:14:00.860 --> 00:14:02.060
to asyncio.


00:14:02.060 --> 00:14:04.860
Right.


00:14:04.860 --> 00:14:09.660
It's because when you do Trio, it's an end to end async stack,


00:14:09.660 --> 00:14:13.960
which means you are basically have to be built for Trio, right?


00:14:13.960 --> 00:14:19.660
It's like if I have, let's say, HTPX, it's I don't know how easy it is to integrate


00:14:19.660 --> 00:14:19.960
that.


00:14:19.960 --> 00:14:24.960
Those kind of things that are expecting an asyncio event loop over into Trio.


00:14:24.960 --> 00:14:29.360
Yeah, so I already have my own event loop running.


00:14:29.360 --> 00:14:32.040
and it's hard to coordinate the tasks, right?


00:14:32.040 --> 00:14:36.720
- So if you are talking about HTTPX,


00:14:36.720 --> 00:14:43.120
it had a TRIO and async I/O backends.


00:14:43.120 --> 00:14:45.920
Now it defaults to the any I/O backend.


00:14:45.920 --> 00:14:49.580
So it runs by default on both.


00:14:49.580 --> 00:14:51.440
- Okay.


00:14:51.440 --> 00:14:57.080
- So about any I/O features,


00:14:58.960 --> 00:15:03.960
It provides a trio like task groups on top of AsyncIO.


00:15:03.960 --> 00:15:10.600
This in here, we should mention that Python 3.11


00:15:10.600 --> 00:15:13.040
has its own concept of a task group,


00:15:13.040 --> 00:15:18.040
but the mechanics are quite a bit different.


00:15:18.040 --> 00:15:21.520
That requires a bit of explaining.


00:15:21.520 --> 00:15:24.400
- Yeah, how's it work here?


00:15:27.280 --> 00:15:32.280
The thing is the async I/O task group,


00:15:32.280 --> 00:15:36.360
so not this one, but the standard library task groups,


00:15:36.360 --> 00:15:38.240
which are in Puzzle 3.11,


00:15:38.240 --> 00:15:44.080
they basically just start normal async I/O task,


00:15:44.080 --> 00:15:47.080
and you can cancel individual tasks


00:15:47.080 --> 00:15:50.080
with using the task objects


00:15:50.080 --> 00:15:53.140
that come out of the create task method.


00:15:54.780 --> 00:15:57.700
What sets any I/O task groups apart


00:15:57.700 --> 00:16:02.540
from async I/O task groups is the way cancellation is done.


00:16:02.540 --> 00:16:08.620
And since any I/O goes designed based on TRIO,


00:16:08.620 --> 00:16:16.880
when you do start soon,


00:16:16.880 --> 00:16:21.900
it doesn't return any task object that you can cancel.


00:16:21.900 --> 00:16:26.900
Instead, cancellation is done via so-called cancel scopes.


00:16:26.900 --> 00:16:31.380
So each task group has its own cancel scope.


00:16:31.380 --> 00:16:32.460
If you cancel that,


00:16:32.460 --> 00:16:37.100
you basically cancel all the underlying tasks.


00:16:37.100 --> 00:16:40.880
But it goes even deeper because,


00:16:40.880 --> 00:16:44.960
okay, this is a bit complicated, so bear with me.


00:16:44.960 --> 00:16:50.660
Cancellation is not done on a per-task basis,


00:16:50.660 --> 00:16:53.860
but on the per cancel scope basis.


00:16:53.860 --> 00:16:58.860
So you can have cancel scopes nested


00:16:58.860 --> 00:17:02.740
so that if you start a task and it starts a cancel scope,


00:17:02.740 --> 00:17:06.340
you can just cancel that scope


00:17:06.340 --> 00:17:10.360
and it cancels everything up to that point.


00:17:10.360 --> 00:17:14.180
- Okay, so like if I call a task,


00:17:14.180 --> 00:17:17.420
if I create a task and then somewhere inside


00:17:17.420 --> 00:17:18.460
for it to do its job,


00:17:18.460 --> 00:17:20.300
it also creates a task.


00:17:20.300 --> 00:17:24.540
Those can be grouped into the same basic scope, right?


00:17:24.540 --> 00:17:25.380
So there's not--


00:17:25.380 --> 00:17:27.740
- Yeah, you don't even have to start another task.


00:17:27.740 --> 00:17:31.220
You don't even have to start another task.


00:17:31.220 --> 00:17:36.220
So if you cancel a cancel scope,


00:17:36.220 --> 00:17:39.780
then anything you basically await on


00:17:39.780 --> 00:17:41.980
gets automatically canceled, bam.


00:17:41.980 --> 00:17:46.540
Which is, this is called level cancellation.


00:17:46.540 --> 00:17:49.700
in contrast to the edge cancellation mechanism


00:17:49.700 --> 00:17:51.740
employed by any SIGIO.


00:17:51.740 --> 00:17:57.020
In edge cancellation, you just cancel the task once


00:17:57.020 --> 00:18:01.700
and it gets a canceled error erased in the task.


00:18:01.700 --> 00:18:04.540
So you can ignore it,


00:18:04.540 --> 00:18:07.060
which is by the way, a bad thing to do,


00:18:07.060 --> 00:18:11.180
but then the task won't be canceled again, usually.


00:18:13.300 --> 00:18:19.220
There are exceptions to this which are a topic of debate in the community.


00:18:19.220 --> 00:18:28.120
But the cancelled scope basically, they define boundaries for cancellation.


00:18:28.120 --> 00:18:38.540
So if you say you cancel a task group's cancelled scope, only the tasks started from that task


00:18:38.540 --> 00:18:39.940
group are cancelled.


00:18:39.940 --> 00:18:43.440
So when those tasks return back,


00:18:43.440 --> 00:18:47.580
so all the tasks are done,


00:18:47.580 --> 00:18:51.180
then the code just goes forward


00:18:51.180 --> 00:18:53.800
from this async context manager.


00:18:53.800 --> 00:19:00.020
Basically, when all the tasks are done,


00:19:00.020 --> 00:19:04.860
then however they end,


00:19:04.860 --> 00:19:08.260
unless some raised exceptions,


00:19:08.260 --> 00:19:09.860
that's a different situation.


00:19:09.860 --> 00:19:13.220
If they were either canceled or successful,


00:19:13.220 --> 00:19:16.320
then the code just goes forward


00:19:16.320 --> 00:19:18.220
to the all tasks finished part.


00:19:18.220 --> 00:19:20.260
Okay.


00:19:20.260 --> 00:19:21.100
- This is really neat.


00:19:21.100 --> 00:19:24.180
The other thing that's standing out here


00:19:24.180 --> 00:19:25.820
as I think about these task groups.


00:19:25.820 --> 00:19:27.020
So for those of you listening,


00:19:27.020 --> 00:19:28.560
you can just create an async with block


00:19:28.560 --> 00:19:30.220
to create the task group.


00:19:30.220 --> 00:19:32.900
And then in there, you can just say task group.start soon


00:19:32.900 --> 00:19:37.900
and give it a bunch of async methods to start running.


00:19:37.900 --> 00:19:38.980
Right?


00:19:38.980 --> 00:19:43.760
The thing that's cool about this is it automatically waits for them all to be finished at the end


00:19:43.760 --> 00:19:45.800
of that context manager, the with block.


00:19:45.800 --> 00:19:49.240
The standard library task groups work the same way, actually.


00:19:49.240 --> 00:19:50.240
Okay.


00:19:50.240 --> 00:19:51.240
And those are in 3.11?


00:19:51.240 --> 00:19:52.240
Yes.


00:19:52.240 --> 00:19:53.240
Uh-huh.


00:19:53.240 --> 00:19:58.200
Which is not out yet, but October is coming very soon.


00:19:58.200 --> 00:19:59.960
Yep.


00:19:59.960 --> 00:20:03.720
We'll see how the mechanism will work.


00:20:03.720 --> 00:20:09.840
There's a new mechanism for cancellation called uncancellation of tasks.


00:20:09.840 --> 00:20:11.520
It's not really battle-tested.


00:20:11.520 --> 00:20:23.680
It's something that was added fairly late in the game to 3.11, so it's not yet clear


00:20:23.680 --> 00:20:27.160
if there are edge cases where it fails totally.


00:20:27.160 --> 00:20:31.580
This is also a debated topic in the community.


00:20:31.580 --> 00:20:36.300
- Sure, the other thing here that I wanted to ask you about


00:20:36.300 --> 00:20:40.680
is you don't say like create task.


00:20:40.680 --> 00:20:43.520
- Right, so this is the model.


00:20:43.520 --> 00:20:44.640
- You say start soon.


00:20:44.640 --> 00:20:48.280
Why do you say, what's this like uncertainty about?


00:20:48.280 --> 00:20:49.120
Tell us about that.


00:20:49.120 --> 00:20:49.940
- Yeah, yeah, yeah.


00:20:49.940 --> 00:20:52.520
So start soon, it's actually,


00:20:52.520 --> 00:20:55.040
it does the same thing as create a task


00:20:55.040 --> 00:20:58.500
because creating task doesn't start running it right away.


00:20:58.500 --> 00:21:00.500
It starts only running it on the,


00:21:00.500 --> 00:21:04.080
perhaps on the next iteration of the event loop.


00:21:04.080 --> 00:21:04.920
- Right, or maybe not.


00:21:04.920 --> 00:21:06.340
Maybe the event loop's all backed up.


00:21:06.340 --> 00:21:09.300
Maybe it's the, you know, it takes a while, right?


00:21:09.300 --> 00:21:14.300
- Yeah, so it's basically the same as loop.callSoon.


00:21:14.300 --> 00:21:15.920
So you schedule a callback.


00:21:15.920 --> 00:21:17.300
That's all that tasks are.


00:21:17.300 --> 00:21:20.860
They are callbacks with bells and whistles.


00:21:22.960 --> 00:21:27.680
So start soon is modeled based on Trio,


00:21:27.680 --> 00:21:32.680
but I should mention that there's also a method called start


00:21:32.680 --> 00:21:34.680
which works a bit differently.


00:21:34.680 --> 00:21:39.440
Yeah, this showcases the start method.


00:21:39.440 --> 00:21:42.400
So this is very, very useful,


00:21:42.400 --> 00:21:45.960
which this feature is not present


00:21:45.960 --> 00:21:48.640
in the standard library task groups.


00:21:48.640 --> 00:21:52.760
So basically it's very useful starting a background service


00:21:52.760 --> 00:21:57.040
that you need to know that the task has actually started


00:21:57.040 --> 00:21:58.040
before you move on.


00:21:58.040 --> 00:21:59.160
- Right.


00:21:59.160 --> 00:22:01.380
So an example that you have in the docs here


00:22:01.380 --> 00:22:02.960
is you create a task group


00:22:02.960 --> 00:22:04.680
and the first thing is to start a service


00:22:04.680 --> 00:22:05.840
that's listening on a port.


00:22:05.840 --> 00:22:09.200
The next thing is to talk to that service on the port.


00:22:09.200 --> 00:22:10.040
- Yeah.


00:22:10.040 --> 00:22:11.640
- And if you just say, kick them both off,


00:22:11.640 --> 00:22:13.400
who knows if that thing is actually gonna be ready


00:22:13.400 --> 00:22:15.500
by the time you try to talk to it.


00:22:15.500 --> 00:22:16.760
- Exactly.


00:22:16.760 --> 00:22:20.200
This is something I use in practice all the time.


00:22:20.200 --> 00:22:22.020
- And this is different than what you would get


00:22:22.020 --> 00:22:25.200
just with the async.io create task or whatever, right?


00:22:25.200 --> 00:22:29.620
- Yeah, and even the new task group feature


00:22:29.620 --> 00:22:30.760
doesn't have this.


00:22:30.760 --> 00:22:34.500
- So I guess you could, in the standard library,


00:22:34.500 --> 00:22:38.380
you could start it and then you would have to just wait,


00:22:38.380 --> 00:22:40.760
you know, wait for it to finish,


00:22:40.760 --> 00:22:41.900
and then you would carry on,


00:22:41.900 --> 00:22:44.100
but it's like two steps, right?


00:22:44.100 --> 00:22:49.100
- The workaround would be to create a future,


00:22:49.420 --> 00:22:54.420
then pass that to the task and then wait on that future.


00:22:54.420 --> 00:22:56.620
So it's a bit cumbersome.


00:22:56.620 --> 00:22:59.880
And then you have to remember to use a try,


00:22:59.880 --> 00:23:03.260
except in case that that task happens to fail,


00:23:03.260 --> 00:23:05.820
otherwise you end up waiting on the future forever.


00:23:05.820 --> 00:23:09.740
- I really like this idea.


00:23:09.740 --> 00:23:13.060
Now, the other thing that I don't see


00:23:13.060 --> 00:23:14.660
in your examples here,


00:23:14.660 --> 00:23:16.980
where I'm creating a task group and starting these tasks


00:23:16.980 --> 00:23:18.060
and waiting for them to finish


00:23:18.060 --> 00:23:22.740
is management of the event loop.


00:23:22.740 --> 00:23:24.620
If I was doing it with my code, I'd probably


00:23:24.620 --> 00:23:27.340
have to create a group or a loop and then


00:23:27.340 --> 00:23:28.500
call some functions on it.


00:23:28.500 --> 00:23:34.740
And here, you just use any I/O. Where's


00:23:34.740 --> 00:23:38.540
the event loop being managed?


00:23:38.540 --> 00:23:39.340
I'm not sure.


00:23:39.340 --> 00:23:41.220
What do you mean?


00:23:41.220 --> 00:23:44.740
Well, a lot of times when you're doing async stuff,


00:23:44.740 --> 00:23:47.380
you have to go and actually create an async event loop


00:23:47.380 --> 00:23:49.540
and then use the loop directly.


00:23:49.540 --> 00:23:52.780
And you're working with a loop for various things.


00:23:52.780 --> 00:23:56.580
>> Well, there is that run command at the bottom.


00:23:56.580 --> 00:23:57.500
>> Yeah, yeah, OK.


00:23:57.500 --> 00:24:01.180
So basically, you just say any I/O dot run.


00:24:01.180 --> 00:24:04.260
>> Or async I/O dot run.


00:24:04.260 --> 00:24:08.100
>> OK, and even though I'm using the any I/O task groups,


00:24:08.100 --> 00:24:10.300
I can still just--


00:24:10.300 --> 00:24:13.860
I can mix and match this with more standard async I/O


00:24:13.860 --> 00:24:15.180
movement loops?


00:24:15.180 --> 00:24:16.140
>> That's the premise.


00:24:16.140 --> 00:24:20.700
So you can just ease into it little by little.


00:24:20.700 --> 00:24:22.660
>> Nice. Yeah. So for example,


00:24:22.660 --> 00:24:26.500
if I have a FastAPI web app,


00:24:26.500 --> 00:24:31.400
and FastAPI is in charge of managing the event loop,


00:24:31.400 --> 00:24:33.640
and I've got an async API endpoint,


00:24:33.640 --> 00:24:35.220
I could still go and use


00:24:35.220 --> 00:24:39.220
an Any.IO task group and get all the benefits in there.


00:24:39.220 --> 00:24:44.340
>> Yeah. I should mention that FastAPI also depends on Any.IO.


00:24:44.340 --> 00:24:45.340
Oh, really?


00:24:45.340 --> 00:24:46.340
Okay.


00:24:46.340 --> 00:24:47.340
How interesting.


00:24:47.340 --> 00:24:54.060
Yeah, I've seen Sebastian Ramirez talking about some little functions that he wrote.


00:24:54.060 --> 00:24:56.860
He's like, "I would love to see these just get back into any I/O.


00:24:56.860 --> 00:25:02.100
I didn't realize that FastAPI itself was using them."


00:25:02.100 --> 00:25:04.100
Yeah.


00:25:04.100 --> 00:25:08.660
Okay, so very useful.


00:25:08.660 --> 00:25:10.460
We've got these task groups.


00:25:10.460 --> 00:25:14.100
We've got the concept of cancellation.


00:25:14.100 --> 00:25:18.900
one that's not exactly cancellation, but is sort of cancellation, is timeouts.


00:25:18.900 --> 00:25:21.620
Do you want to talk about how you do timeouts?


00:25:21.620 --> 00:25:29.060
>> Yeah, I meant to talk about that. As I recall, in Python 3.11, there is a similar


00:25:29.060 --> 00:25:36.660
construct. I think it was with timeout or something similar. I don't remember, really.


00:25:37.460 --> 00:25:46.660
But what this move on after does is it creates a cancel scope with a timeout.


00:25:46.660 --> 00:25:54.180
So basically this is a very practical use of cancel scopes.


00:25:54.180 --> 00:26:03.300
What it does is it starts a timer and after one second it cancels this scope.


00:26:03.860 --> 00:26:07.860
So anything under that gets cancelled.


00:26:07.860 --> 00:26:13.060
So in this case, just that the sleep command gets cancelled


00:26:13.060 --> 00:26:16.500
and then the task just keeps going.


00:26:16.500 --> 00:26:23.220
So that way you described it before, it sounds like if there was a bunch of tasks running,


00:26:23.220 --> 00:26:27.460
if any of them try to await something, they're also going to get cancelled.


00:26:27.460 --> 00:26:29.800
Is that right?


00:26:29.800 --> 00:26:32.260
In this case, you mean?


00:26:32.980 --> 00:26:39.700
Yeah. No, only only the part that is within the week block.


00:26:39.700 --> 00:26:45.300
Right. Well, that's what I mean. But if you had done multiple tasks within like the move on after,


00:26:45.300 --> 00:26:50.020
right, like I say, I try to talk to the database, it's an inserted record. And I try to call an API


00:26:50.020 --> 00:26:55.460
in the database times. Right, so so whatever whatever is awaiting when.


00:27:17.460 --> 00:27:19.460
Alex, did we lose you?


00:27:19.460 --> 00:27:23.940
[AUDIO OUT]


00:27:23.940 --> 00:27:24.440
Hey, Alex.


00:27:24.440 --> 00:27:24.940
Hey, Alex.


00:27:24.940 --> 00:27:26.940
Are you here now?


00:27:26.940 --> 00:27:27.440
Yes.


00:27:27.440 --> 00:27:28.740
Yes, yes, I do hear you now.


00:27:28.740 --> 00:27:29.240
Yeah, sorry.


00:27:29.240 --> 00:27:31.540
[INTERPOSING VOICES]


00:27:31.540 --> 00:27:36.460
Yeah, my headphones, they fizzle out sometimes.


00:27:36.460 --> 00:27:37.900
Sorry about that.


00:27:37.900 --> 00:27:38.540
Yeah, no worries.


00:27:38.540 --> 00:27:39.100
Yeah, no worries.


00:27:39.100 --> 00:27:40.140
I'm trying to get them back.


00:27:40.140 --> 00:27:41.860
Actually, there's a pretty serious echo.


00:27:41.860 --> 00:27:46.100
Can you turn down the speakers, maybe?


00:27:46.100 --> 00:27:48.300
OK, are you hearing me now?


00:27:48.300 --> 00:27:49.140
I hear you good.


00:27:49.140 --> 00:27:50.340
And I don't hear myself.


00:27:50.340 --> 00:27:52.020
Perfect.


00:27:52.020 --> 00:27:52.520
Sorry.


00:27:52.520 --> 00:27:53.500
Yeah, let's carry on.


00:27:53.500 --> 00:27:54.500
We'll just edit that out.


00:27:54.500 --> 00:27:55.660
Sorry, YouTube, it's live.


00:27:55.660 --> 00:27:56.700
It's going to stay there.


00:27:56.700 --> 00:27:58.940
But for the other audio, we'll edit that out.


00:27:58.940 --> 00:28:01.180
OK, so you were telling me, but what


00:28:01.180 --> 00:28:03.180
happens if I have multiple things going on


00:28:03.180 --> 00:28:05.420
and it times out?


00:28:05.420 --> 00:28:11.180
Yeah, so within a single move on after block,


00:28:11.180 --> 00:28:13.460
you can only have one thing going on,


00:28:13.460 --> 00:28:15.220
which is the wait here.


00:28:15.220 --> 00:28:19.060
So even if you start multiple tasks from that task group,


00:28:19.060 --> 00:28:24.380
they are not enclosed within that cancel scope.


00:28:24.380 --> 00:28:27.860
I realize that cancel scopes are a complex and difficult


00:28:27.860 --> 00:28:33.260
concept, and I don't think I can adequately explain them.


00:28:33.260 --> 00:28:39.340
But I hope that this will at least shed some light


00:28:39.340 --> 00:28:40.580
into them.


00:28:40.580 --> 00:28:42.380
Yeah.


00:28:42.380 --> 00:28:48.300
Well, it's a really cool idea because your code could--


00:28:48.300 --> 00:28:53.180
it's async, so it's not as bad as if you were to lock up


00:28:53.180 --> 00:28:55.960
waiting for an API call or something that's


00:28:55.960 --> 00:28:57.900
going to time out on the network eventually


00:28:57.900 --> 00:29:00.660
after a really long time.


00:29:00.660 --> 00:29:04.740
But it's still-- you don't want it to clog up your code, right?


00:29:04.740 --> 00:29:07.420
You want to just say, sorry, this isn't working.


00:29:07.420 --> 00:29:08.980
Yeah.


00:29:08.980 --> 00:29:12.180
One place where I often use constructs like this


00:29:12.180 --> 00:29:23.060
is finalization. So when you are closing up things, then you can use this move on effort


00:29:23.060 --> 00:29:33.140
to set a timeout for closing resources. Yeah, that makes sense because you want to be a good


00:29:33.140 --> 00:29:38.500
citizen in terms of your app and release the resources as soon as possible, like a database


00:29:38.500 --> 00:29:45.620
connection or a file handle. But if it's not working, you know, like, "Oh, I made a try at


00:29:45.620 --> 00:29:52.580
it after a second. We're done." Exactly. And also, I should mention that this is where NEI's biggest


00:29:52.580 --> 00:30:01.700
caveat lies. It is in finalization. I often run into problems with the cancel scopes because


00:30:03.300 --> 00:30:12.100
The thing with cancel scopes is that when you run code within a cancel scope and that scope gets


00:30:12.100 --> 00:30:19.300
cancelled, then anything awaiting on anything within that cancel scope is always cancelled


00:30:19.300 --> 00:30:24.580
time after time. So you cannot wait on anything as long as you are within the cancel scope.


00:30:25.380 --> 00:30:29.780
and async.io code is not expecting that.


00:30:29.780 --> 00:30:35.420
So it might have a final clause where it does await,


00:30:35.420 --> 00:30:37.860
say, connection.close.


00:30:37.860 --> 00:30:42.340
But that also gets canceled if you are within an NEIO cancel scope.


00:30:42.340 --> 00:30:47.740
And it's one of the biggest practical issues with NEIO right now.


00:30:47.740 --> 00:30:53.140
And we are trying to figure out the solution for that.


00:30:54.420 --> 00:31:00.420
just something to keep in mind when you are writing your stuff.


00:31:00.420 --> 00:31:04.900
But yeah, that is tricky, right? Because you say, well, I'm going to try to call this


00:31:04.900 --> 00:31:10.900
this web service and I'm going to wait it. And if it fails, you know, probably internally,


00:31:10.900 --> 00:31:13.380
what you want to do is close the network connection as well.


00:31:13.380 --> 00:31:17.220
Right. But if you try to await closing networks, that connection.


00:31:17.220 --> 00:31:22.260
Yeah. So what happens there? Does it eventually just get cleaned up by the garbage collector?


00:31:24.180 --> 00:31:32.020
Well, garbage collector doesn't work that well with async stuff because the destructors could be called in any thread.


00:31:32.020 --> 00:31:39.140
So you can't rely on that. You can't do any async callbacks in the destructor.


00:31:39.140 --> 00:31:45.060
So it's a good idea not to try any of that and instead just raise a resource warning.


00:31:45.060 --> 00:31:54.620
So if you're writing any I/O where code, you would have either this shielded cancel scope,


00:31:54.620 --> 00:32:01.380
or better yet, a move on after which shield true.


00:32:01.380 --> 00:32:05.380
What does that do?


00:32:05.380 --> 00:32:11.380
That at least temporarily protects the task from cancellation.


00:32:11.380 --> 00:32:17.940
So let's say you have move on after say five and we shield true.


00:32:17.940 --> 00:32:22.140
It means that even if the auto-cancel scope is canceled,


00:32:22.140 --> 00:32:25.540
your actual task will start running until it exits


00:32:25.540 --> 00:32:30.180
that cancel scope or if the timeout expires.


00:32:30.180 --> 00:32:36.380
So you have a five-second window to close any resources that need closing.


00:32:36.380 --> 00:32:39.420
>> Got it. So you could do that,


00:32:39.420 --> 00:32:43.260
say, within your exception handler or something, right?


00:32:43.260 --> 00:32:44.340
- Yeah.


00:32:44.340 --> 00:32:45.340
- Okay.


00:32:45.340 --> 00:32:48.460
- Or actually, I think finally,


00:32:48.460 --> 00:32:52.000
a finally block might be the best place to do that.


00:32:52.000 --> 00:32:55.360
But depending on the audio use case, of course.


00:32:55.360 --> 00:32:56.680
- Yeah, of course.


00:32:56.680 --> 00:32:58.100
Okay, very interesting.


00:32:58.100 --> 00:33:00.260
So all this stuff about task groups


00:33:00.260 --> 00:33:02.240
and scheduling tasks and canceling them,


00:33:02.240 --> 00:33:04.300
that's very Trio-esque,


00:33:04.300 --> 00:33:08.540
but it's also just a small part of any I/O.


00:33:08.540 --> 00:33:11.660
There's a bunch of other features and capabilities here


00:33:11.660 --> 00:33:14.380
that are probably worth going into.


00:33:14.380 --> 00:33:18.900
Some cool stuff about taking AsyncIO code


00:33:18.900 --> 00:33:21.900
and converting it to threads or converting threads to AsyncIO,


00:33:21.900 --> 00:33:23.900
and similarly for subprocesses.


00:33:23.900 --> 00:33:27.780
But let's maybe just talk real quick about the synchronization primitives.


00:33:27.780 --> 00:33:31.540
These are things like events, semaphores.


00:33:31.540 --> 00:33:35.620
Maybe not everyone knows what events and semaphores are in this context.


00:33:35.620 --> 00:33:37.180
Give us a quick rundown.


00:33:37.180 --> 00:33:38.820
Well, these are pretty much the same


00:33:38.820 --> 00:33:40.860
as they are on async I/O.


00:33:40.860 --> 00:33:44.380
Many of them use just the async I/O counterparts


00:33:44.380 --> 00:33:45.260
straight up.


00:33:45.260 --> 00:33:50.260
So events are a mechanism for telling another task


00:33:50.260 --> 00:33:53.620
that something happened,


00:33:53.620 --> 00:33:55.980
something significant happened,


00:33:55.980 --> 00:33:57.480
and they need to react to it.


00:33:57.480 --> 00:34:00.920
It's often used to coordinate tasks.


00:34:00.920 --> 00:34:05.720
So one thing doesn't happen before something else


00:34:05.720 --> 00:34:08.000
has happened in another task.


00:34:08.000 --> 00:34:10.620
- Yeah, yeah, there might be two tasks running


00:34:10.620 --> 00:34:14.600
and one says, I'm gonna wait until this file appears


00:34:14.600 --> 00:34:17.320
and the other one's going to eventually create the file,


00:34:17.320 --> 00:34:19.440
right, but you don't know the order.


00:34:19.440 --> 00:34:20.280
- Yeah.


00:34:20.280 --> 00:34:22.920
- So one option is to just do polling,


00:34:22.920 --> 00:34:26.640
like, well, I'm gonna asyncio.sleep for a little while


00:34:26.640 --> 00:34:28.240
and then see if the file's there,


00:34:28.240 --> 00:34:30.760
try to access it, you know, and do that over and over.


00:34:30.760 --> 00:34:35.040
A much more responsive way and deterministic way


00:34:35.040 --> 00:34:38.800
would be to say, I'm going to wait on an event to be set.


00:34:38.800 --> 00:34:41.040
And the thing that creates a file will create the file


00:34:41.040 --> 00:34:43.360
and then set the event, which will kind of release


00:34:43.360 --> 00:34:45.680
that other task to carry on, right?


00:34:45.680 --> 00:34:46.520
- Right.


00:34:46.520 --> 00:34:48.280
- Okay.


00:34:48.280 --> 00:34:49.920
- Right.


00:34:49.920 --> 00:34:56.320
Moving on, semaphores are mechanism for saying


00:34:56.320 --> 00:35:01.560
that you have this limited, you have a number limit.


00:35:03.840 --> 00:35:06.680
let's say a connection pool or something.


00:35:06.680 --> 00:35:11.680
And you want to specify that whenever


00:35:11.680 --> 00:35:17.380
some part of the code needs access to this resource,


00:35:17.380 --> 00:35:20.820
it needs to acquire the semaphore.


00:35:20.820 --> 00:35:26.620
So you set a limit and then each time


00:35:26.620 --> 00:35:31.620
that's entered as a semaphore, it decrements the counter.


00:35:31.660 --> 00:35:35.740
And when you hit the limit,


00:35:35.740 --> 00:35:40.460
then it starts blocking until something else releases it.


00:35:40.460 --> 00:35:45.020
- Right, so people might be familiar with threadlocks


00:35:45.020 --> 00:35:47.340
or asyncios equivalent,


00:35:47.340 --> 00:35:50.940
where you say only one thing can access this at a time.


00:35:50.940 --> 00:35:52.380
So you don't end up with deadlocks


00:35:52.380 --> 00:35:55.100
or race conditions and so on.


00:35:55.100 --> 00:35:56.980
But semaphores are kind of like that,


00:35:56.980 --> 00:35:59.340
but they allow multiple things to happen.


00:35:59.340 --> 00:36:02.100
Say maybe your database only allows 10 connections


00:36:02.100 --> 00:36:04.180
or you don't want it to have more than 10 connections.


00:36:04.180 --> 00:36:06.900
So you could have a semaphore that says


00:36:06.900 --> 00:36:09.860
it has a limit of 10 and you have to acquire it


00:36:09.860 --> 00:36:11.000
to talk to the database.


00:36:11.000 --> 00:36:12.980
That doesn't mean it stops multiple things


00:36:12.980 --> 00:36:13.820
from happening at once.


00:36:13.820 --> 00:36:16.680
It just doesn't let it become a thousand at once, right?


00:36:16.680 --> 00:36:21.020
- Exactly.


00:36:21.020 --> 00:36:22.180
- I really like this idea.


00:36:22.180 --> 00:36:26.260
And you know, I was showing some people


00:36:26.260 --> 00:36:30.580
some web scraping work with asyncio,


00:36:30.580 --> 00:36:32.260
where it's like, oh, let's go create a whole bunch


00:36:32.260 --> 00:36:37.260
of ACPX requests or whatever type of requests,


00:36:37.260 --> 00:36:40.740
something asynchronous, talking to some servers


00:36:40.740 --> 00:36:43.860
to download some code, and if it's a limited set,


00:36:43.860 --> 00:36:47.320
no big deal, but if you have thousands of URLs to go hit,


00:36:47.320 --> 00:36:51.420
well then how do you manage not killing your network


00:36:51.420 --> 00:36:52.540
or overloading that?


00:36:52.540 --> 00:36:54.540
The semaphore actually would be perfect.


00:36:56.060 --> 00:36:57.940
- So for people listening, the way that you do it


00:36:57.940 --> 00:37:00.220
is you create a task group and then just you pass


00:37:00.220 --> 00:37:01.940
the semaphore to start soon.


00:37:01.940 --> 00:37:03.000
That's really clean.


00:37:03.000 --> 00:37:07.820
And any I/O takes care of just making sure it gets access


00:37:07.820 --> 00:37:10.020
and then runs and then gives it back?


00:37:10.020 --> 00:37:10.860
How's that work?


00:37:10.860 --> 00:37:20.260
- I'm not sure what sort of answer you are expecting,


00:37:20.260 --> 00:37:25.180
but as I recall, this current implementation


00:37:25.180 --> 00:37:30.180
is actually using the underlying async libraries events.


00:37:30.180 --> 00:37:34.540
So there are actually methods to acquire


00:37:34.540 --> 00:37:36.500
and release the semaphores.


00:37:36.500 --> 00:37:45.700
And it just implements an async context manager


00:37:45.700 --> 00:37:48.900
that acquires it at the beginning


00:37:48.900 --> 00:37:51.420
and releases it at the end.


00:37:52.900 --> 00:37:57.900
There's an event involved for notifying any awaiting task


00:37:57.900 --> 00:38:02.940
that it has a semaphore slot available.


00:38:02.940 --> 00:38:07.240
- Yeah, it's super clean.


00:38:07.240 --> 00:38:08.960
And the fact that you don't have to write that code,


00:38:08.960 --> 00:38:12.360
you just say this semaphore is associated with this task


00:38:12.360 --> 00:38:13.240
through your task group?


00:38:13.240 --> 00:38:16.560
- Actually, actually semaphores are not associated


00:38:16.560 --> 00:38:17.640
with a particular task.


00:38:17.640 --> 00:38:20.140
That's what capacity limiters are for.


00:38:20.140 --> 00:38:22.480
- Okay.


00:38:22.480 --> 00:38:25.940
So you can release a semaphore from another task


00:38:25.940 --> 00:38:31.880
while capacity limiters are bound to the specific task


00:38:31.880 --> 00:38:33.520
that you acquired them in.


00:38:33.520 --> 00:38:37.320
- Okay.


00:38:37.320 --> 00:38:39.840
Yeah, in the semaphore example, was it being passed?


00:38:39.840 --> 00:38:42.200
Oh yeah, it's just being passed as an argument, isn't it?


00:38:42.200 --> 00:38:46.000
To the task and it's up to the task to use it.


00:38:46.000 --> 00:38:49.320
I see, okay, so this other concept, the capacity limiter.


00:38:50.840 --> 00:38:53.800
- Yeah, so this is from Trio.


00:38:53.800 --> 00:38:57.440
It's very similar to Semaphore.


00:38:57.440 --> 00:39:01.460
So you can actually set the borrower,


00:39:01.460 --> 00:39:04.640
but in most circumstances,


00:39:04.640 --> 00:39:07.940
you want the current task to be the borrower.


00:39:07.940 --> 00:39:12.940
And limiters are actually used in other parts of any I/O


00:39:12.940 --> 00:39:16.020
as they are in Trio, for example,


00:39:16.020 --> 00:39:19.660
to limit the number of threads that you allocate


00:39:19.660 --> 00:39:24.220
or limit number of subprocesses that you spawn.


00:39:24.220 --> 00:39:25.060
- Sure.


00:39:25.060 --> 00:39:28.220
- But they're using-- - You don't have too many threads,


00:39:28.220 --> 00:39:30.060
you don't have too many subprocesses, right?


00:39:30.060 --> 00:39:33.100
You've got a thousand jobs and you just for each thing a job


00:39:33.100 --> 00:39:35.860
start it in a subprocess, you're gonna have a bad time.


00:39:35.860 --> 00:39:41.580
- Right, so as documentation says,


00:39:41.580 --> 00:39:44.260
they are quite like semaphores,


00:39:44.260 --> 00:39:46.780
but they have additional safeguards.


00:39:49.420 --> 00:39:50.260
- Such as?


00:39:50.260 --> 00:39:54.380
- Well, they check that the borrow is the same.


00:39:54.380 --> 00:39:57.820
- Okay, yeah, that makes sense.


00:39:57.820 --> 00:40:02.820
- By default, they check that the task they use


00:40:02.820 --> 00:40:06.180
for both acquiring or releasing are the same.


00:40:06.180 --> 00:40:09.940
- Yeah, nice.


00:40:09.940 --> 00:40:13.220
Okay, well, I didn't know about capacity limiters.


00:40:13.220 --> 00:40:14.500
That's fantastic.


00:40:14.500 --> 00:40:15.340
I love the idea.


00:40:15.340 --> 00:40:18.980
Okay, let's jump over to,


00:40:18.980 --> 00:40:22.780
You talked about the threads and the subprocesses.


00:40:22.780 --> 00:40:26.740
Let's talk about this thread capability


00:40:26.740 --> 00:40:27.580
that you have here.


00:40:27.580 --> 00:40:29.260
This is very nice.


00:40:29.260 --> 00:40:32.120
The anyio.toThread, what is this?


00:40:32.120 --> 00:40:36.280
- Yeah, so this is also modeled based on Trio.


00:40:36.280 --> 00:40:43.340
It's basically anyio's way of doing WordPress threads.


00:40:47.020 --> 00:40:52.020
So in async.io, you have these thread pool executors


00:40:52.020 --> 00:40:58.340
that do the same as run sync.


00:40:58.340 --> 00:41:03.940
Async.io's API is somewhat problematic


00:41:03.940 --> 00:41:06.860
because you have basically two methods.


00:41:06.860 --> 00:41:11.860
So you have, I forget the older one.


00:41:11.860 --> 00:41:14.820
The newer one is called to_thread.


00:41:14.820 --> 00:41:24.820
The first one was, was it run in executor or whatever it was.


00:41:24.820 --> 00:41:27.820
They both had their own issues.


00:41:27.820 --> 00:41:35.820
ToTread doesn't allow you to specify any thread pool, so it always uses the default thread pool.


00:41:35.820 --> 00:41:40.820
And there is no way to add that to the API because it was done in such a manner.


00:41:40.820 --> 00:41:48.820
Then the older function does have this parameter at the front.


00:41:48.820 --> 00:41:57.820
But the problem is that it doesn't propagate context variables, unlike the newer toThread function.


00:41:57.820 --> 00:42:07.820
So context variables, if you don't know about them, they are a fairly recent addition to Python.


00:42:07.820 --> 00:42:12.820
- They are basically thread locals.


00:42:12.820 --> 00:42:16.200
Are you familiar with thread locals?


00:42:16.200 --> 00:42:18.180
They are thread locals but--


00:42:18.180 --> 00:42:20.100
- Yeah, but let me just make a comment


00:42:20.100 --> 00:42:21.020
for people who don't know.


00:42:21.020 --> 00:42:25.000
Like thread local variables, which also exist in Python,


00:42:25.000 --> 00:42:28.900
allow you to say, I'm gonna have a variable,


00:42:28.900 --> 00:42:31.040
maybe it's even a global variable,


00:42:31.040 --> 00:42:33.380
and it's thread local, which means every thread


00:42:33.380 --> 00:42:37.700
that sees it gets its own copy of the variable,


00:42:37.700 --> 00:42:40.020
where it points to and what value it is.


00:42:40.020 --> 00:42:42.380
And so that way you can initialize something


00:42:42.380 --> 00:42:43.820
at the start of a thread.


00:42:43.820 --> 00:42:44.740
If you have multiple threads,


00:42:44.740 --> 00:42:46.820
they can all kind of have their own copy


00:42:46.820 --> 00:42:48.140
so they don't have to share it.


00:42:48.140 --> 00:42:52.180
But that falls down because asyncio event loops,


00:42:52.180 --> 00:42:54.100
when you await those, all that stuff is running


00:42:54.100 --> 00:42:57.660
on one thread, just the one that's running the loop, right?


00:42:57.660 --> 00:43:00.220
So that's what you're talking about is that equivalent,


00:43:00.220 --> 00:43:03.780
but for asyncio, right?


00:43:03.780 --> 00:43:05.620
- Yeah, so quantified variables


00:43:05.620 --> 00:43:07.340
are a much more advanced concept.


00:43:07.340 --> 00:43:11.160
They basically, yeah, as you said,


00:43:11.160 --> 00:43:13.420
set locals for async tasks.


00:43:13.420 --> 00:43:16.120
So--


00:43:16.120 --> 00:43:17.060
- That sounds very tricky.


00:43:17.060 --> 00:43:17.900
I've thought about that.


00:43:17.900 --> 00:43:20.020
I have no idea how to implement that.


00:43:20.020 --> 00:43:20.980
So that's pretty cool.


00:43:20.980 --> 00:43:22.280
I guess Python would know.


00:43:22.280 --> 00:43:26.380
- Yeah, the thing is the event loop,


00:43:26.380 --> 00:43:28.680
when it starts running a task,


00:43:28.680 --> 00:43:31.260
when it switches between tasks,


00:43:31.260 --> 00:43:36.260
it runs that callback within that context


00:43:37.100 --> 00:43:40.540
that the task is tied to.


00:43:40.540 --> 00:43:45.540
And when you start to work with worker threads,


00:43:45.540 --> 00:43:48.540
then you need to see the same context variables


00:43:48.540 --> 00:43:50.040
in that worker set, right?


00:43:50.040 --> 00:43:52.820
- Right.


00:43:52.820 --> 00:43:56.900
- So this has been somewhat of a problem


00:43:56.900 --> 00:44:01.900
because that older method in AsyncIO


00:44:01.900 --> 00:44:03.980
for running worker threads,


00:44:03.980 --> 00:44:06.700
it doesn't propagate these variables.


00:44:06.700 --> 00:44:10.600
but the newer function to thread does.


00:44:10.600 --> 00:44:17.220
But then you can specify which thread pool you want to use.


00:44:17.220 --> 00:44:22.520
- Right, okay, so it's similar to the built-in one,


00:44:22.520 --> 00:44:24.380
but it gives you more capability


00:44:24.380 --> 00:44:26.440
to determine where you might run it.


00:44:26.440 --> 00:44:32.140
- Yeah, so basically when you call run sync,


00:44:32.140 --> 00:44:35.820
it allows you to specify a limiter.


00:44:35.820 --> 00:44:37.860
and it uses the default limiter,


00:44:37.860 --> 00:44:41.120
which has a capacity of 40 threads.


00:44:41.120 --> 00:44:43.460
- 40?


00:44:43.460 --> 00:44:44.300
- Yeah, 40.


00:44:44.300 --> 00:44:46.600
- That seems like a pretty good default.


00:44:46.600 --> 00:44:51.180
Much more than that, and you end up with memory and--


00:44:51.180 --> 00:44:54.960
- Yeah, it's most arbitrarily set to 40,


00:44:54.960 --> 00:44:59.040
but then Nathaniel and Trio, so I just followed suit.


00:44:59.040 --> 00:44:59.880
- Sure.


00:44:59.880 --> 00:45:03.480
Yeah, so basically, if you've got some function


00:45:03.480 --> 00:45:07.700
that is not async, but you want to be able to await it


00:45:07.700 --> 00:45:10.980
so that basically run it on a background thread.


00:45:10.980 --> 00:45:13.580
Here you just say, anyio.toThread,


00:45:13.580 --> 00:45:18.980
and then .runSync, and you give it the function to call.


00:45:18.980 --> 00:45:20.380
And now you can await it,


00:45:20.380 --> 00:45:22.460
and it runs on a background thread in this thread pool,


00:45:22.460 --> 00:45:24.500
which is really nice.


00:45:24.500 --> 00:45:27.300
- Yeah, that's how it works.


00:45:27.300 --> 00:45:32.180
- So one thing that I'm noticing a lot in the API here


00:45:32.180 --> 00:45:37.180
for any I/O is often, now for the synchronous functions,


00:45:37.180 --> 00:45:39.820
it's completely obvious why you wouldn't do it,


00:45:39.820 --> 00:45:43.360
but even in the sort of creating tasks ones,


00:45:43.360 --> 00:45:48.220
what I'm noticing is that even the async functions,


00:45:48.220 --> 00:45:51.860
you pass the function name and then the arguments


00:45:51.860 --> 00:45:56.180
to like start soon, as opposed to saying,


00:45:56.180 --> 00:45:59.420
call the function, passing the arguments


00:45:59.420 --> 00:46:00.900
and getting a coroutine back.


00:46:00.900 --> 00:46:02.060
Why does it work that way?


00:46:02.060 --> 00:46:04.260
It seems like it would make it a little less easy to use,


00:46:04.260 --> 00:46:06.380
like, say, type hints and auto-complete


00:46:06.380 --> 00:46:10.780
and the various niceties of calling functions in editors.


00:46:10.780 --> 00:46:14.560
- Yeah, there was a good reason for that.


00:46:14.560 --> 00:46:17.040
I can't remember that offhand,


00:46:17.040 --> 00:46:20.480
but at the very least, it's consistent


00:46:20.480 --> 00:46:24.320
with the synchronous counterparts, like run sync.


00:46:24.320 --> 00:46:28.100
- Yeah, okay, cool.


00:46:28.100 --> 00:46:31.020
All right, so we have this stuff about threads,


00:46:31.020 --> 00:46:32.900
And you have the toThread.


00:46:32.900 --> 00:46:38.380
Yeah, also fromThread, which is nice.


00:46:38.380 --> 00:46:39.460
What's fromThread to?


00:46:39.460 --> 00:46:43.740
- Yeah, so when you are in a worker thread


00:46:43.740 --> 00:46:46.500
and you occasionally need to call something


00:46:46.500 --> 00:46:48.580
in the event loop thread,


00:46:48.580 --> 00:46:51.860
then you need to use this fromThread.run


00:46:51.860 --> 00:46:54.780
to run stuff on event loop thread.


00:46:54.780 --> 00:46:58.940
- Right, because the worker method is not async,


00:46:58.940 --> 00:47:00.300
otherwise you would just await it, right?


00:47:00.300 --> 00:47:03.020
It's a regular function.


00:47:03.020 --> 00:47:04.340
In that regular function, you want


00:47:04.340 --> 00:47:05.460
to be able to await a thing.


00:47:05.460 --> 00:47:07.060
You can kind of reverse back.


00:47:07.060 --> 00:47:07.700
I see.


00:47:07.700 --> 00:47:10.460
That's an interesting bidirectional aspect.


00:47:10.460 --> 00:47:12.820
All right, subprocesses.


00:47:12.820 --> 00:47:16.460
We all know about the GIL, how Python doesn't necessarily


00:47:16.460 --> 00:47:20.540
love doing computational work across processes.


00:47:20.540 --> 00:47:26.060
Tell us about the subprocess equivalent.


00:47:26.060 --> 00:47:44.660
Yeah, so this is a really relatively easy way to both run a task in a subprocess and then opening arbitrary executables for running asynchronously.


00:47:46.260 --> 00:47:55.140
I think Kayo has similar facilities for running async processes, but yeah, these async subprocess


00:47:55.140 --> 00:48:01.300
facilities are not really up to par with, say, multiprocessing, which has some additional


00:48:01.300 --> 00:48:10.020
niceties like, I think, shared queues and other synchronization primitives. But they are still


00:48:10.980 --> 00:48:13.380
pretty useful as they are.


00:48:13.380 --> 00:48:17.800
Yeah.


00:48:17.800 --> 00:48:32.300
So basically, you can just say, sorry, you can just say any any IO dot to process run sync, and you give it a function. And now you can await that sub process. multiprocessing.


00:48:33.500 --> 00:48:40.860
Yeah, so there are usual caveats like because they don't share memory, then


00:48:40.860 --> 00:48:48.540
you have to serialize the arguments and that could be a problem in some cases.


00:48:48.540 --> 00:48:55.740
Sure, so basically it pickles the arguments and the return values and sends them over.


00:48:55.740 --> 00:49:02.620
Yeah, it could be even so that the arguments are pickable but the return value is not


00:49:02.620 --> 00:49:07.020
which obviously causes some confusion. Yeah, yeah, absolutely.


00:49:07.020 --> 00:49:16.620
People maybe hear that pickling is bad and you can have all sorts of challenges of like


00:49:16.620 --> 00:49:22.300
code injection and whatnot from pickling through security stuff. This, I would think, is not really


00:49:22.300 --> 00:49:25.660
subject to that because it's you calling the function directly.


00:49:26.220 --> 00:49:27.860
And right, it's like,


00:49:27.860 --> 00:49:30.200
- There's no way to inject anything bad.


00:49:30.200 --> 00:49:32.820
- Yeah, exactly.


00:49:32.820 --> 00:49:35.140
It's all the multi-processing that's handled in it anyway.


00:49:35.140 --> 00:49:36.620
So it should be okay.


00:49:36.620 --> 00:49:37.820
- Yeah.


00:49:37.820 --> 00:49:39.140
- Yeah, cool.


00:49:39.140 --> 00:49:41.460
Another one that is pretty exciting


00:49:41.460 --> 00:49:44.060
has to do with file support.


00:49:44.060 --> 00:49:47.080
So we have open in Python,


00:49:47.080 --> 00:49:52.820
you would say with open something as F, right?


00:49:52.820 --> 00:49:56.020
But that's, there's no async equivalent, right?


00:49:56.020 --> 00:50:05.380
Yeah, so these file facilities are really just a convenience that wraps around these file objects.


00:50:05.380 --> 00:50:17.380
So if somebody wants to know, there is no actual async file I/O happening, because that's not really a thing on Linux,


00:50:17.380 --> 00:50:21.220
and even on Windows it has terrible problems.


00:50:22.900 --> 00:50:29.540
Okay. So what's happening with this ini.io.open file?


00:50:29.540 --> 00:50:38.500
Yeah, so it opens a file in a thread, and then this opens,


00:50:38.500 --> 00:50:43.780
this starts an AsyncContextManager that on exit closes the file.


00:50:43.780 --> 00:50:46.820
This file object--


00:50:46.820 --> 00:50:48.100
It also closes the thread, I guess, right?


00:50:49.140 --> 00:50:53.780
Well, it uses throw away threads, basically from the thread pool.


00:50:53.780 --> 00:50:56.420
All right, I see.


00:50:56.420 --> 00:51:01.260
So it'll use a thread to open the file and get the file handle and then throw away the


00:51:01.260 --> 00:51:07.740
thread and then return to the pool.


00:51:07.740 --> 00:51:13.020
Which is much better than creating it and throwing it away completely.


00:51:13.020 --> 00:51:18.540
Yeah, so also that read call is done in the thread.


00:51:18.540 --> 00:51:23.480
>> Okay. So it just is a fancy layer over top of ThreadPool.


00:51:23.480 --> 00:51:23.740
>> Yeah.


00:51:23.740 --> 00:51:24.980
>> But it's really, really nice.


00:51:24.980 --> 00:51:28.200
You write basically exactly the same code that you would


00:51:28.200 --> 00:51:34.180
write with regular open and a context manager,


00:51:34.180 --> 00:51:35.380
but the async version.


00:51:35.380 --> 00:51:36.580
Although I got to say


00:51:36.580 --> 00:51:40.720
that the opening part of creating a context manager here,


00:51:40.720 --> 00:51:42.100
you say async with,


00:51:42.100 --> 00:51:44.220
which people are probably used to,


00:51:44.220 --> 00:51:47.220
and then async with await open file.


00:51:47.220 --> 00:51:52.220
- Yeah, the reason for that is because you can just do


00:51:52.220 --> 00:51:56.580
a wait open file and then go about your business


00:51:56.580 --> 00:51:58.240
and then manually close the file.


00:51:58.240 --> 00:52:04.500
So I'm not sure if there's a more convenient way to do this.


00:52:04.500 --> 00:52:08.260
I might be open to adding that to any IO,


00:52:08.260 --> 00:52:10.640
but for the moment, this is how you do it.


00:52:10.640 --> 00:52:15.380
- Yeah, you could probably wrap it in some kind of class


00:52:15.380 --> 00:52:16.700
or something that's synchronous,


00:52:16.700 --> 00:52:19.100
but then has an A enter, but yeah, it's,


00:52:19.100 --> 00:52:22.220
I'm not sure if it's totally worth it,


00:52:22.220 --> 00:52:24.500
but yeah, that's quite the statement there.


00:52:24.500 --> 00:52:28.020
And then the other area that's interesting about this is


00:52:28.020 --> 00:52:30.660
if you wanna loop over it line for line,


00:52:30.660 --> 00:52:32.380
instead of doing a regular for loop,


00:52:32.380 --> 00:52:35.380
you can do an async for line and file


00:52:35.380 --> 00:52:38.580
and then read it asynchronously line by line, right?


00:52:38.580 --> 00:52:43.580
- Yeah, so the A next method just gets the next line


00:52:43.580 --> 00:52:46.460
in the worker thread.


00:52:46.460 --> 00:52:47.540
- Mm-hmm, yeah.


00:52:47.540 --> 00:52:49.580
Now this is fantastic.


00:52:49.580 --> 00:52:51.160
So people who are working with files,


00:52:51.160 --> 00:52:52.500
they definitely can check this out.


00:52:52.500 --> 00:52:55.720
And also related to that is you have


00:52:55.720 --> 00:52:58.220
an asynchronous pathlib path.


00:52:58.220 --> 00:53:01.500
- Yeah, that's a fairly recent addition.


00:53:01.500 --> 00:53:05.020
- Yeah, it looks great.


00:53:05.020 --> 00:53:10.760
So you have like an async iterator,


00:53:10.760 --> 00:53:12.460
you have an async, is it a file,


00:53:12.460 --> 00:53:14.980
async read text all built into the path,


00:53:14.980 --> 00:53:17.140
which is like what's built into regular path,


00:53:17.140 --> 00:53:18.260
but not asynchronous.


00:53:18.260 --> 00:53:23.760
Yeah, quite nice.


00:53:23.760 --> 00:53:27.660
Let's see, what else?


00:53:27.660 --> 00:53:29.140
We're getting kind of short on time here.


00:53:29.140 --> 00:53:31.100
What else would you like to highlight here?


00:53:31.100 --> 00:53:34.340
- I would like to highlight the streaming framework here,


00:53:34.340 --> 00:53:38.260
'cause it's one of the unique things in EIO.


00:53:38.260 --> 00:53:39.700
- Okay, yeah, let's talk about it.


00:53:39.700 --> 00:53:44.300
- Trio has its channels and then it has sockets and whatnot,


00:53:44.300 --> 00:53:48.020
but any I/O has something that Trio doesn't have.


00:53:48.020 --> 00:53:53.020
And really, AsyncIO has some kind of streaming abstraction,


00:53:53.020 --> 00:53:55.960
but not quite on this level.


00:53:55.960 --> 00:54:00.960
So in any I/O, we have a streaming


00:54:00.960 --> 00:54:04.340
abstract base class hierarchy.


00:54:04.340 --> 00:54:09.340
We have these object streams and byte streams.


00:54:13.160 --> 00:54:21.640
The difference between these are that object streams can have anything like integers, strings,


00:54:21.640 --> 00:54:30.400
any arbitrary objects, and byte streams have only bytes, and they are modeled according


00:54:30.400 --> 00:54:31.400
to TCP.


00:54:31.400 --> 00:54:38.040
So, with byte streams, you can send a number of bytes or receive bytes, but they might


00:54:38.040 --> 00:54:41.040
be chunked differently.


00:54:41.040 --> 00:54:46.040
These are abstract streams, so you can say,


00:54:46.040 --> 00:54:52.420
build a library that wraps another stream.


00:54:52.420 --> 00:54:58.880
Say you build an SSH client that creates a tunnel


00:54:58.880 --> 00:55:01.420
and it exposes that as a stream.


00:55:01.420 --> 00:55:06.820
So as so long as you are able to consume a stream,


00:55:06.820 --> 00:55:10.000
then you don't have to care how the stream is,


00:55:10.000 --> 00:55:11.820
how the stream works internally


00:55:11.820 --> 00:55:14.200
or what other streams it wraps.


00:55:14.200 --> 00:55:19.200
A good example of a stream wrapper is the TLS support.


00:55:19.200 --> 00:55:23.740
That's right there.


00:55:23.740 --> 00:55:28.740
So TLS support in any IL can wrap any existing stream


00:55:28.740 --> 00:55:34.500
that gives you bytes,


00:55:34.500 --> 00:55:36.100
even if it's an object,


00:55:36.100 --> 00:55:39.160
whether it's an object or byte stream.


00:55:39.160 --> 00:55:42.560
So it does the handshake using the standard library.


00:55:42.560 --> 00:55:45.720
Actually, standard library contains this


00:55:45.720 --> 00:55:51.300
sense I/O protocol for TLS.


00:55:51.300 --> 00:55:55.960
Sense I/O protocol, if you are not aware of it,


00:55:55.960 --> 00:56:00.760
it's basically a state machine without any actual I/O calls.


00:56:00.760 --> 00:56:04.280
It's a very neat protocol implementation


00:56:04.280 --> 00:56:07.040
that lets you add whatever kind of I/O layer


00:56:07.040 --> 00:56:08.480
you want on top of that.


00:56:08.480 --> 00:56:11.640
So this is what ADR uses to implement TLS.


00:56:11.640 --> 00:56:18.480
So you have both a listener and a connect


00:56:18.480 --> 00:56:21.280
and a TLS wrapper.


00:56:21.280 --> 00:56:25.680
So any kind of TLS,


00:56:25.680 --> 00:56:28.560
you can even do TLS on top of TLS if you like.


00:56:28.560 --> 00:56:30.880
Not sure that's useful, but you can do it.


00:56:30.880 --> 00:56:32.080
- It's super encrypted.


00:56:34.320 --> 00:56:39.320
So this is very flexible.


00:56:39.320 --> 00:56:43.560
We have all sorts of streams,


00:56:43.560 --> 00:56:45.700
even these unreliable streams,


00:56:45.700 --> 00:56:48.600
which are modeled based on UDP.


00:56:48.600 --> 00:56:51.300
- Really, okay.


00:56:51.300 --> 00:56:52.320
- Yeah.


00:56:52.320 --> 00:56:57.320
So UDP is implemented by using these unreliable streams.


00:56:57.320 --> 00:57:02.400
I don't think there are any more unreliable streams


00:57:02.400 --> 00:57:03.960
implementations on UDP.


00:57:03.960 --> 00:57:11.360
But yeah, yeah, there are,


00:57:11.360 --> 00:57:14.720
I'm really proud of this streaming class hierarchy


00:57:14.720 --> 00:57:19.720
and it's too bad that there are no cool projects


00:57:19.720 --> 00:57:23.080
to show off this system,


00:57:23.080 --> 00:57:25.160
but maybe in the future we will have.


00:57:25.160 --> 00:57:27.520
Another thing that I would like to highlight


00:57:27.520 --> 00:57:31.040
is a system of typed attributes.


00:57:31.040 --> 00:57:32.320
That has been really useful.


00:57:32.320 --> 00:57:34.720
- Before we moved on to the type attributes,


00:57:34.720 --> 00:57:36.180
let me just ask you real quickly,


00:57:36.180 --> 00:57:40.800
can I use these streams and these bi-directional streams


00:57:40.800 --> 00:57:43.740
where you create like a send stream and a receive stream,


00:57:43.740 --> 00:57:49.640
can we use those across like multi-processing


00:57:49.640 --> 00:57:51.080
or to coordinate threads?


00:57:51.080 --> 00:57:52.800
- Sadly, sadly no.


00:57:52.800 --> 00:57:53.920
Sadly no.


00:57:53.920 --> 00:57:55.280
- Okay.


00:57:55.280 --> 00:57:58.080
- This memory object stream is,


00:57:58.080 --> 00:58:00.800
as they call it in Trio Channel,


00:58:00.800 --> 00:58:05.800
This is one of the most useful pieces of any I/O, really.


00:58:05.800 --> 00:58:07.960
I use this every day at work.


00:58:07.960 --> 00:58:11.400
So these are basically cues on steroids.


00:58:11.400 --> 00:58:14.620
Unlike async I/O cues,


00:58:14.620 --> 00:58:19.740
unlike async I/O cues, you can actually close these,


00:58:19.740 --> 00:58:21.600
you can clone them.


00:58:21.600 --> 00:58:24.040
So you can have multiple tasks waiting


00:58:24.040 --> 00:58:30.140
to receive something, like workers.


00:58:30.140 --> 00:58:31.820
We have multiple senders.


00:58:31.820 --> 00:58:33.140
- Like a producer consumer where,


00:58:33.140 --> 00:58:34.420
or like some things are put in,


00:58:34.420 --> 00:58:35.700
but there's like five workers


00:58:35.700 --> 00:58:37.860
who might grab a job and work on it.


00:58:37.860 --> 00:58:39.620
- Yeah, you can have five consumers


00:58:39.620 --> 00:58:41.940
or five producers all talking to each other.


00:58:41.940 --> 00:58:47.540
Yeah, and then you can just iterate over them.


00:58:47.540 --> 00:58:49.500
Also not possible with queues.


00:58:49.500 --> 00:58:56.540
And then you can close the queues, sorry, streams,


00:58:56.540 --> 00:59:00.780
so that when you iterate on them,


00:59:00.780 --> 00:59:04.080
if all the other ints are closed,


00:59:04.080 --> 00:59:06.540
then the iterator just ends.


00:59:06.540 --> 00:59:09.380
- Oh, wow, okay.


00:59:09.380 --> 00:59:11.540
So if the send stream goes away,


00:59:11.540 --> 00:59:14.500
then the receive stream is done?


00:59:14.500 --> 00:59:16.460
It's at the end? - Yeah.


00:59:16.460 --> 00:59:18.180
- That's fantastic, actually.


00:59:18.180 --> 00:59:19.140
I really like that.


00:59:19.140 --> 00:59:22.460
- Yeah, I think this is also coming to--


00:59:22.460 --> 00:59:24.700
- Go ahead, sorry.


00:59:24.700 --> 00:59:25.520
- I think I, oh.


00:59:25.520 --> 00:59:28.120
I think this is also coming to the standard library.


00:59:28.120 --> 00:59:30.200
- Nice.


00:59:30.200 --> 00:59:33.280
All right, last thing we probably have time for here


00:59:33.280 --> 00:59:36.160
that you wanted to highlight is typed attributes.


00:59:36.160 --> 00:59:38.680
What's the story with typed attributes?


00:59:38.680 --> 00:59:43.680
- Yeah, so if you knew about the async.io extras in,


00:59:43.680 --> 00:59:48.260
I think they have both in protocols and streams.


00:59:48.260 --> 00:59:55.040
For example, with TLS, you want to get the certificate


00:59:55.320 --> 00:59:59.440
from the stream, like if you have negotiated a TLS stream,


00:59:59.440 --> 01:00:01.840
you want to get the client certificate, right?


01:00:01.840 --> 01:00:07.680
So this you can do, but this is a type set way to do it.


01:00:07.680 --> 01:00:12.060
You can add any arbitrary extra attributes to a stream,


01:00:12.060 --> 01:00:17.060
just declare it in the extra attributes method.


01:00:17.060 --> 01:00:23.840
But the niftiest part here is that it can work


01:00:23.840 --> 01:00:25.840
across RAP streams.


01:00:25.840 --> 01:00:28.920
So a very good example is that,


01:00:28.920 --> 01:00:33.800
say you have a stream that is based on HTTP,


01:00:33.800 --> 01:00:37.600
you have an HTTP server and you have a stream,


01:00:37.600 --> 01:00:39.400
let's say web sockets,


01:00:39.400 --> 01:00:44.400
then you want to get the client IP address.


01:00:44.400 --> 01:00:51.840
Well, usually you may have a front end web server


01:00:52.760 --> 01:00:54.840
like Nginx at the front.


01:00:54.840 --> 01:00:57.000
So normally what you would get


01:00:57.000 --> 01:00:58.900
when you ask for an IP address


01:00:58.900 --> 01:01:02.020
is that you actually get the IP address of the server.


01:01:02.020 --> 01:01:05.880
So what you need to do is look at the headers.


01:01:05.880 --> 01:01:09.320
So this is something you can do transparently


01:01:09.320 --> 01:01:11.720
with this type attributes.


01:01:11.720 --> 01:01:16.180
So basically the wrapping stream


01:01:16.180 --> 01:01:18.340
that understands HTTP,


01:01:19.560 --> 01:01:23.360
you can have that handle the request for the IP address,


01:01:23.360 --> 01:01:27.440
the remote IP address and have it look at the headers


01:01:27.440 --> 01:01:30.600
and look for a forwarded header and return that instead.


01:01:30.600 --> 01:01:33.440
- Nice.


01:01:33.440 --> 01:01:36.880
Yeah, so for, let me see if I got this right here.


01:01:36.880 --> 01:01:39.600
So people are probably familiar with Pydantic


01:01:39.600 --> 01:01:43.040
and Pydantic allows you to create a class


01:01:43.040 --> 01:01:45.200
and it says what types are in the class


01:01:45.200 --> 01:01:46.800
and the names and so on.


01:01:46.800 --> 01:01:51.120
and those serialize out a JSON message.


01:01:51.120 --> 01:01:53.740
It sounds to me like what this is built for


01:01:53.740 --> 01:01:57.020
is when I'm talking met binary messages


01:01:57.020 --> 01:01:59.500
over a stream like a TCP stream,


01:01:59.500 --> 01:02:02.220
I can create a similar class that says,


01:02:02.220 --> 01:02:05.900
oh, I expect a message that is a string and then a float,


01:02:05.900 --> 01:02:07.340
read that out of the stream.


01:02:07.340 --> 01:02:09.180
Is that right?


01:02:09.180 --> 01:02:11.440
- Yeah, a good example here is,


01:02:11.440 --> 01:02:15.440
if you go back to the streams part,


01:02:15.440 --> 01:02:20.440
Text streams.


01:02:20.440 --> 01:02:23.440
Okay.


01:02:23.440 --> 01:02:31.440
So, this is something that translates between bytes and streams on the fly.


01:02:31.440 --> 01:02:39.440
So, this is a perfect trivial example of a stream prepper.


01:02:39.440 --> 01:02:46.720
Okay, yes, you have a text receive stream that will do the byte decoding.


01:02:46.720 --> 01:02:47.720
Yeah.


01:02:47.720 --> 01:02:50.200
Yeah, very nice.


01:02:50.200 --> 01:02:54.840
And you don't have to care like what's downstream of that.


01:02:54.840 --> 01:03:02.800
And even if you have three layers on top, you can just still ask for, say, client remote


01:03:02.800 --> 01:03:03.800
IP address.


01:03:03.800 --> 01:03:09.040
If there's a network stream somewhere downstream, that's the stream that will give you your


01:03:09.040 --> 01:03:17.360
answer. Cool. Yeah, the stream work here is really nice. There's a lot of things that are nice.


01:03:17.360 --> 01:03:27.200
The coordinating the task groups, the coordinating limitations like the with a limit, limiter,


01:03:27.200 --> 01:03:33.760
capacity, capacity limiter. A lot of cool building blocks on top of it and also the fact that this


01:03:33.760 --> 01:03:38.840
runs against or integrates with regular AsyncIO


01:03:38.840 --> 01:03:41.960
means you don't have to completely change


01:03:41.960 --> 01:03:44.280
your whole system in order to use it, right?


01:03:44.280 --> 01:03:46.400
>>Yeah.


01:03:46.400 --> 01:03:47.200
>>Very cool.


01:03:47.200 --> 01:03:49.240
All right, well, I think we're about out of time


01:03:49.240 --> 01:03:51.160
to talk about ADIO.


01:03:51.160 --> 01:03:56.760
Do you want to take 30 seconds and just give the elevator


01:03:56.760 --> 01:04:00.040
pitch for SQL A Code Gen?


01:04:00.040 --> 01:04:03.200
This is a really exciting project that you created here.


01:04:03.200 --> 01:04:07.880
Yeah, this is one of those side projects that are on the verge of a major release.


01:04:07.880 --> 01:04:17.600
So what this does is it takes an existing database, it connects to an existing database,


01:04:17.600 --> 01:04:25.200
reflects the schema from that, and then writes model code for you.


01:04:26.120 --> 01:04:29.760
The next major version even supports data classes


01:04:29.760 --> 01:04:34.760
and other kinds of formats.


01:04:34.760 --> 01:04:38.600
- The SQL model one is the one that's most exciting for me


01:04:38.600 --> 01:04:42.520
because that'll give you Pydanic models


01:04:42.520 --> 01:04:45.600
that use the SQL model, which is very exciting.


01:04:45.600 --> 01:04:51.960
Yeah, so nice.


01:04:51.960 --> 01:04:55.600
I mean, think if you're a consultant


01:04:55.600 --> 01:04:58.240
or you've, you talked about Java earlier, right?


01:04:58.240 --> 01:05:00.100
Imagine you've got like a Java code base


01:05:00.100 --> 01:05:02.440
and you wanna do a proof of concept in Python


01:05:02.440 --> 01:05:05.320
and SQL model or SQL alchemy.


01:05:05.320 --> 01:05:07.120
And somebody says, well, why don't you try building


01:05:07.120 --> 01:05:10.200
a simple version that talks to our database?


01:05:10.200 --> 01:05:13.320
And if that thing has like 100 tables


01:05:13.320 --> 01:05:17.320
and complicated relationships, it's no fun to sit down.


01:05:17.320 --> 01:05:18.840
Like a big portion of that project


01:05:18.840 --> 01:05:20.560
might be just modeling the database.


01:05:20.560 --> 01:05:22.960
And here I can just say, SQL echo gen,


01:05:22.960 --> 01:05:27.320
connect to Postgres, boom, outcomes, SQLAlchemy classes.


01:05:27.320 --> 01:05:30.720
That's a huge jumpstart for getting started,


01:05:30.720 --> 01:05:33.320
or if you're a consultant jumping into a new project.


01:05:33.320 --> 01:05:35.160
- Yeah, exactly.


01:05:35.160 --> 01:05:36.840
If you have a really large database,


01:05:36.840 --> 01:05:40.200
and this will save little hours of your time.


01:05:40.200 --> 01:05:43.200
- At least hours, yes.


01:05:43.200 --> 01:05:45.620
And a lot of frustration, right?


01:05:45.620 --> 01:05:49.240
Because with SQLAlchemy, you've got to have the model


01:05:49.240 --> 01:05:51.400
match the database just right,


01:05:51.400 --> 01:05:53.000
and this will do that for you.


01:05:53.000 --> 01:05:53.760
Yeah.


01:05:53.760 --> 01:05:55.600
OK, super cool project.


01:05:55.600 --> 01:05:59.040
TypeGuard is another one you have.


01:05:59.040 --> 01:06:01.920
Not super complicated, but an interesting capability


01:06:01.920 --> 01:06:03.240
to grab on.


01:06:03.240 --> 01:06:08.040
>>Jani: Yeah, also one of those that are on major--


01:06:08.040 --> 01:06:11.000
version of major release.


01:06:11.000 --> 01:06:15.880
I sadly have not had enough time to finish the next major


01:06:15.880 --> 01:06:16.920
version.


01:06:16.920 --> 01:06:19.560
And then there's, of course, Python 3.11,


01:06:19.560 --> 01:06:22.220
which brings a whole bunch of new feature


01:06:22.220 --> 01:06:27.220
that I have not been able to yet incorporate into TypeGuard.


01:06:27.220 --> 01:06:33.060
And sadly, I also have not started using it myself.


01:06:33.060 --> 01:06:39.740
It's a sad story really.


01:06:39.740 --> 01:06:44.740
But the premise is that you have this pytest plugin


01:06:44.740 --> 01:06:54.900
you have this pytest plugin and you activate it during the test run and then


01:06:54.900 --> 01:07:01.500
in addition to you know static type checking your application which you


01:07:01.500 --> 01:07:07.620
usually do with mypy, PyWrite or what have you, you can also do a runtime type


01:07:07.620 --> 01:07:14.620
checking because the static tools don't always see the correct types.


01:07:14.620 --> 01:07:22.000
Well, and you might not be in control of that, right?


01:07:22.000 --> 01:07:26.180
You might write a library, your library might have types declared on what it's supposed


01:07:26.180 --> 01:07:27.180
to take.


01:07:27.180 --> 01:07:32.920
The person consuming your library has no requirement to run mypy and they have no requirement to


01:07:32.920 --> 01:07:37.380
make sure what they typed matches what you said you expect.


01:07:37.380 --> 01:07:44.080
And because they're hints, they're not compiled options in Python, at runtime, you might get


01:07:44.080 --> 01:07:46.880
something you don't expect, even though you put a type there.


01:07:46.880 --> 01:07:48.240
>> Yeah, exactly.


01:07:48.240 --> 01:07:54.400
So this is how you get a runtime assurance that you have the right type there.


01:07:54.400 --> 01:07:55.400
>> Nice.


01:07:55.400 --> 01:08:00.120
So all you do with this type guard library is you put an @typechecked decorator on a


01:08:00.120 --> 01:08:02.120
function and then...


01:08:02.120 --> 01:08:03.120
Go ahead.


01:08:03.120 --> 01:08:06.120
What else do I got to do?


01:08:06.120 --> 01:08:12.560
the best way would be to use the import hook.


01:08:12.560 --> 01:08:18.720
There's an import hook that will automatically


01:08:18.720 --> 01:08:23.200
add these decorators during the import,


01:08:23.200 --> 01:08:26.320
so you don't have to alter your code at all.


01:08:26.320 --> 01:08:31.640
There are some open issues with that import hook,


01:08:31.640 --> 01:08:37.920
like somebody reported that this import


01:08:37.920 --> 01:08:41.640
hook is installed too late, that the modules in question


01:08:41.640 --> 01:08:43.400
were already imported.


01:08:43.400 --> 01:08:48.920
So that's something I have yet to fix or find a workaround for.


01:08:48.920 --> 01:08:51.920
But that's the idea.


01:08:51.920 --> 01:08:52.560
>>Right.


01:08:52.560 --> 01:08:54.400
So you can either use the decorator


01:08:54.400 --> 01:08:59.320
and be somewhat guarded about how you're doing it


01:08:59.320 --> 01:09:00.720
and only apply it to certain parts,


01:09:00.720 --> 01:09:02.760
like say your public API,


01:09:02.760 --> 01:09:05.240
or you could just say install import hook


01:09:05.240 --> 01:09:06.680
and then everything that gets imported


01:09:06.680 --> 01:09:09.320
gets wrapped in the type check decorator.


01:09:09.320 --> 01:09:11.800
And what that does is it looks at the type hints


01:09:11.800 --> 01:09:15.000
and the declared return value and will raise an exception.


01:09:15.000 --> 01:09:17.880
If say that your function takes an integer


01:09:17.880 --> 01:09:21.240
and it's passed a string, that becomes a runtime error.


01:09:21.240 --> 01:09:25.200
- Right, or you can just issue a warning.


01:09:25.200 --> 01:09:28.720
- Sure, the warning may be nice, but it's still,


01:09:29.960 --> 01:09:30.960
I think it's pretty cool.


01:09:30.960 --> 01:09:34.020
You can opt into having Python type hints


01:09:34.020 --> 01:09:37.000
become enforced, basically.


01:09:37.000 --> 01:09:41.080
- Yeah, what I use this for is in the Asphalt.


01:09:41.080 --> 01:09:46.360
When I configure, when I accept the configuration


01:09:46.360 --> 01:09:51.360
for a component, I use this decorator,


01:09:51.360 --> 01:09:57.400
or rather an assert, to check that the types are correct.


01:09:59.360 --> 01:10:03.560
so I don't raise any mysterious warning type errors


01:10:03.560 --> 01:10:05.880
or value errors further down the line,


01:10:05.880 --> 01:10:08.440
or even worse, at runtime.


01:10:08.440 --> 01:10:09.600
- Sure.


01:10:09.600 --> 01:10:11.080
Okay, that's cool.


01:10:11.080 --> 01:10:15.320
There is one of the features of Asphalt or Highlights


01:10:15.320 --> 01:10:18.640
is runtime type checking for development and testing


01:10:18.640 --> 01:10:20.520
to fail early when functions are called


01:10:20.520 --> 01:10:21.880
with incompatible arguments


01:10:21.880 --> 01:10:25.680
and can be disabled for zero overhead.


01:10:25.680 --> 01:10:30.560
So it sounds like you're maybe doing an import hook


01:10:30.560 --> 01:10:34.720
in development mode, and that's handling all this for you.


01:10:34.720 --> 01:10:36.400
Is that right?


01:10:36.400 --> 01:10:38.400
- Well, actually, in this current version,


01:10:38.400 --> 01:10:39.560
I'm using the assert.


01:10:39.560 --> 01:10:44.560
So in case you didn't know, when you have asserts,


01:10:44.560 --> 01:10:50.760
they are normally run without any switches to Python.


01:10:50.760 --> 01:10:54.100
But if you run Python without the debug mode,


01:10:54.100 --> 01:10:56.940
then asserts are not compiled into bytecode.


01:10:56.940 --> 01:11:01.020
So just by using this switch,


01:11:01.020 --> 01:11:04.380
you can disable these potentially expensive asserts.


01:11:04.380 --> 01:11:05.780
- I see.


01:11:05.780 --> 01:11:07.320
Yeah, okay, I didn't know that.


01:11:07.320 --> 01:11:11.020
I'm familiar with that from C and C#


01:11:11.020 --> 01:11:13.060
and other compiled languages with their pragmas


01:11:13.060 --> 01:11:14.340
and that type of thing,


01:11:14.340 --> 01:11:17.160
but didn't realize that about Python asserts.


01:11:17.160 --> 01:11:19.660
- Yeah, there's this one thing that,


01:11:19.660 --> 01:11:23.020
actually, if you have this code,


01:11:23.020 --> 01:11:28.020
if under debug, and there's a bunch of code under that block,


01:11:28.020 --> 01:11:35.020
that whole block gets omitted from the compiled code


01:11:35.020 --> 01:11:39.500
if you run Python with the debug mode disabled.


01:11:39.500 --> 01:11:42.240
- Okay, yeah, very cool.


01:11:42.240 --> 01:11:44.460
All right, Alex, well,


01:11:44.460 --> 01:11:46.660
those are some cool additional projects.


01:11:46.660 --> 01:11:49.260
I feel like the SQL A code gen,


01:11:49.260 --> 01:11:51.220
we almost could spend a whole bunch of other time on it.


01:11:51.220 --> 01:11:53.700
Another one is the AP scheduler.


01:11:53.700 --> 01:11:55.500
Again, could almost be its own show,


01:11:55.500 --> 01:11:58.100
but we're out of time for this one.


01:11:58.100 --> 01:11:59.960
So thanks so much for being here.


01:11:59.960 --> 01:12:01.180
Now, before you get out of here,


01:12:01.180 --> 01:12:03.600
I've got the two final questions to ask you.


01:12:03.600 --> 01:12:04.980
If you're gonna write some Python code,


01:12:04.980 --> 01:12:06.740
what editor are you to use?


01:12:06.740 --> 01:12:12.460
- Well, I've been looking at the different editors


01:12:12.460 --> 01:12:17.180
available and so far PyCharm wins, hands down.


01:12:18.860 --> 01:12:22.620
So it has so many of these intelligent features


01:12:22.620 --> 01:12:25.560
and what have you that,


01:12:25.560 --> 01:12:29.620
for example, I use its database features


01:12:29.620 --> 01:12:32.060
to browse through my database.


01:12:32.060 --> 01:12:36.180
I use its refactoring features to change my code


01:12:36.180 --> 01:12:38.740
relatively safely.


01:12:38.740 --> 01:12:43.740
And its Docker support gives me auto-completion.


01:12:43.740 --> 01:12:48.380
The list goes on and on and on


01:12:48.380 --> 01:12:53.380
And most of these ideas are not nearly as sophisticated.


01:12:53.380 --> 01:12:56.780
- I agree.


01:12:56.780 --> 01:12:57.620
Excellent one.


01:12:57.620 --> 01:12:59.840
Now, a notable PyPI package.


01:12:59.840 --> 01:13:02.520
I mean, we talked about that one.


01:13:02.520 --> 01:13:04.020
You can recommend any of these we talked about,


01:13:04.020 --> 01:13:07.420
or you can say something else that's interesting.


01:13:07.420 --> 01:13:08.260
Sure.


01:13:08.260 --> 01:13:16.060
- Well, I think I already mentioned Trio,


01:13:16.060 --> 01:13:20.920
But this is a difficult question, really.


01:13:20.920 --> 01:13:24.620
Maybe poetry.


01:13:24.620 --> 01:13:27.600
- Okay, yeah, poetry.


01:13:27.600 --> 01:13:30.580
- Yeah, so poetry is something that I use


01:13:30.580 --> 01:13:33.500
for my application at work.


01:13:33.500 --> 01:13:39.780
It's the closest thing in Python to, say, yarn.


01:13:39.780 --> 01:13:44.580
So I manage the dependencies


01:13:44.580 --> 01:13:47.260
and lock down the dependencies using Poetry.


01:13:47.260 --> 01:13:51.660
It's quite handy for that.


01:13:51.660 --> 01:13:54.840
There are some, I have some issues with Poetry


01:13:54.840 --> 01:13:58.340
like when I just need to update one dependency,


01:13:58.340 --> 01:14:02.020
it updates them all and small issues like that.


01:14:02.020 --> 01:14:04.640
But other than that, it's great.


01:14:04.640 --> 01:14:07.860
- Nice, yeah, it looks really great.


01:14:07.860 --> 01:14:09.340
I know a lot of people are loving Poetry.


01:14:09.340 --> 01:14:11.380
It's a good recommendation there.


01:14:11.380 --> 01:14:13.500
Right, final call to action.


01:14:13.500 --> 01:14:16.800
people are interested in any IO, how do they get started?


01:14:16.800 --> 01:14:23.820
- Well, this is somewhat of a tutorial there.


01:14:23.820 --> 01:14:28.860
I really don't have a really long tutorial on like Trio.


01:14:28.860 --> 01:14:32.660
So I'm heavily leaning on Trio's documentation here


01:14:32.660 --> 01:14:36.900
because any IO has such a similar design to Trio


01:14:36.900 --> 01:14:40.100
then a lot of Trio's manual can be used


01:14:41.260 --> 01:14:43.160
to draw parallels to any I/O.


01:14:43.160 --> 01:14:46.980
You can almost use Trio's documentation,


01:14:46.980 --> 01:14:51.360
the tutorial to learn how any I/O works.


01:14:51.360 --> 01:14:55.060
- Yeah, it's highly inspired, right?


01:14:55.060 --> 01:14:59.540
- Right, and if anything else,


01:14:59.540 --> 01:15:02.100
then you should just come to Gitter.


01:15:02.100 --> 01:15:03.540
I think there's a link,


01:15:03.540 --> 01:15:08.140
getting help at the bottom.


01:15:08.140 --> 01:15:09.040
- Okay, yeah.


01:15:10.100 --> 01:15:17.620
So there's a GitHub link, and I'm usually available there.


01:15:17.620 --> 01:15:18.740
>> Great.


01:15:18.740 --> 01:15:20.060
OK, yeah, very, very nice.


01:15:20.060 --> 01:15:23.500
And I'm guessing you accept contributions?


01:15:23.500 --> 01:15:25.220
>> Sure.


01:15:25.220 --> 01:15:26.220
>> Yeah.


01:15:26.220 --> 01:15:27.380
So yeah, let's see.


01:15:27.380 --> 01:15:30.740
Over here, we've got--


01:15:30.740 --> 01:15:32.820
yeah, what is that, 33 contributors?


01:15:32.820 --> 01:15:33.820
So yeah, excellent.


01:15:33.820 --> 01:15:36.220
If people want to contribute to the project,


01:15:36.220 --> 01:15:38.980
and maybe that's code, or maybe even they


01:15:38.980 --> 01:15:41.460
could put together a tutorial or something like that


01:15:41.460 --> 01:15:42.580
if they're interested.


01:15:42.580 --> 01:15:43.820
- Maybe, yeah.


01:15:43.820 --> 01:15:45.180
- Yeah, perhaps, okay.


01:15:45.180 --> 01:15:47.700
Excellent, well, thank you for all the cool libraries


01:15:47.700 --> 01:15:50.460
and take the time to come share them with us.


01:15:50.460 --> 01:15:52.180
- Thanks for having me.


01:15:52.180 --> 01:15:53.420
- Yeah, you bet.


01:15:53.420 --> 01:15:54.260
Bye, thanks everyone for listening.


01:15:54.260 --> 01:15:55.100
- Bye.


01:15:55.100 --> 01:16:05.100
[BLANK_AUDIO]

