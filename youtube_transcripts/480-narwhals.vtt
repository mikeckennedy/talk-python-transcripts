WEBVTT

00:00:00.960 --> 00:00:03.040
Marco, welcome to Talk Python To Me.

00:00:03.040 --> 00:00:05.840
Hi, thanks for having me.

00:00:05.840 --> 00:00:07.280
Hey, it's fantastic to have you here.

00:00:07.280 --> 00:00:13.200
We talked a little bit on the socials and other places, but you know,

00:00:13.200 --> 00:00:16.960
nice to talk to you in person and about some of your projects.

00:00:16.960 --> 00:00:20.880
Yeah, nice to finally do it. I've been listening to your shows for years,

00:00:20.880 --> 00:00:22.800
so it's a pleasure to be here.

00:00:22.800 --> 00:00:27.760
Yeah, that's really cool. It's awesome when people who are listeners for a long time

00:00:27.760 --> 00:00:36.240
get to come on the show. I love it. So we're going to talk about narwhals and data science,

00:00:36.240 --> 00:00:43.440
data frame libraries, and basically coming up with a way to write consistent code against all these

00:00:43.440 --> 00:00:49.040
different libraries, which I think is an awesome goal, which is why I'm having you on the show,

00:00:49.040 --> 00:00:53.120
of course. Before we get to all that, as you know, let's hear a little bit about yourself.

00:00:54.560 --> 00:01:00.560
Sure. So yeah, my name is Marco. I work at a company called Quantsight Labs, which supports

00:01:00.560 --> 00:01:06.240
several open source projects and also offers some training and consulting services.

00:01:06.960 --> 00:01:15.840
I live in Cardiff in Wales and been at Quantsight for about two years now. Originally hired as a

00:01:15.840 --> 00:01:22.480
Pandas maintainer, but then my role shifted considerably towards some other projects, such as Polars.

00:01:22.480 --> 00:01:29.840
And then in February of this year, I tried releasing this Narwhals library as a bit of an experiment.

00:01:30.560 --> 00:01:33.760
And it's growing a bit faster than expected.

00:01:33.760 --> 00:01:42.000
It's a really interesting project. And Quantsight is quite the place. You know, I didn't really know

00:01:42.000 --> 00:01:49.520
about you all before having people on the show from there, but here's my experience. I've had,

00:01:50.160 --> 00:01:54.720
I reached out to say some of the Jupyter folks, whatever. Let's have some of the Jupyter people on.

00:01:54.720 --> 00:01:59.360
There's three or four people from Quantsight show up and then, oh, let's talk about this other project.

00:01:59.360 --> 00:02:05.200
Another person from Quantsight two weeks later, and then you're from Quantsight. And none of those

00:02:05.200 --> 00:02:08.880
connections were like, let me try to find people from Quantsight. I think you all are having a pretty

00:02:08.880 --> 00:02:11.040
big impact in the data science space. That's cool.

00:02:11.040 --> 00:02:17.280
Yeah, it is a bit amusing in the internal Slack channel. If you ask a question, does anyone know

00:02:17.280 --> 00:02:22.000
how to do this? Someone will reply, oh yeah, let me ping this person who's a maintainer of that library.

00:02:22.000 --> 00:02:22.720
And you're like, okay, well.

00:02:22.720 --> 00:02:26.320
Exactly. I think we know how it works. Let's ask them.

00:02:26.320 --> 00:02:32.400
Yeah, it's a big world, but also a small world in interesting ways.

00:02:32.400 --> 00:02:33.920
Yeah.

00:02:33.920 --> 00:02:35.920
How'd you get into programming in the first place?

00:02:37.440 --> 00:02:42.800
I think the first experience with programming I had was at university. So I studied maths. I think

00:02:42.800 --> 00:02:43.920
like you as well.

00:02:43.920 --> 00:02:47.360
Yeah, yeah, yeah. That sounds really... Yeah, keep going. So far, you're telling my story.

00:02:47.360 --> 00:02:53.680
Yeah, sure. Although my initial encounter with it, I didn't... I'm not quite particularly enjoyed it.

00:02:53.680 --> 00:03:00.480
It was just having to solve some problems in MATLAB. I did find it kind of satisfying that if you gave

00:03:00.480 --> 00:03:06.800
it instructions, it did exactly that. But I wouldn't say that I felt like naturally

00:03:06.800 --> 00:03:14.400
talented or anything. I then really took to programming though, after I started a maths PhD and

00:03:14.400 --> 00:03:19.360
dropped out because it wasn't really going anywhere. And once I went deeper into programming,

00:03:19.360 --> 00:03:24.480
then I realized, okay, actually, I do have some affinity for this topic. I do quite enjoy it.

00:03:24.480 --> 00:03:25.440
Yeah.

00:03:25.440 --> 00:03:26.160
I think that's...

00:03:26.160 --> 00:03:28.560
What was your PhD focus before you dropped out?

00:03:28.560 --> 00:03:34.400
It was meant to be, well, some applied mathematics, like stochastic partial differential equations.

00:03:34.400 --> 00:03:41.920
But you know, academia, you publish or perish. And I wasn't publishing and didn't really see that changing.

00:03:41.920 --> 00:03:44.880
So I had to make a bit of a pivot.

00:03:44.880 --> 00:03:51.360
I imagine you made a pretty good choice, just guessing. I mean, I love math, but the options

00:03:51.360 --> 00:03:55.360
are just so much broader outside of academia.

00:03:55.360 --> 00:04:00.880
In hindsight, yeah, I kind of wish that somebody at the time had told me that I could have still had a

00:04:00.880 --> 00:04:06.080
really interesting and rewarding career outside of academia. And that I shouldn't have stressed myself

00:04:06.080 --> 00:04:12.400
out so much about trying to find a PhD or about having to complete it when I had already started it.

00:04:12.400 --> 00:04:19.760
The secret, I think, about being a good programmer is it's kind of like grad school anyway. You're constantly

00:04:19.760 --> 00:04:24.560
studying and learning. You feel like you've figured something out. It's like, well, that's changed.

00:04:24.560 --> 00:04:28.160
Now onto the next thing. You're kind of like, well, we figured out pandas. Now we got polars. Okay,

00:04:28.160 --> 00:04:30.640
well, we're going to start over and figure out how to use that well, right?

00:04:30.640 --> 00:04:30.800
So...

00:04:30.800 --> 00:04:37.040
That is true. You need to do a lot of learning, a lot of self-directed learning in particular.

00:04:37.040 --> 00:04:43.280
It's really stimulating, I must say. It is. It's great if you want that. If you want to just

00:04:43.280 --> 00:04:47.760
nine to five, you don't need to stress about... Well, look, I think there's actually options there.

00:04:47.760 --> 00:04:51.680
We'll get to narwhals in a second. But I think there are options there. I think if you want to do

00:04:51.680 --> 00:04:59.920
COBOL, FORTRAN, some of these older programming languages where so much of the world depends on them,

00:04:59.920 --> 00:05:06.080
but nobody wants to do them. You could totally own that space and make really good money if you didn't

00:05:06.080 --> 00:05:09.120
want to learn anything. But where's the fun in that, right?

00:05:09.120 --> 00:05:12.720
Yeah. Yeah.

00:05:12.720 --> 00:05:17.760
We could all get rid of our legacy systems, but this stuff does power the world.

00:05:17.760 --> 00:05:22.960
They're there for a reason, right? That works. I would really like it if you don't touch it, please.

00:05:22.960 --> 00:05:30.800
But that's not the way it is with narwhals. Let's start with an overview of what narwhals is and

00:05:30.800 --> 00:05:35.280
why you created it. And then I want to talk a bit about some of the data science libraries

00:05:35.280 --> 00:05:41.120
before we get too much deeper. What is narwhals? A narwhal is a cool whale as far as I know. It's

00:05:41.120 --> 00:05:45.840
like the unicorn of the sea, basically. What is this library?

00:05:45.840 --> 00:05:46.320
Yeah, exactly.

00:05:46.320 --> 00:05:53.520
So it's intended as a compatibility layer between different data frame libraries. So narwhals does

00:05:53.520 --> 00:05:59.680
not do any computation itself. It's more of just a wrapper around different data frame APIs.

00:06:00.480 --> 00:06:06.080
And I like the Polars API, so I figured that I should keep it fairly close to the Polars API,

00:06:06.080 --> 00:06:14.240
and in particular to Polars expressions. As to why narwhals, so I was just getting frustrated with the fact

00:06:14.960 --> 00:06:21.120
that there's, let's say about a year ago, there were relatively few libraries that supported Polars.

00:06:22.080 --> 00:06:29.360
And if libraries did support Polars, it was often just done by converting to Pandas or converting to PyArrow.

00:06:29.360 --> 00:06:34.480
Yet a lot of these libraries, they weren't doing anything that complicated with data frames.

00:06:34.480 --> 00:06:40.080
A lot of data frame consuming libraries, they don't really want to do that much. They want to select

00:06:40.080 --> 00:06:44.960
columns. They want to select rows. Maybe they want to do some aggregations. Like they're not doing

00:06:45.920 --> 00:06:51.120
stuff that's completely wild. And so trying to design some minimal

00:06:51.120 --> 00:07:00.240
compatibility layer, I think is a lot easier than trying to make a full blown data frame API that end users are meant to use.

00:07:00.240 --> 00:07:09.040
So the idea with narwhals is this is a tool for tool builders. If library maintainers want to support different data frame libraries as inputs with a minimal

00:07:09.440 --> 00:07:15.520
overhead and with minimal maintenance required on their side, this is the problem we're trying to solve.

00:07:15.520 --> 00:07:26.320
It's a great problem to solve because maybe you want to have a library that works with an abstract concept of a data frame.

00:07:26.320 --> 00:07:33.920
But usually I would imagine you have to start out and say, are we going to go and support Polars? Are we going to support Pandas?

00:07:34.960 --> 00:07:44.880
And the APIs are different. Not just the APIs, but the behaviors, for example, the lazy execution of Polars versus the eager execution of Pandas.

00:07:44.880 --> 00:07:53.840
And so being able to just write your library so it takes either is probably a big hassle, right? Because it's just kind of have to have almost two versions

00:07:53.840 --> 00:07:55.600
each step, right?

00:07:55.600 --> 00:07:56.560
Yeah, exactly.

00:07:56.560 --> 00:07:57.120
Yeah, exactly.

00:07:57.120 --> 00:08:07.440
Well, I actually heard from a maintainer recently who was saying that he was interested in using nowals even just to have Pandas as a dependency because Pandas,

00:08:07.440 --> 00:08:11.760
they, the API changes a bit between versions.

00:08:11.760 --> 00:08:19.040
And he was getting a bit tired of Pandas API changes and was like, okay, well, if we can just defer all of the

00:08:19.760 --> 00:08:28.080
version checks and API differences to an abstraction there that might even simplify our life, even if we're just interested in supporting Pandas.

00:08:28.080 --> 00:08:29.920
Yeah, that's cool.

00:08:29.920 --> 00:08:35.760
Yeah, actually, that's an interesting idea. It's just like, we'll have a compatibility layer, just in case.

00:08:35.760 --> 00:08:43.280
And Pandas went from one to two on major version recently, which is a big deal and switched to PyArrow and

00:08:44.160 --> 00:08:44.880
all that, right?

00:08:44.880 --> 00:08:51.760
Yeah, so version two, it was sometime last year, I think, 2023.

00:08:51.760 --> 00:09:00.640
So yeah, the PyArrow, I think there were some misconceptions around that. So as we're live on air, let's take the chance to address some

00:09:00.640 --> 00:09:05.440
PyArrow misconceptions. PyArrow in Pandas currently is optional.

00:09:06.560 --> 00:09:14.000
And it'll probably stay optional for quite a while. So there is some talk about in version three, using PyArrow strings,

00:09:14.000 --> 00:09:20.960
instead of the classical NumPy object strings, by default, if people have PyArrow installed,

00:09:20.960 --> 00:09:26.960
it's not totally decided, it's not totally set in stone whether PyArrow will be a required dependency.

00:09:28.800 --> 00:09:34.640
And maybe Pandas version four will have it as a required dependency, and it will be the default

00:09:34.640 --> 00:09:37.360
everywhere. But that's a few years away.

00:09:37.360 --> 00:09:42.800
Yeah, maybe. Maybe we'll get Python four as well. You never know.

00:09:42.800 --> 00:09:52.000
It's interesting. I think the data science space, more than many other areas, has this ability to run

00:09:52.000 --> 00:09:59.840
Python in more places. For example, there's PyOdyd, there's Jupyter Lite, there's a lot of

00:09:59.840 --> 00:10:06.480
more constrained environments that it might go in. And I don't know the story with PyArrow and Wasm and

00:10:06.480 --> 00:10:12.560
all these different things. You still get benefits there. But there's a lot to consider.

00:10:12.560 --> 00:10:18.640
Yeah, totally. And I think that's one reason why some library maintainers are really drawn to a

00:10:18.640 --> 00:10:24.960
lightweight compatibility layer like Narwhals. With Narwhals, we say you don't need any dependencies.

00:10:24.960 --> 00:10:29.120
You need Narwhals, but that's just a bunch of Python files. If you wanted to, you could even just

00:10:29.120 --> 00:10:34.880
vendor Narwhals. It's not that big of a deal, but there's no extra dependencies required.

00:10:34.880 --> 00:10:39.760
Like Pandas users don't need PoLers installed, and PoLers users don't need Pandas installed.

00:10:39.760 --> 00:10:44.880
So if you're trying to deploy to a constrained environment where package size is limited,

00:10:45.760 --> 00:10:54.480
like if a library has Narwhals as a required dependency as opposed to any big data frame

00:10:54.480 --> 00:10:59.840
library, and then the user can just bring their own data frame, then like this, we're really minimizing

00:10:59.840 --> 00:11:04.320
the number of installation and dependency hell issues that people might run into. I think you've

00:11:04.320 --> 00:11:12.880
covered dependency hell on the show a few times before. Yeah. Indeed. I think one thing that's

00:11:12.880 --> 00:11:17.040
interesting for people out there listening, we'll talk about the different libraries that it works

00:11:17.040 --> 00:11:23.280
with right now, but if you have a library out there and you're listening, there's not too much work to

00:11:23.280 --> 00:11:32.240
integrate it into or make it Narwhal compatible, the Narwhalification of a library to let it do this

00:11:32.240 --> 00:11:40.000
interchange, right? So I think I can interpret your question in a couple of ways. So I'll just play them back.

00:11:40.000 --> 00:11:47.040
Yes, let's do it. One is if you're a library that consumes data frames. So yeah, there's some examples

00:11:47.040 --> 00:11:53.280
there on the readme of who's adopted Narwhals. So like Altair is the most recent, probably the most famous one.

00:11:53.280 --> 00:11:59.360
I think that's where I heard of it was when I was, some news about Altair and Narwhals together is

00:11:59.360 --> 00:12:07.120
actually how I heard of Narwhals. Okay. Yeah. Yeah. So yeah. And how complicated that is really depends on

00:12:07.120 --> 00:12:13.280
on how complicated the data frame operations this library is doing. In the case of Altair, they weren't

00:12:13.280 --> 00:12:19.840
doing anything that was that crazy. They needed to inspect the data types, select some columns, convert

00:12:19.840 --> 00:12:34.320
date times to strings to strings to get the unique categories out of categoricals. Like it wasn't that bad. So it, like I think within a few weeks we were able to do it.

00:12:34.320 --> 00:12:39.680
Same story with scikit-lego. There's some other libraries that have reached out that have shown interest

00:12:40.240 --> 00:12:48.160
where it's going to be a bit of a heavier lift, but it's generally not as bad as I thought it was going

00:12:48.160 --> 00:12:53.440
to be when I started the project. The other side of, yeah, the other way that I think I might have

00:12:53.440 --> 00:12:58.800
interpreted your question is how difficult is it for a new data frame library to become Narwhals compatible.

00:12:58.800 --> 00:13:06.800
Yeah. There's a couple of ways that they can go about doing that. The preferred way is if they either write to us or open a pull request,

00:13:06.800 --> 00:13:17.680
adding their library as a backend in Narwhals. However, we love open source, but I don't consider myself an open source absolutist.

00:13:17.680 --> 00:13:22.320
I understand that not everything can be open sourced, and so if somebody has a closed source solution,

00:13:22.320 --> 00:13:29.840
we do have an extensibility mechanism within Narwhals such that somebody just needs to implement some Dunder methods,

00:13:29.840 --> 00:13:36.480
and then if they pass the data frame into a library that's been Narwhalified, then Narwhals will know how to glue

00:13:36.480 --> 00:13:42.640
things together and they'll be able to still support this closed source solution without it needing to go out into the open.

00:13:42.640 --> 00:13:51.680
Right. It's kind of something like inheriting from a class and implementing some functions, and then it knows, right?

00:13:51.680 --> 00:13:53.040
Yeah, exactly.

00:13:53.040 --> 00:13:58.640
Yeah. Yeah. Cool. So right now it has full API support for

00:13:59.760 --> 00:14:04.880
CUDF, C-U-D-F. I'm guessing that's CUDA data frame library?

00:14:04.880 --> 00:14:09.360
Yeah, I'm not totally sure how we're supposed to pronounce it. I call it CUDF.

00:14:09.360 --> 00:14:15.920
Yeah, that came out of the Rapids team at NVIDIA. It's like an accelerated version of Pandas on GPU.

00:14:15.920 --> 00:14:17.200
Yeah, that's been quite a fun one.

00:14:17.920 --> 00:14:20.160
Nice. Yeah, I bet. That's pretty wild.

00:14:20.160 --> 00:14:27.360
The API is quite similar to Pandas, but it's not exactly the same. So we have to do a bit of working around.

00:14:27.360 --> 00:14:34.240
Right, right. Because graphics cards are not just regular memory and regular programs. They're weird, right?

00:14:36.320 --> 00:14:40.320
Yeah, that's part of it. So there's some parts of the Pandas API which they intentionally don't support.

00:14:40.320 --> 00:14:45.760
And there's another part of it is just that the Pandas API is so extensive.

00:14:45.760 --> 00:14:52.640
It's just a question of resources. It's pretty difficult to reimplement 100% of the Pandas API.

00:14:52.640 --> 00:15:00.240
But Moden does attempt to do that. Moden does sell itself as a drop-in replacement for Pandas.

00:15:01.040 --> 00:15:08.960
In practice, I think they do have a section in their docs where they do mention some gotchas, some slight differences.

00:15:08.960 --> 00:15:22.400
But that's the idea. They've kind of got their own intermediate representation, and they've got their algebra, which they've published a paper about, which they then map onto the Pandas API.

00:15:22.400 --> 00:15:29.600
A pretty interesting project that was a lot easier to support. The way they make the Pandas API is a lot closer.

00:15:30.560 --> 00:15:39.280
But it's been interesting. Like with novels, we did find a couple of minor bugs in Moden just by running our test suite through the different libraries, which we then reported to them and they fixed very quickly.

00:15:39.280 --> 00:15:41.920
That's pretty awesome. Yeah, yeah, that's super awesome.

00:15:41.920 --> 00:15:53.920
So Moden lets you use Ray, Dask, or Unidisc. Unidisc. Two of one of which I know. One of which I've heard of. Two of which I've heard of.

00:15:55.360 --> 00:16:02.080
So I was going to ask about things like Dask and others, which are sort of themselves extensions of InDesk.

00:16:02.080 --> 00:16:08.080
But if you support Moden, you're kind of through one more layer supporting Dask and grid computing.

00:16:08.080 --> 00:16:16.080
Oh, but it's better. We don't have this on the readme yet, but we do have a level of support for Dask.

00:16:16.080 --> 00:16:22.800
We've not quite... I've not quite put it on the readme yet because we're still kind of defining exactly where the boundaries are.

00:16:22.800 --> 00:16:30.080
But it's going to be some kind of partial, lazy-only layer of support.

00:16:30.080 --> 00:16:33.320
And it's actually quite a nice way to run Dask.

00:16:33.320 --> 00:16:36.900
Like when you're running Dask, there are some things which do trigger compute for you.

00:16:36.900 --> 00:16:41.200
There are some things which may trigger index repartitioning.

00:16:41.200 --> 00:16:42.260
I think that's what it's called.

00:16:42.520 --> 00:16:51.000
And in Nowels, we've just been extremely careful that if you're able to stick to the Nowels API, then what you're doing is going to be performant.

00:16:51.000 --> 00:16:55.080
Awesome. Yeah, that's super cool.

00:16:55.080 --> 00:17:04.120
So one thing I think worth maybe pointing out here is you talked about Pandas, Pandas 1, Pandas 2, and it being an extensive API.

00:17:04.520 --> 00:17:07.500
I mentioned the eager versus lazy computation.

00:17:07.500 --> 00:17:16.800
But these two libraries are maybe some of the most popular ones, but they're pretty different in their philosophy.

00:17:16.800 --> 00:17:21.840
So maybe just could you just quick compare and contrast Polars versus Pandas?

00:17:21.840 --> 00:17:23.860
Yeah, sure.

00:17:23.860 --> 00:17:25.140
And directly Dask and so on.

00:17:25.140 --> 00:17:27.160
Yeah, sure.

00:17:27.160 --> 00:17:33.560
So, well, Pandas started a lot earlier, I think, in 2008, maybe first released in 2009.

00:17:33.560 --> 00:17:39.260
And originally really written heavily around NumPy.

00:17:39.260 --> 00:17:44.660
And you can see this in the classical Pandas NumPy data types.

00:17:44.660 --> 00:17:50.560
So the support for missing values is fairly inconsistent across types.

00:17:50.560 --> 00:17:57.780
So you brought up PyArrow before, so with the PyArrow data types, then we do get consistent missing value handling in Pandas.

00:17:57.780 --> 00:18:00.080
But for the classical NumPy ones, we don't.

00:18:00.080 --> 00:18:02.360
Polars started a lot later.

00:18:03.360 --> 00:18:09.460
It didn't have a lot of backwards compatibility concerns to have to worry about.

00:18:09.460 --> 00:18:11.540
So it could make a lot of good decisions up front.

00:18:11.540 --> 00:18:14.000
It's generally a lot stricter than Pandas.

00:18:14.000 --> 00:18:25.560
And in particular, there's a lot of strictness around the kinds of ways it lets you interact with its subjects.

00:18:25.920 --> 00:18:33.820
So in Pandas, the way we interact with data frames is we typically extract a series as one-dimensional objects.

00:18:33.820 --> 00:18:35.520
We then manipulate those series.

00:18:35.520 --> 00:18:38.080
Maybe we put them back into the original data frame.

00:18:38.260 --> 00:18:39.920
But we're doing everything one step at a time.

00:18:39.920 --> 00:18:47.860
In Polars, the primary way that we interact with data frames is with what you've got there on the screen.

00:18:48.260 --> 00:18:50.860
PL.col, AB, these are called expressions.

00:18:50.860 --> 00:18:54.660
And an expression, my mental model for it is just a function.

00:18:54.660 --> 00:18:57.040
It's a function from a data frame to a series.

00:18:57.040 --> 00:18:59.760
Almost like a generator or something, huh?

00:18:59.760 --> 00:19:01.020
Yeah, kind of.

00:19:01.020 --> 00:19:01.180
Yeah.

00:19:01.280 --> 00:19:07.960
Although I think when you say generator, like in Python, a generator, at some point you can consume it.

00:19:07.960 --> 00:19:10.680
Like you can type next on the generator and it produces a value.

00:19:10.680 --> 00:19:13.040
But an expression doesn't produce a value.

00:19:13.040 --> 00:19:16.260
It's like if you've got lambda x, x times 2.

00:19:16.260 --> 00:19:19.020
It doesn't produce a value until you give it an input.

00:19:19.020 --> 00:19:24.980
And similarly, an expression like PL.col, A, B, by itself, it doesn't do anything.

00:19:25.700 --> 00:19:30.660
The interpretation is given some data frame DF, I'll return you the columns A and B.

00:19:30.660 --> 00:19:34.440
So it only produces those columns once you give it some input data frame.

00:19:34.440 --> 00:19:41.040
And functions, just by their very definition, are lazy, kind of.

00:19:41.040 --> 00:19:43.360
Like you don't need to evaluate them straight away.

00:19:43.360 --> 00:19:46.000
And so Polars can take a look at all of the things you want to do.

00:19:46.000 --> 00:19:49.140
It can recognize some optimization patterns.

00:19:49.140 --> 00:19:54.280
It can recognize that maybe between some of your expressions, there are some parts that are repeated.

00:19:54.780 --> 00:20:01.560
And so instead of having to recompute the same thing multiple times, it can just compute it once and then reuse that between the different expressions.

00:20:01.560 --> 00:20:13.400
Yeah, that's one of the big features of big capabilities of Polars is that it has kind of a query engine optimizer in there.

00:20:13.400 --> 00:20:17.400
Whereas Pandas, because it's not lazy, it just does one thing, then the next, then the next.

00:20:17.400 --> 00:20:26.640
But maybe if you switch the order, like first filter and then compute versus compute and then filter, you might get a way better outcome, right?

00:20:26.640 --> 00:20:28.460
That's a massive one.

00:20:28.460 --> 00:20:28.700
Yeah.

00:20:28.700 --> 00:20:33.220
So when I was doing some benchmarking, we brought up QDF earlier.

00:20:33.220 --> 00:20:35.640
So that's the GPU accelerated version of Pandas.

00:20:35.780 --> 00:20:40.740
And that is super fast if you're just doing single operations on a one at a time in a given order.

00:20:40.740 --> 00:20:52.260
However, there are some benchmarks where maybe you're having to join together multiple data frames, and then you're only selecting certain rows.

00:20:52.560 --> 00:21:01.080
At that point, it's actually faster to just do it on a CPU using a lazy library like Polars, because Polars can do the query optimization.

00:21:01.080 --> 00:21:06.880
It can figure out that it needs to do the filter and only keep certain rows before doing five gigantic joins.

00:21:06.880 --> 00:21:11.860
Whereas QDF, it's super fast on GPU, but it is all eagerly executed.

00:21:12.800 --> 00:21:13.280
Exactly.

00:21:13.280 --> 00:21:17.220
It did way more work, but it did it really fast, so it was about the same in the end.

00:21:17.220 --> 00:21:21.900
Yeah, but now in Polars, there's going to be GPU support.

00:21:21.900 --> 00:21:23.380
Oh, is there?

00:21:23.380 --> 00:21:26.360
And there's going to be query optimized GPU support.

00:21:26.360 --> 00:21:28.460
I don't know if the world is ready for this level of speed.

00:21:28.460 --> 00:21:31.820
Yeah, that's going to be interesting.

00:21:31.820 --> 00:21:42.720
I guess another difference, it's not a massive, you know, in some ways it matters, some ways it doesn't, is Pandas is based on C extensions, right?

00:21:42.720 --> 00:21:44.720
I'm guessing, if I remember right.

00:21:44.720 --> 00:21:54.200
And then Polars is Rust, and they even took the .rs extension for their domain, which is really embracing it.

00:21:54.200 --> 00:22:01.780
But not that it really matters, you know, what your native layer is, if you're not working in that, right?

00:22:01.780 --> 00:22:05.900
Like most Python people don't work in C or Rust, but it's still interesting.

00:22:06.520 --> 00:22:15.960
Well, I think it, yeah, it is interesting, but also it can be useful for users to know this, because Polars has a really nice plugin system.

00:22:15.960 --> 00:22:21.560
So you can extend Polars with your own little expressions, which you can write in Rust.

00:22:21.560 --> 00:22:26.440
And the amount of Rust that you need to do this is really quite minimal.

00:22:26.640 --> 00:22:33.640
Like if you try to write these Polars plugins as if you were writing Python, and then just use some LLM or something to guide you.

00:22:33.640 --> 00:22:41.360
I think realistically, most data scientists can solve 98% of their inefficient data frame usage by using Polars plugins.

00:22:41.360 --> 00:22:46.280
So having a nice, safe language that you can do this in really makes a difference.

00:22:46.540 --> 00:22:50.560
I'm going to write it in Python, and then I'm going to ask some LLM.

00:22:50.560 --> 00:22:54.720
Right now I'm using LLM Studio and I think Llama 3.

00:22:54.720 --> 00:23:00.140
Anyway, ask it, say, okay, write this in Rust for me.

00:23:00.140 --> 00:23:01.940
Write it as a Polars plugin.

00:23:01.940 --> 00:23:02.820
Here we go.

00:23:02.820 --> 00:23:03.160
All right.

00:23:03.160 --> 00:23:04.880
Yeah, exactly.

00:23:04.880 --> 00:23:08.120
It's crazy, this new world we live in.

00:23:08.120 --> 00:23:09.460
Yeah, yeah, totally.

00:23:09.600 --> 00:23:16.820
I mean, like the amount of Rust knowledge you need to take care of some of the complicated parts in Polars is really advanced.

00:23:16.820 --> 00:23:19.860
Really need to study for that, and LLM isn't going to solve it for you.

00:23:19.860 --> 00:23:28.960
But the amount of Rust that you need to just make a plugin to solve some inefficient function, I think that's doable.

00:23:28.960 --> 00:23:30.300
Right, yeah, exactly.

00:23:30.300 --> 00:23:34.420
It's very different to say, we're going to just do this loop in this function call here versus there,

00:23:34.420 --> 00:23:38.940
rather than I'm going to write a whole library in Rust or C or whatever.

00:23:38.940 --> 00:23:40.780
Exactly.

00:23:40.780 --> 00:23:45.580
Yeah, so there's a pretty different API between these.

00:23:45.580 --> 00:23:52.060
And in Narwhals, it looks like you've adopted the Rust API, right?

00:23:52.060 --> 00:23:53.440
A subset of it.

00:23:53.440 --> 00:23:54.220
Is that right?

00:23:54.220 --> 00:23:56.180
The Polars one, yes, exactly.

00:23:56.180 --> 00:23:57.480
So I kind of figured...

00:23:57.480 --> 00:23:58.280
Yeah, yeah, that's what I'm sorry.

00:23:58.280 --> 00:23:58.880
That's what I mean.

00:23:58.880 --> 00:24:00.080
Yeah, the Polars one.

00:24:00.080 --> 00:24:03.240
Yeah, yeah, we can either just choose the Pandas API.

00:24:03.240 --> 00:24:08.760
But to be honest, I found that trying to translate the Pandas API to Polars was fairly painful.

00:24:09.300 --> 00:24:15.400
Like Pandas has a bunch of extra things like the index, multi-index, and it does index alignment on all the operations.

00:24:15.400 --> 00:24:20.960
I just found it not a particularly pleasant experience to try to map this onto Pandas.

00:24:20.960 --> 00:24:25.100
However, when I tried to do the reverse of translating the Polars API to Pandas,

00:24:26.100 --> 00:24:29.040
it kind of just worked without that much effort.

00:24:29.040 --> 00:24:30.420
And I was like, oh, wow, this is magic.

00:24:30.420 --> 00:24:33.580
Okay, let's just take this a bit further, publish it on GitHub.

00:24:33.580 --> 00:24:36.080
Maybe somebody would find a use case for it.

00:24:36.080 --> 00:24:36.820
I don't know.

00:24:38.020 --> 00:24:38.820
Yeah, that's great.

00:24:38.820 --> 00:24:40.380
Out in the audience.

00:24:40.380 --> 00:24:45.640
ZigZackJack asks, how is Norwalks different from IBIS?

00:24:45.640 --> 00:24:47.160
All right.

00:24:47.160 --> 00:24:49.340
The number one most common question.

00:24:49.340 --> 00:24:49.880
Love this.

00:24:49.880 --> 00:24:50.560
Is it?

00:24:50.560 --> 00:24:51.160
Okay, great.

00:24:51.880 --> 00:24:56.280
Yeah, maybe we should provide a bit of context for the listeners on what is IBIS.

00:24:56.280 --> 00:25:00.540
So IBIS, yes, you can see there on the screen, they describe themselves as the portable data frame library.

00:25:00.540 --> 00:25:06.500
So IBIS is really aiming to be a data frame library, just like Pandas, just like Polars.

00:25:07.500 --> 00:25:11.260
But it's got this API, which can then dispatch to different backends.

00:25:11.260 --> 00:25:17.260
The default one is DuckDB, which is a really powerful embedded analytics database.

00:25:17.260 --> 00:25:18.820
I think you covered it on the show.

00:25:18.820 --> 00:25:22.060
In fact, I think I might have first heard about DuckDB on Python Bytes.

00:25:22.060 --> 00:25:26.540
So listeners, if you want to stay up to date, subscribe to Python Bytes.

00:25:26.540 --> 00:25:28.280
Thank you.

00:25:28.280 --> 00:25:31.160
Yeah, one of the shows I almost never miss.

00:25:32.040 --> 00:25:37.680
So, yeah, I think the primary difference between novels and IBIS is the target audience.

00:25:37.680 --> 00:25:43.880
So with IBIS, they're really trying to be this full-blown data frame that people can use to do their analyses.

00:25:43.880 --> 00:25:51.300
Whereas with novels, I'm openly saying to end users, like if you're an end user, if you're a data scientist,

00:25:51.300 --> 00:25:55.220
if you're an ML engineer, if you're a data analyst, don't use novels.

00:25:55.220 --> 00:25:57.940
It's a tool for tool builders.

00:25:58.560 --> 00:26:04.100
Like learn Polars, learn DuckDB, learn whatever the best tool is for your particular task,

00:26:04.100 --> 00:26:08.740
and learn it well, and master that, and do your analyses.

00:26:08.740 --> 00:26:14.580
On the other hand, if you're a tool builder, and you just need to do some simple operations with data frames,

00:26:14.580 --> 00:26:17.020
and you want to empower your...

00:26:17.020 --> 00:26:22.300
If you want to enable your users to use your tool, regardless of which library they're starting with,

00:26:22.300 --> 00:26:26.640
then novels can provide a nice bridge between them.

00:26:27.360 --> 00:26:27.800
Interesting.

00:26:27.800 --> 00:26:32.340
Is there any interoperability between IBIS and Narwhals?

00:26:32.340 --> 00:26:35.280
We do have some level of support for IBIS.

00:26:35.280 --> 00:26:38.520
And at the moment, this is just interchange-level support,

00:26:38.520 --> 00:26:44.580
in the sense that if you pass an IBIS data frame, then you can inspect the schema,

00:26:44.580 --> 00:26:47.460
not do much else.

00:26:47.460 --> 00:26:51.180
But for the Altair use case, that's all they needed.

00:26:51.180 --> 00:26:57.600
They just wanted to inspect the schema, make some decisions about how to encode some different columns.

00:26:57.600 --> 00:27:05.340
And then, depending on how long your data frame is, they might convert to PyArrow and dispatch to a different library called VegaFusion,

00:27:05.340 --> 00:27:07.940
or they might just do everything within Altair.

00:27:08.400 --> 00:27:17.240
But we found that even just having this relatively minimal level of support for IBIS, Vax, DuckDB,

00:27:17.240 --> 00:27:21.400
and anything else, anything that implements the data frame interchange protocol,

00:27:21.400 --> 00:27:24.560
was enough to already solve some problems for users of these libraries.

00:27:25.700 --> 00:27:26.100
Yeah.

00:27:26.100 --> 00:27:27.020
Okay.

00:27:27.020 --> 00:27:28.120
Very interesting.

00:27:28.120 --> 00:27:29.920
Let's see.

00:27:29.920 --> 00:27:32.720
We'll hit a few more of the highlights here.

00:27:32.720 --> 00:27:34.580
100% test coverage.

00:27:34.580 --> 00:27:37.700
You already mentioned that you found some bugs in...

00:27:37.700 --> 00:27:40.600
I think it's...

00:27:40.600 --> 00:27:40.980
Which library was it?

00:27:40.980 --> 00:27:41.520
Modian.

00:27:41.520 --> 00:27:42.280
Yeah, yeah, that's right.

00:27:42.280 --> 00:27:43.720
I think all of them.

00:27:43.820 --> 00:27:50.060
I think it's helps uncover some rough edge cases in, yeah, all of the libraries that we have some support for.

00:27:50.060 --> 00:27:54.900
You write a library and you're going to say, I'm going to try to behave like you do.

00:27:54.900 --> 00:27:56.860
And I'll write some tests around that.

00:27:56.860 --> 00:28:00.400
And then when you find the differences, you're like, wait a minute, right?

00:28:00.400 --> 00:28:02.340
Yeah, exactly.

00:28:02.340 --> 00:28:08.040
Also, really love to see the let your IDE help you thanks to static typing.

00:28:08.040 --> 00:28:10.980
We'll definitely have to dive into that in a bit as well.

00:28:10.980 --> 00:28:12.040
That looks awesome.

00:28:13.300 --> 00:28:13.660
Cheers.

00:28:13.660 --> 00:28:15.080
Yeah, huge fan of static typing.

00:28:15.080 --> 00:28:17.800
You know, it's a bit of a controversial topic in some Python circles.

00:28:17.800 --> 00:28:23.140
Some people say that it's not really what Python is meant for and that it doesn't help you prevent bugs and all of that.

00:28:23.140 --> 00:28:25.480
And I can see where these people are coming from.

00:28:25.480 --> 00:28:36.120
But when I've got a statically typed library and my IDE is just always popping up with helpful suggestions and doc strings and all of that, then that's when I really appreciate it.

00:28:36.120 --> 00:28:37.100
Exactly.

00:28:37.100 --> 00:28:38.380
Like, forget the bugs.

00:28:38.420 --> 00:28:45.960
If I don't have to go to the documentation because I hit dot and it's immediately obvious what I'm supposed to do, that's already a win, right?

00:28:45.960 --> 00:28:47.340
And typing gives you that.

00:28:47.340 --> 00:28:48.800
Plus it gives you checking.

00:28:48.800 --> 00:28:50.500
Plus it gives you lots of other things.

00:28:50.600 --> 00:28:51.800
I think it's great.

00:28:51.800 --> 00:28:54.220
And especially with your focus on tool builders.

00:28:54.220 --> 00:28:57.720
Tool builders can build tools which have typing.

00:28:57.720 --> 00:29:00.720
They can build better tools using your typing.

00:29:00.720 --> 00:29:06.000
But they don't, because it's optional, it's not really forced upon any of the users.

00:29:06.000 --> 00:29:18.260
The only libraries that I can think of that really forced typing on their users is Pydantic and FastAPI and a couple of these that, like, Typer, that have behavior driven on the types you put.

00:29:18.260 --> 00:29:23.480
But if you're using that library, you're choosing that as a feature, not a bug, right?

00:29:23.480 --> 00:29:25.720
Yeah, exactly.

00:29:26.920 --> 00:29:28.060
Yeah, so awesome.

00:29:28.060 --> 00:29:35.680
And then finally, sticking with the focus on tool builders, perfect backwards compatibility policy.

00:29:35.680 --> 00:29:36.260
What does this mean?

00:29:36.260 --> 00:29:38.880
This is a bit of an ambitious thing.

00:29:38.880 --> 00:29:43.500
So when I was learning Rust, I read about Rust editions.

00:29:44.420 --> 00:29:51.640
So the idea is that when you start a Rust project, you specify the edition of Rust that you want to use.

00:29:51.640 --> 00:30:01.780
And even as Rust gets updated, if you write some project using the 2015 edition of Rust, then it should keep working essentially forever.

00:30:01.780 --> 00:30:03.680
So they keep this edition around.

00:30:03.680 --> 00:30:09.940
And if they have to make backwards incompatible changes, there's new editions like 2018, 2021 editions.

00:30:09.940 --> 00:30:12.240
So this is kind of what we're trying to do.

00:30:12.240 --> 00:30:16.620
Like, the idea was, well, we're kind of mimicking the Polars API.

00:30:16.620 --> 00:30:23.480
I think there was a bracket I opened down there, which I might not have finished, which was that the third choice we had was to make an entirely new API.

00:30:23.480 --> 00:30:28.620
But I thought, well, better to do something that people are somewhat familiar with.

00:30:28.620 --> 00:30:30.340
Yeah, I think that's a great choice.

00:30:30.340 --> 00:30:37.660
Yeah, because when you go and write the code, half of the people will already know Polars.

00:30:37.660 --> 00:30:38.840
And so they just keep doing that.

00:30:38.840 --> 00:30:42.060
You don't have to go, well, here's a third thing you have to learn, right?

00:30:42.960 --> 00:30:43.140
Yeah.

00:30:43.140 --> 00:30:48.280
I'd like to think that now half people know Polars.

00:30:48.280 --> 00:30:51.180
Unfortunately, I think we might not quite be there yet.

00:30:51.180 --> 00:30:52.220
No, I think so, too.

00:30:52.220 --> 00:30:52.800
Yeah.

00:30:52.800 --> 00:30:53.400
Yeah, yeah.

00:30:53.400 --> 00:30:54.420
I think we'll get there.

00:30:54.420 --> 00:30:56.740
So, yeah, it's okay.

00:30:56.820 --> 00:31:02.440
We're kind of mimicking a subset of the Polars API, and we're just sticking to fundamentals.

00:31:02.440 --> 00:31:05.140
So that part should be relatively stable.

00:31:05.140 --> 00:31:09.740
But at some point, presumably, Polars is going to make a backwards incompatible change.

00:31:09.740 --> 00:31:11.920
And at that point, what do we do in narwhals?

00:31:12.280 --> 00:31:14.520
What do we do about the top-level narwhals API?

00:31:15.440 --> 00:31:21.860
And coordinating changes between different libraries, it's going to get tricky.

00:31:21.860 --> 00:31:26.780
And the last thing that I want to do is see people put upper bound constraints on the narwhals library.

00:31:27.640 --> 00:31:32.080
I think upper bound constraints on something like this should never really be necessary.

00:31:32.080 --> 00:31:36.360
So we've tried to replicate what Rust does with its additions.

00:31:36.360 --> 00:31:40.080
The idea is that we've got a stable V1 API.

00:31:40.080 --> 00:31:45.180
We will have a stable V2 API at some point if we need to make backwards incompatible changes.

00:31:45.540 --> 00:31:53.760
But if you write your code using the V1 stable narwhals API, then even as new narwhals versions come out,

00:31:53.760 --> 00:31:59.440
even as the main narwhals namespace changes, even as we might introduce V2,

00:31:59.440 --> 00:32:03.680
then your code should, in theory, keep working.

00:32:03.680 --> 00:32:06.580
Like V1 should stay supported indefinitely.

00:32:06.580 --> 00:32:07.940
This is the intention.

00:32:07.940 --> 00:32:13.220
Yeah, and you said see the stable API for how to opt in.

00:32:14.880 --> 00:32:16.960
So how do you...

00:32:16.960 --> 00:32:18.700
So I'm just curious what the mechanism is.

00:32:18.700 --> 00:32:25.120
So, for example, import narwhals.stable.v1 as NW, which is the standard of narwhals.

00:32:25.120 --> 00:32:26.480
So instead of...

00:32:26.480 --> 00:32:27.520
I got you. That's cool.

00:32:27.520 --> 00:32:33.460
Yeah, instead of import narwhals as NW, you'll do import narwhals.stable.v1 as NW.

00:32:33.460 --> 00:32:38.480
And yeah, I encourage people when they're just trying it out, prototyping,

00:32:38.480 --> 00:32:40.360
use import narwhals as NW.

00:32:40.360 --> 00:32:44.820
If you want to make a release and future-proof yourself,

00:32:44.820 --> 00:32:47.500
then switch over to the stable.v1.

00:32:49.240 --> 00:32:57.460
This is a little similar to the api. talkpython.fm/v1 slash whatever

00:32:57.460 --> 00:33:04.180
versus where people encode a different version in their API endpoints, basically.

00:33:04.180 --> 00:33:06.740
But in import statements, I like it.

00:33:06.740 --> 00:33:07.200
I like it a lot.

00:33:07.200 --> 00:33:07.620
It's great.

00:33:10.120 --> 00:33:11.420
Yeah, that's how this goes.

00:33:11.420 --> 00:33:12.620
Yeah, exactly.

00:33:12.620 --> 00:33:13.240
Now it's good.

00:33:13.240 --> 00:33:15.940
So just back to typing real quick.

00:33:15.940 --> 00:33:18.620
Pamphil Roy out there says,

00:33:18.620 --> 00:33:22.360
a lot of open source maintainers complain about typing

00:33:22.360 --> 00:33:25.320
because if you want to make it really correct, it's painful to add.

00:33:25.320 --> 00:33:26.560
That can be true.

00:33:26.760 --> 00:33:30.940
The last 1% is some insane statement.

00:33:30.940 --> 00:33:34.000
But it's so helpful for end users.

00:33:34.000 --> 00:33:36.280
True, yeah.

00:33:36.280 --> 00:33:38.720
You mentioned earlier that everyone seems to be at Quantsight.

00:33:38.720 --> 00:33:40.360
Do you know where I met Pamphil?

00:33:40.360 --> 00:33:41.900
At Quantsight?

00:33:41.900 --> 00:33:44.140
He was an ex-colleague of mine at Quantsight.

00:33:44.240 --> 00:33:44.880
Amazing.

00:33:44.880 --> 00:33:47.400
See?

00:33:47.400 --> 00:33:48.580
It continues to happen.

00:33:48.580 --> 00:33:49.600
It's just...

00:33:49.600 --> 00:33:49.920
Yeah, exactly.

00:33:49.920 --> 00:33:54.940
But yeah, I think that totally sums it up for me as well.

00:33:54.940 --> 00:33:59.660
It's really great to be using libraries that give you those options.

00:33:59.660 --> 00:34:05.080
We do have the PYI files, and we have TypeShed and all of that

00:34:05.080 --> 00:34:09.420
where people can kind of put typing on things from the outside

00:34:09.420 --> 00:34:11.080
that didn't want to support it.

00:34:11.080 --> 00:34:15.340
But if it's built in and part of the project, it's just better, you know?

00:34:15.340 --> 00:34:17.180
Yeah.

00:34:17.180 --> 00:34:19.120
If you have it from day one, it works well.

00:34:19.120 --> 00:34:23.100
I mean, trying to add types to a library that started without types like Pandas,

00:34:23.100 --> 00:34:24.980
it's fairly painful to be honest.

00:34:24.980 --> 00:34:25.860
I bet it is.

00:34:25.860 --> 00:34:27.440
I bet it is.

00:34:27.440 --> 00:34:28.320
Yeah.

00:34:28.320 --> 00:34:28.820
Really cool.

00:34:28.820 --> 00:34:29.080
All right.

00:34:29.080 --> 00:34:33.120
Let's go and talk through...

00:34:33.120 --> 00:34:34.320
I guess a quick shout out.

00:34:34.320 --> 00:34:41.320
Last year, I had Richie Vink, who's the creator of Polars on Talk Python.

00:34:41.320 --> 00:34:46.380
If people want to check that out, they can certainly have a listen to that.

00:34:46.380 --> 00:34:51.540
And I also just recently had Wes McKinney, creator of Pandas, on.

00:34:51.540 --> 00:34:54.040
And I'll link to those shows if people want to dive into those.

00:34:54.200 --> 00:34:57.420
But let's talk a little bit through your documentation.

00:34:57.420 --> 00:34:59.400
It tells a really good story.

00:34:59.400 --> 00:35:04.040
I like what you've put down here as, you know, it's not just here's your API and stuff,

00:35:04.040 --> 00:35:05.460
but it walks you through.

00:35:05.460 --> 00:35:10.740
So we talked about why, obviously, install, pip install.

00:35:10.740 --> 00:35:13.720
It's pure Python with a pure Python wheel, right?

00:35:14.680 --> 00:35:15.280
Yeah, exactly.

00:35:15.280 --> 00:35:17.900
Shouldn't be any issues with installation.

00:35:17.900 --> 00:35:21.700
Is it WASM compatible?

00:35:21.700 --> 00:35:22.240
Do you know?

00:35:22.240 --> 00:35:25.960
Could I use it on PyScript, Pyodide, Jupyterly?

00:35:25.960 --> 00:35:27.720
I don't know.

00:35:27.720 --> 00:35:30.820
Are there any restrictions that they need?

00:35:30.820 --> 00:35:32.780
There's some restrictions.

00:35:32.780 --> 00:35:35.000
For example, I don't think you can do threading.

00:35:35.000 --> 00:35:40.580
I don't think you can use some of the common, which you don't have any dependencies,

00:35:40.720 --> 00:35:46.100
but some of the common third-party HTTP clients because it has to go through the browser's

00:35:46.100 --> 00:35:46.620
AJAX layer.

00:35:46.620 --> 00:35:48.780
There's some, but not terribly many restrictions.

00:35:48.780 --> 00:35:55.300
I'd imagine then that we would only be limited by whichever data frame people are passing in.

00:35:55.300 --> 00:35:56.180
Yeah, yeah.

00:35:56.180 --> 00:35:56.440
Awesome.

00:35:56.440 --> 00:35:57.580
Okay.

00:35:57.580 --> 00:35:59.760
That's super nice.

00:35:59.760 --> 00:36:05.960
And maybe let's just talk through a quick example here, keeping in mind that most people

00:36:05.960 --> 00:36:10.420
can't see any of the code, but let's just give them a sense still of what is it,

00:36:10.680 --> 00:36:17.200
look like to write code that is interoperable with both or all these different libraries,

00:36:17.200 --> 00:36:20.840
these data frame libraries using narwhals.

00:36:20.840 --> 00:36:22.540
So maybe give us just an example.

00:36:22.540 --> 00:36:23.960
Sure.

00:36:23.960 --> 00:36:30.780
So the idea is what we can see on the screen is just a very simple example of a data frame

00:36:30.780 --> 00:36:31.680
agnostic function.

00:36:31.680 --> 00:36:37.740
We've got a function called my function, and this is something that users could maybe just

00:36:37.740 --> 00:36:38.040
use.

00:36:38.160 --> 00:36:42.580
Maybe it's something your library exposes, but the user doesn't need to know about narwhals.

00:36:42.580 --> 00:36:46.680
The narwhals only happens once you get inside the function.

00:36:47.320 --> 00:36:49.160
So the user passes in some data frame.

00:36:49.160 --> 00:36:54.140
We then call narwhals.from native on that data frame object.

00:36:54.140 --> 00:36:58.660
We do some operation, and then we return some native object back to the user.

00:36:58.660 --> 00:37:02.740
Now the narwhals.from native, it's a practically free operation.

00:37:02.740 --> 00:37:04.480
It's not doing any data conversion.

00:37:04.480 --> 00:37:10.060
It's just instantiating some narwhals class that's backed by your original data frame.

00:37:10.060 --> 00:37:11.400
Right, right.

00:37:11.400 --> 00:37:20.740
And I imagine if it's a polar data frame that gets passed in, it's probably a more direct

00:37:20.740 --> 00:37:27.360
pass-through to the API than if you're doing operations on a pandas frame, right?

00:37:27.360 --> 00:37:30.640
Is there a difference of sort of runtime depending on the back end?

00:37:31.640 --> 00:37:35.060
The overhead is really low even for the pandas case.

00:37:35.060 --> 00:37:40.040
In fact, sometimes things do get a little bit faster because of how careful we've been about

00:37:40.040 --> 00:37:45.800
avoiding index operations and unnecessary copies.

00:37:46.480 --> 00:37:52.140
To be honest, some of this will be alleviated in pandas version 3 when copy on write becomes the default.

00:37:52.140 --> 00:37:54.940
Oh, that's interesting, yeah.

00:37:54.940 --> 00:38:00.780
Yeah, in terms of the mapping, on the implementation side, it's a bit easier to do the polar's back end.

00:38:00.780 --> 00:38:02.880
But even then, we do need to do some version checks.

00:38:02.880 --> 00:38:09.440
Like in 0.20.4, they renamed with row count to with row index, I think.

00:38:09.440 --> 00:38:13.680
So, yeah, even there, we do need some if-then statements.

00:38:13.680 --> 00:38:18.880
But at the end of the day, what the library does is there's a few extra function calls,

00:38:18.880 --> 00:38:21.240
a few checks on versions.

00:38:21.240 --> 00:38:23.900
It's not really doing that much.

00:38:23.900 --> 00:38:28.920
You might experience an extra millisecond compared to running something natively at most.

00:38:28.920 --> 00:38:36.820
And usually, you're using a data frame because you have some amount of data, even hundreds of rows.

00:38:36.820 --> 00:38:42.060
It's still most of the computation is going to end up there rather than if it's version this, call that,

00:38:42.060 --> 00:38:43.260
otherwise call this, right?

00:38:43.360 --> 00:38:45.760
That's not a lot of overhead, relatively speaking.

00:38:45.760 --> 00:38:47.540
I agree, yeah.

00:38:47.540 --> 00:38:53.460
So, yeah, we see an example here of a data frame agnostic function, which just calculates some

00:38:53.460 --> 00:38:59.600
descriptive statistics from an input data frame using the expressions API, which we talked about earlier.

00:38:59.600 --> 00:39:00.060
Yeah.

00:39:00.060 --> 00:39:02.480
And here's something that I quite like about mkdocs.

00:39:02.880 --> 00:39:04.740
So, you see where it says, let's try it out.

00:39:04.740 --> 00:39:07.380
We've got these different tabs.

00:39:07.380 --> 00:39:07.880
Yes.

00:39:07.880 --> 00:39:12.060
You can click on polars, pandas, polars lazy.

00:39:12.060 --> 00:39:16.240
And then you can see in each case what it looks like from the user's point of view.

00:39:16.240 --> 00:39:18.640
And you can compare the outputs.

00:39:18.640 --> 00:39:22.880
So, from the user's point of view, they're just passing their object to funk.

00:39:22.880 --> 00:39:27.480
What they're not seeing is that under the hood, funk is using narwhals.

00:39:27.480 --> 00:39:30.820
But from their perspective, they put pandas in, they get pandas out.

00:39:30.820 --> 00:39:32.900
They put polars in, they get polars out.

00:39:33.280 --> 00:39:33.980
That's awesome.

00:39:33.980 --> 00:39:36.820
So, we talked about the typing.

00:39:36.820 --> 00:39:41.040
And in this one, we have a df typed as a frame t.

00:39:41.040 --> 00:39:44.140
Is that some sort of generic?

00:39:44.140 --> 00:39:46.360
And does it have restrictions on it?

00:39:46.360 --> 00:39:47.220
What is this frame t?

00:39:47.220 --> 00:39:50.460
I didn't type in the source and check it out before.

00:39:50.460 --> 00:39:52.480
Sure, yeah, it's a type fur.

00:39:52.480 --> 00:39:59.280
So, it's just the idea that you start with a data frame of some kind, and you get back some data frame of the same kind.

00:39:59.280 --> 00:40:03.080
Start with polars, get back polars, start with pandas, get back pandas.

00:40:03.080 --> 00:40:04.260
And so on.

00:40:04.260 --> 00:40:10.300
And, yeah, this version of the function is using the decorator nw.narwhalify.

00:40:10.300 --> 00:40:13.740
Narwhalify, it's a fantastic verb.

00:40:13.740 --> 00:40:22.000
So, yeah, so there's two ways in which you can implement your function.

00:40:22.000 --> 00:40:31.960
You can do it the explicit way where that's in the quick start and the docs where you write your function that takes some frame,

00:40:31.960 --> 00:40:37.640
some native frame, and then you convert that to this narwhals one.

00:40:37.640 --> 00:40:38.440
You say from native.

00:40:38.440 --> 00:40:39.420
Then you do your work.

00:40:39.420 --> 00:40:43.440
And then, depending on, you could convert it back.

00:40:43.440 --> 00:40:45.900
Or in this case, it returns a list of strings in that example.

00:40:46.680 --> 00:40:57.880
Or you can skip the first and the last step and just put this decorator on it, and it'll convert it to, or wait, convert it from, and then convert it to on the way in and out, right?

00:40:57.880 --> 00:40:59.380
Yeah, exactly.

00:40:59.640 --> 00:41:07.380
So if you're really strict about type annotations, then using from native and to native gives you a little bit of extra information.

00:41:09.320 --> 00:41:10.280
I see.

00:41:10.280 --> 00:41:11.980
I think Narwhalify looks a little bit neater.

00:41:11.980 --> 00:41:13.160
Yeah, that's true.

00:41:13.160 --> 00:41:23.560
So, for example, in the first one, you could say that this is actually a panda's data frame because you're writing the code or something like that.

00:41:23.560 --> 00:41:23.900
I don't know.

00:41:23.900 --> 00:41:25.540
What is this into frame?

00:41:25.540 --> 00:41:27.800
This is the type on this first example.

00:41:28.600 --> 00:41:35.120
Yeah, by into frame, we mean something that can be converted into a novel's data frame or lazy frame.

00:41:35.120 --> 00:41:37.660
How do you implement that in the type system?

00:41:37.660 --> 00:41:40.580
Is it a protocol or what is this?

00:41:40.580 --> 00:41:43.640
Yeah, we've got a protocol.

00:41:43.640 --> 00:41:47.360
So I just found some methods that these libraries have in common.

00:41:47.360 --> 00:41:48.060
Exactly.

00:41:48.060 --> 00:41:48.580
Which wasn't too much.

00:41:48.580 --> 00:41:49.200
You can find them.

00:41:49.200 --> 00:41:51.720
That's what I was thinking, yeah.

00:41:51.720 --> 00:41:53.500
Okay.

00:41:54.340 --> 00:42:01.380
Yeah, but if it has enough of the functions of pandas or pollers, you're like, all right, this is probably good.

00:42:01.380 --> 00:42:01.960
All right?

00:42:01.960 --> 00:42:03.180
And you can say it's one of these.

00:42:03.180 --> 00:42:04.260
That's pretty cool.

00:42:04.260 --> 00:42:06.140
Yeah, exactly.

00:42:06.140 --> 00:42:11.380
I mean, if any of this is confusing to listeners, we do have a page there in the documentation that's all about typing.

00:42:11.380 --> 00:42:14.380
And so people can read through that at their own leisure.

00:42:14.380 --> 00:42:16.560
Yeah, for sure.

00:42:16.560 --> 00:42:18.280
All right.

00:42:18.280 --> 00:42:19.020
Let's see.

00:42:19.020 --> 00:42:22.760
I do like the mkdocs where you can have these different examples.

00:42:23.140 --> 00:42:32.140
One thing I noticed is you've got the pollers eager evaluation and you've got the pollers lazy evaluation.

00:42:32.140 --> 00:42:40.820
And when you have the pollers lazy, this function decorated with the decorator, the narwhalify decorator,

00:42:40.820 --> 00:42:47.120
it itself returns something that is lazy and you've got to call collect on, right?

00:42:47.120 --> 00:42:49.460
So it kind of preserves the laziness, I guess.

00:42:49.460 --> 00:42:49.900
Is that right?

00:42:49.900 --> 00:42:51.460
Yes, exactly.

00:42:51.460 --> 00:42:58.700
This was something that was quite important to me, like not be something that only works well with eager execution.

00:42:58.700 --> 00:43:05.840
I want to have some level of support such that lazy in mean lazy out.

00:43:05.840 --> 00:43:06.620
Yeah.

00:43:06.620 --> 00:43:07.820
Eager in, eager out.

00:43:07.820 --> 00:43:08.840
Lazy in, lazy out.

00:43:08.840 --> 00:43:09.100
Okay.

00:43:09.100 --> 00:43:10.040
Exactly.

00:43:10.780 --> 00:43:11.020
Yeah.

00:43:11.020 --> 00:43:11.040
Yeah.

00:43:11.040 --> 00:43:16.640
So the way you do that in pollers, you create a lazy frame versus a data frame, right?

00:43:16.640 --> 00:43:22.760
But then you've got to call collect on it, kind of like awaiting it and fit more async, which is cool.

00:43:22.760 --> 00:43:24.400
Yeah.

00:43:24.400 --> 00:43:28.720
Well, don't call collect or just wait until you really need to call collect.

00:43:28.720 --> 00:43:29.280
Right.

00:43:29.280 --> 00:43:31.540
Or pass it on to the next one and on to the next.

00:43:31.660 --> 00:43:32.380
Yeah, exactly.

00:43:32.380 --> 00:43:32.540
Exactly.

00:43:32.540 --> 00:43:32.980
Exactly.

00:43:32.980 --> 00:43:33.160
Exactly.

00:43:33.160 --> 00:43:43.820
So one of the things that you talk about here is the pandas index, which is one of the key differences between pollers and pandas.

00:43:44.900 --> 00:43:48.860
And you've classified pandas people into two categories.

00:43:48.860 --> 00:43:53.580
Those who love the index and those who try to get rid of it and ignore it.

00:43:53.580 --> 00:43:55.860
Yeah, exactly.

00:43:55.860 --> 00:44:00.500
So if James Powell is listening, I think we can put him in the first category.

00:44:00.500 --> 00:44:08.680
I think most, realistically, most pandas users that I've seen call .reset index drop equals true every other line of code.

00:44:08.680 --> 00:44:13.200
They just find that the index gets in the way more than helps them most of the time.

00:44:14.320 --> 00:44:17.200
And with novels, we're trying to accommodate both.

00:44:17.200 --> 00:44:20.560
So we don't do automated index alignment.

00:44:20.560 --> 00:44:23.220
So this isn't something that you have to worry about.

00:44:23.220 --> 00:44:37.020
But if you are really bothered about index alignment, say, due to backwards compatibility concerns, then we do have some functions which allow you to do that, which would be no operations for other libraries.

00:44:37.020 --> 00:44:41.580
There's an example in scikit-lego of where they were relying on pandas index alignment.

00:44:42.240 --> 00:44:43.340
So we've got a function here.

00:44:43.340 --> 00:44:45.700
Narwhals may be a line index.

00:44:45.700 --> 00:44:49.780
So for pandas like, it'll do the index will do its thing.

00:44:49.780 --> 00:44:53.320
And for other libraries, the data will just be passed through.

00:44:53.320 --> 00:44:54.600
Right.

00:44:54.600 --> 00:45:01.160
So you said there, you said there pandas like and pandas like is actually a type in your type system, right?

00:45:01.160 --> 00:45:02.860
Can I see that around?

00:45:03.080 --> 00:45:04.280
So we've got, yeah, yeah.

00:45:04.280 --> 00:45:08.240
So we've got is pandas like data frame function to tell.

00:45:08.240 --> 00:45:12.780
So by pandas like, we mean pandas QDF modin.

00:45:12.780 --> 00:45:16.800
So the libraries that have an index and follow those kinds of rules.

00:45:16.800 --> 00:45:18.360
Yeah.

00:45:18.360 --> 00:45:19.360
Yeah, that's really cool.

00:45:20.940 --> 00:45:30.100
Yeah, because at the end of the day, like the idea of writing completely data frame agnostic code is a lot easier for new libraries than for existing libraries that have backwards compatibility concerns.

00:45:30.100 --> 00:45:35.440
And we recognize that it's, it might not be completely achievable.

00:45:35.440 --> 00:45:47.980
I think in all of the use cases where we've seen Narwhals adopted, they're doing most of it in a data frame agnostic way, but they do have some parts of it where they're saying, okay, if this is a pandas data frame, we've got some pandas specific logic.

00:45:47.980 --> 00:45:51.200
And otherwise, let's go down the data frame agnostic route.

00:45:51.200 --> 00:45:56.680
Yeah, you also have here levels of support.

00:45:56.680 --> 00:45:57.960
You have full and interchange.

00:45:57.960 --> 00:45:59.440
I think we talked about that a little bit.

00:45:59.440 --> 00:46:07.980
So maybe just point people here, but this is, if you want to be QDF or modin, you can fully integrate.

00:46:07.980 --> 00:46:16.180
Or if you just want to have enough of an implementation that they can kind of work together, right?

00:46:16.180 --> 00:46:18.480
You can do this data frame interchange protocol.

00:46:18.480 --> 00:46:20.200
Yeah, exactly.

00:46:20.200 --> 00:46:27.000
Or just write to us and we'd be happy to accommodate you without you having to go through the data frame interchange protocol.

00:46:27.000 --> 00:46:27.940
Oh, yeah.

00:46:27.940 --> 00:46:28.460
Very nice.

00:46:28.460 --> 00:46:28.940
Okay.

00:46:28.940 --> 00:46:32.980
You mentioned the overhead before, but you do have a picture.

00:46:32.980 --> 00:46:34.460
Picture's always fun.

00:46:34.460 --> 00:46:42.140
And in the picture, you've got little different operations, different times for each of the operations.

00:46:42.140 --> 00:46:48.520
And there's a quite small overhead for pandas versus pandas with Narwhals.

00:46:48.520 --> 00:46:50.380
Yeah, exactly.

00:46:50.380 --> 00:46:53.700
Like in some of them, you can see it becoming a little bit faster.

00:46:53.700 --> 00:46:55.860
In some of them, you can see it becoming a little bit slower.

00:46:56.780 --> 00:47:02.040
And these are queries that I think are the size that you can expect most data scientists to be working with a lot of the time.

00:47:02.040 --> 00:47:06.100
You've got queries that take between a couple of seconds to 30 seconds.

00:47:06.100 --> 00:47:12.360
And it's pretty hard to distinguish reliably between the blue and red dots.

00:47:12.360 --> 00:47:14.040
Sometimes one's higher.

00:47:14.040 --> 00:47:15.800
Sometimes the other one's higher.

00:47:16.340 --> 00:47:20.180
There's a bit of statistical variance just between running the same benchmark multiple times.

00:47:20.180 --> 00:47:23.320
But overall, yeah, we were pretty happy with these results.

00:47:24.760 --> 00:47:25.720
Yeah, that's great.

00:47:25.720 --> 00:47:32.060
So how well have we covered how it works?

00:47:32.060 --> 00:47:34.680
We talked about the API, but I don't know.

00:47:34.680 --> 00:47:40.320
We've talked about the implementation of how you actually...

00:47:40.320 --> 00:47:43.200
Why is it basically almost the same speed?

00:47:43.200 --> 00:47:44.540
Why are you not doing it?

00:47:44.540 --> 00:47:45.180
Why is it not more work?

00:47:45.180 --> 00:47:48.060
Are you using underwater unicorn magic?

00:47:48.060 --> 00:47:49.360
Is that what it is?

00:47:49.820 --> 00:47:50.960
That's the secret, yes.

00:47:50.960 --> 00:47:52.120
Underwater unicorn magic.

00:47:52.120 --> 00:47:56.240
Well, perhaps first I should just say why we wrote this, how it works.

00:47:56.240 --> 00:47:59.780
And it's because really I want this to be a community-driven project.

00:48:00.440 --> 00:48:05.660
And this is one of those cases where open source is more of a social game than a technical one.

00:48:05.660 --> 00:48:07.200
I'm not saying that's always the case.

00:48:07.200 --> 00:48:09.340
There are many problems that are purely technical.

00:48:09.340 --> 00:48:11.780
Now else is a social game in the end.

00:48:11.780 --> 00:48:13.840
Like what we're doing isn't that complicated.

00:48:13.840 --> 00:48:18.940
But if we want it to work, then it needs to be accessible to the community.

00:48:18.940 --> 00:48:21.060
People do need to be able to trust us.

00:48:21.060 --> 00:48:24.980
And that typically does not happen if it's a one-person project.

00:48:25.520 --> 00:48:29.940
So it was really important to me that different people would be able to contribute to it,

00:48:29.940 --> 00:48:32.780
that it all be as simple and clear as possible.

00:48:32.780 --> 00:48:35.940
So I made this page trying to explain how it works.

00:48:35.940 --> 00:48:39.920
It's not quite as clear and quite as extensive as it'd like to be.

00:48:39.920 --> 00:48:42.960
But a few contributors did say that it really helped them.

00:48:42.960 --> 00:48:46.300
So in terms of how do we get this low overhead,

00:48:46.300 --> 00:48:51.500
so we're just defining an expression as being a function from a data frame to a sequence of series.

00:48:51.500 --> 00:48:54.860
And then we're just repeatedly and strictly applying that definition.

00:48:55.500 --> 00:48:57.380
So there's nothing too fancy going on.

00:48:57.380 --> 00:49:04.800
That's like in the end, just evaluating Lambda functions in Python,

00:49:04.800 --> 00:49:07.440
going down the stack trace, like it's pretty fast.

00:49:07.440 --> 00:49:08.860
Yeah, that's really cool.

00:49:08.860 --> 00:49:11.280
Yeah, so people can check this out if they want to know.

00:49:11.280 --> 00:49:14.160
I think this might be where I saw the pandas-like expression.

00:49:14.160 --> 00:49:15.200
Ah, right, yeah.

00:49:15.200 --> 00:49:16.380
Yeah, pandas-like.

00:49:16.380 --> 00:49:19.500
It's this class that encompasses pandas mode in QDR,

00:49:19.500 --> 00:49:21.820
the ones that kind of follow the pandas API.

00:49:21.820 --> 00:49:25.000
Yeah, close enough for what you need to do.

00:49:25.480 --> 00:49:26.720
Yeah, exactly.

00:49:28.640 --> 00:49:35.980
All right, well, I saw a question out there in the audience somewhere from Francesco,

00:49:35.980 --> 00:49:37.940
which was basically asking about the roadmap.

00:49:37.940 --> 00:49:39.940
Like, where are you?

00:49:39.940 --> 00:49:41.300
Where are you going?

00:49:41.300 --> 00:49:43.700
Yeah, I should probably introduce Francesco.

00:49:43.700 --> 00:49:47.800
He's one of the most active contributors to the project.

00:49:47.800 --> 00:49:52.080
So thanks, Francesco, for helping to make it a success.

00:49:52.080 --> 00:49:56.880
He was actually also the first person to adopt Narwhals in one of his libraries.

00:49:59.100 --> 00:50:04.840
Yeah, I spoke to him about it at a conference, and he was like, I've got this tiny little time-based CV library.

00:50:04.840 --> 00:50:06.820
Let's try now qualifying it as an experiment.

00:50:06.820 --> 00:50:09.160
Sure, we did that then.

00:50:10.160 --> 00:50:10.500
PsychicLern.

00:50:10.500 --> 00:50:12.060
Not PsychicLern, sorry.

00:50:12.060 --> 00:50:13.080
Not there yet.

00:50:13.080 --> 00:50:18.940
PsychicLego, which was this kind of experimental building blocks for PsychicLern pipelines that he maintains.

00:50:19.460 --> 00:50:21.600
And then we've just been taking it from there.

00:50:21.600 --> 00:50:30.000
So in terms of roadmap, my top priority is helping out libraries that have shown interest in Narwhals.

00:50:30.620 --> 00:50:38.720
So at the moment, Formulaic, that opened a draft pull request in which they were trying out Narwhals, and they tagged me just about some things they were missing.

00:50:38.720 --> 00:50:42.260
So I'd like to see if I can take that to completion.

00:50:42.260 --> 00:50:47.720
I think I've got most of it working, but just been a bit busy with conferences recently.

00:50:47.720 --> 00:50:53.280
So maybe next month I'll be able to get something ready for review and show that to them.

00:50:53.280 --> 00:50:54.740
That would be pretty cool.

00:50:54.740 --> 00:50:57.420
Summer is passing.

00:50:57.420 --> 00:50:58.780
The conferences are ending.

00:50:58.780 --> 00:51:00.220
It's going to get dark and cold.

00:51:00.920 --> 00:51:01.820
Perfect time to program.

00:51:01.820 --> 00:51:09.440
Yeah, we'll get back to the situation that I was in when I started Narwhals, which was that it was a rainy Friday.

00:51:09.440 --> 00:51:10.680
Not Friday, sorry.

00:51:10.680 --> 00:51:15.520
It was a rainy February weekend in Wales, the rainiest part of the UK.

00:51:15.520 --> 00:51:18.580
Yeah, that's exactly the same in Oregon here.

00:51:18.580 --> 00:51:20.480
So it's a good time to get stuff done.

00:51:20.480 --> 00:51:21.980
Yeah, exactly.

00:51:21.980 --> 00:51:28.980
And then I've been speaking to people from Shiny and Plotly about potentially looking into Narwhals.

00:51:30.160 --> 00:51:33.520
There's no contract set in stone or anything.

00:51:33.520 --> 00:51:36.600
These people may well change their mind if it doesn't work for them.

00:51:36.600 --> 00:51:38.940
But my idea is, okay, they've shown interest.

00:51:38.940 --> 00:51:44.720
Let's go headfirst into seeing whether we can help them and whether they'd be able to use Narwhals.

00:51:44.720 --> 00:51:50.120
If it doesn't work for Narwhals, we'll just have strengthened the Narwhals API and learn some new things.

00:51:50.120 --> 00:51:52.520
If it does work, then great, exciting.

00:51:54.440 --> 00:51:56.340
So that's my top priority.

00:51:56.340 --> 00:52:00.880
And it's been really pleasing to see the contributor to community develop around Narwhals.

00:52:00.880 --> 00:52:04.120
Narwhals, I really thought it would be a one-person project for a long time.

00:52:04.120 --> 00:52:07.680
But so many people have been contributing really high-quality pull requests.

00:52:07.680 --> 00:52:12.000
It's really been, yeah, you've got to do, okay, one of them is this.

00:52:12.000 --> 00:52:16.860
Okay, maybe a couple of them here are like GitHub bots, this pre-commit CI bot.

00:52:17.720 --> 00:52:18.640
Maybe that's not counted.

00:52:18.640 --> 00:52:20.900
Maybe 40, 30, but still, that's a lot.

00:52:20.900 --> 00:52:27.840
And while we're talking numbers on the homepage, I also want to point out 10 million downloads a month is a lot of downloads.

00:52:27.840 --> 00:52:28.740
That's awesome.

00:52:28.740 --> 00:52:36.620
Yeah, that's maybe slightly misleading because they pretty much just come from the fact that it's now a required dependency of Altair.

00:52:36.620 --> 00:52:37.660
Well, exactly.

00:52:37.660 --> 00:52:39.460
It's millions of downloads.

00:52:39.460 --> 00:52:40.160
Yeah, yeah, yeah, exactly.

00:52:40.160 --> 00:52:43.540
But that's the place of some libraries.

00:52:43.540 --> 00:52:49.600
Like, I don't think many people go, oh, let me go get this HTTP library or it's dangerous.

00:52:49.600 --> 00:52:51.520
They just go, I'm going to use Flask, right?

00:52:51.520 --> 00:53:00.380
But it's still a really important building block of the community, even if people don't seek it out as a top-level thing they use, right?

00:53:00.380 --> 00:53:02.180
Sure, cheers, thanks, yeah.

00:53:02.180 --> 00:53:07.120
In fact, if we do our job well, then most people should never know about novels.

00:53:07.120 --> 00:53:07.780
Exactly.

00:53:07.780 --> 00:53:10.220
They should just use, should just work.

00:53:10.220 --> 00:53:11.180
Yeah, exactly.

00:53:11.180 --> 00:53:16.540
They just look in their pip list like, what is this whale thing in here?

00:53:16.540 --> 00:53:18.560
Yeah, exactly.

00:53:18.560 --> 00:53:19.380
Yeah.

00:53:19.380 --> 00:53:25.580
So, yeah, it's been really encouraging, really pleasing to see this contributor community emerge around the project.

00:53:25.580 --> 00:53:35.720
And I think a lot of the contributors are really interested in adding extra methods and adding extra backends and things.

00:53:35.920 --> 00:53:40.160
So, I'm trying to leave a lot of that to the community.

00:53:40.160 --> 00:53:44.880
So, like with Dask, I just got the rough building blocks together.

00:53:44.880 --> 00:53:53.280
And then it was just so nice, like so many really high-quality contributions coming up that brought the Dask support pretty much complete.

00:53:53.280 --> 00:53:57.280
We should see now if we're able to execute all of the TPC-H queries with the Dask backend.

00:53:57.280 --> 00:54:01.580
We might actually be there or be pretty close to getting there.

00:54:02.200 --> 00:54:02.740
Nice.

00:54:02.740 --> 00:54:06.480
What does TPC-H stand for?

00:54:06.480 --> 00:54:11.620
I don't remember what it stands for, but it's a set of database queries.

00:54:11.620 --> 00:54:12.660
I see.

00:54:12.940 --> 00:54:16.300
They were originally written for testing out different databases.

00:54:16.300 --> 00:54:18.640
So, it's a bunch of SQL queries.

00:54:18.640 --> 00:54:37.160
But I'm not sure if it was Kaggle that popularized the idea of translating these SQL queries to data frame-like APIs and then running different data frames on them to see who wins the speed test.

00:54:37.360 --> 00:54:46.820
But we just figured they do a bunch of things like joins, concatenations, filtering, comparisons with dates, string operations.

00:54:46.820 --> 00:54:53.480
And we're like, okay, if the NowLs API is able to do all of this, then maybe it's extensive enough to be useful.

00:54:53.480 --> 00:54:54.400
Right.

00:54:54.400 --> 00:54:54.600
Yeah.

00:54:54.600 --> 00:54:54.780
Yeah.

00:54:54.780 --> 00:54:57.300
That's super cool.

00:54:57.300 --> 00:55:02.420
It sounds a little bit like the TOB index plus other stuff maybe, but for databases.

00:55:04.200 --> 00:55:05.780
I'm not familiar with that.

00:55:05.780 --> 00:55:08.600
It's like a language ranking type of thing.

00:55:08.600 --> 00:55:12.400
And one aspect is maybe ranking the databases.

00:55:12.400 --> 00:55:14.240
But yeah, no, this is very cool.

00:55:14.240 --> 00:55:14.560
Okay.

00:55:14.560 --> 00:55:15.520
Got it.

00:55:15.520 --> 00:55:22.800
In the end, we're not trying to be fast as NowLs, but we just want to make sure that there's no extra overhead.

00:55:22.800 --> 00:55:23.700
Exactly.

00:55:23.700 --> 00:55:29.960
As long as you're not much slower than the stuff that you're operating with, that's all you should ask for.

00:55:29.960 --> 00:55:32.980
You can't make it go faster in the extreme.

00:55:32.980 --> 00:55:37.120
You did talk about some optimizations, but you can't fundamentally change what's happening.

00:55:37.120 --> 00:55:40.380
Yeah, we could do some optimizations on the NowL side.

00:55:40.380 --> 00:55:42.280
But to be honest, I'm not sure I want to.

00:55:42.280 --> 00:55:46.480
And part of the reason is because I want this to be a pretty simple project that's easy to maintain.

00:55:46.480 --> 00:55:47.440
Yeah, sure.

00:55:47.440 --> 00:55:49.980
And that's really just low overhead.

00:55:49.980 --> 00:55:54.120
Add extra docs and tutorials coming.

00:55:54.120 --> 00:55:55.520
That's fun.

00:55:56.400 --> 00:55:59.900
You're looking for contributors and maybe want to write some tutorials or docs?

00:55:59.900 --> 00:56:01.480
I would love this, yeah.

00:56:01.480 --> 00:56:09.020
I mean, it drives me crazy when I see so many projects where people have put so much effort into making a really good product, but then the documentation is really scant.

00:56:09.020 --> 00:56:15.260
Like, if you don't prioritize writing good docs, nobody's going to use your product.

00:56:15.940 --> 00:56:19.620
So I was really grateful to my company.

00:56:19.620 --> 00:56:25.300
They had four interns come on who really helped out with making the docs look amazing.

00:56:25.300 --> 00:56:25.960
Oh, that's cool.

00:56:25.960 --> 00:56:34.180
Like, if you look at the API reference, I think every single function now has got a doc string with an example.

00:56:34.180 --> 00:56:36.640
At the bottom, I think there's API reference.

00:56:36.800 --> 00:56:45.120
Yeah, if you search for any function in here, yeah, in the search box at the top, I don't know, series dot something.

00:56:45.120 --> 00:56:53.920
Here's, see, for any of these, we've got like an example of, okay, here's how you could write a data frame agnostic function which uses this method.

00:56:53.920 --> 00:56:58.020
And let's show that if you pass pandas or polars, you get the same result.

00:56:58.440 --> 00:57:05.920
And if there's some slight differences that we just cannot get around, like in the way that they handle the missing values, then we've got a very clear note about in the docs.

00:57:05.920 --> 00:57:07.100
Yeah, that's great.

00:57:07.100 --> 00:57:12.460
Maybe someday support for DuckDB.

00:57:12.460 --> 00:57:14.980
I would like that.

00:57:14.980 --> 00:57:19.460
I don't think we have much of a choice about whether or not we support DuckDB.

00:57:19.460 --> 00:57:21.800
Like, DuckDB is really on fire now.

00:57:21.800 --> 00:57:24.060
It really is.

00:57:24.720 --> 00:57:36.080
Yeah, I think it might be a question of either we have some level of support for DuckDB or somebody else is going to make something like novels that support DuckDB and then we become extinct.

00:57:36.080 --> 00:57:43.080
But besides, to be honest, DuckDB is amazing.

00:57:43.080 --> 00:57:46.640
I just find it a bit painful to write SQL strings.

00:57:46.640 --> 00:57:53.640
And so if I could use DuckDB but with the Polars API that I prefer and I'm more familiar with, then...

00:57:53.640 --> 00:57:56.100
Yeah, I 100% agree.

00:57:56.100 --> 00:57:57.820
It looks super nice.

00:57:57.820 --> 00:58:03.140
But if you look, it has a SQL example and then the Python example is just SQL, quote, quote, quote.

00:58:03.140 --> 00:58:04.040
Yeah, exactly.

00:58:04.040 --> 00:58:06.320
Here's the SQL embedded in Python, you know what I mean?

00:58:06.320 --> 00:58:09.000
So you're kind of writing SQL no matter what.

00:58:09.000 --> 00:58:14.300
Yeah, and then the error messages that you get sometimes are like, oh, there's a pass error near this keyword.

00:58:14.300 --> 00:58:16.140
And you're like, what on earth is going on?

00:58:17.180 --> 00:58:18.700
And then you're like, oh, yeah, I forgot.

00:58:18.700 --> 00:58:21.520
I forgot an extra comma at the end of my select or something.

00:58:21.520 --> 00:58:21.860
I don't know.

00:58:21.860 --> 00:58:21.960
Yeah.

00:58:21.960 --> 00:58:30.980
So DuckDB is a little bit like SQLite, but for analytics rather than relational maybe.

00:58:30.980 --> 00:58:33.640
I'm not sure if that's a good summary.

00:58:33.640 --> 00:58:40.320
Primarily aimed at analysts, analytical kinds of things, data scientists and people.

00:58:40.320 --> 00:58:49.160
What we are going to struggle with is that in DuckDB there's no guarantees about row order or operations.

00:58:50.920 --> 00:59:00.720
But on the plus side, when I look at what Altair are doing with data frames, when I look at some of the other libraries that I've shown interest in novels, they're often just doing very simple things.

00:59:00.720 --> 00:59:02.840
They're not doing things that depend on row order.

00:59:02.840 --> 00:59:08.840
So if we could just initially just support DuckDB for the operations that don't require row order.

00:59:08.840 --> 00:59:14.540
So for something like a cumulative sum, maybe initially we just don't support that for DuckDB.

00:59:15.700 --> 00:59:20.080
Like in the end, if you want to do advanced SQL, just use DuckDB directly.

00:59:20.080 --> 00:59:24.980
Like, as I said earlier, I don't recommend that end users use novels directly.

00:59:24.980 --> 00:59:36.720
But even just having some common operations, ones that aren't row order dependent, I'd like to think that this is already enough to solve some real problems for real people.

00:59:36.720 --> 00:59:40.420
Yeah, I know you said it's mostly for library builders.

00:59:40.420 --> 00:59:55.380
But if you were building an app and you were not committed to your data frame library, or you really wanted to leave open the possibility of choosing a different data frame library, you know, sort of using Narwhals to isolate that a little bit might be nice, right?

00:59:55.380 --> 00:59:56.560
Yeah.

00:59:56.560 --> 00:59:58.400
So, yeah.

01:00:00.580 --> 01:00:03.940
Yeah, if anyone tries to do this, and I'd love to hear your story.

01:00:03.940 --> 01:00:07.740
I did hear from somebody in our community call.

01:00:07.740 --> 01:00:11.920
We've got a community call every two weeks, by the way, if anyone wants to come and chat with us.

01:00:11.920 --> 01:00:23.620
I did hear from somebody that, like, at work has got some teams that are primarily using pandas, some teams that are primarily using polars, and he just wanted to build some common logic that both teams could use.

01:00:23.620 --> 01:00:25.600
And he was using Narwhals for that.

01:00:26.020 --> 01:00:29.900
So, I think there are some use cases beyond just library maintainers.

01:00:29.900 --> 01:00:30.800
Yeah, absolutely.

01:00:30.800 --> 01:00:41.460
Maybe you're building just an internal library, and it needs to work with some code you've written in pandas, but maybe you want to try your new project in polars, but you want to still use that library, right?

01:00:41.460 --> 01:00:45.260
That would be a cool use case as well, just to not lock yourself in.

01:00:45.820 --> 01:00:52.620
Yeah, I'm pretty sure you've brought up on the show before that XKCD about, like, the spacebar overheating.

01:00:52.620 --> 01:01:00.800
I don't remember which number that one is, but in the end, with a lot of open source projects, you put it out with some intention of how it's meant to be used.

01:01:00.800 --> 01:01:01.180
Yes.

01:01:01.180 --> 01:01:03.120
But then people find their own way of using it.

01:01:03.120 --> 01:01:06.480
I believe it was spacebar heating.

01:01:06.480 --> 01:01:08.200
The workflow.

01:01:08.200 --> 01:01:08.860
Workflow, this is it.

01:01:08.860 --> 01:01:09.260
Yes.

01:01:09.260 --> 01:01:09.980
Love this one.

01:01:09.980 --> 01:01:18.160
Yeah, it looks like something out of a changelog with feedback or something that says, changes in version 10.7.

01:01:18.160 --> 01:01:20.980
The CPU no longer overheats when you hold down the spacebar.

01:01:20.980 --> 01:01:21.380
Comment.

01:01:21.380 --> 01:01:25.900
Longtime user 4 writes, this update broke my workflow.

01:01:25.900 --> 01:01:32.820
My control key is hard to reach, so I hold the spacebar instead, and I configured Emacs to interpret a rapid temperature rise as control.

01:01:32.820 --> 01:01:33.540
That's horrifying.

01:01:33.540 --> 01:01:35.460
Look, my setup works for me.

01:01:35.460 --> 01:01:38.180
Just add an option to re-enable spacebar heating.

01:01:38.180 --> 01:01:42.860
I've seen it so many times, but it still makes me laugh each time.

01:01:42.860 --> 01:01:44.060
That's incredible.

01:01:44.060 --> 01:01:45.040
That's incredible.

01:01:45.040 --> 01:01:46.780
All right, Marco.

01:01:46.780 --> 01:01:48.720
Well, congrats on the cool library.

01:01:48.720 --> 01:01:49.660
Congrats on the traction.

01:01:49.660 --> 01:01:51.280
Final call to action.

01:01:51.280 --> 01:01:52.840
Maybe people want to start using narwhals.

01:01:52.840 --> 01:01:53.380
What do you tell them?

01:01:53.380 --> 01:01:59.360
Yeah, give it a go, and please join our Discord and all our community calls.

01:01:59.620 --> 01:02:09.540
We're very friendly and open, and we'd love to hear from you and see what we can do to address whatever limitations you might come up against.

01:02:09.540 --> 01:02:10.580
Awesome.

01:02:10.580 --> 01:02:12.040
Well, thanks for being here.

01:02:12.040 --> 01:02:12.540
See you later.

01:02:12.540 --> 01:02:13.720
Thank you, Michael.

01:02:13.720 --> 01:02:15.020
Thank you.

