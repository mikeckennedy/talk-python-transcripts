WEBVTT

00:00:01.480 --> 00:00:03.260
Reuven, welcome back to Talk Python to Me.

00:00:03.540 --> 00:00:04.140
Awesome to have you here.

00:00:05.040 --> 00:00:05.520
Thank you so much.

00:00:05.840 --> 00:00:06.660
Delightful to be here with you.

00:00:08.280 --> 00:00:10.940
Yes, we're coming up on conference season,

00:00:11.820 --> 00:00:13.480
and I saw you doing conference things.

00:00:14.260 --> 00:00:16.800
So I thought I'd reach out and see if you wanted to do

00:00:17.720 --> 00:00:19.700
a bit of a conversation about what you're going to be

00:00:20.060 --> 00:00:20.700
covering at PyCon.

00:00:22.140 --> 00:00:22.500
Absolutely.

00:00:22.820 --> 00:00:23.660
Yeah, I'm really excited.

00:00:23.700 --> 00:00:25.420
I mean, I love conferences.

00:00:25.820 --> 00:00:26.740
I love seeing people.

00:00:27.280 --> 00:00:29.980
I definitely got to the point where they're like conference friends

00:00:30.000 --> 00:00:31.100
see every year and we can sort of

00:00:31.100 --> 00:00:31.560
catch up

00:00:31.560 --> 00:00:34.320
and hang out. It's just like a fun, fun experience.

00:00:34.460 --> 00:00:38.360
I always tell anyone who can, like go to conferences. It's a great place to learn,

00:00:38.360 --> 00:00:39.760
but it's also just a great place to have fun.

00:00:41.060 --> 00:00:44.080
I agree with that. I also think it's a great way to

00:00:45.379 --> 00:00:51.480
connect more deeply with programming and technology and libraries and all that kind of stuff.

00:00:52.460 --> 00:00:59.040
It's real easy for, I think for a lot of folks for this to feel like a set of tutorials and

00:00:59.060 --> 00:01:03.920
documentation, right? And then you get there and you're like, oh, all these people are doing it.

00:01:04.000 --> 00:01:09.080
They're excited. And there's the person that made that one. And, you know, like to swim in those

00:01:09.280 --> 00:01:10.200
waters, it's different.

00:01:11.400 --> 00:01:15.200
I also feel like it's kind of sad, but I mean, I go to all these companies

00:01:15.720 --> 00:01:20.820
and I get a feeling that for many people who are in programming nowadays, it's kind of lost its fun

00:01:21.060 --> 00:01:25.540
and its creativity. And so it's very nice to be in a community where because open source,

00:01:26.080 --> 00:01:29.280
Everyone's there because they want to be there and because they are excited about it.

00:01:29.500 --> 00:01:38.020
And you can sort of like recharge your excitement batteries, as it were, and realize, oh, there's more to this than just the drudgery of day-to-day and meetings and

00:01:38.020 --> 00:01:39.220
filling

00:01:39.220 --> 00:01:40.140
my corporate goals.

00:01:41.120 --> 00:01:41.280
Yeah.

00:01:41.400 --> 00:01:41.520
It's nice.

00:01:41.720 --> 00:01:41.980
It's fun.

00:01:42.760 --> 00:01:43.020
It is.

00:01:43.160 --> 00:01:48.300
And speaking of just swimming in the waters and what is water, right?

00:01:49.240 --> 00:01:55.060
That famous quote, you talked about how it's so much fun because of open source and things like that.

00:01:55.759 --> 00:01:57.280
I hadn't thought about that for a little while.

00:01:58.940 --> 00:02:02.040
When I work on stuff, I can just do whatever I want.

00:02:02.070 --> 00:02:04.040
If I want to share it, I can share it.

00:02:04.040 --> 00:02:05.040
I don't have to share it.

00:02:06.220 --> 00:02:10.600
Use whatever libraries that might be coming along that look promising.

00:02:11.700 --> 00:02:12.220
There's not a

00:02:12.220 --> 00:02:13.620
corporate mandate like,

00:02:14.100 --> 00:02:18.440
we're going to have these features for our library in seven months

00:02:19.000 --> 00:02:22.259
because the customer demand asks for this

00:02:22.280 --> 00:02:25.720
and we're going to put this thing in to promote our cloud

00:02:26.360 --> 00:02:28.100
or our other thing or whatever, right?

00:02:28.300 --> 00:02:29.800
There's a lot of people out there writing code

00:02:29.850 --> 00:02:30.820
with a lot less flexibility.

00:02:32.040 --> 00:02:32.560
Oh my God,

00:02:33.010 --> 00:02:33.140
yes.

00:02:33.450 --> 00:02:33.800
And I seem

00:02:33.800 --> 00:02:35.740
to see more such people each year.

00:02:36.819 --> 00:02:38.580
And I also feel like, I always say,

00:02:38.680 --> 00:02:40.860
like I have this sort of dual flexibility

00:02:41.560 --> 00:02:42.860
that I feel very privileged to have

00:02:42.890 --> 00:02:45.600
that A, I'm a freelancer, I'm independent

00:02:45.860 --> 00:02:46.860
and B, I work in open source.

00:02:47.560 --> 00:02:49.480
So I can say such and such is dumb

00:02:49.530 --> 00:02:50.720
or such and such is bad.

00:02:51.740 --> 00:02:57.120
And people at a normal job, as it were, have to sort of say, well, this is our

00:02:57.120 --> 00:02:57.640
product and

00:02:57.640 --> 00:02:57.980
it's great.

00:02:58.200 --> 00:02:58.640
Or at least they have to

00:02:58.640 --> 00:02:59.180
say it's the outside

00:02:59.180 --> 00:02:59.480
world.

00:02:59.970 --> 00:03:03.680
Whereas day to day, they're just going to meetings saying, how can we convince people that this is great?

00:03:05.020 --> 00:03:05.380
So,

00:03:06.330 --> 00:03:13.380
yeah, yeah, it's a nice way to escape that corporate golden handcuffs.

00:03:13.410 --> 00:03:14.500
Oh, I'm making it sound really terrible.

00:03:15.060 --> 00:03:18.040
For all of you listening, I'm happy you have good jobs.

00:03:18.130 --> 00:03:18.660
I really am.

00:03:21.620 --> 00:03:25.680
Unfortunately, I'm afraid people might start having to appreciate their jobs a little bit more.

00:03:26.180 --> 00:03:27.840
Things are looking a little hectic out there.

00:03:28.340 --> 00:03:32.640
I don't want to go into that, but one little side diversion before we dive into the main topic.

00:03:34.580 --> 00:03:35.900
You go into all these big companies.

00:03:37.280 --> 00:03:41.640
What's the LLM AI story for those

00:03:41.640 --> 00:03:42.040
folks?

00:03:42.160 --> 00:03:43.140
Is it different than

00:03:43.140 --> 00:03:48.900
people on the outside who can just YOLO around the tools however they want?

00:03:48.900 --> 00:03:49.900
Or what's it like?

00:03:50.580 --> 00:03:55.060
so every company is different every company is asking that question right and no one has an

00:03:55.190 --> 00:04:01.500
answer i think a growing number of companies are assuming that their people will use llms of some

00:04:01.680 --> 00:04:06.740
sort uh copilot's been around for a while people are using that uh a year ago i have one big client

00:04:07.020 --> 00:04:11.780
where they said no of course we would never use chat gpt and just a few weeks ago i said so like

00:04:11.880 --> 00:04:15.859
what's the story oh yeah we're definitely using some things we'll get back to you on a lot so

00:04:15.880 --> 00:04:15.980
So it's

00:04:15.980 --> 00:04:16.519
been increasingly

00:04:16.519 --> 00:04:23.140
integrated just because, especially, you know, if you're a senior developer, these LLMs really help you just zoom along.

00:04:23.630 --> 00:04:30.100
The junior ones, it's sort of like a little ifpier, but everyone at least has to answer the question, what are you doing with these?

00:04:30.680 --> 00:04:32.680
And I think it's increasingly integrated into their workflow.

00:04:33.220 --> 00:04:35.960
I don't think anyone knows, like, what is the right way to do it.

00:04:36.520 --> 00:04:42.940
I do think that these companies that are talking about, well, we're not going to hire any developers this coming year because instead we're just going to use LLMs.

00:04:43.360 --> 00:04:44.280
That's just nuts.

00:04:44.740 --> 00:04:46.580
I think they're asking for trouble there.

00:04:47.540 --> 00:04:48.480
And in general, I tell people,

00:04:48.720 --> 00:04:50.240
don't have the LLMs write code for you.

00:04:50.760 --> 00:04:52.160
Have it help you strategize.

00:04:52.500 --> 00:04:53.480
Have it go over your code.

00:04:53.720 --> 00:04:54.600
Have it help you learn things.

00:04:55.500 --> 00:04:56.580
But somewhere, somehow,

00:04:57.340 --> 00:04:58.660
they're going to have LLM-generated code

00:04:58.940 --> 00:04:59.820
that no one's going to look at.

00:04:59.940 --> 00:05:02.060
And I don't like that idea so much,

00:05:02.680 --> 00:05:03.100
at least for now.

00:05:04.700 --> 00:05:05.040
Interesting.

00:05:06.500 --> 00:05:10.500
I would not trust 100% LLM written code.

00:05:11.600 --> 00:05:12.599
Not even necessarily

00:05:12.620 --> 00:05:14.860
because I think LLMs are bad at writing code.

00:05:15.040 --> 00:05:18.580
I'm stunned at how good they are at it.

00:05:20.120 --> 00:05:22.460
But they write the code that you ask them to write.

00:05:23.080 --> 00:05:24.300
Even if they get it 100% right,

00:05:24.340 --> 00:05:25.620
they write what you ask them to write.

00:05:25.780 --> 00:05:29.020
And it's like, I'm just seeing the office space guy,

00:05:29.120 --> 00:05:29.860
like, I'm good with

00:05:29.860 --> 00:05:30.360
customers.

00:05:30.720 --> 00:05:31.680
I talk to the customers.

00:05:33.960 --> 00:05:36.340
What would you say you do here, Bob?

00:05:36.820 --> 00:05:37.400
Like that guy?

00:05:39.300 --> 00:05:41.700
I mean, you've got to give the specifications to the AI.

00:05:42.360 --> 00:05:43.120
really, really well.

00:05:43.920 --> 00:05:48.040
There you go. There you go. So when ChatGPT first came out, right, it was this

00:05:48.200 --> 00:05:53.860
whole meme of the programming language everyone needs to learn now is English. Because all you

00:05:53.860 --> 00:05:58.800
have to do is tell the LLM what you want to do, and it will come out with code. Voila, problem

00:05:59.200 --> 00:06:03.480
solved. And anyone who has worked on a project before, and especially anyone who's worked with

00:06:03.740 --> 00:06:09.460
clients before, non-technical clients, knows that the gap between specifying what you want in clear,

00:06:09.540 --> 00:06:15.360
precise language and getting code that does it can be vast. And the difference between success and

00:06:15.540 --> 00:06:20.360
failure. I often tell my students one of my favorite lines that I heard years ago, which is,

00:06:20.800 --> 00:06:23.760
computers don't do what you want them to do. They do what you tell them to do.

00:06:25.380 --> 00:06:28.340
And like, we've all been bitten by that so many times.

00:06:30.240 --> 00:06:36.659
Yeah, we definitely have. We definitely have. All right. Well, I think this is a story that's

00:06:36.680 --> 00:06:39.600
going to continue to get just more insane.

00:06:41.420 --> 00:06:44.600
It's going to be interesting to see where things go. I think it's both going to

00:06:45.860 --> 00:06:47.280
supercharge open source, but also

00:06:48.980 --> 00:06:52.420
super royal cost turbulence for

00:06:53.320 --> 00:06:54.420
programmers, right? So we're going to see.

00:06:55.780 --> 00:06:56.720
No, no question.

00:06:57.040 --> 00:06:57.840
I 100% agree.

00:06:59.140 --> 00:07:00.320
Yeah. So

00:07:00.760 --> 00:07:04.579
you know, with all this, we haven't given you a chance to introduce

00:07:04.600 --> 00:07:05.140
yourself to

00:07:05.140 --> 00:07:06.360
everyone because everyone

00:07:06.360 --> 00:07:09.460
knows reuben but maybe for the couple people down real quick

00:07:09.700 --> 00:07:11.360
introduction fantastic

00:07:11.360 --> 00:07:15.700
so yeah so i'm reuben learner and i teach python and pandas and git

00:07:15.940 --> 00:07:22.160
for a living i've been doing for a long time since like 1995 or so um and so half of my work is going

00:07:22.160 --> 00:07:27.620
to companies and doing training there and the other half is uh doing online learning i've got my own

00:07:27.740 --> 00:07:32.699
platform we have folks i've got newsletters youtube channel um online boot camp that i do

00:07:33.140 --> 00:07:37.180
and my goal is just like to help people wherever they are with their Python Pandas knowledge to

00:07:37.640 --> 00:07:39.020
advance, get better, get more fluent.

00:07:40.020 --> 00:07:43.720
Awesome. Well, that's pretty much the story of this

00:07:44.380 --> 00:07:49.860
episode as well. But I also, I mean, that's a great introduction.

00:07:51.740 --> 00:07:57.420
But I didn't know you were such an athlete. I mean, you didn't even talk about all these

00:07:57.580 --> 00:08:01.360
workout books that you're writing and you're a workout influencer.

00:08:03.000 --> 00:08:07.400
Yeah, well, I wish it were more physical than virtual.

00:08:08.220 --> 00:08:08.780
But yeah, yeah.

00:08:08.860 --> 00:08:12.400
So I've got my two books published with Manning, Python Workout and

00:08:12.400 --> 00:08:13.160
Panda's Workout.

00:08:14.840 --> 00:08:19.380
And actually, Python Workout is now in its second edition in early release form.

00:08:20.759 --> 00:08:27.940
So it's a relatively minor update to take advantage of all the new stuff that's come out of Python in the last, what, three, four, five years.

00:08:28.180 --> 00:08:30.440
So it's not like a huge overhaul, but like something there.

00:08:30.760 --> 00:08:34.419
Some of the exercises that everyone kind of said, really, you want to do that?

00:08:34.880 --> 00:08:36.919
And so like, yeah, there are always some stinkers in there.

00:08:37.210 --> 00:08:39.120
But overall, it's great fun.

00:08:39.530 --> 00:08:44.980
And the idea is, you know, Manning and I came with the title, but the idea is you're only

00:08:44.990 --> 00:08:48.400
going to get better if you do lots of little practice every day.

00:08:48.690 --> 00:08:53.660
I often say that it's similar to learning a language, but actually, like I have started

00:08:53.880 --> 00:08:54.860
running in the last few months.

00:08:55.460 --> 00:08:56.440
And like, what do you know?

00:08:56.780 --> 00:09:00.940
you do a little more each day, a little more each day. And then like, you know, every so often you'll

00:09:00.940 --> 00:09:05.420
get injured, but like, then you go back to it. And so over time you build up the strength and the

00:09:05.500 --> 00:09:10.840
stamina and the fluency so that you can really like get into a project and do what you need and not

00:09:11.140 --> 00:09:12.420
be looking everything up all the time.

00:09:13.680 --> 00:09:17.080
You know, one of the things I noticed when I, you know,

00:09:17.380 --> 00:09:23.180
as you, I've done a lot of in-person corporate training type stuff, not for a while, but,

00:09:23.660 --> 00:09:30.220
you know, over my career. I think it's really interesting. You go interact with all these folks,

00:09:31.100 --> 00:09:35.380
some of whom are brand new on a team or a project, but others have been, you know, like I've been in

00:09:35.380 --> 00:09:40.840
the company for 20 years and that's usually really awesome. However, there's certainly plenty of

00:09:40.960 --> 00:09:47.199
times that I saw people who had 20 years of experience, but it didn't feel like they had

00:09:47.220 --> 00:09:53.720
20 years of experience knowledge in the sense that they kind of did the same thing you did in the

00:09:54.370 --> 00:10:01.600
first couple years and just kept doing that for 18 more rather than having a wide-ranging set of

00:10:01.780 --> 00:10:08.380
experiences. And it's like a lot of things, like exercise, like sports, like other skills, without

00:10:11.500 --> 00:10:13.000
focused practice on something,

00:10:13.650 --> 00:10:15.840
you can get sort of into a rut

00:10:15.850 --> 00:10:17.500
or get really good at like a few things,

00:10:17.660 --> 00:10:18.200
but you're like,

00:10:18.340 --> 00:10:19.780
well, I've never really created a website.

00:10:20.040 --> 00:10:21.820
I always just work on this database layer.

00:10:21.980 --> 00:10:24.000
It's like 20 years?

00:10:24.230 --> 00:10:26.040
Okay, spread out of it.

00:10:26.220 --> 00:10:26.540
Come on.

00:10:27.060 --> 00:10:28.760
And I feel like this is the kind of stuff

00:10:28.860 --> 00:10:29.620
you're talking about maybe.

00:10:30.780 --> 00:10:31.660
That's exactly it.

00:10:31.800 --> 00:10:34.420
That you want to get this wide variety of practice.

00:10:34.600 --> 00:10:34.960
So the books,

00:10:34.990 --> 00:10:35.960
I don't think I said this explicitly,

00:10:36.400 --> 00:10:37.700
but the books are all exercises.

00:10:38.000 --> 00:10:41.840
Like there's some comments in there and some sort of, shall we call them like mini or micro

00:10:42.100 --> 00:10:43.360
tutorials to get you up to speed.

00:10:43.540 --> 00:10:45.720
But the idea is you've already learned Python.

00:10:45.920 --> 00:10:47.040
You've already learned Pandas.

00:10:47.480 --> 00:10:52.300
And now you just need to practice and better that you practice with, in what I call controlled

00:10:52.520 --> 00:10:56.460
frustration in this sort of like, you know, environment where it's not going to matter

00:10:56.580 --> 00:11:00.160
to your job, then you get to work and your boss is breathing down your neck and you've

00:11:00.160 --> 00:11:00.540
got deadlines.

00:11:01.380 --> 00:11:06.579
And I try to make it as varied as possible so that you'll sort of be exposed to as many

00:11:06.600 --> 00:11:11.780
different ideas as possible. So even if you don't remember it 100%, you'd be like, oh, wait, here,

00:11:11.820 --> 00:11:15.340
I probably could have used a dictionary comprehension. I don't quite remember exactly what

00:11:15.440 --> 00:11:19.980
syntax is, but that's probably the right direction. And that's way better than, what do I do now?

00:11:20.480 --> 00:11:21.360
We're just doing it the wrong way.

00:11:22.160 --> 00:11:26.080
Yeah, absolutely. And circling back a bit to our LLM conversation,

00:11:27.240 --> 00:11:30.720
getting exposure to all these things, you know, like, well, the LLM wrote this and it looked weird

00:11:30.820 --> 00:11:34.139
and I didn't understand it. But now I see what it was doing. It was using this thing that I hadn't

00:11:34.160 --> 00:11:36.600
really played with, this aspect of the language I hadn't played with?

00:11:37.460 --> 00:11:42.680
Yeah, one of the things I like to do with LLMs is I call it the reverse Socratic method,

00:11:43.580 --> 00:11:49.240
where I ask it lots of questions about either my code or like, oh, you're saying I should

00:11:49.240 --> 00:11:50.520
do it this way, but why?

00:11:50.570 --> 00:11:51.440
And what if I do it this way?

00:11:51.840 --> 00:11:54.720
So instead of like the teacher asks the student lots of questions, the students ask the teacher

00:11:54.770 --> 00:11:56.820
lots of questions, that's when we think of the LLM as a teacher.

00:11:57.400 --> 00:12:02.159
And I found that I learned a lot of things that way, probing, both learn the nuances

00:12:02.160 --> 00:12:05.720
and I see where its limitations are and or where it's just bluffing.

00:12:07.420 --> 00:12:11.780
And so I find that to be sort of a useful technique to play with.

00:12:12.759 --> 00:12:13.560
Very interesting.

00:12:14.380 --> 00:12:19.400
Well, I would propose that Panda's certainly proven itself to be a tad useful.

00:12:20.680 --> 00:12:23.240
You know, here and there, there are like a handful of people using it nowadays.

00:12:23.800 --> 00:12:24.220
It's astonishing.

00:12:24.960 --> 00:12:25.340
I know.

00:12:25.420 --> 00:12:26.680
Does it even need an introduction?

00:12:26.900 --> 00:12:28.240
I'm not sure that it needs an introduction.

00:12:29.060 --> 00:12:30.240
I mean, if

00:12:30.240 --> 00:12:30.960
you're listening to this podcast.

00:12:31.000 --> 00:12:31.360
15 seconds.

00:12:31.680 --> 00:12:32.260
You have your list.

00:12:32.660 --> 00:12:35.160
No, well, here's â€“ I'll tell listeners out there,

00:12:35.280 --> 00:12:38.000
there's a very interesting group of people who do listen to this podcast.

00:12:39.740 --> 00:12:41.360
I'd be interested to hear your thoughts on this.

00:12:41.920 --> 00:12:44.740
I've had people write to me and they'll say,

00:12:44.800 --> 00:12:45.660
I really love your show.

00:12:45.900 --> 00:12:46.840
Thanks so much for doing it.

00:12:47.400 --> 00:12:52.580
However, I'm starting to understand a lot of the words that you guys are using

00:12:52.680 --> 00:12:53.640
or what you're talking about.

00:12:54.780 --> 00:12:57.140
I've been listening for two months or something.

00:12:58.220 --> 00:13:03.640
That's the serious persistence to listen for two months and not really like start out not even knowing what's going on.

00:13:03.980 --> 00:13:07.540
But a lot of people use this show like language immersion.

00:13:08.090 --> 00:13:08.220
You know,

00:13:08.750 --> 00:13:09.560
you want

00:13:09.560 --> 00:13:12.540
to learn Portuguese, you move to Brazil and then you start learning it, right?

00:13:12.700 --> 00:13:13.540
Not the other way around.

00:13:14.620 --> 00:13:21.280
And so I'm always cognizant of those folks who are using this to kind of as their first step into the industry.

00:13:22.900 --> 00:13:23.000
What do you

00:13:23.000 --> 00:13:23.540
tell those folks

00:13:23.540 --> 00:13:24.080
Pandas are?

00:13:25.620 --> 00:13:32.980
So Pandas is a library, like a module or package in Python that lets you do data analysis.

00:13:33.480 --> 00:13:38.040
And the way I describe it to people who are not programmers is it's basically Excel inside

00:13:38.150 --> 00:13:38.580
of Python.

00:13:39.260 --> 00:13:41.500
So you can read in data from a lot of different sources.

00:13:41.970 --> 00:13:44.660
You can analyze it in two-dimensional tables, right?

00:13:44.690 --> 00:13:48.960
So you've got rows, you've got columns, and then you can perform a ton of different calculations.

00:13:49.620 --> 00:13:53.860
You can use dates, you can use text, but you also have all the flexibility of Python as

00:13:53.870 --> 00:13:55.000
a programming language.

00:13:55.580 --> 00:13:57.100
so you can extract different parts of it.

00:13:57.270 --> 00:13:58.800
You can mix and match different parts of it.

00:13:59.240 --> 00:14:01.260
And Pandas is especially really good

00:14:01.610 --> 00:14:03.400
at importing from a ton of different sources

00:14:03.880 --> 00:14:05.500
and exporting back to those sources

00:14:05.800 --> 00:14:07.100
or those destinations, I guess.

00:14:08.300 --> 00:14:09.560
And it's become this,

00:14:10.460 --> 00:14:11.700
well, to extend the language thing,

00:14:11.740 --> 00:14:12.580
like this lingua franca,

00:14:12.700 --> 00:14:14.680
like a lot of people use Pandas

00:14:15.080 --> 00:14:18.080
for even a tiny subset of what it can do

00:14:18.560 --> 00:14:20.400
just because it's so ridiculously flexible

00:14:20.720 --> 00:14:21.400
and because it's everywhere.

00:14:22.779 --> 00:14:24.300
Yeah, good description.

00:14:25.700 --> 00:14:30.340
and this loading data from multiple data sources, it's nuts.

00:14:30.820 --> 00:14:32.600
It's crazy how good it is.

00:14:32.960 --> 00:14:36.880
So let me just throw an example out there for people who maybe haven't done a lot

00:14:37.000 --> 00:14:38.100
with importing data with pandas.

00:14:40.000 --> 00:14:48.900
You could do things like there is a HTML table on a state government website

00:14:49.180 --> 00:14:51.060
that talks about some bit of data that you need,

00:14:51.070 --> 00:14:53.920
and it's just embedded in some web page.

00:14:54.120 --> 00:15:00.960
It's the third table, HTML table, bracket table slash table sort of thing on there.

00:15:01.070 --> 00:15:09.580
And you can say, load table, give it that URL and say, or load that HTML, give me the tables, go to the third one.

00:15:09.740 --> 00:15:10.700
And it's a Pandas data frame.

00:15:11.030 --> 00:15:13.860
Like that level of just grab it, right?

00:15:15.240 --> 00:15:22.180
So I have my, like one of the newsletters I produce is Bamboo Weekly where I have like challenges each week to use Pandas.

00:15:22.400 --> 00:15:28.400
And I'm always trying to retrieve stuff from different sources because A, people have lots

00:15:28.400 --> 00:15:28.820
of different needs.

00:15:28.940 --> 00:15:29.960
B, there's lots of data out there.

00:15:30.260 --> 00:15:33.260
And C, then you have to clean it up and you need different techniques for cleaning it.

00:15:33.700 --> 00:15:38.060
And so like, right, you can retrieve it from a PDF file if there are tables there.

00:15:38.120 --> 00:15:39.540
You can retrieve, as you said, from HTML.

00:15:39.600 --> 00:15:43.720
You can retrieve it from Excel, from JSON, from other statistics programs.

00:15:43.940 --> 00:15:45.140
They're binary formats.

00:15:45.660 --> 00:15:47.120
It basically is infinite.

00:15:47.280 --> 00:15:53.160
And then you've got CSV, which is like every possible almost kind of standard under the sun.

00:15:53.820 --> 00:15:55.080
And Pandas is like, oh, that's okay.

00:15:55.520 --> 00:15:58.080
We'll just give you 100,000 different options and then you can read any of them.

00:16:01.680 --> 00:16:02.220
Yeah, that's amazing.

00:16:04.280 --> 00:16:05.480
I'm just blown away with it.

00:16:05.740 --> 00:16:07.700
So super, super interesting.

00:16:08.600 --> 00:16:15.200
One of the things that I think kind of goes hand in hand with Pandas is, of course, NumPy.

00:16:16.120 --> 00:16:20.280
And that's a little bit at the heart of what we're getting at, right?

00:16:20.370 --> 00:16:25.560
Like traditionally Pandas has sort of internally used NumPy to manage its data structures and so on.

00:16:26.220 --> 00:16:29.160
And there's some new libraries and formats coming along.

00:16:29.330 --> 00:16:35.540
And you might be able to mix and match or even have to mix and match eventually.

00:16:36.700 --> 00:16:37.400
Right, right.

00:16:37.700 --> 00:16:49.400
So it all started, like, so when people hear that Python is the number one language for data science and machine learning and data analytics, if they know anything about Python, they're a little confused.

00:16:49.400 --> 00:16:50.280
Like, wait a second.

00:16:51.060 --> 00:16:55.440
Python's a great language, but its data structures are big and slow.

00:16:56.580 --> 00:16:58.180
Why would I possibly want to use this?

00:16:58.300 --> 00:16:59.360
Yeah, especially numbers.

00:17:00.260 --> 00:17:08.720
I think if you look at like what is most out of sync or out of space with like C or other native languages, right?

00:17:09.020 --> 00:17:12.780
Like how big is a Python float versus a regular one and like

00:17:12.780 --> 00:17:14.280
locality

00:17:14.280 --> 00:17:15.300
of data, all that kind of stuff.

00:17:15.920 --> 00:17:22.260
I think the last time I checked, it was like 24 bytes for a zero integer in Python.

00:17:23.280 --> 00:17:26.839
Yes, and they're pointer dereferences and they're on the heap so they might be in different places.

00:17:27.020 --> 00:17:28.160
Like there's a lot going on here.

00:17:29.180 --> 00:17:34.020
So many years ago, I don't know, 20 years ago or something, we got NumPy.

00:17:34.160 --> 00:17:36.420
And NumPy is basically like the best of both worlds.

00:17:36.660 --> 00:17:39.020
It's C, storage, and speed.

00:17:39.640 --> 00:17:44.680
And so all that efficiency, but with a really thin layer of Python so you can work with it.

00:17:44.680 --> 00:17:48.560
And you sort of get the ease of Python and, as I said, the efficiency of C.

00:17:49.120 --> 00:17:50.820
And so NumPy is fantastic at doing that.

00:17:50.900 --> 00:17:55.320
It's very, very widely used in science, engineering, math, statistics, all that stuff.

00:17:56.060 --> 00:17:59.760
And you could do a ton of stuff with NumPy.

00:18:00.020 --> 00:18:00.740
I'd be very happy.

00:18:01.420 --> 00:18:05.020
But most data analysis that we're going to do is going to be in two-dimensional tables.

00:18:05.780 --> 00:18:07.440
And it's going to use a lot of strings.

00:18:08.200 --> 00:18:10.920
And with the import and export that we were talking about.

00:18:11.340 --> 00:18:16.600
And so I always describe Pandas as like an automatic transmission for NumPy's manual transmission.

00:18:17.240 --> 00:18:25.740
That you get a lot of sort of convenience functionality that just makes it smoother, cleaner, easier to do your day-to-day stuff.

00:18:27.200 --> 00:18:32.460
and so pandas has been reliant on numpy for well since it started like no doubt about it

00:18:32.900 --> 00:18:35.840
and if you sort of chip away or like scrape away the outer

00:18:35.840 --> 00:18:36.300
layer there

00:18:36.300 --> 00:18:37.720
you very quickly see numpy

00:18:37.880 --> 00:18:43.380
stuff for example the d types that the data types that we use in each pandas column those are defined

00:18:44.300 --> 00:18:50.700
almost exclusively by numpy types and so i actually when i teach pandas i first teach numpy

00:18:51.320 --> 00:18:55.800
because i feel it's like an easier sort of lower level way to get used to it and then they see

00:18:55.820 --> 00:18:57.960
techniques apply to pandas as well.

00:18:58.660 --> 00:19:02.820
Yeah. The data types are interesting because NumPy is written in

00:19:03.000 --> 00:19:09.720
C. C operates on structured, well-defined, you know, this thing is four bytes, that's eight bytes,

00:19:09.840 --> 00:19:16.760
and so on. Data types. And so those have really interesting limitations. I have a joke for you

00:19:16.800 --> 00:19:22.440
that I ran across recently, and I think it highlights this. So I wish I had a picture I

00:19:22.460 --> 00:19:29.120
could share it, but I don't. So there was this programmer that finds one of these genie in a

00:19:29.270 --> 00:19:36.920
bottle sort of genie things, rubs it. The genie pops out and says, hello, lucky one. You have

00:19:37.050 --> 00:19:41.400
three wishes, but before you can wish, there are some rules. You can't wish to kill someone or make

00:19:41.480 --> 00:19:46.140
someone fall in love with you. Most importantly, you can't wish for more wishes. Programmer says,

00:19:46.170 --> 00:19:51.380
well, can I wish for fewer wishes? Why would you wish for fewer wishes? I just, I don't understand.

00:19:52.220 --> 00:19:53.800
Because I want negative one wishes.

00:19:54.140 --> 00:19:59.320
Fine, you have 2,496,000,000.

00:20:02.300 --> 00:20:03.140
Oh, that's pretty good.

00:20:03.190 --> 00:20:04.080
So what happened?

00:20:04.320 --> 00:20:05.280
Why did that go wrong?

00:20:06.420 --> 00:20:07.560
I mean, that's the D-types, right?

00:20:08.300 --> 00:20:09.200
That's exactly right.

00:20:09.660 --> 00:20:10.420
That's exactly right.

00:20:10.780 --> 00:20:13.000
So I never thought of it that way.

00:20:13.140 --> 00:20:14.760
I always think, maybe because I'm old enough,

00:20:14.970 --> 00:20:16.580
I think you and I are about the same age,

00:20:16.740 --> 00:20:19.540
that when you play video games when you were little,

00:20:19.740 --> 00:20:20.860
if you're really, really good,

00:20:21.180 --> 00:20:22.240
you would get like the maximum score,

00:20:22.260 --> 00:20:23.920
it would sort of wrap around back to zero.

00:20:24.540 --> 00:20:25.160
Or if you had a

00:20:25.160 --> 00:20:26.040
really old car

00:20:26.500 --> 00:20:28.240
and if you drove it like a long time,

00:20:28.500 --> 00:20:29.880
eventually the odometer would go past zero.

00:20:30.220 --> 00:20:30.280
Like

00:20:30.280 --> 00:20:31.340
there's a limited number

00:20:31.340 --> 00:20:32.120
of digits.

00:20:32.780 --> 00:20:35.760
And when after 9999, it has to go back to 000.

00:20:36.580 --> 00:20:39.460
And that's basically what's happening bitwise in NumPy.

00:20:39.580 --> 00:20:41.960
It has a certain set, unlike Python data types,

00:20:41.980 --> 00:20:44.580
like Python integers will get as big

00:20:44.860 --> 00:20:46.020
or as small as you have memory.

00:20:46.460 --> 00:20:47.120
There is no limit.

00:20:47.919 --> 00:20:49.820
But when you're working with NumPy

00:20:49.840 --> 00:20:56.140
or with pandas with these d types you have to say is it 8 bits or 16 or 32 or 64 and that's it once

00:20:56.340 --> 00:21:01.880
like once you reach that ceiling then it wraps around and it will not warn you about this either

00:21:02.060 --> 00:21:07.920
so you need to keep enough of a buffer there between what you think will be your maximum number

00:21:08.300 --> 00:21:13.180
and what could possibly ever be your maximum number like if you want to do i don't know 8 bits

00:21:13.980 --> 00:21:16.860
for ages, that's probably fine, right?

00:21:17.480 --> 00:21:19.640
But if you want to do 8 bits for, I don't know,

00:21:19.710 --> 00:21:21.840
how long is the project going, in a number of days,

00:21:22.450 --> 00:21:25.440
uh-oh, better hope that your project is going to be done soon

00:21:25.720 --> 00:21:28.800
because you could be in trouble and you could be into negative territory.

00:21:29.200 --> 00:21:31.660
Yeah, they should have made it a little bit bigger choice

00:21:31.880 --> 00:21:34.340
for the epoch since 1970, you know?

00:21:35.220 --> 00:21:35.540
That's right.

00:21:35.900 --> 00:21:38.260
We're going to find out in 2038 about that one.

00:21:39.260 --> 00:21:40.040
I think that's the year.

00:21:40.380 --> 00:21:41.080
Anyway, it's going to be bad.

00:21:41.500 --> 00:21:47.020
Yeah, so the genie was basically storing the wishes count in an unsigned 32-bit integer.

00:21:48.720 --> 00:21:49.460
I love that joke.

00:21:50.460 --> 00:21:52.900
And I have no one to tell it to, so I'm very glad you told it to me.

00:21:54.960 --> 00:21:55.240
Exactly.

00:21:55.380 --> 00:21:55.860
What?

00:21:56.120 --> 00:21:56.800
That's a stupid...

00:21:57.040 --> 00:21:57.600
I don't even understand.

00:21:57.940 --> 00:21:58.940
What a stupid genie.

00:21:58.980 --> 00:22:00.680
Of course, they have no more wishes.

00:22:01.560 --> 00:22:02.460
They got some more wishes.

00:22:03.920 --> 00:22:07.020
Another thing, you talked about this buffer sort of deal.

00:22:07.960 --> 00:22:14.620
If you think maybe you need 16 bits or whatever or 32,

00:22:15.220 --> 00:22:17.560
maybe you want to be safe so you're going to double that.

00:22:18.140 --> 00:22:21.140
That also adds to a bunch of memory usage.

00:22:23.560 --> 00:22:27.180
When you allocate 64-bit integers instead of 32,

00:22:28.450 --> 00:22:31.900
even if you don't use that space, you consume that much memory.

00:22:32.800 --> 00:22:33.900
That's right. That's the thing.

00:22:34.320 --> 00:22:41.180
So again, if you're an even experienced Python programmer, you're like, well, I'll just like

00:22:41.320 --> 00:22:42.520
whatever the integers need, they need.

00:22:42.960 --> 00:22:46.740
But then comes along NumPy and Pandas and they say, no, you have to choose how big it's

00:22:46.840 --> 00:22:47.100
going to be.

00:22:47.320 --> 00:22:50.240
You're like, well, okay, let's just make everything 64 bits, right?

00:22:50.440 --> 00:22:50.880
What could be the cost?

00:22:50.880 --> 00:22:51.280
Just be safe.

00:22:52.120 --> 00:22:52.380
Right.

00:22:52.830 --> 00:22:58.740
And basically, let's say you have a billion rows that, you know, let's say you just have

00:22:58.740 --> 00:22:59.420
a billion elements.

00:23:00.040 --> 00:23:04.640
Well, 64 bits is going to be literally twice as much as 32.

00:23:05.530 --> 00:23:09.700
And that could mark the difference between running out of memory and not running out of memory.

00:23:10.460 --> 00:23:11.580
Or having to swap.

00:23:11.820 --> 00:23:13.220
It's going to get very bad.

00:23:13.500 --> 00:23:20.200
And so, especially since Pandas is constrained by what can fit into available RAM.

00:23:22.220 --> 00:23:27.000
So, you're always stuck with this tension with these D types.

00:23:27.100 --> 00:23:29.220
between you have to keep it bigger,

00:23:29.960 --> 00:23:32.120
big enough to fit all the data you want

00:23:32.430 --> 00:23:34.520
and small enough that you'll be able

00:23:34.520 --> 00:23:35.340
to fit everything into memory.

00:23:36.280 --> 00:23:37.360
And it's a bit of a game.

00:23:37.700 --> 00:23:40.780
There's no formula you can use

00:23:40.970 --> 00:23:41.740
because you can't know in advance

00:23:41.870 --> 00:23:43.020
what all your data is going to be usually.

00:23:43.540 --> 00:23:43.900
Yeah.

00:23:45.120 --> 00:23:45.600
Yeah, for sure.

00:23:45.740 --> 00:23:47.900
I mean, honestly, it really freaked me out a little bit

00:23:47.940 --> 00:23:49.460
when I first started doing Python

00:23:49.740 --> 00:23:52.220
and it didn't matter what integer type I created.

00:23:52.250 --> 00:23:53.900
I'm like, well, I give it this number,

00:23:53.950 --> 00:23:55.040
but what if it gets too big?

00:23:55.480 --> 00:23:56.360
How do I control that?

00:23:56.540 --> 00:23:58.340
You know, you don't.

00:23:58.440 --> 00:23:59.820
It's just, it's magic.

00:24:01.380 --> 00:24:01.720
Right, right.

00:24:01.840 --> 00:24:03.920
And I come from like a dynamic language background.

00:24:03.980 --> 00:24:07.160
Like I was always sort of brainwashed to think this is the way normal things are.

00:24:07.680 --> 00:24:15.140
And so when I was like told them there are languages where you have to say how many bits it's going to be in advance, I was like, wait, what kind of crazy stuff is this?

00:24:16.160 --> 00:24:16.240
But

00:24:16.240 --> 00:24:19.600
it turns out a very large number of people see that as totally normal.

00:24:20.520 --> 00:24:20.680
Yeah.

00:24:21.960 --> 00:24:22.400
It's interesting.

00:24:22.500 --> 00:24:26.440
I was just looking at some C-sharp stuff last night,

00:24:27.780 --> 00:24:29.780
and all the symbols and all the stuff there.

00:24:30.860 --> 00:24:32.260
It seems normal when you're in that.

00:24:32.320 --> 00:24:33.280
Then you step out of it.

00:24:33.280 --> 00:24:35.080
You're like, wait, I don't have to be constrained by this,

00:24:35.080 --> 00:24:37.160
or I don't have to worry about that particular thing.

00:24:37.280 --> 00:24:37.660
That's weird.

00:24:37.880 --> 00:24:39.700
But wait, if I don't have to worry about it,

00:24:39.720 --> 00:24:42.860
why have I been spending all my time and energy thinking about it, right?

00:24:43.520 --> 00:24:46.960
But I mean, I would say most languages, actually,

00:24:47.100 --> 00:24:53.260
you probably do have to worry about your numerical sizes, right?

00:24:53.500 --> 00:24:58.380
Anything that's sort of compiled and allocates things like that,

00:24:58.420 --> 00:24:59.040
you work with memory.

00:25:00.260 --> 00:25:04.660
Look, it's like a statically typed versus dynamically typed language sort of thing.

00:25:05.180 --> 00:25:05.400
Do

00:25:05.400 --> 00:25:07.000
you want to have that extra safety?

00:25:07.050 --> 00:25:09.480
Do you want to know in advance how much memory you're going to use?

00:25:10.360 --> 00:25:13.720
Or do you want it to be more expressive and flexible,

00:25:14.340 --> 00:25:19.220
but then potentially have problems if you don't think about enough in advance.

00:25:21.280 --> 00:25:21.480
Yeah,

00:25:21.560 --> 00:25:21.940
yeah, yeah.

00:25:22.420 --> 00:25:23.360
Yeah, for sure.

00:25:24.180 --> 00:25:24.360
All right.

00:25:25.800 --> 00:25:30.720
So that's, I guess, one more thing before we move on to talk about Arrow.

00:25:32.080 --> 00:25:37.180
You can ask Pandas how much data a data frame is consuming, right?

00:25:38.940 --> 00:25:41.740
So the answer is, as always with me, yes and no.

00:25:42.380 --> 00:25:45.980
You can ask it how much memory it's using, and it will give you an answer.

00:25:46.700 --> 00:25:48.520
And sometimes that answer is even accurate.

00:25:49.540 --> 00:25:54.220
And the problem is basically that it will tell you how much memory is being used in NumPy.

00:25:54.920 --> 00:25:59.020
And so if you've got integers, if you've got floats, if you've got date times, it will be 100% accurate.

00:25:59.520 --> 00:26:06.740
The moment that you have strings or other objects, let's just concentrate on strings, NumPy does have strings, and they're terrible.

00:26:07.460 --> 00:26:09.800
And so basically, Pandas is like, we're not going to use those.

00:26:09.920 --> 00:26:14.320
we're going to use Python strings and we'll just store a pointer in NumPy,

00:26:14.360 --> 00:26:16.760
a 64-bit pointer that points the Python string,

00:26:17.520 --> 00:26:20.640
which means that if it calculates how much memory is being used by NumPy,

00:26:21.180 --> 00:26:25.260
it's showing you how big the pointer is, which is potentially,

00:26:25.840 --> 00:26:27.740
I mean, there is no connection.

00:26:27.880 --> 00:26:30.400
There's no correlation between that and the size of the string.

00:26:30.820 --> 00:26:32.100
All strings are eight bytes.

00:26:32.720 --> 00:26:32.980
Problem solved.

00:26:32.980 --> 00:26:33.200
That's right.

00:26:33.480 --> 00:26:33.700
That's right.

00:26:35.340 --> 00:26:36.580
Well, we've washed our heads of that one.

00:26:36.920 --> 00:26:47.060
And so when you use df.info, use the info method on a data frame, it will report back, and then sometimes it'll put a plus after that number.

00:26:47.460 --> 00:26:51.120
And the plus means, hey, I've got some strings here in Python memory.

00:26:51.560 --> 00:26:55.380
I'm going to just give you a fast answer, and I'm not going to go explore that.

00:26:55.500 --> 00:27:02.720
If you really want a real answer, tell me basically deep equals true, and then I'll go off and explore Python memory.

00:27:02.820 --> 00:27:04.700
It'll take longer, but you'll get an accurate count.

00:27:05.520 --> 00:27:12.140
And that's surprising to a lot of people, including because the index and the column names are also typically strings.

00:27:12.650 --> 00:27:17.140
And so the moment you have an index or column names assigned, it'll also give you that plus.

00:27:17.530 --> 00:27:18.600
And you can't depend on it.

00:27:20.280 --> 00:27:20.780
Yeah, interesting.

00:27:21.130 --> 00:27:25.320
And, you know, Python objects have the same issue if you ask in Python.

00:27:25.430 --> 00:27:27.080
I can't remember exactly what the

00:27:27.080 --> 00:27:29.100
size of.

00:27:30.220 --> 00:27:31.080
Yeah, get size of.

00:27:31.220 --> 00:27:31.500
That's it.

00:27:32.200 --> 00:27:34.720
Yeah, and that does the exact same thing.

00:27:34.800 --> 00:27:36.740
So if you've got a list, for example, or a dictionary,

00:27:36.780 --> 00:27:38.260
and you ask how big is it, it's like, well,

00:27:39.179 --> 00:27:42.400
it's basically how many pointers are stored in its structure

00:27:42.500 --> 00:27:43.360
that point out the things.

00:27:44.660 --> 00:27:46.980
For the memory class I did at Talk Python,

00:27:47.520 --> 00:27:49.820
I had to write some code that would basically traverse

00:27:50.040 --> 00:27:52.380
the object graph of all the structures.

00:27:53.539 --> 00:27:55.360
And this is actually how big it is,

00:27:55.360 --> 00:27:57.540
and this is why it's doing this in memory and so on.

00:27:58.360 --> 00:28:04.160
It's not unique to NumPy, but it's just,

00:28:04.720 --> 00:28:08.520
you got pointers, it's a lot more work to traverse them and figure that stuff all out.

00:28:09.120 --> 00:28:19.060
Okay, so there's a lot of energy around a specification, a library, called Arrow from Apache Arrow.

00:28:19.600 --> 00:28:27.020
It's the universal columnar, word always catches me up, columnar, format and multi-language toolbox

00:28:27.360 --> 00:28:30.580
for fast data interchange and in-memory analytics.

00:28:31.360 --> 00:28:33.980
And so this is super interesting, this project.

00:28:34.240 --> 00:28:39.180
Let me go to its homepage or whatever.

00:28:39.860 --> 00:28:45.480
But, yeah, you have this for many different languages, right?

00:28:45.580 --> 00:28:46.400
It's not just Python.

00:28:46.640 --> 00:28:49.980
In fact, it's like NumPy written, and this one's written in C++.

00:28:51.980 --> 00:28:53.940
Yeah, I mean, so think about it this way.

00:28:55.020 --> 00:28:59.820
I mean, I always sort of think about my evolution of seeing amazing stuff in programming languages.

00:29:00.300 --> 00:29:04.340
So it used to be really amazing that you could get strings right back, let's say, 30 years ago.

00:29:04.700 --> 00:29:07.080
Wow, you don't think about arrays of characters.

00:29:07.600 --> 00:29:08.240
It's just a string.

00:29:08.760 --> 00:29:08.940
Amazing.

00:29:09.500 --> 00:29:11.860
Fast forward a number of years, and I was amazed by dates and times.

00:29:12.500 --> 00:29:15.840
And nowadays, everyone wants to do data frames.

00:29:16.680 --> 00:29:23.620
And so Wes McKinney, a bunch of other people, like he invented pandas, said, well, why don't we, instead of everyone inventing our own thing,

00:29:24.020 --> 00:29:29.660
why don't we create a back-end data storage system that everyone can use that does all the data frame stuff?

00:29:29.800 --> 00:29:31.120
because we all want them in our languages.

00:29:31.920 --> 00:29:34.500
And then we can make it really fast and universal

00:29:34.940 --> 00:29:36.040
and do lots of inputs and outputs

00:29:36.960 --> 00:29:39.100
and even have interchange among these different languages.

00:29:39.510 --> 00:29:41.220
And so that's what Arrow is basically trying to do.

00:29:41.220 --> 00:29:43.780
It's trying to be like the universal, super fast,

00:29:44.490 --> 00:29:46.700
super efficient data frame implementation.

00:29:47.650 --> 00:29:52.620
So your pandas library just needs to be a layer on top of that,

00:29:53.180 --> 00:29:56.240
which might have some echoes of just being a layer on top of NumPy.

00:29:56.520 --> 00:29:57.600
Yeah, it sounds similar.

00:29:57.690 --> 00:29:58.160
It sounds familiar.

00:30:00.260 --> 00:30:01.520
Yeah, very cool.

00:30:01.760 --> 00:30:08.920
So let's talk about this columnar thing, columnar aspect of it.

00:30:10.960 --> 00:30:15.200
So I guess Pandas and NumPy operate on the concept of rows.

00:30:15.420 --> 00:30:22.660
I've got rows of data, and Arrow is more about I have columns of data

00:30:22.860 --> 00:30:25.840
that could somehow have row definitions into them.

00:30:27.000 --> 00:30:34.620
And it lets you ask different questions more or less easy, right?

00:30:34.880 --> 00:30:35.680
Depending on what you're trying to ask.

00:30:35.820 --> 00:30:40.140
Like, what is the average of the miles per hour?

00:30:40.330 --> 00:30:42.480
Like, oh, well, that's just this thing.

00:30:42.710 --> 00:30:46.300
I go right down the column and boom, here's the answer, you know?

00:30:47.480 --> 00:30:50.700
Or you start asking that by rows and arrow,

00:30:51.040 --> 00:30:53.060
then it's got to do a lot of work to kind of piece that together.

00:30:53.400 --> 00:30:55.360
And quite the opposite for pandas, right?

00:30:56.560 --> 00:31:02.840
So I'm still digging into exactly like what's going on there. What you said is I think true,

00:31:03.640 --> 00:31:07.380
but it's also true that Pandas data frames, you can think of them, I think of them as like a

00:31:07.590 --> 00:31:14.140
dictionary of series where each column is actually a series. So it's not really row by row, but the

00:31:14.260 --> 00:31:19.020
NumPy implementation is row by row. So I think like something in the back end there is being

00:31:19.240 --> 00:31:24.279
translated differently, but it's a hundred percent true that Arrow is just way faster doing analysis

00:31:24.640 --> 00:31:25.540
of a column.

00:31:26.840 --> 00:31:29.080
NumPy might be faster at adding elements

00:31:29.350 --> 00:31:30.720
or doing that sort of thing.

00:31:31.160 --> 00:31:32.780
But the moment that you want to, as you said,

00:31:32.870 --> 00:31:34.660
get the mean or get the min or the max

00:31:34.710 --> 00:31:35.880
or sum them up or whatever,

00:31:36.480 --> 00:31:38.300
Arrow's just blazingly fast

00:31:38.460 --> 00:31:41.200
because that's what it was very specifically designed to do.

00:31:42.600 --> 00:31:46.200
Yeah, you just preload the data.

00:31:46.340 --> 00:31:47.980
You've got to load it into some kind of data structure, right?

00:31:48.520 --> 00:31:54.260
And you can do that in ways that optimize some things

00:31:54.280 --> 00:31:55.140
at the cost for others.

00:31:55.240 --> 00:31:55.760
I think there's

00:31:55.760 --> 00:31:57.000
a

00:31:57.000 --> 00:31:59.340
little bit of a similarity

00:31:59.780 --> 00:32:03.680
between relational databases and document NoSQL ones

00:32:04.240 --> 00:32:08.760
in the sense like their data is structured in one way

00:32:08.800 --> 00:32:10.900
for really good operations, right?

00:32:11.020 --> 00:32:14.000
Like I want to go through this table really well

00:32:14.640 --> 00:32:16.460
and I want to maybe follow a relationship.

00:32:16.940 --> 00:32:17.900
That's set up really well,

00:32:18.140 --> 00:32:21.120
but you're still computing all those things

00:32:21.160 --> 00:32:23.600
because they're in like different places in relational ones

00:32:23.620 --> 00:32:25.300
And then, like, say, a document database,

00:32:25.800 --> 00:32:27.780
if you know there's always this relationship you follow,

00:32:27.870 --> 00:32:30.600
you can just put them together and, like, kind of pre-compute them.

00:32:31.240 --> 00:32:34.580
But that makes other questions that don't follow that relationship

00:32:35.000 --> 00:32:37.200
but, like, use the nested data super, not super hard,

00:32:37.280 --> 00:32:40.080
but much harder than it otherwise would be, right?

00:32:40.620 --> 00:32:42.940
So it's all about these tradeoffs and how you store stuff.

00:32:43.390 --> 00:32:45.200
You know, what kind of questions are you going to ask it?

00:32:46.440 --> 00:32:46.960
That's right.

00:32:47.480 --> 00:32:48.180
I feel like this is a

00:32:48.180 --> 00:32:48.640
little more.

00:32:49.360 --> 00:32:49.720
Sorry, go ahead.

00:32:50.780 --> 00:32:53.620
I was just going to say, Arrow goes even further than that.

00:32:53.900 --> 00:32:59.920
It does compression because it says, well, if I've got all this stuff in the column and I see a lot of the same things, I'll just compress it.

00:33:00.480 --> 00:33:01.760
Also, it has strings.

00:33:02.560 --> 00:33:03.480
So we don't have to.

00:33:03.900 --> 00:33:14.780
Arrow has its own implementation of strings in its binary format right there, which, again, we were talking a few minutes ago about how currently Pandas ignores NumPy strings.

00:33:14.940 --> 00:33:16.920
And so it uses Python strings.

00:33:17.780 --> 00:33:22.480
And so Arrow offers the opportunity of having them right there in memory nicely and efficiently.

00:33:24.059 --> 00:33:25.740
Yeah, for sure.

00:33:26.760 --> 00:33:28.860
Now we have PyArrow.

00:33:29.540 --> 00:33:29.960
What's the

00:33:29.960 --> 00:33:32.280
relationship between Arrow and PyArrow?

00:33:33.600 --> 00:33:39.700
So that's actually simple to explain, which is PyArrow is just the Python client for Arrow.

00:33:40.320 --> 00:33:41.360
So you want to use Arrow.

00:33:41.830 --> 00:33:42.780
You're a Python developer.

00:33:43.380 --> 00:33:44.680
You do import PyArrow.

00:33:44.730 --> 00:33:46.320
And you now have these data structures available.

00:33:46.780 --> 00:33:48.320
By the way, you can do that without pandas.

00:33:48.500 --> 00:33:57.580
If you are like a pandas hater or you just have no interest in using it, but you want really fast data storage, use PyArrow.

00:33:57.800 --> 00:33:59.320
And there's nothing wrong with that.

00:34:00.800 --> 00:34:06.500
I'll even say that my interest in PyArrow and pandas started a few years ago.

00:34:06.520 --> 00:34:10.620
I saw a talk at a conference somewhere, and I was so incredibly confused.

00:34:10.980 --> 00:34:14.600
I was like, okay, so there's PyArrow and there's pandas, and they say there's a relationship.

00:34:14.820 --> 00:34:15.679
But what is that relationship?

00:34:15.740 --> 00:34:16.860
I have no idea

00:34:17.300 --> 00:34:17.399
and

00:34:17.399 --> 00:34:17.919
that's what like

00:34:18.320 --> 00:34:19.080
it's all NumPy

00:34:19.200 --> 00:34:20.600
and NumPy has nothing to do with it

00:34:20.620 --> 00:34:21.300
what's going on here?

00:34:22.460 --> 00:34:22.659
right

00:34:23.080 --> 00:34:23.280
right right

00:34:24.120 --> 00:34:24.300
so

00:34:24.880 --> 00:34:26.100
so you can use PyArrow

00:34:26.139 --> 00:34:27.060
and there's nothing wrong with it

00:34:27.139 --> 00:34:28.800
and it has a rich set of data types

00:34:29.179 --> 00:34:30.940
and all sorts of really amazing functionality

00:34:31.220 --> 00:34:32.399
and of course it's super fast

00:34:34.120 --> 00:34:34.899
somewhere in here

00:34:34.960 --> 00:34:36.560
I was looking around for

00:34:37.280 --> 00:34:37.460
which

00:34:39.540 --> 00:34:40.639
there's a list that says

00:34:40.820 --> 00:34:41.800
here's all the different languages

00:34:42.040 --> 00:34:43.599
that's supported on the Arrow project

00:34:44.919 --> 00:34:47.879
and yeah, it's the implementation status, I believe.

00:34:48.560 --> 00:34:53.280
And so it says, well, what data types are supported per language?

00:34:53.370 --> 00:34:56.460
So there's like a Java implementation and a C# implementation

00:34:56.840 --> 00:35:00.680
and a Julia and a Swift and a Nano and a Rust and so on.

00:35:01.300 --> 00:35:03.980
And I'm looking through here and like obviously the C++ one

00:35:04.360 --> 00:35:06.340
has pretty much everything supported,

00:35:07.290 --> 00:35:12.200
whereas say the Java one doesn't do decimal 32 or 64,

00:35:12.540 --> 00:35:17.040
but it does floats or does the big, the really big decimals, you know,

00:35:17.180 --> 00:35:18.720
things like that, 120 bit and so on.

00:35:19.400 --> 00:35:21.520
And I'm like, something is wrong.

00:35:21.820 --> 00:35:24.480
There's something is throwing me off here because I know there's a real

00:35:24.760 --> 00:35:28.620
popular Python and I don't, Python is not listed as a language.

00:35:29.340 --> 00:35:30.460
So that's throwing me off.

00:35:30.640 --> 00:35:31.400
Like, why is this?

00:35:32.820 --> 00:35:36.640
So I'm like, Oh, under the details, it says,

00:35:36.740 --> 00:35:37.580
unless otherwise stated,

00:35:37.840 --> 00:35:41.360
Python, R, Ruby, and CGLib libraries

00:35:41.660 --> 00:35:43.560
are following the C++ error library

00:35:43.700 --> 00:35:46.040
because there's like a really native tie

00:35:46.320 --> 00:35:49.180
to the original C++ version.

00:35:49.440 --> 00:35:49.920
Isn't that interesting?

00:35:51.420 --> 00:35:53.740
So I think it also means those languages,

00:35:53.980 --> 00:35:55.020
like those are all dynamic languages,

00:35:55.160 --> 00:35:56.900
well, not C, GLib,

00:35:57.240 --> 00:35:58.740
but like the dynamic languages there

00:35:59.500 --> 00:36:00.600
are I think these thin layers

00:36:00.780 --> 00:36:02.440
that just talk directly to the C++

00:36:02.440 --> 00:36:03.180
implementation.

00:36:03.180 --> 00:36:03.640
Yeah, exactly.

00:36:04.620 --> 00:36:06.540
And so it's like whatever that can do,

00:36:06.650 --> 00:36:07.280
we can do too.

00:36:08.300 --> 00:36:08.700
boom.

00:36:09.360 --> 00:36:17.660
Yeah, exactly. Exactly. So I think when you think about PyArrow, I feel like you almost

00:36:17.940 --> 00:36:24.800
should just think about the C++ layer. Or if you hear features of Arrow, look at the C++ stuff

00:36:24.960 --> 00:36:29.200
because PyArrow is just like you say, a very thin wrapper on top of that. But at first when I look,

00:36:29.280 --> 00:36:36.380
it's like, what? They're talking about C# and Java? No Python in this? I mean, surely there's

00:36:36.400 --> 00:36:40.740
enough data science in Python to warrant a checkbox or a check column.

00:36:41.460 --> 00:36:42.680
They're like, we're so great,

00:36:42.690 --> 00:36:43.720
we don't even need a column.

00:36:44.520 --> 00:36:49.000
Exactly. Yeah. We're the native column. Anyway, I think that's really

00:36:49.240 --> 00:36:54.220
interesting. So I do want to go, I think this, this little data types thing gives us a bit of a

00:36:55.160 --> 00:37:06.360
jumping off point for circling back a little bit. Why did I bring up that genie joke, right? Other

00:37:06.380 --> 00:37:08.420
have these D-type concepts

00:37:09.820 --> 00:37:10.520
down in the C++

00:37:10.800 --> 00:37:12.320
layer, which is really no different in terms

00:37:12.320 --> 00:37:13.620
of data types than C.

00:37:15.180 --> 00:37:16.300
Right? There's still 4-bit

00:37:16.310 --> 00:37:18.180
or 8-bit numbers and so on.

00:37:18.520 --> 00:37:19.400
Signed or unsigned.

00:37:20.560 --> 00:37:21.520
And you have this here, but

00:37:22.120 --> 00:37:23.960
Pi Arrow, and more generally Arrow,

00:37:24.360 --> 00:37:25.960
deals with that differently, right?

00:37:26.060 --> 00:37:28.280
If you have overflows or missing numbers,

00:37:28.520 --> 00:37:29.960
it's not exactly the same as

00:37:31.920 --> 00:37:32.360
negative

00:37:32.850 --> 00:37:33.720
or positive

00:37:33.740 --> 00:37:38.720
of 22 2.4 billion or whatever it is right

00:37:38.720 --> 00:37:43.040
i mean so so yeah well the whole miss missing data thing

00:37:43.240 --> 00:37:49.420
is a whole problem in and of itself so like i mean there's missing data in every data set we have

00:37:49.820 --> 00:37:55.080
right so people forget to enter stuff and sensors go dead and like networks are down all sorts of

00:37:55.160 --> 00:37:59.800
stuff so what do you do if the data is missing because you can't just like have a blank space

00:37:59.820 --> 00:38:01.020
there. And so

00:38:01.020 --> 00:38:02.340
for

00:38:02.340 --> 00:38:05.580
many people, their natural, if they're new to this, their natural assumption is,

00:38:05.760 --> 00:38:11.120
oh, well, I'll just do a minus one, or I'll use zero, and then it'll be great. And you think about,

00:38:11.220 --> 00:38:16.000
well, what happens if the temperature sensors are dead? Okay, fine. So maybe we'll use minus 999.

00:38:16.960 --> 00:38:21.620
Well, wait, that's probably not so good either. And so after, it's been a number of years that

00:38:21.700 --> 00:38:25.920
people have realized, okay, we need a totally separate thing to indicate the data is missing.

00:38:26.440 --> 00:38:31.320
And so that's where NAN comes in, not a number, or in modern Python, it would be NA.

00:38:32.720 --> 00:38:39.300
But then you get into other issues of, well, wait, what type is NA or what type is NAN?

00:38:39.800 --> 00:38:42.620
And it turns out that NAN in traditional NumPy is a float.

00:38:43.380 --> 00:38:47.200
And so if you have a bunch of strings and you want to say there's a missing value, oh,

00:38:47.360 --> 00:38:50.200
wait a second, so now we've got strings and we've got this float, oh no.

00:38:50.860 --> 00:38:52.280
And it just goes downhill from there.

00:38:52.780 --> 00:39:06.580
And so one of the amazing things that Arrow did from the get-go was to say all these types, all these values we have are nullable, meaning that there is a specific value of nan or na or whatnot that fits with all these things.

00:39:06.760 --> 00:39:08.540
So you can have integers and na.

00:39:08.860 --> 00:39:10.400
You can have strings and na.

00:39:11.120 --> 00:39:13.920
You can even have the first row of that table you're showing there is null.

00:39:14.160 --> 00:39:14.760
It's kind of wild.

00:39:15.140 --> 00:39:20.360
But if your column contains only null values, then it will be defined to have a null dtype.

00:39:20.760 --> 00:39:22.480
And then it's just like, oh, yeah, we got 10 nulls.

00:39:22.760 --> 00:39:24.180
And then it's like almost zero storage.

00:39:25.440 --> 00:39:27.060
And so PyO took this into account.

00:39:27.120 --> 00:39:37.220
And it means then that your data is, it's no less accurate, but it's also tighter, easier to work with, and more predictable.

00:39:38.920 --> 00:39:45.480
Yeah, if you use a sentinel number or something for missing data, like you're seeing, like negative 999, that may or may not work.

00:39:45.520 --> 00:39:48.080
But you better not ask what the average temperature is.

00:39:49.460 --> 00:39:50.760
Gosh, it's really cold there.

00:39:50.760 --> 00:39:53.300
I thought Hawaii was nice, but no, it's

00:39:53.300 --> 00:39:53.620
cold.

00:39:55.140 --> 00:39:55.880
That's right.

00:39:56.400 --> 00:39:56.680
That's right.

00:39:58.260 --> 00:39:58.760
Yeah, yeah.

00:39:59.040 --> 00:40:05.220
Another interesting aspect of arrow, C++ arrow, pi arrow, same thing,

00:40:06.120 --> 00:40:10.100
is the copy on write aspect to save memory, right?

00:40:10.640 --> 00:40:15.860
So maybe you've got a string that appears a lot of times like Kansas

00:40:15.860 --> 00:40:19.640
or Oregon or New Jersey or wherever,

00:40:20.780 --> 00:40:22.660
and you've got a million rows of those,

00:40:23.300 --> 00:40:26.400
do you need that string repeated a million times, right?

00:40:27.280 --> 00:40:28.600
That's right. That's right.

00:40:28.630 --> 00:40:30.560
So it's much smarter about that sort of stuff.

00:40:31.000 --> 00:40:33.500
Like, you know, it's always easier

00:40:34.020 --> 00:40:36.160
to design a software system second time around

00:40:36.380 --> 00:40:37.820
when you see where all the issues were.

00:40:38.110 --> 00:40:40.020
And I think that they took a lot of the lessons

00:40:40.480 --> 00:40:43.580
from be it Pandas, be it R, be it Apache Spark,

00:40:43.720 --> 00:40:44.140
all these things.

00:40:44.280 --> 00:40:47.740
They're like, okay, where are their inefficiencies for the program

00:40:47.760 --> 00:40:49.280
or where are their inefficiencies in the system?

00:40:49.740 --> 00:40:53.340
And let's try to just like solve those problems as best as we can

00:40:54.240 --> 00:40:56.740
for the general public so they don't have to think about this.

00:40:57.560 --> 00:41:00.560
And yeah, that's part of like, so it gets way, way faster, way, way smaller.

00:41:01.100 --> 00:41:01.580
Yeah.

00:41:02.160 --> 00:41:03.900
We opened our Panda discussion.

00:41:04.140 --> 00:41:06.640
We're talking about importing data from lots of different sources.

00:41:07.820 --> 00:41:13.140
And it seems like Arrow might be slower because if it's doing compression,

00:41:13.520 --> 00:41:21.400
If it's doing deduping and all these types of things, it seems like it would be slower, but it's actually not.

00:41:21.900 --> 00:41:25.200
Like loading CSVs is way faster and these types of things, right?

00:41:25.960 --> 00:41:26.400
Oh, my God.

00:41:26.680 --> 00:41:27.700
There's no comparison.

00:41:28.260 --> 00:41:32.000
So loading CSVs, and this is one of those things where PyArrow, and we'll get to this in a bit,

00:41:32.420 --> 00:41:35.820
but PyArrow will eventually replace NumPy.

00:41:35.960 --> 00:41:45.200
But even today, like when we're recording, you can with like very confidently use PyArrow to read in your CSV files in Pandas.

00:41:45.620 --> 00:41:46.440
It won't change how it's stored.

00:41:46.540 --> 00:41:47.720
It'll still be stored in NumPy.

00:41:48.340 --> 00:41:54.960
I think, I'm not 100% sure, but I think that it does multi-threading and splitting up the file and all that stuff that we would sort of want it to do.

00:41:55.660 --> 00:41:57.180
So it's like blazingly fast.

00:41:57.960 --> 00:42:02.060
I'll even say like a few days ago, I was talking with people.

00:42:02.210 --> 00:42:04.580
I even put up a YouTube video about this because I was just so floored.

00:42:05.060 --> 00:42:08.780
So reading in an Excel file, I always thought, okay, Excel's a binary format.

00:42:08.980 --> 00:42:09.440
So I'll read it.

00:42:09.440 --> 00:42:10.340
It'll be nice and fast.

00:42:10.760 --> 00:42:13.520
And it took over a minute for me to read it in Excel.

00:42:13.520 --> 00:42:13.580
Wow.

00:42:14.560 --> 00:42:21.060
And then I tried it basically using one of the arrow binary formats that it has defined.

00:42:21.400 --> 00:42:23.560
I guess we'll talk about that a little bit because I'm jumping on a bit.

00:42:23.980 --> 00:42:27.860
And it was, I'm not exaggerating here, 2,000 times faster.

00:42:29.000 --> 00:42:34.640
It was so ridiculously, ridiculously fast because

00:42:34.640 --> 00:42:35.600
it

00:42:35.600 --> 00:42:39.980
is like so optimized for doing like one job and just that one job.

00:42:42.220 --> 00:42:42.520
Incredible.

00:42:42.920 --> 00:42:47.420
Yeah, you think Excel would be optimized for loading data, but I mean, Excel, the app is.

00:42:48.120 --> 00:43:02.920
But I'm pretty sure that the XLXS, whatever, like the format, I think that is a zip file that internally contains a probably namespace-laden XML document.

00:43:04.300 --> 00:43:05.060
You are good.

00:43:05.680 --> 00:43:10.600
So someone, one of my subscribers at Banff Weekly emailed me and he said, okay, I get it.

00:43:10.600 --> 00:43:11.700
You're an open source kind of guy.

00:43:12.080 --> 00:43:13.560
You're not up on all the Excel formats.

00:43:13.920 --> 00:43:14.580
Let me explain to you.

00:43:14.840 --> 00:43:17.480
Just last night we had office hours and he like went into it in more detail.

00:43:17.660 --> 00:43:18.840
So you're spot on.

00:43:20.719 --> 00:43:21.079
XLSX

00:43:21.079 --> 00:43:21.680
is a

00:43:21.680 --> 00:43:22.100
zip file.

00:43:22.620 --> 00:43:25.940
You can actually unzip it and you can see all the XML files inside.

00:43:26.660 --> 00:43:33.280
And so that unzipping and that XML deserialization and so forth, that is where it's taking a ridiculously long time.

00:43:34.040 --> 00:43:34.220
Right.

00:43:34.310 --> 00:43:37.480
And apparently they didn't optimize for load speed.

00:43:37.570 --> 00:43:38.440
They optimized for other stuff.

00:43:38.770 --> 00:43:40.340
And maybe that's the right choice for Excel.

00:43:40.980 --> 00:43:42.380
but this is like coming back to

00:43:42.860 --> 00:43:44.800
like okay we need to fix some of these problems

00:43:44.980 --> 00:43:46.720
and what is the most common thing we do

00:43:46.820 --> 00:43:48.160
let's optimize for that right

00:43:48.780 --> 00:43:50.360
kind of like columnar versus rows

00:43:50.600 --> 00:43:52.780
so that brings us to a couple

00:43:52.980 --> 00:43:54.900
of file formats that are pretty interesting

00:43:56.440 --> 00:43:58.680
let's talk about parquet first

00:44:00.100 --> 00:44:01.060
by the way I will admit

00:44:01.480 --> 00:44:03.220
I have no idea if you're supposed to say parquet

00:44:03.240 --> 00:44:05.040
or parquet so I'll go with you

00:44:05.100 --> 00:44:06.820
and parquet I know that like the flooring

00:44:06.980 --> 00:44:09.099
is parquet but whatever

00:44:09.720 --> 00:44:11.840
you know what I'm going to ask ChatGPT

00:44:14.640 --> 00:44:16.120
it's always good at pronouncing things

00:44:16.610 --> 00:44:18.100
so the basic idea

00:44:18.370 --> 00:44:20.140
is okay like the arrow people

00:44:20.800 --> 00:44:22.240
came up with a great way of representing

00:44:22.370 --> 00:44:23.780
things efficiently in memory

00:44:24.620 --> 00:44:26.300
so they said well what about

00:44:26.700 --> 00:44:28.360
representing that on disk

00:44:29.060 --> 00:44:30.540
and they actually came up with

00:44:30.730 --> 00:44:32.140
two file formats because

00:44:32.800 --> 00:44:34.560
you know there are different tradeoffs we want to make

00:44:35.220 --> 00:44:36.200
and parquet format

00:44:36.490 --> 00:44:37.860
is like a

00:44:38.320 --> 00:44:46.200
sort of very, I don't know, verbatim version of, no, yeah, it's actually compressed. It's taking

00:44:46.320 --> 00:44:51.120
the binary data that we have and compressing it. What's the good news? Takes very little space on

00:44:51.240 --> 00:44:55.000
disk. The bad news is it takes a little bit extra time to do the compression decompression when

00:44:55.000 --> 00:45:01.000
you're saving and loading. Feather is the same idea, it just doesn't get compressed. So it takes

00:45:01.080 --> 00:45:07.840
more disk space, but it's faster to load and save. In either one of these cases, you'll be completely

00:45:07.860 --> 00:45:14.260
utterly blown away by how fast they are. And the fact that they are binary formats that are exactly

00:45:14.270 --> 00:45:19.300
the same D types as you have in Arrow means there's no more guessing. There's no more playing

00:45:19.350 --> 00:45:23.520
around with CSV and having to nudge in the right direction. There's no more of this really long

00:45:23.800 --> 00:45:30.300
loading with Excel that we were just talking about. It just like screamingly fast pulls it

00:45:30.330 --> 00:45:32.620
into memory with exactly the D types that you wanted.

00:45:33.140 --> 00:45:35.500
Yeah. Super interesting there, I think.

00:45:39.920 --> 00:45:43.240
it's still I see too many like because I deal with a lot of public data sets

00:45:43.740 --> 00:45:47.720
and I see overwhelmingly they're still using CSV and Arrow

00:45:48.380 --> 00:45:52.080
I'm sorry CSV and Excel here and there here and there I'm starting to see

00:45:52.220 --> 00:45:56.100
people make things available in parquet format and feather format so like

00:45:56.160 --> 00:45:58.580
it's making some inroads among the like data savvy

00:45:59.640 --> 00:46:03.040
what I was going to ask is what do you think about the workflow

00:46:03.040 --> 00:46:06.260
So I'm going to work on a data science project.

00:46:06.780 --> 00:46:11.440
I've got a 200 meg CSV file that takes forever to load.

00:46:13.640 --> 00:46:16.640
Maybe the first thing I do is convert it to either,

00:46:17.340 --> 00:46:18.660
probably I convert it to Parquet.

00:46:19.400 --> 00:46:23.480
I'm going with that French-ish pronunciation as well.

00:46:24.080 --> 00:46:25.260
I convert it to Parquet files,

00:46:25.800 --> 00:46:28.860
and then from then on my program just works with it.

00:46:29.220 --> 00:46:31.820
Maybe even at the start of your notebook or start of your code,

00:46:31.900 --> 00:46:36.160
Would you say, what is the last change of the Parquet file and the CSV?

00:46:36.440 --> 00:46:38.420
And if the CSV is newer, then regenerate.

00:46:38.520 --> 00:46:40.180
You know, some little, like, guard like that.

00:46:40.340 --> 00:46:44.440
But just keep your CSV file as part of your project,

00:46:44.940 --> 00:46:49.720
but operationally swap it over to one of these new formats and just work with that.

00:46:50.320 --> 00:46:52.320
I would 100% go in that direction.

00:46:53.860 --> 00:46:58.240
It's like, you know, if you start using UV, you're like, oh, my God, I can't

00:46:58.240 --> 00:46:58.800
believe.

00:46:58.820 --> 00:46:59.100
I'm not going

00:46:59.100 --> 00:46:59.220
back.

00:46:59.460 --> 00:47:00.060
I wasted so

00:47:00.060 --> 00:47:00.900
many days

00:47:00.900 --> 00:47:01.780
of my life waiting

00:47:01.780 --> 00:47:03.020
for pip to do its thing.

00:47:04.160 --> 00:47:07.220
And in the same way, when you start reading in files from Parquet,

00:47:07.830 --> 00:47:09.940
like as opposed to CSV files,

00:47:10.220 --> 00:47:10.760
you're

00:47:10.760 --> 00:47:12.100
like, oh my God, this is,

00:47:12.370 --> 00:47:16.360
like it just happens so fast that you can't even believe it.

00:47:18.020 --> 00:47:18.220
Again,

00:47:18.340 --> 00:47:18.720
like in

00:47:18.720 --> 00:47:21.220
my YouTube video, like I show, I use time,

00:47:21.330 --> 00:47:23.340
like I know I didn't use time, but I just like ran,

00:47:23.880 --> 00:47:27.200
like loaded in Excel once and took like, again, a minute, 20 seconds.

00:47:27.560 --> 00:47:30.320
And then I actually used at time it in Jupyter to

00:47:30.320 --> 00:47:31.300
load it from parquet

00:47:31.300 --> 00:47:31.720
format.

00:47:32.070 --> 00:47:33.740
And it was very happy to do a whole bunch of different loops

00:47:33.920 --> 00:47:35.600
and still ended up like way, way, way faster

00:47:35.880 --> 00:47:36.180
because it was

00:47:36.180 --> 00:47:37.040
so

00:47:37.040 --> 00:47:38.720
much, so ridiculously fast.

00:47:39.820 --> 00:47:41.060
Yeah, super interesting.

00:47:41.130 --> 00:47:45.340
And I think this is a big opportunity here for people to really,

00:47:46.160 --> 00:47:49.540
you could probably even for the sufficiently large projects,

00:47:49.800 --> 00:47:51.740
maybe you're not even wanting to use Arrow,

00:47:52.340 --> 00:47:57.040
but you could still probably load up a data frame in PyArrow.

00:47:57.200 --> 00:48:00.040
And then you can call like two pandas or something like that on it, right?

00:48:01.820 --> 00:48:02.000
Right.

00:48:02.250 --> 00:48:03.460
Although, I mean, you could.

00:48:03.570 --> 00:48:04.200
You definitely could.

00:48:04.210 --> 00:48:06.980
And that's how I was like sort of first introduced to Arrow.

00:48:07.520 --> 00:48:08.600
That's a gentle introduction.

00:48:09.540 --> 00:48:09.680
Right.

00:48:09.820 --> 00:48:10.300
Like, right.

00:48:10.470 --> 00:48:13.240
It was like, well, here's Arrow and here's pandas.

00:48:13.330 --> 00:48:14.900
And look, you can convert between the two.

00:48:15.579 --> 00:48:17.340
But, I mean, you can.

00:48:17.560 --> 00:48:19.760
And maybe there are a lot of people doing that.

00:48:20.400 --> 00:48:22.340
I just feel like, you know what?

00:48:22.500 --> 00:48:26.620
If I'm going to use Arrow, if I'm going to use PyArrow now, I'm just going to do it like directly inside of.

00:48:27.620 --> 00:48:30.200
inside my data frame and get the best of both

00:48:30.200 --> 00:48:30.400
worlds.

00:48:32.380 --> 00:48:33.320
Right. Super interesting.

00:48:33.900 --> 00:48:40.060
So that's one of the big aspects or areas you focus on

00:48:40.060 --> 00:48:44.840
in your upcoming PyCon talk is that increasingly there's a way to say,

00:48:45.400 --> 00:48:46.760
I want to use Pandas, but Pandas,

00:48:48.420 --> 00:48:51.280
don't use NumPy as your underlying storage engine.

00:48:51.760 --> 00:48:52.700
Use Arrow instead.

00:48:54.120 --> 00:48:55.000
That's right. That's right.

00:48:55.080 --> 00:48:55.220
So

00:48:55.220 --> 00:48:56.780
at some point,

00:48:57.200 --> 00:49:06.660
and it's not clear when, it's like they're going to make the switch where PyArrow will be the default storage and NumPy will be like an optional way to do it.

00:49:07.200 --> 00:49:10.100
Right now, it's not even the opposite of that.

00:49:10.210 --> 00:49:14.680
Right now, you can specify when you do a read CSV or read Excel or whatever.

00:49:15.110 --> 00:49:18.860
You can say D type backend equals PyArrow.

00:49:19.500 --> 00:49:21.420
And then they have it like big, bold letters.

00:49:21.880 --> 00:49:22.920
This is experimental.

00:49:23.580 --> 00:49:24.640
Do not use in production.

00:49:25.160 --> 00:49:30.380
here be dragons, that sort of thing. But if you do do it, if you're a little like, you know,

00:49:30.660 --> 00:49:36.260
if you're willing to experiment, then the d types you see are not NumPy d types. They are

00:49:36.420 --> 00:49:40.480
PyIro d types. And you can see the difference very clearly because it won't say n64, it'll say

00:49:40.580 --> 00:49:45.620
n64 square brackets PyIro. So it's very obvious to your eyes when you look at the d types.

00:49:46.460 --> 00:49:54.680
And it is blazingly, blazingly fast at anything you want to do on a column. So you want to do

00:49:54.680 --> 00:50:01.380
you want to do max you want to um like uh even when you do like group buys um i have in my talk

00:50:01.500 --> 00:50:06.860
like i have a whole bunch of graphs that i do and there are a few graphs where the bar for

00:50:07.860 --> 00:50:13.520
numpy pandas and the bar for pyro pandas you only see one bar because a pyro data frame

00:50:13.920 --> 00:50:16.120
was so fast that like it's just like

00:50:16.120 --> 00:50:17.920
basically might as well be zero right

00:50:17.920 --> 00:50:21.640
um so so i wouldn't

00:50:21.660 --> 00:50:25.540
say people should run out and put this in production just yet, but with every passing

00:50:25.760 --> 00:50:29.620
month or two, it's getting better and faster and more stable. And this

00:50:29.620 --> 00:50:30.880
is definitely the direction in which we're

00:50:30.880 --> 00:50:33.140
going. Very interesting.

00:50:33.370 --> 00:50:37.520
And so when you make that recommendation like stable versus non-stable production, not production,

00:50:38.240 --> 00:50:41.260
I feel like that probably is a statement on

00:50:42.420 --> 00:50:45.580
Pandas plus PyArrow integrated, not a statement on

00:50:45.890 --> 00:50:46.360
Aero itself.

00:50:47.740 --> 00:50:49.280
That's exactly right. That's right.

00:50:49.320 --> 00:50:55.500
that the core developers are still like cautioning us because they're still like issues and i don't

00:50:55.500 --> 00:51:00.940
even know when i first started using pyro inside pandas i guess about two years ago um and i tried

00:51:00.940 --> 00:51:04.580
to do a bunch of string methods and said hey this string method is not even implemented and

00:51:04.580 --> 00:51:04.980
now as

00:51:05.060 --> 00:51:05.140
far as

00:51:05.140 --> 00:51:09.600
i can tell all the string methods are um but there are there are all sorts of holes that i

00:51:09.620 --> 00:51:16.480
i have not encountered that i'm sure exist um and there there's also one big sort of downside of

00:51:16.440 --> 00:51:22.880
of using Pyro, which is if you try to retrieve things by row. So if you're doing like.ilock

00:51:23.040 --> 00:51:31.460
to retrieve by row location, it is way slower than NumPy. Because suddenly it's like, oh

00:51:31.620 --> 00:51:36.760
wait, you want to do by row? We're not so good at that. Hold your horses. Now, how often

00:51:36.760 --> 00:51:43.380
do you do that? Maybe not that often. Maybe it's not that big of a game changer. But you

00:51:43.400 --> 00:51:45.280
do need to take that into consideration. It's not a

00:51:45.560 --> 00:51:46.340
100% win.

00:51:48.500 --> 00:51:49.320
It's also, you

00:51:49.420 --> 00:51:51.160
can convert from the

00:51:51.300 --> 00:51:52.640
NumPy version to the

00:51:53.200 --> 00:51:54.220
PyArrow version, right?

00:51:55.440 --> 00:51:56.940
Yeah, yeah. So there are

00:51:57.380 --> 00:51:59.140
two different things there. So one is

00:51:59.200 --> 00:52:00.240
if you have

00:52:01.180 --> 00:52:03.180
a data frame. And so you can always use

00:52:03.280 --> 00:52:05.020
the as type method to take a series

00:52:05.560 --> 00:52:06.920
and get a new series back

00:52:07.380 --> 00:52:08.660
from it with a new dtype.

00:52:09.100 --> 00:52:11.020
So if I have n64 and I want to make it n32

00:52:11.260 --> 00:52:13.360
or vice versa, I say dot as type

00:52:13.380 --> 00:52:17.380
destination dtype, I get back a series, and I can even assign it back to that original column.

00:52:17.560 --> 00:52:22.960
And that'll work just fine. So instead, I can say as type n64py arrow, and then assign it back. And

00:52:22.960 --> 00:52:27.220
you can mix and match the dtypes. So you can have a data frame in which some dtypes are pyrow,

00:52:27.350 --> 00:52:34.740
some dtypes are numpy. Now, I just discovered literally in the last few days, in preparation

00:52:35.020 --> 00:52:41.400
for updating my talk, that there is a pandas option. Let's see, what is it? It is, I wrote

00:52:41.400 --> 00:52:46.700
this down here, future.inferString. So if you set

00:52:46.700 --> 00:52:48.020
future.inferString

00:52:48.020 --> 00:52:50.140
to be true, and then you load

00:52:50.140 --> 00:52:57.100
a CSV, all of your strings will be py arrow strings, as opposed to Python strings, as opposed to

00:52:57.240 --> 00:53:02.920
numpy strings. And they are marked as, this has got to be like, someone came up with this, numpy

00:53:03.200 --> 00:53:11.820
PyArrow. Now, what does that mean? It means that it's stored in PyArrow, but it uses some sort of

00:53:12.080 --> 00:53:18.740
NumPy API accessor so that like Pandas doesn't freak out, something like that. But it still uses

00:53:18.770 --> 00:53:23.360
like the PyArrow storage. So you're not going out to Python memory. It uses dramatically less memory

00:53:23.360 --> 00:53:28.360
than before and it's dramatically faster. And that seems like an in-between step that people might

00:53:28.360 --> 00:53:30.500
want to adopt if they have a lot of string data.

00:53:31.580 --> 00:53:33.040
That is an interesting step.

00:53:34.200 --> 00:53:42.380
When you UVPIP install Pandas, do you have to also include PyArrow in order to get these

00:53:42.960 --> 00:53:46.340
featured, or does it come along?

00:53:48.020 --> 00:53:54.800
So the official statement that I've seen is that Pandas 3 will, and I don't think there's

00:53:54.720 --> 00:53:56.660
a release date for that, Pandas 3 will

00:53:56.920 --> 00:53:58.520
require PyArrow as a dependency.

00:53:59.080 --> 00:54:00.500
So even though they're not going to change

00:54:00.960 --> 00:54:02.500
the default, it'll still be

00:54:02.600 --> 00:54:04.800
default using NumPy, but you'll have to have it around.

00:54:05.380 --> 00:54:06.780
I don't believe

00:54:07.000 --> 00:54:08.460
that it's automatically installed when you install

00:54:08.580 --> 00:54:10.480
Pandas now, so I believe that you have to

00:54:10.640 --> 00:54:11.200
pick and install

00:54:11.200 --> 00:54:12.620
both

00:54:12.760 --> 00:54:14.580
of them. It would probably raise an

00:54:14.800 --> 00:54:16.440
exception if you said the

00:54:16.600 --> 00:54:18.560
D type was string bracket PyArrow,

00:54:18.720 --> 00:54:20.060
but it didn't have PyArrow.

00:54:20.800 --> 00:54:21.740
Yes, for sure.

00:54:23.700 --> 00:54:24.680
And I haven't done

00:54:24.700 --> 00:54:26.460
a lot of investigation to this,

00:54:26.810 --> 00:54:29.580
but it seems that Pyro has a lot of rich data types

00:54:29.610 --> 00:54:32.140
and it even has lists and structs.

00:54:32.590 --> 00:54:34.700
And it seems that Pandas now has,

00:54:34.900 --> 00:54:36.560
just as it has.store and.dt

00:54:36.790 --> 00:54:38.540
to get to strings and date times,

00:54:39.020 --> 00:54:40.880
it has a.list and a.struct.

00:54:41.740 --> 00:54:43.040
I've literally written that down

00:54:43.090 --> 00:54:43.980
as something to investigate

00:54:44.240 --> 00:54:46.720
before I do my talk next month,

00:54:47.180 --> 00:54:49.280
but it seems that they're trying to expose

00:54:49.620 --> 00:54:51.640
these complex arrow data structures

00:54:52.210 --> 00:54:53.620
from within Pandas as well.

00:54:54.320 --> 00:54:54.960
How many people are

00:54:54.960 --> 00:54:55.440
really going to use it?

00:54:55.540 --> 00:54:57.060
I'm not sure, but it seems kind of interesting.

00:54:59.560 --> 00:54:59.820
It's going to

00:54:59.820 --> 00:55:00.280
be interesting

00:55:00.280 --> 00:55:00.720
to see

00:55:00.840 --> 00:55:03.960
what the row-based operation performance,

00:55:04.760 --> 00:55:05.880
what happens to that, you know?

00:55:07.480 --> 00:55:10.860
I'm just thinking, is it almost at the point currently

00:55:10.960 --> 00:55:13.520
if it's slow enough that if you know you're about to enter

00:55:13.750 --> 00:55:16.340
into a whole bunch of, asking a bunch of row-oriented questions,

00:55:16.530 --> 00:55:20.220
do you convert it to a NumPy-based data frame?

00:55:21.199 --> 00:55:23.620
Then ask a bunch of questions and then throw that away

00:55:23.640 --> 00:55:26.620
and carry on or i don't know no

00:55:26.620 --> 00:55:29.460
like you know i've been thinking about well okay how many

00:55:29.460 --> 00:55:30.000
row

00:55:30.500 --> 00:55:35.820
operations do i really do and it turns out not to be that many like i think they're making the right

00:55:36.040 --> 00:55:36.620
call here

00:55:36.620 --> 00:55:38.360
oh of course it

00:55:38.360 --> 00:55:41.700
can't be like i just don't think that they're going to leave it this

00:55:41.900 --> 00:55:46.980
slow um and i see i can't remember exactly what it was but when i started playing with

00:55:47.300 --> 00:55:51.640
pyro i remember i think it was grouping i think it was grouping or maybe joining one of those two

00:55:52.040 --> 00:55:53.560
was really, really slow.

00:55:54.220 --> 00:55:55.500
And I was in touch with one of the core developers

00:55:55.660 --> 00:55:57.160
and they were like, don't worry, we know.

00:55:57.400 --> 00:55:58.060
We're working on it.

00:55:58.240 --> 00:55:59.900
That's why it's still not ready for prime time.

00:56:00.340 --> 00:56:02.340
And it's definitely improved a ton since then.

00:56:02.620 --> 00:56:02.820
So

00:56:02.820 --> 00:56:03.760
there are definitely

00:56:03.760 --> 00:56:04.040
people

00:56:04.440 --> 00:56:05.480
working hard on this stuff.

00:56:06.900 --> 00:56:08.460
Yeah, there's probably some data structures

00:56:08.700 --> 00:56:10.300
they can compute at load time

00:56:10.880 --> 00:56:13.480
that allow them more efficient iteration

00:56:14.040 --> 00:56:15.320
of row-oriented data

00:56:15.400 --> 00:56:16.520
if it turns out to be a problem.

00:56:17.340 --> 00:56:17.740
Maybe,

00:56:17.740 --> 00:56:18.140
I

00:56:18.140 --> 00:56:19.160
don't know, maybe you could set a flag

00:56:20.220 --> 00:56:22.240
include optimizations for rows or whatever.

00:56:22.780 --> 00:56:26.400
It does a little extra work to pre-compute.

00:56:27.320 --> 00:56:31.060
Let me ask questions of that data structure and then that maps into the real

00:56:31.880 --> 00:56:35.240
columnar structure or whatever. I don't know. Who knows? It'll be interesting to see

00:56:35.240 --> 00:56:35.820
where it goes though.

00:56:37.290 --> 00:56:37.900
Yeah, for sure.

00:56:41.320 --> 00:56:42.840
So once you have

00:56:43.420 --> 00:56:47.100
columnar data or you just have PyArrow underneath in general

00:56:47.120 --> 00:56:52.940
it leads into the possibility of more direct interaction with other libraries,

00:56:54.070 --> 00:56:57.700
like speaking of things like DuckDB, right?

00:56:58.460 --> 00:57:02.700
DuckDB is really focused on analytics more than rows,

00:57:02.980 --> 00:57:04.340
like kind of SQLite versus

00:57:04.340 --> 00:57:06.660
DuckDB is kind

00:57:06.660 --> 00:57:07.740
of the same thing as,

00:57:09.040 --> 00:57:12.280
you know, Pandas versus PyArrow type thing.

00:57:13.440 --> 00:57:15.240
What do you think about the interop there?

00:57:15.420 --> 00:57:16.580
that make any differences?

00:57:17.610 --> 00:57:19.020
Having played with DuckDB, what are your thoughts?

00:57:19.800 --> 00:57:21.040
So first of all, I've played with DuckDB

00:57:21.450 --> 00:57:23.680
and it is just like astonishingly fast.

00:57:23.860 --> 00:57:26.320
Like it amazes me that something

00:57:26.600 --> 00:57:28.980
that queries Pandas data frames

00:57:29.550 --> 00:57:31.440
can be faster than Pandas itself.

00:57:32.180 --> 00:57:33.140
Right, you think that would be the,

00:57:33.400 --> 00:57:35.080
how could it possibly outrun the thing

00:57:35.180 --> 00:57:38.400
that is its foundation as part of that conversation, right?

00:57:38.820 --> 00:57:39.580
Like how could that be?

00:57:39.820 --> 00:57:40.680
And yet it is.

00:57:41.759 --> 00:57:44.440
So I increasingly see it this way,

00:57:44.500 --> 00:57:47.140
that pandas, as much as people love to hate it

00:57:47.300 --> 00:57:48.520
and they say, oh, it's got this problem

00:57:48.570 --> 00:57:50.360
and that problem and so on and so forth,

00:57:51.159 --> 00:57:53.960
it's becoming, as much as it is a package,

00:57:54.160 --> 00:57:57.080
it's becoming like a pluggable infrastructure

00:57:57.860 --> 00:57:58.740
that you'll be able to have

00:57:58.910 --> 00:58:01.040
different backend storage facilities

00:58:01.240 --> 00:58:02.960
like NumPy, PyArrow,

00:58:03.180 --> 00:58:05.340
and then those will talk to databases and so forth.

00:58:05.710 --> 00:58:07.060
And then the query structure

00:58:07.520 --> 00:58:09.600
is also looking pluggable in some ways,

00:58:09.960 --> 00:58:12.460
whether it's DuckDB or FireDucks

00:58:13.520 --> 00:58:15.640
or like who knows people will come up with more stuff

00:58:16.420 --> 00:58:18.380
and so you'll be able to sort of use pandas

00:58:18.620 --> 00:58:20.020
without using pandas almost

00:58:21.840 --> 00:58:24.300
and like choose your weapon

00:58:26.100 --> 00:58:27.860
I don't know where this is heading

00:58:27.940 --> 00:58:29.900
but I think it just cements pandas

00:58:30.440 --> 00:58:33.640
as like not just the default over stuck with it

00:58:34.020 --> 00:58:37.160
but as like the sort of meeting place

00:58:37.500 --> 00:58:39.400
for all these data manipulation libraries

00:58:39.800 --> 00:58:40.600
in the Python world

00:58:40.720 --> 00:58:49.140
Yeah. Yeah, very interesting. You know, the other big contender, I suppose, is probably Polar's, right?

00:58:50.500 --> 00:58:50.640
Right.

00:58:50.800 --> 00:58:58.380
For solving these types of problems and so on. And I believe it's also based on Pyro, right?

00:58:59.180 --> 00:59:08.440
I believe so. Right. And so a lot of it's speed. I mean, look, I have only the most positive things to say about the developers and the people working on it, people using it.

00:59:09.020 --> 00:59:11.380
It is indeed astonishingly fast.

00:59:11.610 --> 00:59:16.520
And I think that's partly due to Arrow and partly due to like very hard work by Richie and so forth.

00:59:17.260 --> 00:59:22.140
I just don't see it like sort of pushing pandas aside

00:59:22.140 --> 00:59:23.340
simply because

00:59:23.340 --> 00:59:24.380
it's too entrenched.

00:59:26.240 --> 00:59:35.960
I don't know if you remember, again, like I'm dating myself, but like years ago, the Lisp people were furious that C was like the main language.

00:59:36.480 --> 00:59:47.380
And there was this famous article called Worse is Better that basically said, how can it be that Lisp is not the number one language when we all know it's fantastic?

00:59:47.600 --> 00:59:50.140
How can this terrible language C be taking over the world?

00:59:51.080 --> 00:59:53.200
And the answer was, well, it's everywhere.

00:59:53.860 --> 00:59:57.400
And they've made a good run of getting it everywhere.

00:59:57.700 --> 00:59:58.560
So, tough luck.

00:59:59.280 --> 01:00:00.600
And I think in some ways,

01:00:00.920 --> 01:00:02.200
even if

01:00:02.200 --> 01:00:06.840
Polars is better, like Pandas is there and people are using it.

01:00:07.080 --> 01:00:14.240
And you go try telling all these banks, nah, we're going to throw out all the Pandas work we've done in a lot of years and put in Polars.

01:00:14.780 --> 01:00:15.020
Which is not

01:00:15.020 --> 01:00:15.500
going to happen.

01:00:15.980 --> 01:00:17.040
No, it's not going to happen.

01:00:17.680 --> 01:00:26.400
I do think there's interesting libraries like I interviewed Marco from Narwhals, which is like an interoperability story between those two.

01:00:28.420 --> 01:00:29.440
I've heard about it.

01:00:29.860 --> 01:00:30.780
I've heard you talk about it.

01:00:31.120 --> 01:00:33.480
I've played with it a tiny, tiny bit,

01:00:33.940 --> 01:00:36.520
but not enough to really have a real opinion.

01:00:36.940 --> 01:00:37.860
But as far as I'm concerned,

01:00:38.180 --> 01:00:41.220
anything that does interoperability, like, fantastic.

01:00:42.100 --> 01:00:44.400
It's pretty interesting in that it basically,

01:00:44.680 --> 01:00:46.440
it knows if you pass it a Pandas data frame

01:00:47.200 --> 01:00:48.060
or a Polar's data frame,

01:00:48.260 --> 01:00:50.340
and then it kind of adapts what it does

01:00:53.040 --> 01:00:55.500
to allow you to sort of operate on either,

01:00:55.960 --> 01:00:58.020
kind of with the same operations,

01:00:58.280 --> 01:00:59.880
which is pretty interesting.

01:00:59.950 --> 01:01:01.460
But you do have to use the Polar's API,

01:01:01.720 --> 01:01:04.300
so that's something there, I suppose.

01:01:05.800 --> 01:01:10.720
Yeah, and I think this PyArrow change that's coming along

01:01:11.520 --> 01:01:13.400
is going to be powerful, right?

01:01:13.620 --> 01:01:17.180
Certainly the speed is going to be well appreciated.

01:01:17.270 --> 01:01:20.740
The ability to load larger amounts of data

01:01:20.890 --> 01:01:25.400
rather than duplicating a bunch of strings and so on is great.

01:01:26.440 --> 01:01:29.920
But what do you see as the pitfalls or the challenges?

01:01:30.200 --> 01:01:31.300
You know, we're getting short on time here.

01:01:31.420 --> 01:01:37.040
Maybe we could wrap it up with like both a statement of encouragement

01:01:37.360 --> 01:01:41.360
and steps to take, but also maybe warnings to be looking out for.

01:01:42.940 --> 01:01:44.160
I don't think I have too many warnings.

01:01:44.360 --> 01:01:51.080
Like so far, I think the Pandas core developers have been very cautious and slow.

01:01:51.740 --> 01:01:54.480
Probably some people would argue too slow, but I think it's good.

01:01:54.620 --> 01:01:55.560
Like this is people's data.

01:01:55.900 --> 01:01:57.540
This is like a serious thing.

01:01:58.860 --> 01:01:59.420
Take it slowly.

01:01:59.760 --> 01:02:00.180
Be careful.

01:02:00.740 --> 01:02:02.900
Make sure everything is really working the right way and working quickly.

01:02:04.680 --> 01:02:07.960
But I think like it's very encouraging.

01:02:08.010 --> 01:02:14.140
And I would say if you're using Pandas right now, it's worth doing like taking a little detour for a little bit of time.

01:02:14.880 --> 01:02:15.960
Try out PyArrow.

01:02:16.180 --> 01:02:17.020
Try out these other details.

01:02:17.170 --> 01:02:21.660
At the very least, you should certainly be using PyArrow to be loading your CSVs.

01:02:21.860 --> 01:02:26.500
And you should even try out this loading of strings that I just discovered recently.

01:02:27.060 --> 01:02:37.260
I think just those things alone might speed up your pipeline to give you faster iterations and feel better about it.

01:02:38.680 --> 01:02:46.220
And just be ready at some point, right, at some point in the next few years, I don't know exactly when, they're going to flip that switch and say Pyro is now the default.

01:02:46.800 --> 01:02:50.580
And you will be able to, I find it impossible to believe that they're going to say, and we're chucking NumPy.

01:02:50.740 --> 01:02:51.280
That's not going to happen.

01:02:51.400 --> 01:02:53.280
but you will need to say explicitly,

01:02:53.360 --> 01:02:54.140
I want to stick with it.

01:02:54.300 --> 01:02:54.760
And some people,

01:02:55.100 --> 01:02:57.440
I think a lot of people are going to find it advantageous to,

01:02:57.700 --> 01:02:59.340
to make that change along with pandas.

01:03:00.900 --> 01:03:01.300
Yeah.

01:03:01.380 --> 01:03:01.860
It's going to be exciting.

01:03:02.540 --> 01:03:03.320
It is going to be exciting.

01:03:05.240 --> 01:03:09.640
So one area maybe I could ask you about is reproducibility.

01:03:10.660 --> 01:03:11.880
That matters for businesses.

01:03:12.580 --> 01:03:13.220
Like you want to go like,

01:03:13.300 --> 01:03:13.400
well,

01:03:13.400 --> 01:03:16.460
we ran this report and we made this important decision to spend a billion

01:03:16.620 --> 01:03:18.380
dollars on this thing based on this analysis.

01:03:19.660 --> 01:03:20.140
Still good.

01:03:21.580 --> 01:03:22.240
can we make a mistake?

01:03:22.900 --> 01:03:24.280
but certainly in the sciences

01:03:25.260 --> 01:03:25.700
right?

01:03:26.500 --> 01:03:28.000
like people build upon papers

01:03:28.260 --> 01:03:30.240
and theories as if

01:03:30.340 --> 01:03:32.320
they are perfectly solid building blocks

01:03:32.920 --> 01:03:33.880
and if those things were to

01:03:34.580 --> 01:03:36.160
have trouble that would be a real big problem

01:03:36.740 --> 01:03:38.240
you want to be able to rerun your code

01:03:38.740 --> 01:03:39.980
10-15 years later

01:03:41.880 --> 01:03:43.460
changes like this could make it

01:03:43.980 --> 01:03:45.840
not tomorrow or the next day but

01:03:46.060 --> 01:03:47.920
eventually you could see it drifting far enough where

01:03:48.060 --> 01:03:50.160
it's like oh we're kind of done with NumPy

01:03:50.180 --> 01:03:52.040
and we're moving on to this thing.

01:03:52.090 --> 01:03:54.420
And eventually it might be tricky

01:03:54.980 --> 01:03:57.540
to get exact reproducibility.

01:03:59.300 --> 01:03:59.440
Right.

01:03:59.480 --> 01:04:00.300
It's sort of like,

01:04:00.410 --> 01:04:03.720
I remember I saw a talk about porting,

01:04:03.840 --> 01:04:04.640
if I remember correctly,

01:04:05.170 --> 01:04:07.640
like NumPy to Wasm.

01:04:08.540 --> 01:04:09.000
And they were like,

01:04:09.080 --> 01:04:10.980
did you know that NumPy requires Fortran?

01:04:12.240 --> 01:04:13.020
And so we had to like,

01:04:13.340 --> 01:04:14.240
like, I think it's NumPy.

01:04:14.270 --> 01:04:15.840
Like there was some part of this whole,

01:04:16.160 --> 01:04:16.300
like

01:04:16.300 --> 01:04:17.160
the PyData stack,

01:04:17.700 --> 01:04:19.359
and none of us would have expected this

01:04:19.380 --> 01:04:21.020
because we're all like Fortran, right?

01:04:21.170 --> 01:04:21.760
Who uses that?

01:04:21.850 --> 01:04:23.680
But it turns out, right, people use these things.

01:04:24.220 --> 01:04:25.940
So people are going to have to take this into account.

01:04:26.070 --> 01:04:28.280
I think NumPy will still be around.

01:04:28.400 --> 01:04:30.520
Look, it's still a very actively used package.

01:04:31.040 --> 01:04:35.040
It's just not a good match for a lot of things that Pandas is doing.

01:04:35.800 --> 01:04:38.600
So you might need to, I don't know, put in your package specification

01:04:39.060 --> 01:04:42.680
what versions you want, that you do want NumPy to be included.

01:04:42.910 --> 01:04:44.560
Like, it might be a little harder in the future.

01:04:45.160 --> 01:04:47.660
I don't think, like, there's enough of an installed base.

01:04:48.080 --> 01:04:51.040
I don't think they're going to just like throw people to the wolves.

01:04:51.340 --> 01:04:52.180
I think it's going to be,

01:04:52.760 --> 01:04:55.020
it's not going to be a Python two to three situation.

01:04:55.450 --> 01:04:55.580
I

01:04:55.580 --> 01:04:56.840
think enough of us have enough

01:04:56.840 --> 01:04:58.760
like emotional scarring

01:04:58.760 --> 01:05:00.540
that

01:05:00.540 --> 01:05:01.760
it's not going to happen.

01:05:04.580 --> 01:05:05.440
Yeah, I agree.

01:05:05.510 --> 01:05:06.220
I don't think it will happen.

01:05:06.320 --> 01:05:09.080
I'm just thinking, you know, over the longterm,

01:05:09.170 --> 01:05:14.120
you can see sort of a slight eroding to the point where maybe,

01:05:15.020 --> 01:05:18.700
I mean, do we really think about running the same code 20 years later?

01:05:19.300 --> 01:05:21.260
Sometimes, but not that often.

01:05:22.380 --> 01:05:23.000
Not that often.

01:05:23.480 --> 01:05:23.920
I mean,

01:05:23.940 --> 01:05:25.260
Python's only 30 years old.

01:05:26.020 --> 01:05:27.120
NumPy's only 20, right?

01:05:27.720 --> 01:05:28.980
That's double its life, right?

01:05:29.060 --> 01:05:30.360
That's a long ways out.

01:05:31.200 --> 01:05:32.520
Pandas is less old.

01:05:34.080 --> 01:05:35.040
Right, right.

01:05:35.460 --> 01:05:36.940
I'm not too worried about that,

01:05:37.500 --> 01:05:40.480
but someone somewhere is going to get the short end of the stick

01:05:41.000 --> 01:05:44.060
a number of years from now, and that's okay.

01:05:44.260 --> 01:05:45.620
That's what their grad students are for.

01:05:46.760 --> 01:05:47.760
They can't rewrite it.

01:05:48.320 --> 01:05:52.080
No, more seriously, maybe pin your versions, right?

01:05:52.260 --> 01:05:53.920
If you're doing any sort of reproducibility,

01:05:54.440 --> 01:05:55.340
definitely pin your versions,

01:05:55.460 --> 01:05:59.320
but maybe even download some wheels

01:05:59.520 --> 01:06:02.680
and just hang on to some wheels for Linux

01:06:02.860 --> 01:06:04.740
or do a Docker sort of thing or something like that.

01:06:04.760 --> 01:06:05.000
Who knows?

01:06:07.260 --> 01:06:07.640
That's right.

01:06:08.620 --> 01:06:08.880
All right.

01:06:09.640 --> 01:06:11.139
And all these problems are obviously

01:06:12.000 --> 01:06:12.800
a sign of it being

01:06:13.720 --> 01:06:15.600
so successful, right? Pandas being so successful.

01:06:17.260 --> 01:06:17.800
Oh, for sure.

01:06:18.740 --> 01:06:19.500
The numbers are just

01:06:19.760 --> 01:06:21.480
astonishing. I think the last estimate were like

01:06:21.480 --> 01:06:23.360
they're between 5 and 10 million

01:06:23.640 --> 01:06:24.940
people using pandas nowadays.

01:06:26.140 --> 01:06:27.420
And let's assume

01:06:27.580 --> 01:06:29.160
that's like off by a factor of 10.

01:06:30.000 --> 01:06:31.280
It's still an astonishing number.

01:06:32.220 --> 01:06:32.980
It is astonishing.

01:06:34.220 --> 01:06:34.640
It's amazing.

01:06:35.240 --> 01:06:37.380
Well, we're

01:06:37.380 --> 01:06:38.320
going to be at PyCon.

01:06:40.860 --> 01:06:41.760
I got to book some stuff.

01:06:44.500 --> 01:06:46.660
In like five weeks from the time of recording,

01:06:46.900 --> 01:06:50.460
even less time from the time of release, maybe two weeks.

01:06:51.580 --> 01:06:52.480
Tell people about your talk.

01:06:52.520 --> 01:06:55.860
They can come see your dive into this,

01:06:56.240 --> 01:06:57.300
which I think will be fairly different.

01:06:57.480 --> 01:06:59.680
We didn't just go right down the slides of your talk

01:06:59.680 --> 01:07:00.400
or nothing like that.

01:07:00.980 --> 01:07:01.420
So there's

01:07:01.420 --> 01:07:02.100
a lot to learn from

01:07:02.100 --> 01:07:02.740
going to your talk.

01:07:04.160 --> 01:07:06.600
Yeah, the talk is much more like code oriented.

01:07:06.860 --> 01:07:09.620
Like here are like, here's how it looks.

01:07:09.860 --> 01:07:10.520
Here's how it works.

01:07:10.860 --> 01:07:12.560
Here's like a speed comparison.

01:07:13.120 --> 01:07:13.740
Here's where it's better.

01:07:13.960 --> 01:07:14.540
Here's where it's worse.

01:07:16.800 --> 01:07:18.700
I haven't told people about the title.

01:07:19.760 --> 01:07:20.340
Oh, yes.

01:07:20.520 --> 01:07:24.460
So it's called The Pie Arrow Revolution in Pandas.

01:07:25.900 --> 01:07:26.580
And it's

01:07:26.580 --> 01:07:28.480
going to be Friday morning.

01:07:28.980 --> 01:07:29.860
I think I'm telling the

01:07:29.860 --> 01:07:30.360
truth there.

01:07:30.580 --> 01:07:32.820
Get people while they're fresh.

01:07:34.480 --> 01:07:34.880
Yeah, exactly.

01:07:35.140 --> 01:07:37.240
I will not be standing between them and lunch,

01:07:37.620 --> 01:07:39.980
which has often been the case in previous talks.

01:07:40.999 --> 01:07:42.960
And strangely, you don't get a lot of questions then.

01:07:43.440 --> 01:07:44.120
That's interesting.

01:07:44.210 --> 01:07:45.000
I wonder how that works.

01:07:45.980 --> 01:07:46.940
No, you don't want that.

01:07:46.970 --> 01:07:48.320
And you don't want the last talk of the day,

01:07:48.650 --> 01:07:49.500
the last talk of the conference.

01:07:50.679 --> 01:07:52.740
But I mean, it's still good.

01:07:52.960 --> 01:07:53.760
People still appreciate it.

01:07:53.900 --> 01:07:57.320
But it's just, it's the reality of travel and airplanes

01:07:57.760 --> 01:07:59.540
and hunger and all these things.

01:07:59.720 --> 01:08:00.260
So really good.

01:08:00.800 --> 01:08:02.060
I encourage people to go check out your talk.

01:08:02.620 --> 01:08:03.460
And it should be fun.

01:08:03.470 --> 01:08:04.580
It should probably be up on YouTube.

01:08:05.040 --> 01:08:11.240
I don't know what the time frame this year for talks being converted to YouTube videos will be, but eventually.

01:08:12.760 --> 01:08:14.720
Yeah, usually it's like, what, like two months or so after the

01:08:14.720 --> 01:08:14.820
conference.

01:08:14.840 --> 01:08:15.520
Yeah, something like that.

01:08:15.680 --> 01:08:16.520
I'm pretty confident.

01:08:17.420 --> 01:08:17.799
Yeah, absolutely.

01:08:18.220 --> 01:08:18.420
Indeed.

01:08:20.140 --> 01:08:21.779
Reuben, always great to catch up with you.

01:08:22.000 --> 01:08:22.640
Thanks for being on the show.

01:08:23.680 --> 01:08:24.359
My great pleasure.

01:08:24.560 --> 01:08:24.980
I'll see you in a month.

01:08:25.600 --> 01:08:25.720
Yep.

01:08:26.000 --> 01:08:26.100
Bye.

